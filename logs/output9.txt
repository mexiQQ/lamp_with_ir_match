


Command: attack3.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 1000 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
*********************************
*********************************
average of cosine similarity 0.9992717148301148
highest_index [0]
highest [0.9992717148301148]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.007138967514038 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9407122731208801 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9282891750335693 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9228073954582214 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8491121530532837 for ['[CLS] panel officer [SEP]']
Nsteps: 1000



Command: attack3.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 1000 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
*********************************
*********************************
average of cosine similarity 0.9992717148301148
highest_index [0]
highest [0.9992717148301148]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.007138967514038 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9407122731208801 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9282891750335693 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9228073954582214 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8491121530532837 for ['[CLS] panel officer [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=2.567 (perp=11.621, rec=0.243, cos=0.000), tot_loss_proj:2.619 [t=0.25s]
prediction: ['[CLS] severe disappointed [SEP]']
[ 100/1000] tot_loss=2.581 (perp=12.062, rec=0.168, cos=0.000), tot_loss_proj:2.804 [t=0.27s]
prediction: ['[CLS] gothic disappointed [SEP]']
[ 150/1000] tot_loss=2.163 (perp=10.251, rec=0.113, cos=0.000), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 200/1000] tot_loss=2.133 (perp=10.251, rec=0.083, cos=0.000), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/1000] tot_loss=2.120 (perp=10.251, rec=0.070, cos=0.000), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/1000] tot_loss=2.126 (perp=10.251, rec=0.075, cos=0.000), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/1000] tot_loss=2.107 (perp=10.251, rec=0.057, cos=0.000), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/1000] tot_loss=2.104 (perp=10.251, rec=0.054, cos=0.000), tot_loss_proj:2.116 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/1000] tot_loss=2.127 (perp=10.251, rec=0.077, cos=0.000), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/1000] tot_loss=2.115 (perp=10.251, rec=0.064, cos=0.000), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/1000] tot_loss=2.110 (perp=10.251, rec=0.060, cos=0.000), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/1000] tot_loss=2.099 (perp=10.251, rec=0.049, cos=0.000), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/1000] tot_loss=2.110 (perp=10.251, rec=0.060, cos=0.000), tot_loss_proj:2.116 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/1000] tot_loss=2.110 (perp=10.251, rec=0.060, cos=0.000), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/1000] tot_loss=2.109 (perp=10.251, rec=0.059, cos=0.000), tot_loss_proj:2.126 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/1000] tot_loss=2.111 (perp=10.251, rec=0.060, cos=0.000), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/1000] tot_loss=2.118 (perp=10.251, rec=0.067, cos=0.000), tot_loss_proj:2.119 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/1000] tot_loss=2.117 (perp=10.251, rec=0.067, cos=0.000), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/1000] tot_loss=2.106 (perp=10.251, rec=0.055, cos=0.000), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/1000] tot_loss=2.114 (perp=10.251, rec=0.064, cos=0.000), tot_loss_proj:2.112 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:06:10 | total time: 0:06:10


Running input #1 of 100.
reference: 
========================
splendidly 
========================
*********************************
*********************************
average of cosine similarity 0.9993551321672909
highest_index [0]
highest [0.9993551321672909]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0177645683288574 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9790513515472412 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8988101482391357 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.8692125678062439 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8281160593032837 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8196386694908142 for ['[CLS] siam presidents [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=2.658 (perp=12.059, rec=0.246, cos=0.000), tot_loss_proj:2.760 [t=0.25s]
prediction: ['[CLS] splendid successful [SEP]']
[ 100/1000] tot_loss=2.199 (perp=10.288, rec=0.142, cos=0.000), tot_loss_proj:2.349 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/1000] tot_loss=2.138 (perp=10.288, rec=0.081, cos=0.000), tot_loss_proj:2.336 [t=0.26s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Put prefix at the end
[ 200/1000] tot_loss=1.896 (perp=9.171, rec=0.062, cos=0.000), tot_loss_proj:1.899 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/1000] tot_loss=1.901 (perp=9.171, rec=0.067, cos=0.000), tot_loss_proj:1.889 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/1000] tot_loss=1.900 (perp=9.171, rec=0.066, cos=0.000), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/1000] tot_loss=1.893 (perp=9.171, rec=0.059, cos=0.000), tot_loss_proj:1.881 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/1000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.000), tot_loss_proj:1.886 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/1000] tot_loss=1.887 (perp=9.171, rec=0.052, cos=0.000), tot_loss_proj:1.897 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/1000] tot_loss=1.897 (perp=9.171, rec=0.063, cos=0.000), tot_loss_proj:1.896 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/1000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.000), tot_loss_proj:1.891 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/1000] tot_loss=1.894 (perp=9.171, rec=0.060, cos=0.000), tot_loss_proj:1.897 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/1000] tot_loss=1.887 (perp=9.171, rec=0.053, cos=0.000), tot_loss_proj:1.883 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/1000] tot_loss=1.906 (perp=9.171, rec=0.072, cos=0.000), tot_loss_proj:1.900 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/1000] tot_loss=1.891 (perp=9.171, rec=0.057, cos=0.000), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/1000] tot_loss=1.902 (perp=9.171, rec=0.068, cos=0.000), tot_loss_proj:1.899 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/1000] tot_loss=1.892 (perp=9.171, rec=0.058, cos=0.000), tot_loss_proj:1.889 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/1000] tot_loss=1.891 (perp=9.171, rec=0.056, cos=0.000), tot_loss_proj:1.904 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/1000] tot_loss=1.888 (perp=9.171, rec=0.054, cos=0.000), tot_loss_proj:1.890 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/1000] tot_loss=1.900 (perp=9.171, rec=0.066, cos=0.000), tot_loss_proj:1.903 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:06:06 | total time: 0:12:16


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
*********************************
*********************************
average of cosine similarity 0.9994339133342427
highest_index [0]
highest [0.9994339133342427]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8392523527145386 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8272891640663147 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8063728213310242 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.8014678955078125 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.792872428894043 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7871421575546265 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7870720028877258 for ['[CLS] working we would [SEP]']
[Init] best perm rec loss: 0.7757318615913391 for ['[CLS] would we working [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=2.533 (perp=10.604, rec=0.412, cos=0.000), tot_loss_proj:2.757 [t=0.28s]
prediction: ['[CLS] very momentum growth [SEP]']
[ 100/1000] tot_loss=2.407 (perp=10.889, rec=0.229, cos=0.000), tot_loss_proj:2.621 [t=0.27s]
prediction: ['[CLS] much momentum gaining [SEP]']
[ 150/1000] tot_loss=2.280 (perp=10.889, rec=0.102, cos=0.000), tot_loss_proj:2.620 [t=0.26s]
prediction: ['[CLS] much momentum gaining [SEP]']
Attempt swap
Moved token
[ 200/1000] tot_loss=1.787 (perp=8.515, rec=0.084, cos=0.000), tot_loss_proj:1.783 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/1000] tot_loss=1.781 (perp=8.515, rec=0.078, cos=0.000), tot_loss_proj:1.783 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/1000] tot_loss=1.767 (perp=8.515, rec=0.065, cos=0.000), tot_loss_proj:1.792 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/1000] tot_loss=1.770 (perp=8.515, rec=0.067, cos=0.000), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/1000] tot_loss=1.770 (perp=8.515, rec=0.067, cos=0.000), tot_loss_proj:1.786 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/1000] tot_loss=1.766 (perp=8.515, rec=0.063, cos=0.000), tot_loss_proj:1.785 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/1000] tot_loss=1.769 (perp=8.515, rec=0.066, cos=0.000), tot_loss_proj:1.786 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/1000] tot_loss=1.768 (perp=8.515, rec=0.065, cos=0.000), tot_loss_proj:1.793 [t=0.28s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/1000] tot_loss=1.771 (perp=8.515, rec=0.068, cos=0.000), tot_loss_proj:1.783 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/1000] tot_loss=1.772 (perp=8.515, rec=0.069, cos=0.000), tot_loss_proj:1.802 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/1000] tot_loss=1.772 (perp=8.515, rec=0.069, cos=0.000), tot_loss_proj:1.789 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/1000] tot_loss=1.774 (perp=8.515, rec=0.071, cos=0.000), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/1000] tot_loss=1.765 (perp=8.515, rec=0.062, cos=0.000), tot_loss_proj:1.780 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/1000] tot_loss=1.768 (perp=8.515, rec=0.065, cos=0.000), tot_loss_proj:1.789 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/1000] tot_loss=1.757 (perp=8.515, rec=0.054, cos=0.000), tot_loss_proj:1.782 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/1000] tot_loss=1.756 (perp=8.515, rec=0.053, cos=0.000), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/1000] tot_loss=1.768 (perp=8.515, rec=0.065, cos=0.000), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:06:01 | total time: 0:18:18


Running input #3 of 100.
reference: 
========================
flawless film 
========================
*********************************
*********************************
average of cosine similarity 0.9992999820989845
highest_index [0]
highest [0.9992999820989845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0147576332092285 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9051364660263062 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8755358457565308 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8479909896850586 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8464451432228088 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.839372456073761 for ['[CLS] anthony robin [SEP]']
[Init] best perm rec loss: 0.8365500569343567 for ['[CLS] robin anthony [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=1.914 (perp=8.385, rec=0.237, cos=0.000), tot_loss_proj:1.757 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/1000] tot_loss=1.754 (perp=8.385, rec=0.077, cos=0.000), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/1000] tot_loss=1.745 (perp=8.385, rec=0.068, cos=0.000), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 200/1000] tot_loss=1.723 (perp=8.385, rec=0.046, cos=0.000), tot_loss_proj:1.746 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/1000] tot_loss=1.740 (perp=8.385, rec=0.063, cos=0.000), tot_loss_proj:1.749 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/1000] tot_loss=1.734 (perp=8.385, rec=0.057, cos=0.000), tot_loss_proj:1.748 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/1000] tot_loss=1.748 (perp=8.385, rec=0.071, cos=0.000), tot_loss_proj:1.740 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/1000] tot_loss=1.746 (perp=8.385, rec=0.069, cos=0.000), tot_loss_proj:1.755 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/1000] tot_loss=1.743 (perp=8.385, rec=0.066, cos=0.000), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/1000] tot_loss=1.743 (perp=8.385, rec=0.066, cos=0.000), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/1000] tot_loss=1.738 (perp=8.385, rec=0.061, cos=0.000), tot_loss_proj:1.746 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/1000] tot_loss=1.736 (perp=8.385, rec=0.059, cos=0.000), tot_loss_proj:1.755 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/1000] tot_loss=1.744 (perp=8.385, rec=0.067, cos=0.000), tot_loss_proj:1.753 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/1000] tot_loss=1.728 (perp=8.385, rec=0.051, cos=0.000), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/1000] tot_loss=1.741 (perp=8.385, rec=0.064, cos=0.000), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/1000] tot_loss=1.746 (perp=8.385, rec=0.069, cos=0.000), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/1000] tot_loss=1.733 (perp=8.385, rec=0.056, cos=0.000), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/1000] tot_loss=1.733 (perp=8.385, rec=0.056, cos=0.000), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/1000] tot_loss=1.732 (perp=8.385, rec=0.055, cos=0.000), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/1000] tot_loss=1.742 (perp=8.385, rec=0.065, cos=0.000), tot_loss_proj:1.767 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:06:01 | total time: 0:24:19


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
*********************************
*********************************
average of cosine similarity 0.9992303367026724
highest_index [0]
highest [0.9992303367026724]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0336333513259888 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9788164496421814 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9638258218765259 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9627301096916199 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9335359930992126 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.92412930727005 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9173402190208435 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8947184681892395 for ['[CLS] fatedss jack [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=3.344 (perp=15.347, rec=0.274, cos=0.000), tot_loss_proj:3.720 [t=0.26s]
prediction: ['[CLS] tires badlyential [SEP]']
[ 100/1000] tot_loss=1.630 (perp=7.515, rec=0.127, cos=0.000), tot_loss_proj:1.559 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/1000] tot_loss=1.591 (perp=7.515, rec=0.088, cos=0.000), tot_loss_proj:1.581 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 200/1000] tot_loss=1.582 (perp=7.515, rec=0.079, cos=0.000), tot_loss_proj:1.567 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/1000] tot_loss=1.580 (perp=7.515, rec=0.077, cos=0.000), tot_loss_proj:1.560 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/1000] tot_loss=1.573 (perp=7.515, rec=0.070, cos=0.000), tot_loss_proj:1.555 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/1000] tot_loss=1.568 (perp=7.515, rec=0.065, cos=0.000), tot_loss_proj:1.560 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/1000] tot_loss=1.574 (perp=7.515, rec=0.071, cos=0.000), tot_loss_proj:1.564 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/1000] tot_loss=1.555 (perp=7.515, rec=0.052, cos=0.000), tot_loss_proj:1.561 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/1000] tot_loss=1.570 (perp=7.515, rec=0.067, cos=0.000), tot_loss_proj:1.562 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/1000] tot_loss=1.565 (perp=7.515, rec=0.062, cos=0.000), tot_loss_proj:1.560 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/1000] tot_loss=1.570 (perp=7.515, rec=0.067, cos=0.000), tot_loss_proj:1.559 [t=0.29s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/1000] tot_loss=1.562 (perp=7.515, rec=0.059, cos=0.000), tot_loss_proj:1.573 [t=0.29s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/1000] tot_loss=1.568 (perp=7.515, rec=0.065, cos=0.000), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/1000] tot_loss=1.569 (perp=7.515, rec=0.066, cos=0.000), tot_loss_proj:1.575 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/1000] tot_loss=1.554 (perp=7.515, rec=0.051, cos=0.000), tot_loss_proj:1.563 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/1000] tot_loss=1.576 (perp=7.515, rec=0.072, cos=0.000), tot_loss_proj:1.571 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/1000] tot_loss=1.563 (perp=7.515, rec=0.060, cos=0.000), tot_loss_proj:1.568 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/1000] tot_loss=1.568 (perp=7.515, rec=0.065, cos=0.000), tot_loss_proj:1.577 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/1000] tot_loss=1.580 (perp=7.515, rec=0.077, cos=0.000), tot_loss_proj:1.567 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:06:05 | total time: 0:30:24


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
*********************************
*********************************
average of cosine similarity 0.9993645304966434
highest_index [0]
highest [0.9993645304966434]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.95821613073349 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9501219987869263 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9497746825218201 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9327423572540283 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.9101260304450989 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8901438117027283 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.889305830001831 for ['[CLS]. quiet [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=2.246 (perp=10.400, rec=0.167, cos=0.000), tot_loss_proj:2.359 [t=0.26s]
prediction: ['[CLS] good ease [SEP]']
[ 100/1000] tot_loss=2.552 (perp=12.316, rec=0.089, cos=0.000), tot_loss_proj:2.519 [t=0.27s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 150/1000] tot_loss=2.532 (perp=12.316, rec=0.069, cos=0.000), tot_loss_proj:2.523 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 200/1000] tot_loss=2.524 (perp=12.316, rec=0.060, cos=0.000), tot_loss_proj:2.530 [t=0.28s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 250/1000] tot_loss=2.527 (perp=12.316, rec=0.064, cos=0.000), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 300/1000] tot_loss=2.517 (perp=12.316, rec=0.053, cos=0.000), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 350/1000] tot_loss=2.522 (perp=12.316, rec=0.058, cos=0.000), tot_loss_proj:2.515 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 400/1000] tot_loss=2.523 (perp=12.316, rec=0.060, cos=0.000), tot_loss_proj:2.524 [t=0.27s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 450/1000] tot_loss=2.532 (perp=12.316, rec=0.069, cos=0.000), tot_loss_proj:2.522 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 500/1000] tot_loss=2.522 (perp=12.316, rec=0.059, cos=0.000), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 550/1000] tot_loss=2.523 (perp=12.316, rec=0.059, cos=0.000), tot_loss_proj:2.523 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 600/1000] tot_loss=2.524 (perp=12.316, rec=0.060, cos=0.000), tot_loss_proj:2.534 [t=0.28s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 650/1000] tot_loss=2.522 (perp=12.316, rec=0.058, cos=0.000), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 700/1000] tot_loss=2.531 (perp=12.316, rec=0.068, cos=0.000), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 750/1000] tot_loss=2.520 (perp=12.316, rec=0.057, cos=0.000), tot_loss_proj:2.519 [t=0.27s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 800/1000] tot_loss=2.511 (perp=12.316, rec=0.048, cos=0.000), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 850/1000] tot_loss=2.531 (perp=12.316, rec=0.068, cos=0.000), tot_loss_proj:2.524 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 900/1000] tot_loss=2.533 (perp=12.316, rec=0.070, cos=0.000), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 950/1000] tot_loss=2.531 (perp=12.316, rec=0.068, cos=0.000), tot_loss_proj:2.527 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1000/1000] tot_loss=2.518 (perp=12.316, rec=0.054, cos=0.000), tot_loss_proj:2.517 [t=0.27s]
prediction: ['[CLS] enjoyable ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] enjoyable ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #5 time: 0:06:02 | total time: 0:36:27


Running input #6 of 100.
reference: 
========================
grayish 
========================
*********************************
*********************************
average of cosine similarity 0.9992503249766884
highest_index [0]
highest [0.9992503249766884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9550511240959167 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.953325092792511 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9326099753379822 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.874465823173523 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8655936121940613 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8069045543670654 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.785679817199707 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7714593410491943 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.755589485168457 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7480524778366089 for ['[CLS] too u2 [SEP]']
Nsteps: 1000
[  50/1000] tot_loss=2.528 (perp=11.047, rec=0.318, cos=0.000), tot_loss_proj:3.243 [t=0.30s]
prediction: ['[CLS] bother gray [SEP]']
[ 100/1000] tot_loss=1.574 (perp=6.813, rec=0.212, cos=0.000), tot_loss_proj:2.614 [t=0.28s]
prediction: ['[CLS] gray gray [SEP]']
[ 150/1000] tot_loss=2.226 (perp=10.461, rec=0.134, cos=0.000), tot_loss_proj:2.428 [t=0.28s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Put prefix at the end
[ 200/1000] tot_loss=1.709 (perp=8.089, rec=0.091, cos=0.000), tot_loss_proj:1.687 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/1000] tot_loss=1.681 (perp=8.089, rec=0.063, cos=0.000), tot_loss_proj:1.687 [t=0.30s]
prediction: ['[CLS] grayish [SEP]']
[ 300/1000] tot_loss=1.689 (perp=8.089, rec=0.071, cos=0.000), tot_loss_proj:1.685 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/1000] tot_loss=1.692 (perp=8.089, rec=0.074, cos=0.000), tot_loss_proj:1.680 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/1000] tot_loss=1.670 (perp=8.089, rec=0.052, cos=0.000), tot_loss_proj:1.685 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
[ 450/1000] tot_loss=1.682 (perp=8.089, rec=0.064, cos=0.000), tot_loss_proj:1.683 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/1000] tot_loss=1.673 (perp=8.089, rec=0.055, cos=0.000), tot_loss_proj:1.688 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/1000] tot_loss=1.686 (perp=8.089, rec=0.068, cos=0.000), tot_loss_proj:1.683 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
[ 600/1000] tot_loss=1.668 (perp=8.089, rec=0.050, cos=0.000), tot_loss_proj:1.677 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/1000] tot_loss=1.682 (perp=8.089, rec=0.064, cos=0.000), tot_loss_proj:1.680 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/1000] tot_loss=1.682 (perp=8.089, rec=0.065, cos=0.000), tot_loss_proj:1.691 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
[ 750/1000] tot_loss=1.676 (perp=8.089, rec=0.059, cos=0.000), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/1000] tot_loss=1.693 (perp=8.089, rec=0.075, cos=0.000), tot_loss_proj:1.674 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/1000] tot_loss=1.697 (perp=8.089, rec=0.080, cos=0.000), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 900/1000] tot_loss=1.685 (perp=8.089, rec=0.067, cos=0.000), tot_loss_proj:1.685 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/1000] tot_loss=1.672 (perp=8.089, rec=0.054, cos=0.000), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/1000] tot_loss=1.672 (perp=8.089, rec=0.054, cos=0.000), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #6 time: 0:06:15 | total time: 0:42:43


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
*********************************
*********************************
average of cosine similarity 0.9991777446374113
highest_index [0]
highest [0.9991777446374113]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9109516739845276 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8394120335578918 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8297978639602661 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.8297332525253296 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7952309846878052 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7945571541786194 for ['[CLS] 17th alec diseasenieside madagascar gold on none pacific animal depending moffat consisting main ran life classics career battalion blow mukherjeezed sony manual tourism [SEP]']
[Init] best perm rec loss: 0.7937612533569336 for ['[CLS] consisting sonyzed battalion classics life blownies gold career depending manual mukherjee animal main tourismide none ran pacific 17th madagascar alec on moffat disease [SEP]']
[Init] best perm rec loss: 0.7936407923698425 for ['[CLS]ide disease on mukherjee blow manual tourism battalion consisting madagascar animal moffat classics main 17th pacific none life depending gold career aleczednies sony ran [SEP]']
[Init] best perm rec loss: 0.7926773428916931 for ['[CLS] career disease blow ran depending nonenies tourism manual life mukherjee pacific 17th main consisting alec on battalion moffat sony madagascar goldzedide classics animal [SEP]']
[Init] best perm rec loss: 0.7919961214065552 for ['[CLS] main battalion classics aleczed sony gold madagascar disease mukherjee depending manual on pacific life tourismide animal career blow moffat none consisting 17th rannies [SEP]']
[Init] best perm rec loss: 0.7916224598884583 for ['[CLS] mukherjee gold pacific classics manual tourism blow mainzed alec lifenies battalion disease madagascar noneide animal consisting ran depending sony career on 17th moffat [SEP]']
[Init] best perm rec loss: 0.7910394072532654 for ['[CLS]zed ran diseaseide 17th tourism main classics blow consisting mukherjee depending gold life animal on pacific moffat nonenies battalion career madagascar manual alec sony [SEP]']
[Init] best perm rec loss: 0.7906759977340698 for ['[CLS]zed battalion animal main alec disease madagascar consisting classics manualnies 17th none career blow on pacific mukherjeeide depending life tourism gold ran moffat sony [SEP]']
[Init] best perm rec loss: 0.7893084287643433 for ['[CLS] classics manual ran pacific on main gold depending blow animal mukherjee sony nonenies battalion 17th diseasezed tourism moffatide life alec madagascar consisting career [SEP]']
[Init] best perm rec loss: 0.7891665697097778 for ['[CLS] alec career consisting blow classics life mukherjee dependingnieszed tourism sony manual diseaseide madagascar battalion none gold main 17th on animal moffat pacific ran [SEP]']
[Init] best perm rec loss: 0.7888503670692444 for ['[CLS] classics main none alec onzed mukherjee depending consisting madagascar ran life pacific 17th tourism battalion disease blow sony goldide moffat animal careernies manual [SEP]']
[Init] best perm rec loss: 0.7882052659988403 for ['[CLS] depending 17thnies onzedide consisting manual alec animal blow pacific none disease gold sony tourism classics career ran main mukherjee moffat battalion madagascar life [SEP]']
[Init] best perm rec loss: 0.7875663042068481 for ['[CLS] none life madagascar alecide gold consisting classics ran mukherjee animal sony moffat on 17th disease tourism battalion depending blownies main pacific careerzed manual [SEP]']
Nsteps: 1000
[  50/2000] tot_loss=2.762 (perp=11.735, rec=0.415, cos=0.000), tot_loss_proj:3.151 [t=0.27s]
prediction: ['[CLS] none -. estate security problem station probably accordion massachusetts stupid no disgustotide gallery rhode asbestos damage. government stores originated probably shut ugly mustache [SEP]']
[ 100/2000] tot_loss=2.425 (perp=10.484, rec=0.328, cos=0.000), tot_loss_proj:2.926 [t=0.28s]
prediction: ['[CLS] no - was property department problem station problem accordion ghana badly no lack for were wearing or damage. government. arm which himself ugly him [SEP]']
[ 150/2000] tot_loss=2.411 (perp=10.715, rec=0.268, cos=0.000), tot_loss_proj:2.941 [t=0.27s]
prediction: ['[CLS] no - is ugly department problem issue problem accordion clearly badly is has for were wearing or damage. government. sex that himself ugly factor [SEP]']
[ 200/2000] tot_loss=2.354 (perp=10.432, rec=0.268, cos=0.000), tot_loss_proj:2.807 [t=0.27s]
prediction: ['[CLS] no cute. ugly department problem rate problem accordion clearly actively is has for was likely blamed bad, person ;es it himself nothing him [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.465 (perp=11.153, rec=0.234, cos=0.000), tot_loss_proj:3.401 [t=0.28s]
prediction: ['[CLS] no cute character ugly department problem attempt problem characters clearly actively is has truck were had problem damage, for ;us it personal no factor [SEP]']
[ 300/2000] tot_loss=2.056 (perp=9.245, rec=0.207, cos=0.000), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] no cute character ugly mentioned here i problem characters you actively no has person that. or damage, for ; or it personal no factor [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.067 (perp=9.347, rec=0.198, cos=0.000), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS] no cute character ugly mentioned the i problem characters you injured no person has that true or damage. for ; or it mind no factor [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.102 (perp=9.524, rec=0.197, cos=0.000), tot_loss_proj:2.744 [t=0.27s]
prediction: ['[CLS] no cute character ugly mentioned he i problem characters is offense no person has or true or personal. for ; or it damage no here [SEP]']
[ 450/2000] tot_loss=2.038 (perp=9.282, rec=0.181, cos=0.000), tot_loss_proj:2.666 [t=0.26s]
prediction: ['[CLS] no cute character ugly mentioned he mind problem character is offense no person has or true or personal. for ; or it damage no here [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.850 (perp=8.378, rec=0.175, cos=0.000), tot_loss_proj:2.423 [t=0.28s]
prediction: ['[CLS] no cute character ugly mentioned he mind problem here is loved no person has the love or mind. for ; or it damage lots characters [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.884 (perp=8.542, rec=0.176, cos=0.000), tot_loss_proj:2.508 [t=0.26s]
prediction: ['[CLS] no cute character ugly mentioned he mind problem here is loved no. has the love or mind marketed for ; or it damage lots characters [SEP]']
[ 600/2000] tot_loss=1.887 (perp=8.597, rec=0.168, cos=0.000), tot_loss_proj:2.826 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind problem here is love no. has the love is mind marketed for ; of which fear. characters [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.835 (perp=8.371, rec=0.161, cos=0.000), tot_loss_proj:2.839 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind problem here is love no. has the love is mind marketed for ; of which fear characters. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.788 (perp=8.061, rec=0.176, cos=0.000), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind problem here ; love no. has the love ; of it damage is mind marketed for characters. [SEP]']
[ 750/2000] tot_loss=1.722 (perp=7.799, rec=0.162, cos=0.000), tot_loss_proj:2.542 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind problem here ; love no. has the love ; of which damage is anything marketed for characters. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.694 (perp=7.653, rec=0.164, cos=0.000), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind problem here is love no. ; has the love of which might is anything marketed for cute. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.710 (perp=7.758, rec=0.159, cos=0.000), tot_loss_proj:3.258 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is love no problem ; has or love of which has is anything marketed for cute. [SEP]']
[ 900/2000] tot_loss=1.629 (perp=7.380, rec=0.153, cos=0.000), tot_loss_proj:3.250 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is love no problem ; has the love of which has is anythingds for cute. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.628 (perp=7.417, rec=0.145, cos=0.000), tot_loss_proj:3.183 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love problem ; has the love of which has or anythingate for cute. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.739 (perp=7.910, rec=0.157, cos=0.000), tot_loss_proj:3.288 [t=0.28s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ; has or loveable which has mindate for cute. [SEP]']
[1050/2000] tot_loss=1.682 (perp=7.637, rec=0.155, cos=0.000), tot_loss_proj:3.301 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ; has the loveable which has mindate for cute. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.634 (perp=7.417, rec=0.151, cos=0.000), tot_loss_proj:3.221 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;able has the love which has mindate for cute. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.631 (perp=7.410, rec=0.149, cos=0.000), tot_loss_proj:3.201 [t=0.28s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which has mindable for cute. [SEP]']
[1200/2000] tot_loss=1.631 (perp=7.410, rec=0.149, cos=0.000), tot_loss_proj:3.195 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which has mindable for cute. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.625 (perp=7.410, rec=0.143, cos=0.000), tot_loss_proj:3.194 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which has mindable for cute. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.602 (perp=7.270, rec=0.148, cos=0.000), tot_loss_proj:3.018 [t=0.27s]
prediction: ['[CLS] no cute character ugly which he mind. here is no love or problem ;ate has or love apparently has mindable for cute. [SEP]']
[1350/2000] tot_loss=1.568 (perp=7.100, rec=0.148, cos=0.000), tot_loss_proj:3.027 [t=0.27s]
prediction: ['[CLS] no cute character ugly which he mind. here is no love or problem ;ate has or love apparently is mindable for cute. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.526 (perp=6.938, rec=0.138, cos=0.000), tot_loss_proj:3.083 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.528 (perp=6.938, rec=0.141, cos=0.000), tot_loss_proj:3.091 [t=0.28s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
[1500/2000] tot_loss=1.522 (perp=6.938, rec=0.135, cos=0.000), tot_loss_proj:3.090 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.531 (perp=6.938, rec=0.143, cos=0.000), tot_loss_proj:3.094 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.525 (perp=6.938, rec=0.138, cos=0.000), tot_loss_proj:3.087 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
[1650/2000] tot_loss=1.530 (perp=6.938, rec=0.143, cos=0.000), tot_loss_proj:3.089 [t=0.28s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.525 (perp=6.938, rec=0.137, cos=0.000), tot_loss_proj:3.090 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.516 (perp=6.938, rec=0.128, cos=0.000), tot_loss_proj:3.091 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
[1800/2000] tot_loss=1.525 (perp=6.938, rec=0.138, cos=0.000), tot_loss_proj:3.090 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.525 (perp=6.938, rec=0.137, cos=0.000), tot_loss_proj:3.085 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.522 (perp=6.938, rec=0.135, cos=0.000), tot_loss_proj:3.089 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
[1950/2000] tot_loss=1.525 (perp=6.938, rec=0.138, cos=0.000), tot_loss_proj:3.089 [t=0.26s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.526 (perp=6.938, rec=0.138, cos=0.000), tot_loss_proj:3.088 [t=0.27s]
prediction: ['[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] no cute character ugly apparently he mind. here is no love or problem ;ate has or love which is mindable for cute. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 58.333 | r: 66.667
rouge2     | fm: 9.302 | p: 8.696 | r: 10.000
rougeL     | fm: 35.556 | p: 33.333 | r: 38.095
rougeLsum  | fm: 35.556 | p: 33.333 | r: 38.095
r1fm+r2fm = 71.525

[Aggregate metrics]:
rouge1     | fm: 95.278 | p: 94.792 | r: 95.833
rouge2     | fm: 88.663 | p: 88.587 | r: 88.750
rougeL     | fm: 91.944 | p: 91.667 | r: 92.262
rougeLsum  | fm: 91.944 | p: 91.667 | r: 92.262
r1fm+r2fm = 183.941

input #7 time: 0:11:12 | total time: 0:53:55


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
*********************************
*********************************
average of cosine similarity 0.9994029292199194
highest_index [0]
highest [0.9994029292199194]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7498204708099365 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7109988927841187 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6939706802368164 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6878713965415955 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6800667643547058 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6785854697227478 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6757738590240479 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6690454483032227 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6682000756263733 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.666154146194458 for ['[CLS]mei wanda plaque canon badminton february sweat dna tail sitta screens adventure season product socially res facts eisenhower arkansasdentey prison franchise [SEP]']
[Init] best perm rec loss: 0.663054347038269 for ['[CLS] canon productdent adventure sweat res tail socially plaque prison eisenhower february badminton wanda season screens sittaey arkansas facts franchisemei dna [SEP]']
[Init] best perm rec loss: 0.661344587802887 for ['[CLS]mei res plaque si sweat screens franchise canon dna tail adventure season february eisenhower sociallytta factseydent wanda badminton prison product arkansas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.067 (perp=13.226, rec=0.422, cos=0.000), tot_loss_proj:4.108 [t=0.21s]
prediction: ['[CLS] force resides pseudonym whatever weird jack adventure darcy harder arriving adventure prior at birthdayito idea diner com check turned liquor - sadly junction [SEP]']
[ 100/2000] tot_loss=3.293 (perp=14.861, rec=0.321, cos=0.000), tot_loss_proj:4.238 [t=0.21s]
prediction: ['[CLS] rocks whatever devon vanity mor jack adventure vanity initials arriving grin america upper filmho idea check com hunting paid doubt which vanity films [SEP]']
[ 150/2000] tot_loss=3.019 (perp=13.289, rec=0.361, cos=0.000), tot_loss_proj:3.985 [t=0.22s]
prediction: ['[CLS]wyn whatever tumor taking glasses remy against vanity fangs vanity pornographic graduates tells film truth thousand ex awesome recreation pay doubt what vanity debt [SEP]']
[ 200/2000] tot_loss=2.985 (perp=13.599, rec=0.265, cos=0.000), tot_loss_proj:4.109 [t=0.21s]
prediction: ['[CLS]wyn whatever tumor vanity glasses sharon against vanity fangs vanity vanity tournaments owed film lds t r ・ vanity paid doubt what vanity debt [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.747 (perp=12.519, rec=0.243, cos=0.000), tot_loss_proj:3.833 [t=0.21s]
prediction: ["[CLS] whatever vanity vanity・max crimes vanity fangs vanity vanity tournaments without film'grief t discontinued ^ vanity pays doubt what vanity debt [SEP]"]
[ 300/2000] tot_loss=2.855 (perp=13.239, rec=0.207, cos=0.000), tot_loss_proj:3.819 [t=0.21s]
prediction: ["[CLS] film vanity vanity・max against vanity fangs vanity vanity nana no film'fiat t discontinued ^ vanity pays doubt what vanity debt [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.537 (perp=11.837, rec=0.169, cos=0.000), tot_loss_proj:3.760 [t=0.21s]
prediction: ["[CLS]% vanity vanity filmmax dread vanity fright vanity vanity, no film'missible t none ^ vanity pays doubt what vanity debt [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.523 (perp=10.719, rec=0.379, cos=0.000), tot_loss_proj:3.367 [t=0.22s]
prediction: ["[CLS] to vanity acts film doubt diplomacy vanity fright vanity vanity, no film'want t! @ owed pays majesty what vanity debt [SEP]"]
[ 450/2000] tot_loss=2.274 (perp=10.174, rec=0.240, cos=0.000), tot_loss_proj:3.279 [t=0.22s]
prediction: ["[CLS] to vanity slice film doubt terror vanity vanity vanity vanity, no film'for t?, owed paysmax what vanity debt [SEP]"]
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.082 (perp=9.395, rec=0.203, cos=0.000), tot_loss_proj:2.908 [t=0.21s]
prediction: ["[CLS] slice film doubt terror vanity vanity vanity vanity that no film'for t?, owed paysmax what vanity debt to vanity [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.100 (perp=9.593, rec=0.182, cos=0.000), tot_loss_proj:2.950 [t=0.21s]
prediction: ["[CLS] slice film doubt terror vanity vanity vanity vanity that no film'for tomax?, owed pays what vanity debt to fright [SEP]"]
[ 600/2000] tot_loss=2.130 (perp=9.819, rec=0.166, cos=0.000), tot_loss_proj:3.043 [t=0.21s]
prediction: ['[CLS] something film doubt terror vanity vanity vanity vanity that no film s for tomax,, owed pays what vanity debt to fright [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.987 (perp=9.172, rec=0.153, cos=0.000), tot_loss_proj:2.822 [t=0.21s]
prediction: ['[CLS] a film doubt terror vanity vanity vanity fright that no film s for tomax,, owed pays what vanity debt to fright [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.965 (perp=9.095, rec=0.146, cos=0.000), tot_loss_proj:2.862 [t=0.21s]
prediction: ['[CLS] a film doubt terror vanity vanity vanity fright that no film, s for tomax. owed pays what vanity debt to fright [SEP]']
[ 750/2000] tot_loss=1.879 (perp=8.700, rec=0.139, cos=0.000), tot_loss_proj:2.847 [t=0.21s]
prediction: ['[CLS] a film doubt terror vanity vanity vanity fright that no film, s for tomax, owed pays what vanity debt to fright [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.904 (perp=8.866, rec=0.131, cos=0.000), tot_loss_proj:2.882 [t=0.21s]
prediction: ['[CLS] a film doubt vanityful vanity vanity fright that no film, s for tomax, owed pays what vanity debt to fright [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.821 (perp=8.425, rec=0.136, cos=0.000), tot_loss_proj:2.952 [t=0.22s]
prediction: ['[CLS] a film doubt frightful benign vanity fright that no film, s for theymax, owed pays what vanity debt to vanity [SEP]']
[ 900/2000] tot_loss=1.810 (perp=8.425, rec=0.125, cos=0.000), tot_loss_proj:2.952 [t=0.22s]
prediction: ['[CLS] a film doubt frightful benign vanity fright that no film, s for theymax, owed pays what vanity debt to vanity [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.842 (perp=8.624, rec=0.117, cos=0.000), tot_loss_proj:3.025 [t=0.21s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, s for feltmax, owed pays what vanity debt to vanity [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.823 (perp=8.502, rec=0.123, cos=0.000), tot_loss_proj:2.951 [t=0.22s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, s for vanitymax, owed pays what felt debt to vanity [SEP]']
[1050/2000] tot_loss=1.826 (perp=8.502, rec=0.125, cos=0.000), tot_loss_proj:2.956 [t=0.21s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, s for vanitymax, owed pays what felt debt to vanity [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.788 (perp=8.381, rec=0.112, cos=0.000), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, smax, owed for vanity pays what felt debt to vanity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.790 (perp=8.381, rec=0.114, cos=0.000), tot_loss_proj:2.851 [t=0.26s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, smax, owed for vanity pays what felt debt to vanity [SEP]']
[1200/2000] tot_loss=1.795 (perp=8.381, rec=0.119, cos=0.000), tot_loss_proj:2.844 [t=0.28s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, smax, owed for vanity pays what felt debt to vanity [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.771 (perp=8.320, rec=0.107, cos=0.000), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] a doubt film frightful benign vanity fright that no film, smax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.742 (perp=8.155, rec=0.111, cos=0.000), tot_loss_proj:2.783 [t=0.27s]
prediction: ['[CLS] a doubt s frightful benign vanity fright that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
[1350/2000] tot_loss=1.739 (perp=8.155, rec=0.108, cos=0.000), tot_loss_proj:2.786 [t=0.27s]
prediction: ['[CLS] a doubt s frightful benign vanity fright that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.155, rec=0.106, cos=0.000), tot_loss_proj:2.783 [t=0.29s]
prediction: ['[CLS] a doubt s frightful benign vanity fright that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.733 (perp=8.155, rec=0.102, cos=0.000), tot_loss_proj:2.786 [t=0.26s]
prediction: ['[CLS] a doubt s frightful benign vanity fright that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
[1500/2000] tot_loss=1.820 (perp=8.560, rec=0.108, cos=0.000), tot_loss_proj:2.928 [t=0.27s]
prediction: ['[CLS] a doubt sfulful benign vanity fright that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.818 (perp=8.560, rec=0.107, cos=0.000), tot_loss_proj:2.940 [t=0.27s]
prediction: ['[CLS] a doubt sfulful benign vanity fright that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.743 (perp=8.210, rec=0.101, cos=0.000), tot_loss_proj:2.808 [t=0.26s]
prediction: ['[CLS] a doubt s frightful benign vanityful that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
[1650/2000] tot_loss=1.743 (perp=8.210, rec=0.101, cos=0.000), tot_loss_proj:2.810 [t=0.26s]
prediction: ['[CLS] a doubt s frightful benign vanityful that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.672 (perp=7.797, rec=0.113, cos=0.000), tot_loss_proj:2.741 [t=0.27s]
prediction: ['[CLS] a doubtful s frightful benign vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.647 (perp=7.726, rec=0.101, cos=0.000), tot_loss_proj:2.665 [t=0.26s]
prediction: ['[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
[1800/2000] tot_loss=1.653 (perp=7.726, rec=0.108, cos=0.000), tot_loss_proj:2.668 [t=0.26s]
prediction: ['[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.656 (perp=7.726, rec=0.111, cos=0.000), tot_loss_proj:2.666 [t=0.26s]
prediction: ['[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.658 (perp=7.726, rec=0.113, cos=0.000), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
[1950/2000] tot_loss=1.651 (perp=7.726, rec=0.106, cos=0.000), tot_loss_proj:2.665 [t=0.35s]
prediction: ['[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.655 (perp=7.726, rec=0.110, cos=0.000), tot_loss_proj:2.661 [t=0.27s]
prediction: ['[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] a doubtful benign s frightful vanity that no film, filmmax owed for vanity, pays what felt debt to vanity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.171 | p: 71.429 | r: 75.000
rouge2     | fm: 10.256 | p: 10.000 | r: 10.526
rougeL     | fm: 53.659 | p: 52.381 | r: 55.000
rougeLsum  | fm: 53.659 | p: 52.381 | r: 55.000
r1fm+r2fm = 83.427

[Aggregate metrics]:
rouge1     | fm: 92.821 | p: 92.196 | r: 93.519
rouge2     | fm: 79.951 | p: 79.855 | r: 80.058
rougeL     | fm: 87.690 | p: 87.302 | r: 88.122
rougeLsum  | fm: 87.690 | p: 87.302 | r: 88.122
r1fm+r2fm = 172.772

input #8 time: 0:09:47 | total time: 1:03:42


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
*********************************
*********************************
average of cosine similarity 0.9993985851753847
highest_index [0]
highest [0.9993985851753847]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8237752318382263 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.774014949798584 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7310062050819397 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7175238728523254 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6826789975166321 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6812739372253418 for ['[CLS]ser further afitionrn wore high bottom [SEP]']
[Init] best rec loss: 0.6777704358100891 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6555982232093811 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6541460752487183 for ['[CLS] luck decca cody outlaw edward deathsdden arsenal [SEP]']
[Init] best perm rec loss: 0.6495437622070312 for ['[CLS]dden decca edward arsenal outlaw luck cody deaths [SEP]']
[Init] best perm rec loss: 0.6468034386634827 for ['[CLS] arsenal luck cody edward outlaw decca deathsdden [SEP]']
[Init] best perm rec loss: 0.6466689705848694 for ['[CLS] deaths decca outlaw codydden edward luck arsenal [SEP]']
[Init] best perm rec loss: 0.6463043093681335 for ['[CLS] cody decca deaths edward luck arsenaldden outlaw [SEP]']
[Init] best perm rec loss: 0.6462281942367554 for ['[CLS] deaths arsenal decca outlaw luck codydden edward [SEP]']
[Init] best perm rec loss: 0.6455578207969666 for ['[CLS] arsenaldden outlaw deaths decca luck edward cody [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.064 (perp=13.377, rec=0.389, cos=0.000), tot_loss_proj:3.957 [t=0.27s]
prediction: ['[CLS] blindcon pu shifters diphead editorialball [SEP]']
[ 100/2000] tot_loss=2.615 (perp=11.728, rec=0.269, cos=0.000), tot_loss_proj:3.397 [t=0.27s]
prediction: ['[CLS] malacon of shifters offheadₜ tactical [SEP]']
[ 150/2000] tot_loss=2.583 (perp=11.821, rec=0.218, cos=0.000), tot_loss_proj:3.823 [t=0.27s]
prediction: ['[CLS] soft clap of shifters raisedhead clap clap [SEP]']
[ 200/2000] tot_loss=2.431 (perp=11.266, rec=0.178, cos=0.000), tot_loss_proj:3.417 [t=0.26s]
prediction: ['[CLS] soft clap oftra softhead clap clap [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.092 (perp=9.581, rec=0.176, cos=0.000), tot_loss_proj:2.794 [t=0.26s]
prediction: ['[CLS] softp of claptra softhead clap [SEP]']
[ 300/2000] tot_loss=2.050 (perp=9.581, rec=0.134, cos=0.000), tot_loss_proj:2.793 [t=0.27s]
prediction: ['[CLS] softp of claptra softhead clap [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.800 (perp=8.404, rec=0.119, cos=0.000), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] soft of claptrap softhead clap [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.692 (perp=7.920, rec=0.108, cos=0.000), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] of soft claptrap softhead clap [SEP]']
[ 450/2000] tot_loss=1.694 (perp=7.920, rec=0.110, cos=0.000), tot_loss_proj:2.396 [t=0.26s]
prediction: ['[CLS] of soft claptrap softhead clap [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.492 (perp=6.965, rec=0.099, cos=0.000), tot_loss_proj:2.247 [t=0.26s]
prediction: ['[CLS] of soft claptrap soft claphead [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.487 (perp=6.965, rec=0.094, cos=0.000), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] of soft claptrap soft claphead [SEP]']
[ 600/2000] tot_loss=1.803 (perp=8.562, rec=0.090, cos=0.000), tot_loss_proj:2.323 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap soft claphead [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.785 (perp=8.477, rec=0.089, cos=0.000), tot_loss_proj:2.356 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap softhead clap [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.704 (perp=8.067, rec=0.091, cos=0.000), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] of metaphysical clap claptrap softhead [SEP]']
[ 750/2000] tot_loss=1.695 (perp=8.067, rec=0.082, cos=0.000), tot_loss_proj:2.008 [t=0.27s]
prediction: ['[CLS] of metaphysical clap claptrap softhead [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.770 (perp=8.442, rec=0.082, cos=0.000), tot_loss_proj:2.022 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.770 (perp=8.442, rec=0.082, cos=0.000), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.442, rec=0.084, cos=0.000), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.766 (perp=8.442, rec=0.078, cos=0.000), tot_loss_proj:2.018 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1000/2000] tot_loss=1.758 (perp=8.442, rec=0.069, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1050/2000] tot_loss=1.766 (perp=8.442, rec=0.077, cos=0.000), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1100/2000] tot_loss=1.763 (perp=8.442, rec=0.075, cos=0.000), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1150/2000] tot_loss=1.771 (perp=8.442, rec=0.082, cos=0.000), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1200/2000] tot_loss=1.771 (perp=8.442, rec=0.082, cos=0.000), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=8.442, rec=0.072, cos=0.000), tot_loss_proj:2.015 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1300/2000] tot_loss=1.760 (perp=8.442, rec=0.072, cos=0.000), tot_loss_proj:2.008 [t=0.29s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1350/2000] tot_loss=1.759 (perp=8.442, rec=0.071, cos=0.000), tot_loss_proj:2.010 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1400/2000] tot_loss=1.780 (perp=8.442, rec=0.091, cos=0.000), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1450/2000] tot_loss=1.766 (perp=8.442, rec=0.078, cos=0.000), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1500/2000] tot_loss=1.762 (perp=8.442, rec=0.074, cos=0.000), tot_loss_proj:2.009 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1550/2000] tot_loss=1.778 (perp=8.442, rec=0.089, cos=0.000), tot_loss_proj:2.012 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1600/2000] tot_loss=1.754 (perp=8.442, rec=0.065, cos=0.000), tot_loss_proj:2.010 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1650/2000] tot_loss=1.767 (perp=8.442, rec=0.079, cos=0.000), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1700/2000] tot_loss=1.761 (perp=8.442, rec=0.073, cos=0.000), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1750/2000] tot_loss=1.761 (perp=8.442, rec=0.073, cos=0.000), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1800/2000] tot_loss=1.764 (perp=8.442, rec=0.076, cos=0.000), tot_loss_proj:2.017 [t=0.27s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1850/2000] tot_loss=1.765 (perp=8.442, rec=0.077, cos=0.000), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[1900/2000] tot_loss=1.766 (perp=8.442, rec=0.077, cos=0.000), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
[1950/2000] tot_loss=1.754 (perp=8.442, rec=0.066, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Attempt swap
[2000/2000] tot_loss=1.768 (perp=8.442, rec=0.080, cos=0.000), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] of metaphysical metaphysical claptrap softhead [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical metaphysical claptrap softhead [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 91.232 | p: 90.119 | r: 92.500
rouge2     | fm: 75.592 | p: 75.203 | r: 76.053
rougeL     | fm: 86.632 | p: 85.714 | r: 87.667
rougeLsum  | fm: 86.632 | p: 85.714 | r: 87.667
r1fm+r2fm = 166.824

input #9 time: 0:11:08 | total time: 1:14:51


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
*********************************
*********************************
average of cosine similarity 0.9991477120848691
highest_index [0]
highest [0.9991477120848691]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8751858472824097 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8741042613983154 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8258084058761597 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8136948347091675 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8082869052886963 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8051810264587402 for ['[CLS]car immediately helpelin hid swing reacher championship eva besides accompanied pounded nervous [SEP]']
[Init] best perm rec loss: 0.8036962747573853 for ['[CLS] help immediately evaelin reachercar swing hid championship accompanied nervous besides pounded [SEP]']
[Init] best perm rec loss: 0.8035407066345215 for ['[CLS] nervous accompanied championshipcar eva swing immediatelyelin help besides pounded reacher hid [SEP]']
[Init] best perm rec loss: 0.8034554123878479 for ['[CLS] championshipcar immediately pounded nervous accompanied evaelin swing hid help reacher besides [SEP]']
[Init] best perm rec loss: 0.8026493787765503 for ['[CLS] accompanied help immediatelyelin eva championship nervous hid poundedcar besides swing reacher [SEP]']
[Init] best perm rec loss: 0.8002617955207825 for ['[CLS] nervous accompanied eva hid reacher immediately championshipcarelin besides swing help pounded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.989 (perp=12.933, rec=0.402, cos=0.000), tot_loss_proj:3.778 [t=0.26s]
prediction: ['[CLS] role master eva control completelyably southwest commercials introduction for romantic oftenshore [SEP]']
[ 100/2000] tot_loss=2.617 (perp=11.628, rec=0.292, cos=0.000), tot_loss_proj:3.960 [t=0.26s]
prediction: ['[CLS]less balance fiction control completely becomingly ab divingst romantic often moments [SEP]']
[ 150/2000] tot_loss=2.491 (perp=11.320, rec=0.227, cos=0.000), tot_loss_proj:3.591 [t=0.26s]
prediction: ['[CLS]ly balance max control non becomingly ab rhythmsst emotional. during [SEP]']
[ 200/2000] tot_loss=2.324 (perp=10.687, rec=0.186, cos=0.000), tot_loss_proj:3.817 [t=0.25s]
prediction: ['[CLS]ly balances incident nonablyly ab rhythms forulsive. time [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.113 (perp=9.736, rec=0.166, cos=0.000), tot_loss_proj:2.950 [t=0.26s]
prediction: ['[CLS]ly balances incidentulsive kisses rhythms ably withulsive. time [SEP]']
[ 300/2000] tot_loss=2.086 (perp=9.669, rec=0.152, cos=0.000), tot_loss_proj:2.912 [t=0.35s]
prediction: ['[CLS]ly balances incident real kisses rhythms ably withulsive. time [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.037 (perp=9.139, rec=0.210, cos=0.000), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS]ly balances political realencies rhythms ably with.ulsive tackles [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.962 (perp=9.024, rec=0.157, cos=0.000), tot_loss_proj:2.437 [t=0.26s]
prediction: ['[CLS]ly balancesulsive realencies with ably rhythms.ulsive tackles [SEP]']
[ 450/2000] tot_loss=1.965 (perp=9.074, rec=0.150, cos=0.000), tot_loss_proj:2.486 [t=0.26s]
prediction: ['[CLS]ly balancesulsive real times with ably rhythms.ulsive tackles [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.763 (perp=8.061, rec=0.151, cos=0.000), tot_loss_proj:2.130 [t=0.25s]
prediction: ['[CLS]ly balances realulsive times with ably rhythms. real tackles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.752 (perp=8.061, rec=0.139, cos=0.000), tot_loss_proj:2.133 [t=0.25s]
prediction: ['[CLS]ly balances realulsive times with ably rhythms. real tackles [SEP]']
[ 600/2000] tot_loss=1.935 (perp=9.045, rec=0.126, cos=0.000), tot_loss_proj:2.378 [t=0.26s]
prediction: ['[CLS]ly balances realulsive times with ab time rhythms. real defender [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.833 (perp=8.484, rec=0.136, cos=0.000), tot_loss_proj:2.328 [t=0.27s]
prediction: ['[CLS]ly balances really times with abulsive rhythms. real defender [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.766 (perp=8.209, rec=0.124, cos=0.000), tot_loss_proj:2.491 [t=0.25s]
prediction: ['[CLS]ly balances times really with abulsive rhythms. real defender [SEP]']
[ 750/2000] tot_loss=1.770 (perp=8.209, rec=0.128, cos=0.000), tot_loss_proj:2.486 [t=0.25s]
prediction: ['[CLS]ly balances times really with abulsive rhythms. real defender [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.743 (perp=8.084, rec=0.126, cos=0.000), tot_loss_proj:2.162 [t=0.27s]
prediction: ['[CLS]ly balances time really with abulsive rhythms. real defender [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.737 (perp=8.046, rec=0.128, cos=0.000), tot_loss_proj:2.560 [t=0.27s]
prediction: ['[CLS]ly time balances real time with abulsive rhythms. real defender [SEP]']
[ 900/2000] tot_loss=1.735 (perp=8.046, rec=0.125, cos=0.000), tot_loss_proj:2.563 [t=0.26s]
prediction: ['[CLS]ly time balances real time with abulsive rhythms. real defender [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.685 (perp=7.790, rec=0.127, cos=0.000), tot_loss_proj:2.285 [t=0.27s]
prediction: ['[CLS]ly time balances real time with real abulsive rhythms. defender [SEP]']
Attempt swap
[1000/2000] tot_loss=1.674 (perp=7.790, rec=0.116, cos=0.000), tot_loss_proj:2.280 [t=0.27s]
prediction: ['[CLS]ly time balances real time with real abulsive rhythms. defender [SEP]']
[1050/2000] tot_loss=1.741 (perp=8.130, rec=0.115, cos=0.000), tot_loss_proj:2.683 [t=0.27s]
prediction: ['[CLS]ly time balances reals with real abulsive rhythms. defender [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.735 (perp=8.054, rec=0.124, cos=0.000), tot_loss_proj:2.536 [t=0.27s]
prediction: ['[CLS]ly time balances reals with real abulsive rhythms defender. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.725 (perp=8.054, rec=0.114, cos=0.000), tot_loss_proj:2.536 [t=0.26s]
prediction: ['[CLS]ly time balances reals with real abulsive rhythms defender. [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.054, rec=0.111, cos=0.000), tot_loss_proj:2.528 [t=0.28s]
prediction: ['[CLS]ly time balances reals with real abulsive rhythms defender. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.706 (perp=8.005, rec=0.105, cos=0.000), tot_loss_proj:2.267 [t=0.32s]
prediction: ['[CLS] timely balances reals with real abulsive rhythms defender. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.713 (perp=8.005, rec=0.112, cos=0.000), tot_loss_proj:2.271 [t=0.28s]
prediction: ['[CLS] timely balances reals with real abulsive rhythms defender. [SEP]']
[1350/2000] tot_loss=1.766 (perp=8.296, rec=0.107, cos=0.000), tot_loss_proj:2.277 [t=0.28s]
prediction: ['[CLS] timely balances reals with real abulsive rhythms prop. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.726 (perp=8.073, rec=0.111, cos=0.000), tot_loss_proj:2.295 [t=0.26s]
prediction: ['[CLS] timely balances reals withulsive ab propulsive rhythms. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.482 (perp=6.838, rec=0.114, cos=0.000), tot_loss_proj:2.130 [t=0.28s]
prediction: ['[CLS] time ably balances reals withulsive propulsive rhythms. [SEP]']
[1500/2000] tot_loss=1.478 (perp=6.838, rec=0.110, cos=0.000), tot_loss_proj:2.131 [t=0.26s]
prediction: ['[CLS] time ably balances reals withulsive propulsive rhythms. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.418 (perp=6.535, rec=0.110, cos=0.000), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.407 (perp=6.535, rec=0.100, cos=0.000), tot_loss_proj:2.120 [t=0.28s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
[1650/2000] tot_loss=1.413 (perp=6.535, rec=0.106, cos=0.000), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.410 (perp=6.535, rec=0.103, cos=0.000), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.412 (perp=6.535, rec=0.105, cos=0.000), tot_loss_proj:2.118 [t=0.27s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
[1800/2000] tot_loss=1.417 (perp=6.535, rec=0.110, cos=0.000), tot_loss_proj:2.119 [t=0.28s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.406 (perp=6.535, rec=0.099, cos=0.000), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] time ably balances reals with propulsiveulsive rhythms. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.411 (perp=6.454, rec=0.121, cos=0.000), tot_loss_proj:2.066 [t=0.28s]
prediction: ['[CLS] time ably balances realulsives with propulsive rhythms. [SEP]']
[1950/2000] tot_loss=1.398 (perp=6.454, rec=0.107, cos=0.000), tot_loss_proj:2.071 [t=0.27s]
prediction: ['[CLS] time ably balances realulsives with propulsive rhythms. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.405 (perp=6.454, rec=0.114, cos=0.000), tot_loss_proj:2.071 [t=0.27s]
prediction: ['[CLS] time ably balances realulsives with propulsive rhythms. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] time ably balances realulsives with propulsive rhythms. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 88.889 | r: 80.000
rouge2     | fm: 23.529 | p: 25.000 | r: 22.222
rougeL     | fm: 63.158 | p: 66.667 | r: 60.000
rougeLsum  | fm: 63.158 | p: 66.667 | r: 60.000
r1fm+r2fm = 107.740

[Aggregate metrics]:
rouge1     | fm: 90.830 | p: 90.007 | r: 91.667
rouge2     | fm: 70.923 | p: 70.758 | r: 71.159
rougeL     | fm: 84.481 | p: 83.983 | r: 85.130
rougeLsum  | fm: 84.893 | p: 84.416 | r: 85.584
r1fm+r2fm = 161.752

input #10 time: 0:11:11 | total time: 1:26:02


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
*********************************
*********************************
average of cosine similarity 0.9992845902209342
highest_index [0]
highest [0.9992845902209342]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9115942716598511 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9003689885139465 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8191804885864258 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8184278607368469 for ['[CLS] familiar mile drawn tal platformgu mevdture inland [SEP]']
[Init] best perm rec loss: 0.8171436190605164 for ['[CLS] inland platformvd mile familiar drawnture talgu me [SEP]']
[Init] best perm rec loss: 0.8153274059295654 for ['[CLS] mile meguture platform tal familiar drawn inlandvd [SEP]']
[Init] best perm rec loss: 0.8116759061813354 for ['[CLS]gu meture familiar platform mile talvd drawn inland [SEP]']
[Init] best perm rec loss: 0.8115344047546387 for ['[CLS] inland talgu familiar platformture me drawnvd mile [SEP]']
[Init] best perm rec loss: 0.8105883002281189 for ['[CLS] talvdgu inland me platform drawnture mile familiar [SEP]']
[Init] best perm rec loss: 0.8038451075553894 for ['[CLS] inland drawn mevd mileture talgu familiar platform [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.934 (perp=12.526, rec=0.429, cos=0.000), tot_loss_proj:3.279 [t=0.26s]
prediction: ['[CLS] oruled sated food mitsubishi veterinary bacterium refused party [SEP]']
[ 100/2000] tot_loss=2.842 (perp=12.600, rec=0.322, cos=0.000), tot_loss_proj:3.679 [t=0.26s]
prediction: ['[CLS] not trying stubborned badly refused gel gel refused parties [SEP]']
[ 150/2000] tot_loss=3.029 (perp=13.751, rec=0.278, cos=0.000), tot_loss_proj:3.687 [t=0.27s]
prediction: ['[CLS] was trying stubborned flat refused gel gel refused parties [SEP]']
[ 200/2000] tot_loss=2.921 (perp=13.494, rec=0.222, cos=0.000), tot_loss_proj:3.841 [t=0.27s]
prediction: ['[CLS] was refused stubborn thatly attempted gel gel refused conducted [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.508 (perp=11.767, rec=0.154, cos=0.000), tot_loss_proj:3.581 [t=0.27s]
prediction: ['[CLS] was refused stubborn herely attempted that gel refused conducted [SEP]']
[ 300/2000] tot_loss=2.459 (perp=11.758, rec=0.108, cos=0.000), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] was to stubborn herely attempted that gel refused conducted [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.785 (perp=8.425, rec=0.100, cos=0.000), tot_loss_proj:2.833 [t=0.27s]
prediction: ['[CLS] was here to stubbornly attempted that gel refused to [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.488 (perp=6.957, rec=0.097, cos=0.000), tot_loss_proj:2.246 [t=0.27s]
prediction: ['[CLS] was here that stubbornly attempted to gel refused to [SEP]']
[ 450/2000] tot_loss=1.477 (perp=6.957, rec=0.086, cos=0.000), tot_loss_proj:2.251 [t=0.27s]
prediction: ['[CLS] was here that stubbornly attempted to gel refused to [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.480 (perp=6.957, rec=0.088, cos=0.000), tot_loss_proj:2.258 [t=0.25s]
prediction: ['[CLS] was here that stubbornly attempted to gel refused to [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.585 (perp=7.504, rec=0.084, cos=0.000), tot_loss_proj:2.401 [t=0.26s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
[ 600/2000] tot_loss=1.575 (perp=7.504, rec=0.074, cos=0.000), tot_loss_proj:2.396 [t=0.26s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.579 (perp=7.504, rec=0.078, cos=0.000), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.582 (perp=7.504, rec=0.082, cos=0.000), tot_loss_proj:2.401 [t=0.27s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
[ 750/2000] tot_loss=1.586 (perp=7.504, rec=0.085, cos=0.000), tot_loss_proj:2.403 [t=0.27s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.562 (perp=7.504, rec=0.061, cos=0.000), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.570 (perp=7.504, rec=0.070, cos=0.000), tot_loss_proj:2.397 [t=0.26s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
[ 900/2000] tot_loss=1.575 (perp=7.504, rec=0.075, cos=0.000), tot_loss_proj:2.399 [t=0.25s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.560 (perp=7.504, rec=0.059, cos=0.000), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[1000/2000] tot_loss=1.566 (perp=7.504, rec=0.065, cos=0.000), tot_loss_proj:2.395 [t=0.27s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
[1050/2000] tot_loss=1.572 (perp=7.504, rec=0.071, cos=0.000), tot_loss_proj:2.398 [t=0.27s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[1100/2000] tot_loss=1.565 (perp=7.504, rec=0.064, cos=0.000), tot_loss_proj:2.397 [t=0.25s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[1150/2000] tot_loss=1.569 (perp=7.504, rec=0.068, cos=0.000), tot_loss_proj:2.402 [t=0.26s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
[1200/2000] tot_loss=1.569 (perp=7.504, rec=0.069, cos=0.000), tot_loss_proj:2.399 [t=0.25s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
[1250/2000] tot_loss=1.564 (perp=7.504, rec=0.063, cos=0.000), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] was here that stubbornly attempted to gel being refused [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.540 (perp=7.308, rec=0.079, cos=0.000), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] was here stubbornly attempted to gel that being refused [SEP]']
[1350/2000] tot_loss=1.531 (perp=7.308, rec=0.069, cos=0.000), tot_loss_proj:2.238 [t=0.25s]
prediction: ['[CLS] was here stubbornly attempted to gel that being refused [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.480 (perp=7.037, rec=0.072, cos=0.000), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1450/2000] tot_loss=1.485 (perp=7.037, rec=0.077, cos=0.000), tot_loss_proj:2.182 [t=0.26s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
[1500/2000] tot_loss=1.477 (perp=7.037, rec=0.069, cos=0.000), tot_loss_proj:2.179 [t=0.28s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1550/2000] tot_loss=1.475 (perp=7.037, rec=0.068, cos=0.000), tot_loss_proj:2.176 [t=0.25s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1600/2000] tot_loss=1.482 (perp=7.037, rec=0.075, cos=0.000), tot_loss_proj:2.177 [t=0.26s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
[1650/2000] tot_loss=1.483 (perp=7.037, rec=0.075, cos=0.000), tot_loss_proj:2.175 [t=0.26s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1700/2000] tot_loss=1.476 (perp=7.037, rec=0.068, cos=0.000), tot_loss_proj:2.177 [t=0.25s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1750/2000] tot_loss=1.473 (perp=7.037, rec=0.065, cos=0.000), tot_loss_proj:2.180 [t=0.26s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
[1800/2000] tot_loss=1.482 (perp=7.037, rec=0.074, cos=0.000), tot_loss_proj:2.180 [t=0.26s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1850/2000] tot_loss=1.479 (perp=7.037, rec=0.072, cos=0.000), tot_loss_proj:2.179 [t=0.27s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[1900/2000] tot_loss=1.476 (perp=7.037, rec=0.068, cos=0.000), tot_loss_proj:2.175 [t=0.25s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
[1950/2000] tot_loss=1.471 (perp=7.037, rec=0.064, cos=0.000), tot_loss_proj:2.175 [t=0.25s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=7.037, rec=0.069, cos=0.000), tot_loss_proj:2.177 [t=0.25s]
prediction: ['[CLS] here was stubbornly attempted to gel that being refused [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] was here that stubbornly attempted to gel being refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 91.641 | p: 91.005 | r: 92.361
rouge2     | fm: 68.511 | p: 68.533 | r: 68.562
rougeL     | fm: 83.502 | p: 83.045 | r: 84.096
rougeLsum  | fm: 83.944 | p: 83.442 | r: 84.544
r1fm+r2fm = 160.152

input #11 time: 0:11:09 | total time: 1:37:11


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
*********************************
*********************************
average of cosine similarity 0.9993443764984037
highest_index [0]
highest [0.9993443764984037]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8663572669029236 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8622331619262695 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.7986651659011841 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7722939252853394 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7697809338569641 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7439014315605164 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7429554462432861 for ['[CLS] ha guess shades margin office series bethitasyn few victor laynction translate [SEP]']
[Init] best perm rec loss: 0.7426284551620483 for ['[CLS]ynnction marginitas shades office guess lay beth few translate series victor ha [SEP]']
[Init] best perm rec loss: 0.7409300208091736 for ['[CLS] beth victor office guess shadesitasyn series margin translate hanction lay few [SEP]']
[Init] best perm rec loss: 0.7407931089401245 for ['[CLS]ynitas few shades lay guessnction beth ha victor series office translate margin [SEP]']
[Init] best perm rec loss: 0.739176332950592 for ['[CLS] shades victor lay ha marginnction series translateyn few guess officeitas beth [SEP]']
[Init] best perm rec loss: 0.7389779686927795 for ['[CLS]ynnction translate office seriesitas few ha guess shades margin lay victor beth [SEP]']
[Init] best perm rec loss: 0.7385421395301819 for ['[CLS] guess laynction bethitas office few series victoryn shades ha translate margin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.005 (perp=12.869, rec=0.431, cos=0.000), tot_loss_proj:3.603 [t=0.26s]
prediction: ['[CLS] maybe supposedly sick under apparently under broadband competition quit alleged perceived blind bubble advantage [SEP]']
[ 100/2000] tot_loss=2.776 (perp=12.361, rec=0.304, cos=0.000), tot_loss_proj:3.510 [t=0.26s]
prediction: ['[CLS] scared except sick against prone a cable records better our jurisdiction decent @ better [SEP]']
[ 150/2000] tot_loss=2.371 (perp=10.742, rec=0.222, cos=0.000), tot_loss_proj:3.188 [t=0.26s]
prediction: ['[CLS] see since sick advantage on a cable herself better its jurisdiction barely hardly better [SEP]']
[ 200/2000] tot_loss=2.414 (perp=11.206, rec=0.173, cos=0.000), tot_loss_proj:3.230 [t=0.26s]
prediction: ['[CLS] see since sick advantage on to cable herself better its rule barely barely better [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.313 (perp=10.734, rec=0.166, cos=0.000), tot_loss_proj:3.086 [t=0.27s]
prediction: ['[CLS] see considering sick advantage on or cable better its stock grounds barely barely better [SEP]']
[ 300/2000] tot_loss=2.033 (perp=9.419, rec=0.149, cos=0.000), tot_loss_proj:2.687 [t=0.26s]
prediction: ['[CLS] will considering to advantage on to cable better its feeling for barely barely better [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.915 (perp=8.877, rec=0.140, cos=0.000), tot_loss_proj:2.707 [t=0.26s]
prediction: ['[CLS] will to advantage on to cable better considering its stock for barely barely better [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.995 (perp=9.332, rec=0.128, cos=0.000), tot_loss_proj:2.627 [t=0.26s]
prediction: ['[CLS] will seen advantage on to cable for better considering its s barely barely better [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.332, rec=0.121, cos=0.000), tot_loss_proj:2.624 [t=0.26s]
prediction: ['[CLS] will seen advantage on to cable for better considering its s barely barely better [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.316 (perp=10.239, rec=0.269, cos=0.000), tot_loss_proj:3.117 [t=0.25s]
prediction: ['[CLS] will seen on, cable withoutact advantage considering its from barely barely better [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.071 (perp=9.274, rec=0.216, cos=0.000), tot_loss_proj:2.791 [t=0.25s]
prediction: ['[CLS] will seen on, cable for its advantage consideringact at barely barely better [SEP]']
[ 600/2000] tot_loss=2.036 (perp=9.274, rec=0.181, cos=0.000), tot_loss_proj:2.785 [t=0.26s]
prediction: ['[CLS] will seen on, cable for its advantage consideringact at barely barely better [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.935 (perp=8.845, rec=0.166, cos=0.000), tot_loss_proj:2.804 [t=0.25s]
prediction: ['[CLS] will seen on cable, for its advantage consideringact its barely barely better [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.861 (perp=8.218, rec=0.217, cos=0.000), tot_loss_proj:2.426 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
[ 750/2000] tot_loss=1.829 (perp=8.218, rec=0.185, cos=0.000), tot_loss_proj:2.425 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.848 (perp=8.218, rec=0.205, cos=0.000), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.827 (perp=8.218, rec=0.183, cos=0.000), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
[ 900/2000] tot_loss=1.814 (perp=8.218, rec=0.171, cos=0.000), tot_loss_proj:2.435 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.801 (perp=8.218, rec=0.157, cos=0.000), tot_loss_proj:2.426 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=8.218, rec=0.161, cos=0.000), tot_loss_proj:2.424 [t=0.28s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
[1050/2000] tot_loss=1.800 (perp=8.218, rec=0.156, cos=0.000), tot_loss_proj:2.420 [t=0.25s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
Attempt swap
[1100/2000] tot_loss=1.794 (perp=8.218, rec=0.150, cos=0.000), tot_loss_proj:2.429 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact its will barely better [SEP]']
Attempt swap
[1150/2000] tot_loss=1.875 (perp=8.624, rec=0.150, cos=0.000), tot_loss_proj:2.404 [t=0.28s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringact since will barely better [SEP]']
[1200/2000] tot_loss=1.834 (perp=8.414, rec=0.151, cos=0.000), tot_loss_proj:2.407 [t=0.27s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
Attempt swap
[1250/2000] tot_loss=1.838 (perp=8.414, rec=0.155, cos=0.000), tot_loss_proj:2.407 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
Attempt swap
[1300/2000] tot_loss=1.830 (perp=8.414, rec=0.147, cos=0.000), tot_loss_proj:2.407 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
[1350/2000] tot_loss=1.825 (perp=8.414, rec=0.143, cos=0.000), tot_loss_proj:2.407 [t=0.27s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
Attempt swap
[1400/2000] tot_loss=1.829 (perp=8.414, rec=0.146, cos=0.000), tot_loss_proj:2.400 [t=0.25s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
Attempt swap
[1450/2000] tot_loss=1.822 (perp=8.414, rec=0.139, cos=0.000), tot_loss_proj:2.409 [t=0.26s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
[1500/2000] tot_loss=1.820 (perp=8.414, rec=0.137, cos=0.000), tot_loss_proj:2.405 [t=0.27s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
Attempt swap
[1550/2000] tot_loss=1.817 (perp=8.414, rec=0.134, cos=0.000), tot_loss_proj:2.405 [t=0.25s]
prediction: ['[CLS] barely seen on cable, against its advantage consideringept since will barely better [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.809 (perp=8.330, rec=0.143, cos=0.000), tot_loss_proj:2.396 [t=0.25s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
[1650/2000] tot_loss=1.806 (perp=8.330, rec=0.140, cos=0.000), tot_loss_proj:2.399 [t=0.27s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=8.330, rec=0.135, cos=0.000), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
Attempt swap
[1750/2000] tot_loss=1.810 (perp=8.330, rec=0.144, cos=0.000), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
[1800/2000] tot_loss=1.800 (perp=8.330, rec=0.134, cos=0.000), tot_loss_proj:2.399 [t=0.26s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
Attempt swap
[1850/2000] tot_loss=1.805 (perp=8.330, rec=0.139, cos=0.000), tot_loss_proj:2.391 [t=0.27s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
Attempt swap
[1900/2000] tot_loss=1.799 (perp=8.330, rec=0.133, cos=0.000), tot_loss_proj:2.394 [t=0.25s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
[1950/2000] tot_loss=1.799 (perp=8.330, rec=0.133, cos=0.000), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
Attempt swap
[2000/2000] tot_loss=1.797 (perp=8.330, rec=0.131, cos=0.000), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] barely seen on cable against its advantage, consideringept since will barely better [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] will seen advantage on to cable for better considering its s barely barely better [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.419 | p: 75.000 | r: 80.000
rouge2     | fm: 13.793 | p: 13.333 | r: 14.286
rougeL     | fm: 64.516 | p: 62.500 | r: 66.667
rougeLsum  | fm: 64.516 | p: 62.500 | r: 66.667
r1fm+r2fm = 91.212

[Aggregate metrics]:
rouge1     | fm: 90.434 | p: 89.835 | r: 91.282
rouge2     | fm: 64.026 | p: 63.860 | r: 64.122
rougeL     | fm: 82.163 | p: 81.714 | r: 83.085
rougeLsum  | fm: 81.937 | p: 81.414 | r: 82.779
r1fm+r2fm = 154.460

input #12 time: 0:11:08 | total time: 1:48:20


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
*********************************
*********************************
average of cosine similarity 0.9992537517665578
highest_index [0]
highest [0.9992537517665578]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.886827290058136 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8561435341835022 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7805824875831604 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.77261883020401 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7622662782669067 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7556506991386414 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 0.745349645614624 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7445032596588135 for ['[CLS] permanent arm precision rowe cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7409077882766724 for ['[CLS] permanent defeat cardinalional rowe precision arm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.619 (perp=11.440, rec=0.331, cos=0.000), tot_loss_proj:3.379 [t=0.26s]
prediction: ['[CLS] option old broom blunt drugs flame stuff [SEP]']
[ 100/2000] tot_loss=2.487 (perp=11.246, rec=0.238, cos=0.000), tot_loss_proj:3.027 [t=0.26s]
prediction: ['[CLS] point that flame explode dashboard flame stuff [SEP]']
[ 150/2000] tot_loss=2.358 (perp=10.988, rec=0.160, cos=0.000), tot_loss_proj:3.027 [t=0.26s]
prediction: ['[CLS] point at explode explode things flame stuff [SEP]']
[ 200/2000] tot_loss=2.275 (perp=10.730, rec=0.130, cos=0.000), tot_loss_proj:3.122 [t=0.28s]
prediction: ['[CLS] point at explode explode things flame into [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.074 (perp=9.834, rec=0.107, cos=0.000), tot_loss_proj:3.121 [t=0.26s]
prediction: ['[CLS] point at explode into things flame into [SEP]']
[ 300/2000] tot_loss=2.116 (perp=10.119, rec=0.092, cos=0.000), tot_loss_proj:2.721 [t=0.28s]
prediction: ['[CLS] point at explode into things flame that [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.963 (perp=9.353, rec=0.093, cos=0.000), tot_loss_proj:2.465 [t=0.27s]
prediction: ['[CLS] point at things explode into flame that [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.897 (perp=9.022, rec=0.092, cos=0.000), tot_loss_proj:2.695 [t=0.26s]
prediction: ['[CLS] point at things explode into that flame [SEP]']
[ 450/2000] tot_loss=1.892 (perp=9.022, rec=0.087, cos=0.000), tot_loss_proj:2.692 [t=0.27s]
prediction: ['[CLS] point at things explode into that flame [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.728 (perp=8.254, rec=0.077, cos=0.000), tot_loss_proj:1.881 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.731 (perp=8.254, rec=0.080, cos=0.000), tot_loss_proj:1.876 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 600/2000] tot_loss=1.720 (perp=8.254, rec=0.069, cos=0.000), tot_loss_proj:1.881 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.737 (perp=8.254, rec=0.086, cos=0.000), tot_loss_proj:1.885 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.733 (perp=8.254, rec=0.082, cos=0.000), tot_loss_proj:1.879 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 750/2000] tot_loss=1.730 (perp=8.254, rec=0.080, cos=0.000), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.728 (perp=8.254, rec=0.077, cos=0.000), tot_loss_proj:1.871 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.733 (perp=8.254, rec=0.083, cos=0.000), tot_loss_proj:1.872 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 900/2000] tot_loss=1.725 (perp=8.254, rec=0.075, cos=0.000), tot_loss_proj:1.879 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=8.254, rec=0.082, cos=0.000), tot_loss_proj:1.879 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.719 (perp=8.254, rec=0.068, cos=0.000), tot_loss_proj:1.883 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.254, rec=0.072, cos=0.000), tot_loss_proj:1.872 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.705 (perp=8.254, rec=0.054, cos=0.000), tot_loss_proj:1.883 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.713 (perp=8.254, rec=0.062, cos=0.000), tot_loss_proj:1.877 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.254, rec=0.071, cos=0.000), tot_loss_proj:1.874 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.712 (perp=8.254, rec=0.061, cos=0.000), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.715 (perp=8.254, rec=0.065, cos=0.000), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1350/2000] tot_loss=1.705 (perp=8.254, rec=0.055, cos=0.000), tot_loss_proj:1.875 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.722 (perp=8.254, rec=0.072, cos=0.000), tot_loss_proj:1.880 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.714 (perp=8.254, rec=0.063, cos=0.000), tot_loss_proj:1.873 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1500/2000] tot_loss=1.721 (perp=8.254, rec=0.070, cos=0.000), tot_loss_proj:1.875 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.719 (perp=8.254, rec=0.068, cos=0.000), tot_loss_proj:1.872 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.707 (perp=8.254, rec=0.057, cos=0.000), tot_loss_proj:1.870 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1650/2000] tot_loss=1.710 (perp=8.254, rec=0.060, cos=0.000), tot_loss_proj:1.874 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.715 (perp=8.254, rec=0.064, cos=0.000), tot_loss_proj:1.879 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.711 (perp=8.254, rec=0.060, cos=0.000), tot_loss_proj:1.878 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1800/2000] tot_loss=1.712 (perp=8.254, rec=0.061, cos=0.000), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.717 (perp=8.254, rec=0.066, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.254, rec=0.063, cos=0.000), tot_loss_proj:1.872 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1950/2000] tot_loss=1.712 (perp=8.254, rec=0.061, cos=0.000), tot_loss_proj:1.877 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.708 (perp=8.254, rec=0.057, cos=0.000), tot_loss_proj:1.877 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point at things that explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.213 | p: 90.618 | r: 91.905
rouge2     | fm: 66.992 | p: 66.931 | r: 67.349
rougeL     | fm: 83.336 | p: 82.881 | r: 84.080
rougeLsum  | fm: 83.518 | p: 82.993 | r: 84.123
r1fm+r2fm = 158.206

input #13 time: 0:11:11 | total time: 1:59:31


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
*********************************
*********************************
average of cosine similarity 0.9993216742496194
highest_index [0]
highest [0.9993216742496194]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9582127928733826 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9391553997993469 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9280614256858826 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9169368743896484 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9135110378265381 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8921391367912292 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8712345957756042 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8704444766044617 for ['[CLS] harold [MASK] myers sprayed tom [SEP]']
[Init] best perm rec loss: 0.8692229390144348 for ['[CLS] tom harold myers [MASK] sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.685 (perp=12.044, rec=0.276, cos=0.000), tot_loss_proj:2.844 [t=0.25s]
prediction: ['[CLS] intriguing film intriguingpot moving [SEP]']
[ 100/2000] tot_loss=2.513 (perp=11.658, rec=0.181, cos=0.000), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] intriguing film intriguingbly intriguing [SEP]']
[ 150/2000] tot_loss=2.403 (perp=11.311, rec=0.141, cos=0.000), tot_loss_proj:2.924 [t=0.28s]
prediction: ['[CLS] intriguing filmgiblebly intriguing [SEP]']
[ 200/2000] tot_loss=1.976 (perp=9.271, rec=0.122, cos=0.000), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.700 (perp=7.970, rec=0.106, cos=0.000), tot_loss_proj:1.910 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 300/2000] tot_loss=1.700 (perp=7.970, rec=0.106, cos=0.000), tot_loss_proj:1.907 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.680 (perp=7.970, rec=0.086, cos=0.000), tot_loss_proj:1.902 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=7.970, rec=0.089, cos=0.000), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.692 (perp=7.970, rec=0.098, cos=0.000), tot_loss_proj:1.903 [t=0.32s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.685 (perp=7.970, rec=0.091, cos=0.000), tot_loss_proj:1.895 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.674 (perp=7.970, rec=0.080, cos=0.000), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.681 (perp=7.970, rec=0.087, cos=0.000), tot_loss_proj:1.892 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.679 (perp=7.970, rec=0.085, cos=0.000), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=7.970, rec=0.092, cos=0.000), tot_loss_proj:1.910 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.678 (perp=7.970, rec=0.084, cos=0.000), tot_loss_proj:1.892 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.670 (perp=7.970, rec=0.076, cos=0.000), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.426 (perp=6.728, rec=0.080, cos=0.000), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.425 (perp=6.728, rec=0.079, cos=0.000), tot_loss_proj:1.417 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.413 (perp=6.728, rec=0.067, cos=0.000), tot_loss_proj:1.418 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.407 (perp=6.728, rec=0.061, cos=0.000), tot_loss_proj:1.415 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.414 (perp=6.728, rec=0.068, cos=0.000), tot_loss_proj:1.414 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.407 (perp=6.728, rec=0.061, cos=0.000), tot_loss_proj:1.411 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=6.728, rec=0.067, cos=0.000), tot_loss_proj:1.418 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.414 (perp=6.728, rec=0.068, cos=0.000), tot_loss_proj:1.413 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.418 (perp=6.728, rec=0.073, cos=0.000), tot_loss_proj:1.409 [t=0.30s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.407 (perp=6.728, rec=0.061, cos=0.000), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.411 (perp=6.728, rec=0.065, cos=0.000), tot_loss_proj:1.414 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.403 (perp=6.728, rec=0.057, cos=0.000), tot_loss_proj:1.412 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.413 (perp=6.728, rec=0.067, cos=0.000), tot_loss_proj:1.410 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.405 (perp=6.728, rec=0.059, cos=0.000), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.406 (perp=6.728, rec=0.060, cos=0.000), tot_loss_proj:1.406 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.400 (perp=6.728, rec=0.054, cos=0.000), tot_loss_proj:1.409 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.404 (perp=6.728, rec=0.058, cos=0.000), tot_loss_proj:1.414 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.406 (perp=6.728, rec=0.060, cos=0.000), tot_loss_proj:1.408 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.412 (perp=6.728, rec=0.066, cos=0.000), tot_loss_proj:1.407 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.393 (perp=6.728, rec=0.047, cos=0.000), tot_loss_proj:1.415 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.408 (perp=6.728, rec=0.062, cos=0.000), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.412 (perp=6.728, rec=0.066, cos=0.000), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.409 (perp=6.728, rec=0.063, cos=0.000), tot_loss_proj:1.408 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.405 (perp=6.728, rec=0.059, cos=0.000), tot_loss_proj:1.408 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.860 | p: 91.243 | r: 92.556
rouge2     | fm: 68.886 | p: 68.691 | r: 69.118
rougeL     | fm: 84.492 | p: 83.936 | r: 85.141
rougeLsum  | fm: 84.436 | p: 83.975 | r: 85.063
r1fm+r2fm = 160.746

input #14 time: 0:11:05 | total time: 2:10:37


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
*********************************
*********************************
average of cosine similarity 0.999272107601477
highest_index [0]
highest [0.999272107601477]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9673743844032288 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9287669658660889 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9170325398445129 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9072756767272949 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9005352854728699 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8952277898788452 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8836863040924072 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best perm rec loss: 0.8820591568946838 for ['[CLS] martha much safe [CLS] troopergly consumer diner [SEP]']
[Init] best perm rec loss: 0.8807841539382935 for ['[CLS] safe [CLS] martha trooper diner consumer muchgly [SEP]']
[Init] best perm rec loss: 0.87947678565979 for ['[CLS] consumer trooper muchgly [CLS] safe diner martha [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.904 (perp=13.239, rec=0.256, cos=0.000), tot_loss_proj:4.286 [t=0.28s]
prediction: ['[CLS] log efficiency efficientablyableably singer uniform [SEP]']
[ 100/2000] tot_loss=2.994 (perp=14.047, rec=0.184, cos=0.000), tot_loss_proj:3.940 [t=0.28s]
prediction: ['[CLS] chill efficient efficientablyablyably chill suit [SEP]']
[ 150/2000] tot_loss=2.242 (perp=10.506, rec=0.140, cos=0.000), tot_loss_proj:3.154 [t=0.29s]
prediction: ['[CLS] chiller efficientablyably suiter. [SEP]']
[ 200/2000] tot_loss=2.724 (perp=13.095, rec=0.105, cos=0.000), tot_loss_proj:4.069 [t=0.29s]
prediction: ['[CLS] chill anonymous efficientablyably suiter. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.991 (perp=9.505, rec=0.090, cos=0.000), tot_loss_proj:2.591 [t=0.28s]
prediction: ['[CLS] chillably efficient anonymous anonymous suiter. [SEP]']
[ 300/2000] tot_loss=1.987 (perp=9.505, rec=0.086, cos=0.000), tot_loss_proj:2.603 [t=0.29s]
prediction: ['[CLS] chillably efficient anonymous anonymous suiter. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.814 (perp=8.737, rec=0.066, cos=0.000), tot_loss_proj:2.534 [t=0.29s]
prediction: ['[CLS] chillably efficient anonymous, suiter. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.710 (perp=7.507, rec=0.208, cos=0.000), tot_loss_proj:1.755 [t=0.28s]
prediction: ['[CLS] suitably efficient anonymous, chiller. [SEP]']
[ 450/2000] tot_loss=1.624 (perp=7.507, rec=0.123, cos=0.000), tot_loss_proj:1.760 [t=0.29s]
prediction: ['[CLS] suitably efficient anonymous, chiller. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.427 (perp=6.697, rec=0.088, cos=0.000), tot_loss_proj:1.506 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.420 (perp=6.697, rec=0.081, cos=0.000), tot_loss_proj:1.512 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.419 (perp=6.697, rec=0.080, cos=0.000), tot_loss_proj:1.510 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.000), tot_loss_proj:1.519 [t=0.29s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.409 (perp=6.697, rec=0.070, cos=0.000), tot_loss_proj:1.506 [t=0.29s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.406 (perp=6.697, rec=0.066, cos=0.000), tot_loss_proj:1.509 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.000), tot_loss_proj:1.505 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.407 (perp=6.697, rec=0.068, cos=0.000), tot_loss_proj:1.507 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.405 (perp=6.697, rec=0.065, cos=0.000), tot_loss_proj:1.508 [t=0.30s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.403 (perp=6.697, rec=0.064, cos=0.000), tot_loss_proj:1.514 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.000), tot_loss_proj:1.503 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.415 (perp=6.697, rec=0.076, cos=0.000), tot_loss_proj:1.512 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.400 (perp=6.697, rec=0.061, cos=0.000), tot_loss_proj:1.514 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.000), tot_loss_proj:1.505 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.414 (perp=6.697, rec=0.074, cos=0.000), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.407 (perp=6.697, rec=0.067, cos=0.000), tot_loss_proj:1.508 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.411 (perp=6.697, rec=0.072, cos=0.000), tot_loss_proj:1.501 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.410 (perp=6.697, rec=0.071, cos=0.000), tot_loss_proj:1.512 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.408 (perp=6.697, rec=0.069, cos=0.000), tot_loss_proj:1.506 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.404 (perp=6.697, rec=0.065, cos=0.000), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.407 (perp=6.697, rec=0.067, cos=0.000), tot_loss_proj:1.510 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.397 (perp=6.697, rec=0.057, cos=0.000), tot_loss_proj:1.504 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.000), tot_loss_proj:1.499 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.000), tot_loss_proj:1.506 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.409 (perp=6.697, rec=0.069, cos=0.000), tot_loss_proj:1.506 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.404 (perp=6.697, rec=0.065, cos=0.000), tot_loss_proj:1.510 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.404 (perp=6.697, rec=0.065, cos=0.000), tot_loss_proj:1.511 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.399 (perp=6.697, rec=0.059, cos=0.000), tot_loss_proj:1.512 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.399 (perp=6.697, rec=0.060, cos=0.000), tot_loss_proj:1.507 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.697, rec=0.061, cos=0.000), tot_loss_proj:1.515 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.400 (perp=6.697, rec=0.061, cos=0.000), tot_loss_proj:1.510 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 92.315 | p: 91.791 | r: 93.021
rouge2     | fm: 66.998 | p: 66.793 | r: 67.282
rougeL     | fm: 84.417 | p: 84.062 | r: 85.000
rougeLsum  | fm: 84.349 | p: 83.998 | r: 84.940
r1fm+r2fm = 159.313

input #15 time: 0:11:30 | total time: 2:22:07


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
*********************************
*********************************
average of cosine similarity 0.9993409595047945
highest_index [0]
highest [0.9993409595047945]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.0216281414031982 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8980923295021057 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7393960356712341 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.73758465051651 for ['[CLS] alta film slowly various lordathi [SEP]']
[Init] best perm rec loss: 0.7368499636650085 for ['[CLS] various slowly lord altaathi film [SEP]']
[Init] best perm rec loss: 0.7358532547950745 for ['[CLS] slowly film various lord altaathi [SEP]']
[Init] best perm rec loss: 0.7357162237167358 for ['[CLS]athi slowly film alta lord various [SEP]']
[Init] best perm rec loss: 0.734098494052887 for ['[CLS]athi film lord various alta slowly [SEP]']
[Init] best perm rec loss: 0.7340617775917053 for ['[CLS] various film lord slowlyathi alta [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.633 (perp=11.079, rec=0.418, cos=0.000), tot_loss_proj:3.435 [t=0.26s]
prediction: ['[CLS] several and lord on then other [SEP]']
[ 100/2000] tot_loss=1.940 (perp=8.115, rec=0.317, cos=0.000), tot_loss_proj:2.484 [t=0.27s]
prediction: ['[CLS] that and. on this more [SEP]']
[ 150/2000] tot_loss=2.032 (perp=8.964, rec=0.239, cos=0.000), tot_loss_proj:3.402 [t=0.26s]
prediction: ['[CLS] this and, slowly all more [SEP]']
[ 200/2000] tot_loss=1.499 (perp=6.579, rec=0.183, cos=0.000), tot_loss_proj:2.186 [t=0.27s]
prediction: ['[CLS] this of, and all more [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.196 (perp=5.425, rec=0.111, cos=0.000), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] this of all, and more [SEP]']
[ 300/2000] tot_loss=1.171 (perp=5.425, rec=0.086, cos=0.000), tot_loss_proj:1.726 [t=0.26s]
prediction: ['[CLS] this of all, and more [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.021 (perp=4.697, rec=0.082, cos=0.000), tot_loss_proj:1.246 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.015 (perp=4.697, rec=0.075, cos=0.000), tot_loss_proj:1.241 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.014 (perp=4.697, rec=0.075, cos=0.000), tot_loss_proj:1.248 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.009 (perp=4.697, rec=0.070, cos=0.000), tot_loss_proj:1.241 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.007 (perp=4.697, rec=0.067, cos=0.000), tot_loss_proj:1.242 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.014 (perp=4.697, rec=0.074, cos=0.000), tot_loss_proj:1.227 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.013 (perp=4.697, rec=0.073, cos=0.000), tot_loss_proj:1.240 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.014 (perp=4.697, rec=0.075, cos=0.000), tot_loss_proj:1.238 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.011 (perp=4.697, rec=0.071, cos=0.000), tot_loss_proj:1.238 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.012 (perp=4.697, rec=0.072, cos=0.000), tot_loss_proj:1.240 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.006 (perp=4.697, rec=0.067, cos=0.000), tot_loss_proj:1.235 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.002 (perp=4.697, rec=0.062, cos=0.000), tot_loss_proj:1.243 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.996 (perp=4.697, rec=0.056, cos=0.000), tot_loss_proj:1.238 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.001 (perp=4.697, rec=0.062, cos=0.000), tot_loss_proj:1.246 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.000 (perp=4.697, rec=0.061, cos=0.000), tot_loss_proj:1.238 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.005 (perp=4.697, rec=0.065, cos=0.000), tot_loss_proj:1.248 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.012 (perp=4.697, rec=0.072, cos=0.000), tot_loss_proj:1.238 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.010 (perp=4.697, rec=0.071, cos=0.000), tot_loss_proj:1.238 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.011 (perp=4.697, rec=0.072, cos=0.000), tot_loss_proj:1.239 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.006 (perp=4.697, rec=0.067, cos=0.000), tot_loss_proj:1.235 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.009 (perp=4.697, rec=0.069, cos=0.000), tot_loss_proj:1.242 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.009 (perp=4.697, rec=0.069, cos=0.000), tot_loss_proj:1.245 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.005 (perp=4.697, rec=0.065, cos=0.000), tot_loss_proj:1.235 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.002 (perp=4.697, rec=0.063, cos=0.000), tot_loss_proj:1.235 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.017 (perp=4.697, rec=0.078, cos=0.000), tot_loss_proj:1.232 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.005 (perp=4.697, rec=0.065, cos=0.000), tot_loss_proj:1.241 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.002 (perp=4.697, rec=0.063, cos=0.000), tot_loss_proj:1.237 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.004 (perp=4.697, rec=0.065, cos=0.000), tot_loss_proj:1.228 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.006 (perp=4.697, rec=0.066, cos=0.000), tot_loss_proj:1.244 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.008 (perp=4.697, rec=0.069, cos=0.000), tot_loss_proj:1.239 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.017 (perp=4.697, rec=0.077, cos=0.000), tot_loss_proj:1.244 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.011 (perp=4.697, rec=0.071, cos=0.000), tot_loss_proj:1.234 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.003 (perp=4.697, rec=0.064, cos=0.000), tot_loss_proj:1.236 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.006 (perp=4.697, rec=0.067, cos=0.000), tot_loss_proj:1.243 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.614 | p: 92.110 | r: 93.235
rouge2     | fm: 69.093 | p: 69.041 | r: 69.237
rougeL     | fm: 85.611 | p: 85.178 | r: 86.078
rougeLsum  | fm: 85.448 | p: 84.985 | r: 85.944
r1fm+r2fm = 161.708

input #16 time: 0:11:09 | total time: 2:33:17


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
*********************************
*********************************
average of cosine similarity 0.9992297140368904
highest_index [0]
highest [0.9992297140368904]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8476374745368958 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8250529170036316 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8236644268035889 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.8204348683357239 for ['[CLS] bit crookedus felicity york electedyre = cheese ourselves consulting [SEP]']
[Init] best rec loss: 0.8198862075805664 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8108278512954712 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7923518419265747 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.767731785774231 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7572525143623352 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7548929452896118 for ['[CLS] marius pressureuin meeting honestly miss lieutenant i magazine grey saved [SEP]']
[Init] best perm rec loss: 0.7525354027748108 for ['[CLS] pressure saved magazine grey honestly mariusuin lieutenant i meeting miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.991 (perp=12.765, rec=0.438, cos=0.000), tot_loss_proj:3.889 [t=0.28s]
prediction: ['[CLS] abuse accusedke institute wantander suburb two on shut revolution [SEP]']
[ 100/2000] tot_loss=2.516 (perp=10.923, rec=0.331, cos=0.000), tot_loss_proj:3.543 [t=0.28s]
prediction: ["[CLS] incomplete partyke about want too tow'to about crazy [SEP]"]
[ 150/2000] tot_loss=2.374 (perp=10.601, rec=0.253, cos=0.000), tot_loss_proj:3.262 [t=0.28s]
prediction: ['[CLS] too attackke about want too on about too about on [SEP]']
[ 200/2000] tot_loss=2.338 (perp=10.991, rec=0.140, cos=0.000), tot_loss_proj:3.202 [t=0.28s]
prediction: ['[CLS] too going decide think want too on about much about on [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.042 (perp=9.585, rec=0.125, cos=0.000), tot_loss_proj:2.942 [t=0.28s]
prediction: ['[CLS] too want too on attack bullshit think about much what on [SEP]']
[ 300/2000] tot_loss=1.984 (perp=9.392, rec=0.105, cos=0.000), tot_loss_proj:2.729 [t=0.30s]
prediction: ['[CLS] too want too on going thing think about much what on [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.860 (perp=8.791, rec=0.102, cos=0.000), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] too want too much going eternity think about on what on [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.650 (perp=7.805, rec=0.089, cos=0.000), tot_loss_proj:2.436 [t=0.26s]
prediction: ['[CLS] too want too much going on think about eternity what on [SEP]']
[ 450/2000] tot_loss=1.617 (perp=7.619, rec=0.093, cos=0.000), tot_loss_proj:2.235 [t=0.27s]
prediction: ['[CLS] too want too much going on think about thing what on [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.504 (perp=7.023, rec=0.099, cos=0.000), tot_loss_proj:2.045 [t=0.27s]
prediction: ['[CLS] too want too much going on think about what what on [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.529 (perp=7.183, rec=0.093, cos=0.000), tot_loss_proj:2.152 [t=0.29s]
prediction: ['[CLS] too want too much aquitaine on think about what going on [SEP]']
[ 600/2000] tot_loss=1.375 (perp=6.460, rec=0.083, cos=0.000), tot_loss_proj:1.931 [t=0.28s]
prediction: ['[CLS] too want too much everything on think about what going on [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.299 (perp=6.051, rec=0.089, cos=0.000), tot_loss_proj:1.826 [t=0.31s]
prediction: ['[CLS] to want too much everything on think about what going on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.288 (perp=6.051, rec=0.078, cos=0.000), tot_loss_proj:1.829 [t=0.29s]
prediction: ['[CLS] to want too much everything on think about what going on [SEP]']
[ 750/2000] tot_loss=1.289 (perp=6.051, rec=0.079, cos=0.000), tot_loss_proj:1.824 [t=0.29s]
prediction: ['[CLS] to want too much everything on think about what going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.289 (perp=6.051, rec=0.079, cos=0.000), tot_loss_proj:1.827 [t=0.28s]
prediction: ['[CLS] to want too much everything on think about what going on [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.328 (perp=6.199, rec=0.088, cos=0.000), tot_loss_proj:1.703 [t=0.28s]
prediction: ['[CLS] to want too much on think about what what going on [SEP]']
[ 900/2000] tot_loss=1.473 (perp=7.009, rec=0.071, cos=0.000), tot_loss_proj:1.939 [t=0.28s]
prediction: ['[CLS] to want too much on think about what aquitaine going on [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.450 (perp=6.843, rec=0.081, cos=0.000), tot_loss_proj:1.868 [t=0.26s]
prediction: ['[CLS] to want too much on think about what going on aquitaine [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.371 (perp=6.479, rec=0.075, cos=0.000), tot_loss_proj:1.946 [t=0.26s]
prediction: ['[CLS] to want too much aquitaine think about what going on on [SEP]']
[1050/2000] tot_loss=1.433 (perp=6.728, rec=0.087, cos=0.000), tot_loss_proj:1.959 [t=0.27s]
prediction: ['[CLS] to want too much seth think about what going on on [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.279 (perp=6.021, rec=0.075, cos=0.000), tot_loss_proj:1.812 [t=0.29s]
prediction: ['[CLS] seth want too much to think about what going on on [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.289 (perp=6.021, rec=0.085, cos=0.000), tot_loss_proj:1.813 [t=0.26s]
prediction: ['[CLS] seth want too much to think about what going on on [SEP]']
[1200/2000] tot_loss=1.278 (perp=6.021, rec=0.074, cos=0.000), tot_loss_proj:1.805 [t=0.27s]
prediction: ['[CLS] seth want too much to think about what going on on [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.242 (perp=5.829, rec=0.076, cos=0.000), tot_loss_proj:1.453 [t=0.25s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.241 (perp=5.829, rec=0.075, cos=0.000), tot_loss_proj:1.461 [t=0.26s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
[1350/2000] tot_loss=1.241 (perp=5.829, rec=0.075, cos=0.000), tot_loss_proj:1.462 [t=0.26s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.241 (perp=5.829, rec=0.075, cos=0.000), tot_loss_proj:1.455 [t=0.26s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.236 (perp=5.829, rec=0.071, cos=0.000), tot_loss_proj:1.461 [t=0.26s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
[1500/2000] tot_loss=1.236 (perp=5.829, rec=0.070, cos=0.000), tot_loss_proj:1.453 [t=0.27s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.238 (perp=5.829, rec=0.073, cos=0.000), tot_loss_proj:1.456 [t=0.25s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.237 (perp=5.829, rec=0.071, cos=0.000), tot_loss_proj:1.459 [t=0.26s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
[1650/2000] tot_loss=1.243 (perp=5.829, rec=0.078, cos=0.000), tot_loss_proj:1.462 [t=0.27s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.249 (perp=5.829, rec=0.084, cos=0.000), tot_loss_proj:1.460 [t=0.27s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.238 (perp=5.829, rec=0.073, cos=0.000), tot_loss_proj:1.458 [t=0.25s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
[1800/2000] tot_loss=1.234 (perp=5.829, rec=0.068, cos=0.000), tot_loss_proj:1.456 [t=0.25s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.241 (perp=5.829, rec=0.075, cos=0.000), tot_loss_proj:1.451 [t=0.27s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.239 (perp=5.829, rec=0.073, cos=0.000), tot_loss_proj:1.454 [t=0.27s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
[1950/2000] tot_loss=1.233 (perp=5.829, rec=0.068, cos=0.000), tot_loss_proj:1.460 [t=0.27s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.239 (perp=5.829, rec=0.074, cos=0.000), tot_loss_proj:1.453 [t=0.25s]
prediction: ['[CLS] seth want to think too much about what going on on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] seth want to think too much about what going on on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 88.000 | p: 84.615 | r: 91.667
rougeLsum  | fm: 88.000 | p: 84.615 | r: 91.667
r1fm+r2fm = 157.565

[Aggregate metrics]:
rouge1     | fm: 92.378 | p: 91.691 | r: 93.194
rouge2     | fm: 68.858 | p: 68.585 | r: 69.254
rougeL     | fm: 85.693 | p: 85.058 | r: 86.395
rougeLsum  | fm: 85.533 | p: 85.009 | r: 86.283
r1fm+r2fm = 161.235

input #17 time: 0:11:24 | total time: 2:44:41


Running input #18 of 100.
reference: 
========================
invigorating 
========================
*********************************
*********************************
average of cosine similarity 0.9993189277344137
highest_index [0]
highest [0.9993189277344137]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9810099005699158 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9475374221801758 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9375584125518799 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9278880953788757 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8875415325164795 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8744075298309326 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.8678218722343445 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8673678636550903 for ['[CLS] middle away mc reserves [SEP]']
[Init] best rec loss: 0.8221362829208374 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8196918964385986 for ['[CLS]odle du circle dual [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.178 (perp=14.239, rec=0.330, cos=0.000), tot_loss_proj:3.942 [t=0.26s]
prediction: ['[CLS]side impact thosegor [SEP]']
[ 100/2000] tot_loss=2.971 (perp=13.586, rec=0.253, cos=0.000), tot_loss_proj:4.280 [t=0.26s]
prediction: ['[CLS]gor impactgorgor [SEP]']
[ 150/2000] tot_loss=2.493 (perp=11.530, rec=0.187, cos=0.000), tot_loss_proj:3.729 [t=0.27s]
prediction: ['[CLS]goratinggorgor [SEP]']
[ 200/2000] tot_loss=2.844 (perp=13.530, rec=0.138, cos=0.000), tot_loss_proj:4.478 [t=0.26s]
prediction: ['[CLS]viatingvigor [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.826 (perp=8.482, rec=0.130, cos=0.000), tot_loss_proj:2.075 [t=0.27s]
prediction: ['[CLS]vivigorating [SEP]']
[ 300/2000] tot_loss=1.774 (perp=8.482, rec=0.078, cos=0.000), tot_loss_proj:2.077 [t=0.28s]
prediction: ['[CLS]vivigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.186 (perp=5.588, rec=0.069, cos=0.000), tot_loss_proj:1.185 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.182 (perp=5.588, rec=0.064, cos=0.000), tot_loss_proj:1.176 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.188 (perp=5.588, rec=0.070, cos=0.000), tot_loss_proj:1.187 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.185 (perp=5.588, rec=0.067, cos=0.000), tot_loss_proj:1.189 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.174 (perp=5.588, rec=0.057, cos=0.000), tot_loss_proj:1.192 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.180 (perp=5.588, rec=0.062, cos=0.000), tot_loss_proj:1.186 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.177 (perp=5.588, rec=0.060, cos=0.000), tot_loss_proj:1.181 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.181 (perp=5.588, rec=0.064, cos=0.000), tot_loss_proj:1.188 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.177 (perp=5.588, rec=0.060, cos=0.000), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.178 (perp=5.588, rec=0.061, cos=0.000), tot_loss_proj:1.188 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.178 (perp=5.588, rec=0.061, cos=0.000), tot_loss_proj:1.181 [t=0.29s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.173 (perp=5.588, rec=0.055, cos=0.000), tot_loss_proj:1.184 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.177 (perp=5.588, rec=0.059, cos=0.000), tot_loss_proj:1.190 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.169 (perp=5.588, rec=0.052, cos=0.000), tot_loss_proj:1.189 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.180 (perp=5.588, rec=0.063, cos=0.000), tot_loss_proj:1.187 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.175 (perp=5.588, rec=0.058, cos=0.000), tot_loss_proj:1.179 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.588, rec=0.061, cos=0.000), tot_loss_proj:1.185 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.190 (perp=5.588, rec=0.072, cos=0.000), tot_loss_proj:1.181 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.185 (perp=5.588, rec=0.068, cos=0.000), tot_loss_proj:1.178 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.174 (perp=5.588, rec=0.056, cos=0.000), tot_loss_proj:1.183 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.182 (perp=5.588, rec=0.064, cos=0.000), tot_loss_proj:1.181 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.166 (perp=5.588, rec=0.049, cos=0.000), tot_loss_proj:1.182 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.175 (perp=5.588, rec=0.057, cos=0.000), tot_loss_proj:1.185 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.180 (perp=5.588, rec=0.062, cos=0.000), tot_loss_proj:1.187 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.188 (perp=5.588, rec=0.070, cos=0.000), tot_loss_proj:1.181 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.168 (perp=5.588, rec=0.050, cos=0.000), tot_loss_proj:1.194 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.183 (perp=5.588, rec=0.066, cos=0.000), tot_loss_proj:1.190 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.186 (perp=5.588, rec=0.069, cos=0.000), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.188 (perp=5.588, rec=0.071, cos=0.000), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.168 (perp=5.588, rec=0.050, cos=0.000), tot_loss_proj:1.185 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.169 (perp=5.588, rec=0.051, cos=0.000), tot_loss_proj:1.188 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.189 (perp=5.588, rec=0.071, cos=0.000), tot_loss_proj:1.183 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.170 (perp=5.588, rec=0.053, cos=0.000), tot_loss_proj:1.179 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.178 (perp=5.588, rec=0.060, cos=0.000), tot_loss_proj:1.186 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.784 | p: 92.162 | r: 93.640
rouge2     | fm: 71.246 | p: 70.887 | r: 71.502
rougeL     | fm: 86.404 | p: 85.811 | r: 87.123
rougeLsum  | fm: 86.382 | p: 85.757 | r: 87.129
r1fm+r2fm = 164.031

input #18 time: 0:11:12 | total time: 2:55:54


Running input #19 of 100.
reference: 
========================
to infamy 
========================
*********************************
*********************************
average of cosine similarity 0.9993639581045685
highest_index [0]
highest [0.9993639581045685]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7712881565093994 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.758459746837616 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7393767237663269 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7259345054626465 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7096830010414124 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7007758021354675 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6931649446487427 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.679755449295044 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6751877665519714 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6420116424560547 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6417650580406189 for ['[CLS] orderyna pin reaching [SEP]']
[Init] best perm rec loss: 0.6412523984909058 for ['[CLS] order reachingyna pin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.335 (perp=9.450, rec=0.445, cos=0.000), tot_loss_proj:3.526 [t=0.29s]
prediction: ['[CLS] avon in of fiction [SEP]']
[ 100/2000] tot_loss=2.580 (perp=11.219, rec=0.336, cos=0.000), tot_loss_proj:3.539 [t=0.28s]
prediction: ['[CLS] inca infa fiction [SEP]']
[ 150/2000] tot_loss=2.346 (perp=10.793, rec=0.187, cos=0.000), tot_loss_proj:3.485 [t=0.28s]
prediction: ['[CLS]fa tofamy [SEP]']
[ 200/2000] tot_loss=2.265 (perp=10.793, rec=0.106, cos=0.000), tot_loss_proj:3.491 [t=0.29s]
prediction: ['[CLS]fa tofamy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.550 (perp=6.522, rec=0.245, cos=0.000), tot_loss_proj:1.661 [t=0.28s]
prediction: ['[CLS] infamy to [SEP]']
[ 300/2000] tot_loss=1.432 (perp=6.522, rec=0.128, cos=0.000), tot_loss_proj:1.638 [t=0.29s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.320 (perp=6.110, rec=0.099, cos=0.000), tot_loss_proj:1.294 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.306 (perp=6.110, rec=0.084, cos=0.000), tot_loss_proj:1.283 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.310 (perp=6.110, rec=0.088, cos=0.000), tot_loss_proj:1.293 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.293 (perp=6.110, rec=0.071, cos=0.000), tot_loss_proj:1.286 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.282 (perp=6.110, rec=0.060, cos=0.000), tot_loss_proj:1.295 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.283 (perp=6.110, rec=0.061, cos=0.000), tot_loss_proj:1.294 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.291 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.292 (perp=6.110, rec=0.070, cos=0.000), tot_loss_proj:1.298 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.284 (perp=6.110, rec=0.062, cos=0.000), tot_loss_proj:1.300 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.282 (perp=6.110, rec=0.060, cos=0.000), tot_loss_proj:1.288 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.290 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.280 (perp=6.110, rec=0.058, cos=0.000), tot_loss_proj:1.284 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.285 (perp=6.110, rec=0.063, cos=0.000), tot_loss_proj:1.279 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.274 (perp=6.110, rec=0.052, cos=0.000), tot_loss_proj:1.302 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.278 (perp=6.110, rec=0.056, cos=0.000), tot_loss_proj:1.293 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.288 (perp=6.110, rec=0.066, cos=0.000), tot_loss_proj:1.293 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.296 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.285 (perp=6.110, rec=0.063, cos=0.000), tot_loss_proj:1.291 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.283 (perp=6.110, rec=0.061, cos=0.000), tot_loss_proj:1.288 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.290 (perp=6.110, rec=0.068, cos=0.000), tot_loss_proj:1.285 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.298 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.273 (perp=6.110, rec=0.051, cos=0.000), tot_loss_proj:1.300 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.279 (perp=6.110, rec=0.057, cos=0.000), tot_loss_proj:1.297 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.281 (perp=6.110, rec=0.059, cos=0.000), tot_loss_proj:1.288 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.290 (perp=6.110, rec=0.068, cos=0.000), tot_loss_proj:1.306 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.277 (perp=6.110, rec=0.055, cos=0.000), tot_loss_proj:1.292 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.277 (perp=6.110, rec=0.055, cos=0.000), tot_loss_proj:1.286 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.292 (perp=6.110, rec=0.070, cos=0.000), tot_loss_proj:1.291 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.281 (perp=6.110, rec=0.059, cos=0.000), tot_loss_proj:1.291 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.297 (perp=6.110, rec=0.075, cos=0.000), tot_loss_proj:1.304 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.295 (perp=6.110, rec=0.073, cos=0.000), tot_loss_proj:1.294 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.266 (perp=6.110, rec=0.044, cos=0.000), tot_loss_proj:1.301 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.287 (perp=6.110, rec=0.065, cos=0.000), tot_loss_proj:1.298 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.290 (perp=6.110, rec=0.068, cos=0.000), tot_loss_proj:1.303 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.197 | p: 92.631 | r: 93.917
rouge2     | fm: 71.972 | p: 71.685 | r: 72.352
rougeL     | fm: 87.090 | p: 86.515 | r: 87.791
rougeLsum  | fm: 87.078 | p: 86.614 | r: 87.714
r1fm+r2fm = 165.169

input #19 time: 0:11:34 | total time: 3:07:28


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
*********************************
*********************************
average of cosine similarity 0.9992464929891436
highest_index [0]
highest [0.9992464929891436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8144314289093018 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8005215525627136 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7946104407310486 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7945479154586792 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7917590141296387 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.7615105509757996 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7611092925071716 for ['[CLS] africanpid poor forming [SEP]']
[Init] best perm rec loss: 0.7601674199104309 for ['[CLS] poor african formingpid [SEP]']
[Init] best perm rec loss: 0.7590469717979431 for ['[CLS] poor forming africanpid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.944 (perp=11.803, rec=0.538, cos=0.046), tot_loss_proj:4.092 [t=0.29s]
prediction: ['[CLS] worst pleasure card flashed [SEP]']
[ 100/2000] tot_loss=2.315 (perp=9.938, rec=0.328, cos=0.000), tot_loss_proj:3.738 [t=0.29s]
prediction: ['[CLS] worst pleasure pleasure banquet [SEP]']
[ 150/2000] tot_loss=2.294 (perp=10.179, rec=0.258, cos=0.000), tot_loss_proj:2.779 [t=0.31s]
prediction: ['[CLS]verse pleasure pleasureverse [SEP]']
[ 200/2000] tot_loss=2.276 (perp=10.179, rec=0.241, cos=0.000), tot_loss_proj:2.782 [t=0.29s]
prediction: ['[CLS]verse pleasure pleasureverse [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.046 (perp=9.252, rec=0.196, cos=0.000), tot_loss_proj:2.386 [t=0.29s]
prediction: ['[CLS]verse pleasure per pleasure [SEP]']
[ 300/2000] tot_loss=1.989 (perp=9.252, rec=0.138, cos=0.000), tot_loss_proj:2.392 [t=0.30s]
prediction: ['[CLS]verse pleasure per pleasure [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.943 (perp=9.116, rec=0.120, cos=0.000), tot_loss_proj:2.849 [t=0.29s]
prediction: ['[CLS] theverse pleasure pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.890 (perp=8.790, rec=0.132, cos=0.000), tot_loss_proj:3.308 [t=0.28s]
prediction: ['[CLS] perverse pleasureverse [SEP]']
[ 450/2000] tot_loss=1.863 (perp=8.790, rec=0.105, cos=0.000), tot_loss_proj:3.309 [t=0.29s]
prediction: ['[CLS] perverse pleasureverse [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.705 (perp=7.917, rec=0.122, cos=0.000), tot_loss_proj:2.482 [t=0.28s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.688 (perp=7.917, rec=0.104, cos=0.000), tot_loss_proj:2.465 [t=0.28s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.698 (perp=7.917, rec=0.114, cos=0.000), tot_loss_proj:2.456 [t=0.29s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.692 (perp=7.917, rec=0.109, cos=0.000), tot_loss_proj:2.449 [t=0.29s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.658 (perp=7.917, rec=0.075, cos=0.000), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.719 (perp=8.166, rec=0.085, cos=0.000), tot_loss_proj:1.951 [t=0.27s]
prediction: ['[CLS] per perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.720 (perp=8.166, rec=0.086, cos=0.000), tot_loss_proj:1.956 [t=0.27s]
prediction: ['[CLS] per perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.704 (perp=8.166, rec=0.071, cos=0.000), tot_loss_proj:1.954 [t=0.26s]
prediction: ['[CLS] per perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.716 (perp=8.166, rec=0.083, cos=0.000), tot_loss_proj:1.955 [t=0.26s]
prediction: ['[CLS] per perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.716 (perp=8.166, rec=0.083, cos=0.000), tot_loss_proj:1.955 [t=0.27s]
prediction: ['[CLS] per perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.713 (perp=8.166, rec=0.080, cos=0.000), tot_loss_proj:1.956 [t=0.26s]
prediction: ['[CLS] per perverse pleasure [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.166, rec=0.069, cos=0.000), tot_loss_proj:1.945 [t=0.27s]
prediction: ['[CLS] per perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.692 (perp=8.166, rec=0.059, cos=0.000), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] per perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.712 (perp=8.166, rec=0.079, cos=0.000), tot_loss_proj:1.950 [t=0.27s]
prediction: ['[CLS] per perverse pleasure [SEP]']
[1200/2000] tot_loss=1.896 (perp=9.095, rec=0.077, cos=0.000), tot_loss_proj:2.155 [t=0.26s]
prediction: ['[CLS] per theverse pleasure [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.593 (perp=7.610, rec=0.071, cos=0.000), tot_loss_proj:1.673 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.594 (perp=7.610, rec=0.072, cos=0.000), tot_loss_proj:1.682 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.598 (perp=7.610, rec=0.076, cos=0.000), tot_loss_proj:1.668 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.590 (perp=7.610, rec=0.068, cos=0.000), tot_loss_proj:1.662 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.596 (perp=7.610, rec=0.074, cos=0.000), tot_loss_proj:1.661 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.590 (perp=7.610, rec=0.068, cos=0.000), tot_loss_proj:1.672 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.581 (perp=7.610, rec=0.059, cos=0.000), tot_loss_proj:1.672 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.610, rec=0.064, cos=0.000), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.610, rec=0.066, cos=0.000), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.586 (perp=7.610, rec=0.064, cos=0.000), tot_loss_proj:1.665 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.585 (perp=7.610, rec=0.063, cos=0.000), tot_loss_proj:1.667 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.592 (perp=7.610, rec=0.070, cos=0.000), tot_loss_proj:1.671 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.610, rec=0.068, cos=0.000), tot_loss_proj:1.654 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.601 (perp=7.610, rec=0.079, cos=0.000), tot_loss_proj:1.669 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.588 (perp=7.610, rec=0.066, cos=0.000), tot_loss_proj:1.673 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.610, rec=0.074, cos=0.000), tot_loss_proj:1.670 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.572 | p: 92.952 | r: 94.286
rouge2     | fm: 73.693 | p: 73.430 | r: 74.052
rougeL     | fm: 87.916 | p: 87.288 | r: 88.543
rougeLsum  | fm: 87.709 | p: 87.198 | r: 88.243
r1fm+r2fm = 167.264

input #20 time: 0:11:17 | total time: 3:18:45


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
*********************************
*********************************
average of cosine similarity 0.9993227008393977
highest_index [0]
highest [0.9993227008393977]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9395535588264465 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8812665343284607 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8690040111541748 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8488208055496216 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8241045475006104 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.8159998059272766 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8128362894058228 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8126795887947083 for ['[CLS] extra odd commission jinoom waters [SEP] village episode chamber return sq speed firm viva range daddy clear surgicalfying above right evidence brows ashland [SEP]']
[Init] best perm rec loss: 0.8120970129966736 for ['[CLS] [SEP] range extra chamber commission ashland episodefying jin speed viva odd return surgical village waters clear right daddy evidence aboveoom firm brows sq [SEP]']
[Init] best perm rec loss: 0.8115790486335754 for ['[CLS] chamber firm above extra daddy ashlandfying surgical commission sqoom episode right odd range clear viva brows speed [SEP] jin return waters village evidence [SEP]']
[Init] best perm rec loss: 0.8102937936782837 for ['[CLS] firm range evidence [SEP] surgical ashland viva daddy returnfying episode clearoom brows commission above jin extra waters sq speed chamber village right odd [SEP]']
[Init] best perm rec loss: 0.809334933757782 for ['[CLS]oom [SEP] surgical abovefying clear firm episode jin return range brows village chamber extra commission daddy ashland odd waters viva speed evidence right sq [SEP]']
[Init] best perm rec loss: 0.8084885478019714 for ['[CLS] return episode brows odd evidence above jin speed firm [SEP] right chamber waters daddy range vivaoom clear village extra ashlandfying surgical commission sq [SEP]']
[Init] best perm rec loss: 0.8076668381690979 for ['[CLS] jin sq clearfying range waters ashland above odd right viva daddy chamber speed brows commission extraoom evidence surgical [SEP] episode return firm village [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.657 (perp=11.239, rec=0.409, cos=0.000), tot_loss_proj:3.106 [t=0.26s]
prediction: ["[CLS]? instead wife government most more rack about izzy no torture bastard useless these? become rate communist problem cause worker'abandonedes sites [SEP]"]
[ 100/2000] tot_loss=2.419 (perp=10.415, rec=0.336, cos=0.000), tot_loss_proj:2.863 [t=0.27s]
prediction: ["[CLS]? instead women policies so more guns about izzy a caused bastard officials these way worse rate scared problem policy worker'abandonedes. [SEP]"]
[ 150/2000] tot_loss=2.442 (perp=10.759, rec=0.290, cos=0.000), tot_loss_proj:2.974 [t=0.28s]
prediction: ['[CLS]? makes women policies that more guns found innovation a look only teacherstypical mistaken worse rate scared usual years athletesed abandonedes. [SEP]']
[ 200/2000] tot_loss=2.524 (perp=11.348, rec=0.255, cos=0.000), tot_loss_proj:3.287 [t=0.27s]
prediction: ['[CLS] looks makes women worked that more any make worked a look for teacherstypical mistaken quite economics scared usual years athletes - abandonedes. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.479 (perp=11.208, rec=0.238, cos=0.000), tot_loss_proj:3.317 [t=0.26s]
prediction: ['[CLS] looks makes women everything guns more that make worked women look of teacherstypical mistaken quite reapers scaredtypical initially athletes - equivalentes. [SEP]']
[ 300/2000] tot_loss=2.262 (perp=9.911, rec=0.280, cos=0.000), tot_loss_proj:3.235 [t=0.28s]
prediction: ['[CLS] looking makes women works any more that make worked women look of teachers looked mistaken quite reapers caretakertypical therefore athletes and equivalentes. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.220 (perp=10.017, rec=0.216, cos=0.000), tot_loss_proj:3.390 [t=0.27s]
prediction: ['[CLS] way makes women everything any more that make worked women look of caretaker looked than quite writes exchange athletestypical athletes - equivalent ). [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.021 (perp=9.123, rec=0.196, cos=0.000), tot_loss_proj:3.044 [t=0.29s]
prediction: ['[CLS] way makes women everything any more the like worked women look more caretaker look than quite writes athletes exchangetypical athletes and equivalent ). [SEP]']
[ 450/2000] tot_loss=1.994 (perp=9.131, rec=0.167, cos=0.000), tot_loss_proj:2.582 [t=0.27s]
prediction: ['[CLS] way makes women all any more the like works women look more caretaker look instead instead writes athletes exchangetypical athletes and generic ). [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.944 (perp=8.902, rec=0.163, cos=0.000), tot_loss_proj:2.509 [t=0.28s]
prediction: ['[CLS] way makes women any more all the like works women look more caretaker look instead instead writes athletes expressiontypical athletes and generic ). [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.883 (perp=8.610, rec=0.161, cos=0.000), tot_loss_proj:2.516 [t=0.28s]
prediction: ['[CLS] way makes women any more all the like works women look like caretaker look generic instead writes athletes expressiontypical athletes and instead ). [SEP]']
[ 600/2000] tot_loss=1.919 (perp=8.875, rec=0.144, cos=0.000), tot_loss_proj:2.816 [t=0.28s]
prediction: ['[CLS] way makes women any more all the like works women look like caretaker look stereo instead therefore athletes expressiontypical athletes and instead ). [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.884 (perp=8.709, rec=0.142, cos=0.000), tot_loss_proj:2.698 [t=0.27s]
prediction: ['[CLS] way makes women any more all the like works the look like caretaker look stereo instead of teachers moraltypical athletes and instead letters. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.820 (perp=8.397, rec=0.140, cos=0.000), tot_loss_proj:2.530 [t=0.27s]
prediction: ['[CLS] way makes women any more all the like works the look like caretaker look stereotypical of teachers moral instead athletes and instead letters. [SEP]']
[ 750/2000] tot_loss=1.807 (perp=8.393, rec=0.129, cos=0.000), tot_loss_proj:2.527 [t=0.28s]
prediction: ['[CLS] way makes women any more all the like works the look like caretaker look stereotypical of teachers serious instead athletes and instead letters. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.734 (perp=8.096, rec=0.115, cos=0.000), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] way makes women any more all the like works the look like caretaker look stereotypical of teachers instead serious athletes and instead letters. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.753 (perp=8.103, rec=0.133, cos=0.000), tot_loss_proj:2.272 [t=0.26s]
prediction: ['[CLS] way makes women any more all the like works caretaker look like the look stereotypical of teachers instead serious athletes, insteadst. [SEP]']
[ 900/2000] tot_loss=1.745 (perp=8.103, rec=0.125, cos=0.000), tot_loss_proj:2.280 [t=0.28s]
prediction: ['[CLS] way makes women any more all the like works caretaker look like the look stereotypical of teachers instead serious athletes, insteadst. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.710 (perp=7.967, rec=0.117, cos=0.000), tot_loss_proj:2.368 [t=0.27s]
prediction: ['[CLS] way makes women any more all the like works caretaker look like the look stereotypical of teachers instead instead athletes, seriousst. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.670 (perp=7.746, rec=0.121, cos=0.000), tot_loss_proj:2.275 [t=0.31s]
prediction: ['[CLS] way makes women any more all the like works caretaker look like the look stereotypical of teachers instead, athletes instead seriousst. [SEP]']
[1050/2000] tot_loss=1.667 (perp=7.746, rec=0.118, cos=0.000), tot_loss_proj:2.277 [t=0.30s]
prediction: ['[CLS] way makes women any more all the like works caretaker look like the look stereotypical of teachers instead, athletes instead seriousst. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.596 (perp=7.399, rec=0.116, cos=0.000), tot_loss_proj:2.189 [t=0.29s]
prediction: ['[CLS] way makes women all more all the like works caretaker look like the look of stereotypical teachers instead, athletes instead serious out. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.564 (perp=7.213, rec=0.121, cos=0.000), tot_loss_proj:2.048 [t=0.27s]
prediction: ['[CLS] way makes all women more all the like works caretaker look like the look of stereotypical teachers instead, athletes instead serious out. [SEP]']
[1200/2000] tot_loss=1.551 (perp=7.190, rec=0.113, cos=0.000), tot_loss_proj:2.493 [t=0.27s]
prediction: ['[CLS] way makes of women more all the like works caretaker and like the look of stereotypical teachers instead, athletes instead serious out. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.540 (perp=7.190, rec=0.102, cos=0.000), tot_loss_proj:2.494 [t=0.28s]
prediction: ['[CLS] way makes of women more all the like works caretaker and like the look of stereotypical teachers instead, athletes instead serious out. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.489 (perp=6.906, rec=0.108, cos=0.000), tot_loss_proj:2.450 [t=0.28s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers instead, athletes instead serious out. [SEP]']
[1350/2000] tot_loss=1.539 (perp=7.196, rec=0.100, cos=0.000), tot_loss_proj:2.712 [t=0.26s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers quite, athletes instead serious out. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.524 (perp=7.108, rec=0.102, cos=0.000), tot_loss_proj:2.704 [t=0.28s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers, quite athletes instead serious out. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.484 (perp=6.907, rec=0.102, cos=0.000), tot_loss_proj:2.728 [t=0.27s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers, athletes quite instead serious out. [SEP]']
[1500/2000] tot_loss=1.486 (perp=6.907, rec=0.105, cos=0.000), tot_loss_proj:2.728 [t=0.28s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers, athletes quite instead serious out. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.430 (perp=6.664, rec=0.097, cos=0.000), tot_loss_proj:2.608 [t=0.27s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers, athletes instead quite serious out. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.431 (perp=6.664, rec=0.098, cos=0.000), tot_loss_proj:2.609 [t=0.28s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers, athletes instead quite serious out. [SEP]']
[1650/2000] tot_loss=1.427 (perp=6.664, rec=0.094, cos=0.000), tot_loss_proj:2.608 [t=0.27s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the look of stereotypical teachers, athletes instead quite serious out. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.572 (perp=7.372, rec=0.098, cos=0.000), tot_loss_proj:2.832 [t=0.27s]
prediction: ['[CLS] way makes all women more of the like works caretaker and like the looks stereotypical teachers, athletes instead quite serious out. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.456 (perp=6.775, rec=0.101, cos=0.000), tot_loss_proj:2.631 [t=0.27s]
prediction: ['[CLS] way makes all women more of the like works caretakers like the look and stereotypical teachers, athletes instead quite serious out. [SEP]']
[1800/2000] tot_loss=1.447 (perp=6.775, rec=0.092, cos=0.000), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] way makes all women more of the like works caretakers like the look and stereotypical teachers, athletes instead quite serious out. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.401 (perp=6.508, rec=0.100, cos=0.000), tot_loss_proj:2.846 [t=0.28s]
prediction: ['[CLS] way makes all women more of the like works caretakers like the look out and stereotypical teachers, athletes instead quite serious. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.374 (perp=6.355, rec=0.103, cos=0.000), tot_loss_proj:2.511 [t=0.27s]
prediction: ['[CLS] way makes all women more of the works like caretakers like the look out and stereotypical teachers, athletes instead quite serious. [SEP]']
[1950/2000] tot_loss=1.367 (perp=6.355, rec=0.096, cos=0.000), tot_loss_proj:2.511 [t=0.26s]
prediction: ['[CLS] way makes all women more of the works like caretakers like the look out and stereotypical teachers, athletes instead quite serious. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.361 (perp=6.293, rec=0.102, cos=0.000), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] way makes all women like more of the works caretakers like the look out and stereotypical teachers, athletes instead quite serious. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] way makes all women more of the like works caretaker and like the looks stereotypical teachers, athletes instead quite serious out. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.609 | p: 82.609 | r: 82.609
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.826 | p: 47.826 | r: 47.826
rougeLsum  | fm: 47.826 | p: 47.826 | r: 47.826
r1fm+r2fm = 82.609

[Aggregate metrics]:
rouge1     | fm: 92.996 | p: 92.526 | r: 93.636
rouge2     | fm: 70.406 | p: 70.054 | r: 70.801
rougeL     | fm: 85.971 | p: 85.503 | r: 86.642
rougeLsum  | fm: 85.779 | p: 85.182 | r: 86.403
r1fm+r2fm = 163.402

input #21 time: 0:11:17 | total time: 3:30:02


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
*********************************
*********************************
average of cosine similarity 0.9993363171572422
highest_index [0]
highest [0.9993363171572422]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9597271680831909 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9563654065132141 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9516496658325195 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9361298084259033 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9215717911720276 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.919853925704956 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9158571362495422 for ['[CLS] manufacture i another dir poor $ immunity wrote access vested resemblance [SEP]']
[Init] best perm rec loss: 0.9156816005706787 for ['[CLS] resemblance vested i immunity dir $ wrote manufacture another access poor [SEP]']
[Init] best perm rec loss: 0.9151819348335266 for ['[CLS] immunity i dir $ access wrote vested resemblance another manufacture poor [SEP]']
[Init] best perm rec loss: 0.9144731163978577 for ['[CLS] poor access dir vested resemblance immunity manufacture another i wrote $ [SEP]']
[Init] best perm rec loss: 0.9127120971679688 for ['[CLS] another $ resemblance dir access vested i manufacture immunity wrote poor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.407 (perp=10.798, rec=0.247, cos=0.000), tot_loss_proj:2.614 [t=0.27s]
prediction: ['[CLS] a success good adaptation cafe wonderful adaptation enjoyed original. successful [SEP]']
[ 100/2000] tot_loss=2.182 (perp=9.995, rec=0.183, cos=0.000), tot_loss_proj:2.427 [t=0.25s]
prediction: ['[CLS] a successful successful adaptation an successful adaptation successful enjoyable adaptation enjoyable [SEP]']
[ 150/2000] tot_loss=1.837 (perp=8.508, rec=0.136, cos=0.000), tot_loss_proj:2.153 [t=0.26s]
prediction: ['[CLS] a successful successful adaptation and successful adaptation successful enjoyable adaptation enjoyable [SEP]']
[ 200/2000] tot_loss=2.094 (perp=9.785, rec=0.137, cos=0.000), tot_loss_proj:2.413 [t=0.27s]
prediction: ['[CLS] a successful an its and successful adaptation successful enjoyable film enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.849 (perp=8.595, rec=0.130, cos=0.000), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] a successful film its and successful adaptation successful enjoyable an enjoyable [SEP]']
[ 300/2000] tot_loss=1.812 (perp=8.482, rec=0.116, cos=0.000), tot_loss_proj:2.118 [t=0.27s]
prediction: ['[CLS] a successful film own and successful adaptation successful enjoyable an enjoyable [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.592 (perp=7.374, rec=0.118, cos=0.000), tot_loss_proj:1.831 [t=0.28s]
prediction: ['[CLS] a successful film own successful enjoyable an enjoyable and successful adaptation [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.395 (perp=6.413, rec=0.112, cos=0.000), tot_loss_proj:1.648 [t=0.26s]
prediction: ['[CLS] a successful film own enjoyable film an enjoyable and successful adaptation [SEP]']
[ 450/2000] tot_loss=1.691 (perp=7.940, rec=0.103, cos=0.000), tot_loss_proj:1.995 [t=0.26s]
prediction: ['[CLS] a successful film own enjoyable film an right and successful adaptation [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.498 (perp=7.006, rec=0.097, cos=0.000), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] a successful film own an enjoyable film right and successful adaptation [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.493 (perp=7.006, rec=0.092, cos=0.000), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] a successful film own an enjoyable film right and successful adaptation [SEP]']
[ 600/2000] tot_loss=1.488 (perp=7.006, rec=0.087, cos=0.000), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] a successful film own an enjoyable film right and successful adaptation [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.441 (perp=6.748, rec=0.091, cos=0.000), tot_loss_proj:1.640 [t=0.26s]
prediction: ['[CLS] a successful film an enjoyable film own right and successful adaptation [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.433 (perp=6.748, rec=0.084, cos=0.000), tot_loss_proj:1.636 [t=0.26s]
prediction: ['[CLS] a successful film an enjoyable film own right and successful adaptation [SEP]']
[ 750/2000] tot_loss=1.433 (perp=6.748, rec=0.084, cos=0.000), tot_loss_proj:1.628 [t=0.28s]
prediction: ['[CLS] a successful film an enjoyable film own right and successful adaptation [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.501 (perp=7.075, rec=0.086, cos=0.000), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] a successful film an enjoyable enjoyable own right and successful adaptation [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.694 (perp=8.015, rec=0.091, cos=0.000), tot_loss_proj:1.954 [t=0.26s]
prediction: ['[CLS] a successful film own right an enjoyable its and successful adaptation [SEP]']
[ 900/2000] tot_loss=1.691 (perp=8.015, rec=0.088, cos=0.000), tot_loss_proj:1.940 [t=0.27s]
prediction: ['[CLS] a successful film own right an enjoyable its and successful adaptation [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.390 (perp=6.532, rec=0.083, cos=0.000), tot_loss_proj:1.573 [t=0.27s]
prediction: ['[CLS] a successful film its own right an enjoyable and successful adaptation [SEP]']
Attempt swap
[1000/2000] tot_loss=1.542 (perp=7.300, rec=0.082, cos=0.000), tot_loss_proj:1.767 [t=0.27s]
prediction: ['[CLS] a own film its own right an enjoyable and successful adaptation [SEP]']
[1050/2000] tot_loss=1.535 (perp=7.300, rec=0.075, cos=0.000), tot_loss_proj:1.774 [t=0.26s]
prediction: ['[CLS] a own film its own right an enjoyable and successful adaptation [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.438 (perp=6.756, rec=0.086, cos=0.000), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] a own right its own film an enjoyable and successful adaptation [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.404 (perp=6.562, rec=0.091, cos=0.000), tot_loss_proj:1.715 [t=0.27s]
prediction: ['[CLS] a right its own film own an enjoyable and successful adaptation [SEP]']
[1200/2000] tot_loss=1.403 (perp=6.562, rec=0.091, cos=0.000), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] a right its own film own an enjoyable and successful adaptation [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.392 (perp=6.562, rec=0.079, cos=0.000), tot_loss_proj:1.723 [t=0.26s]
prediction: ['[CLS] a right its own film own an enjoyable and successful adaptation [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.390 (perp=6.495, rec=0.092, cos=0.000), tot_loss_proj:1.684 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.495, rec=0.094, cos=0.000), tot_loss_proj:1.693 [t=0.28s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1400/2000] tot_loss=1.383 (perp=6.495, rec=0.084, cos=0.000), tot_loss_proj:1.689 [t=0.27s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1450/2000] tot_loss=1.379 (perp=6.495, rec=0.080, cos=0.000), tot_loss_proj:1.681 [t=0.25s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
[1500/2000] tot_loss=1.387 (perp=6.495, rec=0.088, cos=0.000), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1550/2000] tot_loss=1.377 (perp=6.495, rec=0.078, cos=0.000), tot_loss_proj:1.684 [t=0.27s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1600/2000] tot_loss=1.376 (perp=6.495, rec=0.078, cos=0.000), tot_loss_proj:1.692 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
[1650/2000] tot_loss=1.385 (perp=6.495, rec=0.087, cos=0.000), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1700/2000] tot_loss=1.373 (perp=6.495, rec=0.074, cos=0.000), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1750/2000] tot_loss=1.383 (perp=6.495, rec=0.084, cos=0.000), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
[1800/2000] tot_loss=1.382 (perp=6.495, rec=0.084, cos=0.000), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1850/2000] tot_loss=1.382 (perp=6.495, rec=0.083, cos=0.000), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[1900/2000] tot_loss=1.381 (perp=6.495, rec=0.082, cos=0.000), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
[1950/2000] tot_loss=1.385 (perp=6.495, rec=0.086, cos=0.000), tot_loss_proj:1.694 [t=0.28s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Attempt swap
[2000/2000] tot_loss=1.387 (perp=6.495, rec=0.088, cos=0.000), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] a right its own own film an enjoyable and successful adaptation [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a right its own own film an enjoyable and successful adaptation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 38.462 | p: 38.462 | r: 38.462
rougeLsum  | fm: 38.462 | p: 38.462 | r: 38.462
r1fm+r2fm = 125.641

[Aggregate metrics]:
rouge1     | fm: 92.992 | p: 92.518 | r: 93.694
rouge2     | fm: 68.529 | p: 68.220 | r: 68.893
rougeL     | fm: 83.794 | p: 83.295 | r: 84.426
rougeLsum  | fm: 83.665 | p: 83.171 | r: 84.288
r1fm+r2fm = 161.521

input #22 time: 0:11:08 | total time: 3:41:11


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
*********************************
*********************************
average of cosine similarity 0.9992354906378623
highest_index [0]
highest [0.9992354906378623]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8034012913703918 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7636498212814331 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7599901556968689 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7420994639396667 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.7417494654655457 for ['[CLS] compiling ears eponymous education carlo debutrk area guᵈ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.736446738243103 for ['[CLS] 2018 screenwriter stone arlington lightquist circle only tight wire hospital weaponerateau would homestead grid inquiries das all locomotives makeup amazingpireau opponent velocitypressedise modifiedrish like footballer berlinnesian counter, nomination aden plantented bye brass mine gave a transport mira [SEP]']
[Init] best rec loss: 0.7294015288352966 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.72591233253479 for ['[CLS]blood air writ baseball major culture quitcellularperation tracks. pepper debuted competition finland her level colonont critics host x must another reaching - mayo marijuana test novel asleep ericatat fine bullshit total remote into rocker steam monroe sensation office count madame clutch created eve [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.737 (perp=11.156, rec=0.506, cos=0.000), tot_loss_proj:3.258 [t=0.29s]
prediction: ['[CLS] norwegian broken collection have national culture task! cafe legacy. doctorate artwork catchment output risku offensive aim action mission international if distance sectorpoint alone • values gently,ography creating assessment and the technology development. handle connection. transition whose vanessa target shot environmental [SEP]']
[ 100/2000] tot_loss=2.526 (perp=10.942, rec=0.338, cos=0.000), tot_loss_proj:3.187 [t=0.29s]
prediction: ["[CLS] biological objective shadow have primary patriotic task! 1978 of. the artwork environmental education risku ultimately the strategic mission vietnam greater strategic soldiers revolutionary harvest'thesis gently :rp the health and the program built. thermal into. pedestrian whose desire target his policy [SEP]"]
[ 150/2000] tot_loss=2.309 (perp=10.161, rec=0.277, cos=0.000), tot_loss_proj:3.131 [t=0.31s]
prediction: ["[CLS] actor battle shadow understand assumptions patriotic task : horror of. the photography education list risk, ultimately : strategicly vietnam tv strategic soldiers revolutionary harvest'thesis gently, still vietnam the and the stress maurice, overhaul into. pedestrian their objective main his generation [SEP]"]
[ 200/2000] tot_loss=2.325 (perp=10.470, rec=0.231, cos=0.000), tot_loss_proj:3.508 [t=0.30s]
prediction: ['[CLS] actor rather shadow understand existing patrioticous jarrett vietnam of of the pictures environmental list crisis - ultimately the objectively vietnam tv strategic soldiers ultimately retribution from idea tone,. vietnam the and the stressoint,ease into assessment pedestrian capturing objective main my generation [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.250 (perp=10.242, rec=0.202, cos=0.000), tot_loss_proj:3.203 [t=0.29s]
prediction: ['[CLS] actor rather sounded understand : patrioticing jarrett vietnam of of the pictures critic list conflict, ultimately the objectively vietnam its strategic soldiers ultimately : while idea tone, conventional vietnam the. the stress marketing, tee - assessment auto capturing objective main your generation [SEP]']
[ 300/2000] tot_loss=2.150 (perp=9.916, rec=0.167, cos=0.000), tot_loss_proj:3.168 [t=0.29s]
prediction: ['[CLS] actor rather sounded roots : patrioticing jarrett vietnam of of a picture critique list conflict, ultimately the objectively vietnam its strategic soldiers ultimately : while idea tone, initial vietnam the - the strategic tone. tau - assessment its capturing objective main your generation [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.115 (perp=9.816, rec=0.151, cos=0.000), tot_loss_proj:3.321 [t=0.29s]
prediction: ['[CLS] spectators held idea roots : patrioticing ： vietnam of a picture critique picture conflict, achieve the objective strategic of vietnam its strategic soldiers ultimately : while idea tone, initial vietnam the the the role drama. ra that assessment ultimately capturing objective main his generation [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.044 (perp=9.581, rec=0.128, cos=0.000), tot_loss_proj:3.255 [t=0.30s]
prediction: ['[CLS] spectators is idea cost : patriotic, : vietnam of a picture critique of conflict, achieves objectiveio of vietnam its strategic soldiers achieves while idea toneing some vietnam the the the cost drama. ra - assessment ultimately capturing objective main our generation [SEP]']
[ 450/2000] tot_loss=2.086 (perp=9.797, rec=0.126, cos=0.000), tot_loss_proj:2.808 [t=0.28s]
prediction: ['[CLS] actor with idea cost : patriotic, ： vietnam of a picture environmental of vietnam, achieves objective× og vietnam its strategic soldiers achieves while idea toneing some vietnam the the the cost drama. ra that assessment ultimatelyizing objective main our generation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.020 (perp=9.512, rec=0.118, cos=0.000), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] drama the ideachy : patriotic, the vietnam of a pictureroving of vietnam, achieves objective× ra vietnam its strategic soldiers achieves while idea toneing some vietnam picture the the cost drama. ra that assessment ultimatelyizing objective main our generation [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.960 (perp=9.211, rec=0.118, cos=0.000), tot_loss_proj:2.794 [t=0.27s]
prediction: ['[CLS] drama the ideachy : patriotic, the vietnam of a pictureroving of vietnam, achieves objective× cost vietnam its strategic soldiers achieves while idea tonezing some vietnam picture the the ra drama. ra that assessment ultimatelyizing objective main our generation [SEP]']
[ 600/2000] tot_loss=2.029 (perp=9.583, rec=0.112, cos=0.000), tot_loss_proj:2.911 [t=0.27s]
prediction: ['[CLS] drama the mightchy : patriotic, the vietnam of a pictureroving with vietnam, achieves objective× cost vietnam its strategic soldiers achieves while idea tonezing some drama picture the the ra drama. ra that loss ultimately definition objective main our generation [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.922 (perp=9.083, rec=0.106, cos=0.000), tot_loss_proj:2.783 [t=0.27s]
prediction: ['[CLS] drama the might cost : patriotic, the vietnam of a picture object with vietnam, achieves objective× cost vietnam its strategic soldiers achieves while idea tonezing some drama picture the the main drama. ra that else ultimately definition objective ra our generation [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.880 (perp=8.840, rec=0.112, cos=0.000), tot_loss_proj:2.761 [t=0.26s]
prediction: ['[CLS] drama the might cost : patriotic, the vietnam of a picture object with vietnam, achieves objective× cost vietnam its strategic soldiers achieves while the idea tonezing some drama picture the main drama. ra that else ultimately definition objective ra a generation [SEP]']
[ 750/2000] tot_loss=1.818 (perp=8.607, rec=0.097, cos=0.000), tot_loss_proj:2.695 [t=0.27s]
prediction: ['[CLS] drama the might cost : patriotic, the vietnam of a picture object with vietnam, achieves objective× cost vietnam its strategic soldiers achieves while the idea tonezing some drama : the main drama. ra that else ultimately definition objective ra a generation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.775 (perp=8.357, rec=0.104, cos=0.000), tot_loss_proj:2.533 [t=0.28s]
prediction: ['[CLS] strategic drama the might cost : patriotic, the vietnam with a picture object with vietnam, achieves objective× cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that goes ultimately definition objective ra a generation [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.748 (perp=8.237, rec=0.101, cos=0.000), tot_loss_proj:2.520 [t=0.27s]
prediction: ['[CLS] strategic drama the might cost :, the vietnam - a patriotic picture object with vietnam, achieves objective× cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that that ultimately definition objective ra a generation [SEP]']
[ 900/2000] tot_loss=1.728 (perp=8.178, rec=0.092, cos=0.000), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] strategic drama the might cost :, the vietnam with a patriotic picture object with vietnam, achieves objective× cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that that ultimately definition objective ra a generation [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.740 (perp=8.242, rec=0.091, cos=0.000), tot_loss_proj:2.501 [t=0.27s]
prediction: ['[CLS] strategic drama the might cost :, the vietnam - a patriotic picture object with vietnam, achieves a li cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that to ultimately definition objective ra objective generation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.708 (perp=8.063, rec=0.095, cos=0.000), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] strategic drama the cost : will, the vietnam - a patriotic picture object with vietnam, achieves aka cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that to ultimately definition objective ra objective generation [SEP]']
[1050/2000] tot_loss=1.701 (perp=8.067, rec=0.088, cos=0.000), tot_loss_proj:2.498 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : will, the vietnam - a patriotic picture object with vietnam, achieves a li cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that to ultimately definition objective ra objective generation [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.679 (perp=7.921, rec=0.095, cos=0.000), tot_loss_proj:2.458 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the will, vietnam - a patriotic picture object with vietnam, achieves a li cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that to ultimately definition objective ra objective generation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.665 (perp=7.850, rec=0.094, cos=0.000), tot_loss_proj:2.499 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : theh, vietnam - a patriotic picture object with vietnam, achieves a will cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that to ultimately definition objective ra objective generation [SEP]']
[1200/2000] tot_loss=1.662 (perp=7.850, rec=0.092, cos=0.000), tot_loss_proj:2.498 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : theh, vietnam - a patriotic picture object with vietnam, achieves a will cost vietnam its soldiers achieves while the idea tonezing some drama : the main drama. ra that to ultimately definition objective ra objective generation [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.735 (perp=8.228, rec=0.089, cos=0.000), tot_loss_proj:2.564 [t=0.25s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will cost li its soldiers achieves while the idea tonezing some drama : the main drama. ra that came ultimately definition objective ra objective generation [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.578 (perp=7.429, rec=0.092, cos=0.000), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will cost that its soldiers achieves while the idea tonezing some drama : the main drama. rah to ultimately definition objective og objective generation [SEP]']
[1350/2000] tot_loss=1.578 (perp=7.429, rec=0.092, cos=0.000), tot_loss_proj:2.329 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will cost that its soldiers achieves while the idea tonezing some drama : the main drama. rah to ultimately definition objective og objective generation [SEP]']
Attempt swap
[1400/2000] tot_loss=1.635 (perp=7.760, rec=0.083, cos=0.000), tot_loss_proj:2.443 [t=0.26s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will cost that its soldiers achieves while the idea tonezing some drama : the main drama. rah define ultimately definition objective og objective generation [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.592 (perp=7.540, rec=0.084, cos=0.000), tot_loss_proj:2.356 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will cost that its soldiers achieves while the idea tonezing some to picture the main drama. rah drama ultimately definition objective og objective generation [SEP]']
[1500/2000] tot_loss=1.568 (perp=7.393, rec=0.089, cos=0.000), tot_loss_proj:2.303 [t=0.26s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will cost that its soldiers achieves while the idea tonezing some to picture the main drama. rah drama ultimately definition objective defined objective generation [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.564 (perp=7.350, rec=0.094, cos=0.000), tot_loss_proj:2.358 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with vietnam, achieves a will that its cost soldiers achieves while the idea tonezing some to picture the main drama. rah drama ultimately definition objective defined objective generation [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.526 (perp=7.192, rec=0.088, cos=0.000), tot_loss_proj:2.284 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tonezing some to picture the main drama. rah drama objective definition ultimately defined objective generation [SEP]']
[1650/2000] tot_loss=1.532 (perp=7.192, rec=0.093, cos=0.000), tot_loss_proj:2.281 [t=0.28s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnam - a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tonezing some to picture the main drama. rah drama objective definition ultimately defined objective generation [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.579 (perp=7.449, rec=0.089, cos=0.000), tot_loss_proj:2.344 [t=0.26s]
prediction: ['[CLS] strategic drama the cost : the vietnam, vietnamh a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing to picture the main drama. rah drama objective definition ultimately defined objective generation [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.564 (perp=7.416, rec=0.081, cos=0.000), tot_loss_proj:2.333 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam vietnam,h a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing to picture the main drama. rah drama objective definition ultimately defined objective generation [SEP]']
[1800/2000] tot_loss=1.572 (perp=7.416, rec=0.089, cos=0.000), tot_loss_proj:2.335 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam vietnam,h a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing to picture the main drama. rah drama objective definition ultimately defined objective generation [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.471, rec=0.089, cos=0.000), tot_loss_proj:2.409 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam vietnam,h a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing to picture the main drama. rah drama objective definition ultimately define objective generation [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.583 (perp=7.506, rec=0.082, cos=0.000), tot_loss_proj:2.442 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam vietnam,h a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing picture to the main drama. rah drama objective definition ultimately define objective generation [SEP]']
[1950/2000] tot_loss=1.588 (perp=7.506, rec=0.087, cos=0.000), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS] strategic drama the cost : the vietnam vietnam,h a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing picture to the main drama. rah drama objective definition ultimately define objective generation [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.622 (perp=7.675, rec=0.087, cos=0.000), tot_loss_proj:2.407 [t=0.27s]
prediction: ['[CLS] strategic drama the picture : the vietnam vietnam,h a patriotic picture object such conflict, achieves a will that its cost soldiers achieves while the idea tone somezing cost to the main drama. rah drama objective definition ultimately define objective generation [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] strategic drama the cost : the vietnam vietnam,h a patriotic picture object with conflict, achieves a will that its cost soldiers achieves while the idea tone somezing to picture the main drama. rah drama objective definition ultimately define objective generation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.171 | p: 71.429 | r: 75.000
rouge2     | fm: 5.000 | p: 4.878 | r: 5.128
rougeL     | fm: 31.707 | p: 30.952 | r: 32.500
rougeLsum  | fm: 31.707 | p: 30.952 | r: 32.500
r1fm+r2fm = 78.171

[Aggregate metrics]:
rouge1     | fm: 92.208 | p: 91.654 | r: 92.869
rouge2     | fm: 65.638 | p: 65.384 | r: 65.946
rougeL     | fm: 81.866 | p: 81.341 | r: 82.419
rougeLsum  | fm: 81.315 | p: 80.864 | r: 81.900
r1fm+r2fm = 157.846

input #23 time: 0:11:23 | total time: 3:52:34


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
*********************************
*********************************
average of cosine similarity 0.9993536249967531
highest_index [0]
highest [0.9993536249967531]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8953457474708557 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8711922764778137 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8592777848243713 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8263744115829468 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.8198344707489014 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8171668648719788 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7646704912185669 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7622896432876587 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7606878280639648 for ['[CLS] unless county attack younger damnedwyl no bond play snow suffer village emaneous mid ryu port happy bush arms [SEP]']
[Init] best perm rec loss: 0.7564651966094971 for ['[CLS] unless damned happy em younger county port bush bond mid snow arms no ryu village play attack sufferwylaneous [SEP]']
[Init] best perm rec loss: 0.7556052803993225 for ['[CLS] happyaneous younger unless suffer snow bond mid play damned em ryu nowyl village attack bush port arms county [SEP]']
[Init] best perm rec loss: 0.7554426193237305 for ['[CLS] attack unless port play younger arms county bush village em no suffer mid damnedaneous snow ryuwyl bond happy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.618 (perp=11.021, rec=0.414, cos=0.000), tot_loss_proj:3.066 [t=0.27s]
prediction: ['[CLS] attack stopped police a terrorists allegedly police nominee were stupid military political rape ; security mail boston backed security authorities [SEP]']
[ 100/2000] tot_loss=2.572 (perp=11.239, rec=0.324, cos=0.000), tot_loss_proj:3.164 [t=0.26s]
prediction: ['[CLS] secured slippery terrorists the evil allegedly issuing nominee were evil tactical political taken ; security mail swing backed foreign! [SEP]']
[ 150/2000] tot_loss=2.539 (perp=11.213, rec=0.297, cos=0.000), tot_loss_proj:3.009 [t=0.27s]
prediction: ['[CLS] taken spelled terrorists the evil possibly issuing nominee were evil the political taken ; security sexual!typical government context [SEP]']
[ 200/2000] tot_loss=2.338 (perp=10.440, rec=0.250, cos=0.000), tot_loss_proj:2.811 [t=0.28s]
prediction: ['[CLS] taken muslims terrorists the evil ( : historian ) evil ins political taken ; weapons sexual! outside background context [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.921 (perp=8.603, rec=0.200, cos=0.000), tot_loss_proj:2.417 [t=0.26s]
prediction: ['[CLS] taken muslims taken the evil than ( context ) evil! political terrorists ; weapons sexual! outside the context [SEP]']
[ 300/2000] tot_loss=1.782 (perp=8.074, rec=0.167, cos=0.000), tot_loss_proj:2.297 [t=0.27s]
prediction: ['[CLS] taken muslims taken the evil than ( see ) evil! political terrorists ; terrorists sexual! outside the context [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.737 (perp=7.877, rec=0.162, cos=0.000), tot_loss_proj:2.303 [t=0.27s]
prediction: ['[CLS] muslims taken the evil than taken ( see ) evil! : terrorists ; terrorists sexual! outside current context [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.713 (perp=7.775, rec=0.158, cos=0.000), tot_loss_proj:2.250 [t=0.29s]
prediction: ['[CLS] muslims taken the evil than taken ( see evil )! : terrorists ; climate sexual! outside current context [SEP]']
[ 450/2000] tot_loss=1.637 (perp=7.448, rec=0.147, cos=0.000), tot_loss_proj:2.111 [t=0.28s]
prediction: ['[CLS] more taken the evil than taken ( see climate )! : terrorists ; climate sexual! outside current context [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.732 (perp=7.984, rec=0.135, cos=0.000), tot_loss_proj:2.236 [t=0.28s]
prediction: ['[CLS] more taken than ( evil taken ( see climate )! : terrorists : climate sexual! outside current context [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.719 (perp=7.984, rec=0.122, cos=0.000), tot_loss_proj:2.235 [t=0.28s]
prediction: ['[CLS] more taken than ( evil taken ( see climate )! : terrorists : climate sexual! outside current context [SEP]']
[ 600/2000] tot_loss=1.691 (perp=7.854, rec=0.120, cos=0.000), tot_loss_proj:2.178 [t=0.28s]
prediction: ['[CLS] more taken than ( evil taken ( see climate )! : terrorists are climate sexual! outside current context [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.729 (perp=8.050, rec=0.119, cos=0.000), tot_loss_proj:2.283 [t=0.25s]
prediction: ['[CLS] more than taken ( evil taken ( see climate ) ever : terrorists are climate sexual! outside current context [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.691 (perp=7.858, rec=0.119, cos=0.000), tot_loss_proj:2.232 [t=0.27s]
prediction: ['[CLS] more than evil taken ( taken ( see climate ) ever : terrorists are climate sexual! outside current context [SEP]']
[ 750/2000] tot_loss=1.821 (perp=7.770, rec=0.268, cos=0.000), tot_loss_proj:2.359 [t=0.28s]
prediction: ['[CLS] more than evil taken the bench! see climate ( ever : terrorists are government )! outside current context [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.730 (perp=7.713, rec=0.188, cos=0.000), tot_loss_proj:2.245 [t=0.29s]
prediction: ['[CLS] more evil than taken the bench! see climate ( ever : terrorists are government )! outside current context [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.635 (perp=7.296, rec=0.175, cos=0.000), tot_loss_proj:2.129 [t=0.28s]
prediction: ['[CLS] more evil than taken the bench! see climate ( ever : terrorists are government! outside the context ) [SEP]']
[ 900/2000] tot_loss=1.622 (perp=7.296, rec=0.163, cos=0.000), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] more evil than taken the bench! see climate ( ever : terrorists are government! outside the context ) [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.592 (perp=7.181, rec=0.156, cos=0.000), tot_loss_proj:2.096 [t=0.28s]
prediction: ['[CLS] more evil taken than the bench! see climate ( ever : terrorists are government! outside the context ) [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.578 (perp=7.166, rec=0.145, cos=0.000), tot_loss_proj:2.049 [t=0.28s]
prediction: ['[CLS] more evil taken than the bench ( see climate! ever : terrorists are government! outside the context ) [SEP]']
[1050/2000] tot_loss=1.573 (perp=7.166, rec=0.140, cos=0.000), tot_loss_proj:2.043 [t=0.27s]
prediction: ['[CLS] more evil taken than the bench ( see climate! ever : terrorists are government! outside the context ) [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.407 (perp=6.320, rec=0.143, cos=0.000), tot_loss_proj:2.028 [t=0.29s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate! : terrorists are government! outside the context ) [SEP]']
Attempt swap
[1150/2000] tot_loss=1.393 (perp=6.320, rec=0.129, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate! : terrorists are government! outside the context ) [SEP]']
[1200/2000] tot_loss=1.398 (perp=6.320, rec=0.134, cos=0.000), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate! : terrorists are government! outside the context ) [SEP]']
Attempt swap
[1250/2000] tot_loss=1.391 (perp=6.320, rec=0.127, cos=0.000), tot_loss_proj:1.997 [t=0.27s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate! : terrorists are government! outside the context ) [SEP]']
Attempt swap
[1300/2000] tot_loss=1.388 (perp=6.320, rec=0.124, cos=0.000), tot_loss_proj:1.992 [t=0.28s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate! : terrorists are government! outside the context ) [SEP]']
[1350/2000] tot_loss=1.382 (perp=6.320, rec=0.118, cos=0.000), tot_loss_proj:1.987 [t=0.28s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate! : terrorists are government! outside the context ) [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.360 (perp=6.136, rec=0.133, cos=0.000), tot_loss_proj:1.950 [t=0.28s]
prediction: ['[CLS] ever more evil taken than the bench ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=6.886, rec=0.131, cos=0.000), tot_loss_proj:2.056 [t=0.29s]
prediction: ['[CLS] ever more evil taken than ( bench ( see climate : terrorists are government! outside the context! ) [SEP]']
[1500/2000] tot_loss=1.501 (perp=6.886, rec=0.124, cos=0.000), tot_loss_proj:2.051 [t=0.30s]
prediction: ['[CLS] ever more evil taken than ( bench ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.468 (perp=6.697, rec=0.129, cos=0.000), tot_loss_proj:2.065 [t=0.29s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.463 (perp=6.697, rec=0.123, cos=0.000), tot_loss_proj:2.059 [t=0.31s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
[1650/2000] tot_loss=1.451 (perp=6.697, rec=0.111, cos=0.000), tot_loss_proj:2.062 [t=0.30s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
[1700/2000] tot_loss=1.466 (perp=6.697, rec=0.126, cos=0.000), tot_loss_proj:2.057 [t=0.27s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.463 (perp=6.697, rec=0.124, cos=0.000), tot_loss_proj:2.064 [t=0.26s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
[1800/2000] tot_loss=1.458 (perp=6.697, rec=0.118, cos=0.000), tot_loss_proj:2.059 [t=0.27s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.457 (perp=6.697, rec=0.117, cos=0.000), tot_loss_proj:2.062 [t=0.28s]
prediction: ['[CLS] ever more evil taken than bench ( ( see climate : terrorists are government! outside the context! ) [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.439 (perp=6.561, rec=0.127, cos=0.000), tot_loss_proj:1.983 [t=0.28s]
prediction: ['[CLS] ever more evil taken than climate ( ( see bench : terrorists are government! outside the context! ) [SEP]']
[1950/2000] tot_loss=1.446 (perp=6.561, rec=0.133, cos=0.000), tot_loss_proj:1.989 [t=0.29s]
prediction: ['[CLS] ever more evil taken than climate ( ( see bench : terrorists are government! outside the context! ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.430 (perp=6.561, rec=0.118, cos=0.000), tot_loss_proj:1.982 [t=0.28s]
prediction: ['[CLS] ever more evil taken than climate ( ( see bench : terrorists are government! outside the context! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] more than taken ( evil taken ( see climate ) ever : terrorists are climate sexual! outside current context [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 82.353 | r: 77.778
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 34.286 | p: 35.294 | r: 33.333
rougeLsum  | fm: 34.286 | p: 35.294 | r: 33.333
r1fm+r2fm = 86.061

[Aggregate metrics]:
rouge1     | fm: 91.741 | p: 91.222 | r: 92.337
rouge2     | fm: 63.541 | p: 63.333 | r: 63.816
rougeL     | fm: 79.805 | p: 79.286 | r: 80.309
rougeLsum  | fm: 79.690 | p: 79.170 | r: 80.039
r1fm+r2fm = 155.282

input #24 time: 0:11:23 | total time: 4:03:57


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
*********************************
*********************************
average of cosine similarity 0.9993186375693031
highest_index [0]
highest [0.9993186375693031]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.0046311616897583 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9432210326194763 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9324101805686951 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9292864203453064 for ['[CLS] riot phone expectix [SEP]']
[Init] best rec loss: 0.9201552867889404 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9130578637123108 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9060046672821045 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.8839746713638306 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.8813798427581787 for ['[CLS] mouth cycle jury oblast [SEP]']
[Init] best perm rec loss: 0.8804708123207092 for ['[CLS] jury cycle oblast mouth [SEP]']
[Init] best perm rec loss: 0.8778733611106873 for ['[CLS] jury oblast cycle mouth [SEP]']
[Init] best perm rec loss: 0.8735387921333313 for ['[CLS] oblast jury mouth cycle [SEP]']
[Init] best perm rec loss: 0.8733189702033997 for ['[CLS] jury oblast mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.130 (perp=9.210, rec=0.288, cos=0.000), tot_loss_proj:2.342 [t=0.26s]
prediction: ['[CLS] film beautiful beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.204 (perp=10.165, rec=0.171, cos=0.000), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] film beautiful beautiful strange [SEP]']
[ 150/2000] tot_loss=2.183 (perp=10.165, rec=0.150, cos=0.000), tot_loss_proj:2.451 [t=0.25s]
prediction: ['[CLS] film beautiful beautiful strange [SEP]']
[ 200/2000] tot_loss=2.162 (perp=10.165, rec=0.129, cos=0.000), tot_loss_proj:2.448 [t=0.27s]
prediction: ['[CLS] film beautiful beautiful strange [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.593 (perp=7.298, rec=0.133, cos=0.000), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
[ 300/2000] tot_loss=1.572 (perp=7.298, rec=0.112, cos=0.000), tot_loss_proj:1.744 [t=0.27s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.562 (perp=7.298, rec=0.102, cos=0.000), tot_loss_proj:1.748 [t=0.27s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.550 (perp=7.298, rec=0.091, cos=0.000), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
[ 450/2000] tot_loss=1.495 (perp=7.104, rec=0.074, cos=0.000), tot_loss_proj:1.623 [t=0.28s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.403 (perp=6.646, rec=0.074, cos=0.000), tot_loss_proj:1.449 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.401 (perp=6.646, rec=0.072, cos=0.000), tot_loss_proj:1.435 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.400 (perp=6.646, rec=0.071, cos=0.000), tot_loss_proj:1.434 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.391 (perp=6.646, rec=0.062, cos=0.000), tot_loss_proj:1.436 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.000), tot_loss_proj:1.438 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.393 (perp=6.646, rec=0.064, cos=0.000), tot_loss_proj:1.430 [t=0.29s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.396 (perp=6.646, rec=0.066, cos=0.000), tot_loss_proj:1.440 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.390 (perp=6.646, rec=0.061, cos=0.000), tot_loss_proj:1.436 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.390 (perp=6.646, rec=0.061, cos=0.000), tot_loss_proj:1.441 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.386 (perp=6.646, rec=0.057, cos=0.000), tot_loss_proj:1.436 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.393 (perp=6.646, rec=0.064, cos=0.000), tot_loss_proj:1.435 [t=0.29s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.387 (perp=6.646, rec=0.058, cos=0.000), tot_loss_proj:1.433 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.390 (perp=6.646, rec=0.061, cos=0.000), tot_loss_proj:1.428 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.390 (perp=6.646, rec=0.061, cos=0.000), tot_loss_proj:1.450 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.391 (perp=6.646, rec=0.062, cos=0.000), tot_loss_proj:1.428 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.387 (perp=6.646, rec=0.058, cos=0.000), tot_loss_proj:1.429 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.398 (perp=6.646, rec=0.069, cos=0.000), tot_loss_proj:1.438 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.382 (perp=6.646, rec=0.053, cos=0.000), tot_loss_proj:1.442 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.391 (perp=6.646, rec=0.062, cos=0.000), tot_loss_proj:1.443 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.386 (perp=6.646, rec=0.057, cos=0.000), tot_loss_proj:1.438 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.398 (perp=6.646, rec=0.069, cos=0.000), tot_loss_proj:1.434 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.384 (perp=6.646, rec=0.055, cos=0.000), tot_loss_proj:1.441 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.396 (perp=6.646, rec=0.067, cos=0.000), tot_loss_proj:1.436 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.381 (perp=6.646, rec=0.051, cos=0.000), tot_loss_proj:1.435 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.385 (perp=6.646, rec=0.056, cos=0.000), tot_loss_proj:1.439 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.395 (perp=6.646, rec=0.066, cos=0.000), tot_loss_proj:1.426 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.646, rec=0.054, cos=0.000), tot_loss_proj:1.443 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.384 (perp=6.646, rec=0.055, cos=0.000), tot_loss_proj:1.430 [t=0.31s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.000), tot_loss_proj:1.431 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.389 (perp=6.646, rec=0.060, cos=0.000), tot_loss_proj:1.429 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.387 (perp=6.646, rec=0.058, cos=0.000), tot_loss_proj:1.443 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.115 | p: 91.607 | r: 92.655
rouge2     | fm: 64.731 | p: 64.530 | r: 65.024
rougeL     | fm: 80.579 | p: 80.155 | r: 81.118
rougeLsum  | fm: 80.119 | p: 79.755 | r: 80.579
r1fm+r2fm = 156.846

input #25 time: 0:11:12 | total time: 4:15:10


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
*********************************
*********************************
average of cosine similarity 0.9992069913482746
highest_index [0]
highest [0.9992069913482746]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9761833548545837 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9669443368911743 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.9600929021835327 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9561089277267456 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9441299438476562 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9398886561393738 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9354456663131714 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8887447118759155 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8856053948402405 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8834297060966492 for ['[CLS] boat huge supposed hair teaches ao rectangular deputy should bat family also addם whomness space timeline charity intent failed intent list [SEP]']
[Init] best perm rec loss: 0.8828130960464478 for ['[CLS] add also failed timeline whom list bat space hairness teaches ao familyם boat charity intent huge deputy intent supposed should rectangular [SEP]']
[Init] best perm rec loss: 0.8825820088386536 for ['[CLS] should space boat bat teaches failed huge also charity supposed ao intent rectangular whom timeline deputyness intent list add hair familyם [SEP]']
[Init] best perm rec loss: 0.8820961713790894 for ['[CLS] also deputy bat whom family huge intent boatם teaches ao should add intent rectangular space hair supposed failedness timeline list charity [SEP]']
[Init] best perm rec loss: 0.881793200969696 for ['[CLS] intent supposed should hair ao family list intent rectangular alsonessם whom failed boat huge add charity deputy space bat teaches timeline [SEP]']
[Init] best perm rec loss: 0.8804860711097717 for ['[CLS] rectangular failedness timeline whom deputy also space boat intent bat list supposed shouldם huge ao charity teaches family intent hair add [SEP]']
[Init] best perm rec loss: 0.8795996904373169 for ['[CLS] should add charityness boat timeline supposed family alsoם ao teaches intent huge hair list intent whom space deputy rectangular failed bat [SEP]']
[Init] best perm rec loss: 0.8791795372962952 for ['[CLS] should rectangular intent batם ao charityness intent teaches failed list timeline also hair deputy boat add huge family supposed space whom [SEP]']
[Init] best perm rec loss: 0.8789591789245605 for ['[CLS] boat spaceness timeline list intent supposed family deputy ao also hair rectangular intent teaches add should charity whom bat failed hugeם [SEP]']
[Init] best perm rec loss: 0.8763189315795898 for ['[CLS] shouldם whom also hair deputy supposed rectangular failed teaches spaceness ao bat list charity boat intent family huge intent timeline add [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.797 (perp=12.344, rec=0.328, cos=0.000), tot_loss_proj:3.096 [t=0.30s]
prediction: ['[CLS] dumb / german? useless empty pointless old stupid legislativecus left raceway illegal total louisville repair al! stupid dog jenks riddle [SEP]']
[ 100/2000] tot_loss=2.488 (perp=11.233, rec=0.241, cos=0.000), tot_loss_proj:2.826 [t=0.30s]
prediction: ['[CLS] college - french also pointless empty pointless ) sold rotten -sed posts arrest payments french loss import ) reckless gr import french [SEP]']
[ 150/2000] tot_loss=2.276 (perp=10.382, rec=0.200, cos=0.000), tot_loss_proj:2.591 [t=0.30s]
prediction: ['[CLS] young - french ) pointless - pointless -ic algerian - from pm agency post french ended import ) import gr import french [SEP]']
[ 200/2000] tot_loss=2.025 (perp=9.171, rec=0.191, cos=0.000), tot_loss_proj:2.355 [t=0.30s]
prediction: ['[CLS] young - french ) pointless - pointless -ish childish - from age agency import age age import ) import - import french [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.130 (perp=9.747, rec=0.181, cos=0.000), tot_loss_proj:2.516 [t=0.30s]
prediction: ['[CLS] young - french ) this mean pointless -ish algerian - from age import import age age import pointlessder - import writer [SEP]']
[ 300/2000] tot_loss=2.090 (perp=9.653, rec=0.159, cos=0.000), tot_loss_proj:2.493 [t=0.26s]
prediction: ['[CLS] coming - french ) this mean pointless -ish algerian - and age import import age age import pointlessder - import writer [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.172 (perp=10.133, rec=0.145, cos=0.000), tot_loss_proj:2.658 [t=0.27s]
prediction: ['[CLS] coming - french ) this mean pointlessder - breton - import sophie age from coming age import pointlessder import and writer [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.001 (perp=9.388, rec=0.123, cos=0.000), tot_loss_proj:2.526 [t=0.28s]
prediction: ['[CLS] coming - french ) this mean pointlessder - - import sophie breton age from coming age import pointlessder import and writer [SEP]']
[ 450/2000] tot_loss=2.004 (perp=9.486, rec=0.107, cos=0.000), tot_loss_proj:2.800 [t=0.28s]
prediction: ['[CLS] coming - french ) this mean pointlessder - - import sophie passionate age from age age import pointlessing import and writer [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.959 (perp=9.292, rec=0.100, cos=0.000), tot_loss_proj:2.757 [t=0.28s]
prediction: ['[CLS] coming ) french - this mean pointlessder - - import sophie charlotte age from age age import pointlessing import and writer [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.026 (perp=9.613, rec=0.103, cos=0.000), tot_loss_proj:2.626 [t=0.27s]
prediction: ['[CLS] coming ) french - this mean pointlessder of age import sophie mori - from age age import pointlessing import and director [SEP]']
[ 600/2000] tot_loss=1.912 (perp=9.102, rec=0.091, cos=0.000), tot_loss_proj:2.560 [t=0.27s]
prediction: ['[CLS] coming ) french - this mean pointlessder of age import sophie breton - from age age import pointlessing import and director [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.827 (perp=8.709, rec=0.085, cos=0.000), tot_loss_proj:2.345 [t=0.28s]
prediction: ['[CLS] coming ) french - this mean pointlessder of age pointless sophie breton - from age - import importing import and director [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.725 (perp=8.182, rec=0.089, cos=0.000), tot_loss_proj:2.148 [t=0.27s]
prediction: ['[CLS] coming ) french - this pointless meander of age pointless sophie breton - from age - import importing import and director [SEP]']
[ 750/2000] tot_loss=1.721 (perp=8.182, rec=0.085, cos=0.000), tot_loss_proj:2.154 [t=0.28s]
prediction: ['[CLS] coming ) french - this pointless meander of age pointless sophie breton - from age - import importing import and director [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.800 (perp=8.615, rec=0.077, cos=0.000), tot_loss_proj:2.214 [t=0.25s]
prediction: ['[CLS] coming ) french - this pointless meander of age pointless sophie jacques - from writer - import importing import and director [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.792 (perp=8.533, rec=0.085, cos=0.000), tot_loss_proj:2.194 [t=0.27s]
prediction: ['[CLS] coming ) french - this pointless meander of age and sophie jacques - from writer - import importing import pointless director [SEP]']
[ 900/2000] tot_loss=1.787 (perp=8.533, rec=0.081, cos=0.000), tot_loss_proj:2.189 [t=0.27s]
prediction: ['[CLS] coming ) french - this pointless meander of age and sophie jacques - from writer - import importing import pointless director [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.859 (perp=8.885, rec=0.082, cos=0.000), tot_loss_proj:2.269 [t=0.27s]
prediction: ['[CLS] coming ) french - this pointless meander of age - sophierot - from writer and import importing import pointless director [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.824 (perp=8.699, rec=0.084, cos=0.000), tot_loss_proj:2.250 [t=0.28s]
prediction: ['[CLS] coming ) french - this pointless meander of age - sophierot pointless - from writer and import importing import director [SEP]']
[1050/2000] tot_loss=1.820 (perp=8.699, rec=0.080, cos=0.000), tot_loss_proj:2.245 [t=0.28s]
prediction: ['[CLS] coming ) french - this pointless meander of age - sophierot pointless - from writer and import importing import director [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.882 (perp=9.015, rec=0.079, cos=0.000), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] coming ) french - this pointless meander of age anne -rot bi - from writer and import importing import director [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.785 (perp=8.548, rec=0.075, cos=0.000), tot_loss_proj:2.287 [t=0.28s]
prediction: ['[CLS] coming ) french - this pointless meander of age anne - - birot from writer and import importing import director [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.548, rec=0.078, cos=0.000), tot_loss_proj:2.282 [t=0.28s]
prediction: ['[CLS] coming ) french - this pointless meander of age anne - - birot from writer and import importing import director [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.773 (perp=8.501, rec=0.073, cos=0.000), tot_loss_proj:2.221 [t=0.27s]
prediction: ['[CLS] coming french ) - this pointless meander of age anne - - birot from writer and import importing import director [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.683 (perp=8.051, rec=0.073, cos=0.000), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] coming french ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
[1350/2000] tot_loss=1.691 (perp=8.051, rec=0.081, cos=0.000), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] coming french ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=8.051, rec=0.068, cos=0.000), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] coming french ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.652 (perp=7.885, rec=0.075, cos=0.000), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
[1500/2000] tot_loss=1.651 (perp=7.885, rec=0.074, cos=0.000), tot_loss_proj:2.479 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
Attempt swap
[1550/2000] tot_loss=1.652 (perp=7.885, rec=0.075, cos=0.000), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
Attempt swap
[1600/2000] tot_loss=1.660 (perp=7.885, rec=0.083, cos=0.000), tot_loss_proj:2.480 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
[1650/2000] tot_loss=1.649 (perp=7.885, rec=0.072, cos=0.000), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]']
Attempt swap
[1700/2000] tot_loss=1.651 (perp=7.897, rec=0.072, cos=0.000), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import importing - director [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.606 (perp=7.630, rec=0.080, cos=0.000), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import - importing director [SEP]']
[1800/2000] tot_loss=1.597 (perp=7.630, rec=0.071, cos=0.000), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import - importing director [SEP]']
Attempt swap
[1850/2000] tot_loss=1.596 (perp=7.630, rec=0.070, cos=0.000), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and import - importing director [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.606 (perp=7.640, rec=0.078, cos=0.000), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and importing import - director [SEP]']
[1950/2000] tot_loss=1.604 (perp=7.640, rec=0.076, cos=0.000), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] french coming ) - this pointless meander of age - - anne birot from writer and importing import - director [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.593 (perp=7.579, rec=0.077, cos=0.000), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] coming ) - this french pointless meander of age - - anne birot from writer and importing import - director [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] coming french ) - this pointless meander of age - - anne birot from writer and import importing import director [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 83.333 | r: 88.235
rouge2     | fm: 12.121 | p: 11.765 | r: 12.500
rougeL     | fm: 51.429 | p: 50.000 | r: 52.941
rougeLsum  | fm: 51.429 | p: 50.000 | r: 52.941
r1fm+r2fm = 97.835

[Aggregate metrics]:
rouge1     | fm: 91.875 | p: 91.300 | r: 92.448
rouge2     | fm: 62.575 | p: 62.398 | r: 62.964
rougeL     | fm: 79.445 | p: 79.059 | r: 80.051
rougeLsum  | fm: 79.052 | p: 78.555 | r: 79.592
r1fm+r2fm = 154.450

input #26 time: 0:10:32 | total time: 4:25:42


Running input #27 of 100.
reference: 
========================
are so generic 
========================
*********************************
*********************************
average of cosine similarity 0.9993448142110618
highest_index [0]
highest [0.9993448142110618]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9622665047645569 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9328019022941589 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.908375084400177 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.8574681878089905 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8030140995979309 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8020824790000916 for ['[CLS]wine transit given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.648 (perp=11.530, rec=0.342, cos=0.000), tot_loss_proj:2.853 [t=0.27s]
prediction: ['[CLS] hated generic generic [SEP]']
[ 100/2000] tot_loss=2.141 (perp=9.693, rec=0.203, cos=0.000), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 150/2000] tot_loss=2.160 (perp=10.068, rec=0.147, cos=0.000), tot_loss_proj:2.780 [t=0.27s]
prediction: ['[CLS] yellow generic are [SEP]']
[ 200/2000] tot_loss=1.874 (perp=8.813, rec=0.111, cos=0.000), tot_loss_proj:3.639 [t=0.26s]
prediction: ['[CLS] not generic are [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.578 (perp=7.321, rec=0.114, cos=0.000), tot_loss_proj:3.013 [t=0.26s]
prediction: ['[CLS] not so generic [SEP]']
[ 300/2000] tot_loss=1.574 (perp=7.321, rec=0.109, cos=0.000), tot_loss_proj:3.006 [t=0.26s]
prediction: ['[CLS] not so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.654 (perp=7.779, rec=0.098, cos=0.000), tot_loss_proj:1.712 [t=0.27s]
prediction: ['[CLS] is so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.654 (perp=7.779, rec=0.098, cos=0.000), tot_loss_proj:1.720 [t=0.26s]
prediction: ['[CLS] is so generic [SEP]']
[ 450/2000] tot_loss=1.680 (perp=7.779, rec=0.124, cos=0.000), tot_loss_proj:1.725 [t=0.26s]
prediction: ['[CLS] is so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.661 (perp=7.779, rec=0.105, cos=0.000), tot_loss_proj:1.731 [t=0.27s]
prediction: ['[CLS] is so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.765 (perp=8.320, rec=0.101, cos=0.000), tot_loss_proj:1.740 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.735 (perp=8.320, rec=0.071, cos=0.000), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.725 (perp=8.320, rec=0.061, cos=0.000), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.738 (perp=8.320, rec=0.074, cos=0.000), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.727 (perp=8.320, rec=0.063, cos=0.000), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.734 (perp=8.320, rec=0.070, cos=0.000), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.723 (perp=8.320, rec=0.059, cos=0.000), tot_loss_proj:1.744 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.717 (perp=8.320, rec=0.053, cos=0.000), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.742 (perp=8.320, rec=0.078, cos=0.000), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.720 (perp=8.320, rec=0.056, cos=0.000), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.716 (perp=8.320, rec=0.052, cos=0.000), tot_loss_proj:1.734 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.722 (perp=8.320, rec=0.058, cos=0.000), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.728 (perp=8.320, rec=0.064, cos=0.000), tot_loss_proj:1.730 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.320, rec=0.057, cos=0.000), tot_loss_proj:1.734 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.725 (perp=8.320, rec=0.061, cos=0.000), tot_loss_proj:1.735 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.730 (perp=8.320, rec=0.066, cos=0.000), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.730 (perp=8.320, rec=0.066, cos=0.000), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.727 (perp=8.320, rec=0.063, cos=0.000), tot_loss_proj:1.731 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.730 (perp=8.320, rec=0.066, cos=0.000), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.716 (perp=8.320, rec=0.052, cos=0.000), tot_loss_proj:1.727 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=8.320, rec=0.066, cos=0.000), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.731 (perp=8.320, rec=0.067, cos=0.000), tot_loss_proj:1.742 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.721 (perp=8.320, rec=0.057, cos=0.000), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.722 (perp=8.320, rec=0.058, cos=0.000), tot_loss_proj:1.741 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.723 (perp=8.320, rec=0.059, cos=0.000), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.722 (perp=8.320, rec=0.058, cos=0.000), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.725 (perp=8.320, rec=0.061, cos=0.000), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.729 (perp=8.320, rec=0.065, cos=0.000), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.719 (perp=8.320, rec=0.055, cos=0.000), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.739 (perp=8.320, rec=0.075, cos=0.000), tot_loss_proj:1.726 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.146 | p: 91.669 | r: 92.668
rouge2     | fm: 64.153 | p: 63.959 | r: 64.440
rougeL     | fm: 80.196 | p: 79.828 | r: 80.788
rougeLsum  | fm: 79.784 | p: 79.412 | r: 80.320
r1fm+r2fm = 156.299

input #27 time: 0:11:12 | total time: 4:36:55


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
*********************************
*********************************
average of cosine similarity 0.9993335637127583
highest_index [0]
highest [0.9993335637127583]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8102776408195496 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7932990789413452 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7825984954833984 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7524017095565796 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best perm rec loss: 0.7509779334068298 for ['[CLS] mixed battlefield fullyuro [SEP]']
[Init] best perm rec loss: 0.7453075051307678 for ['[CLS] battlefield fullyuro mixed [SEP]']
[Init] best perm rec loss: 0.7452954053878784 for ['[CLS]uro battlefield fully mixed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.498 (perp=10.827, rec=0.333, cos=0.000), tot_loss_proj:3.333 [t=0.27s]
prediction: ['[CLS] [SEP] circus week weekday [SEP]']
[ 100/2000] tot_loss=1.822 (perp=8.154, rec=0.192, cos=0.000), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] for 37 minutes minutes [SEP]']
[ 150/2000] tot_loss=1.822 (perp=8.475, rec=0.127, cos=0.000), tot_loss_proj:2.083 [t=0.25s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 200/2000] tot_loss=1.623 (perp=7.699, rec=0.083, cos=0.000), tot_loss_proj:1.631 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.601 (perp=7.699, rec=0.061, cos=0.000), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 300/2000] tot_loss=1.608 (perp=7.699, rec=0.068, cos=0.000), tot_loss_proj:1.627 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.603 (perp=7.699, rec=0.063, cos=0.000), tot_loss_proj:1.626 [t=0.35s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.601 (perp=7.699, rec=0.062, cos=0.000), tot_loss_proj:1.629 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.610 (perp=7.699, rec=0.070, cos=0.000), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.606 (perp=7.699, rec=0.066, cos=0.000), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.600 (perp=7.699, rec=0.060, cos=0.000), tot_loss_proj:1.627 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.603 (perp=7.699, rec=0.063, cos=0.000), tot_loss_proj:1.634 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.601 (perp=7.699, rec=0.062, cos=0.000), tot_loss_proj:1.628 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.600 (perp=7.699, rec=0.060, cos=0.000), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.607 (perp=7.699, rec=0.067, cos=0.000), tot_loss_proj:1.633 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.608 (perp=7.699, rec=0.068, cos=0.000), tot_loss_proj:1.633 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.604 (perp=7.699, rec=0.064, cos=0.000), tot_loss_proj:1.633 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.596 (perp=7.699, rec=0.056, cos=0.000), tot_loss_proj:1.630 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.597 (perp=7.699, rec=0.058, cos=0.000), tot_loss_proj:1.618 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.597 (perp=7.699, rec=0.058, cos=0.000), tot_loss_proj:1.629 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.589 (perp=7.699, rec=0.049, cos=0.000), tot_loss_proj:1.631 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.593 (perp=7.699, rec=0.053, cos=0.000), tot_loss_proj:1.629 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.599 (perp=7.699, rec=0.060, cos=0.000), tot_loss_proj:1.639 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.600 (perp=7.699, rec=0.060, cos=0.000), tot_loss_proj:1.627 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.598 (perp=7.699, rec=0.058, cos=0.000), tot_loss_proj:1.625 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.589 (perp=7.699, rec=0.049, cos=0.000), tot_loss_proj:1.629 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.598 (perp=7.699, rec=0.058, cos=0.000), tot_loss_proj:1.631 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.603 (perp=7.699, rec=0.064, cos=0.000), tot_loss_proj:1.634 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.592 (perp=7.699, rec=0.053, cos=0.000), tot_loss_proj:1.633 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.699, rec=0.060, cos=0.000), tot_loss_proj:1.636 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.600 (perp=7.699, rec=0.061, cos=0.000), tot_loss_proj:1.631 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.607 (perp=7.699, rec=0.067, cos=0.000), tot_loss_proj:1.628 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.605 (perp=7.699, rec=0.065, cos=0.000), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.602 (perp=7.699, rec=0.063, cos=0.000), tot_loss_proj:1.628 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.599 (perp=7.699, rec=0.060, cos=0.000), tot_loss_proj:1.633 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.605 (perp=7.699, rec=0.066, cos=0.000), tot_loss_proj:1.635 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.601 (perp=7.699, rec=0.062, cos=0.000), tot_loss_proj:1.636 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=7.699, rec=0.057, cos=0.000), tot_loss_proj:1.629 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.599 (perp=7.699, rec=0.059, cos=0.000), tot_loss_proj:1.633 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.699, rec=0.056, cos=0.000), tot_loss_proj:1.635 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.432 | p: 91.860 | r: 92.971
rouge2     | fm: 65.573 | p: 65.339 | r: 65.836
rougeL     | fm: 80.909 | p: 80.552 | r: 81.418
rougeLsum  | fm: 80.626 | p: 80.210 | r: 81.136
r1fm+r2fm = 158.005

input #28 time: 0:11:09 | total time: 4:48:04


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
*********************************
*********************************
average of cosine similarity 0.9992950120222769
highest_index [0]
highest [0.9992950120222769]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9423229694366455 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9257262945175171 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9105294346809387 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8550407886505127 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8468914031982422 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8449756503105164 for ['[CLS] crystal shock completion carrydable stay recordingdrive ella off [SEP]']
[Init] best rec loss: 0.8242601752281189 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.819426417350769 for ['[CLS] type attack www estate ambulance + chelsealand out todd [SEP]']
[Init] best rec loss: 0.8130525946617126 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.8121238350868225 for ['[CLS] meters axle cells transmit f bufounded u mostly veto [SEP]']
[Init] best perm rec loss: 0.8086562156677246 for ['[CLS] meters ffounded mostly cells transmit axle veto bu u [SEP]']
[Init] best perm rec loss: 0.8071014881134033 for ['[CLS]founded axle u f cells bu meters mostly veto transmit [SEP]']
[Init] best perm rec loss: 0.8066072463989258 for ['[CLS] axle bufounded u mostly f cells meters veto transmit [SEP]']
[Init] best perm rec loss: 0.8048798441886902 for ['[CLS] cells meters f axle mostlyfounded u veto transmit bu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.160 (perp=13.916, rec=0.377, cos=0.000), tot_loss_proj:3.729 [t=0.26s]
prediction: ['[CLS] sure werefurt rumor hatch papal.wi discrimination situation [SEP]']
[ 100/2000] tot_loss=2.718 (perp=12.136, rec=0.291, cos=0.000), tot_loss_proj:4.033 [t=0.27s]
prediction: ['[CLS] sure resident believe is humphreyfirmed.₀tland jurisdiction [SEP]']
[ 150/2000] tot_loss=2.111 (perp=9.417, rec=0.228, cos=0.000), tot_loss_proj:3.166 [t=0.25s]
prediction: ['[CLS] believe resident that not residentfirmed. residentcute it [SEP]']
[ 200/2000] tot_loss=1.919 (perp=8.660, rec=0.187, cos=0.000), tot_loss_proj:3.008 [t=0.27s]
prediction: ['[CLS] believe resident that not resident disbelief. resident evil it [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.812 (perp=8.102, rec=0.191, cos=0.000), tot_loss_proj:2.910 [t=0.27s]
prediction: ['[CLS] believe resident also not resident. resident evil accepted it [SEP]']
[ 300/2000] tot_loss=1.686 (perp=7.647, rec=0.156, cos=0.000), tot_loss_proj:2.498 [t=0.26s]
prediction: ['[CLS] believe resident also not resident. resident evil that it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.542 (perp=7.143, rec=0.114, cos=0.000), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.537 (perp=7.143, rec=0.108, cos=0.000), tot_loss_proj:2.591 [t=0.27s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
[ 450/2000] tot_loss=1.532 (perp=7.143, rec=0.103, cos=0.000), tot_loss_proj:2.591 [t=0.27s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.537 (perp=7.143, rec=0.108, cos=0.000), tot_loss_proj:2.579 [t=0.27s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.527 (perp=7.143, rec=0.098, cos=0.000), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
[ 600/2000] tot_loss=1.527 (perp=7.143, rec=0.099, cos=0.000), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.535 (perp=7.143, rec=0.107, cos=0.000), tot_loss_proj:2.582 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.512 (perp=7.143, rec=0.084, cos=0.000), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
[ 750/2000] tot_loss=1.529 (perp=7.143, rec=0.100, cos=0.000), tot_loss_proj:2.583 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.523 (perp=7.143, rec=0.094, cos=0.000), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.520 (perp=7.143, rec=0.091, cos=0.000), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
[ 900/2000] tot_loss=1.525 (perp=7.143, rec=0.096, cos=0.000), tot_loss_proj:2.583 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is resident evil that it [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.623 (perp=7.669, rec=0.089, cos=0.000), tot_loss_proj:2.599 [t=0.25s]
prediction: ['[CLS] believe also resident not resident is i evil that it [SEP]']
Attempt swap
[1000/2000] tot_loss=1.617 (perp=7.669, rec=0.083, cos=0.000), tot_loss_proj:2.603 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is i evil that it [SEP]']
[1050/2000] tot_loss=1.624 (perp=7.669, rec=0.090, cos=0.000), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] believe also resident not resident is i evil that it [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.587 (perp=7.455, rec=0.096, cos=0.000), tot_loss_proj:3.141 [t=0.26s]
prediction: ['[CLS] believe also resident is not resident i evil that it [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.450 (perp=6.730, rec=0.104, cos=0.000), tot_loss_proj:2.421 [t=0.28s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
[1200/2000] tot_loss=1.447 (perp=6.730, rec=0.101, cos=0.000), tot_loss_proj:2.418 [t=0.25s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1250/2000] tot_loss=1.438 (perp=6.730, rec=0.092, cos=0.000), tot_loss_proj:2.425 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1300/2000] tot_loss=1.445 (perp=6.730, rec=0.099, cos=0.000), tot_loss_proj:2.412 [t=0.25s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
[1350/2000] tot_loss=1.431 (perp=6.730, rec=0.085, cos=0.000), tot_loss_proj:2.422 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1400/2000] tot_loss=1.432 (perp=6.730, rec=0.086, cos=0.000), tot_loss_proj:2.422 [t=0.27s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.445 (perp=6.730, rec=0.099, cos=0.000), tot_loss_proj:2.419 [t=0.27s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
[1500/2000] tot_loss=1.436 (perp=6.730, rec=0.090, cos=0.000), tot_loss_proj:2.417 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1550/2000] tot_loss=1.446 (perp=6.730, rec=0.100, cos=0.000), tot_loss_proj:2.415 [t=0.27s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.442 (perp=6.730, rec=0.096, cos=0.000), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
[1650/2000] tot_loss=1.444 (perp=6.730, rec=0.098, cos=0.000), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.438 (perp=6.730, rec=0.092, cos=0.000), tot_loss_proj:2.424 [t=0.25s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1750/2000] tot_loss=1.428 (perp=6.730, rec=0.082, cos=0.000), tot_loss_proj:2.420 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
[1800/2000] tot_loss=1.453 (perp=6.730, rec=0.107, cos=0.000), tot_loss_proj:2.422 [t=0.27s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.439 (perp=6.730, rec=0.093, cos=0.000), tot_loss_proj:2.418 [t=0.25s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.431 (perp=6.730, rec=0.085, cos=0.000), tot_loss_proj:2.421 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
[1950/2000] tot_loss=1.430 (perp=6.730, rec=0.084, cos=0.000), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.427 (perp=6.730, rec=0.081, cos=0.000), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] i believe also resident is not resident evil that it [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe also resident is not resident evil that it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 92.471 | p: 91.860 | r: 93.150
rouge2     | fm: 64.547 | p: 64.282 | r: 64.897
rougeL     | fm: 80.376 | p: 79.911 | r: 81.056
rougeLsum  | fm: 80.184 | p: 79.690 | r: 80.823
r1fm+r2fm = 157.018

input #29 time: 0:11:09 | total time: 4:59:14


Running input #30 of 100.
reference: 
========================
fizzability 
========================
*********************************
*********************************
average of cosine similarity 0.9992722707397942
highest_index [0]
highest [0.9992722707397942]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9133288860321045 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8706606030464172 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8705593943595886 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 0.8064538240432739 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7871582508087158 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7867048978805542 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 0.7824510931968689 for ['[CLS] footading night [SEP]']
[Init] best rec loss: 0.7801363468170166 for ['[CLS] johnson trans gap [SEP]']
[Init] best rec loss: 0.7397655248641968 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7131261825561523 for ['[CLS] acceleration council lizard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.916 (perp=12.773, rec=0.361, cos=0.000), tot_loss_proj:4.274 [t=0.26s]
prediction: ['[CLS] giant bottle than [SEP]']
[ 100/2000] tot_loss=2.873 (perp=13.069, rec=0.259, cos=0.000), tot_loss_proj:4.309 [t=0.26s]
prediction: ['[CLS]bilityfire fi [SEP]']
[ 150/2000] tot_loss=2.780 (perp=12.950, rec=0.190, cos=0.000), tot_loss_proj:3.612 [t=0.26s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.732 (perp=12.950, rec=0.142, cos=0.000), tot_loss_proj:3.613 [t=0.28s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.134 (perp=9.539, rec=0.226, cos=0.000), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.019 (perp=9.539, rec=0.111, cos=0.000), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.996 (perp=9.539, rec=0.088, cos=0.000), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.970 (perp=9.539, rec=0.062, cos=0.000), tot_loss_proj:1.958 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.977 (perp=9.539, rec=0.069, cos=0.000), tot_loss_proj:1.976 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.539, rec=0.063, cos=0.000), tot_loss_proj:1.962 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.982 (perp=9.539, rec=0.074, cos=0.000), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.974 (perp=9.539, rec=0.066, cos=0.000), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.968 (perp=9.539, rec=0.060, cos=0.000), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=9.539, rec=0.062, cos=0.000), tot_loss_proj:1.977 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.969 (perp=9.539, rec=0.061, cos=0.000), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.972 (perp=9.539, rec=0.064, cos=0.000), tot_loss_proj:1.962 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.967 (perp=9.539, rec=0.059, cos=0.000), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.967 (perp=9.539, rec=0.059, cos=0.000), tot_loss_proj:1.973 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.970 (perp=9.539, rec=0.062, cos=0.000), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.977 (perp=9.539, rec=0.070, cos=0.000), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.964 (perp=9.539, rec=0.056, cos=0.000), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.977 (perp=9.539, rec=0.069, cos=0.000), tot_loss_proj:1.967 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.967 (perp=9.539, rec=0.059, cos=0.000), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.971 (perp=9.539, rec=0.063, cos=0.000), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.958 (perp=9.539, rec=0.050, cos=0.000), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.962 (perp=9.539, rec=0.054, cos=0.000), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.968 (perp=9.539, rec=0.060, cos=0.000), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.965 (perp=9.539, rec=0.057, cos=0.000), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.972 (perp=9.539, rec=0.065, cos=0.000), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.977 (perp=9.539, rec=0.069, cos=0.000), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.964 (perp=9.539, rec=0.056, cos=0.000), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.977 (perp=9.539, rec=0.070, cos=0.000), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.957 (perp=9.539, rec=0.049, cos=0.000), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.974 (perp=9.539, rec=0.066, cos=0.000), tot_loss_proj:1.959 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.968 (perp=9.539, rec=0.061, cos=0.000), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.980 (perp=9.539, rec=0.072, cos=0.000), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.978 (perp=9.539, rec=0.071, cos=0.000), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.962 (perp=9.539, rec=0.055, cos=0.000), tot_loss_proj:1.978 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.966 (perp=9.539, rec=0.058, cos=0.000), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.962 (perp=9.539, rec=0.054, cos=0.000), tot_loss_proj:1.974 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.717 | p: 92.167 | r: 93.367
rouge2     | fm: 65.581 | p: 65.326 | r: 65.921
rougeL     | fm: 81.007 | p: 80.539 | r: 81.581
rougeLsum  | fm: 80.766 | p: 80.341 | r: 81.334
r1fm+r2fm = 158.298

input #30 time: 0:11:08 | total time: 5:10:22


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
*********************************
*********************************
average of cosine similarity 0.99933965413518
highest_index [0]
highest [0.99933965413518]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9404395818710327 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.920451819896698 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8848218321800232 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.868414044380188 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8055649995803833 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8024404048919678 for ['[CLS] robin running artwork [SEP]']
[Init] best perm rec loss: 0.7951310276985168 for ['[CLS] artwork running robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.075 (perp=8.746, rec=0.325, cos=0.000), tot_loss_proj:2.634 [t=0.25s]
prediction: ['[CLS] better better school [SEP]']
[ 100/2000] tot_loss=2.170 (perp=9.604, rec=0.250, cos=0.000), tot_loss_proj:2.279 [t=0.29s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 150/2000] tot_loss=2.116 (perp=9.604, rec=0.195, cos=0.000), tot_loss_proj:2.273 [t=0.26s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 200/2000] tot_loss=2.091 (perp=9.604, rec=0.170, cos=0.000), tot_loss_proj:2.283 [t=0.29s]
prediction: ['[CLS] better better vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.057 (perp=9.604, rec=0.136, cos=0.000), tot_loss_proj:2.277 [t=0.28s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 300/2000] tot_loss=1.871 (perp=8.742, rec=0.123, cos=0.000), tot_loss_proj:3.173 [t=0.29s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.623 (perp=7.603, rec=0.103, cos=0.000), tot_loss_proj:1.661 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.630 (perp=7.603, rec=0.109, cos=0.000), tot_loss_proj:1.671 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.623 (perp=7.603, rec=0.102, cos=0.000), tot_loss_proj:1.660 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.623 (perp=7.603, rec=0.103, cos=0.000), tot_loss_proj:1.660 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.621 (perp=7.603, rec=0.101, cos=0.000), tot_loss_proj:1.669 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.616 (perp=7.603, rec=0.095, cos=0.000), tot_loss_proj:1.669 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.613 (perp=7.603, rec=0.092, cos=0.000), tot_loss_proj:1.667 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.612 (perp=7.603, rec=0.091, cos=0.000), tot_loss_proj:1.668 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.619 (perp=7.603, rec=0.099, cos=0.000), tot_loss_proj:1.663 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.619 (perp=7.603, rec=0.098, cos=0.000), tot_loss_proj:1.675 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.625 (perp=7.603, rec=0.105, cos=0.000), tot_loss_proj:1.668 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.617 (perp=7.603, rec=0.096, cos=0.000), tot_loss_proj:1.662 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.623 (perp=7.603, rec=0.103, cos=0.000), tot_loss_proj:1.665 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.607 (perp=7.603, rec=0.087, cos=0.000), tot_loss_proj:1.658 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.613 (perp=7.603, rec=0.092, cos=0.000), tot_loss_proj:1.669 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.612 (perp=7.603, rec=0.091, cos=0.000), tot_loss_proj:1.658 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.626 (perp=7.603, rec=0.106, cos=0.000), tot_loss_proj:1.660 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.618 (perp=7.603, rec=0.097, cos=0.000), tot_loss_proj:1.659 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.611 (perp=7.603, rec=0.090, cos=0.000), tot_loss_proj:1.664 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.612 (perp=7.603, rec=0.092, cos=0.000), tot_loss_proj:1.669 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.612 (perp=7.603, rec=0.092, cos=0.000), tot_loss_proj:1.669 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.624 (perp=7.603, rec=0.104, cos=0.000), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.626 (perp=7.603, rec=0.105, cos=0.000), tot_loss_proj:1.663 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.603 (perp=7.603, rec=0.082, cos=0.000), tot_loss_proj:1.670 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.617 (perp=7.603, rec=0.096, cos=0.000), tot_loss_proj:1.662 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.619 (perp=7.603, rec=0.098, cos=0.000), tot_loss_proj:1.663 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.615 (perp=7.603, rec=0.095, cos=0.000), tot_loss_proj:1.656 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.605 (perp=7.603, rec=0.084, cos=0.000), tot_loss_proj:1.665 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.621 (perp=7.603, rec=0.101, cos=0.000), tot_loss_proj:1.670 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.612 (perp=7.603, rec=0.091, cos=0.000), tot_loss_proj:1.658 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.614 (perp=7.603, rec=0.094, cos=0.000), tot_loss_proj:1.653 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.603 (perp=7.603, rec=0.082, cos=0.000), tot_loss_proj:1.656 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.618 (perp=7.603, rec=0.097, cos=0.000), tot_loss_proj:1.655 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.604 (perp=7.603, rec=0.083, cos=0.000), tot_loss_proj:1.651 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.942 | p: 92.404 | r: 93.601
rouge2     | fm: 66.755 | p: 66.487 | r: 67.008
rougeL     | fm: 81.888 | p: 81.351 | r: 82.343
rougeLsum  | fm: 81.469 | p: 80.938 | r: 82.032
r1fm+r2fm = 159.697

input #31 time: 0:11:21 | total time: 5:21:44


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
*********************************
*********************************
average of cosine similarity 0.9992518566738027
highest_index [0]
highest [0.9992518566738027]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0378060340881348 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9469242095947266 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8885713219642639 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8826674222946167 for ['[CLS] shot scale nest benefit jenny aspen introduced everything zoe arrival capital theory [SEP]']
[Init] best rec loss: 0.8797690272331238 for ['[CLS] spiders armenian dreams¨ me riff clearly space cyprus center ᵍ glory [SEP]']
[Init] best rec loss: 0.8632789254188538 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8472914695739746 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8472805619239807 for ['[CLS]erated doc tax 2009 citizens completely fa outreach {zic spot 2 [SEP]']
[Init] best perm rec loss: 0.8461568355560303 for ['[CLS] taxerated 2009zic doc fa spot outreach completely citizens { 2 [SEP]']
[Init] best perm rec loss: 0.8456001281738281 for ['[CLS]zic spot { 2erated tax fa 2009 outreach citizens completely doc [SEP]']
[Init] best perm rec loss: 0.8439976572990417 for ['[CLS] fa citizens outreachzic {erated tax completely doc spot 2009 2 [SEP]']
[Init] best perm rec loss: 0.8423302173614502 for ['[CLS] outreacherated doc { fa 2009 citizens spot 2 tax completelyzic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.063 (perp=13.989, rec=0.265, cos=0.000), tot_loss_proj:4.397 [t=0.25s]
prediction: ['[CLS] revivalhi influenced criteriafat accessible accessible easily alongside neededonate stories [SEP]']
[ 100/2000] tot_loss=2.703 (perp=12.501, rec=0.203, cos=0.000), tot_loss_proj:3.931 [t=0.26s]
prediction: ['[CLS] hasting broker malcolm that accessible easily easily together neededonate stories [SEP]']
[ 150/2000] tot_loss=3.060 (perp=14.508, rec=0.159, cos=0.000), tot_loss_proj:4.364 [t=0.27s]
prediction: ['[CLS] res res pull jayneul accessible easily accessible togethertonesonate stories [SEP]']
[ 200/2000] tot_loss=3.046 (perp=14.482, rec=0.149, cos=0.000), tot_loss_proj:4.779 [t=0.27s]
prediction: ['[CLS] res res pull pullund accessible easily accessible togethertonesonate stories [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.282 (perp=10.803, rec=0.122, cos=0.000), tot_loss_proj:3.886 [t=0.25s]
prediction: ['[CLS] pull res pull resund easily easily accessible with togetheronate stories [SEP]']
[ 300/2000] tot_loss=2.427 (perp=11.635, rec=0.099, cos=0.000), tot_loss_proj:3.815 [t=0.25s]
prediction: ['[CLS] pull res pull resund together easily accessible that togetheronate stories [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.416 (perp=11.555, rec=0.105, cos=0.000), tot_loss_proj:3.562 [t=0.25s]
prediction: ['[CLS] pull res pull resund together easily together that accessibleonate stories [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.116 (perp=10.045, rec=0.107, cos=0.000), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] pull accessible pull resund together easily with that resonate stories [SEP]']
[ 450/2000] tot_loss=2.096 (perp=10.045, rec=0.087, cos=0.000), tot_loss_proj:3.357 [t=0.26s]
prediction: ['[CLS] pull accessible pull resund together easily with that resonate stories [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.166 (perp=10.376, rec=0.091, cos=0.000), tot_loss_proj:3.554 [t=0.27s]
prediction: ['[CLS] pull accessible pull resund together easily stories that profonate with [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.074 (perp=9.815, rec=0.111, cos=0.000), tot_loss_proj:2.758 [t=0.25s]
prediction: ['[CLS] pull accessible pull res together easily stories that profundonate with [SEP]']
[ 600/2000] tot_loss=2.047 (perp=9.815, rec=0.084, cos=0.000), tot_loss_proj:2.775 [t=0.27s]
prediction: ['[CLS] pull accessible pull res together easily stories that profundonate with [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.979 (perp=9.482, rec=0.082, cos=0.000), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] pull accessible pull easily together res stories that profundonate with [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.826 (perp=8.663, rec=0.093, cos=0.000), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS] pull accessible pull easily together stories that profund resonate with [SEP]']
[ 750/2000] tot_loss=1.811 (perp=8.663, rec=0.078, cos=0.000), tot_loss_proj:2.134 [t=0.27s]
prediction: ['[CLS] pull accessible pull easily together stories that profund resonate with [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.854 (perp=8.881, rec=0.078, cos=0.000), tot_loss_proj:2.193 [t=0.26s]
prediction: ['[CLS]ity accessible pull easily together stories that profund resonate with [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.691 (perp=8.072, rec=0.077, cos=0.000), tot_loss_proj:1.895 [t=0.26s]
prediction: ['[CLS] accessible pull easily together stories that profundity resonate with [SEP]']
[ 900/2000] tot_loss=1.699 (perp=8.072, rec=0.085, cos=0.000), tot_loss_proj:1.894 [t=0.26s]
prediction: ['[CLS] accessible pull easily together stories that profundity resonate with [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.517 (perp=7.223, rec=0.073, cos=0.000), tot_loss_proj:1.794 [t=0.27s]
prediction: ['[CLS] accessible stories that pull easily together profundity resonate with [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.415 (perp=6.673, rec=0.081, cos=0.000), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] accessible stories that pull easily together with profundity resonate [SEP]']
[1050/2000] tot_loss=1.409 (perp=6.673, rec=0.074, cos=0.000), tot_loss_proj:1.632 [t=0.27s]
prediction: ['[CLS] accessible stories that pull easily together with profundity resonate [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.387 (perp=6.586, rec=0.069, cos=0.000), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] accessible stories that pull together easily with profundity resonate [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.333 (perp=6.319, rec=0.070, cos=0.000), tot_loss_proj:1.514 [t=0.26s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
[1200/2000] tot_loss=1.334 (perp=6.319, rec=0.071, cos=0.000), tot_loss_proj:1.508 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1250/2000] tot_loss=1.327 (perp=6.319, rec=0.063, cos=0.000), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1300/2000] tot_loss=1.328 (perp=6.319, rec=0.064, cos=0.000), tot_loss_proj:1.515 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
[1350/2000] tot_loss=1.339 (perp=6.319, rec=0.075, cos=0.000), tot_loss_proj:1.514 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1400/2000] tot_loss=1.331 (perp=6.319, rec=0.067, cos=0.000), tot_loss_proj:1.510 [t=0.26s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1450/2000] tot_loss=1.322 (perp=6.319, rec=0.058, cos=0.000), tot_loss_proj:1.522 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
[1500/2000] tot_loss=1.346 (perp=6.319, rec=0.082, cos=0.000), tot_loss_proj:1.516 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1550/2000] tot_loss=1.339 (perp=6.319, rec=0.075, cos=0.000), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1600/2000] tot_loss=1.335 (perp=6.319, rec=0.071, cos=0.000), tot_loss_proj:1.510 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
[1650/2000] tot_loss=1.333 (perp=6.319, rec=0.069, cos=0.000), tot_loss_proj:1.522 [t=0.25s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1700/2000] tot_loss=1.328 (perp=6.319, rec=0.064, cos=0.000), tot_loss_proj:1.517 [t=0.28s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1750/2000] tot_loss=1.325 (perp=6.319, rec=0.062, cos=0.000), tot_loss_proj:1.507 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
[1800/2000] tot_loss=1.329 (perp=6.319, rec=0.065, cos=0.000), tot_loss_proj:1.514 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1850/2000] tot_loss=1.333 (perp=6.319, rec=0.069, cos=0.000), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[1900/2000] tot_loss=1.334 (perp=6.319, rec=0.070, cos=0.000), tot_loss_proj:1.517 [t=0.28s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
[1950/2000] tot_loss=1.330 (perp=6.319, rec=0.066, cos=0.000), tot_loss_proj:1.519 [t=0.26s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Attempt swap
[2000/2000] tot_loss=1.330 (perp=6.319, rec=0.066, cos=0.000), tot_loss_proj:1.510 [t=0.27s]
prediction: ['[CLS] easily accessible stories that pull together with profundity resonate [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] easily accessible stories that pull together with profundity resonate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 93.168 | p: 92.623 | r: 93.800
rouge2     | fm: 66.273 | p: 66.003 | r: 66.515
rougeL     | fm: 81.351 | p: 80.919 | r: 81.962
rougeLsum  | fm: 81.218 | p: 80.798 | r: 81.779
r1fm+r2fm = 159.441

input #32 time: 0:11:08 | total time: 5:32:53


Running input #33 of 100.
reference: 
========================
higher 
========================
*********************************
*********************************
average of cosine similarity 0.9992774353775351
highest_index [0]
highest [0.9992774353775351]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.0021233558654785 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9776734113693237 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9482463598251343 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9034788608551025 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8223047256469727 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7980056405067444 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.792485237121582 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.541 (perp=11.231, rec=0.295, cos=0.000), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.328 (perp=11.231, rec=0.082, cos=0.000), tot_loss_proj:2.448 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.303 (perp=11.231, rec=0.057, cos=0.000), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.305 (perp=11.231, rec=0.059, cos=0.000), tot_loss_proj:2.384 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.304 (perp=11.231, rec=0.058, cos=0.000), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.307 (perp=11.231, rec=0.061, cos=0.000), tot_loss_proj:2.387 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.312 (perp=11.231, rec=0.066, cos=0.000), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.309 (perp=11.231, rec=0.063, cos=0.000), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.306 (perp=11.231, rec=0.060, cos=0.000), tot_loss_proj:2.400 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.311 (perp=11.231, rec=0.065, cos=0.000), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.313 (perp=11.231, rec=0.067, cos=0.000), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.307 (perp=11.231, rec=0.061, cos=0.000), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.311 (perp=11.231, rec=0.065, cos=0.000), tot_loss_proj:2.395 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.297 (perp=11.231, rec=0.051, cos=0.000), tot_loss_proj:2.399 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.294 (perp=11.231, rec=0.047, cos=0.000), tot_loss_proj:2.386 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.322 (perp=11.231, rec=0.076, cos=0.000), tot_loss_proj:2.402 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.308 (perp=11.231, rec=0.062, cos=0.000), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.313 (perp=11.231, rec=0.067, cos=0.000), tot_loss_proj:2.382 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.304 (perp=11.231, rec=0.058, cos=0.000), tot_loss_proj:2.393 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.324 (perp=11.231, rec=0.078, cos=0.000), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.308 (perp=11.231, rec=0.062, cos=0.000), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.304 (perp=11.231, rec=0.058, cos=0.000), tot_loss_proj:2.388 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.301 (perp=11.231, rec=0.055, cos=0.000), tot_loss_proj:2.413 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.308 (perp=11.231, rec=0.062, cos=0.000), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.326 (perp=11.231, rec=0.080, cos=0.000), tot_loss_proj:2.391 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.298 (perp=11.231, rec=0.052, cos=0.000), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.000), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.299 (perp=11.231, rec=0.053, cos=0.000), tot_loss_proj:2.387 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.301 (perp=11.231, rec=0.055, cos=0.000), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.296 (perp=11.231, rec=0.050, cos=0.000), tot_loss_proj:2.400 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.308 (perp=11.231, rec=0.061, cos=0.000), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.304 (perp=11.231, rec=0.058, cos=0.000), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.310 (perp=11.231, rec=0.064, cos=0.000), tot_loss_proj:2.385 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.297 (perp=11.231, rec=0.051, cos=0.000), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.304 (perp=11.231, rec=0.058, cos=0.000), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.300 (perp=11.231, rec=0.054, cos=0.000), tot_loss_proj:2.384 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.303 (perp=11.231, rec=0.057, cos=0.000), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.313 (perp=11.231, rec=0.067, cos=0.000), tot_loss_proj:2.385 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.299 (perp=11.231, rec=0.053, cos=0.000), tot_loss_proj:2.401 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.307 (perp=11.231, rec=0.061, cos=0.000), tot_loss_proj:2.386 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.361 | p: 92.852 | r: 94.014
rouge2     | fm: 67.292 | p: 67.039 | r: 67.546
rougeL     | fm: 82.033 | p: 81.583 | r: 82.553
rougeLsum  | fm: 81.822 | p: 81.322 | r: 82.353
r1fm+r2fm = 160.653

input #33 time: 0:11:07 | total time: 5:44:00


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
*********************************
*********************************
average of cosine similarity 0.9992095874336102
highest_index [0]
highest [0.9992095874336102]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8934751749038696 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8867652416229248 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8387898802757263 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8131259679794312 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8121541142463684 for ['[CLS]ibe lissa founder statue slight alongask who drivers okay worth ship field [SEP]']
[Init] best perm rec loss: 0.8113055229187012 for ['[CLS] drivers slight founder okay field ship lissaask whoibe along worth statue [SEP]']
[Init] best perm rec loss: 0.8105695843696594 for ['[CLS] founder who statue slight worth along field lissa okayibe shipask drivers [SEP]']
[Init] best perm rec loss: 0.809282660484314 for ['[CLS]ask who drivers okay founder along field lissa ship slight statue worthibe [SEP]']
[Init] best perm rec loss: 0.808682918548584 for ['[CLS]ibe founder lissa drivers fieldask okay who statue worth slight ship along [SEP]']
[Init] best perm rec loss: 0.8075406551361084 for ['[CLS] field along lissa okay worth whoask statue drivers founder slight shipibe [SEP]']
[Init] best perm rec loss: 0.8066137433052063 for ['[CLS] ship slight who statue fieldask along okay worth founderibe drivers lissa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.430, rec=0.384, cos=0.000), tot_loss_proj:3.024 [t=0.25s]
prediction: ['[CLS] pendant story. alex power cedar. greater urgency artistic energy urgent and [SEP]']
[ 100/2000] tot_loss=2.680 (perp=12.110, rec=0.258, cos=0.000), tot_loss_proj:4.027 [t=0.27s]
prediction: ['[CLS] pendant viewer. anna force viewer. extreme urgencyurrent become urgency and [SEP]']
[ 150/2000] tot_loss=2.228 (perp=10.174, rec=0.194, cos=0.000), tot_loss_proj:2.939 [t=0.27s]
prediction: ['[CLS] build viewer. takes keep viewer and extreme urgency extreme take urgency. [SEP]']
[ 200/2000] tot_loss=2.090 (perp=9.625, rec=0.165, cos=0.000), tot_loss_proj:3.011 [t=0.27s]
prediction: ['[CLS] build viewer. the mind viewer and extreme urgency extreme take urgency. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.874 (perp=8.743, rec=0.125, cos=0.000), tot_loss_proj:2.704 [t=0.27s]
prediction: ['[CLS] build viewer build viewer in mind and extreme urgency extreme take extreme. [SEP]']
[ 300/2000] tot_loss=1.888 (perp=8.743, rec=0.139, cos=0.000), tot_loss_proj:2.704 [t=0.26s]
prediction: ['[CLS] build viewer build viewer in mind and extreme urgency extreme take extreme. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.729 (perp=8.146, rec=0.099, cos=0.000), tot_loss_proj:2.403 [t=0.27s]
prediction: ['[CLS] build viewer build viewers in mind and extreme urgency take on extreme. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.679 (perp=7.899, rec=0.099, cos=0.000), tot_loss_proj:2.368 [t=0.25s]
prediction: ['[CLS] build viewer build viewer in mind and extreme urgency take on extreme. [SEP]']
[ 450/2000] tot_loss=1.709 (perp=8.115, rec=0.086, cos=0.000), tot_loss_proj:2.456 [t=0.27s]
prediction: ['[CLS] build viewer build of in mind and extreme urgency take on extreme. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.546 (perp=7.318, rec=0.082, cos=0.000), tot_loss_proj:2.212 [t=0.26s]
prediction: ['[CLS] build build of viewer in mind and extreme urgency take on extreme. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.494 (perp=7.020, rec=0.090, cos=0.000), tot_loss_proj:2.403 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[ 600/2000] tot_loss=1.481 (perp=7.020, rec=0.077, cos=0.000), tot_loss_proj:2.408 [t=0.28s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.487 (perp=7.020, rec=0.083, cos=0.000), tot_loss_proj:2.407 [t=0.29s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.486 (perp=7.020, rec=0.082, cos=0.000), tot_loss_proj:2.408 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[ 750/2000] tot_loss=1.484 (perp=7.020, rec=0.080, cos=0.000), tot_loss_proj:2.410 [t=0.29s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.480 (perp=7.020, rec=0.076, cos=0.000), tot_loss_proj:2.412 [t=0.28s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.477 (perp=7.020, rec=0.073, cos=0.000), tot_loss_proj:2.410 [t=0.28s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[ 900/2000] tot_loss=1.475 (perp=7.020, rec=0.071, cos=0.000), tot_loss_proj:2.414 [t=0.29s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.481 (perp=7.020, rec=0.077, cos=0.000), tot_loss_proj:2.418 [t=0.28s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.474 (perp=7.020, rec=0.070, cos=0.000), tot_loss_proj:2.416 [t=0.30s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1050/2000] tot_loss=1.478 (perp=7.020, rec=0.074, cos=0.000), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.483 (perp=7.020, rec=0.079, cos=0.000), tot_loss_proj:2.413 [t=0.28s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.461 (perp=7.020, rec=0.057, cos=0.000), tot_loss_proj:2.416 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1200/2000] tot_loss=1.480 (perp=7.020, rec=0.076, cos=0.000), tot_loss_proj:2.418 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.472 (perp=7.020, rec=0.068, cos=0.000), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.476 (perp=7.020, rec=0.072, cos=0.000), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.020, rec=0.084, cos=0.000), tot_loss_proj:2.425 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.466 (perp=7.020, rec=0.062, cos=0.000), tot_loss_proj:2.422 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.479 (perp=7.020, rec=0.075, cos=0.000), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1500/2000] tot_loss=1.478 (perp=7.020, rec=0.074, cos=0.000), tot_loss_proj:2.416 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.480 (perp=7.020, rec=0.076, cos=0.000), tot_loss_proj:2.422 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.473 (perp=7.020, rec=0.068, cos=0.000), tot_loss_proj:2.422 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1650/2000] tot_loss=1.474 (perp=7.020, rec=0.070, cos=0.000), tot_loss_proj:2.423 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.471 (perp=7.020, rec=0.067, cos=0.000), tot_loss_proj:2.424 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.473 (perp=7.020, rec=0.069, cos=0.000), tot_loss_proj:2.426 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1800/2000] tot_loss=1.473 (perp=7.020, rec=0.069, cos=0.000), tot_loss_proj:2.424 [t=0.26s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.475 (perp=7.020, rec=0.071, cos=0.000), tot_loss_proj:2.421 [t=0.28s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.478 (perp=7.020, rec=0.074, cos=0.000), tot_loss_proj:2.420 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
[1950/2000] tot_loss=1.480 (perp=7.020, rec=0.076, cos=0.000), tot_loss_proj:2.426 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.481 (perp=7.020, rec=0.077, cos=0.000), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build build of viewer urgency in mind and extreme take on extreme. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 23.077 | p: 23.077 | r: 23.077
rougeL     | fm: 64.286 | p: 64.286 | r: 64.286
rougeLsum  | fm: 64.286 | p: 64.286 | r: 64.286
r1fm+r2fm = 108.791

[Aggregate metrics]:
rouge1     | fm: 93.146 | p: 92.598 | r: 93.744
rouge2     | fm: 66.110 | p: 65.844 | r: 66.381
rougeL     | fm: 81.479 | p: 81.029 | r: 81.993
rougeLsum  | fm: 81.192 | p: 80.817 | r: 81.768
r1fm+r2fm = 159.255

input #34 time: 0:11:13 | total time: 5:55:14


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
*********************************
*********************************
average of cosine similarity 0.9993288613758544
highest_index [0]
highest [0.9993288613758544]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9245964884757996 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9230044484138489 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9209198355674744 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9203950762748718 for ['[CLS], part isabella published lynch one denied folk sleeper beautyght ms nightmares energy province actdrive zionvil appointment fade thousand singer deservesar pages signs somehow intervals dynamic alternative primary sole device flow fae lack field position organizeddran outside [SEP]']
[Init] best perm rec loss: 0.9178836345672607 for ['[CLS] sleeper, flow intervals isabella appointmentdran singer publishedvil deserve province zionsar outside position act dynamic organized part sole beauty folk fae device primary nightmares alternative lack lynch signs field somehowght ms denied thousand fade energy pages onedrive [SEP]']
[Init] best perm rec loss: 0.9175959825515747 for ['[CLS] singer energy act organized lynch position intervals somehow device fade zion alternative, provinceght pages isabella outside primarydrive sleeper published deserve flow part sole denied appointment thousandsar field ms nightmares signs faevil folk one dynamic beauty lackdran [SEP]']
[Init] best perm rec loss: 0.915134847164154 for ['[CLS] isabellavil signs lynch sole deservesar somehow lack intervalsdrive sleeperdran province energy zion field nightmares organized dynamic part thousand outside alternative pages flow, singer ms device fade one denied position published primary act fae beauty appointment folkght [SEP]']
[Init] best perm rec loss: 0.9148914217948914 for ['[CLS] denied thousand flow outside alternative province lynchght isabella part sole organized folk position field ms device signs dynamic primary deserve nightmares sleepervil act, faesar zion beauty somehow appointment singer energydrive intervalsdran published pages fade one lack [SEP]']
[Init] best perm rec loss: 0.9135206341743469 for ['[CLS] publisheddrive deserve intervals singer ms field zion one nightmaresdran energy sole sleeper isabella somehow act outside organized denied beauty lynch flow provincesar, alternativeght device lack fade signs appointment part dynamic position thousandvil pages folk fae primary [SEP]']
[Init] best perm rec loss: 0.9134281873703003 for ['[CLS] signs nightmares appointment one thousand denieddran province beauty sole alternative energy dynamic fae somehow flow zion part organized sleeper published lynch lack singer intervalsght device ms, pagesdrive deservevil folk primary fade actsar isabella position field outside [SEP]']
[Init] best perm rec loss: 0.9117394685745239 for ['[CLS] position signs deservesar nightmares sleeper singer folk device somehow field, isabella flow fade lynch province one ms energy appointmentght alternative denied intervals act primary dynamicvil fae published lackdrive sole thousand beauty outside zion part pages organizeddran [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.726 (perp=11.438, rec=0.438, cos=0.000), tot_loss_proj:2.975 [t=0.27s]
prediction: ['[CLS] churchill international guggenheimischen beautiful musical producer john history special and, romantic around theeu young thompson young [SEP] christopher beyond produced special medieval journey of dynamic hunter also personal touch success the through role outside consuming sights for wonderful stadium [SEP]']
[ 100/2000] tot_loss=2.883 (perp=12.752, rec=0.332, cos=0.000), tot_loss_proj:3.663 [t=0.28s]
prediction: ['[CLS] played athena beyondischen amazing₃ care john namesake collector but, romantic ( the theo beautiful anderson young. leo theylves following medieval daughter with classical before visual withished fortune the among championship from over blockedka wonderful most [SEP]']
[ 150/2000] tot_loss=2.677 (perp=11.925, rec=0.292, cos=0.000), tot_loss_proj:3.856 [t=0.28s]
prediction: ["[CLS] starred scala damienism amazing australian care we introduced we but, travel rec aum beautiful they young of'just makes some historically daughter asgraphic before [ with of fortune the through championship where over blocked world outstanding most [SEP]"]
[ 200/2000] tot_loss=2.551 (perp=11.439, rec=0.264, cos=0.000), tot_loss_proj:3.948 [t=0.27s]
prediction: ["[CLS] helped scala originally before amazing australian care we teacher we but, final ; 'de superb directors young.'seen makes before historically grandson asgraphic about [ with of before the.nation,nation blocked before outstanding most [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.327 (perp=10.461, rec=0.235, cos=0.000), tot_loss_proj:3.910 [t=0.28s]
prediction: ["[CLS] helped whose'beforenation australian care we teacher we but but of ; 'degraphic director young.'seen makes before historically grandson ( your about about seen of before the wenation ofnation ga before outstanding most [SEP]"]
[ 300/2000] tot_loss=2.595 (perp=10.120, rec=0.571, cos=0.000), tot_loss_proj:3.587 [t=0.27s]
prediction: ["[CLS] seen actually'before lover this care of teacher them and but islamic ; ', foreign carter new and've made before works assists'reactor new juliana seen ofr declan we circle of social hidden before powerful plants [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.433 (perp=10.033, rec=0.426, cos=0.000), tot_loss_proj:3.623 [t=0.29s]
prediction: ["[CLS] equipped actually'before human of care of professor them and but islamic ;'of foreign carter made before studies points, build new does'since new talking seen of experience declan you tesla of social agent'successful plants [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.416 (perp=10.162, rec=0.383, cos=0.000), tot_loss_proj:3.862 [t=0.30s]
prediction: ["[CLS] equipped actually'before does the care of professor them and but islamic ;'of foreign carter made before of points seeing multiplayer new human'von new talking seen of everyday declan you tesla of of agent company unique plants [SEP]"]
[ 450/2000] tot_loss=2.376 (perp=10.155, rec=0.345, cos=0.000), tot_loss_proj:3.851 [t=0.29s]
prediction: ["[CLS] equipped actually'before does the care of teacher them and but military!'of foreign carter made before of points seeing multiplayer new human'since new talking seen of everyday sergei youvinsky of of agent company unique plants [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.297 (perp=9.914, rec=0.314, cos=0.000), tot_loss_proj:3.676 [t=0.30s]
prediction: ["[CLS] seen actually'before does the care of teacher them of but military ;'of foreign carter made regular of points coast multiplayer new human'since of talking seen of everyday sergei youvinsky of first squad company unique plants [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.459 (perp=10.530, rec=0.353, cos=0.000), tot_loss_proj:3.838 [t=0.30s]
prediction: ["[CLS] equipped actually'beforedo every care of teacher but of them economic ;'of foreign carter made previously about points'multiplayer new human streets since ofmates seen of everyday sergei youvinsky of first squad company unique plants [SEP]"]
[ 600/2000] tot_loss=2.228 (perp=9.551, rec=0.318, cos=0.000), tot_loss_proj:3.534 [t=0.28s]
prediction: ["[CLS] seen actually'before that every care of teacher but of them economic ;'of foreign carter made previously about points'site new human streets since ofmates seen of everyday sergei youvinsky of first squad company unique plants [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=2.245 (perp=9.745, rec=0.296, cos=0.000), tot_loss_proj:3.591 [t=0.28s]
prediction: ["[CLS] seen actually'before that themselves care of teacher but of them economic ;'of foreign carter made previously about points'convention new human bu since of youmates seen of everyday sergeivinsky of first squad company unique plants [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.192 (perp=9.534, rec=0.286, cos=0.000), tot_loss_proj:3.478 [t=0.29s]
prediction: ["[CLS] seen actually'before that themselves care of teacher but of them military ;'of foreign carter made previously about points'of new human bu since of youmates seen of everyday sergeivinsky site first squad company unique plants [SEP]"]
[ 750/2000] tot_loss=2.295 (perp=9.871, rec=0.321, cos=0.000), tot_loss_proj:3.460 [t=0.30s]
prediction: ["[CLS] seen originally'beforenes much care of teacher but of them military ;'of foreign carter made previously about points'of new human bu since of youmates seen of everyday sergeivinsky director first squad company unique plants [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.167 (perp=9.374, rec=0.292, cos=0.000), tot_loss_proj:3.585 [t=0.30s]
prediction: ["[CLS] seen originally'beforenes much care of teacher but of them military ;'of foreign carter made previously about points'of school human johnnie since of youmates seen'ever sergeivinsky director first squad of unique plants [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=2.165 (perp=9.435, rec=0.278, cos=0.000), tot_loss_proj:3.688 [t=0.30s]
prediction: ["[CLS] seen actually'beforenes total care of teacher but of them islamic ;'of foreign carter makes previously about points'of school human johnnie of youmates seen characters ever since sergeivinsky director first squad of unique walls [SEP]"]
[ 900/2000] tot_loss=2.237 (perp=9.820, rec=0.273, cos=0.000), tot_loss_proj:3.784 [t=0.29s]
prediction: ["[CLS] seen originally'beforenesdrop care of teacher but of them islamic ;'of foreign carter makes previously about points'of school human johnnie of youmates seen characters ever since sergeination director first squad of unique walls [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.186 (perp=9.633, rec=0.260, cos=0.000), tot_loss_proj:3.756 [t=0.29s]
prediction: ["[CLS] seen originally'beforenesdrop care of teacher but of them military ;'of foreign carter makes previously about points'of school human johnnie of youmates seen walls ever since sergeination director first squad of unique characters [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.179 (perp=9.621, rec=0.255, cos=0.000), tot_loss_proj:3.641 [t=0.30s]
prediction: ["[CLS] seen originally'beforenesdrop care of teacher but of us walls,'of foreign carter makes previously about points'of friends human johnnie of youmates seen military ever since sergeination director first squad of unique characters [SEP]"]
[1050/2000] tot_loss=2.224 (perp=9.819, rec=0.260, cos=0.000), tot_loss_proj:3.730 [t=0.30s]
prediction: ["[CLS] seen originally'beforenesdrop care of teacher but of us walls,'of foreign carter makes previously about points'ofrization human johnnie of youmates seen sri ever since sergeination director first squad of unique characters [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.155 (perp=9.538, rec=0.247, cos=0.000), tot_loss_proj:3.690 [t=0.30s]
prediction: ["[CLS] seen originally'beforenesdrop care of teacher but of us walls,'of foreign carter makes previously about points'ofrization human johnnie of youmates seennation ever since sergei islamic director first squad of unique characters [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.137 (perp=9.451, rec=0.247, cos=0.000), tot_loss_proj:3.631 [t=0.29s]
prediction: ["[CLS] seen originally'beforenesdrop care of walls but of us teacher,'of foreign carter makes previously about points'ofrization human johnnie of youmates seennation ever since sergei islamic director first squad of unique characters [SEP]"]
[1200/2000] tot_loss=2.219 (perp=9.819, rec=0.255, cos=0.000), tot_loss_proj:3.651 [t=0.30s]
prediction: ["[CLS] seen started'beforenes shane care of walls but of us teacher,'of foreign carter makes previously about points'ofrization human johnnie of youmates seennation ever since sergei economic director first squad of unique characters [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.123 (perp=9.306, rec=0.262, cos=0.000), tot_loss_proj:3.605 [t=0.30s]
prediction: ["[CLS] seen started'beforenes you care of walls but of us teacher,'of foreign carter makes previously about points'ofrization human johnnie of shanemates seennation ever since sergei economic director first squad of unique characters [SEP]"]
Attempt swap
[1300/2000] tot_loss=2.117 (perp=9.306, rec=0.256, cos=0.000), tot_loss_proj:3.602 [t=0.30s]
prediction: ["[CLS] seen started'beforenes you care of walls but of us teacher,'of foreign carter makes previously about points'ofrization human johnnie of shanemates seennation ever since sergei economic director first squad of unique characters [SEP]"]
[1350/2000] tot_loss=2.109 (perp=9.306, rec=0.248, cos=0.000), tot_loss_proj:3.603 [t=0.31s]
prediction: ["[CLS] seen started'beforenes you care of walls but of us teacher,'of foreign carter makes previously about points'ofrization human johnnie of shanemates seennation ever since sergei economic director first squad of unique characters [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.043 (perp=8.920, rec=0.259, cos=0.000), tot_loss_proj:3.603 [t=0.30s]
prediction: ["[CLS] seen started'beforenes you care of walls but of usnation,'of foreign carter makes more about points'ofrization human johnnie ofkindmates seen teacher ever since sergei economic director first squad of unique'[SEP]"]
Attempt swap
[1450/2000] tot_loss=2.054 (perp=9.011, rec=0.252, cos=0.000), tot_loss_proj:3.631 [t=0.30s]
prediction: ["[CLS] seen started'beforenes you care of plants but of usnation,'of foreign carter makes more about points'ofrization human johnnie ofkindmates seen teacher ever since sergei economic director first squad of unique'[SEP]"]
[1500/2000] tot_loss=2.045 (perp=9.011, rec=0.243, cos=0.000), tot_loss_proj:3.632 [t=0.30s]
prediction: ["[CLS] seen started'beforenes you care of plants but of usnation,'of foreign carter makes more about points'ofrization human johnnie ofkindmates seen teacher ever since sergei economic director first squad of unique'[SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.235 (perp=9.944, rec=0.246, cos=0.000), tot_loss_proj:3.851 [t=0.31s]
prediction: ["[CLS] seen officially'before title you care of plants but of usnation,'of foreign carter makes more scientology'' ofrization human johnnie ofkindmates seen teacher multiple since sergei economic director first squad of unique points [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=2.214 (perp=9.831, rec=0.248, cos=0.000), tot_loss_proj:3.703 [t=0.31s]
prediction: ["[CLS] seen officially'before title you care of plants but of usnation,'of foreign carter makes more scientology'' ofrization human johnnie ofkindmates seen since teacher multiple sergei economic director first squad of unique points [SEP]"]
[1650/2000] tot_loss=2.214 (perp=9.831, rec=0.248, cos=0.000), tot_loss_proj:3.702 [t=0.30s]
prediction: ["[CLS] seen officially'before title you care of plants but of usnation,'of foreign carter makes more scientology'' ofrization human johnnie ofkindmates seen since teacher multiple sergei economic director first squad of unique points [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.180 (perp=9.678, rec=0.245, cos=0.000), tot_loss_proj:3.594 [t=0.30s]
prediction: ["[CLS] seen officially'before title you care of plants but of us sergei,'of foreign carter makes more scientology'' ofrization human johnnie ofkindmates seen since teacher multiplenation economic director first squad of unique points [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.154 (perp=9.558, rec=0.242, cos=0.000), tot_loss_proj:3.601 [t=0.32s]
prediction: ["[CLS] seen officially'before title you care of plants but of us sergei,'of foreign carter makes more scientology'of of disabilities human johnnie 'kindmates seen since teacher multiplenation economic director first squad of unique points [SEP]"]
[1800/2000] tot_loss=2.153 (perp=9.558, rec=0.241, cos=0.000), tot_loss_proj:3.603 [t=0.30s]
prediction: ["[CLS] seen officially'before title you care of plants but of us sergei,'of foreign carter makes more scientology'of of disabilities human johnnie 'kindmates seen since teacher multiplenation economic director first squad of unique points [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=2.103 (perp=9.268, rec=0.249, cos=0.000), tot_loss_proj:3.547 [t=0.30s]
prediction: ["[CLS] seen officially'before title you care of plants but of us sergei,'of foreign carter makes more scientology'of disabilities human of johnnie 'kindmates seen since teacher multiplenation economic director first agent of unique points [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.113 (perp=9.340, rec=0.246, cos=0.000), tot_loss_proj:3.577 [t=0.31s]
prediction: ["[CLS] seen officially'before title you care of plants but of us sergei,'of foreign carter makes more scientology human of disabilities'of johnnie 'kindmates seen since teacher multiplenation economic director first agent of unique points [SEP]"]
[1950/2000] tot_loss=2.102 (perp=9.298, rec=0.243, cos=0.000), tot_loss_proj:3.568 [t=0.26s]
prediction: ["[CLS] seen officially'before title you care of plants but of us sergei,'of foreign carter makes more scientology human of cease'of johnnie 'kindmates seen since teacher multiplenation economic director first agent of unique points [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.097 (perp=9.209, rec=0.255, cos=0.000), tot_loss_proj:3.499 [t=0.27s]
prediction: ["[CLS] seen officially'before title seen care of plants but of us sergei,'of foreign carter makes more scientology human of cease'of johnnie 'kindmates you since teacher multiplenation economic director first agent of unique points [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] help whose'beforenation education care we teacher us but but one director 'de excellent director '.'ve makes before historically grandson'your all about seen about before the wenation.nation ga before outstanding we [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.571 | p: 48.571 | r: 48.571
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 22.857 | p: 22.857 | r: 22.857
rougeLsum  | fm: 22.857 | p: 22.857 | r: 22.857
r1fm+r2fm = 48.571

[Aggregate metrics]:
rouge1     | fm: 91.853 | p: 91.434 | r: 92.464
rouge2     | fm: 64.063 | p: 63.795 | r: 64.391
rougeL     | fm: 79.787 | p: 79.329 | r: 80.233
rougeLsum  | fm: 79.561 | p: 79.114 | r: 80.163
r1fm+r2fm = 155.916

input #35 time: 0:11:38 | total time: 6:06:53


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
*********************************
*********************************
average of cosine similarity 0.9992848878121703
highest_index [0]
highest [0.9992848878121703]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9965106844902039 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9938651323318481 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9531474709510803 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9292848706245422 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9227098822593689 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.91852205991745 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8277139067649841 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8250531554222107 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 0.8241528868675232 for ['[CLS] harassment bates ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.822794497013092 for ['[CLS] ramsey harassment bates cornelius [SEP]']
[Init] best perm rec loss: 0.8227003812789917 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8196044564247131 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.180 (perp=9.448, rec=0.291, cos=0.000), tot_loss_proj:2.627 [t=0.27s]
prediction: ['[CLS] horribly wrong wrong wrong [SEP]']
[ 100/2000] tot_loss=1.897 (perp=8.845, rec=0.128, cos=0.000), tot_loss_proj:2.131 [t=0.25s]
prediction: ['[CLS] horribly wrong horribly wrong [SEP]']
[ 150/2000] tot_loss=2.173 (perp=10.398, rec=0.094, cos=0.000), tot_loss_proj:2.563 [t=0.27s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 200/2000] tot_loss=2.160 (perp=10.398, rec=0.081, cos=0.000), tot_loss_proj:2.562 [t=0.26s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.857 (perp=8.830, rec=0.091, cos=0.000), tot_loss_proj:2.044 [t=0.29s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.839 (perp=8.830, rec=0.073, cos=0.000), tot_loss_proj:2.047 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.832 (perp=8.830, rec=0.066, cos=0.000), tot_loss_proj:2.044 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.828 (perp=8.830, rec=0.062, cos=0.000), tot_loss_proj:2.041 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=1.827 (perp=8.830, rec=0.061, cos=0.000), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.834 (perp=8.830, rec=0.068, cos=0.000), tot_loss_proj:2.042 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.834 (perp=8.830, rec=0.068, cos=0.000), tot_loss_proj:2.039 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 600/2000] tot_loss=1.831 (perp=8.830, rec=0.065, cos=0.000), tot_loss_proj:2.042 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.839 (perp=8.830, rec=0.073, cos=0.000), tot_loss_proj:2.039 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.842 (perp=8.830, rec=0.076, cos=0.000), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 750/2000] tot_loss=1.824 (perp=8.830, rec=0.058, cos=0.000), tot_loss_proj:2.044 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.835 (perp=8.830, rec=0.069, cos=0.000), tot_loss_proj:2.042 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.841 (perp=8.830, rec=0.075, cos=0.000), tot_loss_proj:2.056 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 900/2000] tot_loss=1.850 (perp=8.830, rec=0.085, cos=0.000), tot_loss_proj:2.050 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.830, rec=0.056, cos=0.000), tot_loss_proj:2.048 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1000/2000] tot_loss=1.827 (perp=8.830, rec=0.061, cos=0.000), tot_loss_proj:2.032 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1050/2000] tot_loss=1.845 (perp=8.830, rec=0.079, cos=0.000), tot_loss_proj:2.045 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1100/2000] tot_loss=1.841 (perp=8.830, rec=0.075, cos=0.000), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1150/2000] tot_loss=1.839 (perp=8.830, rec=0.073, cos=0.000), tot_loss_proj:2.044 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1200/2000] tot_loss=1.823 (perp=8.830, rec=0.057, cos=0.000), tot_loss_proj:2.047 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1250/2000] tot_loss=1.830 (perp=8.830, rec=0.064, cos=0.000), tot_loss_proj:2.035 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1300/2000] tot_loss=1.838 (perp=8.830, rec=0.072, cos=0.000), tot_loss_proj:2.046 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1350/2000] tot_loss=1.828 (perp=8.830, rec=0.062, cos=0.000), tot_loss_proj:2.044 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1400/2000] tot_loss=1.852 (perp=8.830, rec=0.086, cos=0.000), tot_loss_proj:2.047 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1450/2000] tot_loss=1.828 (perp=8.830, rec=0.062, cos=0.000), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1500/2000] tot_loss=1.827 (perp=8.830, rec=0.061, cos=0.000), tot_loss_proj:2.045 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1550/2000] tot_loss=1.833 (perp=8.830, rec=0.067, cos=0.000), tot_loss_proj:2.044 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1600/2000] tot_loss=1.845 (perp=8.830, rec=0.079, cos=0.000), tot_loss_proj:2.045 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1650/2000] tot_loss=1.836 (perp=8.830, rec=0.070, cos=0.000), tot_loss_proj:2.047 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1700/2000] tot_loss=1.831 (perp=8.830, rec=0.065, cos=0.000), tot_loss_proj:2.033 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1750/2000] tot_loss=1.839 (perp=8.830, rec=0.073, cos=0.000), tot_loss_proj:2.040 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1800/2000] tot_loss=1.827 (perp=8.830, rec=0.061, cos=0.000), tot_loss_proj:2.051 [t=0.29s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1850/2000] tot_loss=1.839 (perp=8.830, rec=0.073, cos=0.000), tot_loss_proj:2.037 [t=0.28s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.830, rec=0.069, cos=0.000), tot_loss_proj:2.044 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[1950/2000] tot_loss=1.837 (perp=8.830, rec=0.071, cos=0.000), tot_loss_proj:2.043 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[2000/2000] tot_loss=1.816 (perp=8.830, rec=0.050, cos=0.000), tot_loss_proj:2.034 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s wrong horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 66.667 | p: 60.000 | r: 75.000
rougeL     | fm: 90.909 | p: 83.333 | r: 100.000
rougeLsum  | fm: 90.909 | p: 83.333 | r: 100.000
r1fm+r2fm = 157.576

[Aggregate metrics]:
rouge1     | fm: 91.874 | p: 91.143 | r: 92.731
rouge2     | fm: 64.106 | p: 63.714 | r: 64.643
rougeL     | fm: 80.158 | p: 79.600 | r: 80.898
rougeLsum  | fm: 79.977 | p: 79.408 | r: 80.685
r1fm+r2fm = 155.980

input #36 time: 0:11:09 | total time: 6:18:02


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
*********************************
*********************************
average of cosine similarity 0.9993681286555303
highest_index [0]
highest [0.9993681286555303]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9651467204093933 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9522649049758911 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8846222758293152 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.8049560189247131 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7965478301048279 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7804299592971802 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7524718046188354 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7465671896934509 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7185426950454712 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.6988452076911926 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6844379305839539 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.671655535697937 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.644182562828064 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.64206463098526 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.590 (perp=10.991, rec=0.392, cos=0.000), tot_loss_proj:2.966 [t=0.27s]
prediction: ['[CLS] eccentric cbs [SEP]']
[ 100/2000] tot_loss=2.097 (perp=9.583, rec=0.180, cos=0.000), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=2.054 (perp=9.583, rec=0.138, cos=0.000), tot_loss_proj:2.016 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.989 (perp=9.583, rec=0.073, cos=0.000), tot_loss_proj:2.003 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.985 (perp=9.583, rec=0.068, cos=0.000), tot_loss_proj:1.999 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.981 (perp=9.583, rec=0.064, cos=0.000), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.988 (perp=9.583, rec=0.072, cos=0.000), tot_loss_proj:2.000 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.973 (perp=9.583, rec=0.056, cos=0.000), tot_loss_proj:1.993 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.975 (perp=9.583, rec=0.059, cos=0.000), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.990 (perp=9.583, rec=0.074, cos=0.000), tot_loss_proj:2.004 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.982 (perp=9.583, rec=0.065, cos=0.000), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.978 (perp=9.583, rec=0.062, cos=0.000), tot_loss_proj:1.995 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.989 (perp=9.583, rec=0.072, cos=0.000), tot_loss_proj:2.002 [t=0.28s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=9.583, rec=0.052, cos=0.000), tot_loss_proj:1.999 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.975 (perp=9.583, rec=0.059, cos=0.000), tot_loss_proj:2.000 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.995 (perp=9.583, rec=0.078, cos=0.000), tot_loss_proj:1.995 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.980 (perp=9.583, rec=0.063, cos=0.000), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.987 (perp=9.583, rec=0.070, cos=0.000), tot_loss_proj:2.004 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.978 (perp=9.583, rec=0.061, cos=0.000), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.971 (perp=9.583, rec=0.054, cos=0.000), tot_loss_proj:2.000 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.966 (perp=9.583, rec=0.050, cos=0.000), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.978 (perp=9.583, rec=0.062, cos=0.000), tot_loss_proj:2.003 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.971 (perp=9.583, rec=0.054, cos=0.000), tot_loss_proj:2.005 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.965 (perp=9.583, rec=0.049, cos=0.000), tot_loss_proj:2.005 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.978 (perp=9.583, rec=0.061, cos=0.000), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.980 (perp=9.583, rec=0.064, cos=0.000), tot_loss_proj:1.989 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.973 (perp=9.583, rec=0.056, cos=0.000), tot_loss_proj:2.001 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.974 (perp=9.583, rec=0.057, cos=0.000), tot_loss_proj:2.007 [t=0.28s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.968 (perp=9.583, rec=0.052, cos=0.000), tot_loss_proj:2.003 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.978 (perp=9.583, rec=0.062, cos=0.000), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.980 (perp=9.583, rec=0.063, cos=0.000), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.973 (perp=9.583, rec=0.056, cos=0.000), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.977 (perp=9.583, rec=0.061, cos=0.000), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.971 (perp=9.583, rec=0.054, cos=0.000), tot_loss_proj:2.007 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.970 (perp=9.583, rec=0.053, cos=0.000), tot_loss_proj:1.993 [t=0.28s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.980 (perp=9.583, rec=0.063, cos=0.000), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.980 (perp=9.583, rec=0.063, cos=0.000), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.976 (perp=9.583, rec=0.059, cos=0.000), tot_loss_proj:1.996 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.984 (perp=9.583, rec=0.067, cos=0.000), tot_loss_proj:1.999 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.972 (perp=9.583, rec=0.056, cos=0.000), tot_loss_proj:1.997 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.021 | p: 91.380 | r: 92.825
rouge2     | fm: 64.834 | p: 64.421 | r: 65.357
rougeL     | fm: 80.724 | p: 80.124 | r: 81.417
rougeLsum  | fm: 80.460 | p: 79.984 | r: 81.141
r1fm+r2fm = 156.855

input #37 time: 0:11:07 | total time: 6:29:10


Running input #38 of 100.
reference: 
========================
scare 
========================
*********************************
*********************************
average of cosine similarity 0.9992658416777674
highest_index [0]
highest [0.9992658416777674]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8038928508758545 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.7725152969360352 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7171775102615356 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6799152493476868 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6252588629722595 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.994 (perp=14.070, rec=0.180, cos=0.000), tot_loss_proj:2.966 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.906 (perp=14.070, rec=0.092, cos=0.000), tot_loss_proj:2.877 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.873 (perp=14.070, rec=0.059, cos=0.000), tot_loss_proj:2.876 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.881 (perp=14.070, rec=0.067, cos=0.000), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.875 (perp=14.070, rec=0.061, cos=0.000), tot_loss_proj:2.869 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.880 (perp=14.070, rec=0.066, cos=0.000), tot_loss_proj:2.883 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.881 (perp=14.070, rec=0.067, cos=0.000), tot_loss_proj:2.869 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.864 (perp=14.070, rec=0.050, cos=0.000), tot_loss_proj:2.861 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.871 (perp=14.070, rec=0.057, cos=0.000), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.877 (perp=14.070, rec=0.063, cos=0.000), tot_loss_proj:2.867 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.874 (perp=14.070, rec=0.060, cos=0.000), tot_loss_proj:2.863 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.869 (perp=14.070, rec=0.055, cos=0.000), tot_loss_proj:2.876 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.865 (perp=14.070, rec=0.050, cos=0.000), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.871 (perp=14.070, rec=0.057, cos=0.000), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.874 (perp=14.070, rec=0.060, cos=0.000), tot_loss_proj:2.867 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.881 (perp=14.070, rec=0.067, cos=0.000), tot_loss_proj:2.863 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.885 (perp=14.070, rec=0.070, cos=0.000), tot_loss_proj:2.865 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.889 (perp=14.070, rec=0.075, cos=0.000), tot_loss_proj:2.874 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.876 (perp=14.070, rec=0.062, cos=0.000), tot_loss_proj:2.861 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.872 (perp=14.070, rec=0.058, cos=0.000), tot_loss_proj:2.866 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.862 (perp=14.070, rec=0.048, cos=0.000), tot_loss_proj:2.872 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.865 (perp=14.070, rec=0.051, cos=0.000), tot_loss_proj:2.871 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.879 (perp=14.070, rec=0.065, cos=0.000), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.866 (perp=14.070, rec=0.052, cos=0.000), tot_loss_proj:2.875 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.883 (perp=14.070, rec=0.069, cos=0.000), tot_loss_proj:2.883 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.881 (perp=14.070, rec=0.067, cos=0.000), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.875 (perp=14.070, rec=0.061, cos=0.000), tot_loss_proj:2.871 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.870 (perp=14.070, rec=0.056, cos=0.000), tot_loss_proj:2.872 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.870 (perp=14.070, rec=0.056, cos=0.000), tot_loss_proj:2.882 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.866 (perp=14.070, rec=0.052, cos=0.000), tot_loss_proj:2.876 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.879 (perp=14.070, rec=0.064, cos=0.000), tot_loss_proj:2.870 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.868 (perp=14.070, rec=0.054, cos=0.000), tot_loss_proj:2.865 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.866 (perp=14.070, rec=0.052, cos=0.000), tot_loss_proj:2.885 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.885 (perp=14.070, rec=0.071, cos=0.000), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.882 (perp=14.070, rec=0.068, cos=0.000), tot_loss_proj:2.879 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.870 (perp=14.070, rec=0.056, cos=0.000), tot_loss_proj:2.865 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.861 (perp=14.070, rec=0.047, cos=0.000), tot_loss_proj:2.870 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.881 (perp=14.070, rec=0.067, cos=0.000), tot_loss_proj:2.864 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.875 (perp=14.070, rec=0.061, cos=0.000), tot_loss_proj:2.876 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.869 (perp=14.070, rec=0.055, cos=0.000), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.326 | p: 91.665 | r: 93.068
rouge2     | fm: 65.909 | p: 65.451 | r: 66.443
rougeL     | fm: 81.195 | p: 80.629 | r: 81.846
rougeLsum  | fm: 81.290 | p: 80.705 | r: 81.942
r1fm+r2fm = 158.235

input #38 time: 0:11:08 | total time: 6:40:19


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
*********************************
*********************************
average of cosine similarity 0.9992524905646034
highest_index [0]
highest [0.9992524905646034]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.009259581565857 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0036354064941406 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9888045787811279 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9337722659111023 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9266416430473328 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9256927967071533 for ['[CLS] pressed score limiting value blinking walkerson hitch micro mouths inside pockets... : international darby mclaren trace lightec madman formation inquiry end soul [SEP]']
[Init] best rec loss: 0.9185788035392761 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9078559875488281 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9041820168495178 for ['[CLS]ney eventhypher gordon lab main happened wash townpet hurt south be cassidy etc positiontive then sometimes sail jury inwindowa [SEP]']
[Init] best perm rec loss: 0.9033174514770508 for ['[CLS] position lab washpet main thenney south event etcwind sail cassidy in hurt towntive jury happenedpherhy be gordonowa sometimes [SEP]']
[Init] best perm rec loss: 0.9023675322532654 for ['[CLS]ney event inowative main townwind gordon be jurypher south cassidypethy lab etc then sail position hurt sometimes wash happened [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.804 (perp=12.098, rec=0.384, cos=0.000), tot_loss_proj:3.136 [t=0.28s]
prediction: ['[CLS] roles structure underneath explain revealed empathy drama until softness future magnum inspiration strong learning joan michael mal moore new new night! romantic in new [SEP]']
[ 100/2000] tot_loss=2.513 (perp=11.198, rec=0.273, cos=0.000), tot_loss_proj:3.863 [t=0.28s]
prediction: ['[CLS] roles texture underneath conservative gave assumptions holdings and was new got vogue conservative reality, michael conservative moore from new - movie boom film new [SEP]']
[ 150/2000] tot_loss=2.351 (perp=10.621, rec=0.226, cos=0.000), tot_loss_proj:3.403 [t=0.28s]
prediction: ['[CLS] finds texture underneath conservative gave hidebound and, new got vogue conservative reality, movie conservative moore the most - moviesily film new [SEP]']
[ 200/2000] tot_loss=2.273 (perp=10.353, rec=0.203, cos=0.000), tot_loss_proj:3.305 [t=0.27s]
prediction: ['[CLS] finds texture tradition conservative gave hidebound and, new, vogue conservative texture, moviebound traditions ; most - moviesily film new [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.893 (perp=8.552, rec=0.183, cos=0.000), tot_loss_proj:3.134 [t=0.27s]
prediction: ['[CLS] finds texture tradition conservative gave hidebound and, new, ponytail - texture, moviebound traditions, most conservative movie movie film new [SEP]']
[ 300/2000] tot_loss=1.853 (perp=8.530, rec=0.147, cos=0.000), tot_loss_proj:2.713 [t=0.28s]
prediction: ['[CLS] finds texture traditions conservative gave hidebound and, new, traditions - texture, moviebound traditions, most new movie movie film new [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.810 (perp=8.392, rec=0.132, cos=0.000), tot_loss_proj:2.789 [t=0.26s]
prediction: ['[CLS] finds new traditions conservative gives hidebound and hence texture, reality - texture - moviebound traditions, most new movie movie. new [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.956 (perp=8.642, rec=0.227, cos=0.000), tot_loss_proj:2.918 [t=0.28s]
prediction: ['[CLS] finds new traditions conservative gives hidebound and index texture, new - texture his moviebound new characters, our new movie movie films [SEP]']
[ 450/2000] tot_loss=1.838 (perp=8.382, rec=0.161, cos=0.000), tot_loss_proj:2.465 [t=0.28s]
prediction: ['[CLS] finds new traditions conservative gives hidebound and highest texture, new and texture it moviebound new characters, our new movie movie movie [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.747 (perp=8.043, rec=0.138, cos=0.000), tot_loss_proj:2.529 [t=0.27s]
prediction: ['[CLS] finds new traditions conservative gives hidebound andbound, new texture and texture it moviebound new texture, our new movie movie movie [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.873 (perp=8.676, rec=0.138, cos=0.000), tot_loss_proj:2.763 [t=0.28s]
prediction: ['[CLS] finds new traditions conservative gives hidebound andbound, new texture most texture it moviebound new texture, our new movie movie movie [SEP]']
[ 600/2000] tot_loss=1.845 (perp=8.676, rec=0.110, cos=0.000), tot_loss_proj:2.757 [t=0.26s]
prediction: ['[CLS] finds new traditions conservative gives hidebound andbound, new texture most texture it moviebound new texture, our new movie movie movie [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.767 (perp=8.287, rec=0.109, cos=0.000), tot_loss_proj:2.677 [t=0.26s]
prediction: ['[CLS] finds new traditions and conservative gives hideboundbound, new texture most texture it moviebound new texture, our new movie movie movie [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.794 (perp=8.386, rec=0.117, cos=0.000), tot_loss_proj:2.573 [t=0.26s]
prediction: ['[CLS] finds new traditions and conservative gives hideboundbound, new texture most texture itbound new texture, our new movie making movie movie [SEP]']
[ 750/2000] tot_loss=1.784 (perp=8.418, rec=0.100, cos=0.000), tot_loss_proj:2.480 [t=0.27s]
prediction: ['[CLS] finds new traditions and conservative gives hidebound most, new texture most texture itbound new texture, our new movie making movie movie [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.689 (perp=7.891, rec=0.111, cos=0.000), tot_loss_proj:2.352 [t=0.28s]
prediction: ['[CLS] finds new traditions and conservative gives hidebound most new texture, most texture itbound new texture, our new movie making movie movie [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.642 (perp=7.681, rec=0.106, cos=0.000), tot_loss_proj:2.432 [t=0.27s]
prediction: ['[CLS] finds new traditions and conservative gives hidebound most texture, most texture itbound new texture, our new movie making new movie movie [SEP]']
[ 900/2000] tot_loss=1.684 (perp=7.912, rec=0.102, cos=0.000), tot_loss_proj:2.375 [t=0.27s]
prediction: ['[CLS] finds new traditions and conservative gives hidebound most relevance, most texture itbound new texture, our new movie making new movie movie [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.732 (perp=8.205, rec=0.091, cos=0.000), tot_loss_proj:2.647 [t=0.27s]
prediction: ['[CLS] finds reality traditions and conservative gives hidebound most texture, and texture itbound new texture, our new movie making new movie movie [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.678 (perp=7.905, rec=0.097, cos=0.000), tot_loss_proj:2.512 [t=0.27s]
prediction: ['[CLS] finds reality traditions and conservative gives hidebound most texture, and itbound new texture texture, our new movie making new movie movie [SEP]']
[1050/2000] tot_loss=1.720 (perp=8.089, rec=0.102, cos=0.000), tot_loss_proj:2.531 [t=0.27s]
prediction: ['[CLS] finds reality traditions and conservative gives hidebound most texture, and itbound new texture relevance, our new movie making new movie movie [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.665 (perp=7.885, rec=0.088, cos=0.000), tot_loss_proj:2.314 [t=0.28s]
prediction: ['[CLS] finds conservative traditions and reality gives hidebound most texture, and itbound new texture relevance, our new movie making new movie movie [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.655 (perp=7.836, rec=0.088, cos=0.000), tot_loss_proj:2.254 [t=0.29s]
prediction: ['[CLS] finds conservative traditions and reality gives hidebound most texture, and itbound new relevance texture, our new movie making new movie movie [SEP]']
[1200/2000] tot_loss=1.664 (perp=7.836, rec=0.097, cos=0.000), tot_loss_proj:2.262 [t=0.28s]
prediction: ['[CLS] finds conservative traditions and reality gives hidebound most texture, and itbound new relevance texture, our new movie making new movie movie [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.642 (perp=7.745, rec=0.093, cos=0.000), tot_loss_proj:2.331 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and itbound new relevance texture, our new movie making new movie movie [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.586 (perp=7.499, rec=0.087, cos=0.000), tot_loss_proj:2.195 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.499, rec=0.087, cos=0.000), tot_loss_proj:2.191 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
[1400/2000] tot_loss=1.580 (perp=7.499, rec=0.080, cos=0.000), tot_loss_proj:2.189 [t=0.28s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
[1450/2000] tot_loss=1.587 (perp=7.499, rec=0.087, cos=0.000), tot_loss_proj:2.190 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
[1500/2000] tot_loss=1.586 (perp=7.499, rec=0.086, cos=0.000), tot_loss_proj:2.189 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
[1550/2000] tot_loss=1.582 (perp=7.499, rec=0.082, cos=0.000), tot_loss_proj:2.188 [t=0.26s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.588 (perp=7.499, rec=0.088, cos=0.000), tot_loss_proj:2.189 [t=0.28s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
[1650/2000] tot_loss=1.590 (perp=7.499, rec=0.090, cos=0.000), tot_loss_proj:2.190 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.499, rec=0.096, cos=0.000), tot_loss_proj:2.190 [t=0.28s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.499, rec=0.083, cos=0.000), tot_loss_proj:2.191 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
[1800/2000] tot_loss=1.585 (perp=7.499, rec=0.085, cos=0.000), tot_loss_proj:2.190 [t=0.28s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture, and it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.590 (perp=7.481, rec=0.094, cos=0.000), tot_loss_proj:2.194 [t=0.26s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture and, it texturebound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.560 (perp=7.371, rec=0.086, cos=0.000), tot_loss_proj:2.252 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture and texture, itbound new relevance, our new movie making new movie movie [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.371, rec=0.091, cos=0.000), tot_loss_proj:2.252 [t=0.26s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture and texture, itbound new relevance, our new movie making new movie movie [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.556 (perp=7.343, rec=0.087, cos=0.000), tot_loss_proj:2.256 [t=0.27s]
prediction: ['[CLS] conservative finds traditions and reality gives hidebound most texture and texture, itbound new relevance, our new movie movie new movie making [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] conservative finds traditions and reality gives hidebound most texture and texture, itbound new relevance, our new movie making new movie movie [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 82.609 | r: 86.364
rouge2     | fm: 13.953 | p: 13.636 | r: 14.286
rougeL     | fm: 44.444 | p: 43.478 | r: 45.455
rougeLsum  | fm: 44.444 | p: 43.478 | r: 45.455
r1fm+r2fm = 98.398

[Aggregate metrics]:
rouge1     | fm: 92.111 | p: 91.415 | r: 92.953
rouge2     | fm: 64.617 | p: 64.240 | r: 65.073
rougeL     | fm: 80.447 | p: 79.787 | r: 81.163
rougeLsum  | fm: 80.074 | p: 79.515 | r: 80.768
r1fm+r2fm = 156.728

input #39 time: 0:11:19 | total time: 6:51:38


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
*********************************
*********************************
average of cosine similarity 0.9993179101577563
highest_index [0]
highest [0.9993179101577563]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9929419755935669 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9581857919692993 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9360306262969971 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.9324253797531128 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9271036386489868 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9193928837776184 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9033973217010498 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8470988869667053 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8442991375923157 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8434320688247681 for ['[CLS] georgian already kent abd but deciding lady° many [SEP]']
[Init] best perm rec loss: 0.8420918583869934 for ['[CLS] kent georgian deciding but° already abd many lady [SEP]']
[Init] best perm rec loss: 0.8414740562438965 for ['[CLS] kent abd many georgian but lady° deciding already [SEP]']
[Init] best perm rec loss: 0.8401283025741577 for ['[CLS] many deciding° already kent but abd lady georgian [SEP]']
[Init] best perm rec loss: 0.8394578099250793 for ['[CLS]° lady kent georgian deciding but already abd many [SEP]']
[Init] best perm rec loss: 0.8391994833946228 for ['[CLS] kent° georgian but abd already lady deciding many [SEP]']
[Init] best perm rec loss: 0.8386645317077637 for ['[CLS] lady already kent° deciding but many georgian abd [SEP]']
[Init] best perm rec loss: 0.8364506363868713 for ['[CLS] deciding° but lady already kent georgian abd many [SEP]']
[Init] best perm rec loss: 0.8344376087188721 for ['[CLS] many but lady kent deciding° already abd georgian [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.666 (perp=11.844, rec=0.297, cos=0.000), tot_loss_proj:3.539 [t=0.26s]
prediction: ['[CLS] college exhibits prefecture phone video artworkmmel usony [SEP]']
[ 100/2000] tot_loss=2.714 (perp=12.783, rec=0.157, cos=0.000), tot_loss_proj:3.394 [t=0.25s]
prediction: ['[CLS] bleeding withony pu imagery ormmel usony [SEP]']
[ 150/2000] tot_loss=2.781 (perp=13.417, rec=0.098, cos=0.000), tot_loss_proj:3.269 [t=0.26s]
prediction: ['[CLS] bleeding withony pu imagery phmmel usony [SEP]']
[ 200/2000] tot_loss=2.622 (perp=12.678, rec=0.087, cos=0.000), tot_loss_proj:3.082 [t=0.27s]
prediction: ['[CLS] pu withony pu imagery phmmel usony [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.183 (perp=10.426, rec=0.098, cos=0.000), tot_loss_proj:2.590 [t=0.27s]
prediction: ['[CLS] pu with puony imagery phmmel usony [SEP]']
[ 300/2000] tot_loss=2.118 (perp=10.206, rec=0.076, cos=0.000), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS] pu with puony imagery phmmel us imagery [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.213 (perp=10.622, rec=0.088, cos=0.000), tot_loss_proj:2.954 [t=0.25s]
prediction: ['[CLS] pu with orony imagery pummel us imagery [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.115 (perp=10.136, rec=0.088, cos=0.000), tot_loss_proj:2.968 [t=0.26s]
prediction: ['[CLS] or with insaneony music pummel us imagery [SEP]']
[ 450/2000] tot_loss=2.117 (perp=10.136, rec=0.090, cos=0.000), tot_loss_proj:2.972 [t=0.26s]
prediction: ['[CLS] or with insaneony music pummel us imagery [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.669 (perp=7.879, rec=0.093, cos=0.000), tot_loss_proj:2.934 [t=0.27s]
prediction: ['[CLS] orony music pummel us with insane imagery [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.706 (perp=7.714, rec=0.163, cos=0.000), tot_loss_proj:2.761 [t=0.26s]
prediction: ['[CLS]ony or music pummel us with crazy imagery [SEP]']
[ 600/2000] tot_loss=1.660 (perp=7.714, rec=0.117, cos=0.000), tot_loss_proj:2.851 [t=0.27s]
prediction: ['[CLS]ony or music pummel us with crazy imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.647 (perp=7.714, rec=0.105, cos=0.000), tot_loss_proj:2.852 [t=0.27s]
prediction: ['[CLS]ony or music pummel us with crazy imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.644 (perp=7.714, rec=0.102, cos=0.000), tot_loss_proj:2.848 [t=0.27s]
prediction: ['[CLS]ony or music pummel us with crazy imagery [SEP]']
[ 750/2000] tot_loss=1.899 (perp=8.972, rec=0.105, cos=0.000), tot_loss_proj:3.067 [t=0.26s]
prediction: ['[CLS]ony or music pummel us withroud imagery [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.800 (perp=8.550, rec=0.090, cos=0.000), tot_loss_proj:3.337 [t=0.26s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.808 (perp=8.550, rec=0.098, cos=0.000), tot_loss_proj:3.326 [t=0.27s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
[ 900/2000] tot_loss=1.804 (perp=8.550, rec=0.094, cos=0.000), tot_loss_proj:3.323 [t=0.27s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.800 (perp=8.550, rec=0.090, cos=0.000), tot_loss_proj:3.319 [t=0.25s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=8.550, rec=0.086, cos=0.000), tot_loss_proj:3.319 [t=0.25s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
[1050/2000] tot_loss=1.799 (perp=8.550, rec=0.089, cos=0.000), tot_loss_proj:3.318 [t=0.26s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.798 (perp=8.550, rec=0.088, cos=0.000), tot_loss_proj:3.314 [t=0.27s]
prediction: ['[CLS]ony or music pummelroud us with imagery [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.854 (perp=8.783, rec=0.098, cos=0.000), tot_loss_proj:3.291 [t=0.26s]
prediction: ['[CLS] music pummelony or pagan us with imagery [SEP]']
[1200/2000] tot_loss=1.742 (perp=8.273, rec=0.088, cos=0.000), tot_loss_proj:3.545 [t=0.26s]
prediction: ['[CLS] music pummelony or bowl us with imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.734 (perp=8.273, rec=0.080, cos=0.000), tot_loss_proj:3.541 [t=0.25s]
prediction: ['[CLS] music pummelony or bowl us with imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.736 (perp=8.273, rec=0.081, cos=0.000), tot_loss_proj:3.551 [t=0.27s]
prediction: ['[CLS] music pummelony or bowl us with imagery [SEP]']
[1350/2000] tot_loss=1.736 (perp=8.273, rec=0.081, cos=0.000), tot_loss_proj:3.551 [t=0.26s]
prediction: ['[CLS] music pummelony or bowl us with imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.787 (perp=8.540, rec=0.079, cos=0.000), tot_loss_proj:3.515 [t=0.27s]
prediction: ['[CLS] music pummelony or ph us with imagery [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.558 (perp=7.355, rec=0.087, cos=0.000), tot_loss_proj:2.063 [t=0.27s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.355, rec=0.083, cos=0.000), tot_loss_proj:2.070 [t=0.27s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.550 (perp=7.355, rec=0.079, cos=0.000), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.553 (perp=7.355, rec=0.082, cos=0.000), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[1650/2000] tot_loss=1.548 (perp=7.355, rec=0.077, cos=0.000), tot_loss_proj:2.078 [t=0.27s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.556 (perp=7.355, rec=0.085, cos=0.000), tot_loss_proj:2.076 [t=0.27s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.552 (perp=7.355, rec=0.081, cos=0.000), tot_loss_proj:2.071 [t=0.26s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[1800/2000] tot_loss=1.553 (perp=7.355, rec=0.082, cos=0.000), tot_loss_proj:2.078 [t=0.28s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.548 (perp=7.355, rec=0.077, cos=0.000), tot_loss_proj:2.081 [t=0.26s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.541 (perp=7.355, rec=0.070, cos=0.000), tot_loss_proj:2.073 [t=0.27s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[1950/2000] tot_loss=1.562 (perp=7.355, rec=0.091, cos=0.000), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.544 (perp=7.355, rec=0.073, cos=0.000), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] music pummel us or phony with imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 112.500

[Aggregate metrics]:
rouge1     | fm: 92.294 | p: 91.569 | r: 93.053
rouge2     | fm: 63.234 | p: 62.842 | r: 63.685
rougeL     | fm: 79.984 | p: 79.328 | r: 80.646
rougeLsum  | fm: 79.745 | p: 79.170 | r: 80.412
r1fm+r2fm = 155.528

input #40 time: 0:11:08 | total time: 7:02:47


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
*********************************
*********************************
average of cosine similarity 0.9993037303121441
highest_index [0]
highest [0.9993037303121441]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9765738248825073 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9476155042648315 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9412702918052673 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9319030046463013 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.925689697265625 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.9252750873565674 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9234011769294739 for ['[CLS] style tomorrow [SEP]']
[Init] best rec loss: 0.9051069617271423 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8952760100364685 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8565412759780884 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8269596695899963 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8254073858261108 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.164 (perp=10.212, rec=0.121, cos=0.000), tot_loss_proj:2.117 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.104 (perp=10.212, rec=0.062, cos=0.000), tot_loss_proj:2.104 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.000), tot_loss_proj:2.109 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.107 (perp=10.212, rec=0.064, cos=0.000), tot_loss_proj:2.098 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.102 (perp=10.212, rec=0.060, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.102 (perp=10.212, rec=0.060, cos=0.000), tot_loss_proj:2.098 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.099 (perp=10.212, rec=0.057, cos=0.000), tot_loss_proj:2.101 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.000), tot_loss_proj:2.108 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.095 (perp=10.212, rec=0.053, cos=0.000), tot_loss_proj:2.107 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.100 (perp=10.212, rec=0.058, cos=0.000), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.101 (perp=10.212, rec=0.059, cos=0.000), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.099 (perp=10.212, rec=0.057, cos=0.000), tot_loss_proj:2.103 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.105 (perp=10.212, rec=0.063, cos=0.000), tot_loss_proj:2.112 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.099 (perp=10.212, rec=0.057, cos=0.000), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.090 (perp=10.212, rec=0.048, cos=0.000), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.103 (perp=10.212, rec=0.061, cos=0.000), tot_loss_proj:2.098 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.103 (perp=10.212, rec=0.061, cos=0.000), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.000), tot_loss_proj:2.103 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.108 (perp=10.212, rec=0.066, cos=0.000), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.111 (perp=10.212, rec=0.069, cos=0.000), tot_loss_proj:2.101 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.107 (perp=10.212, rec=0.065, cos=0.000), tot_loss_proj:2.109 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.087 (perp=10.212, rec=0.045, cos=0.000), tot_loss_proj:2.110 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.107 (perp=10.212, rec=0.065, cos=0.000), tot_loss_proj:2.105 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.106 (perp=10.212, rec=0.064, cos=0.000), tot_loss_proj:2.107 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.097 (perp=10.212, rec=0.054, cos=0.000), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.092 (perp=10.212, rec=0.050, cos=0.000), tot_loss_proj:2.105 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.113 (perp=10.212, rec=0.071, cos=0.000), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.108 (perp=10.212, rec=0.066, cos=0.000), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.105 (perp=10.212, rec=0.063, cos=0.000), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.100 (perp=10.212, rec=0.058, cos=0.000), tot_loss_proj:2.099 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.101 (perp=10.212, rec=0.058, cos=0.000), tot_loss_proj:2.116 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.114 (perp=10.212, rec=0.072, cos=0.000), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.103 (perp=10.212, rec=0.061, cos=0.000), tot_loss_proj:2.103 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.108 (perp=10.212, rec=0.065, cos=0.000), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.111 (perp=10.212, rec=0.069, cos=0.000), tot_loss_proj:2.108 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.106 (perp=10.212, rec=0.063, cos=0.000), tot_loss_proj:2.115 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.099 (perp=10.212, rec=0.056, cos=0.000), tot_loss_proj:2.097 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.108 (perp=10.212, rec=0.065, cos=0.000), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.106 (perp=10.212, rec=0.064, cos=0.000), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.110 (perp=10.212, rec=0.068, cos=0.000), tot_loss_proj:2.109 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.517 | p: 91.859 | r: 93.228
rouge2     | fm: 64.168 | p: 63.799 | r: 64.588
rougeL     | fm: 80.429 | p: 79.886 | r: 81.123
rougeLsum  | fm: 80.316 | p: 79.887 | r: 80.902
r1fm+r2fm = 156.685

input #41 time: 0:11:17 | total time: 7:14:05


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
*********************************
*********************************
average of cosine similarity 0.9993259393872982
highest_index [0]
highest [0.9993259393872982]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9050977230072021 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8550873398780823 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8506534099578857 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8179433345794678 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7971985936164856 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7963161468505859 for ['[CLS] enough dare wishbe offended ever cut lifted treaty mapletaking superseded bandapling assignmentctric stages kitchengible largerrs internationalures scale ran attracted [SEP]']
[Init] best perm rec loss: 0.7939856648445129 for ['[CLS]ures enough treaty wish dare larger kitchen attracted international scaletaking assignment ran superseded offendedbe maplers evergiblepling lifted cutctric stages banda [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.895 (perp=12.549, rec=0.385, cos=0.000), tot_loss_proj:3.153 [t=0.28s]
prediction: ["[CLS] poorly garbage gang less forgot least police obscure bus german government'transitized poorlyno drug wiring iraqi vendors victim drug truck stool against massacre [SEP]"]
[ 100/2000] tot_loss=2.678 (perp=11.970, rec=0.284, cos=0.000), tot_loss_proj:2.995 [t=0.27s]
prediction: ["[CLS] poorly garbage monster media forgot any police neither bathroom red not'ticket instead poorlyno chinese phone franchise called victim iphone hatch quota stage manson [SEP]"]
[ 150/2000] tot_loss=2.619 (perp=11.886, rec=0.242, cos=0.000), tot_loss_proj:3.108 [t=0.27s]
prediction: ["[CLS] poorly help beautiful they forgot anying well bathroom data anyone'ticket as poorly. re organization franchiseites victims iphone door barracks. fetal [SEP]"]
[ 200/2000] tot_loss=2.479 (perp=11.401, rec=0.198, cos=0.000), tot_loss_proj:2.859 [t=0.26s]
prediction: ["[CLS] poorly stand project they forgot to to well bathroom data nothing'ticket as poorly. re wiring franchise into victimsad door school. footage [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.218 (perp=10.167, rec=0.185, cos=0.000), tot_loss_proj:2.651 [t=0.27s]
prediction: ["[CLS] poorly amendment project they forgot to a well consul data anything'any as poorly. re roosevelt franchise into victims iphone to school. footage [SEP]"]
[ 300/2000] tot_loss=2.303 (perp=10.713, rec=0.161, cos=0.000), tot_loss_proj:2.733 [t=0.27s]
prediction: ['[CLS] poorlygger project they forgot to a even goethe re anythingville anything as poorly. re roosevelt attraction into victimz to school. setting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.226 (perp=10.386, rec=0.149, cos=0.000), tot_loss_proj:2.609 [t=0.27s]
prediction: ['[CLS] poorlygger project they forgot to a even scary re anythinggger anything as poorly re roosevelt attraction into off. death to school. setting [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.245 (perp=10.530, rec=0.139, cos=0.000), tot_loss_proj:2.666 [t=0.27s]
prediction: ['[CLS] poorlygger project they forgot significantly to a scary ha anythinggger scary as poorly regger attraction into off. death to school. setting [SEP]']
[ 450/2000] tot_loss=2.186 (perp=10.259, rec=0.134, cos=0.000), tot_loss_proj:2.712 [t=0.28s]
prediction: ['[CLS] poorlygger project they forgot significantly include a scary re anythinggger scary as poorly regger attraction into off. death to school. setting [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.114 (perp=9.947, rec=0.125, cos=0.000), tot_loss_proj:2.593 [t=0.28s]
prediction: ['[CLS] poorlygger project they forgot even include a scary re anythinggger scary as poorly regger attraction into off. death a school setting. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.199 (perp=10.407, rec=0.117, cos=0.000), tot_loss_proj:3.101 [t=0.28s]
prediction: ['[CLS] poorlygger project they forgot even include a scary films anythinggger scary as poorly regger attraction into off death. a school setting high [SEP]']
[ 600/2000] tot_loss=2.195 (perp=10.428, rec=0.109, cos=0.000), tot_loss_proj:3.091 [t=0.28s]
prediction: ['[CLS] poorlygger project they forgot even include a scary films anythinggger scary as poorlyjigger attraction into off death. a school setting high [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.146 (perp=10.158, rec=0.115, cos=0.000), tot_loss_proj:2.637 [t=0.27s]
prediction: ['[CLS] poorlygger project they forgot even include a scary films anythinggger scary as poorlyjigger attraction into high off death. a school setting [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.068 (perp=9.784, rec=0.111, cos=0.000), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] poorlygger project they forgot even include a scary films they anything scary as poorlyji fatal attraction into high off death. a school setting [SEP]']
[ 750/2000] tot_loss=2.125 (perp=10.090, rec=0.107, cos=0.000), tot_loss_proj:2.638 [t=0.22s]
prediction: ['[CLS] poorlygger project filmmakers forgot even include a scary films they anything scary as poorlyji fatal attraction into high off death. a school setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.043 (perp=9.653, rec=0.112, cos=0.000), tot_loss_proj:2.572 [t=0.27s]
prediction: ['[CLS] poorlygger project they forgot they include a scary films even anything scary as poorlyji fatal attraction into high off death. a school setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.997 (perp=9.428, rec=0.111, cos=0.000), tot_loss_proj:2.606 [t=0.27s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary films even anything scary as poorlyji fatal attraction into high off death. a school setting [SEP]']
[ 900/2000] tot_loss=1.993 (perp=9.428, rec=0.107, cos=0.000), tot_loss_proj:2.601 [t=0.27s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary films even anything scary as poorlyji fatal attraction into high off death. a school setting [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.959 (perp=9.298, rec=0.099, cos=0.000), tot_loss_proj:2.611 [t=0.26s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary films even anything scary as poorlyji off death fatal attraction into high. a school setting [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.891 (perp=8.975, rec=0.096, cos=0.000), tot_loss_proj:2.492 [t=0.26s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary films even anything scary as poorlyji off death fatal attraction into high setting a school. [SEP]']
[1050/2000] tot_loss=1.894 (perp=8.975, rec=0.099, cos=0.000), tot_loss_proj:2.490 [t=0.28s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary films even anything scary as poorlyji off death fatal attraction into high setting a school. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.829 (perp=8.648, rec=0.100, cos=0.000), tot_loss_proj:2.348 [t=0.27s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary films even anything scary as poorlyji off death fatal attraction into high school a setting. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.856 (perp=8.754, rec=0.105, cos=0.000), tot_loss_proj:2.300 [t=0.28s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary anything even re scary as poorlyji off death fatal attraction into high school a setting. [SEP]']
[1200/2000] tot_loss=1.844 (perp=8.754, rec=0.093, cos=0.000), tot_loss_proj:2.306 [t=0.27s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary anything even re scary as poorlyji off death fatal attraction into high school a setting. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.848 (perp=8.763, rec=0.096, cos=0.000), tot_loss_proj:2.371 [t=0.27s]
prediction: ['[CLS] agger project filmmakers forgot they include poorly scary anything even re scary as poorlyji off death fatal attraction into high school setting a. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.771 (perp=8.395, rec=0.092, cos=0.000), tot_loss_proj:2.312 [t=0.29s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into high school setting a. [SEP]']
[1350/2000] tot_loss=1.777 (perp=8.395, rec=0.098, cos=0.000), tot_loss_proj:2.315 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into high school setting a. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.770 (perp=8.395, rec=0.091, cos=0.000), tot_loss_proj:2.311 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into high school setting a. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.804 (perp=8.577, rec=0.088, cos=0.000), tot_loss_proj:2.322 [t=0.27s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into to high school setting. [SEP]']
[1500/2000] tot_loss=1.692 (perp=7.993, rec=0.093, cos=0.000), tot_loss_proj:2.165 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.696 (perp=7.993, rec=0.097, cos=0.000), tot_loss_proj:2.165 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=7.993, rec=0.083, cos=0.000), tot_loss_proj:2.168 [t=0.27s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
[1650/2000] tot_loss=1.685 (perp=7.993, rec=0.086, cos=0.000), tot_loss_proj:2.174 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=7.993, rec=0.092, cos=0.000), tot_loss_proj:2.166 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.690 (perp=7.993, rec=0.091, cos=0.000), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
[1800/2000] tot_loss=1.692 (perp=7.993, rec=0.093, cos=0.000), tot_loss_proj:2.170 [t=0.29s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.689 (perp=7.993, rec=0.090, cos=0.000), tot_loss_proj:2.169 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.688 (perp=7.993, rec=0.089, cos=0.000), tot_loss_proj:2.173 [t=0.28s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
[1950/2000] tot_loss=1.674 (perp=7.993, rec=0.076, cos=0.000), tot_loss_proj:2.170 [t=0.27s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.684 (perp=7.993, rec=0.085, cos=0.000), tot_loss_proj:2.175 [t=0.26s]
prediction: ['[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] agger poorly project filmmakers forgot they include scary anything even re scary as poorlyji off death fatal attraction into a high school setting. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.551 | p: 76.000 | r: 79.167
rouge2     | fm: 42.553 | p: 41.667 | r: 43.478
rougeL     | fm: 69.388 | p: 68.000 | r: 70.833
rougeLsum  | fm: 69.388 | p: 68.000 | r: 70.833
r1fm+r2fm = 120.104

[Aggregate metrics]:
rouge1     | fm: 92.177 | p: 91.507 | r: 92.967
rouge2     | fm: 63.529 | p: 63.231 | r: 63.993
rougeL     | fm: 80.126 | p: 79.577 | r: 80.788
rougeLsum  | fm: 79.927 | p: 79.312 | r: 80.654
r1fm+r2fm = 155.707

input #42 time: 0:11:14 | total time: 7:25:19


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
*********************************
*********************************
average of cosine similarity 0.9992733684043211
highest_index [0]
highest [0.9992733684043211]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9608437418937683 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9222672581672668 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8934417366981506 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8700019717216492 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8576014637947083 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.8500288128852844 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8336692452430725 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7880537509918213 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7835390567779541 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7798994779586792 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 0.7791914939880371 for ['[CLS] council enrollment deserved oxidation [SEP]']
[Init] best perm rec loss: 0.7782258987426758 for ['[CLS] council oxidation enrollment deserved [SEP]']
[Init] best perm rec loss: 0.7781441807746887 for ['[CLS] oxidation council deserved enrollment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.060 (perp=13.657, rec=0.329, cos=0.000), tot_loss_proj:3.560 [t=0.27s]
prediction: ['[CLS] emptyacingereless [SEP]']
[ 100/2000] tot_loss=2.662 (perp=12.138, rec=0.234, cos=0.000), tot_loss_proj:3.231 [t=0.26s]
prediction: ['[CLS] emptyacingissistic [SEP]']
[ 150/2000] tot_loss=2.227 (perp=10.221, rec=0.183, cos=0.000), tot_loss_proj:3.120 [t=0.27s]
prediction: ['[CLS] off naissistic [SEP]']
[ 200/2000] tot_loss=1.148 (perp=5.048, rec=0.139, cos=0.000), tot_loss_proj:1.102 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.113 (perp=5.048, rec=0.103, cos=0.000), tot_loss_proj:1.097 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.084 (perp=5.048, rec=0.074, cos=0.000), tot_loss_proj:1.098 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.078 (perp=5.048, rec=0.068, cos=0.000), tot_loss_proj:1.099 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.075 (perp=5.048, rec=0.066, cos=0.000), tot_loss_proj:1.098 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.084 (perp=5.048, rec=0.074, cos=0.000), tot_loss_proj:1.099 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.083 (perp=5.048, rec=0.074, cos=0.000), tot_loss_proj:1.101 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.066 (perp=5.048, rec=0.057, cos=0.000), tot_loss_proj:1.096 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.073 (perp=5.048, rec=0.063, cos=0.000), tot_loss_proj:1.091 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.081 (perp=5.048, rec=0.071, cos=0.000), tot_loss_proj:1.097 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.078 (perp=5.048, rec=0.068, cos=0.000), tot_loss_proj:1.099 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.068 (perp=5.048, rec=0.058, cos=0.000), tot_loss_proj:1.096 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.066 (perp=5.048, rec=0.057, cos=0.000), tot_loss_proj:1.089 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.080 (perp=5.048, rec=0.070, cos=0.000), tot_loss_proj:1.089 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.071 (perp=5.048, rec=0.061, cos=0.000), tot_loss_proj:1.088 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.064 (perp=5.048, rec=0.054, cos=0.000), tot_loss_proj:1.092 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.074 (perp=5.048, rec=0.064, cos=0.000), tot_loss_proj:1.102 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.061 (perp=5.048, rec=0.052, cos=0.000), tot_loss_proj:1.081 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.068 (perp=5.048, rec=0.059, cos=0.000), tot_loss_proj:1.088 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.070 (perp=5.048, rec=0.060, cos=0.000), tot_loss_proj:1.084 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.073 (perp=5.048, rec=0.064, cos=0.000), tot_loss_proj:1.084 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.074 (perp=5.048, rec=0.064, cos=0.000), tot_loss_proj:1.091 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.065 (perp=5.048, rec=0.056, cos=0.000), tot_loss_proj:1.082 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.073 (perp=5.048, rec=0.064, cos=0.000), tot_loss_proj:1.085 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.072 (perp=5.048, rec=0.062, cos=0.000), tot_loss_proj:1.088 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.056 (perp=5.048, rec=0.046, cos=0.000), tot_loss_proj:1.097 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.062 (perp=5.048, rec=0.052, cos=0.000), tot_loss_proj:1.101 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.066 (perp=5.048, rec=0.056, cos=0.000), tot_loss_proj:1.092 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.077 (perp=5.048, rec=0.067, cos=0.000), tot_loss_proj:1.091 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.080 (perp=5.048, rec=0.070, cos=0.000), tot_loss_proj:1.093 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.071 (perp=5.048, rec=0.062, cos=0.000), tot_loss_proj:1.094 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.070 (perp=5.048, rec=0.061, cos=0.000), tot_loss_proj:1.096 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.075 (perp=5.048, rec=0.065, cos=0.000), tot_loss_proj:1.084 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.064 (perp=5.048, rec=0.055, cos=0.000), tot_loss_proj:1.087 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.073 (perp=5.048, rec=0.064, cos=0.000), tot_loss_proj:1.078 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.073 (perp=5.048, rec=0.064, cos=0.000), tot_loss_proj:1.092 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.080 (perp=5.048, rec=0.070, cos=0.000), tot_loss_proj:1.099 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.327 | p: 91.670 | r: 93.105
rouge2     | fm: 64.642 | p: 64.261 | r: 65.093
rougeL     | fm: 80.569 | p: 80.025 | r: 81.252
rougeLsum  | fm: 80.610 | p: 79.995 | r: 81.287
r1fm+r2fm = 156.969

input #43 time: 0:11:13 | total time: 7:36:32


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
*********************************
*********************************
average of cosine similarity 0.9992417740131494
highest_index [0]
highest [0.9992417740131494]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9832764267921448 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9583490490913391 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9306989312171936 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9303932189941406 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 0.9085362553596497 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.9080809354782104 for ['[CLS] contains co nation slave blue capacity settled comedy contestants rock hello brow illustrated ; landon raceway hee contact graphic formerly intent fatty ltd haleyhair dataosi s harbor [SEP]']
[Init] best perm rec loss: 0.9075305461883545 for ['[CLS] contact contestants intent nation raceway blue graphic rock settled haley hello containshair slave s formerly brow comedyosi landon ; harbor capacity ltd illustrated fatty hee data co [SEP]']
[Init] best perm rec loss: 0.90745609998703 for ['[CLS] rock intent contains slavehair sosi settled comedy hello illustrated fatty nation landon hee haley formerly co blue ; brow data ltd raceway capacity contestants harbor graphic contact [SEP]']
[Init] best perm rec loss: 0.906627357006073 for ['[CLS]hair formerly raceway comedy contact brow intent capacity nation illustrated hello fatty landon hee ; data harbor slave ltd sosi haley blue contestants co contains settled rock graphic [SEP]']
[Init] best perm rec loss: 0.9054799675941467 for ['[CLS] s comedy co raceway illustrated blue harborosi brow ; contestants intent hello contact contains data graphic settled formerlyhair ltd nation slave hee landon capacity rock haley fatty [SEP]']
[Init] best perm rec loss: 0.9043555855751038 for ['[CLS] contact brow co hello intent blueosi settledhair contestants slave fatty comedy contains graphic ; capacity rock data s haley ltd raceway landon hee illustrated formerly harbor nation [SEP]']
[Init] best perm rec loss: 0.901726484298706 for ['[CLS] fatty rock contestantshair blue intent nation slave illustrated hello harbor landon brow graphicosi capacity contact co raceway comedy data ltd settled contains haley formerly s hee ; [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.543 (perp=11.407, rec=0.261, cos=0.000), tot_loss_proj:3.075 [t=0.27s]
prediction: ['[CLS] decorative lost a britisheros term. tax dog lost hear photo show correction lost counting routine translation during -voking? the for justine lost revenge resembles ; [SEP]']
[ 100/2000] tot_loss=2.157 (perp=9.906, rec=0.176, cos=0.000), tot_loss_proj:2.556 [t=0.28s]
prediction: ['[CLS] archaic lost a german in translation. pay " lost translation hollywood routine slack lost the routine translation during -fest. the the fright slackcus ے between [SEP]']
[ 150/2000] tot_loss=2.314 (perp=10.893, rec=0.136, cos=0.000), tot_loss_proj:3.027 [t=0.28s]
prediction: ['[CLS] customs lost been another in translation. hollywood wagon lost another hollywood routine slack hereditary the routine translation slack -fest. the thealic slackizes ے between [SEP]']
[ 200/2000] tot_loss=2.166 (perp=10.223, rec=0.121, cos=0.000), tot_loss_proj:2.496 [t=0.28s]
prediction: ['[CLS] ridiculous lost been another in translation. hollywood execution has another hollywood routine slackalic the routine translation slack -fest. the thealic slackizes premise between [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.038 (perp=9.650, rec=0.108, cos=0.000), tot_loss_proj:2.390 [t=0.27s]
prediction: ['[CLS] ridiculous lost been another in the. hollywood execution has another hollywood routine thealic slack routine translation slack -fest. the thealic slackizes premise in [SEP]']
[ 300/2000] tot_loss=2.081 (perp=9.890, rec=0.103, cos=0.000), tot_loss_proj:2.455 [t=0.29s]
prediction: ['[CLS] absurd lost been another in the. hollywood execution has another hollywood routine thealicizes routine translation slack -fest. the thealic slackizes premise in [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.070 (perp=9.887, rec=0.092, cos=0.000), tot_loss_proj:2.491 [t=0.26s]
prediction: ['[CLS] absurd been another in the lost. hollywood execution has another hollywood routine thealicizes routine translation fright -fest. the thealic slackizes premise in [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.100 (perp=9.859, rec=0.129, cos=0.000), tot_loss_proj:2.507 [t=0.27s]
prediction: ['[CLS] absurd has another in the lost. hollywood execution. another where fright thealicizes routine - fright translationfest. the thealic slackizes premiseity [SEP]']
[ 450/2000] tot_loss=2.093 (perp=10.022, rec=0.088, cos=0.000), tot_loss_proj:2.536 [t=0.28s]
prediction: ['[CLS] absurd has another in the lost. hollywood execution. another which fright thealicizes routine - fright translationfest. the thealic slackizes premiseity [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.962 (perp=9.396, rec=0.083, cos=0.000), tot_loss_proj:2.494 [t=0.27s]
prediction: ['[CLS] premise has in in the lost. hollywood execution. another which fright thealicizes routine - fright translationfest. the thealic slackizes absurdity [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.888 (perp=9.054, rec=0.077, cos=0.000), tot_loss_proj:2.456 [t=0.28s]
prediction: ['[CLS] premise has in in the lost. hollywood execution. another which frightizes it the routine - fright translationfest. the thealic slackizes absurdity [SEP]']
[ 600/2000] tot_loss=1.898 (perp=9.054, rec=0.087, cos=0.000), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] premise has in in the lost. hollywood execution. another which frightizes it the routine - fright translationfest. the thealic slackizes absurdity [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.833 (perp=8.800, rec=0.073, cos=0.000), tot_loss_proj:2.338 [t=0.28s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightizes it the routine in fright translationfest. the thealic slackizes absurdity [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.795 (perp=8.593, rec=0.076, cos=0.000), tot_loss_proj:2.280 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightity it the routine in fright translation. the thealic slackfestizes absurdity [SEP]']
[ 750/2000] tot_loss=1.793 (perp=8.593, rec=0.074, cos=0.000), tot_loss_proj:2.278 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightity it the routine in fright translation. the thealic slackfestizes absurdity [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.769 (perp=8.485, rec=0.072, cos=0.000), tot_loss_proj:2.250 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightity it the routine in fright translation. the slackalic thefestizes absurdity [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.758 (perp=8.349, rec=0.089, cos=0.000), tot_loss_proj:2.245 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightity it the routine in fright translation. the slackalicizesfest the absurdity [SEP]']
[ 900/2000] tot_loss=1.736 (perp=8.349, rec=0.066, cos=0.000), tot_loss_proj:2.246 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightity it the routine in fright translation. the slackalicizesfest the absurdity [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.715 (perp=8.207, rec=0.073, cos=0.000), tot_loss_proj:2.232 [t=0.28s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightizes it the routine in fright translation. the slackalicityfest the absurdity [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.707 (perp=8.163, rec=0.074, cos=0.000), tot_loss_proj:2.269 [t=0.28s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightizes it the routine. in fright translation the slackalicityfest the absurdity [SEP]']
[1050/2000] tot_loss=1.698 (perp=8.163, rec=0.066, cos=0.000), tot_loss_proj:2.262 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which frightizes it the routine. in fright translation the slackalicityfest the absurdity [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.677 (perp=8.036, rec=0.070, cos=0.000), tot_loss_proj:2.228 [t=0.28s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which routineizes it the fright. in fright translation the slackalicityfest the absurdity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.680 (perp=8.036, rec=0.073, cos=0.000), tot_loss_proj:2.226 [t=0.28s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which routineizes it the fright. in fright translation the slackalicityfest the absurdity [SEP]']
[1200/2000] tot_loss=1.683 (perp=8.036, rec=0.076, cos=0.000), tot_loss_proj:2.224 [t=0.27s]
prediction: ['[CLS] premise has the in the lost. hollywood execution. another which routineizes it the fright. in fright translation the slackalicityfest the absurdity [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.665 (perp=7.900, rec=0.085, cos=0.000), tot_loss_proj:2.356 [t=0.27s]
prediction: ['[CLS] premise has the in execution the lost. hollywood. another which routineizes it the fright. in fright translation the slackalicityfest the absurdity [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.641 (perp=7.824, rec=0.077, cos=0.000), tot_loss_proj:2.474 [t=0.27s]
prediction: ['[CLS] premise has it in execution the lost. hollywood. another which routineizes the the fright. in fright translation the slackalicityfest the absurdity [SEP]']
[1350/2000] tot_loss=1.650 (perp=7.824, rec=0.085, cos=0.000), tot_loss_proj:2.476 [t=0.27s]
prediction: ['[CLS] premise has it in execution the lost. hollywood. another which routineizes the the fright. in fright translation the slackalicityfest the absurdity [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.630 (perp=7.802, rec=0.069, cos=0.000), tot_loss_proj:2.304 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which routineizes the the fright. in fright translation the slackalicityfest the absurdity [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.618 (perp=7.732, rec=0.072, cos=0.000), tot_loss_proj:2.246 [t=0.28s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which routineizes the the fright. in translation the slack frightalicityfest the absurdity [SEP]']
[1500/2000] tot_loss=1.619 (perp=7.732, rec=0.072, cos=0.000), tot_loss_proj:2.249 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which routineizes the the fright. in translation the slack frightalicityfest the absurdity [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.618 (perp=7.675, rec=0.083, cos=0.000), tot_loss_proj:2.214 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation the slack frightalicityfest the absurdity [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.599 (perp=7.641, rec=0.071, cos=0.000), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation slack the frightalicityfest the absurdity [SEP]']
[1650/2000] tot_loss=1.607 (perp=7.641, rec=0.079, cos=0.000), tot_loss_proj:2.239 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation slack the frightalicityfest the absurdity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.600 (perp=7.641, rec=0.072, cos=0.000), tot_loss_proj:2.246 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation slack the frightalicityfest the absurdity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.602 (perp=7.641, rec=0.074, cos=0.000), tot_loss_proj:2.234 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation slack the frightalicityfest the absurdity [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.641, rec=0.066, cos=0.000), tot_loss_proj:2.236 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation slack the frightalicityfest the absurdity [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.567 (perp=7.437, rec=0.079, cos=0.000), tot_loss_proj:2.201 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost. hollywood. another which the routineizes the frightfest. in translation slack the frightalicity the absurdity [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.555 (perp=7.391, rec=0.077, cos=0.000), tot_loss_proj:2.441 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost hollywood. another. which the routineizes the frightfest. in translation slack the frightalicity the absurdity [SEP]']
[1950/2000] tot_loss=1.560 (perp=7.391, rec=0.082, cos=0.000), tot_loss_proj:2.445 [t=0.27s]
prediction: ['[CLS] premise has it in the execution lost hollywood. another. which the routineizes the frightfest. in translation slack the frightalicity the absurdity [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.551 (perp=7.365, rec=0.078, cos=0.000), tot_loss_proj:2.168 [t=0.28s]
prediction: ['[CLS] premise has it in hollywood the execution lost. another. which the routineizes the frightfest. in translation slack the frightalicity the absurdity [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] premise has it in the execution lost. hollywood. another which the routineizes the fright. in translation slack the frightalicityfest the absurdity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 78.261 | r: 78.261
rouge2     | fm: 13.636 | p: 13.636 | r: 13.636
rougeL     | fm: 47.826 | p: 47.826 | r: 47.826
rougeLsum  | fm: 47.826 | p: 47.826 | r: 47.826
r1fm+r2fm = 91.897

[Aggregate metrics]:
rouge1     | fm: 92.010 | p: 91.457 | r: 92.748
rouge2     | fm: 63.257 | p: 62.867 | r: 63.626
rougeL     | fm: 79.828 | p: 79.238 | r: 80.485
rougeLsum  | fm: 79.707 | p: 79.109 | r: 80.360
r1fm+r2fm = 155.267

input #44 time: 0:11:16 | total time: 7:47:48


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
*********************************
*********************************
average of cosine similarity 0.9993985389127414
highest_index [0]
highest [0.9993985389127414]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9833581447601318 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9404494762420654 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9160202741622925 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9078320264816284 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.9062800407409668 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.9015963077545166 for ['[CLS] circussome nj lodge photoᅵ bioome kg morning. have interviewrcus account winfield letofan shy broken man floor sunday sack tuneenter station ll [SEP]']
[Init] best rec loss: 0.8669224381446838 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8654311895370483 for ['[CLS] enclosed bore entrance joan single ( ku operated special skin football tree2tiv few via gentry murmured v letter military five status whoa curtis taste aroundlanda [SEP]']
[Init] best perm rec loss: 0.8648079633712769 for ['[CLS] via special whoa few tree status single gentry football bore letter ku enclosed joanlanda entrance military skin murmured curtis ( five v around tastetiv operated2 [SEP]']
[Init] best perm rec loss: 0.8639764785766602 for ['[CLS] bore joan gentry enclosedlanda murmured ( around operated letter single v taste2 military curtis via five ku entrance whoa few tree special status football skintiv [SEP]']
[Init] best perm rec loss: 0.8631333708763123 for ['[CLS] tree joan ( enclosed letter entrance single operated around2 curtis few military whoa special football bore gentry tastetiv via v status murmuredlanda five ku skin [SEP]']
[Init] best perm rec loss: 0.8625210523605347 for ['[CLS] five military whoa taste entrance murmured gentry v status tree single specialtiv ku letterlanda curtis football around2 skin via few enclosed operated bore joan ( [SEP]']
[Init] best perm rec loss: 0.8622099161148071 for ['[CLS] letter tree five football via status bore military skin operated around enclosed taste v curtis ku special joan murmured ( entrance gentrylanda single few2tiv whoa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.858 (perp=12.340, rec=0.390, cos=0.000), tot_loss_proj:3.202 [t=0.26s]
prediction: ['[CLS] military smuged competition removed - alarmes - leave fat thatnig than phone fl -ery seed text allegedly butlanglary worst years drink system [SEP]']
[ 100/2000] tot_loss=2.466 (perp=10.887, rec=0.288, cos=0.000), tot_loss_proj:2.909 [t=0.28s]
prediction: ['[CLS] military cassette - competition removed - standes - leave / - vessels than phone fl - anger delegates text allegedly butesete mixed sg system [SEP]']
[ 150/2000] tot_loss=2.490 (perp=11.280, rec=0.234, cos=0.000), tot_loss_proj:2.987 [t=0.27s]
prediction: ['[CLS] army heavyweight - exercise exercise - stand - - shelf sick - movements than this freaking - movements bow - foul but lotickistic s scare action [SEP]']
[ 200/2000] tot_loss=2.179 (perp=9.911, rec=0.196, cos=0.000), tot_loss_proj:2.573 [t=0.27s]
prediction: ['[CLS] walking shelf - exercise exercise - stand - - shelf - - movements than this shelf - movements bow - foul -mmickistic - versus exercise [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.105 (perp=9.763, rec=0.153, cos=0.000), tot_loss_proj:3.048 [t=0.27s]
prediction: ['[CLS] - shelf long exercise exercise - stand - - shelf in - - than this shelf this movements bow - tough -mmely movements shelf exercise [SEP]']
[ 300/2000] tot_loss=2.089 (perp=9.738, rec=0.142, cos=0.000), tot_loss_proj:2.897 [t=0.28s]
prediction: ['[CLS] - shelf long shoot exercise - stand - - shelf in - - than this shelf this movements bow - shoot -mmely movements drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.144 (perp=10.112, rec=0.122, cos=0.000), tot_loss_proj:2.972 [t=0.27s]
prediction: ['[CLS] - troll longmm exercise - on - - shelf gi - - thanel shelf this movements bow - shoot dramas shootely movements drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.153 (perp=10.066, rec=0.140, cos=0.000), tot_loss_proj:2.944 [t=0.26s]
prediction: ['[CLS]y tv longmm exercise - - - on shelf gi - - thanel shelf this movements bow - shoot dramas shootely movements drama exercise [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.338, rec=0.121, cos=0.000), tot_loss_proj:2.774 [t=0.27s]
prediction: ['[CLS]y - longmm exercise - - - on shelf gi - - thanel shelf this exercise bow - shoot dramas shootely movements drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.995 (perp=9.414, rec=0.113, cos=0.000), tot_loss_proj:2.860 [t=0.26s]
prediction: ['[CLS]y - longmm exercise - - - on shelf gi - - thanel points exercise this bow - shoot drama shootelick movements drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.834 (perp=8.602, rec=0.114, cos=0.000), tot_loss_proj:2.773 [t=0.28s]
prediction: ['[CLS] of - longmm exercise - - - on shelf shoot - - thanel points exercise this bow - shoot drama gielick movements drama exercise [SEP]']
[ 600/2000] tot_loss=1.852 (perp=8.770, rec=0.098, cos=0.000), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] of - longmm exercise - - - on shelf shoot - - thanel point exercise this bow shoot shoot drama gielick movements drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.781 (perp=8.395, rec=0.102, cos=0.000), tot_loss_proj:2.764 [t=0.27s]
prediction: ['[CLS] of - longmm shoot - - - on shelf shoot - - thanel point exercise this bow shoot exercise drama gielick movements drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.767 (perp=8.359, rec=0.095, cos=0.000), tot_loss_proj:2.717 [t=0.28s]
prediction: ['[CLS] of - longmm shoot - - this on shelf shoot - - thanel point exercise - bow shoot exercise drama gielick movements crime exercise [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.305, rec=0.091, cos=0.000), tot_loss_proj:2.712 [t=0.30s]
prediction: ['[CLS] of - longmm shoot - - this on shelf shoot - - thanel shoot exercise - bow shoot exercise drama gielick movements crime exercise [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.720 (perp=8.165, rec=0.087, cos=0.000), tot_loss_proj:2.588 [t=0.28s]
prediction: ['[CLS] of - longmm shoot - - this on shelf shoot - - thanel shoot exercise - bow shoot exercise exercise gielick movements crime drama [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.702 (perp=8.072, rec=0.088, cos=0.000), tot_loss_proj:2.543 [t=0.27s]
prediction: ['[CLS] of - longmm shoot - - this on shelf shoot - - thanel exercise shoot - bow shoot exercise exercise gielick movements crime drama [SEP]']
[ 900/2000] tot_loss=1.737 (perp=8.272, rec=0.083, cos=0.000), tot_loss_proj:2.656 [t=0.27s]
prediction: ['[CLS] of - longmm shoot - - this on shelf shoot - - thanel crime shoot - bow shoot exercise exercise gielick movements crime drama [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.730 (perp=8.188, rec=0.093, cos=0.000), tot_loss_proj:2.675 [t=0.28s]
prediction: ['[CLS] of - longmm shoot - - on this shelf shoot - - thanel crime shoot - bow shoot exercise exercise gielick movements crime drama [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.665 (perp=7.798, rec=0.105, cos=0.000), tot_loss_proj:2.250 [t=0.27s]
prediction: ['[CLS] of - longel shoot - - on this shelf shoot - - thanel crime shoot - bow shoot exercise exercise gimmick movements crime drama [SEP]']
[1050/2000] tot_loss=1.641 (perp=7.798, rec=0.082, cos=0.000), tot_loss_proj:2.254 [t=0.27s]
prediction: ['[CLS] of - longel shoot - - on this shelf shoot - - thanel crime shoot - bow shoot exercise exercise gimmick movements crime drama [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.572 (perp=7.410, rec=0.090, cos=0.000), tot_loss_proj:2.126 [t=0.27s]
prediction: ['[CLS] of - longel shoot - - on this shelf shoot - - thanel movements shoot - bow shoot exercise exercise gimmick crime crime drama [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.553 (perp=7.327, rec=0.087, cos=0.000), tot_loss_proj:2.149 [t=0.27s]
prediction: ['[CLS] of -el long shoot - - on this shelf shoot - - thanel movements shoot - bow shoot exercise exercise gimmick crime crime drama [SEP]']
[1200/2000] tot_loss=1.552 (perp=7.327, rec=0.087, cos=0.000), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] of -el long shoot - - on this shelf shoot - - thanel movements shoot - bow shoot exercise exercise gimmick crime crime drama [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.523 (perp=7.140, rec=0.095, cos=0.000), tot_loss_proj:2.194 [t=0.27s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot exercise exercise gimmick crime crime drama [SEP]']
Attempt swap
[1300/2000] tot_loss=1.517 (perp=7.140, rec=0.089, cos=0.000), tot_loss_proj:2.196 [t=0.27s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot exercise exercise gimmick crime crime drama [SEP]']
[1350/2000] tot_loss=1.508 (perp=7.110, rec=0.086, cos=0.000), tot_loss_proj:2.278 [t=0.26s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
[1400/2000] tot_loss=1.501 (perp=7.110, rec=0.079, cos=0.000), tot_loss_proj:2.277 [t=0.27s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
[1450/2000] tot_loss=1.518 (perp=7.110, rec=0.096, cos=0.000), tot_loss_proj:2.281 [t=0.27s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.110, rec=0.083, cos=0.000), tot_loss_proj:2.275 [t=0.27s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.498 (perp=7.110, rec=0.076, cos=0.000), tot_loss_proj:2.274 [t=0.27s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
[1600/2000] tot_loss=1.516 (perp=7.110, rec=0.094, cos=0.000), tot_loss_proj:2.268 [t=0.26s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
[1650/2000] tot_loss=1.504 (perp=7.110, rec=0.082, cos=0.000), tot_loss_proj:2.273 [t=0.25s]
prediction: ['[CLS] ofel long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.627, rec=0.087, cos=0.000), tot_loss_proj:2.333 [t=0.28s]
prediction: ['[CLS] ofick long shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.587 (perp=7.492, rec=0.088, cos=0.000), tot_loss_proj:2.236 [t=0.28s]
prediction: ['[CLS] longick of shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
[1800/2000] tot_loss=1.580 (perp=7.492, rec=0.081, cos=0.000), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS] longick of shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
[1850/2000] tot_loss=1.578 (perp=7.492, rec=0.080, cos=0.000), tot_loss_proj:2.232 [t=0.29s]
prediction: ['[CLS] longick of shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.552 (perp=7.375, rec=0.077, cos=0.000), tot_loss_proj:2.305 [t=0.27s]
prediction: ['[CLS] long ofick shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
[1950/2000] tot_loss=1.559 (perp=7.375, rec=0.084, cos=0.000), tot_loss_proj:2.295 [t=0.27s]
prediction: ['[CLS] long ofick shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=7.375, rec=0.074, cos=0.000), tot_loss_proj:2.297 [t=0.28s]
prediction: ['[CLS] long ofick shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] long ofick shoot - - - on this shelf shoot - in thanel movements shoot - bow shoot shoot exercise gimmick crime crime drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 57.143 | r: 66.667
rouge2     | fm: 16.216 | p: 15.000 | r: 17.647
rougeL     | fm: 46.154 | p: 42.857 | r: 50.000
rougeLsum  | fm: 46.154 | p: 42.857 | r: 50.000
r1fm+r2fm = 77.755

[Aggregate metrics]:
rouge1     | fm: 91.287 | p: 90.563 | r: 92.186
rouge2     | fm: 62.409 | p: 62.031 | r: 62.857
rougeL     | fm: 79.116 | p: 78.499 | r: 79.865
rougeLsum  | fm: 79.068 | p: 78.394 | r: 79.829
r1fm+r2fm = 153.696

input #45 time: 0:11:15 | total time: 7:59:04


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
*********************************
*********************************
average of cosine similarity 0.9992706340099029
highest_index [0]
highest [0.9992706340099029]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9914612174034119 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792836308479309 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.943648636341095 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.941935122013092 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9368497729301453 for ['[CLS] sacked age s between pack lowell [SEP]']
[Init] best rec loss: 0.9330108165740967 for ['[CLS] once definition delgnoeousosed [SEP]']
[Init] best rec loss: 0.9311715960502625 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9135607481002808 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best rec loss: 0.9118399620056152 for ['[CLS] serie templebie half succeeding coast [SEP]']
[Init] best perm rec loss: 0.911443829536438 for ['[CLS] coast succeeding seriebie temple half [SEP]']
[Init] best perm rec loss: 0.9091481566429138 for ['[CLS] coast succeedingbie half temple serie [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.569 (perp=11.585, rec=0.252, cos=0.000), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] established striking visual abstracts architectureing [SEP]']
[ 100/2000] tot_loss=2.394 (perp=11.114, rec=0.171, cos=0.000), tot_loss_proj:2.648 [t=0.25s]
prediction: ['[CLS] slick striking slick abstracts stagedly [SEP]']
[ 150/2000] tot_loss=2.211 (perp=10.406, rec=0.130, cos=0.000), tot_loss_proj:2.371 [t=0.28s]
prediction: ['[CLS] striking visually slickfully stagedly [SEP]']
[ 200/2000] tot_loss=1.923 (perp=9.061, rec=0.111, cos=0.000), tot_loss_proj:2.046 [t=0.25s]
prediction: ['[CLS] striking visually slickly stagedly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.699 (perp=8.005, rec=0.098, cos=0.000), tot_loss_proj:1.813 [t=0.26s]
prediction: ['[CLS] strikingly visually slickly staged [SEP]']
[ 300/2000] tot_loss=1.653 (perp=7.880, rec=0.076, cos=0.000), tot_loss_proj:1.688 [t=0.28s]
prediction: ['[CLS] striking and visually slickly staged [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.539 (perp=7.329, rec=0.073, cos=0.000), tot_loss_proj:1.651 [t=0.26s]
prediction: ['[CLS] slick and visually strikingly staged [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.402 (perp=6.580, rec=0.086, cos=0.000), tot_loss_proj:1.481 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 450/2000] tot_loss=1.387 (perp=6.580, rec=0.071, cos=0.000), tot_loss_proj:1.490 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.380 (perp=6.580, rec=0.064, cos=0.000), tot_loss_proj:1.498 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.393 (perp=6.580, rec=0.077, cos=0.000), tot_loss_proj:1.484 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 600/2000] tot_loss=1.384 (perp=6.580, rec=0.068, cos=0.000), tot_loss_proj:1.494 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.390 (perp=6.580, rec=0.074, cos=0.000), tot_loss_proj:1.485 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.382 (perp=6.580, rec=0.066, cos=0.000), tot_loss_proj:1.489 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 750/2000] tot_loss=1.382 (perp=6.580, rec=0.066, cos=0.000), tot_loss_proj:1.488 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.379 (perp=6.580, rec=0.063, cos=0.000), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.389 (perp=6.580, rec=0.073, cos=0.000), tot_loss_proj:1.491 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 900/2000] tot_loss=1.380 (perp=6.580, rec=0.064, cos=0.000), tot_loss_proj:1.493 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.393 (perp=6.580, rec=0.077, cos=0.000), tot_loss_proj:1.495 [t=0.30s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1000/2000] tot_loss=1.386 (perp=6.580, rec=0.070, cos=0.000), tot_loss_proj:1.490 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1050/2000] tot_loss=1.389 (perp=6.580, rec=0.073, cos=0.000), tot_loss_proj:1.493 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1100/2000] tot_loss=1.389 (perp=6.580, rec=0.073, cos=0.000), tot_loss_proj:1.477 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.376 (perp=6.580, rec=0.060, cos=0.000), tot_loss_proj:1.491 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1200/2000] tot_loss=1.370 (perp=6.580, rec=0.054, cos=0.000), tot_loss_proj:1.478 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1250/2000] tot_loss=1.377 (perp=6.580, rec=0.061, cos=0.000), tot_loss_proj:1.486 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.380 (perp=6.580, rec=0.064, cos=0.000), tot_loss_proj:1.484 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1350/2000] tot_loss=1.382 (perp=6.580, rec=0.066, cos=0.000), tot_loss_proj:1.491 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.376 (perp=6.580, rec=0.060, cos=0.000), tot_loss_proj:1.484 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.375 (perp=6.580, rec=0.059, cos=0.000), tot_loss_proj:1.489 [t=0.30s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1500/2000] tot_loss=1.381 (perp=6.580, rec=0.065, cos=0.000), tot_loss_proj:1.497 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.397 (perp=6.580, rec=0.081, cos=0.000), tot_loss_proj:1.489 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1600/2000] tot_loss=1.398 (perp=6.580, rec=0.082, cos=0.000), tot_loss_proj:1.482 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1650/2000] tot_loss=1.379 (perp=6.580, rec=0.063, cos=0.000), tot_loss_proj:1.501 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.369 (perp=6.580, rec=0.053, cos=0.000), tot_loss_proj:1.488 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.391 (perp=6.580, rec=0.075, cos=0.000), tot_loss_proj:1.491 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1800/2000] tot_loss=1.390 (perp=6.580, rec=0.074, cos=0.000), tot_loss_proj:1.489 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.378 (perp=6.580, rec=0.062, cos=0.000), tot_loss_proj:1.486 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.376 (perp=6.580, rec=0.060, cos=0.000), tot_loss_proj:1.483 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1950/2000] tot_loss=1.391 (perp=6.580, rec=0.075, cos=0.000), tot_loss_proj:1.491 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.383 (perp=6.580, rec=0.067, cos=0.000), tot_loss_proj:1.485 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] slickly staged and visually striking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 91.498 | p: 90.808 | r: 92.340
rouge2     | fm: 61.894 | p: 61.569 | r: 62.297
rougeL     | fm: 78.706 | p: 78.068 | r: 79.417
rougeLsum  | fm: 78.379 | p: 77.770 | r: 79.119
r1fm+r2fm = 153.391

input #46 time: 0:11:24 | total time: 8:10:28


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
*********************************
*********************************
average of cosine similarity 0.9992062856246862
highest_index [0]
highest [0.9992062856246862]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6919234991073608 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6893526911735535 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6824025511741638 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6734322905540466 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.672934353351593 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6719985604286194 for ['[CLS] salt reality poles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.661 (perp=11.559, rec=0.349, cos=0.000), tot_loss_proj:3.467 [t=0.27s]
prediction: ['[CLS] % transparent lone [SEP]']
[ 100/2000] tot_loss=2.986 (perp=13.345, rec=0.317, cos=0.000), tot_loss_proj:3.483 [t=0.26s]
prediction: ['[CLS]right transparentright [SEP]']
[ 150/2000] tot_loss=2.859 (perp=13.345, rec=0.191, cos=0.000), tot_loss_proj:3.515 [t=0.26s]
prediction: ['[CLS]right transparentright [SEP]']
[ 200/2000] tot_loss=2.822 (perp=13.345, rec=0.153, cos=0.000), tot_loss_proj:3.529 [t=0.26s]
prediction: ['[CLS]right transparentright [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.388 (perp=11.101, rec=0.168, cos=0.000), tot_loss_proj:2.813 [t=0.26s]
prediction: ['[CLS] collinsright transparent [SEP]']
[ 300/2000] tot_loss=1.885 (perp=8.803, rec=0.125, cos=0.000), tot_loss_proj:1.920 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.864 (perp=8.803, rec=0.103, cos=0.000), tot_loss_proj:1.918 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.852 (perp=8.803, rec=0.091, cos=0.000), tot_loss_proj:1.918 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.830 (perp=8.803, rec=0.070, cos=0.000), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.836 (perp=8.803, rec=0.076, cos=0.000), tot_loss_proj:1.927 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.828 (perp=8.803, rec=0.067, cos=0.000), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.834 (perp=8.803, rec=0.073, cos=0.000), tot_loss_proj:1.918 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.817 (perp=8.803, rec=0.057, cos=0.000), tot_loss_proj:1.921 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.820 (perp=8.803, rec=0.060, cos=0.000), tot_loss_proj:1.913 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.838 (perp=8.803, rec=0.077, cos=0.000), tot_loss_proj:1.920 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.835 (perp=8.803, rec=0.074, cos=0.000), tot_loss_proj:1.905 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.824 (perp=8.803, rec=0.063, cos=0.000), tot_loss_proj:1.907 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.831 (perp=8.803, rec=0.070, cos=0.000), tot_loss_proj:1.911 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.803, rec=0.061, cos=0.000), tot_loss_proj:1.907 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.827 (perp=8.803, rec=0.067, cos=0.000), tot_loss_proj:1.911 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.811 (perp=8.803, rec=0.050, cos=0.000), tot_loss_proj:1.920 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.831 (perp=8.803, rec=0.070, cos=0.000), tot_loss_proj:1.904 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.830 (perp=8.803, rec=0.069, cos=0.000), tot_loss_proj:1.922 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.823 (perp=8.803, rec=0.063, cos=0.000), tot_loss_proj:1.916 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.831 (perp=8.803, rec=0.070, cos=0.000), tot_loss_proj:1.918 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.817 (perp=8.803, rec=0.056, cos=0.000), tot_loss_proj:1.914 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.813 (perp=8.803, rec=0.053, cos=0.000), tot_loss_proj:1.924 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.815 (perp=8.803, rec=0.055, cos=0.000), tot_loss_proj:1.923 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.827 (perp=8.803, rec=0.066, cos=0.000), tot_loss_proj:1.906 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.815 (perp=8.803, rec=0.055, cos=0.000), tot_loss_proj:1.910 [t=0.30s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.829 (perp=8.803, rec=0.069, cos=0.000), tot_loss_proj:1.913 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.810 (perp=8.803, rec=0.050, cos=0.000), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.833 (perp=8.803, rec=0.073, cos=0.000), tot_loss_proj:1.898 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.827 (perp=8.803, rec=0.066, cos=0.000), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.814 (perp=8.803, rec=0.054, cos=0.000), tot_loss_proj:1.908 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.818 (perp=8.803, rec=0.057, cos=0.000), tot_loss_proj:1.910 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.830 (perp=8.803, rec=0.069, cos=0.000), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.831 (perp=8.803, rec=0.070, cos=0.000), tot_loss_proj:1.915 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.825 (perp=8.803, rec=0.065, cos=0.000), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.832 (perp=8.803, rec=0.071, cos=0.000), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.675 | p: 91.014 | r: 92.507
rouge2     | fm: 62.609 | p: 62.253 | r: 63.088
rougeL     | fm: 79.073 | p: 78.520 | r: 79.802
rougeLsum  | fm: 78.952 | p: 78.406 | r: 79.623
r1fm+r2fm = 154.284

input #47 time: 0:11:25 | total time: 8:21:54


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
*********************************
*********************************
average of cosine similarity 0.9993046518468323
highest_index [0]
highest [0.9993046518468323]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9492654800415039 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9282971024513245 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9096147418022156 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.8921412229537964 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8839486241340637 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8647245764732361 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8392558693885803 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.7997488379478455 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7973767518997192 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7965604066848755 for ['[CLS]tutedine graveyard runs [SEP]']
[Init] best perm rec loss: 0.7944426536560059 for ['[CLS]tute graveyard runsdine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.013 (perp=13.831, rec=0.247, cos=0.000), tot_loss_proj:3.231 [t=0.25s]
prediction: ['[CLS] decay rottingole rotting [SEP]']
[ 100/2000] tot_loss=1.938 (perp=8.982, rec=0.142, cos=0.000), tot_loss_proj:2.283 [t=0.27s]
prediction: ['[CLS] under rottingbelly [SEP]']
[ 150/2000] tot_loss=1.893 (perp=8.982, rec=0.096, cos=0.000), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] under rottingbelly [SEP]']
[ 200/2000] tot_loss=1.867 (perp=8.982, rec=0.071, cos=0.000), tot_loss_proj:2.286 [t=0.27s]
prediction: ['[CLS] under rottingbelly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.500 (perp=7.108, rec=0.079, cos=0.000), tot_loss_proj:1.496 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.490 (perp=7.108, rec=0.069, cos=0.000), tot_loss_proj:1.486 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.473 (perp=7.108, rec=0.051, cos=0.000), tot_loss_proj:1.490 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.474 (perp=7.108, rec=0.052, cos=0.000), tot_loss_proj:1.496 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.478 (perp=7.108, rec=0.057, cos=0.000), tot_loss_proj:1.483 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.488 (perp=7.108, rec=0.066, cos=0.000), tot_loss_proj:1.489 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.486 (perp=7.108, rec=0.065, cos=0.000), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.471 (perp=7.108, rec=0.050, cos=0.000), tot_loss_proj:1.491 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.493 (perp=7.108, rec=0.072, cos=0.000), tot_loss_proj:1.490 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.478 (perp=7.108, rec=0.057, cos=0.000), tot_loss_proj:1.478 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.489 (perp=7.108, rec=0.067, cos=0.000), tot_loss_proj:1.486 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.487 (perp=7.108, rec=0.066, cos=0.000), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.475 (perp=7.108, rec=0.053, cos=0.000), tot_loss_proj:1.495 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.481 (perp=7.108, rec=0.059, cos=0.000), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.473 (perp=7.108, rec=0.052, cos=0.000), tot_loss_proj:1.475 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.492 (perp=7.108, rec=0.071, cos=0.000), tot_loss_proj:1.487 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.489 (perp=7.108, rec=0.067, cos=0.000), tot_loss_proj:1.484 [t=0.28s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.488 (perp=7.108, rec=0.067, cos=0.000), tot_loss_proj:1.483 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.480 (perp=7.108, rec=0.058, cos=0.000), tot_loss_proj:1.485 [t=0.28s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.479 (perp=7.108, rec=0.057, cos=0.000), tot_loss_proj:1.488 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.481 (perp=7.108, rec=0.059, cos=0.000), tot_loss_proj:1.482 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.487 (perp=7.108, rec=0.066, cos=0.000), tot_loss_proj:1.494 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.478 (perp=7.108, rec=0.056, cos=0.000), tot_loss_proj:1.491 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.490 (perp=7.108, rec=0.069, cos=0.000), tot_loss_proj:1.493 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.480 (perp=7.108, rec=0.059, cos=0.000), tot_loss_proj:1.480 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.480 (perp=7.108, rec=0.059, cos=0.000), tot_loss_proj:1.487 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.486 (perp=7.108, rec=0.065, cos=0.000), tot_loss_proj:1.480 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.480 (perp=7.108, rec=0.058, cos=0.000), tot_loss_proj:1.499 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.482 (perp=7.108, rec=0.060, cos=0.000), tot_loss_proj:1.490 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.480 (perp=7.108, rec=0.058, cos=0.000), tot_loss_proj:1.481 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.482 (perp=7.108, rec=0.060, cos=0.000), tot_loss_proj:1.494 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.481 (perp=7.108, rec=0.060, cos=0.000), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.486 (perp=7.108, rec=0.064, cos=0.000), tot_loss_proj:1.483 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.482 (perp=7.108, rec=0.060, cos=0.000), tot_loss_proj:1.487 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.491 (perp=7.108, rec=0.070, cos=0.000), tot_loss_proj:1.493 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=7.108, rec=0.055, cos=0.000), tot_loss_proj:1.483 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.845 | p: 91.187 | r: 92.696
rouge2     | fm: 63.306 | p: 62.976 | r: 63.778
rougeL     | fm: 79.477 | p: 78.837 | r: 80.251
rougeLsum  | fm: 79.520 | p: 78.933 | r: 80.136
r1fm+r2fm = 155.151

input #48 time: 0:11:09 | total time: 8:33:03


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
*********************************
*********************************
average of cosine similarity 0.9992290345656085
highest_index [0]
highest [0.9992290345656085]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8312081098556519 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7826305031776428 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7823294401168823 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7810743451118469 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7783752083778381 for ['[CLS] nat search apprenticeship ranged este not0 ₂ whitney waterhak street [SEP]']
[Init] best rec loss: 0.7663204073905945 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7545866966247559 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7537117004394531 for ['[CLS] process gmina baby tongue trick jose patrick college duringiza legs jockey [SEP]']
[Init] best perm rec loss: 0.7524945735931396 for ['[CLS] tongue college legs trickiza jockey process patrick gmina baby jose during [SEP]']
[Init] best perm rec loss: 0.7512368559837341 for ['[CLS] joseiza patrick tongue process trick gmina jockey college during legs baby [SEP]']
[Init] best perm rec loss: 0.7501923441886902 for ['[CLS] legs jockey tongue trick patrick jose gmina processiza during baby college [SEP]']
[Init] best perm rec loss: 0.74892657995224 for ['[CLS] tongue process during college trick jose jockey patrick legs babyiza gmina [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.497 (perp=10.565, rec=0.385, cos=0.000), tot_loss_proj:3.189 [t=0.26s]
prediction: ['[CLS] opposition types. actually pit more abuse female meant government enforcement coverage [SEP]']
[ 100/2000] tot_loss=2.520 (perp=11.241, rec=0.272, cos=0.000), tot_loss_proj:3.327 [t=0.26s]
prediction: ['[CLS] contempt understood. possibly confuse morearies female contempt government enforcement coverage [SEP]']
[ 150/2000] tot_loss=2.373 (perp=10.887, rec=0.196, cos=0.000), tot_loss_proj:3.182 [t=0.28s]
prediction: ['[CLS] contempt would. possiblyuous more single female contempt government population population [SEP]']
[ 200/2000] tot_loss=2.257 (perp=10.466, rec=0.164, cos=0.000), tot_loss_proj:3.086 [t=0.27s]
prediction: ['[CLS] contempt could, possibly be more single female contempt government population population [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.153 (perp=10.089, rec=0.135, cos=0.000), tot_loss_proj:2.993 [t=0.26s]
prediction: ['[CLS] contempt possibly, possibly be more single female contempt militia of population [SEP]']
[ 300/2000] tot_loss=2.124 (perp=10.047, rec=0.115, cos=0.000), tot_loss_proj:2.898 [t=0.27s]
prediction: ['[CLS] contempt possibly, possibly be more single femaleuous militia of population [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.822 (perp=8.577, rec=0.107, cos=0.000), tot_loss_proj:2.507 [t=0.27s]
prediction: ['[CLS] possibly. could be more single female contemptuous enforcement of population [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.854 (perp=8.627, rec=0.128, cos=0.000), tot_loss_proj:2.362 [t=0.26s]
prediction: ['[CLS] possibly. could stock be more single female contemptuous of population [SEP]']
[ 450/2000] tot_loss=1.829 (perp=8.627, rec=0.104, cos=0.000), tot_loss_proj:2.367 [t=0.27s]
prediction: ['[CLS] possibly. could stock be more single female contemptuous of population [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.690 (perp=7.964, rec=0.097, cos=0.000), tot_loss_proj:2.247 [t=0.28s]
prediction: ['[CLS] possibly could ( be more single female contemptuous of population, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.471 (perp=6.858, rec=0.099, cos=0.000), tot_loss_proj:2.042 [t=0.27s]
prediction: ['[CLS] ( could possibly be more single female contemptuous of population, [SEP]']
[ 600/2000] tot_loss=1.456 (perp=6.858, rec=0.085, cos=0.000), tot_loss_proj:2.041 [t=0.25s]
prediction: ['[CLS] ( could possibly be more single female contemptuous of population, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.464 (perp=6.858, rec=0.092, cos=0.000), tot_loss_proj:2.037 [t=0.27s]
prediction: ['[CLS] ( could possibly be more single female contemptuous of population, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.590, rec=0.081, cos=0.000), tot_loss_proj:1.984 [t=0.28s]
prediction: ['[CLS] ( could possibly be more single female contemptuous of population. [SEP]']
[ 750/2000] tot_loss=1.410 (perp=6.590, rec=0.092, cos=0.000), tot_loss_proj:1.989 [t=0.27s]
prediction: ['[CLS] ( could possibly be more single female contemptuous of population. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.352 (perp=6.332, rec=0.086, cos=0.000), tot_loss_proj:1.886 [t=0.26s]
prediction: ['[CLS] ( could possibly be more single contemptuous of female population. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.283 (perp=6.045, rec=0.074, cos=0.000), tot_loss_proj:1.730 [t=0.26s]
prediction: ['[CLS] ( could possibly be more contemptuous of single female population. [SEP]']
[ 900/2000] tot_loss=1.298 (perp=6.045, rec=0.089, cos=0.000), tot_loss_proj:1.732 [t=0.26s]
prediction: ['[CLS] ( could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.288 (perp=6.045, rec=0.079, cos=0.000), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] ( could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.278 (perp=6.045, rec=0.069, cos=0.000), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] ( could possibly be more contemptuous of single female population. [SEP]']
[1050/2000] tot_loss=1.358 (perp=6.373, rec=0.083, cos=0.000), tot_loss_proj:1.677 [t=0.27s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.354 (perp=6.373, rec=0.080, cos=0.000), tot_loss_proj:1.666 [t=0.28s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.348 (perp=6.373, rec=0.074, cos=0.000), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
[1200/2000] tot_loss=1.352 (perp=6.373, rec=0.077, cos=0.000), tot_loss_proj:1.674 [t=0.28s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.344 (perp=6.373, rec=0.069, cos=0.000), tot_loss_proj:1.671 [t=0.27s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.348 (perp=6.373, rec=0.074, cos=0.000), tot_loss_proj:1.669 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
[1350/2000] tot_loss=1.350 (perp=6.373, rec=0.075, cos=0.000), tot_loss_proj:1.674 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.353 (perp=6.373, rec=0.079, cos=0.000), tot_loss_proj:1.673 [t=0.27s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.347 (perp=6.373, rec=0.073, cos=0.000), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
[1500/2000] tot_loss=1.351 (perp=6.373, rec=0.076, cos=0.000), tot_loss_proj:1.670 [t=0.25s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.338 (perp=6.373, rec=0.064, cos=0.000), tot_loss_proj:1.678 [t=0.27s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.350 (perp=6.373, rec=0.075, cos=0.000), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
[1650/2000] tot_loss=1.344 (perp=6.373, rec=0.070, cos=0.000), tot_loss_proj:1.672 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.343 (perp=6.373, rec=0.068, cos=0.000), tot_loss_proj:1.671 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.343 (perp=6.373, rec=0.068, cos=0.000), tot_loss_proj:1.670 [t=0.27s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
[1800/2000] tot_loss=1.349 (perp=6.373, rec=0.074, cos=0.000), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.350 (perp=6.373, rec=0.076, cos=0.000), tot_loss_proj:1.675 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.351 (perp=6.373, rec=0.076, cos=0.000), tot_loss_proj:1.669 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
[1950/2000] tot_loss=1.339 (perp=6.373, rec=0.065, cos=0.000), tot_loss_proj:1.676 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.351 (perp=6.373, rec=0.077, cos=0.000), tot_loss_proj:1.670 [t=0.26s]
prediction: ['[CLS] stock could possibly be more contemptuous of single female population. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] stock could possibly be more contemptuous of single female population. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 91.879 | p: 91.162 | r: 92.645
rouge2     | fm: 63.536 | p: 63.177 | r: 63.941
rougeL     | fm: 79.732 | p: 79.153 | r: 80.452
rougeLsum  | fm: 79.649 | p: 79.153 | r: 80.362
r1fm+r2fm = 155.415

input #49 time: 0:11:08 | total time: 8:44:12


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
*********************************
*********************************
average of cosine similarity 0.9992839909575625
highest_index [0]
highest [0.9992839909575625]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9197331666946411 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8376165628433228 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7576577067375183 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7542896270751953 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best rec loss: 0.7541337609291077 for ['[CLS] tab draft lessons berman pattern family modifications sharing illusions [SEP]']
[Init] best perm rec loss: 0.7539732456207275 for ['[CLS] pattern lessons berman illusions family tab modifications sharing draft [SEP]']
[Init] best perm rec loss: 0.7520403265953064 for ['[CLS] berman sharing illusions tab pattern family modifications lessons draft [SEP]']
[Init] best perm rec loss: 0.7505223155021667 for ['[CLS] sharing family berman lessons pattern tab modifications illusions draft [SEP]']
[Init] best perm rec loss: 0.7498471736907959 for ['[CLS] berman lessons illusions sharing family tab pattern draft modifications [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.053 (perp=13.045, rec=0.444, cos=0.000), tot_loss_proj:3.898 [t=0.29s]
prediction: ['[CLS] worth knowing to college clever arrivedbasket watching reservations [SEP]']
[ 100/2000] tot_loss=2.667 (perp=11.544, rec=0.358, cos=0.000), tot_loss_proj:3.949 [t=0.29s]
prediction: ['[CLS] liked knowing ons clever whatbasket ted alfred [SEP]']
[ 150/2000] tot_loss=2.784 (perp=11.907, rec=0.402, cos=0.000), tot_loss_proj:3.382 [t=0.29s]
prediction: ["[CLS] call ordersesrri clever'too literallyno [SEP]"]
[ 200/2000] tot_loss=2.536 (perp=11.043, rec=0.328, cos=0.000), tot_loss_proj:3.471 [t=0.28s]
prediction: ["[CLS] call orders 'rri clever'too halfno [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.176 (perp=9.331, rec=0.310, cos=0.000), tot_loss_proj:2.782 [t=0.27s]
prediction: ["[CLS] call hearn half clever'toorri most [SEP]"]
[ 300/2000] tot_loss=2.725 (perp=12.266, rec=0.272, cos=0.000), tot_loss_proj:3.543 [t=0.27s]
prediction: ['[CLS] call hear english half clever ` toorri criticized [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.652 (perp=11.505, rec=0.351, cos=0.000), tot_loss_proj:3.780 [t=0.26s]
prediction: ['[CLS] call english by clever ` by england quickly what [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.194 (perp=9.452, rec=0.304, cos=0.000), tot_loss_proj:3.375 [t=0.27s]
prediction: ['[CLS] ` english by clever call by england most what [SEP]']
[ 450/2000] tot_loss=2.057 (perp=8.931, rec=0.271, cos=0.000), tot_loss_proj:3.159 [t=0.26s]
prediction: ['[CLS] ` english by clever call by any most what [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.058 (perp=9.129, rec=0.233, cos=0.000), tot_loss_proj:2.852 [t=0.26s]
prediction: ['[CLS] ` english by clever call by what half clever [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.896 (perp=8.378, rec=0.220, cos=0.000), tot_loss_proj:2.720 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what clever [SEP]']
[ 600/2000] tot_loss=1.983 (perp=8.970, rec=0.189, cos=0.000), tot_loss_proj:2.830 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.970 (perp=8.970, rec=0.176, cos=0.000), tot_loss_proj:2.829 [t=0.25s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.951 (perp=8.970, rec=0.157, cos=0.000), tot_loss_proj:2.828 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[ 750/2000] tot_loss=1.953 (perp=8.970, rec=0.159, cos=0.000), tot_loss_proj:2.828 [t=0.28s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.935 (perp=8.970, rec=0.141, cos=0.000), tot_loss_proj:2.827 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.919 (perp=8.970, rec=0.125, cos=0.000), tot_loss_proj:2.828 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[ 900/2000] tot_loss=1.899 (perp=8.970, rec=0.105, cos=0.000), tot_loss_proj:2.827 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.897 (perp=8.970, rec=0.103, cos=0.000), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1000/2000] tot_loss=1.886 (perp=8.970, rec=0.092, cos=0.000), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1050/2000] tot_loss=1.892 (perp=8.970, rec=0.098, cos=0.000), tot_loss_proj:2.828 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1100/2000] tot_loss=1.888 (perp=8.970, rec=0.094, cos=0.000), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1150/2000] tot_loss=1.893 (perp=8.970, rec=0.100, cos=0.000), tot_loss_proj:2.827 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1200/2000] tot_loss=1.885 (perp=8.970, rec=0.091, cos=0.000), tot_loss_proj:2.825 [t=0.25s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1250/2000] tot_loss=1.892 (perp=8.970, rec=0.098, cos=0.000), tot_loss_proj:2.825 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1300/2000] tot_loss=1.890 (perp=8.970, rec=0.096, cos=0.000), tot_loss_proj:2.827 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1350/2000] tot_loss=1.889 (perp=8.970, rec=0.095, cos=0.000), tot_loss_proj:2.830 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1400/2000] tot_loss=1.878 (perp=8.970, rec=0.084, cos=0.000), tot_loss_proj:2.828 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1450/2000] tot_loss=1.873 (perp=8.970, rec=0.079, cos=0.000), tot_loss_proj:2.823 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1500/2000] tot_loss=1.874 (perp=8.970, rec=0.080, cos=0.000), tot_loss_proj:2.826 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1550/2000] tot_loss=1.881 (perp=8.970, rec=0.087, cos=0.000), tot_loss_proj:2.828 [t=0.28s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1600/2000] tot_loss=1.881 (perp=8.970, rec=0.087, cos=0.000), tot_loss_proj:2.826 [t=0.28s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1650/2000] tot_loss=1.875 (perp=8.970, rec=0.081, cos=0.000), tot_loss_proj:2.826 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1700/2000] tot_loss=1.875 (perp=8.970, rec=0.081, cos=0.000), tot_loss_proj:2.822 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1750/2000] tot_loss=1.876 (perp=8.970, rec=0.082, cos=0.000), tot_loss_proj:2.823 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1800/2000] tot_loss=1.872 (perp=8.970, rec=0.079, cos=0.000), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1850/2000] tot_loss=1.879 (perp=8.970, rec=0.085, cos=0.000), tot_loss_proj:2.826 [t=0.27s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[1900/2000] tot_loss=1.871 (perp=8.970, rec=0.077, cos=0.000), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
[1950/2000] tot_loss=1.885 (perp=8.970, rec=0.092, cos=0.000), tot_loss_proj:2.828 [t=0.26s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Attempt swap
[2000/2000] tot_loss=1.882 (perp=8.970, rec=0.088, cos=0.000), tot_loss_proj:2.821 [t=0.25s]
prediction: ['[CLS] ` english half by clever call by what too [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] ` english half by clever call by what too [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 90.000

[Aggregate metrics]:
rouge1     | fm: 91.783 | p: 91.133 | r: 92.534
rouge2     | fm: 62.364 | p: 61.961 | r: 62.779
rougeL     | fm: 79.225 | p: 78.647 | r: 79.903
rougeLsum  | fm: 79.138 | p: 78.613 | r: 79.762
r1fm+r2fm = 154.147

input #50 time: 0:11:15 | total time: 8:55:28


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
*********************************
*********************************
average of cosine similarity 0.9992547340508808
highest_index [0]
highest [0.9992547340508808]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.8239725828170776 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7901466488838196 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7369245886802673 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7290186882019043 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7257851362228394 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.720592200756073 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7110686302185059 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7087100744247437 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7084143161773682 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7022585868835449 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7015665769577026 for ['[CLS] once disappointed in market literaryrak toured medium renamed watching [SEP]']
[Init] best perm rec loss: 0.7009227871894836 for ['[CLS] toured literary watching once medium inrak renamed disappointed market [SEP]']
[Init] best perm rec loss: 0.6990828514099121 for ['[CLS] once toured in disappointed literary renamedrak market medium watching [SEP]']
[Init] best perm rec loss: 0.6981620788574219 for ['[CLS] renamed touredrak medium in literary disappointed market once watching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.879 (perp=12.385, rec=0.402, cos=0.000), tot_loss_proj:3.375 [t=0.27s]
prediction: ['[CLS] director sucks : funny comics what interestingkali goodbye paralympics [SEP]']
[ 100/2000] tot_loss=2.625 (perp=11.655, rec=0.294, cos=0.000), tot_loss_proj:3.212 [t=0.26s]
prediction: ['[CLS] sucked sucks. sucks except has funnytime funny funny [SEP]']
[ 150/2000] tot_loss=1.811 (perp=7.964, rec=0.218, cos=0.000), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] sucks sucks and sucks but has funny or funny. [SEP]']
[ 200/2000] tot_loss=1.685 (perp=7.671, rec=0.151, cos=0.000), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS] have sucks, sucks but has funny or funny. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.759 (perp=8.181, rec=0.122, cos=0.000), tot_loss_proj:2.332 [t=0.26s]
prediction: ['[CLS] have sucks, sucks but has funny or moment. [SEP]']
[ 300/2000] tot_loss=1.675 (perp=7.862, rec=0.103, cos=0.000), tot_loss_proj:2.331 [t=0.26s]
prediction: ['[CLS] sometimes sucks, sucks but has funny or moment. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.548 (perp=7.233, rec=0.102, cos=0.000), tot_loss_proj:1.993 [t=0.27s]
prediction: ['[CLS] sometimes sucks, but has funny sucks or moment. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.666 (perp=7.886, rec=0.089, cos=0.000), tot_loss_proj:2.156 [t=0.27s]
prediction: ['[CLS] sometimes sucks, but has funny moment or sucks two [SEP]']
[ 450/2000] tot_loss=1.696 (perp=8.007, rec=0.095, cos=0.000), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] a sucks, but has funny moment or sucks two [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.572 (perp=7.436, rec=0.084, cos=0.000), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] a sucks, but has funny moment or two sucks [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.571 (perp=7.436, rec=0.083, cos=0.000), tot_loss_proj:2.116 [t=0.27s]
prediction: ['[CLS] a sucks, but has funny moment or two sucks [SEP]']
[ 600/2000] tot_loss=1.578 (perp=7.436, rec=0.090, cos=0.000), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] a sucks, but has funny moment or two sucks [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.573 (perp=7.436, rec=0.086, cos=0.000), tot_loss_proj:2.118 [t=0.27s]
prediction: ['[CLS] a sucks, but has funny moment or two sucks [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.349 (perp=6.353, rec=0.078, cos=0.000), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 750/2000] tot_loss=1.342 (perp=6.353, rec=0.071, cos=0.000), tot_loss_proj:2.107 [t=0.28s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.341 (perp=6.353, rec=0.071, cos=0.000), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.345 (perp=6.353, rec=0.074, cos=0.000), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 900/2000] tot_loss=1.336 (perp=6.353, rec=0.065, cos=0.000), tot_loss_proj:2.106 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.345 (perp=6.353, rec=0.075, cos=0.000), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1000/2000] tot_loss=1.341 (perp=6.353, rec=0.070, cos=0.000), tot_loss_proj:2.110 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1050/2000] tot_loss=1.339 (perp=6.353, rec=0.068, cos=0.000), tot_loss_proj:2.109 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1100/2000] tot_loss=1.346 (perp=6.353, rec=0.075, cos=0.000), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1150/2000] tot_loss=1.340 (perp=6.353, rec=0.069, cos=0.000), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[1200/2000] tot_loss=1.340 (perp=6.353, rec=0.070, cos=0.000), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1250/2000] tot_loss=1.333 (perp=6.353, rec=0.063, cos=0.000), tot_loss_proj:2.097 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[1300/2000] tot_loss=1.118 (perp=5.210, rec=0.076, cos=0.000), tot_loss_proj:1.159 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1350/2000] tot_loss=1.103 (perp=5.210, rec=0.061, cos=0.000), tot_loss_proj:1.151 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.108 (perp=5.210, rec=0.066, cos=0.000), tot_loss_proj:1.163 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.103 (perp=5.210, rec=0.061, cos=0.000), tot_loss_proj:1.164 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1500/2000] tot_loss=1.103 (perp=5.210, rec=0.061, cos=0.000), tot_loss_proj:1.154 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.113 (perp=5.210, rec=0.071, cos=0.000), tot_loss_proj:1.154 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.114 (perp=5.210, rec=0.072, cos=0.000), tot_loss_proj:1.156 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1650/2000] tot_loss=1.106 (perp=5.210, rec=0.064, cos=0.000), tot_loss_proj:1.157 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.112 (perp=5.210, rec=0.070, cos=0.000), tot_loss_proj:1.157 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.110 (perp=5.210, rec=0.068, cos=0.000), tot_loss_proj:1.160 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1800/2000] tot_loss=1.110 (perp=5.210, rec=0.068, cos=0.000), tot_loss_proj:1.152 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.159 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.158 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1950/2000] tot_loss=1.107 (perp=5.210, rec=0.065, cos=0.000), tot_loss_proj:1.156 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.118 (perp=5.210, rec=0.076, cos=0.000), tot_loss_proj:1.154 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.975 | p: 91.329 | r: 92.723
rouge2     | fm: 62.774 | p: 62.459 | r: 63.182
rougeL     | fm: 79.630 | p: 79.066 | r: 80.258
rougeLsum  | fm: 79.391 | p: 78.857 | r: 80.099
r1fm+r2fm = 154.750

input #51 time: 0:11:09 | total time: 9:06:38


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
*********************************
*********************************
average of cosine similarity 0.9992768062076273
highest_index [0]
highest [0.9992768062076273]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9595772624015808 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9317372441291809 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8995898365974426 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8750851154327393 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7909459471702576 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7780885696411133 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7069104313850403 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.70586097240448 for ['[CLS] expected vocabulary football [SEP]']
[Init] best perm rec loss: 0.7040697336196899 for ['[CLS] vocabulary expected football [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.568 (perp=11.737, rec=0.220, cos=0.000), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.478 (perp=11.737, rec=0.131, cos=0.000), tot_loss_proj:2.643 [t=0.27s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.190 (perp=10.529, rec=0.084, cos=0.000), tot_loss_proj:2.193 [t=0.27s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.173 (perp=10.529, rec=0.067, cos=0.000), tot_loss_proj:2.187 [t=0.25s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.806 (perp=8.482, rec=0.109, cos=0.000), tot_loss_proj:2.093 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.780 (perp=8.482, rec=0.084, cos=0.000), tot_loss_proj:2.088 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.760 (perp=8.482, rec=0.063, cos=0.000), tot_loss_proj:2.092 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.760 (perp=8.482, rec=0.063, cos=0.000), tot_loss_proj:2.093 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.762 (perp=8.482, rec=0.066, cos=0.000), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.765 (perp=8.482, rec=0.068, cos=0.000), tot_loss_proj:2.092 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.752 (perp=8.482, rec=0.055, cos=0.000), tot_loss_proj:2.083 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.482, rec=0.066, cos=0.000), tot_loss_proj:2.081 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.754 (perp=8.482, rec=0.057, cos=0.000), tot_loss_proj:2.090 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.758 (perp=8.482, rec=0.061, cos=0.000), tot_loss_proj:2.085 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.757 (perp=8.482, rec=0.061, cos=0.000), tot_loss_proj:2.093 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.769 (perp=8.482, rec=0.073, cos=0.000), tot_loss_proj:2.089 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.760 (perp=8.482, rec=0.063, cos=0.000), tot_loss_proj:2.086 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.762 (perp=8.482, rec=0.065, cos=0.000), tot_loss_proj:2.084 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=8.482, rec=0.050, cos=0.000), tot_loss_proj:2.085 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.760 (perp=8.482, rec=0.064, cos=0.000), tot_loss_proj:2.089 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.757 (perp=8.482, rec=0.060, cos=0.000), tot_loss_proj:2.083 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.756 (perp=8.482, rec=0.060, cos=0.000), tot_loss_proj:2.081 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.761 (perp=8.482, rec=0.064, cos=0.000), tot_loss_proj:2.089 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.755 (perp=8.482, rec=0.058, cos=0.000), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.759 (perp=8.482, rec=0.063, cos=0.000), tot_loss_proj:2.093 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.768 (perp=8.482, rec=0.071, cos=0.000), tot_loss_proj:2.088 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.770 (perp=8.482, rec=0.074, cos=0.000), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.767 (perp=8.482, rec=0.071, cos=0.000), tot_loss_proj:2.084 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.747 (perp=8.482, rec=0.051, cos=0.000), tot_loss_proj:2.091 [t=0.34s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.761 (perp=8.482, rec=0.064, cos=0.000), tot_loss_proj:2.080 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.760 (perp=8.482, rec=0.063, cos=0.000), tot_loss_proj:2.084 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.755 (perp=8.482, rec=0.058, cos=0.000), tot_loss_proj:2.088 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.765 (perp=8.482, rec=0.069, cos=0.000), tot_loss_proj:2.094 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.748 (perp=8.482, rec=0.051, cos=0.000), tot_loss_proj:2.089 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.769 (perp=8.482, rec=0.073, cos=0.000), tot_loss_proj:2.079 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.751 (perp=8.482, rec=0.054, cos=0.000), tot_loss_proj:2.094 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=8.482, rec=0.064, cos=0.000), tot_loss_proj:2.087 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.752 (perp=8.482, rec=0.056, cos=0.000), tot_loss_proj:2.086 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.769 (perp=8.482, rec=0.072, cos=0.000), tot_loss_proj:2.089 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.754 (perp=8.482, rec=0.057, cos=0.000), tot_loss_proj:2.086 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.158 | p: 91.512 | r: 92.859
rouge2     | fm: 61.943 | p: 61.620 | r: 62.313
rougeL     | fm: 79.507 | p: 78.954 | r: 80.090
rougeLsum  | fm: 79.388 | p: 78.886 | r: 79.984
r1fm+r2fm = 154.101

input #52 time: 0:11:11 | total time: 9:17:49


Running input #53 of 100.
reference: 
========================
flinching 
========================
*********************************
*********************************
average of cosine similarity 0.9993460246461926
highest_index [0]
highest [0.9993460246461926]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9496892094612122 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8591198325157166 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8245270252227783 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7937619090080261 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7161449790000916 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.6961936950683594 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6954168677330017 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6789679527282715 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.676031768321991 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.790 (perp=12.384, rec=0.314, cos=0.000), tot_loss_proj:3.276 [t=0.28s]
prediction: ['[CLS] flinch flinched [SEP]']
[ 100/2000] tot_loss=2.690 (perp=12.492, rec=0.191, cos=0.000), tot_loss_proj:3.228 [t=0.28s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.657 (perp=12.492, rec=0.159, cos=0.000), tot_loss_proj:3.244 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.643 (perp=12.492, rec=0.144, cos=0.000), tot_loss_proj:3.239 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.629 (perp=12.492, rec=0.131, cos=0.000), tot_loss_proj:3.239 [t=0.21s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.597 (perp=12.492, rec=0.098, cos=0.000), tot_loss_proj:3.244 [t=0.21s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.555 (perp=12.414, rec=0.072, cos=0.000), tot_loss_proj:3.237 [t=0.21s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.681 (perp=8.090, rec=0.063, cos=0.000), tot_loss_proj:1.683 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.684 (perp=8.090, rec=0.066, cos=0.000), tot_loss_proj:1.682 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.691 (perp=8.090, rec=0.073, cos=0.000), tot_loss_proj:1.691 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.090, rec=0.058, cos=0.000), tot_loss_proj:1.687 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.688 (perp=8.090, rec=0.070, cos=0.000), tot_loss_proj:1.685 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.680 (perp=8.090, rec=0.062, cos=0.000), tot_loss_proj:1.674 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.684 (perp=8.090, rec=0.066, cos=0.000), tot_loss_proj:1.690 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.679 (perp=8.090, rec=0.061, cos=0.000), tot_loss_proj:1.691 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.665 (perp=8.090, rec=0.047, cos=0.000), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.682 (perp=8.090, rec=0.064, cos=0.000), tot_loss_proj:1.685 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.682 (perp=8.090, rec=0.064, cos=0.000), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.680 (perp=8.090, rec=0.062, cos=0.000), tot_loss_proj:1.679 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.672 (perp=8.090, rec=0.054, cos=0.000), tot_loss_proj:1.683 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.674 (perp=8.090, rec=0.056, cos=0.000), tot_loss_proj:1.691 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.684 (perp=8.090, rec=0.066, cos=0.000), tot_loss_proj:1.697 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.673 (perp=8.090, rec=0.055, cos=0.000), tot_loss_proj:1.696 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.674 (perp=8.090, rec=0.056, cos=0.000), tot_loss_proj:1.686 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.669 (perp=8.090, rec=0.051, cos=0.000), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.684 (perp=8.090, rec=0.067, cos=0.000), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.679 (perp=8.090, rec=0.061, cos=0.000), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.673 (perp=8.090, rec=0.055, cos=0.000), tot_loss_proj:1.695 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.686 (perp=8.090, rec=0.068, cos=0.000), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.671 (perp=8.090, rec=0.053, cos=0.000), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.671 (perp=8.090, rec=0.053, cos=0.000), tot_loss_proj:1.693 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=8.090, rec=0.051, cos=0.000), tot_loss_proj:1.681 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.682 (perp=8.090, rec=0.064, cos=0.000), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.667 (perp=8.090, rec=0.049, cos=0.000), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.685 (perp=8.090, rec=0.067, cos=0.000), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.674 (perp=8.090, rec=0.056, cos=0.000), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=8.090, rec=0.066, cos=0.000), tot_loss_proj:1.691 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.686 (perp=8.090, rec=0.068, cos=0.000), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.669 (perp=8.090, rec=0.051, cos=0.000), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.675 (perp=8.090, rec=0.057, cos=0.000), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.330 | p: 91.714 | r: 93.024
rouge2     | fm: 62.477 | p: 62.165 | r: 62.851
rougeL     | fm: 79.831 | p: 79.301 | r: 80.445
rougeLsum  | fm: 79.716 | p: 79.217 | r: 80.372
r1fm+r2fm = 154.807

input #53 time: 0:09:14 | total time: 9:27:03


Running input #54 of 100.
reference: 
========================
hot topics 
========================
*********************************
*********************************
average of cosine similarity 0.9991885194729966
highest_index [0]
highest [0.9991885194729966]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9526175260543823 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8000466823577881 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7551351189613342 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.718959391117096 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7020211815834045 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.6970599293708801 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.103 (perp=13.270, rec=0.449, cos=0.000), tot_loss_proj:3.854 [t=0.26s]
prediction: ['[CLS] topics ear [SEP]']
[ 100/2000] tot_loss=2.591 (perp=11.553, rec=0.280, cos=0.000), tot_loss_proj:2.803 [t=0.27s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.466 (perp=11.553, rec=0.156, cos=0.000), tot_loss_proj:2.808 [t=0.28s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.425 (perp=11.553, rec=0.114, cos=0.000), tot_loss_proj:2.818 [t=0.27s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.748 (perp=8.198, rec=0.108, cos=0.000), tot_loss_proj:1.730 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.722 (perp=8.198, rec=0.082, cos=0.000), tot_loss_proj:1.727 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.716 (perp=8.198, rec=0.076, cos=0.000), tot_loss_proj:1.734 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.709 (perp=8.198, rec=0.069, cos=0.000), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.726 (perp=8.198, rec=0.087, cos=0.000), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.705 (perp=8.198, rec=0.065, cos=0.000), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.694 (perp=8.198, rec=0.054, cos=0.000), tot_loss_proj:1.750 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.694 (perp=8.198, rec=0.055, cos=0.000), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.702 (perp=8.198, rec=0.063, cos=0.000), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.710 (perp=8.198, rec=0.070, cos=0.000), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.705 (perp=8.198, rec=0.066, cos=0.000), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.705 (perp=8.198, rec=0.065, cos=0.000), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.701 (perp=8.198, rec=0.061, cos=0.000), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.701 (perp=8.198, rec=0.061, cos=0.000), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.700 (perp=8.198, rec=0.061, cos=0.000), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.198, rec=0.061, cos=0.000), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.703 (perp=8.198, rec=0.063, cos=0.000), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.700 (perp=8.198, rec=0.060, cos=0.000), tot_loss_proj:1.741 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.695 (perp=8.198, rec=0.056, cos=0.000), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.707 (perp=8.198, rec=0.068, cos=0.000), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.706 (perp=8.198, rec=0.066, cos=0.000), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.708 (perp=8.198, rec=0.068, cos=0.000), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.691 (perp=8.198, rec=0.052, cos=0.000), tot_loss_proj:1.742 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.695 (perp=8.198, rec=0.056, cos=0.000), tot_loss_proj:1.744 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.701 (perp=8.198, rec=0.061, cos=0.000), tot_loss_proj:1.738 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.198, rec=0.065, cos=0.000), tot_loss_proj:1.743 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.696 (perp=8.198, rec=0.056, cos=0.000), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.702 (perp=8.198, rec=0.063, cos=0.000), tot_loss_proj:1.746 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.689 (perp=8.198, rec=0.049, cos=0.000), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.705 (perp=8.198, rec=0.065, cos=0.000), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.695 (perp=8.198, rec=0.056, cos=0.000), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.700 (perp=8.198, rec=0.060, cos=0.000), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.697 (perp=8.198, rec=0.057, cos=0.000), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.690 (perp=8.198, rec=0.050, cos=0.000), tot_loss_proj:1.746 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.696 (perp=8.198, rec=0.057, cos=0.000), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.698 (perp=8.198, rec=0.058, cos=0.000), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.402 | p: 91.826 | r: 93.140
rouge2     | fm: 63.194 | p: 62.995 | r: 63.563
rougeL     | fm: 80.217 | p: 79.721 | r: 80.843
rougeLsum  | fm: 80.038 | p: 79.539 | r: 80.587
r1fm+r2fm = 155.596

input #54 time: 0:11:10 | total time: 9:38:14


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
*********************************
*********************************
average of cosine similarity 0.9991198671556452
highest_index [0]
highest [0.9991198671556452]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9138370156288147 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8676082491874695 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7880235910415649 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7713199257850647 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.761566162109375 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7580128908157349 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7514014840126038 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.7189949750900269 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7076445817947388 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7070018649101257 for ['[CLS] holly stride post [SEP]']
[Init] best perm rec loss: 0.7052616477012634 for ['[CLS] stride post holly [SEP]']
[Init] best perm rec loss: 0.7035731077194214 for ['[CLS] post stride holly [SEP]']
[Init] best perm rec loss: 0.7012022137641907 for ['[CLS] post holly stride [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.013 (perp=12.672, rec=0.478, cos=0.000), tot_loss_proj:4.030 [t=0.27s]
prediction: ['[CLS] war inherited easy [SEP]']
[ 100/2000] tot_loss=2.764 (perp=11.998, rec=0.364, cos=0.000), tot_loss_proj:3.848 [t=0.26s]
prediction: ['[CLS] war pack settles [SEP]']
[ 150/2000] tot_loss=2.777 (perp=10.251, rec=0.535, cos=0.192), tot_loss_proj:2.826 [t=0.25s]
prediction: ['[CLS] cold easily settles [SEP]']
[ 200/2000] tot_loss=2.339 (perp=10.294, rec=0.280, cos=0.000), tot_loss_proj:2.921 [t=0.27s]
prediction: ['[CLS] non easily settles [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.850 (perp=8.688, rec=0.113, cos=0.000), tot_loss_proj:2.143 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.822 (perp=8.688, rec=0.084, cos=0.000), tot_loss_proj:2.169 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.814 (perp=8.688, rec=0.076, cos=0.000), tot_loss_proj:2.158 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.801 (perp=8.688, rec=0.063, cos=0.000), tot_loss_proj:2.159 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.812 (perp=8.688, rec=0.075, cos=0.000), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=8.688, rec=0.065, cos=0.000), tot_loss_proj:2.155 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.799 (perp=8.688, rec=0.061, cos=0.000), tot_loss_proj:2.167 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.800 (perp=8.688, rec=0.062, cos=0.000), tot_loss_proj:2.167 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.806 (perp=8.688, rec=0.069, cos=0.000), tot_loss_proj:2.161 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.796 (perp=8.688, rec=0.058, cos=0.000), tot_loss_proj:2.152 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.688, rec=0.059, cos=0.000), tot_loss_proj:2.161 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.800 (perp=8.688, rec=0.062, cos=0.000), tot_loss_proj:2.162 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.815 (perp=8.688, rec=0.078, cos=0.000), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.813 (perp=8.688, rec=0.076, cos=0.000), tot_loss_proj:2.158 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.688, rec=0.065, cos=0.000), tot_loss_proj:2.162 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.798 (perp=8.688, rec=0.061, cos=0.000), tot_loss_proj:2.165 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.806 (perp=8.688, rec=0.068, cos=0.000), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.802 (perp=8.688, rec=0.064, cos=0.000), tot_loss_proj:2.164 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.803 (perp=8.688, rec=0.066, cos=0.000), tot_loss_proj:2.170 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.791 (perp=8.688, rec=0.053, cos=0.000), tot_loss_proj:2.158 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.801 (perp=8.688, rec=0.063, cos=0.000), tot_loss_proj:2.161 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.803 (perp=8.688, rec=0.065, cos=0.000), tot_loss_proj:2.162 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.808 (perp=8.688, rec=0.071, cos=0.000), tot_loss_proj:2.159 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.801 (perp=8.688, rec=0.064, cos=0.000), tot_loss_proj:2.161 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.793 (perp=8.688, rec=0.056, cos=0.000), tot_loss_proj:2.167 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.808 (perp=8.688, rec=0.071, cos=0.000), tot_loss_proj:2.166 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.800 (perp=8.688, rec=0.063, cos=0.000), tot_loss_proj:2.175 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.798 (perp=8.688, rec=0.061, cos=0.000), tot_loss_proj:2.168 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.807 (perp=8.688, rec=0.070, cos=0.000), tot_loss_proj:2.162 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.795 (perp=8.688, rec=0.058, cos=0.000), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.796 (perp=8.688, rec=0.058, cos=0.000), tot_loss_proj:2.172 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.688, rec=0.059, cos=0.000), tot_loss_proj:2.159 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.801 (perp=8.688, rec=0.064, cos=0.000), tot_loss_proj:2.160 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.688, rec=0.059, cos=0.000), tot_loss_proj:2.159 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.802 (perp=8.688, rec=0.064, cos=0.000), tot_loss_proj:2.178 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.789 (perp=8.688, rec=0.052, cos=0.000), tot_loss_proj:2.162 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.576 | p: 91.956 | r: 93.280
rouge2     | fm: 62.605 | p: 62.268 | r: 63.017
rougeL     | fm: 80.234 | p: 79.734 | r: 80.799
rougeLsum  | fm: 80.170 | p: 79.669 | r: 80.773
r1fm+r2fm = 155.182

input #55 time: 0:11:09 | total time: 9:49:24


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
*********************************
*********************************
average of cosine similarity 0.9992753356504276
highest_index [0]
highest [0.9992753356504276]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.9329692125320435 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9173128008842468 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9010238647460938 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8954348564147949 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.893097460269928 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8846154808998108 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8843698501586914 for ['[CLS] dive emotional organization almost up consolation cas potential leadership with variables defeated been spectroscopy handed existing acquainted obsidian wall households realm [SEP]']
[Init] best perm rec loss: 0.8831345438957214 for ['[CLS] spectroscopy potential variables wall households been emotional acquainted dive defeated organization up handed almost consolation obsidian leadership existing with cas realm [SEP]']
[Init] best perm rec loss: 0.8822870254516602 for ['[CLS] leadership been obsidian existing handed realm organization acquainted consolation almost households with emotional dive potential variables wall up defeated cas spectroscopy [SEP]']
[Init] best perm rec loss: 0.8811699748039246 for ['[CLS] leadership handed existing almost households variables potential defeated cas acquainted with consolation spectroscopy organization dive been realm up emotional wall obsidian [SEP]']
[Init] best perm rec loss: 0.8802573680877686 for ['[CLS] acquainted cas existing obsidian spectroscopy organization realm handed wall households emotional variables consolation up defeated been almost with potential dive leadership [SEP]']
[Init] best perm rec loss: 0.8799365162849426 for ['[CLS] been households leadership almost realm wall acquainted variables existing organization spectroscopy emotional consolation handed potential cas obsidian defeated up dive with [SEP]']
[Init] best perm rec loss: 0.8793233036994934 for ['[CLS] existing emotional defeated wall consolation with dive realm variables been organization cas almost potential leadership spectroscopy acquainted households obsidian handed up [SEP]']
[Init] best perm rec loss: 0.8792343735694885 for ['[CLS] defeated cas potential obsidian dive handed leadership households been acquainted emotional almost existing wall organization spectroscopy up variables with consolation realm [SEP]']
[Init] best perm rec loss: 0.8785929679870605 for ['[CLS] handed been wall leadership existing acquainted realm cas defeated variables almost obsidian up organization spectroscopy potential with households dive emotional consolation [SEP]']
[Init] best perm rec loss: 0.8776257634162903 for ['[CLS] spectroscopy defeated cas realm emotional almost obsidian consolation with up leadership households existing acquainted handed organization been wall variables dive potential [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.651, rec=0.358, cos=0.000), tot_loss_proj:3.325 [t=0.30s]
prediction: ['[CLS] ₹ failedweight of fixing by angry impossible [ up estimates costlyological speech probably chicken whiches guyster analysis [SEP]']
[ 100/2000] tot_loss=2.669 (perp=12.122, rec=0.245, cos=0.000), tot_loss_proj:3.378 [t=0.29s]
prediction: ['[CLS] destroyed apparent damaged of damage which damage impossible destroy painful hundreds costly regimenow almost apparently whichs films analysis analysis [SEP]']
[ 150/2000] tot_loss=2.510 (perp=11.560, rec=0.198, cos=0.000), tot_loss_proj:3.295 [t=0.30s]
prediction: ['[CLS] costly apparent damaged of damage which costly costly never damages loads damage ofcola that apparently ofate films fix analysis [SEP]']
[ 200/2000] tot_loss=2.229 (perp=10.365, rec=0.156, cos=0.000), tot_loss_proj:2.999 [t=0.29s]
prediction: ['[CLS] costly cause damage of damage which costly costly never cause loads damage of se that apparently ofsari films fix analysis [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.316 (perp=10.900, rec=0.136, cos=0.000), tot_loss_proj:2.958 [t=0.28s]
prediction: ['[CLS] costly cause damage of damage which costly costly never will loads of damagepara that years ofpara films fix analysis [SEP]']
[ 300/2000] tot_loss=2.352 (perp=11.153, rec=0.122, cos=0.000), tot_loss_proj:3.060 [t=0.28s]
prediction: ['[CLS] costly cause damage of damage which♥ costly never will loads of damagepara that years ofpara films fix analysis [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.109 (perp=9.994, rec=0.111, cos=0.000), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] costly cause lots of damage which♥para never will loads of damagepara that years of costly films fix analysis [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.037 (perp=9.677, rec=0.102, cos=0.000), tot_loss_proj:2.534 [t=0.28s]
prediction: ['[CLS] costly lots of damage which seasonspara never cause will loads of damagepara that years of costly films fix analysis [SEP]']
[ 450/2000] tot_loss=2.033 (perp=9.673, rec=0.098, cos=0.000), tot_loss_proj:2.518 [t=0.28s]
prediction: ['[CLS] costly lots of damage which irpara never cause will loads of damagepara that years of costly films fix analysis [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.961 (perp=9.319, rec=0.097, cos=0.000), tot_loss_proj:2.514 [t=0.27s]
prediction: ['[CLS] costly lots of damage which irpara never cause will loads of damagepara that years of costly analysis fix films [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.032 (perp=9.632, rec=0.105, cos=0.000), tot_loss_proj:2.722 [t=0.27s]
prediction: ['[CLS] costly loads of damage which irpara never cause will lotsble damagepara that years of costly analysis fix films [SEP]']
[ 600/2000] tot_loss=2.020 (perp=9.632, rec=0.094, cos=0.000), tot_loss_proj:2.730 [t=0.28s]
prediction: ['[CLS] costly loads of damage which irpara never cause will lotsble damagepara that years of costly analysis fix films [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.952 (perp=9.298, rec=0.093, cos=0.000), tot_loss_proj:2.786 [t=0.27s]
prediction: ['[CLS] costly loads of damage which irpara never cause will lotsble damage cause that years of costly analysis fix films [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.778 (perp=8.410, rec=0.096, cos=0.000), tot_loss_proj:2.727 [t=0.27s]
prediction: ['[CLS] costly loads of damage which ir cause never cause willparable damage cause that years of costly analysis fix films [SEP]']
[ 750/2000] tot_loss=1.772 (perp=8.410, rec=0.091, cos=0.000), tot_loss_proj:2.722 [t=0.27s]
prediction: ['[CLS] costly loads of damage which ir cause never cause willparable damage cause that years of costly analysis fix films [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.726 (perp=8.188, rec=0.089, cos=0.000), tot_loss_proj:2.814 [t=0.27s]
prediction: ['[CLS] costly loads of damage which will cause never cause irparable damage cause that years and costly analysis fix films [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.670 (perp=7.855, rec=0.099, cos=0.000), tot_loss_proj:2.660 [t=0.26s]
prediction: ['[CLS] costly loads of damage which films will cause never cause irparable damage cause that years and costly analysis fix [SEP]']
[ 900/2000] tot_loss=1.571 (perp=7.391, rec=0.093, cos=0.000), tot_loss_proj:2.450 [t=0.27s]
prediction: ['[CLS] costly loads of damage which films will cause never cause irparable damage cause that years of costly analysis fix [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.860 (perp=8.878, rec=0.084, cos=0.000), tot_loss_proj:2.628 [t=0.28s]
prediction: ['[CLS] costly loads of damage which films will cause never cause irparableble cause that years and costly analysis fix [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.825 (perp=8.710, rec=0.083, cos=0.000), tot_loss_proj:2.302 [t=0.28s]
prediction: ['[CLS] costly loads of damage which films will cause never ir irbleparable cause that years of costly analysis fix [SEP]']
[1050/2000] tot_loss=1.932 (perp=9.255, rec=0.081, cos=0.000), tot_loss_proj:2.503 [t=0.27s]
prediction: ['[CLS] costly loads of damage which films will cause never ir irbleparable cause that years and costly analysis fix [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.689 (perp=8.012, rec=0.087, cos=0.000), tot_loss_proj:2.204 [t=0.27s]
prediction: ['[CLS] costly loads of damage which films will cause never irbleparable ir cause that years of costly analysis fix [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.586 (perp=7.533, rec=0.080, cos=0.000), tot_loss_proj:2.105 [t=0.27s]
prediction: ['[CLS] costly loads of damage which films will never cause irbleparable ir cause that years of costly analysis fix [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.533, rec=0.086, cos=0.000), tot_loss_proj:2.101 [t=0.27s]
prediction: ['[CLS] costly loads of damage which films will never cause irbleparable ir cause that years of costly analysis fix [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.539 (perp=7.293, rec=0.080, cos=0.000), tot_loss_proj:2.137 [t=0.27s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir cause that years of costly analysis fix [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.505 (perp=7.122, rec=0.080, cos=0.000), tot_loss_proj:2.072 [t=0.27s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years of costly analysis fix [SEP]']
[1350/2000] tot_loss=1.504 (perp=7.122, rec=0.080, cos=0.000), tot_loss_proj:2.066 [t=0.26s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years of costly analysis fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=7.122, rec=0.082, cos=0.000), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years of costly analysis fix [SEP]']
Attempt swap
[1450/2000] tot_loss=1.506 (perp=7.122, rec=0.081, cos=0.000), tot_loss_proj:2.068 [t=0.27s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years of costly analysis fix [SEP]']
[1500/2000] tot_loss=1.568 (perp=7.432, rec=0.082, cos=0.000), tot_loss_proj:2.205 [t=0.28s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
Attempt swap
[1550/2000] tot_loss=1.570 (perp=7.432, rec=0.084, cos=0.000), tot_loss_proj:2.205 [t=0.27s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.570 (perp=7.432, rec=0.084, cos=0.000), tot_loss_proj:2.208 [t=0.29s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
[1650/2000] tot_loss=1.570 (perp=7.432, rec=0.084, cos=0.000), tot_loss_proj:2.209 [t=0.28s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.564 (perp=7.432, rec=0.078, cos=0.000), tot_loss_proj:2.210 [t=0.28s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.565 (perp=7.432, rec=0.079, cos=0.000), tot_loss_proj:2.208 [t=0.27s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
[1800/2000] tot_loss=1.560 (perp=7.432, rec=0.074, cos=0.000), tot_loss_proj:2.208 [t=0.26s]
prediction: ['[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.540 (perp=7.288, rec=0.082, cos=0.000), tot_loss_proj:2.404 [t=0.28s]
prediction: ['[CLS] costly loads of ir films which will never cause irbleparable damage that cause years and costly analysis fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.536 (perp=7.288, rec=0.078, cos=0.000), tot_loss_proj:2.403 [t=0.28s]
prediction: ['[CLS] costly loads of ir films which will never cause irbleparable damage that cause years and costly analysis fix [SEP]']
[1950/2000] tot_loss=1.541 (perp=7.288, rec=0.083, cos=0.000), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] costly loads of ir films which will never cause irbleparable damage that cause years and costly analysis fix [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.508 (perp=7.097, rec=0.088, cos=0.000), tot_loss_proj:2.395 [t=0.27s]
prediction: ['[CLS] ir loads of costly films which will never cause irbleparable damage that cause years and costly analysis fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] costly loads of damage films which will never cause irbleparable ir that cause years and costly analysis fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 31.579 | p: 31.579 | r: 31.579
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 111.579

[Aggregate metrics]:
rouge1     | fm: 92.360 | p: 91.811 | r: 93.047
rouge2     | fm: 61.933 | p: 61.661 | r: 62.250
rougeL     | fm: 79.842 | p: 79.346 | r: 80.413
rougeLsum  | fm: 79.794 | p: 79.285 | r: 80.351
r1fm+r2fm = 154.293

input #56 time: 0:11:26 | total time: 10:00:50


Running input #57 of 100.
reference: 
========================
wears 
========================
*********************************
*********************************
average of cosine similarity 0.9993820261307658
highest_index [0]
highest [0.9993820261307658]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.858372151851654 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7990744709968567 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.7146762013435364 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6487741470336914 for ['[CLS] expressed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.926 (perp=12.705, rec=0.385, cos=0.000), tot_loss_proj:3.179 [t=0.28s]
prediction: ['[CLS] wore [SEP]']
[ 100/2000] tot_loss=2.572 (perp=12.283, rec=0.115, cos=0.000), tot_loss_proj:2.518 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.523 (perp=12.283, rec=0.066, cos=0.000), tot_loss_proj:2.505 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.518 (perp=12.283, rec=0.061, cos=0.000), tot_loss_proj:2.516 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.520 (perp=12.283, rec=0.064, cos=0.000), tot_loss_proj:2.521 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.519 (perp=12.283, rec=0.062, cos=0.000), tot_loss_proj:2.514 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.500 (perp=12.283, rec=0.043, cos=0.000), tot_loss_proj:2.509 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.508 (perp=12.283, rec=0.051, cos=0.000), tot_loss_proj:2.518 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.513 (perp=12.283, rec=0.057, cos=0.000), tot_loss_proj:2.508 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.515 (perp=12.283, rec=0.058, cos=0.000), tot_loss_proj:2.521 [t=0.31s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.515 (perp=12.283, rec=0.058, cos=0.000), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.512 (perp=12.283, rec=0.055, cos=0.000), tot_loss_proj:2.504 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.519 (perp=12.283, rec=0.062, cos=0.000), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.511 (perp=12.283, rec=0.055, cos=0.000), tot_loss_proj:2.521 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.515 (perp=12.283, rec=0.058, cos=0.000), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.521 (perp=12.283, rec=0.065, cos=0.000), tot_loss_proj:2.510 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.523 (perp=12.283, rec=0.067, cos=0.000), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.520 (perp=12.283, rec=0.063, cos=0.000), tot_loss_proj:2.511 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.513 (perp=12.283, rec=0.057, cos=0.000), tot_loss_proj:2.503 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.525 (perp=12.283, rec=0.068, cos=0.000), tot_loss_proj:2.524 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.513 (perp=12.283, rec=0.057, cos=0.000), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.516 (perp=12.283, rec=0.060, cos=0.000), tot_loss_proj:2.524 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.528 (perp=12.283, rec=0.071, cos=0.000), tot_loss_proj:2.508 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.524 (perp=12.283, rec=0.067, cos=0.000), tot_loss_proj:2.534 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.513 (perp=12.283, rec=0.056, cos=0.000), tot_loss_proj:2.511 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.510 (perp=12.283, rec=0.054, cos=0.000), tot_loss_proj:2.513 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.501 (perp=12.283, rec=0.044, cos=0.000), tot_loss_proj:2.516 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.519 (perp=12.283, rec=0.062, cos=0.000), tot_loss_proj:2.521 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.508 (perp=12.283, rec=0.051, cos=0.000), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.516 (perp=12.283, rec=0.060, cos=0.000), tot_loss_proj:2.510 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.512 (perp=12.283, rec=0.055, cos=0.000), tot_loss_proj:2.505 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.525 (perp=12.283, rec=0.069, cos=0.000), tot_loss_proj:2.506 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.509 (perp=12.283, rec=0.052, cos=0.000), tot_loss_proj:2.526 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.524 (perp=12.283, rec=0.068, cos=0.000), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.532 (perp=12.283, rec=0.075, cos=0.000), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.513 (perp=12.283, rec=0.056, cos=0.000), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.510 (perp=12.283, rec=0.054, cos=0.000), tot_loss_proj:2.517 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.532 (perp=12.283, rec=0.076, cos=0.000), tot_loss_proj:2.527 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.529 (perp=12.283, rec=0.072, cos=0.000), tot_loss_proj:2.519 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.519 (perp=12.283, rec=0.063, cos=0.000), tot_loss_proj:2.513 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.494 | p: 91.915 | r: 93.187
rouge2     | fm: 62.832 | p: 62.479 | r: 63.146
rougeL     | fm: 80.328 | p: 79.825 | r: 80.892
rougeLsum  | fm: 80.053 | p: 79.615 | r: 80.661
r1fm+r2fm = 155.326

input #57 time: 0:11:15 | total time: 10:12:06


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
*********************************
*********************************
average of cosine similarity 0.999268237347387
highest_index [0]
highest [0.999268237347387]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9618048667907715 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9565212726593018 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9196410179138184 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9163019061088562 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9154348373413086 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 0.8902940154075623 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8762199878692627 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.874187707901001 for ['[CLS] award professor travelersry baby fingers be hall° feet occasion % overlap billga top [SEP]']
[Init] best rec loss: 0.8700031638145447 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.8699682950973511 for ['[CLS] est chiefager downtyle trade apart herself beautyuration serious finisheditical verde thighs zack [SEP]']
[Init] best perm rec loss: 0.8695088624954224 for ['[CLS] tradeurationtyleitical downager apart verde serious thighs finished beauty zack est chief herself [SEP]']
[Init] best perm rec loss: 0.8690589070320129 for ['[CLS]ageritical chief verde thighs aparttyle est beauty herself down serious trade zackuration finished [SEP]']
[Init] best perm rec loss: 0.8668156862258911 for ['[CLS] chiefager thighsuration down tradetyle apart zack serious estitical verde herself beauty finished [SEP]']
[Init] best perm rec loss: 0.864094614982605 for ['[CLS]uration chief beauty thighs zack trade apart verdetyle est seriousiticalager down finished herself [SEP]']
[Init] best perm rec loss: 0.8639208078384399 for ['[CLS] apart chief verdeurationager zack thighstyle finished down beauty trade herselfitical est serious [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.745 (perp=12.407, rec=0.264, cos=0.000), tot_loss_proj:3.459 [t=0.30s]
prediction: ['[CLS] sydney love kiss first story insight a revelation a lucivar good event pointedsm loving awarded [SEP]']
[ 100/2000] tot_loss=2.473 (perp=11.584, rec=0.156, cos=0.000), tot_loss_proj:3.521 [t=0.29s]
prediction: ['[CLS] inspirational love capture story story innocence isism the first capture trade thatsm innocence inspirational [SEP]']
[ 150/2000] tot_loss=2.358 (perp=11.173, rec=0.124, cos=0.000), tot_loss_proj:3.132 [t=0.30s]
prediction: ['[CLS] inspirational love capturing story story innocence isist the first capturing encounter thatsm innocence inspirational [SEP]']
[ 200/2000] tot_loss=1.986 (perp=9.376, rec=0.110, cos=0.000), tot_loss_proj:2.616 [t=0.31s]
prediction: ['[CLS] inspirational love capturing story story innocence is and the first capturing encounter that biography innocence inspirational [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.896 (perp=8.995, rec=0.097, cos=0.000), tot_loss_proj:2.411 [t=0.30s]
prediction: ['[CLS] inspirational love story capturing story innocence is and the first capturing encounter that ideal innocence inspirational [SEP]']
[ 300/2000] tot_loss=1.912 (perp=9.084, rec=0.095, cos=0.000), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS] inspirational love story, story innocence is and the first capturing encounter that ideal innocence inspirational [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.535 (perp=7.230, rec=0.089, cos=0.000), tot_loss_proj:2.008 [t=0.30s]
prediction: ['[CLS] inspirational love story is story innocence, and the first capturing encounter of idealism inspirational [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.536 (perp=7.230, rec=0.090, cos=0.000), tot_loss_proj:2.017 [t=0.30s]
prediction: ['[CLS] inspirational love story is story innocence, and the first capturing encounter of idealism inspirational [SEP]']
[ 450/2000] tot_loss=1.532 (perp=7.230, rec=0.086, cos=0.000), tot_loss_proj:2.020 [t=0.30s]
prediction: ['[CLS] inspirational love story is story innocence, and the first capturing encounter of idealism inspirational [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.416 (perp=6.735, rec=0.069, cos=0.000), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] inspirational love story is story capturing innocence, and the first encounter of idealism inspirational [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.538 (perp=7.277, rec=0.082, cos=0.000), tot_loss_proj:1.875 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing innocence, first the first encounter of idealism inspirational [SEP]']
[ 600/2000] tot_loss=1.536 (perp=7.277, rec=0.080, cos=0.000), tot_loss_proj:1.863 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing innocence, first the first encounter of idealism inspirational [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.449 (perp=6.814, rec=0.086, cos=0.000), tot_loss_proj:1.757 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing innocence, inspirational the first encounter of idealism first [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.395 (perp=6.566, rec=0.082, cos=0.000), tot_loss_proj:1.693 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing innocence, the inspirational first encounter of idealism first [SEP]']
[ 750/2000] tot_loss=1.525 (perp=7.227, rec=0.080, cos=0.000), tot_loss_proj:1.804 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing innocence, the inspirational that encounter of idealism first [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.380 (perp=6.516, rec=0.077, cos=0.000), tot_loss_proj:1.627 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.379 (perp=6.516, rec=0.076, cos=0.000), tot_loss_proj:1.631 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
[ 900/2000] tot_loss=1.381 (perp=6.516, rec=0.078, cos=0.000), tot_loss_proj:1.621 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.377 (perp=6.516, rec=0.074, cos=0.000), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[1000/2000] tot_loss=1.383 (perp=6.516, rec=0.080, cos=0.000), tot_loss_proj:1.625 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
[1050/2000] tot_loss=1.377 (perp=6.516, rec=0.074, cos=0.000), tot_loss_proj:1.629 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[1100/2000] tot_loss=1.369 (perp=6.516, rec=0.066, cos=0.000), tot_loss_proj:1.629 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[1150/2000] tot_loss=1.380 (perp=6.516, rec=0.077, cos=0.000), tot_loss_proj:1.624 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
[1200/2000] tot_loss=1.378 (perp=6.516, rec=0.075, cos=0.000), tot_loss_proj:1.625 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[1250/2000] tot_loss=1.379 (perp=6.516, rec=0.076, cos=0.000), tot_loss_proj:1.625 [t=0.29s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
[1300/2000] tot_loss=1.373 (perp=6.516, rec=0.069, cos=0.000), tot_loss_proj:1.631 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
[1350/2000] tot_loss=1.372 (perp=6.516, rec=0.069, cos=0.000), tot_loss_proj:1.626 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.320 (perp=6.223, rec=0.075, cos=0.000), tot_loss_proj:1.520 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[1450/2000] tot_loss=1.319 (perp=6.223, rec=0.074, cos=0.000), tot_loss_proj:1.519 [t=0.30s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
[1500/2000] tot_loss=1.325 (perp=6.223, rec=0.080, cos=0.000), tot_loss_proj:1.524 [t=0.36s]
prediction: ['[CLS] love story is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[1550/2000] tot_loss=1.436 (perp=6.793, rec=0.078, cos=0.000), tot_loss_proj:1.683 [t=0.30s]
prediction: ['[CLS] love is is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.352 (perp=6.403, rec=0.072, cos=0.000), tot_loss_proj:1.610 [t=0.30s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
[1650/2000] tot_loss=1.352 (perp=6.403, rec=0.071, cos=0.000), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[1700/2000] tot_loss=1.355 (perp=6.403, rec=0.075, cos=0.000), tot_loss_proj:1.620 [t=0.28s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[1750/2000] tot_loss=1.363 (perp=6.403, rec=0.083, cos=0.000), tot_loss_proj:1.622 [t=0.30s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
[1800/2000] tot_loss=1.360 (perp=6.403, rec=0.080, cos=0.000), tot_loss_proj:1.618 [t=0.31s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[1850/2000] tot_loss=1.362 (perp=6.403, rec=0.081, cos=0.000), tot_loss_proj:1.617 [t=0.29s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[1900/2000] tot_loss=1.353 (perp=6.403, rec=0.073, cos=0.000), tot_loss_proj:1.617 [t=0.29s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
[1950/2000] tot_loss=1.360 (perp=6.403, rec=0.079, cos=0.000), tot_loss_proj:1.616 [t=0.30s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Attempt swap
[2000/2000] tot_loss=1.350 (perp=6.403, rec=0.069, cos=0.000), tot_loss_proj:1.623 [t=0.30s]
prediction: ['[CLS] is love is inspirational story capturing that innocence, the inspirational first encounter of idealism [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] love story is inspirational story capturing that innocence, the inspirational encounter of idealism first [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 13.333 | p: 13.333 | r: 13.333
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 100.833

[Aggregate metrics]:
rouge1     | fm: 92.392 | p: 91.884 | r: 93.078
rouge2     | fm: 62.151 | p: 61.861 | r: 62.592
rougeL     | fm: 79.835 | p: 79.411 | r: 80.416
rougeLsum  | fm: 79.697 | p: 79.220 | r: 80.244
r1fm+r2fm = 154.543

input #58 time: 0:11:50 | total time: 10:23:57


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9992229438439673
highest_index [0]
highest [0.9992229438439673]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9162289500236511 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8992224931716919 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8989856243133545 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.8979661464691162 for ['[CLS] type tonight closer by creditsored curve salvadorrov county sparhawk obviousalis jax busyner [SEP]']
[Init] best rec loss: 0.8685634136199951 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.8683179020881653 for ['[CLS] het hill income rule helping icon minh were way lisa ufc these vampire skins notch good [SEP]']
[Init] best rec loss: 0.8592894077301025 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8308866024017334 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8302691578865051 for ['[CLS] fleetby tunnel information thus awhile noah wasak races temperament bologna stuff bobo pump 1993 [SEP]']
[Init] best perm rec loss: 0.8286914825439453 for ['[CLS]ak information bobo fleet stuff pump awhile races thus bologna 1993 noah temperament tunnelby was [SEP]']
[Init] best perm rec loss: 0.8286150693893433 for ['[CLS] stuff fleet information 1993by temperament pump bobo thus tunnelak races was noah bologna awhile [SEP]']
[Init] best perm rec loss: 0.8283534646034241 for ['[CLS] information fleet thus bobo pump 1993 noahby tunnel races awhile was stuffak bologna temperament [SEP]']
[Init] best perm rec loss: 0.8283429741859436 for ['[CLS] 1993 awhileak bologna temperament thus was pump noah boboby stuff fleet information tunnel races [SEP]']
[Init] best perm rec loss: 0.8259471654891968 for ['[CLS] bologna 1993 awhile fleet thus temperament stuff tunnel noahbyak pump was races bobo information [SEP]']
[Init] best perm rec loss: 0.8253877758979797 for ['[CLS]by fleet thus races temperamentak bobo 1993 tunnel awhile stuff noah pump was information bologna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.796 (perp=12.285, rec=0.339, cos=0.000), tot_loss_proj:3.818 [t=0.30s]
prediction: ['[CLS] extendedism teaches andbook a the offers na john victoria lucky proved woman regent design [SEP]']
[ 100/2000] tot_loss=2.609 (perp=11.872, rec=0.235, cos=0.000), tot_loss_proj:3.407 [t=0.29s]
prediction: ['[CLS] has char knows of passionate of pair offers na young india young the woman the char [SEP]']
[ 150/2000] tot_loss=2.325 (perp=10.728, rec=0.180, cos=0.000), tot_loss_proj:3.591 [t=0.30s]
prediction: ['[CLS] has char knows of knows a6 howist young woman young the woman holding char [SEP]']
[ 200/2000] tot_loss=2.334 (perp=10.924, rec=0.149, cos=0.000), tot_loss_proj:3.302 [t=0.30s]
prediction: ['[CLS] has char knows of knows a screen howist young woman young the woman hold char [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.990 (perp=9.200, rec=0.150, cos=0.000), tot_loss_proj:2.987 [t=0.27s]
prediction: ['[CLS] has char knows of how a screen knowsist young woman how the woman hold char [SEP]']
[ 300/2000] tot_loss=2.113 (perp=10.035, rec=0.106, cos=0.000), tot_loss_proj:3.153 [t=0.28s]
prediction: ['[CLS] hasism knows of how a screen knowsism young woman how the who hold char [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.949 (perp=9.175, rec=0.114, cos=0.000), tot_loss_proj:2.960 [t=0.28s]
prediction: ['[CLS] hasism knows of how a screen knows who young woman how theism hold char [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.894 (perp=8.999, rec=0.094, cos=0.000), tot_loss_proj:2.817 [t=0.28s]
prediction: ['[CLS] hasism knows of how a screen knows who the young woman howism hold char [SEP]']
[ 450/2000] tot_loss=1.782 (perp=8.433, rec=0.095, cos=0.000), tot_loss_proj:2.710 [t=0.28s]
prediction: ['[CLS] hasism knows of how a screen knows who the young woman howa hold char [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.740 (perp=8.307, rec=0.078, cos=0.000), tot_loss_proj:2.657 [t=0.27s]
prediction: ['[CLS] hasism knows of how a screen knows who the young woman chara hold how [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.744 (perp=8.362, rec=0.071, cos=0.000), tot_loss_proj:2.806 [t=0.27s]
prediction: ['[CLS] hasism knows of how a screen knows a who the young woman chara hold [SEP]']
[ 600/2000] tot_loss=1.883 (perp=9.017, rec=0.080, cos=0.000), tot_loss_proj:2.946 [t=0.27s]
prediction: ['[CLS] hasism knows of how a screen the a who the young woman chara hold [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.727 (perp=8.275, rec=0.072, cos=0.000), tot_loss_proj:2.806 [t=0.28s]
prediction: ['[CLS] hasism knows of how a screen the to who hold the young woman chara [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.673 (perp=8.021, rec=0.069, cos=0.000), tot_loss_proj:2.995 [t=0.28s]
prediction: ['[CLS] hasism knows of how a screen the hold to who the young woman chara [SEP]']
[ 750/2000] tot_loss=1.678 (perp=8.021, rec=0.073, cos=0.000), tot_loss_proj:2.995 [t=0.27s]
prediction: ['[CLS] hasism knows of how a screen the hold to who the young woman chara [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.584 (perp=7.550, rec=0.074, cos=0.000), tot_loss_proj:2.637 [t=0.26s]
prediction: ['[CLS] hasism knows of how a hold the screen to who the young woman chara [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.577 (perp=7.550, rec=0.067, cos=0.000), tot_loss_proj:2.651 [t=0.27s]
prediction: ['[CLS] hasism knows of how a hold the screen to who the young woman chara [SEP]']
[ 900/2000] tot_loss=1.570 (perp=7.550, rec=0.060, cos=0.000), tot_loss_proj:2.660 [t=0.27s]
prediction: ['[CLS] hasism knows of how a hold the screen to who the young woman chara [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.521 (perp=7.260, rec=0.069, cos=0.000), tot_loss_proj:2.146 [t=0.27s]
prediction: ['[CLS] hasism knows how a hold of the screen to who the young woman chara [SEP]']
Attempt swap
[1000/2000] tot_loss=1.529 (perp=7.260, rec=0.077, cos=0.000), tot_loss_proj:2.158 [t=0.27s]
prediction: ['[CLS] hasism knows how a hold of the screen to who the young woman chara [SEP]']
[1050/2000] tot_loss=1.524 (perp=7.260, rec=0.072, cos=0.000), tot_loss_proj:2.152 [t=0.26s]
prediction: ['[CLS] hasism knows how a hold of the screen to who the young woman chara [SEP]']
Attempt swap
[1100/2000] tot_loss=1.520 (perp=7.260, rec=0.068, cos=0.000), tot_loss_proj:2.151 [t=0.28s]
prediction: ['[CLS] hasism knows how a hold of the screen to who the young woman chara [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.411 (perp=6.697, rec=0.072, cos=0.000), tot_loss_proj:1.840 [t=0.28s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
[1200/2000] tot_loss=1.414 (perp=6.697, rec=0.075, cos=0.000), tot_loss_proj:1.840 [t=0.28s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
Attempt swap
[1250/2000] tot_loss=1.405 (perp=6.697, rec=0.065, cos=0.000), tot_loss_proj:1.839 [t=0.28s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
Attempt swap
[1300/2000] tot_loss=1.407 (perp=6.697, rec=0.067, cos=0.000), tot_loss_proj:1.846 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
[1350/2000] tot_loss=1.403 (perp=6.697, rec=0.064, cos=0.000), tot_loss_proj:1.842 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.697, rec=0.056, cos=0.000), tot_loss_proj:1.836 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
Attempt swap
[1450/2000] tot_loss=1.416 (perp=6.697, rec=0.076, cos=0.000), tot_loss_proj:1.839 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
[1500/2000] tot_loss=1.389 (perp=6.697, rec=0.050, cos=0.000), tot_loss_proj:1.848 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
Attempt swap
[1550/2000] tot_loss=1.406 (perp=6.697, rec=0.066, cos=0.000), tot_loss_proj:1.842 [t=0.26s]
prediction: ['[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.347 (perp=6.365, rec=0.074, cos=0.000), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] has knows how a hold of the screen to the young woman who charisma [SEP]']
[1650/2000] tot_loss=1.335 (perp=6.365, rec=0.062, cos=0.000), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to the young woman who charisma [SEP]']
Attempt swap
[1700/2000] tot_loss=1.332 (perp=6.365, rec=0.059, cos=0.000), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to the young woman who charisma [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.326 (perp=6.348, rec=0.057, cos=0.000), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to the young woman charisma who [SEP]']
[1800/2000] tot_loss=1.342 (perp=6.348, rec=0.073, cos=0.000), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] has knows how a hold of the screen to the young woman charisma who [SEP]']
Attempt swap
Put prefix at the end
[1850/2000] tot_loss=1.262 (perp=5.968, rec=0.068, cos=0.000), tot_loss_proj:1.872 [t=0.27s]
prediction: ['[CLS] who has knows how a hold of the screen to the young woman charisma [SEP]']
Attempt swap
[1900/2000] tot_loss=1.255 (perp=5.968, rec=0.061, cos=0.000), tot_loss_proj:1.871 [t=0.28s]
prediction: ['[CLS] who has knows how a hold of the screen to the young woman charisma [SEP]']
[1950/2000] tot_loss=1.258 (perp=5.968, rec=0.064, cos=0.000), tot_loss_proj:1.868 [t=0.28s]
prediction: ['[CLS] who has knows how a hold of the screen to the young woman charisma [SEP]']
Attempt swap
[2000/2000] tot_loss=1.266 (perp=5.968, rec=0.072, cos=0.000), tot_loss_proj:1.876 [t=0.27s]
prediction: ['[CLS] who has knows how a hold of the screen to the young woman charisma [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] has knows how a hold of the screen to who the young woman charisma [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 126.667

[Aggregate metrics]:
rouge1     | fm: 92.608 | p: 92.047 | r: 93.225
rouge2     | fm: 61.322 | p: 61.061 | r: 61.674
rougeL     | fm: 79.410 | p: 78.939 | r: 79.923
rougeLsum  | fm: 79.210 | p: 78.750 | r: 79.682
r1fm+r2fm = 153.930

input #59 time: 0:11:22 | total time: 10:35:19


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
*********************************
*********************************
average of cosine similarity 0.9993721482705427
highest_index [0]
highest [0.9993721482705427]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9260178804397583 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9138332009315491 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8756172060966492 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.873114824295044 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8547941446304321 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.8451055884361267 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.844318687915802 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 0.8405671715736389 for ['[CLS] constitution / majority upset plentyshawlbyouring through coveritude strung [SEP]']
[Init] best perm rec loss: 0.8402827382087708 for ['[CLS] /shawlbyitude majority cover through upset constitutionouring strung plenty [SEP]']
[Init] best perm rec loss: 0.8390963673591614 for ['[CLS]ouring /lby throughitude strung plenty constitution cover majority upsetshaw [SEP]']
[Init] best perm rec loss: 0.8384876847267151 for ['[CLS] / plentyouring strunglbyshaw constitutionitude majority through upset cover [SEP]']
[Init] best perm rec loss: 0.8381200432777405 for ['[CLS] strungitude constitution / upsetshaw coverouringlby through plenty majority [SEP]']
[Init] best perm rec loss: 0.8380623459815979 for ['[CLS]itude majority plentylbyshaw upset /ouring constitution through cover strung [SEP]']
[Init] best perm rec loss: 0.8373181223869324 for ['[CLS] strungitude / through upsetshaw constitution majorityouringlby plenty cover [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.063 (perp=13.641, rec=0.335, cos=0.000), tot_loss_proj:3.426 [t=0.26s]
prediction: ['[CLS] maori poor awkwardly phone scandal idiot hospital is progressive sox arrest depends [SEP]']
[ 100/2000] tot_loss=2.516 (perp=11.398, rec=0.237, cos=0.000), tot_loss_proj:2.823 [t=0.25s]
prediction: ['[CLS] is awkwardly awkwardly phone opera mall awkwardly is progressive sox israte [SEP]']
[ 150/2000] tot_loss=2.439 (perp=11.237, rec=0.191, cos=0.000), tot_loss_proj:2.755 [t=0.26s]
prediction: ['[CLS] is awkwardly awkwardly paced soap mall circuit is the dvd storyfor [SEP]']
[ 200/2000] tot_loss=2.087 (perp=9.622, rec=0.162, cos=0.000), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] is awkwardly awkwardly paced soap soap circuit is the circuit story is [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.974 (perp=9.156, rec=0.143, cos=0.000), tot_loss_proj:2.296 [t=0.25s]
prediction: ['[CLS] is awkwardly soap awkwardly paced soap circuit is the soap story is [SEP]']
[ 300/2000] tot_loss=2.019 (perp=9.414, rec=0.136, cos=0.000), tot_loss_proj:2.348 [t=0.27s]
prediction: ['[CLS] is awkwardly soap awkwardly paced soap circuit is the soap story - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.025 (perp=9.523, rec=0.120, cos=0.000), tot_loss_proj:2.382 [t=0.26s]
prediction: ['[CLS] is awkwardly soap awkwardly paced soap circuit is - soap story is [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.955 (perp=9.127, rec=0.129, cos=0.000), tot_loss_proj:2.296 [t=0.27s]
prediction: ['[CLS] - awkwardly soap the awkwardly paced soap circuit is soap story is [SEP]']
[ 450/2000] tot_loss=1.954 (perp=9.197, rec=0.115, cos=0.000), tot_loss_proj:2.259 [t=0.27s]
prediction: ['[CLS] - awkwardly soap the awkwardly paced opera circuit is soap story is [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.826 (perp=8.559, rec=0.114, cos=0.000), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] - awkwardly soap the awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.760 (perp=8.235, rec=0.113, cos=0.000), tot_loss_proj:2.178 [t=0.27s]
prediction: ['[CLS] theh soap - awkwardly paced story circuit is soap opera is [SEP]']
[ 600/2000] tot_loss=1.743 (perp=8.235, rec=0.096, cos=0.000), tot_loss_proj:2.180 [t=0.26s]
prediction: ['[CLS] theh soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.661 (perp=7.846, rec=0.091, cos=0.000), tot_loss_proj:2.100 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.659 (perp=7.846, rec=0.090, cos=0.000), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[ 750/2000] tot_loss=1.663 (perp=7.846, rec=0.093, cos=0.000), tot_loss_proj:2.108 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.663 (perp=7.846, rec=0.094, cos=0.000), tot_loss_proj:2.104 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.641 (perp=7.846, rec=0.071, cos=0.000), tot_loss_proj:2.098 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[ 900/2000] tot_loss=1.639 (perp=7.846, rec=0.070, cos=0.000), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.652 (perp=7.846, rec=0.083, cos=0.000), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.639 (perp=7.846, rec=0.070, cos=0.000), tot_loss_proj:2.103 [t=0.28s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1050/2000] tot_loss=1.639 (perp=7.846, rec=0.070, cos=0.000), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.655 (perp=7.846, rec=0.086, cos=0.000), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.640 (perp=7.846, rec=0.071, cos=0.000), tot_loss_proj:2.102 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1200/2000] tot_loss=1.643 (perp=7.846, rec=0.074, cos=0.000), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.644 (perp=7.846, rec=0.075, cos=0.000), tot_loss_proj:2.101 [t=0.25s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.641 (perp=7.846, rec=0.072, cos=0.000), tot_loss_proj:2.102 [t=0.29s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1350/2000] tot_loss=1.645 (perp=7.846, rec=0.076, cos=0.000), tot_loss_proj:2.102 [t=0.28s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.644 (perp=7.846, rec=0.075, cos=0.000), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.645 (perp=7.846, rec=0.076, cos=0.000), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1500/2000] tot_loss=1.654 (perp=7.846, rec=0.085, cos=0.000), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.846, rec=0.073, cos=0.000), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.643 (perp=7.846, rec=0.074, cos=0.000), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1650/2000] tot_loss=1.639 (perp=7.846, rec=0.070, cos=0.000), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.651 (perp=7.846, rec=0.082, cos=0.000), tot_loss_proj:2.103 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.644 (perp=7.846, rec=0.075, cos=0.000), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1800/2000] tot_loss=1.644 (perp=7.846, rec=0.075, cos=0.000), tot_loss_proj:2.107 [t=0.27s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.645 (perp=7.846, rec=0.076, cos=0.000), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.642 (perp=7.846, rec=0.072, cos=0.000), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
[1950/2000] tot_loss=1.654 (perp=7.846, rec=0.085, cos=0.000), tot_loss_proj:2.104 [t=0.28s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.639 (perp=7.846, rec=0.070, cos=0.000), tot_loss_proj:2.111 [t=0.28s]
prediction: ['[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS]h the soap - awkwardly paced story circuit is soap opera is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 76.923 | r: 90.909
rouge2     | fm: 27.273 | p: 25.000 | r: 30.000
rougeL     | fm: 58.333 | p: 53.846 | r: 63.636
rougeLsum  | fm: 58.333 | p: 53.846 | r: 63.636
r1fm+r2fm = 110.606

[Aggregate metrics]:
rouge1     | fm: 92.388 | p: 91.718 | r: 93.149
rouge2     | fm: 60.815 | p: 60.510 | r: 61.184
rougeL     | fm: 78.953 | p: 78.425 | r: 79.633
rougeLsum  | fm: 78.839 | p: 78.296 | r: 79.499
r1fm+r2fm = 153.203

input #60 time: 0:11:14 | total time: 10:46:34


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
*********************************
*********************************
average of cosine similarity 0.999284566963917
highest_index [0]
highest [0.999284566963917]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9807907938957214 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.972777247428894 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.951108992099762 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9471060037612915 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9461003541946411 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9359208941459656 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.919204592704773 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9123846888542175 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9054304957389832 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.8742703199386597 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.823196530342102 for ['[CLS] request lets mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.793 (perp=7.753, rec=0.242, cos=0.000), tot_loss_proj:1.795 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.700 (perp=7.753, rec=0.150, cos=0.000), tot_loss_proj:1.801 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 150/2000] tot_loss=1.683 (perp=7.753, rec=0.133, cos=0.000), tot_loss_proj:1.801 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 200/2000] tot_loss=1.671 (perp=7.753, rec=0.121, cos=0.000), tot_loss_proj:1.805 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.488 (perp=7.102, rec=0.067, cos=0.000), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.477 (perp=7.102, rec=0.057, cos=0.000), tot_loss_proj:1.605 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.485 (perp=7.102, rec=0.065, cos=0.000), tot_loss_proj:1.610 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.487 (perp=7.102, rec=0.066, cos=0.000), tot_loss_proj:1.622 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.490 (perp=7.102, rec=0.070, cos=0.000), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.486 (perp=7.102, rec=0.066, cos=0.000), tot_loss_proj:1.606 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.488 (perp=7.102, rec=0.068, cos=0.000), tot_loss_proj:1.620 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.488 (perp=7.102, rec=0.067, cos=0.000), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.496 (perp=7.102, rec=0.075, cos=0.000), tot_loss_proj:1.609 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.473 (perp=7.102, rec=0.053, cos=0.000), tot_loss_proj:1.615 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.489 (perp=7.102, rec=0.069, cos=0.000), tot_loss_proj:1.616 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.488 (perp=7.102, rec=0.068, cos=0.000), tot_loss_proj:1.629 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.480 (perp=7.102, rec=0.059, cos=0.000), tot_loss_proj:1.611 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.490 (perp=7.102, rec=0.070, cos=0.000), tot_loss_proj:1.616 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.492 (perp=7.102, rec=0.072, cos=0.000), tot_loss_proj:1.615 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.492 (perp=7.102, rec=0.072, cos=0.000), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.485 (perp=7.102, rec=0.064, cos=0.000), tot_loss_proj:1.613 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.484 (perp=7.102, rec=0.063, cos=0.000), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.489 (perp=7.102, rec=0.069, cos=0.000), tot_loss_proj:1.619 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.473 (perp=7.102, rec=0.053, cos=0.000), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.477 (perp=7.102, rec=0.057, cos=0.000), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.480 (perp=7.102, rec=0.059, cos=0.000), tot_loss_proj:1.619 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.493 (perp=7.102, rec=0.072, cos=0.000), tot_loss_proj:1.616 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.484 (perp=7.102, rec=0.063, cos=0.000), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=7.102, rec=0.073, cos=0.000), tot_loss_proj:1.597 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.487 (perp=7.102, rec=0.066, cos=0.000), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.490 (perp=7.102, rec=0.070, cos=0.000), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.486 (perp=7.102, rec=0.066, cos=0.000), tot_loss_proj:1.608 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.485 (perp=7.102, rec=0.065, cos=0.000), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.479 (perp=7.102, rec=0.059, cos=0.000), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.476 (perp=7.102, rec=0.056, cos=0.000), tot_loss_proj:1.612 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.490 (perp=7.102, rec=0.069, cos=0.000), tot_loss_proj:1.620 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.488 (perp=7.102, rec=0.068, cos=0.000), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.490 (perp=7.102, rec=0.070, cos=0.000), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.482 (perp=7.102, rec=0.062, cos=0.000), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.470 (perp=7.102, rec=0.050, cos=0.000), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.462 | p: 91.827 | r: 93.194
rouge2     | fm: 61.246 | p: 60.899 | r: 61.671
rougeL     | fm: 79.442 | p: 78.920 | r: 80.078
rougeLsum  | fm: 79.196 | p: 78.638 | r: 79.776
r1fm+r2fm = 153.708

input #61 time: 0:11:09 | total time: 10:57:43


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
*********************************
*********************************
average of cosine similarity 0.9992558954217241
highest_index [0]
highest [0.9992558954217241]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.957578718662262 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9302873015403748 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.9183879494667053 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best perm rec loss: 0.9183876514434814 for ['[CLS] persian cardslonmund pits trap theater record percentage dread dan freestyle sackshur existedzing dancegoldee shape sacred [SEP]']
[Init] best perm rec loss: 0.918329656124115 for ['[CLS] percentage existedlon recordgoldmundhur theater sacks dread pits trap dan freestyle sacred shape dancezing persianee cards [SEP]']
[Init] best perm rec loss: 0.9171617031097412 for ['[CLS] theater pits existed sacred cards percentagegold dan shapezing persian sacks dance dread trap recordlonhur freestyleeemund [SEP]']
[Init] best perm rec loss: 0.9169938564300537 for ['[CLS]mundhur theateree sacks shape dan sacred cards persianzing record freestylegold percentage dance pits trap existed dreadlon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.676 (perp=11.574, rec=0.362, cos=0.000), tot_loss_proj:2.990 [t=0.26s]
prediction: ['[CLS] hit good biography grace people grace a. cards story ranch frank donation values when challenging the make talent noir best [SEP]']
[ 100/2000] tot_loss=2.105 (perp=9.250, rec=0.255, cos=0.000), tot_loss_proj:3.005 [t=0.28s]
prediction: ['[CLS] classic best movies grace ever grace one the cards war movie to prevention it when challenging the make grace noir best [SEP]']
[ 150/2000] tot_loss=1.933 (perp=8.624, rec=0.208, cos=0.000), tot_loss_proj:2.408 [t=0.27s]
prediction: ['[CLS] classic best movies grace ever grace - the war war movies to prevention narrative through to making with movies truly best [SEP]']
[ 200/2000] tot_loss=2.269 (perp=10.497, rec=0.170, cos=0.000), tot_loss_proj:3.903 [t=0.27s]
prediction: ['[CLS] one among movies grace ever grace it one war war call to prevention resulted without to making making movies truly best [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.172 (perp=9.723, rec=0.227, cos=0.000), tot_loss_proj:3.765 [t=0.28s]
prediction: ['[CLS] one among movies grace ever grace it [SEP] prevention war call to prevention signal rather of making war movie quietly best [SEP]']
[ 300/2000] tot_loss=2.123 (perp=9.913, rec=0.141, cos=0.000), tot_loss_proj:3.743 [t=0.26s]
prediction: ['[CLS] one of movies grace ever grace it [SEP] blame war call to prevention call rather to making war movie even best [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.007 (perp=9.424, rec=0.122, cos=0.000), tot_loss_proj:3.694 [t=0.26s]
prediction: ['[CLS] one of movies grace ever grace it call [SEP] blame war to prevention call rather to making war movie made best [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.972 (perp=9.254, rec=0.121, cos=0.000), tot_loss_proj:3.711 [t=0.26s]
prediction: ['[CLS] one the movies to ever grace it call [SEP] blame war to prevention than rather grace making war made made best [SEP]']
[ 450/2000] tot_loss=1.959 (perp=9.254, rec=0.108, cos=0.000), tot_loss_proj:3.715 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace it call [SEP] blame war to prevention than rather grace making war made made best [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.882 (perp=8.840, rec=0.114, cos=0.000), tot_loss_proj:3.619 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] blame war than rather grace making war made made best [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.852 (perp=8.791, rec=0.094, cos=0.000), tot_loss_proj:3.641 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] blame grace than rather war making war made made best [SEP]']
[ 600/2000] tot_loss=1.854 (perp=8.791, rec=0.096, cos=0.000), tot_loss_proj:3.639 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] blame grace than rather war making war made made best [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.794 (perp=8.504, rec=0.093, cos=0.000), tot_loss_proj:3.573 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] blame grace than rather making war made war made best [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.779 (perp=8.401, rec=0.099, cos=0.000), tot_loss_proj:3.548 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] than blame grace rather making war made war made best [SEP]']
[ 750/2000] tot_loss=1.782 (perp=8.401, rec=0.101, cos=0.000), tot_loss_proj:3.550 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] than blame grace rather making war made war made best [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.766 (perp=8.401, rec=0.086, cos=0.000), tot_loss_proj:3.553 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace it call to prevention [SEP] than blame grace rather making war made war made best [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.821 (perp=8.621, rec=0.097, cos=0.000), tot_loss_proj:3.570 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to prevention [SEP] than blame it rather making war made war place best [SEP]']
[ 900/2000] tot_loss=1.815 (perp=8.621, rec=0.091, cos=0.000), tot_loss_proj:3.572 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to prevention [SEP] than blame it rather making war made war place best [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.763 (perp=8.341, rec=0.095, cos=0.000), tot_loss_proj:3.533 [t=0.26s]
prediction: ['[CLS] one the movies to ever grace grace call to prevention [SEP] rather than blame it making war made war place best [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.752 (perp=8.286, rec=0.095, cos=0.000), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS] one the movies to ever grace grace call to prevention the rather than blame making it war made war place best [SEP]']
[1050/2000] tot_loss=1.750 (perp=8.286, rec=0.093, cos=0.000), tot_loss_proj:3.385 [t=0.30s]
prediction: ['[CLS] one the movies to ever grace grace call to prevention the rather than blame making it war made war place best [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.672 (perp=7.917, rec=0.089, cos=0.000), tot_loss_proj:3.261 [t=0.30s]
prediction: ['[CLS] one the movies to ever grace grace call to the prevention rather than blame making it war made war place best [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.633 (perp=7.668, rec=0.099, cos=0.000), tot_loss_proj:3.226 [t=0.30s]
prediction: ['[CLS] one the movies to ever grace grace call to the prevention rather than blame making place war made war it best [SEP]']
[1200/2000] tot_loss=1.624 (perp=7.668, rec=0.090, cos=0.000), tot_loss_proj:3.228 [t=0.30s]
prediction: ['[CLS] one the movies to ever grace grace call to the prevention rather than blame making place war made war it best [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.568 (perp=7.358, rec=0.096, cos=0.000), tot_loss_proj:3.174 [t=0.29s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
Attempt swap
[1300/2000] tot_loss=1.547 (perp=7.358, rec=0.075, cos=0.000), tot_loss_proj:3.177 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
[1350/2000] tot_loss=1.562 (perp=7.358, rec=0.090, cos=0.000), tot_loss_proj:3.175 [t=0.29s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
Attempt swap
[1400/2000] tot_loss=1.567 (perp=7.358, rec=0.096, cos=0.000), tot_loss_proj:3.178 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
Attempt swap
[1450/2000] tot_loss=1.565 (perp=7.358, rec=0.093, cos=0.000), tot_loss_proj:3.177 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
[1500/2000] tot_loss=1.563 (perp=7.358, rec=0.091, cos=0.000), tot_loss_proj:3.177 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
Attempt swap
[1550/2000] tot_loss=1.565 (perp=7.358, rec=0.093, cos=0.000), tot_loss_proj:3.175 [t=0.26s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war made war it best [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.552 (perp=7.324, rec=0.087, cos=0.000), tot_loss_proj:3.145 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.324, rec=0.096, cos=0.000), tot_loss_proj:3.146 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
Attempt swap
[1700/2000] tot_loss=1.553 (perp=7.324, rec=0.089, cos=0.000), tot_loss_proj:3.146 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
Attempt swap
[1750/2000] tot_loss=1.554 (perp=7.324, rec=0.090, cos=0.000), tot_loss_proj:3.145 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
[1800/2000] tot_loss=1.557 (perp=7.324, rec=0.093, cos=0.000), tot_loss_proj:3.144 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
Attempt swap
[1850/2000] tot_loss=1.559 (perp=7.324, rec=0.094, cos=0.000), tot_loss_proj:3.142 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
Attempt swap
[1900/2000] tot_loss=1.560 (perp=7.324, rec=0.095, cos=0.000), tot_loss_proj:3.146 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.324, rec=0.091, cos=0.000), tot_loss_proj:3.149 [t=0.27s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.324, rec=0.092, cos=0.000), tot_loss_proj:3.148 [t=0.28s]
prediction: ['[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] one the movies to ever grace grace call to making prevention rather than blame the place war war made it best [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 86.957 | r: 90.909
rouge2     | fm: 9.302 | p: 9.091 | r: 9.524
rougeL     | fm: 48.889 | p: 47.826 | r: 50.000
rougeLsum  | fm: 48.889 | p: 47.826 | r: 50.000
r1fm+r2fm = 98.191

[Aggregate metrics]:
rouge1     | fm: 92.424 | p: 91.782 | r: 93.209
rouge2     | fm: 60.530 | p: 60.191 | r: 61.005
rougeL     | fm: 78.930 | p: 78.404 | r: 79.605
rougeLsum  | fm: 78.716 | p: 78.147 | r: 79.334
r1fm+r2fm = 152.954

input #62 time: 0:11:25 | total time: 11:09:09


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
*********************************
*********************************
average of cosine similarity 0.9992641321002576
highest_index [0]
highest [0.9992641321002576]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9540460109710693 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9015830159187317 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.744281530380249 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7419572472572327 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7275969386100769 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7271380424499512 for ['[CLS]... solutions forces civil offense [SEP]']
[Init] best perm rec loss: 0.7270265221595764 for ['[CLS] solutions forces offense civil... [SEP]']
[Init] best perm rec loss: 0.7268968224525452 for ['[CLS] civil... forces offense solutions [SEP]']
[Init] best perm rec loss: 0.7266950607299805 for ['[CLS] offense solutions... civil forces [SEP]']
[Init] best perm rec loss: 0.7265195250511169 for ['[CLS] solutions forces civil offense... [SEP]']
[Init] best perm rec loss: 0.7261634469032288 for ['[CLS] civil forces solutions offense... [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.019 (perp=12.737, rec=0.472, cos=0.000), tot_loss_proj:3.765 [t=0.30s]
prediction: ['[CLS] money failing debt uh failed [SEP]']
[ 100/2000] tot_loss=2.502 (perp=11.021, rec=0.298, cos=0.000), tot_loss_proj:2.967 [t=0.28s]
prediction: ['[CLS] electronics seeking ticket ticket off [SEP]']
[ 150/2000] tot_loss=2.159 (perp=9.769, rec=0.205, cos=0.000), tot_loss_proj:3.447 [t=0.29s]
prediction: ['[CLS] ticket seeking looking ticket ticket [SEP]']
[ 200/2000] tot_loss=2.422 (perp=11.271, rec=0.167, cos=0.000), tot_loss_proj:3.220 [t=0.28s]
prediction: ['[CLS] ticket looking looking return ticket [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.078 (perp=9.766, rec=0.125, cos=0.000), tot_loss_proj:3.093 [t=0.28s]
prediction: ['[CLS] ticket return ticket looking looking [SEP]']
[ 300/2000] tot_loss=1.932 (perp=9.193, rec=0.094, cos=0.000), tot_loss_proj:2.587 [t=0.27s]
prediction: ['[CLS] ticket return ticket looking for [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.651 (perp=7.788, rec=0.094, cos=0.000), tot_loss_proj:2.434 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.639 (perp=7.788, rec=0.082, cos=0.000), tot_loss_proj:2.434 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[ 450/2000] tot_loss=1.643 (perp=7.788, rec=0.085, cos=0.000), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.648 (perp=7.788, rec=0.091, cos=0.000), tot_loss_proj:2.430 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.633 (perp=7.788, rec=0.076, cos=0.000), tot_loss_proj:2.435 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[ 600/2000] tot_loss=1.632 (perp=7.788, rec=0.074, cos=0.000), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.638 (perp=7.788, rec=0.080, cos=0.000), tot_loss_proj:2.426 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.624 (perp=7.788, rec=0.067, cos=0.000), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[ 750/2000] tot_loss=1.631 (perp=7.788, rec=0.073, cos=0.000), tot_loss_proj:2.431 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.638 (perp=7.788, rec=0.081, cos=0.000), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.636 (perp=7.788, rec=0.078, cos=0.000), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[ 900/2000] tot_loss=1.632 (perp=7.788, rec=0.075, cos=0.000), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.635 (perp=7.788, rec=0.077, cos=0.000), tot_loss_proj:2.429 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.634 (perp=7.788, rec=0.077, cos=0.000), tot_loss_proj:2.430 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1050/2000] tot_loss=1.638 (perp=7.788, rec=0.080, cos=0.000), tot_loss_proj:2.431 [t=0.28s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.636 (perp=7.788, rec=0.078, cos=0.000), tot_loss_proj:2.429 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.633 (perp=7.788, rec=0.076, cos=0.000), tot_loss_proj:2.430 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1200/2000] tot_loss=1.639 (perp=7.788, rec=0.081, cos=0.000), tot_loss_proj:2.428 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.625 (perp=7.788, rec=0.068, cos=0.000), tot_loss_proj:2.429 [t=0.25s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.634 (perp=7.788, rec=0.076, cos=0.000), tot_loss_proj:2.438 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1350/2000] tot_loss=1.632 (perp=7.788, rec=0.074, cos=0.000), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.627 (perp=7.788, rec=0.070, cos=0.000), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.635 (perp=7.788, rec=0.077, cos=0.000), tot_loss_proj:2.429 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1500/2000] tot_loss=1.636 (perp=7.788, rec=0.079, cos=0.000), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.633 (perp=7.788, rec=0.075, cos=0.000), tot_loss_proj:2.432 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.633 (perp=7.788, rec=0.075, cos=0.000), tot_loss_proj:2.431 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1650/2000] tot_loss=1.630 (perp=7.788, rec=0.072, cos=0.000), tot_loss_proj:2.431 [t=0.25s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.628 (perp=7.788, rec=0.070, cos=0.000), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.634 (perp=7.788, rec=0.076, cos=0.000), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1800/2000] tot_loss=1.624 (perp=7.788, rec=0.066, cos=0.000), tot_loss_proj:2.435 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.630 (perp=7.788, rec=0.072, cos=0.000), tot_loss_proj:2.430 [t=0.27s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.629 (perp=7.788, rec=0.071, cos=0.000), tot_loss_proj:2.435 [t=0.25s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[1950/2000] tot_loss=1.630 (perp=7.788, rec=0.072, cos=0.000), tot_loss_proj:2.426 [t=0.28s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.630 (perp=7.788, rec=0.073, cos=0.000), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] ticket return looking for ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 92.307 | p: 91.624 | r: 93.095
rouge2     | fm: 60.240 | p: 59.923 | r: 60.602
rougeL     | fm: 78.714 | p: 78.127 | r: 79.327
rougeLsum  | fm: 78.649 | p: 78.099 | r: 79.221
r1fm+r2fm = 152.547

input #63 time: 0:11:16 | total time: 11:20:26


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
*********************************
*********************************
average of cosine similarity 0.9991609700381362
highest_index [0]
highest [0.9991609700381362]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8792434334754944 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8661943674087524 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.7239647507667542 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6714571714401245 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6710698008537292 for ['[CLS]onale visions water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.135 (perp=9.190, rec=0.297, cos=0.000), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 100/2000] tot_loss=2.025 (perp=9.190, rec=0.187, cos=0.000), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 150/2000] tot_loss=1.992 (perp=9.190, rec=0.154, cos=0.000), tot_loss_proj:2.115 [t=0.28s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 200/2000] tot_loss=1.976 (perp=9.190, rec=0.138, cos=0.000), tot_loss_proj:2.128 [t=0.26s]
prediction: ['[CLS] strange strange horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.947 (perp=9.190, rec=0.109, cos=0.000), tot_loss_proj:2.125 [t=0.26s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.685 (perp=8.065, rec=0.072, cos=0.000), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.686 (perp=8.065, rec=0.073, cos=0.000), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.674 (perp=8.065, rec=0.061, cos=0.000), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.673 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=8.065, rec=0.067, cos=0.000), tot_loss_proj:1.715 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.000), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.681 (perp=8.065, rec=0.068, cos=0.000), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.675 (perp=8.065, rec=0.062, cos=0.000), tot_loss_proj:1.703 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.680 (perp=8.065, rec=0.067, cos=0.000), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.669 (perp=8.065, rec=0.056, cos=0.000), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.667 (perp=8.065, rec=0.054, cos=0.000), tot_loss_proj:1.693 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.673 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.703 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.669 (perp=8.065, rec=0.056, cos=0.000), tot_loss_proj:1.709 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.668 (perp=8.065, rec=0.055, cos=0.000), tot_loss_proj:1.709 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.669 (perp=8.065, rec=0.057, cos=0.000), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.000), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.673 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.672 (perp=8.065, rec=0.059, cos=0.000), tot_loss_proj:1.709 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.666 (perp=8.065, rec=0.053, cos=0.000), tot_loss_proj:1.708 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.684 (perp=8.065, rec=0.071, cos=0.000), tot_loss_proj:1.705 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.673 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.707 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.684 (perp=8.065, rec=0.071, cos=0.000), tot_loss_proj:1.709 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.671 (perp=8.065, rec=0.058, cos=0.000), tot_loss_proj:1.710 [t=0.34s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=8.065, rec=0.063, cos=0.000), tot_loss_proj:1.707 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.000), tot_loss_proj:1.709 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.675 (perp=8.065, rec=0.062, cos=0.000), tot_loss_proj:1.720 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.000), tot_loss_proj:1.700 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.666 (perp=8.065, rec=0.053, cos=0.000), tot_loss_proj:1.718 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.671 (perp=8.065, rec=0.058, cos=0.000), tot_loss_proj:1.721 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.662 (perp=8.065, rec=0.049, cos=0.000), tot_loss_proj:1.708 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.673 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.710 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.677 (perp=8.065, rec=0.064, cos=0.000), tot_loss_proj:1.709 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=8.065, rec=0.059, cos=0.000), tot_loss_proj:1.709 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.065, rec=0.063, cos=0.000), tot_loss_proj:1.724 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.000), tot_loss_proj:1.708 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.417 | p: 91.789 | r: 93.152
rouge2     | fm: 60.950 | p: 60.722 | r: 61.320
rougeL     | fm: 78.968 | p: 78.401 | r: 79.608
rougeLsum  | fm: 79.091 | p: 78.571 | r: 79.693
r1fm+r2fm = 153.367

input #64 time: 0:11:17 | total time: 11:31:43


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
*********************************
*********************************
average of cosine similarity 0.9992259564973898
highest_index [0]
highest [0.9992259564973898]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.022931694984436 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9583079218864441 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9501063823699951 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9471226930618286 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.885361909866333 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8774837255477905 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8763042092323303 for ['[CLS] fun someday news generalmament overs puhoff even [SEP]']
[Init] best perm rec loss: 0.8738518357276917 for ['[CLS] someday news overs evenmamenthoff pu fun general [SEP]']
[Init] best perm rec loss: 0.8727050423622131 for ['[CLS] pu news evenhoff overs someday generalmament fun [SEP]']
[Init] best perm rec loss: 0.8726363778114319 for ['[CLS] general someday pu newsmament funhoff overs even [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.830 (perp=12.313, rec=0.368, cos=0.000), tot_loss_proj:3.068 [t=0.33s]
prediction: ['[CLS] joy fortune r thoughts joy breathless lake asia even [SEP]']
[ 100/2000] tot_loss=2.335 (perp=10.427, rec=0.250, cos=0.000), tot_loss_proj:2.624 [t=0.32s]
prediction: ['[CLS] joy zoological,ur joyous film anglia, [SEP]']
[ 150/2000] tot_loss=2.333 (perp=10.872, rec=0.159, cos=0.000), tot_loss_proj:2.849 [t=0.29s]
prediction: ['[CLS] joy film, of romous filmous even [SEP]']
[ 200/2000] tot_loss=2.303 (perp=10.872, rec=0.128, cos=0.000), tot_loss_proj:2.859 [t=0.28s]
prediction: ['[CLS] joy film, of romous filmous even [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.614 (perp=7.401, rec=0.134, cos=0.000), tot_loss_proj:2.324 [t=0.28s]
prediction: ['[CLS] joy film, of romous, film. [SEP]']
[ 300/2000] tot_loss=1.579 (perp=7.401, rec=0.099, cos=0.000), tot_loss_proj:2.289 [t=0.25s]
prediction: ['[CLS] joy film, of romous, film. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.463 (perp=6.829, rec=0.097, cos=0.000), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] joyous film, of rom, film. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.305 (perp=5.993, rec=0.107, cos=0.000), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] joyous film, a rom of film. [SEP]']
[ 450/2000] tot_loss=1.289 (perp=5.993, rec=0.090, cos=0.000), tot_loss_proj:1.526 [t=0.27s]
prediction: ['[CLS] joyous film, a rom of film. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.209 (perp=5.629, rec=0.083, cos=0.000), tot_loss_proj:1.499 [t=0.27s]
prediction: ['[CLS] joyous rom, a film of film. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.208 (perp=5.629, rec=0.083, cos=0.000), tot_loss_proj:1.490 [t=0.26s]
prediction: ['[CLS] joyous rom, a film of film. [SEP]']
[ 600/2000] tot_loss=1.306 (perp=6.092, rec=0.087, cos=0.000), tot_loss_proj:2.043 [t=0.27s]
prediction: ['[CLS] joyous rom, a filmp film. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=0.995 (perp=4.546, rec=0.086, cos=0.000), tot_loss_proj:1.203 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.990 (perp=4.546, rec=0.081, cos=0.000), tot_loss_proj:1.201 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[ 750/2000] tot_loss=0.997 (perp=4.546, rec=0.088, cos=0.000), tot_loss_proj:1.200 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.007 (perp=4.546, rec=0.098, cos=0.000), tot_loss_proj:1.201 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.003 (perp=4.546, rec=0.094, cos=0.000), tot_loss_proj:1.207 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[ 900/2000] tot_loss=0.995 (perp=4.546, rec=0.085, cos=0.000), tot_loss_proj:1.198 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.997 (perp=4.546, rec=0.088, cos=0.000), tot_loss_proj:1.199 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.984 (perp=4.546, rec=0.075, cos=0.000), tot_loss_proj:1.199 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1050/2000] tot_loss=0.996 (perp=4.546, rec=0.087, cos=0.000), tot_loss_proj:1.197 [t=0.28s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.992 (perp=4.546, rec=0.082, cos=0.000), tot_loss_proj:1.205 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.994 (perp=4.546, rec=0.085, cos=0.000), tot_loss_proj:1.195 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1200/2000] tot_loss=0.991 (perp=4.546, rec=0.082, cos=0.000), tot_loss_proj:1.201 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.988 (perp=4.546, rec=0.079, cos=0.000), tot_loss_proj:1.204 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.002 (perp=4.546, rec=0.093, cos=0.000), tot_loss_proj:1.208 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1350/2000] tot_loss=0.991 (perp=4.546, rec=0.082, cos=0.000), tot_loss_proj:1.201 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.995 (perp=4.546, rec=0.086, cos=0.000), tot_loss_proj:1.202 [t=0.28s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.001 (perp=4.546, rec=0.092, cos=0.000), tot_loss_proj:1.203 [t=0.28s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1500/2000] tot_loss=0.982 (perp=4.546, rec=0.073, cos=0.000), tot_loss_proj:1.202 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.177 (perp=5.452, rec=0.086, cos=0.000), tot_loss_proj:1.579 [t=0.25s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.169 (perp=5.452, rec=0.079, cos=0.000), tot_loss_proj:1.571 [t=0.26s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
[1650/2000] tot_loss=1.167 (perp=5.452, rec=0.076, cos=0.000), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.163 (perp=5.452, rec=0.072, cos=0.000), tot_loss_proj:1.582 [t=0.29s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.171 (perp=5.452, rec=0.081, cos=0.000), tot_loss_proj:1.574 [t=0.27s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
[1800/2000] tot_loss=1.177 (perp=5.452, rec=0.086, cos=0.000), tot_loss_proj:1.575 [t=0.26s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.164 (perp=5.452, rec=0.074, cos=0.000), tot_loss_proj:1.579 [t=0.27s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.174 (perp=5.452, rec=0.084, cos=0.000), tot_loss_proj:1.579 [t=0.26s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
[1950/2000] tot_loss=1.174 (perp=5.452, rec=0.084, cos=0.000), tot_loss_proj:1.575 [t=0.26s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.174 (perp=5.452, rec=0.084, cos=0.000), tot_loss_proj:1.574 [t=0.27s]
prediction: ['[CLS] joyousp, a romp film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous film, a romp film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 92.307 | p: 91.694 | r: 93.076
rouge2     | fm: 60.430 | p: 60.156 | r: 60.746
rougeL     | fm: 78.966 | p: 78.426 | r: 79.570
rougeLsum  | fm: 78.940 | p: 78.439 | r: 79.523
r1fm+r2fm = 152.736

input #65 time: 0:11:19 | total time: 11:43:02


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
*********************************
*********************************
average of cosine similarity 0.9992329221317826
highest_index [0]
highest [0.9992329221317826]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.9712681174278259 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9281011819839478 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9187041521072388 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8865641355514526 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8741660714149475 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.87413090467453 for ['[CLS]beersa two bryce [SEP]']
[Init] best perm rec loss: 0.8721376061439514 for ['[CLS] twobee brycersa [SEP]']
[Init] best perm rec loss: 0.8711047172546387 for ['[CLS]bee tworsa bryce [SEP]']
[Init] best perm rec loss: 0.8708147406578064 for ['[CLS] twobeersa bryce [SEP]']
[Init] best perm rec loss: 0.8693501353263855 for ['[CLS] two brycersabee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.871 (perp=7.998, rec=0.271, cos=0.000), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] longtime fan fan fan [SEP]']
[ 100/2000] tot_loss=1.835 (perp=8.534, rec=0.128, cos=0.000), tot_loss_proj:1.947 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan fan [SEP]']
[ 150/2000] tot_loss=1.815 (perp=8.534, rec=0.108, cos=0.000), tot_loss_proj:1.942 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan fan [SEP]']
[ 200/2000] tot_loss=1.810 (perp=8.534, rec=0.103, cos=0.000), tot_loss_proj:1.935 [t=0.27s]
prediction: ['[CLS] longtime tolkien fan fan [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.726 (perp=8.227, rec=0.081, cos=0.000), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
[ 300/2000] tot_loss=1.739 (perp=8.227, rec=0.093, cos=0.000), tot_loss_proj:1.921 [t=0.25s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.741 (perp=8.227, rec=0.096, cos=0.000), tot_loss_proj:1.926 [t=0.28s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.740 (perp=8.227, rec=0.094, cos=0.000), tot_loss_proj:1.917 [t=0.26s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
[ 450/2000] tot_loss=1.855 (perp=8.773, rec=0.101, cos=0.000), tot_loss_proj:1.962 [t=0.29s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.844 (perp=8.773, rec=0.090, cos=0.000), tot_loss_proj:1.962 [t=0.27s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.848 (perp=8.773, rec=0.093, cos=0.000), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.821 (perp=8.773, rec=0.066, cos=0.000), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.835 (perp=8.773, rec=0.080, cos=0.000), tot_loss_proj:1.968 [t=0.27s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.606 (perp=7.673, rec=0.071, cos=0.000), tot_loss_proj:1.605 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.673, rec=0.060, cos=0.000), tot_loss_proj:1.593 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.600 (perp=7.673, rec=0.065, cos=0.000), tot_loss_proj:1.597 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=7.673, rec=0.062, cos=0.000), tot_loss_proj:1.603 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.601 (perp=7.673, rec=0.066, cos=0.000), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.673, rec=0.060, cos=0.000), tot_loss_proj:1.592 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.594 (perp=7.673, rec=0.060, cos=0.000), tot_loss_proj:1.605 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.673, rec=0.062, cos=0.000), tot_loss_proj:1.602 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.599 (perp=7.673, rec=0.064, cos=0.000), tot_loss_proj:1.599 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.596 (perp=7.673, rec=0.062, cos=0.000), tot_loss_proj:1.592 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.582 (perp=7.673, rec=0.048, cos=0.000), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.673, rec=0.060, cos=0.000), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.597 (perp=7.673, rec=0.062, cos=0.000), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.673, rec=0.052, cos=0.000), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.583 (perp=7.673, rec=0.049, cos=0.000), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.589 (perp=7.673, rec=0.054, cos=0.000), tot_loss_proj:1.601 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.610 (perp=7.673, rec=0.075, cos=0.000), tot_loss_proj:1.594 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=7.673, rec=0.058, cos=0.000), tot_loss_proj:1.603 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.596 (perp=7.673, rec=0.062, cos=0.000), tot_loss_proj:1.589 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.605 (perp=7.673, rec=0.070, cos=0.000), tot_loss_proj:1.594 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.589 (perp=7.673, rec=0.054, cos=0.000), tot_loss_proj:1.604 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.597 (perp=7.673, rec=0.062, cos=0.000), tot_loss_proj:1.600 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.673, rec=0.059, cos=0.000), tot_loss_proj:1.598 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.673, rec=0.049, cos=0.000), tot_loss_proj:1.594 [t=0.32s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.588 (perp=7.673, rec=0.053, cos=0.000), tot_loss_proj:1.589 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.594 (perp=7.673, rec=0.059, cos=0.000), tot_loss_proj:1.600 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.592 (perp=7.673, rec=0.058, cos=0.000), tot_loss_proj:1.606 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.482 | p: 91.841 | r: 93.212
rouge2     | fm: 61.198 | p: 60.906 | r: 61.578
rougeL     | fm: 79.201 | p: 78.669 | r: 79.815
rougeLsum  | fm: 79.188 | p: 78.644 | r: 79.872
r1fm+r2fm = 153.680

input #66 time: 0:11:23 | total time: 11:54:26


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
*********************************
*********************************
average of cosine similarity 0.9992921573107081
highest_index [0]
highest [0.9992921573107081]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.0107383728027344 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9560741782188416 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.945533275604248 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9434413909912109 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9314542412757874 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9267476201057434 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best perm rec loss: 0.9254758358001709 for ['[CLS] mainly season abby need pricehood source ultimatelyible swift [SEP]']
[Init] best perm rec loss: 0.924954354763031 for ['[CLS] source price season abby swift mainlyhood ultimatelyible need [SEP]']
[Init] best perm rec loss: 0.9242756962776184 for ['[CLS] price abbyhood season source mainly needible swift ultimately [SEP]']
[Init] best perm rec loss: 0.9240195155143738 for ['[CLS]hood source abby mainly need season price ultimatelyible swift [SEP]']
[Init] best perm rec loss: 0.9239747524261475 for ['[CLS] seasonible mainly source swifthood price need abby ultimately [SEP]']
[Init] best perm rec loss: 0.9231786727905273 for ['[CLS] source seasonible abby need mainly price swift ultimatelyhood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.577 (perp=11.196, rec=0.338, cos=0.000), tot_loss_proj:3.506 [t=0.27s]
prediction: ["[CLS] successful humored collin abilities international shortly dark'kind [SEP]"]
[ 100/2000] tot_loss=2.906 (perp=13.493, rec=0.208, cos=0.000), tot_loss_proj:3.566 [t=0.27s]
prediction: ['[CLS] deep hearted non circlewar nonental kind kind [SEP]']
[ 150/2000] tot_loss=2.566 (perp=12.052, rec=0.156, cos=0.000), tot_loss_proj:3.456 [t=0.27s]
prediction: ['[CLS] deepwarming nongmwar nonental kind kind [SEP]']
[ 200/2000] tot_loss=2.539 (perp=12.052, rec=0.128, cos=0.000), tot_loss_proj:3.455 [t=0.26s]
prediction: ['[CLS] deepwarming nongmwar nonental kind kind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.721 (perp=7.991, rec=0.123, cos=0.000), tot_loss_proj:2.207 [t=0.26s]
prediction: ['[CLS] heartwarming nongmental nonwar, kind [SEP]']
[ 300/2000] tot_loss=1.691 (perp=7.991, rec=0.093, cos=0.000), tot_loss_proj:2.205 [t=0.28s]
prediction: ['[CLS] heartwarming nongmental nonwar, kind [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.688 (perp=7.991, rec=0.090, cos=0.000), tot_loss_proj:2.205 [t=0.26s]
prediction: ['[CLS] heartwarming nongmental nonwar, kind [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.780 (perp=8.463, rec=0.087, cos=0.000), tot_loss_proj:2.048 [t=0.26s]
prediction: ['[CLS] heartwarming nongmjudental, kind [SEP]']
[ 450/2000] tot_loss=1.767 (perp=8.463, rec=0.074, cos=0.000), tot_loss_proj:2.051 [t=0.25s]
prediction: ['[CLS] heartwarming nongmjudental, kind [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.345 (perp=6.362, rec=0.073, cos=0.000), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] heartwarming nonjudgmental, kind [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.308 (perp=6.021, rec=0.103, cos=0.000), tot_loss_proj:1.472 [t=0.26s]
prediction: ['[CLS] heartwarming nonjudgmental kind, [SEP]']
[ 600/2000] tot_loss=1.283 (perp=6.021, rec=0.079, cos=0.000), tot_loss_proj:1.455 [t=0.27s]
prediction: ['[CLS] heartwarming nonjudgmental kind, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.209 (perp=5.648, rec=0.079, cos=0.000), tot_loss_proj:1.211 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.192 (perp=5.648, rec=0.062, cos=0.000), tot_loss_proj:1.208 [t=0.25s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[ 750/2000] tot_loss=1.198 (perp=5.648, rec=0.068, cos=0.000), tot_loss_proj:1.211 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.186 (perp=5.648, rec=0.056, cos=0.000), tot_loss_proj:1.211 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.200 (perp=5.648, rec=0.070, cos=0.000), tot_loss_proj:1.211 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[ 900/2000] tot_loss=1.193 (perp=5.648, rec=0.063, cos=0.000), tot_loss_proj:1.205 [t=0.28s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.197 (perp=5.648, rec=0.068, cos=0.000), tot_loss_proj:1.208 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.194 (perp=5.648, rec=0.065, cos=0.000), tot_loss_proj:1.220 [t=0.28s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1050/2000] tot_loss=1.180 (perp=5.648, rec=0.051, cos=0.000), tot_loss_proj:1.204 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.195 (perp=5.648, rec=0.066, cos=0.000), tot_loss_proj:1.206 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.186 (perp=5.648, rec=0.057, cos=0.000), tot_loss_proj:1.209 [t=0.28s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1200/2000] tot_loss=1.198 (perp=5.648, rec=0.068, cos=0.000), tot_loss_proj:1.219 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.203 (perp=5.648, rec=0.073, cos=0.000), tot_loss_proj:1.203 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1300/2000] tot_loss=1.195 (perp=5.648, rec=0.066, cos=0.000), tot_loss_proj:1.209 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1350/2000] tot_loss=1.191 (perp=5.648, rec=0.061, cos=0.000), tot_loss_proj:1.200 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.193 (perp=5.648, rec=0.064, cos=0.000), tot_loss_proj:1.200 [t=0.25s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.180 (perp=5.648, rec=0.050, cos=0.000), tot_loss_proj:1.186 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1500/2000] tot_loss=1.195 (perp=5.648, rec=0.066, cos=0.000), tot_loss_proj:1.212 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.188 (perp=5.648, rec=0.058, cos=0.000), tot_loss_proj:1.203 [t=0.28s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.198 (perp=5.648, rec=0.068, cos=0.000), tot_loss_proj:1.216 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1650/2000] tot_loss=1.189 (perp=5.648, rec=0.060, cos=0.000), tot_loss_proj:1.218 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.190 (perp=5.648, rec=0.060, cos=0.000), tot_loss_proj:1.206 [t=0.25s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.190 (perp=5.648, rec=0.060, cos=0.000), tot_loss_proj:1.205 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1800/2000] tot_loss=1.183 (perp=5.648, rec=0.054, cos=0.000), tot_loss_proj:1.217 [t=0.27s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.186 (perp=5.648, rec=0.056, cos=0.000), tot_loss_proj:1.215 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.197 (perp=5.648, rec=0.067, cos=0.000), tot_loss_proj:1.219 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[1950/2000] tot_loss=1.195 (perp=5.648, rec=0.065, cos=0.000), tot_loss_proj:1.200 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.187 (perp=5.648, rec=0.057, cos=0.000), tot_loss_proj:1.199 [t=0.26s]
prediction: ['[CLS] heartwarming, nonjudgmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.548 | p: 91.937 | r: 93.264
rouge2     | fm: 61.724 | p: 61.406 | r: 62.038
rougeL     | fm: 79.481 | p: 79.009 | r: 80.018
rougeLsum  | fm: 79.560 | p: 79.050 | r: 80.130
r1fm+r2fm = 154.272

input #67 time: 0:11:13 | total time: 12:05:39


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
*********************************
*********************************
average of cosine similarity 0.999277960150343
highest_index [0]
highest [0.999277960150343]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9886776804924011 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9680570960044861 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9397196769714355 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9248572587966919 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8689963817596436 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8601563572883606 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8548768162727356 for ['[CLS] medaliferous beth comfort form councils flooryn possibly riding. died view [SEP]']
[Init] best perm rec loss: 0.8497585654258728 for ['[CLS]yn possibly councils form beth.iferous riding view floor medal comfort died [SEP]']
[Init] best perm rec loss: 0.8496531248092651 for ['[CLS] died. beth possiblyiferous medal view form ridingyn floor councils comfort [SEP]']
[Init] best perm rec loss: 0.8486950397491455 for ['[CLS].yn floor beth possibly riding comfort form died medal viewiferous councils [SEP]']
[Init] best perm rec loss: 0.8479105830192566 for ['[CLS] councils bethiferous form possibly medal comfort died.yn riding floor view [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.536 (perp=11.384, rec=0.259, cos=0.000), tot_loss_proj:2.763 [t=0.25s]
prediction: ['[CLS] absurd scale drag plan just amendment absurd [SEP]. absurd ( resulting absurd [SEP]']
[ 100/2000] tot_loss=2.208 (perp=10.186, rec=0.171, cos=0.000), tot_loss_proj:2.497 [t=0.26s]
prediction: ['[CLS] absurdnched for cancellation, un absurdsiblesible absurd and vicious absurd [SEP]']
[ 150/2000] tot_loss=2.239 (perp=10.537, rec=0.132, cos=0.000), tot_loss_proj:2.559 [t=0.28s]
prediction: ['[CLS] absurd hormones off bid, unctsiblesible absurd and vicious vicious [SEP]']
[ 200/2000] tot_loss=2.234 (perp=10.538, rec=0.127, cos=0.000), tot_loss_proj:2.916 [t=0.27s]
prediction: ['[CLS] sick hormones off,, uncosibleomp absurd and vicious vicious [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.170 (perp=10.238, rec=0.122, cos=0.000), tot_loss_proj:2.429 [t=0.27s]
prediction: ['[CLS]pl, uncosibleomp rhetoric off, absurd and vicious vicious [SEP]']
[ 300/2000] tot_loss=2.139 (perp=10.190, rec=0.101, cos=0.000), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS]pl, uncosibleomp rhetoricuth, absurd and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.778 (perp=8.458, rec=0.087, cos=0.000), tot_loss_proj:2.209 [t=0.28s]
prediction: ['[CLS]sible, uncoplomp rhetoricuth, absurd and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.892 (perp=8.984, rec=0.095, cos=0.000), tot_loss_proj:2.291 [t=0.28s]
prediction: ['[CLS]sible, uncoplomputhhen, absurd and vicious vicious [SEP]']
[ 450/2000] tot_loss=1.891 (perp=8.984, rec=0.094, cos=0.000), tot_loss_proj:2.304 [t=0.27s]
prediction: ['[CLS]sible, uncoplomputhhen, absurd and vicious vicious [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.647 (perp=7.839, rec=0.079, cos=0.000), tot_loss_proj:2.171 [t=0.29s]
prediction: ['[CLS]sible, uncouthompomphen, absurd and vicious vicious [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.592 (perp=7.546, rec=0.083, cos=0.000), tot_loss_proj:2.154 [t=0.26s]
prediction: ['[CLS]sible, uncouth viciousompomphen, absurd and vicious [SEP]']
[ 600/2000] tot_loss=1.581 (perp=7.546, rec=0.072, cos=0.000), tot_loss_proj:2.144 [t=0.27s]
prediction: ['[CLS]sible, uncouth viciousompomphen, absurd and vicious [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.486 (perp=7.044, rec=0.077, cos=0.000), tot_loss_proj:2.153 [t=0.28s]
prediction: ['[CLS]sibleompomphen, uncouth vicious, absurd and vicious [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.419 (perp=6.719, rec=0.075, cos=0.000), tot_loss_proj:1.905 [t=0.28s]
prediction: ['[CLS]sibleompomphen, uncouth absurd, vicious and vicious [SEP]']
[ 750/2000] tot_loss=1.422 (perp=6.719, rec=0.078, cos=0.000), tot_loss_proj:1.909 [t=0.27s]
prediction: ['[CLS]sibleompomphen, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.414 (perp=6.719, rec=0.070, cos=0.000), tot_loss_proj:1.914 [t=0.27s]
prediction: ['[CLS]sibleompomphen, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.333 (perp=6.248, rec=0.083, cos=0.000), tot_loss_proj:1.535 [t=0.27s]
prediction: ['[CLS]ompomphensible, uncouth absurd, vicious and vicious [SEP]']
[ 900/2000] tot_loss=1.333 (perp=6.248, rec=0.083, cos=0.000), tot_loss_proj:1.537 [t=0.27s]
prediction: ['[CLS]ompomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.174 (perp=5.550, rec=0.064, cos=0.000), tot_loss_proj:1.322 [t=0.25s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1000/2000] tot_loss=1.181 (perp=5.550, rec=0.071, cos=0.000), tot_loss_proj:1.322 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1050/2000] tot_loss=1.185 (perp=5.550, rec=0.075, cos=0.000), tot_loss_proj:1.324 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1100/2000] tot_loss=1.181 (perp=5.550, rec=0.071, cos=0.000), tot_loss_proj:1.326 [t=0.28s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1150/2000] tot_loss=1.179 (perp=5.550, rec=0.070, cos=0.000), tot_loss_proj:1.324 [t=0.28s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1200/2000] tot_loss=1.189 (perp=5.550, rec=0.080, cos=0.000), tot_loss_proj:1.321 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1250/2000] tot_loss=1.180 (perp=5.550, rec=0.070, cos=0.000), tot_loss_proj:1.320 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1300/2000] tot_loss=1.183 (perp=5.550, rec=0.073, cos=0.000), tot_loss_proj:1.321 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1350/2000] tot_loss=1.180 (perp=5.550, rec=0.070, cos=0.000), tot_loss_proj:1.321 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1400/2000] tot_loss=1.178 (perp=5.550, rec=0.068, cos=0.000), tot_loss_proj:1.320 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1450/2000] tot_loss=1.187 (perp=5.550, rec=0.078, cos=0.000), tot_loss_proj:1.326 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1500/2000] tot_loss=1.174 (perp=5.550, rec=0.064, cos=0.000), tot_loss_proj:1.324 [t=0.30s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1550/2000] tot_loss=1.169 (perp=5.550, rec=0.059, cos=0.000), tot_loss_proj:1.332 [t=0.28s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1600/2000] tot_loss=1.180 (perp=5.550, rec=0.070, cos=0.000), tot_loss_proj:1.328 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1650/2000] tot_loss=1.175 (perp=5.550, rec=0.065, cos=0.000), tot_loss_proj:1.326 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.170 (perp=5.550, rec=0.060, cos=0.000), tot_loss_proj:1.326 [t=0.28s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1750/2000] tot_loss=1.177 (perp=5.550, rec=0.067, cos=0.000), tot_loss_proj:1.324 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1800/2000] tot_loss=1.175 (perp=5.550, rec=0.066, cos=0.000), tot_loss_proj:1.324 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1850/2000] tot_loss=1.178 (perp=5.550, rec=0.068, cos=0.000), tot_loss_proj:1.331 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[1900/2000] tot_loss=1.184 (perp=5.550, rec=0.074, cos=0.000), tot_loss_proj:1.331 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
[1950/2000] tot_loss=1.177 (perp=5.550, rec=0.067, cos=0.000), tot_loss_proj:1.322 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Attempt swap
[2000/2000] tot_loss=1.177 (perp=5.550, rec=0.067, cos=0.000), tot_loss_proj:1.325 [t=0.29s]
prediction: ['[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] incomphensible, uncouth absurd, vicious and vicious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 95.385

[Aggregate metrics]:
rouge1     | fm: 92.370 | p: 91.729 | r: 93.167
rouge2     | fm: 60.908 | p: 60.575 | r: 61.277
rougeL     | fm: 79.311 | p: 78.782 | r: 79.997
rougeLsum  | fm: 79.347 | p: 78.787 | r: 80.057
r1fm+r2fm = 153.278

input #68 time: 0:11:21 | total time: 12:17:01


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
*********************************
*********************************
average of cosine similarity 0.9992903267885285
highest_index [0]
highest [0.9992903267885285]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.0891327857971191 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9452259540557861 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.9285263419151306 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9229622483253479 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.914220929145813 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9023697376251221 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.883520245552063 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8763737082481384 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8750739693641663 for ['[CLS]mission unopposed port [MASK] case main trayacio burnham adelaide platform ferrisest gross down african [SEP]']
[Init] best perm rec loss: 0.8746346235275269 for ['[CLS] case burnham [MASK] ferris main african platformacio adelaidemission unopposed tray portest down gross [SEP]']
[Init] best perm rec loss: 0.8741676807403564 for ['[CLS] ferris platform burnham grossestmissionacio unopposed tray case main adelaide african port down [MASK] [SEP]']
[Init] best perm rec loss: 0.8730548024177551 for ['[CLS] traymission african adelaide ferrisacio platform burnham case gross unopposed main downest [MASK] port [SEP]']
[Init] best perm rec loss: 0.870721161365509 for ['[CLS] platform case burnhammissionacio adelaide africanest port ferris [MASK] tray main down unopposed gross [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.754 (perp=12.281, rec=0.298, cos=0.000), tot_loss_proj:3.183 [t=0.26s]
prediction: ["[CLS] nice warmed experience energy landscape touch strong talk debut institution 'yn england hale sexual [SEP]"]
[ 100/2000] tot_loss=2.476 (perp=11.216, rec=0.233, cos=0.000), tot_loss_proj:2.797 [t=0.27s]
prediction: ['[CLS] catching warm, approved smart gentle touch real ; smart winner, dennis pen real sexual [SEP]']
[ 150/2000] tot_loss=2.228 (perp=10.175, rec=0.193, cos=0.000), tot_loss_proj:2.756 [t=0.27s]
prediction: ['[CLS] catching warm, approved smart - touched real - smart winner,peed winner subtle sexual [SEP]']
[ 200/2000] tot_loss=2.146 (perp=9.920, rec=0.162, cos=0.000), tot_loss_proj:2.601 [t=0.27s]
prediction: ['[CLS] funny warm, - smart - quantum real - subtle winner,, - subtle sexual [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.868 (perp=8.604, rec=0.147, cos=0.000), tot_loss_proj:2.470 [t=0.27s]
prediction: ['[CLS]ona winner, - smart - quantum real - subtle warm,, - subtle sexual [SEP]']
[ 300/2000] tot_loss=1.648 (perp=7.578, rec=0.132, cos=0.000), tot_loss_proj:2.147 [t=0.27s]
prediction: ['[CLS]ona winner, - smart -, real - subtle funny,, - subtle women [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.650 (perp=7.567, rec=0.137, cos=0.000), tot_loss_proj:2.019 [t=0.28s]
prediction: ['[CLS]ona winner, - smart -, real - subtle, funny,. subtle women [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.547 (perp=7.131, rec=0.121, cos=0.000), tot_loss_proj:1.849 [t=0.26s]
prediction: ['[CLS]ona winner, - - smart, real - subtle, funny,. subtle women [SEP]']
[ 450/2000] tot_loss=1.642 (perp=7.603, rec=0.122, cos=0.000), tot_loss_proj:2.047 [t=0.27s]
prediction: ["[CLS]ona winner,'- smart, real - subtle, sensitive,.ona business [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.501 (perp=6.875, rec=0.126, cos=0.000), tot_loss_proj:1.886 [t=0.27s]
prediction: ["[CLS]ona winner,'- smart, real, subtle, sensitive -.ona business [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.719 (perp=7.947, rec=0.129, cos=0.000), tot_loss_proj:2.215 [t=0.27s]
prediction: ['[CLS]ona winner, - - smartnt real, subtle, sensitive - business.ona [SEP]']
[ 600/2000] tot_loss=1.442 (perp=6.635, rec=0.115, cos=0.000), tot_loss_proj:1.742 [t=0.28s]
prediction: ["[CLS]ona winner,'- smart, real, subtle, sensitive - triumphant.ona [SEP]"]
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.397 (perp=6.351, rec=0.126, cos=0.000), tot_loss_proj:1.834 [t=0.27s]
prediction: ["[CLS]onaona winner,'- smart, real, subtle, religious - peer. [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.401 (perp=6.378, rec=0.125, cos=0.000), tot_loss_proj:1.830 [t=0.27s]
prediction: ['[CLS]onaona winner, - - smart, real, subtle, religious - mistress. [SEP]']
[ 750/2000] tot_loss=1.399 (perp=6.378, rec=0.123, cos=0.000), tot_loss_proj:1.833 [t=0.28s]
prediction: ['[CLS]onaona winner, - - smart, real, subtle, religious - mistress. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.327 (perp=6.055, rec=0.116, cos=0.000), tot_loss_proj:1.765 [t=0.29s]
prediction: ['[CLS]onaona winner - - - smart, real, subtle, religious, mistress. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.419 (perp=6.508, rec=0.117, cos=0.000), tot_loss_proj:1.726 [t=0.27s]
prediction: ['[CLS]onant winner - - - smart, real, subtle, religious, mistress. [SEP]']
[ 900/2000] tot_loss=1.693 (perp=7.890, rec=0.115, cos=0.000), tot_loss_proj:2.274 [t=0.27s]
prediction: ['[CLS]onant winner - - - smartnt real, subtle, religious, terms. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.488 (perp=6.885, rec=0.111, cos=0.000), tot_loss_proj:1.815 [t=0.27s]
prediction: ['[CLS]onant winner - - - smart, real, subtle, funnynt terms. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.433 (perp=6.574, rec=0.118, cos=0.000), tot_loss_proj:1.771 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funnynt terms. [SEP]']
[1050/2000] tot_loss=1.431 (perp=6.574, rec=0.116, cos=0.000), tot_loss_proj:1.769 [t=0.26s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funnynt terms. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.428 (perp=6.574, rec=0.113, cos=0.000), tot_loss_proj:1.776 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funnynt terms. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.422 (perp=6.574, rec=0.107, cos=0.000), tot_loss_proj:1.775 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funnynt terms. [SEP]']
[1200/2000] tot_loss=1.421 (perp=6.574, rec=0.106, cos=0.000), tot_loss_proj:1.772 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funnynt terms. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.335 (perp=6.126, rec=0.110, cos=0.000), tot_loss_proj:1.603 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, terms. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.350 (perp=6.237, rec=0.102, cos=0.000), tot_loss_proj:1.611 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
[1350/2000] tot_loss=1.356 (perp=6.237, rec=0.109, cos=0.000), tot_loss_proj:1.619 [t=0.26s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.365 (perp=6.237, rec=0.117, cos=0.000), tot_loss_proj:1.616 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.366 (perp=6.237, rec=0.119, cos=0.000), tot_loss_proj:1.616 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
[1500/2000] tot_loss=1.356 (perp=6.237, rec=0.108, cos=0.000), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.354 (perp=6.237, rec=0.107, cos=0.000), tot_loss_proj:1.620 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.361 (perp=6.237, rec=0.113, cos=0.000), tot_loss_proj:1.614 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
[1650/2000] tot_loss=1.354 (perp=6.237, rec=0.107, cos=0.000), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.357 (perp=6.237, rec=0.109, cos=0.000), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.347 (perp=6.237, rec=0.100, cos=0.000), tot_loss_proj:1.609 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
[1800/2000] tot_loss=1.360 (perp=6.237, rec=0.112, cos=0.000), tot_loss_proj:1.618 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.355 (perp=6.237, rec=0.108, cos=0.000), tot_loss_proj:1.612 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.357 (perp=6.237, rec=0.110, cos=0.000), tot_loss_proj:1.609 [t=0.27s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
[1950/2000] tot_loss=1.358 (perp=6.237, rec=0.111, cos=0.000), tot_loss_proj:1.616 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.354 (perp=6.237, rec=0.106, cos=0.000), tot_loss_proj:1.615 [t=0.28s]
prediction: ['[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS]onant - winner - - smart, real, subtle, funny, when. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 77.778 | r: 70.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 52.632 | p: 55.556 | r: 50.000
rougeLsum  | fm: 52.632 | p: 55.556 | r: 50.000
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 92.113 | p: 91.521 | r: 92.812
rouge2     | fm: 60.191 | p: 59.928 | r: 60.520
rougeL     | fm: 78.968 | p: 78.509 | r: 79.578
rougeLsum  | fm: 78.916 | p: 78.365 | r: 79.501
r1fm+r2fm = 152.303

input #69 time: 0:11:02 | total time: 12:28:04


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9993747013926036
highest_index [0]
highest [0.9993747013926036]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8455935716629028 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.8194145560264587 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7926039099693298 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7368897795677185 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.734348714351654 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7333130240440369 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.732122540473938 for ['[CLS] effects sharma detention blood herself technological mark [SEP]']
[Init] best perm rec loss: 0.7310177683830261 for ['[CLS] herself detention sharma mark technological blood effects [SEP]']
[Init] best perm rec loss: 0.7299274206161499 for ['[CLS] detention herself sharma mark technological blood effects [SEP]']
[Init] best perm rec loss: 0.7288514375686646 for ['[CLS] detention sharma technological blood mark herself effects [SEP]']
[Init] best perm rec loss: 0.7279748320579529 for ['[CLS] blood effects detention herself mark technological sharma [SEP]']
[Init] best perm rec loss: 0.7263690233230591 for ['[CLS] detention herself sharma effects technological mark blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.102 (perp=13.628, rec=0.376, cos=0.000), tot_loss_proj:3.571 [t=0.29s]
prediction: ['[CLS] mess circuit scotia getting grade jammedtalk [SEP]']
[ 100/2000] tot_loss=3.150 (perp=14.248, rec=0.301, cos=0.000), tot_loss_proj:3.493 [t=0.29s]
prediction: ['[CLS] junkock cl getsunkunk screen [SEP]']
[ 150/2000] tot_loss=2.845 (perp=13.254, rec=0.194, cos=0.000), tot_loss_proj:3.739 [t=0.28s]
prediction: ['[CLS] filledunk on getsunkunk screen [SEP]']
[ 200/2000] tot_loss=2.518 (perp=11.856, rec=0.146, cos=0.000), tot_loss_proj:3.344 [t=0.28s]
prediction: ['[CLS]edunk on gets clunk screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.068 (perp=9.740, rec=0.120, cos=0.000), tot_loss_proj:2.853 [t=0.30s]
prediction: ['[CLS]edy gets clunk on screen [SEP]']
[ 300/2000] tot_loss=2.115 (perp=10.098, rec=0.095, cos=0.000), tot_loss_proj:2.847 [t=0.28s]
prediction: ['[CLS]yy gets clunk on screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.519 (perp=7.184, rec=0.082, cos=0.000), tot_loss_proj:1.702 [t=0.30s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.523 (perp=7.184, rec=0.086, cos=0.000), tot_loss_proj:1.698 [t=0.28s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 450/2000] tot_loss=1.525 (perp=7.184, rec=0.088, cos=0.000), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.515 (perp=7.184, rec=0.078, cos=0.000), tot_loss_proj:1.705 [t=0.28s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.512 (perp=7.184, rec=0.075, cos=0.000), tot_loss_proj:1.707 [t=0.28s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 600/2000] tot_loss=1.520 (perp=7.184, rec=0.083, cos=0.000), tot_loss_proj:1.701 [t=0.29s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.509 (perp=7.184, rec=0.073, cos=0.000), tot_loss_proj:1.700 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.513 (perp=7.184, rec=0.076, cos=0.000), tot_loss_proj:1.697 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 750/2000] tot_loss=1.502 (perp=7.184, rec=0.065, cos=0.000), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.514 (perp=7.184, rec=0.077, cos=0.000), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.508 (perp=7.184, rec=0.071, cos=0.000), tot_loss_proj:1.709 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 900/2000] tot_loss=1.510 (perp=7.184, rec=0.073, cos=0.000), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.512 (perp=7.184, rec=0.075, cos=0.000), tot_loss_proj:1.706 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.511 (perp=7.184, rec=0.074, cos=0.000), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1050/2000] tot_loss=1.504 (perp=7.184, rec=0.067, cos=0.000), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.510 (perp=7.184, rec=0.073, cos=0.000), tot_loss_proj:1.703 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.513 (perp=7.184, rec=0.076, cos=0.000), tot_loss_proj:1.713 [t=0.28s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1200/2000] tot_loss=1.508 (perp=7.184, rec=0.071, cos=0.000), tot_loss_proj:1.706 [t=0.25s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.514 (perp=7.184, rec=0.077, cos=0.000), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.511 (perp=7.184, rec=0.074, cos=0.000), tot_loss_proj:1.707 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1350/2000] tot_loss=1.504 (perp=7.184, rec=0.067, cos=0.000), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.499 (perp=7.184, rec=0.062, cos=0.000), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.512 (perp=7.184, rec=0.075, cos=0.000), tot_loss_proj:1.701 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1500/2000] tot_loss=1.512 (perp=7.184, rec=0.075, cos=0.000), tot_loss_proj:1.703 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.511 (perp=7.184, rec=0.074, cos=0.000), tot_loss_proj:1.713 [t=0.28s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.510 (perp=7.184, rec=0.073, cos=0.000), tot_loss_proj:1.711 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1650/2000] tot_loss=1.511 (perp=7.184, rec=0.075, cos=0.000), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.510 (perp=7.184, rec=0.073, cos=0.000), tot_loss_proj:1.707 [t=0.27s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.509 (perp=7.184, rec=0.072, cos=0.000), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1800/2000] tot_loss=1.503 (perp=7.184, rec=0.066, cos=0.000), tot_loss_proj:1.706 [t=0.28s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.518 (perp=7.184, rec=0.081, cos=0.000), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.184, rec=0.066, cos=0.000), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1950/2000] tot_loss=1.509 (perp=7.184, rec=0.072, cos=0.000), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.509 (perp=7.184, rec=0.072, cos=0.000), tot_loss_proj:1.715 [t=0.26s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS]y gets clunky on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 92.052 | p: 91.483 | r: 92.732
rouge2     | fm: 59.963 | p: 59.675 | r: 60.310
rougeL     | fm: 79.113 | p: 78.621 | r: 79.633
rougeLsum  | fm: 79.014 | p: 78.527 | r: 79.603
r1fm+r2fm = 152.015

input #70 time: 0:11:21 | total time: 12:39:25


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
*********************************
*********************************
average of cosine similarity 0.9993409712634834
highest_index [0]
highest [0.9993409712634834]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8858124613761902 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.847004771232605 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8450173139572144 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8434007167816162 for ['[CLS]hen conduct longitudinalez reckon hood reachldon shifters bearings now sheridan area sloan september [SEP]']
[Init] best rec loss: 0.8422675132751465 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.831749677658081 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8238405585289001 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8161496520042419 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.8106833696365356 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.810418963432312 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8095448017120361 for ['[CLS] reservoir untiltered acids goghathlon tomb course. south little wright stagearth beyond [SEP]']
[Init] best perm rec loss: 0.8093586564064026 for ['[CLS] tomb courseathlon beyond acids wright south reservoir little until stagetered. gogharth [SEP]']
[Init] best perm rec loss: 0.8083019852638245 for ['[CLS] littlearthtered tomb course until acids gogh beyond. south wrightathlon reservoir stage [SEP]']
[Init] best perm rec loss: 0.8082954287528992 for ['[CLS] wright reservoir beyondarth acids until. course little stage southtered gogh tombathlon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.719 (perp=11.736, rec=0.372, cos=0.000), tot_loss_proj:3.721 [t=0.28s]
prediction: ['[CLS] not t short seemed not srricular moment seats wage nound or time industry [SEP]']
[ 100/2000] tot_loss=1.947 (perp=8.569, rec=0.233, cos=0.000), tot_loss_proj:2.543 [t=0.28s]
prediction: ['[CLS] not - single regards not single? moment seat - - seat - moment jump [SEP]']
[ 150/2000] tot_loss=1.778 (perp=8.120, rec=0.154, cos=0.000), tot_loss_proj:2.588 [t=0.27s]
prediction: ['[CLS] not - single s not single and jump seat - - seat - moment jump [SEP]']
[ 200/2000] tot_loss=1.793 (perp=8.337, rec=0.126, cos=0.000), tot_loss_proj:3.150 [t=0.27s]
prediction: ['[CLS] there a single s not single and jump seat - - seat your moment jump [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.617 (perp=7.616, rec=0.094, cos=0.000), tot_loss_proj:2.535 [t=0.28s]
prediction: ['[CLS] there and a single s not single jump in - - seat your moment jump [SEP]']
[ 300/2000] tot_loss=1.606 (perp=7.616, rec=0.083, cos=0.000), tot_loss_proj:2.537 [t=0.29s]
prediction: ['[CLS] there and a single s not single jump in - - seat your moment jump [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.487 (perp=7.088, rec=0.069, cos=0.000), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] there and a single s not single jump in - - seat jump your moment [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.402 (perp=6.630, rec=0.076, cos=0.000), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] there and single s not a single jump in - - seat jump your moment [SEP]']
[ 450/2000] tot_loss=1.400 (perp=6.630, rec=0.074, cos=0.000), tot_loss_proj:1.955 [t=0.28s]
prediction: ['[CLS] there and single s not a single jump in - - seat jump your moment [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.111 (perp=5.214, rec=0.069, cos=0.000), tot_loss_proj:1.543 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.106 (perp=5.214, rec=0.063, cos=0.000), tot_loss_proj:1.544 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
[ 600/2000] tot_loss=1.113 (perp=5.214, rec=0.071, cos=0.000), tot_loss_proj:1.540 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.116 (perp=5.214, rec=0.074, cos=0.000), tot_loss_proj:1.544 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.100 (perp=5.214, rec=0.057, cos=0.000), tot_loss_proj:1.549 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
[ 750/2000] tot_loss=1.103 (perp=5.214, rec=0.060, cos=0.000), tot_loss_proj:1.544 [t=0.28s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.120 (perp=5.214, rec=0.077, cos=0.000), tot_loss_proj:1.545 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.104 (perp=5.214, rec=0.061, cos=0.000), tot_loss_proj:1.549 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
[ 900/2000] tot_loss=1.116 (perp=5.214, rec=0.074, cos=0.000), tot_loss_proj:1.551 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - seat jump your moment [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.100 (perp=5.145, rec=0.071, cos=0.000), tot_loss_proj:1.406 [t=0.25s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.096 (perp=5.145, rec=0.067, cos=0.000), tot_loss_proj:1.418 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
[1050/2000] tot_loss=1.088 (perp=5.145, rec=0.059, cos=0.000), tot_loss_proj:1.415 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.101 (perp=5.145, rec=0.072, cos=0.000), tot_loss_proj:1.420 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.086 (perp=5.145, rec=0.057, cos=0.000), tot_loss_proj:1.420 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
[1200/2000] tot_loss=1.090 (perp=5.145, rec=0.061, cos=0.000), tot_loss_proj:1.420 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.088 (perp=5.145, rec=0.059, cos=0.000), tot_loss_proj:1.405 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.099 (perp=5.145, rec=0.070, cos=0.000), tot_loss_proj:1.420 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
[1350/2000] tot_loss=1.094 (perp=5.145, rec=0.065, cos=0.000), tot_loss_proj:1.420 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.092 (perp=5.145, rec=0.063, cos=0.000), tot_loss_proj:1.417 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.095 (perp=5.145, rec=0.066, cos=0.000), tot_loss_proj:1.414 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
[1500/2000] tot_loss=1.090 (perp=5.145, rec=0.061, cos=0.000), tot_loss_proj:1.423 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.102 (perp=5.145, rec=0.073, cos=0.000), tot_loss_proj:1.414 [t=0.26s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.085 (perp=5.145, rec=0.055, cos=0.000), tot_loss_proj:1.416 [t=0.28s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
[1650/2000] tot_loss=1.103 (perp=5.145, rec=0.074, cos=0.000), tot_loss_proj:1.416 [t=0.27s]
prediction: ["[CLS] and there's not a single jump in - - your jump seat moment [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.097 (perp=5.152, rec=0.067, cos=0.000), tot_loss_proj:1.606 [t=0.28s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.098 (perp=5.152, rec=0.068, cos=0.000), tot_loss_proj:1.604 [t=0.26s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
[1800/2000] tot_loss=1.088 (perp=5.152, rec=0.058, cos=0.000), tot_loss_proj:1.606 [t=0.27s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.097 (perp=5.152, rec=0.066, cos=0.000), tot_loss_proj:1.606 [t=0.27s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.088 (perp=5.152, rec=0.058, cos=0.000), tot_loss_proj:1.607 [t=0.27s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
[1950/2000] tot_loss=1.085 (perp=5.152, rec=0.055, cos=0.000), tot_loss_proj:1.613 [t=0.27s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.105 (perp=5.152, rec=0.075, cos=0.000), tot_loss_proj:1.608 [t=0.28s]
prediction: ["[CLS] and there's not a single in jump - - your jump seat moment [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there's not a single in jump - - your jump seat moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 40.000 | p: 38.462 | r: 41.667
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 136.296

[Aggregate metrics]:
rouge1     | fm: 92.111 | p: 91.436 | r: 92.862
rouge2     | fm: 60.007 | p: 59.726 | r: 60.348
rougeL     | fm: 79.049 | p: 78.518 | r: 79.665
rougeLsum  | fm: 79.078 | p: 78.531 | r: 79.638
r1fm+r2fm = 152.117

input #71 time: 0:11:14 | total time: 12:50:40


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
*********************************
*********************************
average of cosine similarity 0.9992328795744121
highest_index [0]
highest [0.9992328795744121]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7878946661949158 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7563902735710144 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7559114098548889 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7540911436080933 for ['[CLS] renaissance lie devil brigade unit purcell as harvest strandedfr uncommon powers behaviour ken terror [SEP]']
[Init] best rec loss: 0.7353218197822571 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.716721773147583 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7151246666908264 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7138395309448242 for ['[CLS] nonetheless zone except reserve accidentally supportungen! pork lifeboat van dna ta orbital walking [SEP]']
[Init] best perm rec loss: 0.713516891002655 for ['[CLS] nonetheless zone orbital ta reserve dna lifeboat! vanungen except walking accidentally pork support [SEP]']
[Init] best perm rec loss: 0.7132456302642822 for ['[CLS] except accidentally nonetheless supportungen pork lifeboat dna ta zone! van reserve orbital walking [SEP]']
[Init] best perm rec loss: 0.7129440903663635 for ['[CLS] orbital porkungen support except dna accidentally lifeboat ta nonetheless! reserve zone van walking [SEP]']
[Init] best perm rec loss: 0.7125667929649353 for ['[CLS]! support pork zone nonetheless except dna lifeboat van taungen walking orbital accidentally reserve [SEP]']
[Init] best perm rec loss: 0.7122027277946472 for ['[CLS] walking support orbital dna lifeboat van accidentally reserveungen pork zone except ta! nonetheless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.807 (perp=11.981, rec=0.410, cos=0.000), tot_loss_proj:3.403 [t=0.27s]
prediction: ['[CLS] shit itsation gut cuts prison tough grouping anyway. acts advocated a paperɛ [SEP]']
[ 100/2000] tot_loss=2.475 (perp=10.969, rec=0.281, cos=0.000), tot_loss_proj:3.212 [t=0.27s]
prediction: ['[CLS] ( itser rape tough time tough government coordinator. violence estimates a paper eligibility [SEP]']
[ 150/2000] tot_loss=2.345 (perp=10.712, rec=0.202, cos=0.000), tot_loss_proj:3.168 [t=0.26s]
prediction: ['[CLS] has itser hack tough time tough characterou the violence nietzsche a bracket time [SEP]']
[ 200/2000] tot_loss=2.235 (perp=10.402, rec=0.155, cos=0.000), tot_loss_proj:3.011 [t=0.28s]
prediction: ['[CLS] has itser its tough timeer itsou the violence philosophy a college time [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.024 (perp=9.396, rec=0.145, cos=0.000), tot_loss_proj:2.808 [t=0.27s]
prediction: ['[CLS] has itser a tougher time itsou its violence philosophy a writer time [SEP]']
[ 300/2000] tot_loss=2.041 (perp=9.614, rec=0.118, cos=0.000), tot_loss_proj:2.788 [t=0.28s]
prediction: ['[CLS] has itser a tougher time itsou balancing violence philosophy a college time [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.974 (perp=9.335, rec=0.107, cos=0.000), tot_loss_proj:2.497 [t=0.27s]
prediction: ['[CLS] has itser a tougher timeou balancing its violence philosophy withfk time [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.057 (perp=9.703, rec=0.116, cos=0.000), tot_loss_proj:2.583 [t=0.28s]
prediction: ['[CLS] has basketballer rape tougher timeou balancing its violence philosophy with its time [SEP]']
[ 450/2000] tot_loss=1.811 (perp=8.594, rec=0.092, cos=0.000), tot_loss_proj:2.305 [t=0.28s]
prediction: ['[CLS] has basketballer a tougher timeou balancing its violence philosophy with its time [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.730 (perp=8.188, rec=0.092, cos=0.000), tot_loss_proj:2.181 [t=0.29s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophyou with its time [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.780 (perp=8.467, rec=0.086, cos=0.000), tot_loss_proj:2.309 [t=0.27s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophy withoufk time [SEP]']
[ 600/2000] tot_loss=1.783 (perp=8.467, rec=0.090, cos=0.000), tot_loss_proj:2.312 [t=0.26s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophy withoufk time [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.707 (perp=8.092, rec=0.089, cos=0.000), tot_loss_proj:2.173 [t=0.26s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.698 (perp=8.092, rec=0.080, cos=0.000), tot_loss_proj:2.174 [t=0.28s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophy with timeoufk [SEP]']
[ 750/2000] tot_loss=1.700 (perp=8.092, rec=0.082, cos=0.000), tot_loss_proj:2.169 [t=0.28s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.694 (perp=8.092, rec=0.076, cos=0.000), tot_loss_proj:2.173 [t=0.26s]
prediction: ['[CLS] hasfker a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.587 (perp=7.522, rec=0.082, cos=0.000), tot_loss_proj:1.819 [t=0.25s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeoufk [SEP]']
[ 900/2000] tot_loss=1.592 (perp=7.522, rec=0.088, cos=0.000), tot_loss_proj:1.823 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.589 (perp=7.522, rec=0.085, cos=0.000), tot_loss_proj:1.820 [t=0.26s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
[1000/2000] tot_loss=1.591 (perp=7.522, rec=0.087, cos=0.000), tot_loss_proj:1.831 [t=0.26s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeoufk [SEP]']
[1050/2000] tot_loss=1.579 (perp=7.522, rec=0.075, cos=0.000), tot_loss_proj:1.824 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
[1100/2000] tot_loss=1.582 (perp=7.522, rec=0.078, cos=0.000), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeoufk [SEP]']
Attempt swap
[1150/2000] tot_loss=1.518 (perp=7.209, rec=0.076, cos=0.000), tot_loss_proj:1.759 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeafk [SEP]']
[1200/2000] tot_loss=1.520 (perp=7.209, rec=0.078, cos=0.000), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeafk [SEP]']
Attempt swap
[1250/2000] tot_loss=1.510 (perp=7.209, rec=0.069, cos=0.000), tot_loss_proj:1.753 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeafk [SEP]']
Attempt swap
[1300/2000] tot_loss=1.521 (perp=7.209, rec=0.079, cos=0.000), tot_loss_proj:1.767 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeafk [SEP]']
[1350/2000] tot_loss=1.522 (perp=7.209, rec=0.080, cos=0.000), tot_loss_proj:1.759 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeafk [SEP]']
Attempt swap
[1400/2000] tot_loss=1.717 (perp=8.179, rec=0.081, cos=0.000), tot_loss_proj:1.953 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timeaika [SEP]']
Attempt swap
[1450/2000] tot_loss=1.521 (perp=7.195, rec=0.082, cos=0.000), tot_loss_proj:1.790 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timea inspired [SEP]']
[1500/2000] tot_loss=1.516 (perp=7.195, rec=0.077, cos=0.000), tot_loss_proj:1.784 [t=0.27s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
[1550/2000] tot_loss=1.510 (perp=7.195, rec=0.071, cos=0.000), tot_loss_proj:1.776 [t=0.26s]
prediction: ['[CLS]fker has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.504 (perp=7.161, rec=0.071, cos=0.000), tot_loss_proj:1.752 [t=0.26s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
[1650/2000] tot_loss=1.508 (perp=7.161, rec=0.076, cos=0.000), tot_loss_proj:1.759 [t=0.28s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
[1700/2000] tot_loss=1.495 (perp=7.161, rec=0.063, cos=0.000), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
[1750/2000] tot_loss=1.511 (perp=7.161, rec=0.079, cos=0.000), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
[1800/2000] tot_loss=1.501 (perp=7.161, rec=0.069, cos=0.000), tot_loss_proj:1.758 [t=0.27s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
[1850/2000] tot_loss=1.511 (perp=7.161, rec=0.078, cos=0.000), tot_loss_proj:1.765 [t=0.28s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=7.161, rec=0.072, cos=0.000), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
[1950/2000] tot_loss=1.506 (perp=7.161, rec=0.073, cos=0.000), tot_loss_proj:1.764 [t=0.27s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Attempt swap
[2000/2000] tot_loss=1.507 (perp=7.161, rec=0.075, cos=0.000), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]erfk has a tougher time balancing its violence philosophy with timea inspired [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 85.714 | r: 92.308
rouge2     | fm: 48.000 | p: 46.154 | r: 50.000
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 136.889

[Aggregate metrics]:
rouge1     | fm: 92.032 | p: 91.415 | r: 92.806
rouge2     | fm: 59.697 | p: 59.339 | r: 60.039
rougeL     | fm: 79.200 | p: 78.571 | r: 79.858
rougeLsum  | fm: 79.130 | p: 78.542 | r: 79.751
r1fm+r2fm = 151.729

input #72 time: 0:11:15 | total time: 13:01:56


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
*********************************
*********************************
average of cosine similarity 0.9991742100892312
highest_index [0]
highest [0.9991742100892312]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9927911758422852 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.969111442565918 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9550182819366455 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9139609336853027 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.9138845801353455 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 0.9065971970558167 for ['[CLS]dicated circles [SEP]']
[Init] best rec loss: 0.8424801230430603 for ['[CLS] tierney sector [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.868 (perp=13.015, rec=0.265, cos=0.000), tot_loss_proj:3.040 [t=0.26s]
prediction: ['[CLS] filmmaking bad [SEP]']
[ 100/2000] tot_loss=2.697 (perp=13.015, rec=0.094, cos=0.000), tot_loss_proj:3.056 [t=0.26s]
prediction: ['[CLS] filmmaking bad [SEP]']
[ 150/2000] tot_loss=2.681 (perp=13.015, rec=0.078, cos=0.000), tot_loss_proj:3.056 [t=0.26s]
prediction: ['[CLS] filmmaking bad [SEP]']
[ 200/2000] tot_loss=2.679 (perp=13.015, rec=0.076, cos=0.000), tot_loss_proj:3.056 [t=0.28s]
prediction: ['[CLS] filmmaking bad [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.029 (perp=9.724, rec=0.084, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.017 (perp=9.724, rec=0.072, cos=0.000), tot_loss_proj:2.008 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.000 (perp=9.724, rec=0.055, cos=0.000), tot_loss_proj:2.024 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.005 (perp=9.724, rec=0.061, cos=0.000), tot_loss_proj:2.015 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.004 (perp=9.724, rec=0.059, cos=0.000), tot_loss_proj:2.020 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=9.724, rec=0.053, cos=0.000), tot_loss_proj:2.026 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=9.724, rec=0.056, cos=0.000), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.014 (perp=9.724, rec=0.070, cos=0.000), tot_loss_proj:2.027 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.013 (perp=9.724, rec=0.068, cos=0.000), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.009 (perp=9.724, rec=0.064, cos=0.000), tot_loss_proj:2.028 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.008 (perp=9.724, rec=0.063, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.005 (perp=9.724, rec=0.060, cos=0.000), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.002 (perp=9.724, rec=0.057, cos=0.000), tot_loss_proj:2.020 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.006 (perp=9.724, rec=0.061, cos=0.000), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.995 (perp=9.724, rec=0.050, cos=0.000), tot_loss_proj:2.005 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.000 (perp=9.724, rec=0.055, cos=0.000), tot_loss_proj:2.018 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.008 (perp=9.724, rec=0.064, cos=0.000), tot_loss_proj:2.016 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.012 (perp=9.724, rec=0.067, cos=0.000), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.004 (perp=9.724, rec=0.059, cos=0.000), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.008 (perp=9.724, rec=0.063, cos=0.000), tot_loss_proj:2.016 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.006 (perp=9.724, rec=0.062, cos=0.000), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.002 (perp=9.724, rec=0.058, cos=0.000), tot_loss_proj:2.024 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=1.999 (perp=9.724, rec=0.054, cos=0.000), tot_loss_proj:2.013 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.007 (perp=9.724, rec=0.062, cos=0.000), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.009 (perp=9.724, rec=0.065, cos=0.000), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.009 (perp=9.724, rec=0.064, cos=0.000), tot_loss_proj:2.017 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.008 (perp=9.724, rec=0.064, cos=0.000), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.003 (perp=9.724, rec=0.059, cos=0.000), tot_loss_proj:2.017 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.002 (perp=9.724, rec=0.057, cos=0.000), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.013 (perp=9.724, rec=0.068, cos=0.000), tot_loss_proj:2.021 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.003 (perp=9.724, rec=0.058, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.008 (perp=9.724, rec=0.064, cos=0.000), tot_loss_proj:2.006 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.012 (perp=9.724, rec=0.067, cos=0.000), tot_loss_proj:2.015 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.015 (perp=9.724, rec=0.070, cos=0.000), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.003 (perp=9.724, rec=0.058, cos=0.000), tot_loss_proj:2.010 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.002 (perp=9.724, rec=0.057, cos=0.000), tot_loss_proj:2.004 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.170 | p: 91.513 | r: 92.966
rouge2     | fm: 60.094 | p: 59.785 | r: 60.515
rougeL     | fm: 79.426 | p: 78.897 | r: 80.066
rougeLsum  | fm: 79.337 | p: 78.765 | r: 80.032
r1fm+r2fm = 152.264

input #73 time: 0:11:08 | total time: 13:13:05


Running input #74 of 100.
reference: 
========================
share 
========================
*********************************
*********************************
average of cosine similarity 0.9992586471115836
highest_index [0]
highest [0.9992586471115836]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0052329301834106 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.685093879699707 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6562045216560364 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.921 (perp=9.382, rec=0.869, cos=0.176), tot_loss_proj:2.940 [t=0.29s]
prediction: ['[CLS] change [SEP]']
[ 100/2000] tot_loss=2.872 (perp=10.499, rec=0.772, cos=0.000), tot_loss_proj:3.629 [t=0.28s]
prediction: ['[CLS] blank [SEP]']
[ 150/2000] tot_loss=2.828 (perp=10.499, rec=0.728, cos=0.000), tot_loss_proj:3.619 [t=0.28s]
prediction: ['[CLS] blank [SEP]']
[ 200/2000] tot_loss=2.811 (perp=10.499, rec=0.712, cos=0.000), tot_loss_proj:3.627 [t=0.27s]
prediction: ['[CLS] blank [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.798 (perp=10.499, rec=0.698, cos=0.000), tot_loss_proj:3.626 [t=0.27s]
prediction: ['[CLS] blank [SEP]']
[ 300/2000] tot_loss=2.585 (perp=9.419, rec=0.674, cos=0.028), tot_loss_proj:3.166 [t=0.26s]
prediction: ['[CLS] clue [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.008 (perp=6.483, rec=0.686, cos=0.026), tot_loss_proj:2.502 [t=0.26s]
prediction: ['[CLS] poems [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.280 (perp=8.178, rec=0.645, cos=0.000), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.285 (perp=8.178, rec=0.649, cos=0.000), tot_loss_proj:1.975 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.287 (perp=8.178, rec=0.651, cos=0.000), tot_loss_proj:1.979 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.287 (perp=8.178, rec=0.640, cos=0.012), tot_loss_proj:1.932 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.265 (perp=8.178, rec=0.630, cos=0.000), tot_loss_proj:1.939 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.274 (perp=8.178, rec=0.638, cos=0.000), tot_loss_proj:1.942 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.253 (perp=8.178, rec=0.617, cos=0.000), tot_loss_proj:1.929 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.269 (perp=8.178, rec=0.633, cos=0.000), tot_loss_proj:1.934 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.257 (perp=8.178, rec=0.622, cos=0.000), tot_loss_proj:1.914 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.252 (perp=8.178, rec=0.617, cos=0.000), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.239 (perp=8.178, rec=0.603, cos=0.000), tot_loss_proj:1.900 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.243 (perp=8.178, rec=0.607, cos=0.000), tot_loss_proj:1.889 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.246 (perp=8.178, rec=0.609, cos=0.001), tot_loss_proj:1.881 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.245 (perp=8.178, rec=0.606, cos=0.003), tot_loss_proj:1.887 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.246 (perp=8.178, rec=0.611, cos=0.000), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.235 (perp=8.178, rec=0.599, cos=0.000), tot_loss_proj:1.879 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.235 (perp=8.178, rec=0.600, cos=0.000), tot_loss_proj:1.872 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.231 (perp=8.178, rec=0.596, cos=0.000), tot_loss_proj:1.855 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.237 (perp=8.178, rec=0.601, cos=0.000), tot_loss_proj:1.867 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.227 (perp=8.178, rec=0.592, cos=0.000), tot_loss_proj:1.839 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.222 (perp=8.178, rec=0.586, cos=0.000), tot_loss_proj:1.848 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.224 (perp=8.178, rec=0.589, cos=0.000), tot_loss_proj:1.847 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.217 (perp=8.178, rec=0.581, cos=0.000), tot_loss_proj:1.826 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.227 (perp=8.178, rec=0.591, cos=0.000), tot_loss_proj:1.832 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.222 (perp=8.178, rec=0.587, cos=0.000), tot_loss_proj:1.828 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.223 (perp=8.178, rec=0.588, cos=0.000), tot_loss_proj:1.840 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.226 (perp=8.178, rec=0.591, cos=0.000), tot_loss_proj:1.835 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.223 (perp=8.178, rec=0.587, cos=0.000), tot_loss_proj:1.829 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.220 (perp=8.178, rec=0.584, cos=0.000), tot_loss_proj:1.830 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.220 (perp=8.178, rec=0.585, cos=0.000), tot_loss_proj:1.814 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.215 (perp=8.178, rec=0.580, cos=0.000), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.224 (perp=8.178, rec=0.589, cos=0.000), tot_loss_proj:1.810 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.220 (perp=8.178, rec=0.584, cos=0.000), tot_loss_proj:1.829 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.274 | p: 91.623 | r: 93.042
rouge2     | fm: 60.679 | p: 60.375 | r: 61.093
rougeL     | fm: 79.612 | p: 79.081 | r: 80.230
rougeLsum  | fm: 79.680 | p: 79.108 | r: 80.301
r1fm+r2fm = 152.953

input #74 time: 0:11:15 | total time: 13:24:20


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
*********************************
*********************************
average of cosine similarity 0.9993453151136955
highest_index [0]
highest [0.9993453151136955]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9618315696716309 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9597263932228088 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 0.9510676264762878 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.941656231880188 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.905746340751648 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8959568738937378 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8942171335220337 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8857147097587585 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8665376305580139 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8657839298248291 for ['[CLS] loop auxiliary viewed magiccl apollo regarded royalties crown to skillrateception left fact each resultedmmel stood [SEP]']
[Init] best perm rec loss: 0.865285336971283 for ['[CLS] torate resultedcl viewed stood auxiliary skillception regarded royalties loopmmel fact apollo magic crown each left [SEP]']
[Init] best perm rec loss: 0.8634203672409058 for ['[CLS] fact stood skill regarded loop crown apolloception eachrate resultedcl royalties magic viewed to left auxiliarymmel [SEP]']
[Init] best perm rec loss: 0.8621346950531006 for ['[CLS] to eachrate left regarded apollo crown royalties fact auxiliaryceptioncl viewed resulted magicmmel skill loop stood [SEP]']
[Init] best perm rec loss: 0.8615400791168213 for ['[CLS] to resulted loop regarded skill left viewed auxiliaryratecl apollo magic stoodmmelception fact each royalties crown [SEP]']
[Init] best perm rec loss: 0.8605470657348633 for ['[CLS] toclception regarded left crown skill resulted auxiliarymmel magic apollo stood eachrate viewed royalties loop fact [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.712 (perp=11.168, rec=0.479, cos=0.000), tot_loss_proj:3.824 [t=0.26s]
prediction: ['[CLS] continue playing league courtney stability unfortunately out delicious innocent doubles successceae lovers occasionally peter hotel opportunities several. [SEP]']
[ 100/2000] tot_loss=2.613 (perp=11.649, rec=0.283, cos=0.000), tot_loss_proj:3.565 [t=0.27s]
prediction: ['[CLS] continue playing league mcc operated managingurable consecutive moments isn success dangerous novels not forgotten internal sometimes dangerous. [SEP]']
[ 150/2000] tot_loss=2.405 (perp=10.937, rec=0.217, cos=0.000), tot_loss_proj:2.970 [t=0.27s]
prediction: ['[CLS] continue playing matters mcc virtual managing into intense classic is excursioncious novels not forgotten easily or gotten. [SEP]']
[ 200/2000] tot_loss=2.097 (perp=9.633, rec=0.171, cos=0.000), tot_loss_proj:3.126 [t=0.26s]
prediction: ['[CLS] continue playing intobelt virtual concerns into excursion selena is excursion instability instability not forgotten easily or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.908 (perp=8.722, rec=0.163, cos=0.000), tot_loss_proj:3.137 [t=0.27s]
prediction: ['[CLS] continue this intobelt products endangered into excursion favorites is excursion instability instability not easily forgotten or forgotten. [SEP]']
[ 300/2000] tot_loss=1.814 (perp=8.417, rec=0.131, cos=0.000), tot_loss_proj:3.103 [t=0.26s]
prediction: ['[CLS] continue this intobelt virtualters into this largest is excursion instability instability not easily forgotten or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.875 (perp=8.769, rec=0.121, cos=0.000), tot_loss_proj:2.828 [t=0.28s]
prediction: ['[CLS] this continue intosphere virtualters into thisenter is excursion instability instability not easily forgotten or forgotten. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.820 (perp=8.387, rec=0.143, cos=0.000), tot_loss_proj:2.775 [t=0.27s]
prediction: ['[CLS] this continue into travels is into of thiscola instability excursion instability instability not easily forgotten or forgotten. [SEP]']
[ 450/2000] tot_loss=1.912 (perp=8.999, rec=0.112, cos=0.000), tot_loss_proj:2.989 [t=0.27s]
prediction: ['[CLS] this continue into travels is intoenter thiscola instability excursion instability instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.693 (perp=7.947, rec=0.104, cos=0.000), tot_loss_proj:3.064 [t=0.27s]
prediction: ['[CLS] this excursion into journey is intoenter thiscola instability continue mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.664 (perp=7.795, rec=0.105, cos=0.000), tot_loss_proj:3.034 [t=0.26s]
prediction: ['[CLS] this excursion into this journey is intoentercola instability continue mental instability not easily forgotten or dismissed. [SEP]']
[ 600/2000] tot_loss=1.638 (perp=7.795, rec=0.079, cos=0.000), tot_loss_proj:3.051 [t=0.26s]
prediction: ['[CLS] this excursion into this journey is intoentercola instability continue mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.603 (perp=7.595, rec=0.084, cos=0.000), tot_loss_proj:2.458 [t=0.27s]
prediction: ['[CLS] this excursion into this journey is intoentercola mental instability instability continue not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.727 (perp=8.186, rec=0.090, cos=0.000), tot_loss_proj:2.747 [t=0.28s]
prediction: ['[CLS] this excursionenter this journey is into instabilityentercola mental instability continue not easily forgotten or dismissed. [SEP]']
[ 750/2000] tot_loss=1.722 (perp=8.186, rec=0.085, cos=0.000), tot_loss_proj:2.754 [t=0.28s]
prediction: ['[CLS] this excursionenter this journey is into instabilityentercola mental instability continue not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.678 (perp=7.965, rec=0.085, cos=0.000), tot_loss_proj:2.123 [t=0.28s]
prediction: ['[CLS] this excursionenter this journey into instabilityentercola mental instability continue is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.568 (perp=7.415, rec=0.085, cos=0.000), tot_loss_proj:1.981 [t=0.27s]
prediction: ['[CLS] this excursion continue this journey into instabilityentercola mental instabilityenter is not easily forgotten or dismissed. [SEP]']
[ 900/2000] tot_loss=1.572 (perp=7.415, rec=0.089, cos=0.000), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] this excursion continue this journey into instabilityentercola mental instabilityenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.663 (perp=7.944, rec=0.074, cos=0.000), tot_loss_proj:2.059 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into instabilityentercola mental mentalenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.634 (perp=7.747, rec=0.085, cos=0.000), tot_loss_proj:2.032 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into instabilitycola mental mentalenterenter is not easily forgotten or dismissed. [SEP]']
[1050/2000] tot_loss=1.631 (perp=7.747, rec=0.082, cos=0.000), tot_loss_proj:2.025 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into instabilitycola mental mentalenterenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.680 (perp=8.027, rec=0.075, cos=0.000), tot_loss_proj:2.082 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into instabilityed mentalenter mentalenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.588 (perp=7.510, rec=0.086, cos=0.000), tot_loss_proj:1.929 [t=0.31s]
prediction: ['[CLS] this excursion continue this journey into mental instabilityed mentalenterenter is not easily forgotten or dismissed. [SEP]']
[1200/2000] tot_loss=1.581 (perp=7.510, rec=0.079, cos=0.000), tot_loss_proj:1.935 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into mental instabilityed mentalenterenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.576 (perp=7.510, rec=0.074, cos=0.000), tot_loss_proj:1.940 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into mental instabilityed mentalenterenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.558 (perp=7.376, rec=0.083, cos=0.000), tot_loss_proj:1.944 [t=0.29s]
prediction: ['[CLS] this excursion continue this journey into mental instability mentalenteredenter is not easily forgotten or dismissed. [SEP]']
[1350/2000] tot_loss=1.558 (perp=7.376, rec=0.083, cos=0.000), tot_loss_proj:1.944 [t=0.28s]
prediction: ['[CLS] this excursion continue this journey into mental instability mentalenteredenter is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.533 (perp=7.287, rec=0.076, cos=0.000), tot_loss_proj:1.921 [t=0.28s]
prediction: ['[CLS] this excursion continue this journey into mental instability mentalenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.508 (perp=7.167, rec=0.075, cos=0.000), tot_loss_proj:1.940 [t=0.27s]
prediction: ['[CLS] this excursion continue this journey into mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
[1500/2000] tot_loss=1.516 (perp=7.167, rec=0.083, cos=0.000), tot_loss_proj:1.937 [t=0.28s]
prediction: ['[CLS] this excursion continue this journey into mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.518 (perp=7.167, rec=0.084, cos=0.000), tot_loss_proj:1.958 [t=0.27s]
prediction: ['[CLS] this excursion continue this journey into mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.506 (perp=7.167, rec=0.073, cos=0.000), tot_loss_proj:1.949 [t=0.27s]
prediction: ['[CLS] this excursion continue this journey into mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
[1650/2000] tot_loss=1.510 (perp=7.167, rec=0.077, cos=0.000), tot_loss_proj:1.959 [t=0.27s]
prediction: ['[CLS] this excursion continue this journey into mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.550 (perp=7.358, rec=0.078, cos=0.000), tot_loss_proj:1.894 [t=0.27s]
prediction: ['[CLS] the excursion into this journey continue mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.493 (perp=7.060, rec=0.081, cos=0.000), tot_loss_proj:1.882 [t=0.28s]
prediction: ['[CLS] the excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
[1800/2000] tot_loss=1.494 (perp=7.060, rec=0.082, cos=0.000), tot_loss_proj:1.882 [t=0.28s]
prediction: ['[CLS] the excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.477 (perp=7.060, rec=0.065, cos=0.000), tot_loss_proj:1.881 [t=0.26s]
prediction: ['[CLS] the excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.479 (perp=7.060, rec=0.067, cos=0.000), tot_loss_proj:1.871 [t=0.27s]
prediction: ['[CLS] the excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
[1950/2000] tot_loss=1.597 (perp=7.621, rec=0.073, cos=0.000), tot_loss_proj:2.008 [t=0.29s]
prediction: ['[CLS] epic excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.606 (perp=7.621, rec=0.082, cos=0.000), tot_loss_proj:2.003 [t=0.28s]
prediction: ['[CLS] epic excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] the excursion continue into this journey mental mental instabilityenterentered is not easily forgotten or dismissed. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 88.971

[Aggregate metrics]:
rouge1     | fm: 92.049 | p: 91.384 | r: 92.795
rouge2     | fm: 60.279 | p: 60.001 | r: 60.635
rougeL     | fm: 79.334 | p: 78.725 | r: 79.945
rougeLsum  | fm: 79.312 | p: 78.735 | r: 79.960
r1fm+r2fm = 152.329

input #75 time: 0:11:19 | total time: 13:35:40


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
*********************************
*********************************
average of cosine similarity 0.9991396461793809
highest_index [0]
highest [0.9991396461793809]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9205226898193359 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9014512300491333 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.897919237613678 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.8925905227661133 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8711327910423279 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8609960675239563 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.854517936706543 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8516943454742432 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoˣ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8500584363937378 for ['[CLS] backward surreal onwards leftˣ hardoning pushed mango ab ( taut pursehaw [SEP]']
[Init] best perm rec loss: 0.8497618436813354 for ['[CLS] taut pushed backward purse abˣ ( onwards surrealhaw hard mangooning left [SEP]']
[Init] best perm rec loss: 0.8475678563117981 for ['[CLS] ab hardhaw taut onwardsoning left pushed backwardˣ ( surreal purse mango [SEP]']
[Init] best perm rec loss: 0.8462727069854736 for ['[CLS] mango left pushed ( backwardˣ onwards hard surreal taut aboning pursehaw [SEP]']
[Init] best perm rec loss: 0.8460181951522827 for ['[CLS] taut backwardhaw leftoning onwardsˣ ( ab hard pushed surreal mango purse [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.821 (perp=12.213, rec=0.378, cos=0.000), tot_loss_proj:3.383 [t=0.26s]
prediction: ['[CLS] junk collapse category hit. gm shell had stoppedlessburn like premises career [SEP]']
[ 100/2000] tot_loss=2.305 (perp=10.298, rec=0.246, cos=0.000), tot_loss_proj:3.139 [t=0.26s]
prediction: ["[CLS].'army hit. gm sources has stopped disabled stopped like yards challenging [SEP]"]
[ 150/2000] tot_loss=2.316 (perp=10.669, rec=0.182, cos=0.000), tot_loss_proj:3.607 [t=0.28s]
prediction: ["[CLS] while'escort plug. rawballs has stopped hard stopped if allen challenging [SEP]"]
[ 200/2000] tot_loss=2.160 (perp=10.021, rec=0.156, cos=0.000), tot_loss_proj:3.152 [t=0.25s]
prediction: ["[CLS] when'often 1960s, raw dealers has stopped as stopped as allen challenging [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=1.935 (perp=8.830, rec=0.169, cos=0.000), tot_loss_proj:2.665 [t=0.26s]
prediction: ["[CLS] at'66,. row 66 has stopped as stopped as allen challenging [SEP]"]
[ 300/2000] tot_loss=1.832 (perp=8.464, rec=0.139, cos=0.000), tot_loss_proj:2.661 [t=0.26s]
prediction: ["[CLS] at'66,, 35 66 has stopped as, as allen challenging [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.762 (perp=8.153, rec=0.132, cos=0.000), tot_loss_proj:2.644 [t=0.25s]
prediction: ["[CLS] at'66, 35, 66 has stopped as is as himself challenging [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.206 (perp=9.196, rec=0.366, cos=0.000), tot_loss_proj:2.886 [t=0.27s]
prediction: ["[CLS] at'[... 36., has stopped b challenging as himself'[SEP]"]
[ 450/2000] tot_loss=2.141 (perp=9.287, rec=0.284, cos=0.000), tot_loss_proj:2.945 [t=0.28s]
prediction: ["[CLS] at'[channel 36., has stoppedm challenging as himself. [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.798 (perp=7.799, rec=0.238, cos=0.000), tot_loss_proj:2.295 [t=0.26s]
prediction: ["[CLS] at'[ marker 36.,m has stopped challenging as himself. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.719 (perp=7.489, rec=0.221, cos=0.000), tot_loss_proj:2.184 [t=0.26s]
prediction: ["[CLS] at ['marker 36.,m has stopped challenging as himself. [SEP]"]
[ 600/2000] tot_loss=1.737 (perp=7.703, rec=0.197, cos=0.000), tot_loss_proj:2.223 [t=0.25s]
prediction: ["[CLS] at ['farm 36.,m has stopped challenging as himself. [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.773 (perp=7.897, rec=0.194, cos=0.000), tot_loss_proj:2.258 [t=0.26s]
prediction: ["[CLS] at ['farm 36.,r has stopped challenging as himself. [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.857 (perp=8.368, rec=0.183, cos=0.000), tot_loss_proj:2.441 [t=0.26s]
prediction: ['[CLS] [ ( farm at 36.,m has stopped challenging as himself. [SEP]']
[ 750/2000] tot_loss=1.927 (perp=8.780, rec=0.171, cos=0.000), tot_loss_proj:2.563 [t=0.27s]
prediction: ['[CLS] [ ( farm at 36., 16 has stopped challenging as himself. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.900 (perp=8.698, rec=0.161, cos=0.000), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS] [ ( farm at. 36, 16 has stopped challenging as himself. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.847 (perp=8.353, rec=0.176, cos=0.000), tot_loss_proj:2.503 [t=0.27s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging. as himself. [SEP]']
[ 900/2000] tot_loss=1.835 (perp=8.353, rec=0.165, cos=0.000), tot_loss_proj:2.506 [t=0.28s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging. as himself. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.799 (perp=8.196, rec=0.160, cos=0.000), tot_loss_proj:2.447 [t=0.28s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.798 (perp=8.196, rec=0.158, cos=0.000), tot_loss_proj:2.458 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1050/2000] tot_loss=1.798 (perp=8.196, rec=0.159, cos=0.000), tot_loss_proj:2.451 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.795 (perp=8.196, rec=0.156, cos=0.000), tot_loss_proj:2.452 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.803 (perp=8.196, rec=0.163, cos=0.000), tot_loss_proj:2.456 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1200/2000] tot_loss=1.785 (perp=8.196, rec=0.145, cos=0.000), tot_loss_proj:2.455 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.798 (perp=8.196, rec=0.159, cos=0.000), tot_loss_proj:2.445 [t=0.31s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.788 (perp=8.196, rec=0.149, cos=0.000), tot_loss_proj:2.451 [t=0.34s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1350/2000] tot_loss=1.782 (perp=8.196, rec=0.143, cos=0.000), tot_loss_proj:2.449 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.793 (perp=8.196, rec=0.154, cos=0.000), tot_loss_proj:2.452 [t=0.32s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.781 (perp=8.196, rec=0.142, cos=0.000), tot_loss_proj:2.452 [t=0.29s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1500/2000] tot_loss=1.793 (perp=8.196, rec=0.154, cos=0.000), tot_loss_proj:2.452 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.783 (perp=8.196, rec=0.143, cos=0.000), tot_loss_proj:2.456 [t=0.29s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.774 (perp=8.196, rec=0.135, cos=0.000), tot_loss_proj:2.444 [t=0.29s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1650/2000] tot_loss=1.789 (perp=8.196, rec=0.150, cos=0.000), tot_loss_proj:2.454 [t=0.29s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.787 (perp=8.196, rec=0.148, cos=0.000), tot_loss_proj:2.452 [t=0.28s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.795 (perp=8.196, rec=0.156, cos=0.000), tot_loss_proj:2.455 [t=0.28s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1800/2000] tot_loss=1.793 (perp=8.196, rec=0.154, cos=0.000), tot_loss_proj:2.450 [t=0.29s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.778 (perp=8.196, rec=0.138, cos=0.000), tot_loss_proj:2.450 [t=0.34s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.792 (perp=8.196, rec=0.153, cos=0.000), tot_loss_proj:2.452 [t=0.33s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
[1950/2000] tot_loss=1.778 (perp=8.196, rec=0.139, cos=0.000), tot_loss_proj:2.457 [t=0.29s]
prediction: ['[CLS] [ ( farm at 36, 16 has stopped challenging himself as.. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.755 (perp=8.000, rec=0.155, cos=0.000), tot_loss_proj:2.409 [t=0.29s]
prediction: ['[CLS] [ ( 16 farm at 36, has stopped challenging himself as.. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] at'66, 66,, has stopped as is as himself challenging [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 102.273

[Aggregate metrics]:
rouge1     | fm: 91.828 | p: 91.216 | r: 92.574
rouge2     | fm: 59.609 | p: 59.329 | r: 59.948
rougeL     | fm: 79.124 | p: 78.587 | r: 79.740
rougeLsum  | fm: 79.092 | p: 78.574 | r: 79.673
r1fm+r2fm = 151.437

input #76 time: 0:11:38 | total time: 13:47:19


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
*********************************
*********************************
average of cosine similarity 0.9992010794940915
highest_index [0]
highest [0.9992010794940915]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.913427472114563 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.9125373363494873 for ['[CLS] luther around domestic capacity unclear film four wing 1902 best capacity action nur say santos [SEP]']
[Init] best rec loss: 0.8778700828552246 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8727616667747498 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.871478259563446 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8687657713890076 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8680912852287292 for ['[CLS] matthew rural countyyanalson something poet endless yugoslav tel blacksmith pencil daylightdrop gallery [SEP]']
[Init] best perm rec loss: 0.8680518269538879 for ['[CLS] yugoslavyana gallerydroplson endless rural daylight pencil blacksmith something poet county matthew tel [SEP]']
[Init] best perm rec loss: 0.8669929504394531 for ['[CLS] daylight county pencil blacksmithdroplson endless yugoslav rural gallery something tel poet matthewyana [SEP]']
[Init] best perm rec loss: 0.8643523454666138 for ['[CLS] somethingdrop matthew pencil yugoslav tel daylight rural gallery blacksmithlson endless countyyana poet [SEP]']
[Init] best perm rec loss: 0.8635179996490479 for ['[CLS] yugoslavdropyana something rurallson pencil daylight blacksmith endless tel poet matthew county gallery [SEP]']
[Init] best perm rec loss: 0.861438512802124 for ['[CLS] pencillsondrop county something endless gallery matthew rural yugoslav tel poet blacksmithyana daylight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.147 (perp=13.887, rec=0.370, cos=0.000), tot_loss_proj:3.462 [t=0.29s]
prediction: ['[CLS] legend eternity truth heavenly victims outstanding scenes energy willow high final academy true is claims [SEP]']
[ 100/2000] tot_loss=2.634 (perp=11.757, rec=0.283, cos=0.000), tot_loss_proj:3.064 [t=0.27s]
prediction: ['[CLS]l above promisethe life bo gallery promise that makes final academyn is the [SEP]']
[ 150/2000] tot_loss=2.246 (perp=9.973, rec=0.252, cos=0.000), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] is above promise ec life its life promise that make believed academy material is made [SEP]']
[ 200/2000] tot_loss=1.820 (perp=8.091, rec=0.201, cos=0.000), tot_loss_proj:2.580 [t=0.27s]
prediction: ['[CLS] is above promise its life its life promise that make believe society material is made [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.004 (perp=9.045, rec=0.195, cos=0.000), tot_loss_proj:2.467 [t=0.27s]
prediction: ['[CLS] is promise its life which life promisears above make believe love material is realm [SEP]']
[ 300/2000] tot_loss=2.008 (perp=9.270, rec=0.154, cos=0.000), tot_loss_proj:2.710 [t=0.28s]
prediction: ['[CLS] is promise its life that life promisears above make believe grief material is realm [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.821 (perp=8.404, rec=0.141, cos=0.000), tot_loss_proj:2.805 [t=0.27s]
prediction: ['[CLS] is promise its life that life promisears above make believe realm material is grief [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.767 (perp=8.215, rec=0.124, cos=0.000), tot_loss_proj:2.369 [t=0.28s]
prediction: ['[CLS] is promise its promise that life lifears above make believe realm material is realm [SEP]']
[ 450/2000] tot_loss=1.753 (perp=8.215, rec=0.110, cos=0.000), tot_loss_proj:2.376 [t=0.28s]
prediction: ['[CLS] is promise its promise that life lifears above make believe realm material is realm [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.689 (perp=7.859, rec=0.117, cos=0.000), tot_loss_proj:2.384 [t=0.26s]
prediction: ['[CLS] is life promise its promise that lifears above make believe realm material is realm [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.927 (perp=9.027, rec=0.122, cos=0.000), tot_loss_proj:2.465 [t=0.34s]
prediction: ['[CLS] is life promise nicholas its promise that lifears above make believe realm material realm [SEP]']
[ 600/2000] tot_loss=1.930 (perp=9.084, rec=0.113, cos=0.000), tot_loss_proj:2.310 [t=0.29s]
prediction: ['[CLS] is life promise nicholas its promise that soars above make believe realm material realm [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.764 (perp=8.285, rec=0.107, cos=0.000), tot_loss_proj:2.163 [t=0.27s]
prediction: ['[CLS] nicholas is life promise its promise that soars above make believe realm material realm [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.738 (perp=8.111, rec=0.116, cos=0.000), tot_loss_proj:2.111 [t=0.28s]
prediction: ['[CLS] nicholas is life promise that its promise soars above make believe realm material realm [SEP]']
[ 750/2000] tot_loss=1.763 (perp=8.340, rec=0.095, cos=0.000), tot_loss_proj:2.158 [t=0.28s]
prediction: ['[CLS] are is life promise that its promise soars above make believe realm material / [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.584 (perp=7.425, rec=0.099, cos=0.000), tot_loss_proj:1.993 [t=0.28s]
prediction: ['[CLS] the life is promise that its promise soars above make believe realm material - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.543 (perp=7.292, rec=0.085, cos=0.000), tot_loss_proj:1.955 [t=0.27s]
prediction: ['[CLS] the life is promise that its promise soars above make believe material realm - [SEP]']
[ 900/2000] tot_loss=1.551 (perp=7.292, rec=0.093, cos=0.000), tot_loss_proj:1.951 [t=0.28s]
prediction: ['[CLS] the life is promise that its promise soars above make believe material realm - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.548 (perp=7.292, rec=0.089, cos=0.000), tot_loss_proj:1.953 [t=0.27s]
prediction: ['[CLS] the life is promise that its promise soars above make believe material realm - [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.512 (perp=7.099, rec=0.092, cos=0.000), tot_loss_proj:1.840 [t=0.27s]
prediction: ['[CLS] the life is its promise that promise soars above make believe material realm - [SEP]']
[1050/2000] tot_loss=1.502 (perp=7.099, rec=0.082, cos=0.000), tot_loss_proj:1.847 [t=0.27s]
prediction: ['[CLS] the life is its promise that promise soars above make believe material realm - [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.423 (perp=6.700, rec=0.083, cos=0.000), tot_loss_proj:1.795 [t=0.26s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.428 (perp=6.700, rec=0.088, cos=0.000), tot_loss_proj:1.797 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
[1200/2000] tot_loss=1.419 (perp=6.700, rec=0.079, cos=0.000), tot_loss_proj:1.794 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.418 (perp=6.700, rec=0.078, cos=0.000), tot_loss_proj:1.793 [t=0.27s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.413 (perp=6.700, rec=0.073, cos=0.000), tot_loss_proj:1.790 [t=0.27s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
[1350/2000] tot_loss=1.420 (perp=6.700, rec=0.080, cos=0.000), tot_loss_proj:1.791 [t=0.27s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.422 (perp=6.700, rec=0.082, cos=0.000), tot_loss_proj:1.799 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.416 (perp=6.700, rec=0.076, cos=0.000), tot_loss_proj:1.798 [t=0.29s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
[1500/2000] tot_loss=1.428 (perp=6.700, rec=0.088, cos=0.000), tot_loss_proj:1.796 [t=0.29s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.417 (perp=6.700, rec=0.077, cos=0.000), tot_loss_proj:1.793 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.423 (perp=6.700, rec=0.083, cos=0.000), tot_loss_proj:1.798 [t=0.27s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
[1650/2000] tot_loss=1.402 (perp=6.700, rec=0.062, cos=0.000), tot_loss_proj:1.799 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.405 (perp=6.700, rec=0.066, cos=0.000), tot_loss_proj:1.792 [t=0.27s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.411 (perp=6.700, rec=0.071, cos=0.000), tot_loss_proj:1.793 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
[1800/2000] tot_loss=1.422 (perp=6.700, rec=0.082, cos=0.000), tot_loss_proj:1.793 [t=0.27s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.423 (perp=6.700, rec=0.083, cos=0.000), tot_loss_proj:1.794 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.410 (perp=6.700, rec=0.070, cos=0.000), tot_loss_proj:1.794 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
[1950/2000] tot_loss=1.420 (perp=6.700, rec=0.080, cos=0.000), tot_loss_proj:1.795 [t=0.28s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.405 (perp=6.700, rec=0.065, cos=0.000), tot_loss_proj:1.791 [t=0.30s]
prediction: ['[CLS] the promise is its promise that life soars above make believe material realm - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] the promise is its promise that life soars above make believe material realm - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 129.048

[Aggregate metrics]:
rouge1     | fm: 91.802 | p: 91.153 | r: 92.547
rouge2     | fm: 59.298 | p: 59.006 | r: 59.676
rougeL     | fm: 78.900 | p: 78.345 | r: 79.534
rougeLsum  | fm: 78.887 | p: 78.365 | r: 79.473
r1fm+r2fm = 151.101

input #77 time: 0:11:23 | total time: 13:58:42


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
*********************************
*********************************
average of cosine similarity 0.9992698971123128
highest_index [0]
highest [0.9992698971123128]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.985163152217865 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9773079752922058 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8533859848976135 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8280754685401917 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.8269926309585571 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 0.8269504904747009 for ['[CLS] screens le grant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.287 (perp=9.835, rec=0.320, cos=0.000), tot_loss_proj:2.968 [t=0.26s]
prediction: ['[CLS] exit shut exit [SEP]']
[ 100/2000] tot_loss=1.702 (perp=7.444, rec=0.214, cos=0.000), tot_loss_proj:2.461 [t=0.25s]
prediction: ['[CLS] exit exit exit [SEP]']
[ 150/2000] tot_loss=1.939 (perp=8.924, rec=0.154, cos=0.000), tot_loss_proj:2.605 [t=0.27s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 200/2000] tot_loss=1.899 (perp=8.924, rec=0.114, cos=0.000), tot_loss_proj:2.609 [t=0.28s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.095 (perp=10.073, rec=0.080, cos=0.000), tot_loss_proj:3.226 [t=0.25s]
prediction: ['[CLS] theater the exit [SEP]']
[ 300/2000] tot_loss=2.091 (perp=10.073, rec=0.077, cos=0.000), tot_loss_proj:3.223 [t=0.28s]
prediction: ['[CLS] theater the exit [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.692 (perp=8.145, rec=0.064, cos=0.000), tot_loss_proj:2.325 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.702 (perp=8.145, rec=0.073, cos=0.000), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 450/2000] tot_loss=1.709 (perp=8.145, rec=0.080, cos=0.000), tot_loss_proj:2.324 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.694 (perp=8.145, rec=0.065, cos=0.000), tot_loss_proj:2.329 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.700 (perp=8.145, rec=0.071, cos=0.000), tot_loss_proj:2.333 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 600/2000] tot_loss=1.703 (perp=8.145, rec=0.074, cos=0.000), tot_loss_proj:2.324 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.694 (perp=8.145, rec=0.065, cos=0.000), tot_loss_proj:2.325 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.700 (perp=8.145, rec=0.071, cos=0.000), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 750/2000] tot_loss=1.695 (perp=8.145, rec=0.066, cos=0.000), tot_loss_proj:2.328 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.696 (perp=8.145, rec=0.067, cos=0.000), tot_loss_proj:2.322 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.691 (perp=8.145, rec=0.062, cos=0.000), tot_loss_proj:2.322 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 900/2000] tot_loss=1.705 (perp=8.145, rec=0.076, cos=0.000), tot_loss_proj:2.332 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.692 (perp=8.145, rec=0.064, cos=0.000), tot_loss_proj:2.330 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.145, rec=0.072, cos=0.000), tot_loss_proj:2.325 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[1050/2000] tot_loss=1.694 (perp=8.145, rec=0.065, cos=0.000), tot_loss_proj:2.324 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.693 (perp=8.145, rec=0.064, cos=0.000), tot_loss_proj:2.329 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.691 (perp=8.145, rec=0.062, cos=0.000), tot_loss_proj:2.324 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
[1200/2000] tot_loss=1.701 (perp=8.145, rec=0.072, cos=0.000), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.695 (perp=8.145, rec=0.066, cos=0.000), tot_loss_proj:2.324 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.704 (perp=8.145, rec=0.075, cos=0.000), tot_loss_proj:2.328 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[1350/2000] tot_loss=1.697 (perp=8.145, rec=0.068, cos=0.000), tot_loss_proj:2.328 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.697 (perp=8.145, rec=0.068, cos=0.000), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.685 (perp=8.145, rec=0.056, cos=0.000), tot_loss_proj:2.336 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
[1500/2000] tot_loss=1.693 (perp=8.145, rec=0.065, cos=0.000), tot_loss_proj:2.335 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.689 (perp=8.145, rec=0.060, cos=0.000), tot_loss_proj:2.327 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.696 (perp=8.145, rec=0.067, cos=0.000), tot_loss_proj:2.331 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
[1650/2000] tot_loss=1.690 (perp=8.145, rec=0.061, cos=0.000), tot_loss_proj:2.333 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.693 (perp=8.145, rec=0.064, cos=0.000), tot_loss_proj:2.331 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.689 (perp=8.145, rec=0.060, cos=0.000), tot_loss_proj:2.327 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
[1800/2000] tot_loss=1.687 (perp=8.145, rec=0.058, cos=0.000), tot_loss_proj:2.333 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.681 (perp=8.145, rec=0.052, cos=0.000), tot_loss_proj:2.328 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.692 (perp=8.145, rec=0.063, cos=0.000), tot_loss_proj:2.332 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
[1950/2000] tot_loss=1.686 (perp=8.145, rec=0.057, cos=0.000), tot_loss_proj:2.329 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.686 (perp=8.145, rec=0.057, cos=0.000), tot_loss_proj:2.330 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] the theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.914 | p: 91.288 | r: 92.629
rouge2     | fm: 59.018 | p: 58.735 | r: 59.316
rougeL     | fm: 78.864 | p: 78.323 | r: 79.492
rougeLsum  | fm: 78.879 | p: 78.369 | r: 79.446
r1fm+r2fm = 150.932

input #78 time: 0:11:09 | total time: 14:09:52


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
*********************************
*********************************
average of cosine similarity 0.9993336740864431
highest_index [0]
highest [0.9993336740864431]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9752817153930664 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8514729142189026 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8496491312980652 for ['[CLS]rna into [SEP]']
[Init] best rec loss: 0.8476698994636536 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8318015336990356 for ['[CLS] funslow [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.964 (perp=13.766, rec=0.211, cos=0.000), tot_loss_proj:3.214 [t=0.27s]
prediction: ['[CLS] pleased fascinating [SEP]']
[ 100/2000] tot_loss=2.441 (perp=11.427, rec=0.156, cos=0.000), tot_loss_proj:2.609 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=1.963 (perp=9.381, rec=0.087, cos=0.000), tot_loss_proj:1.960 [t=0.27s]
prediction: ['[CLS] is fascinating [SEP]']
[ 200/2000] tot_loss=1.926 (perp=9.381, rec=0.050, cos=0.000), tot_loss_proj:1.951 [t=0.27s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.941 (perp=9.381, rec=0.065, cos=0.000), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] is fascinating [SEP]']
[ 300/2000] tot_loss=1.946 (perp=9.381, rec=0.070, cos=0.000), tot_loss_proj:1.947 [t=0.27s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.938 (perp=9.381, rec=0.062, cos=0.000), tot_loss_proj:1.954 [t=0.26s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.941 (perp=9.381, rec=0.065, cos=0.000), tot_loss_proj:1.943 [t=0.26s]
prediction: ['[CLS] is fascinating [SEP]']
[ 450/2000] tot_loss=1.948 (perp=9.381, rec=0.071, cos=0.000), tot_loss_proj:1.942 [t=0.28s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.927 (perp=9.381, rec=0.051, cos=0.000), tot_loss_proj:1.948 [t=0.26s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.808 (perp=8.695, rec=0.069, cos=0.000), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.804 (perp=8.695, rec=0.065, cos=0.000), tot_loss_proj:1.959 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.807 (perp=8.695, rec=0.068, cos=0.000), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.813 (perp=8.695, rec=0.074, cos=0.000), tot_loss_proj:1.961 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.813 (perp=8.695, rec=0.074, cos=0.000), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=8.695, rec=0.066, cos=0.000), tot_loss_proj:1.964 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.803 (perp=8.695, rec=0.065, cos=0.000), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.801 (perp=8.695, rec=0.062, cos=0.000), tot_loss_proj:1.956 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.695, rec=0.057, cos=0.000), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.805 (perp=8.695, rec=0.066, cos=0.000), tot_loss_proj:1.969 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.798 (perp=8.695, rec=0.059, cos=0.000), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.805 (perp=8.695, rec=0.066, cos=0.000), tot_loss_proj:1.961 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.794 (perp=8.695, rec=0.055, cos=0.000), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.800 (perp=8.695, rec=0.061, cos=0.000), tot_loss_proj:1.956 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.816 (perp=8.695, rec=0.077, cos=0.000), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.793 (perp=8.695, rec=0.054, cos=0.000), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.804 (perp=8.695, rec=0.065, cos=0.000), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.791 (perp=8.695, rec=0.052, cos=0.000), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.800 (perp=8.695, rec=0.061, cos=0.000), tot_loss_proj:1.959 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.806 (perp=8.695, rec=0.067, cos=0.000), tot_loss_proj:1.958 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.802 (perp=8.695, rec=0.063, cos=0.000), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=8.695, rec=0.065, cos=0.000), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.811 (perp=8.695, rec=0.072, cos=0.000), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.820 (perp=8.695, rec=0.081, cos=0.000), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.799 (perp=8.695, rec=0.060, cos=0.000), tot_loss_proj:1.966 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.695, rec=0.057, cos=0.000), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.800 (perp=8.695, rec=0.061, cos=0.000), tot_loss_proj:1.970 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.803 (perp=8.695, rec=0.064, cos=0.000), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.798 (perp=8.695, rec=0.059, cos=0.000), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.808 (perp=8.695, rec=0.069, cos=0.000), tot_loss_proj:1.963 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] is fascinating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.047 | p: 91.414 | r: 92.777
rouge2     | fm: 59.481 | p: 59.204 | r: 59.876
rougeL     | fm: 79.180 | p: 78.675 | r: 79.742
rougeLsum  | fm: 79.218 | p: 78.692 | r: 79.814
r1fm+r2fm = 151.528

input #79 time: 0:11:08 | total time: 14:21:01


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
*********************************
*********************************
average of cosine similarity 0.9992812481413065
highest_index [0]
highest [0.9992812481413065]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9647944569587708 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9647476673126221 for ['[CLS]sol floor stand now district [SEP]']
[Init] best rec loss: 0.9623568654060364 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 0.9388115406036377 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9318601489067078 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9272443056106567 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9229627251625061 for ['[CLS] anywhere occupiedmity love today [SEP]']
[Init] best rec loss: 0.9159227013587952 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9152803421020508 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9144142866134644 for ["[CLS] incense it jubilee kraft'[SEP]"]
[Init] best perm rec loss: 0.9142530560493469 for ["[CLS] kraft'it incense jubilee [SEP]"]
[Init] best perm rec loss: 0.9141202569007874 for ["[CLS] it kraft'incense jubilee [SEP]"]
[Init] best perm rec loss: 0.9132319688796997 for ["[CLS] it jubilee kraft incense'[SEP]"]
[Init] best perm rec loss: 0.9131988883018494 for ["[CLS] incense it'kraft jubilee [SEP]"]
[Init] best perm rec loss: 0.9131816625595093 for ["[CLS] incense it kraft jubilee'[SEP]"]
[Init] best perm rec loss: 0.9123598337173462 for ["[CLS] it'incense jubilee kraft [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.596 (perp=11.592, rec=0.277, cos=0.000), tot_loss_proj:3.604 [t=0.26s]
prediction: ['[CLS] sense as wise quaker acres [SEP]']
[ 100/2000] tot_loss=2.556 (perp=11.857, rec=0.185, cos=0.000), tot_loss_proj:3.208 [t=0.26s]
prediction: ['[CLS] wise wi wise knobzen [SEP]']
[ 150/2000] tot_loss=2.508 (perp=11.857, rec=0.136, cos=0.000), tot_loss_proj:3.210 [t=0.25s]
prediction: ['[CLS] wise wi wise knobzen [SEP]']
[ 200/2000] tot_loss=2.497 (perp=11.857, rec=0.126, cos=0.000), tot_loss_proj:3.205 [t=0.28s]
prediction: ['[CLS] wise wi wise knobzen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.621 (perp=12.179, rec=0.185, cos=0.000), tot_loss_proj:3.142 [t=0.27s]
prediction: ['[CLS] wise wi pe wisezen [SEP]']
[ 300/2000] tot_loss=2.615 (perp=12.464, rec=0.122, cos=0.000), tot_loss_proj:3.067 [t=0.27s]
prediction: ['[CLS] wise wi wi wisezen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.992 (perp=9.356, rec=0.121, cos=0.000), tot_loss_proj:2.377 [t=0.26s]
prediction: ['[CLS] wise wi wise wizen [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.328 (perp=11.094, rec=0.109, cos=0.000), tot_loss_proj:3.005 [t=0.26s]
prediction: ['[CLS] wi wi wise wizen [SEP]']
[ 450/2000] tot_loss=2.259 (perp=10.785, rec=0.102, cos=0.000), tot_loss_proj:3.374 [t=0.27s]
prediction: ['[CLS] wi, wiseedzen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.713 (perp=8.179, rec=0.077, cos=0.000), tot_loss_proj:2.071 [t=0.25s]
prediction: ['[CLS] wise, wiedzen [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.383 (perp=6.600, rec=0.063, cos=0.000), tot_loss_proj:1.380 [t=0.25s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.385 (perp=6.600, rec=0.065, cos=0.000), tot_loss_proj:1.398 [t=0.28s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.381 (perp=6.600, rec=0.061, cos=0.000), tot_loss_proj:1.378 [t=0.29s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.371 (perp=6.600, rec=0.051, cos=0.000), tot_loss_proj:1.384 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.388 (perp=6.600, rec=0.068, cos=0.000), tot_loss_proj:1.389 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.390 (perp=6.600, rec=0.070, cos=0.000), tot_loss_proj:1.379 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.379 (perp=6.600, rec=0.059, cos=0.000), tot_loss_proj:1.387 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.368 (perp=6.600, rec=0.048, cos=0.000), tot_loss_proj:1.382 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.389 (perp=6.600, rec=0.069, cos=0.000), tot_loss_proj:1.392 [t=0.25s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.375 (perp=6.600, rec=0.055, cos=0.000), tot_loss_proj:1.383 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.378 (perp=6.600, rec=0.058, cos=0.000), tot_loss_proj:1.394 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.380 (perp=6.600, rec=0.060, cos=0.000), tot_loss_proj:1.392 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.381 (perp=6.600, rec=0.061, cos=0.000), tot_loss_proj:1.390 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.391 (perp=6.600, rec=0.071, cos=0.000), tot_loss_proj:1.383 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.383 (perp=6.600, rec=0.063, cos=0.000), tot_loss_proj:1.387 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.394 (perp=6.600, rec=0.074, cos=0.000), tot_loss_proj:1.391 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.600, rec=0.071, cos=0.000), tot_loss_proj:1.392 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.379 (perp=6.600, rec=0.059, cos=0.000), tot_loss_proj:1.385 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.381 (perp=6.600, rec=0.061, cos=0.000), tot_loss_proj:1.389 [t=0.25s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.375 (perp=6.600, rec=0.055, cos=0.000), tot_loss_proj:1.371 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.385 (perp=6.600, rec=0.065, cos=0.000), tot_loss_proj:1.387 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.383 (perp=6.600, rec=0.063, cos=0.000), tot_loss_proj:1.380 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.379 (perp=6.600, rec=0.059, cos=0.000), tot_loss_proj:1.380 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.373 (perp=6.600, rec=0.053, cos=0.000), tot_loss_proj:1.382 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.388 (perp=6.600, rec=0.068, cos=0.000), tot_loss_proj:1.389 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.386 (perp=6.600, rec=0.065, cos=0.000), tot_loss_proj:1.387 [t=0.25s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.389 (perp=6.600, rec=0.069, cos=0.000), tot_loss_proj:1.391 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.376 (perp=6.600, rec=0.056, cos=0.000), tot_loss_proj:1.390 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.367 (perp=6.600, rec=0.047, cos=0.000), tot_loss_proj:1.383 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.381 (perp=6.600, rec=0.061, cos=0.000), tot_loss_proj:1.382 [t=0.26s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.108 | p: 91.511 | r: 92.862
rouge2     | fm: 59.979 | p: 59.679 | r: 60.322
rougeL     | fm: 79.371 | p: 78.918 | r: 79.947
rougeLsum  | fm: 79.421 | p: 78.906 | r: 79.959
r1fm+r2fm = 152.087

input #80 time: 0:11:12 | total time: 14:32:13


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
*********************************
*********************************
average of cosine similarity 0.9992866426251815
highest_index [0]
highest [0.9992866426251815]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9056998491287231 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.8568585515022278 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8448610305786133 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8234034776687622 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.816824197769165 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8083908557891846 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.7943952679634094 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.7932813167572021 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.793279767036438 for ['[CLS] donaldson ivyvikplatedown proceeded [SEP]']
[Init] best perm rec loss: 0.7898890376091003 for ['[CLS] ivyplate donaldsonvikdown proceeded [SEP]']
[Init] best perm rec loss: 0.7895854711532593 for ['[CLS] proceeded ivy donaldsondownvikplate [SEP]']
[Init] best perm rec loss: 0.7894756197929382 for ['[CLS] proceededplate ivydown donaldsonvik [SEP]']
[Init] best perm rec loss: 0.7885058522224426 for ['[CLS] donaldson proceededvikdown ivyplate [SEP]']
[Init] best perm rec loss: 0.7874219417572021 for ['[CLS] ivydown donaldson proceededvikplate [SEP]']
[Init] best perm rec loss: 0.7865276336669922 for ['[CLS]down proceededplatevik donaldson ivy [SEP]']
[Init] best perm rec loss: 0.786270022392273 for ['[CLS] proceeded ivyplatevikdown donaldson [SEP]']
[Init] best perm rec loss: 0.7844774723052979 for ['[CLS] ivydownvik proceeded donaldsonplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.889 (perp=11.982, rec=0.493, cos=0.000), tot_loss_proj:3.634 [t=0.35s]
prediction: ['[CLS] compensation third prison worse penalty no [SEP]']
[ 100/2000] tot_loss=3.006 (perp=13.174, rec=0.371, cos=0.000), tot_loss_proj:3.843 [t=0.26s]
prediction: ['[CLS] penalty iii doesn didn worse not [SEP]']
[ 150/2000] tot_loss=2.406 (perp=10.682, rec=0.270, cos=0.000), tot_loss_proj:3.706 [t=0.25s]
prediction: ['[CLS] player is doesn not worst best [SEP]']
[ 200/2000] tot_loss=1.962 (perp=8.868, rec=0.189, cos=0.000), tot_loss_proj:3.424 [t=0.26s]
prediction: ['[CLS] player is not not most most [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.747 (perp=7.911, rec=0.165, cos=0.000), tot_loss_proj:3.262 [t=0.26s]
prediction: ['[CLS] player is not most not most [SEP]']
[ 300/2000] tot_loss=1.727 (perp=7.911, rec=0.145, cos=0.000), tot_loss_proj:3.255 [t=0.25s]
prediction: ['[CLS] player is not most not most [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.704 (perp=7.911, rec=0.122, cos=0.000), tot_loss_proj:3.258 [t=0.27s]
prediction: ['[CLS] player is not most not most [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.704 (perp=7.981, rec=0.107, cos=0.000), tot_loss_proj:2.290 [t=0.26s]
prediction: ['[CLS] player is not most impressive most [SEP]']
[ 450/2000] tot_loss=1.748 (perp=8.187, rec=0.111, cos=0.000), tot_loss_proj:2.133 [t=0.27s]
prediction: ['[CLS] player is not most impressive impressive [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.597 (perp=7.385, rec=0.120, cos=0.000), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.585 (perp=7.385, rec=0.108, cos=0.000), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.385, rec=0.112, cos=0.000), tot_loss_proj:2.774 [t=0.25s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.588 (perp=7.385, rec=0.111, cos=0.000), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.385, rec=0.107, cos=0.000), tot_loss_proj:2.771 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[ 750/2000] tot_loss=1.593 (perp=7.385, rec=0.116, cos=0.000), tot_loss_proj:2.774 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.582 (perp=7.385, rec=0.105, cos=0.000), tot_loss_proj:2.776 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.578 (perp=7.385, rec=0.101, cos=0.000), tot_loss_proj:2.773 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[ 900/2000] tot_loss=1.584 (perp=7.385, rec=0.107, cos=0.000), tot_loss_proj:2.775 [t=0.27s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.570 (perp=7.385, rec=0.093, cos=0.000), tot_loss_proj:2.774 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.581 (perp=7.385, rec=0.104, cos=0.000), tot_loss_proj:2.782 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1050/2000] tot_loss=1.565 (perp=7.385, rec=0.088, cos=0.000), tot_loss_proj:2.777 [t=0.27s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=7.385, rec=0.097, cos=0.000), tot_loss_proj:2.768 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.579 (perp=7.385, rec=0.102, cos=0.000), tot_loss_proj:2.769 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1200/2000] tot_loss=1.577 (perp=7.385, rec=0.101, cos=0.000), tot_loss_proj:2.779 [t=0.27s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.577 (perp=7.385, rec=0.100, cos=0.000), tot_loss_proj:2.770 [t=0.28s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.584 (perp=7.385, rec=0.107, cos=0.000), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1350/2000] tot_loss=1.560 (perp=7.385, rec=0.083, cos=0.000), tot_loss_proj:2.776 [t=0.27s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.573 (perp=7.385, rec=0.096, cos=0.000), tot_loss_proj:2.773 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.571 (perp=7.385, rec=0.094, cos=0.000), tot_loss_proj:2.772 [t=0.28s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1500/2000] tot_loss=1.576 (perp=7.385, rec=0.099, cos=0.000), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.581 (perp=7.385, rec=0.104, cos=0.000), tot_loss_proj:2.776 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.566 (perp=7.385, rec=0.089, cos=0.000), tot_loss_proj:2.771 [t=0.26s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1650/2000] tot_loss=1.578 (perp=7.385, rec=0.101, cos=0.000), tot_loss_proj:2.774 [t=0.27s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.569 (perp=7.385, rec=0.092, cos=0.000), tot_loss_proj:2.765 [t=0.28s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.562 (perp=7.385, rec=0.085, cos=0.000), tot_loss_proj:2.772 [t=0.29s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1800/2000] tot_loss=1.569 (perp=7.385, rec=0.092, cos=0.000), tot_loss_proj:2.772 [t=0.29s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.573 (perp=7.385, rec=0.096, cos=0.000), tot_loss_proj:2.773 [t=0.30s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.562 (perp=7.385, rec=0.085, cos=0.000), tot_loss_proj:2.767 [t=0.31s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
[1950/2000] tot_loss=1.572 (perp=7.385, rec=0.095, cos=0.000), tot_loss_proj:2.773 [t=0.29s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.565 (perp=7.385, rec=0.088, cos=0.000), tot_loss_proj:2.771 [t=0.30s]
prediction: ['[CLS] player impressive is not most impressive [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] player impressive is not most impressive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 116.071

[Aggregate metrics]:
rouge1     | fm: 92.070 | p: 91.469 | r: 92.774
rouge2     | fm: 59.651 | p: 59.375 | r: 60.013
rougeL     | fm: 79.391 | p: 78.853 | r: 79.969
rougeLsum  | fm: 79.355 | p: 78.895 | r: 79.916
r1fm+r2fm = 151.722

input #81 time: 0:11:12 | total time: 14:43:26


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
*********************************
*********************************
average of cosine similarity 0.9992804263641312
highest_index [0]
highest [0.9992804263641312]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9898845553398132 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9780224561691284 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.94807368516922 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9382750988006592 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9370442032814026 for ['[CLS] volume welcome immigrated keep eye dress storyrity [SEP]']
[Init] best rec loss: 0.9302403330802917 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.865448534488678 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8297544121742249 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.825180172920227 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8229060769081116 for ['[CLS]basket respective whoever role plumagefurach record [SEP]']
[Init] best perm rec loss: 0.8196631669998169 for ['[CLS]basket respective whoever plumage roleach recordfur [SEP]']
[Init] best perm rec loss: 0.818000078201294 for ['[CLS] whoeverbasket rolefur respective plumage recordach [SEP]']
[Init] best perm rec loss: 0.8177376389503479 for ['[CLS]furbasket respectiveach plumage whoever role record [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.196 (perp=9.508, rec=0.295, cos=0.000), tot_loss_proj:2.856 [t=0.27s]
prediction: ['[CLS] as paper surface paint undone ; process undone [SEP]']
[ 100/2000] tot_loss=2.282 (perp=10.547, rec=0.172, cos=0.000), tot_loss_proj:2.567 [t=0.27s]
prediction: ['[CLS] sloppy script s undone undone by script undone [SEP]']
[ 150/2000] tot_loss=2.333 (perp=11.033, rec=0.126, cos=0.000), tot_loss_proj:2.662 [t=0.26s]
prediction: ['[CLS] sloppy script s sloppy undone by script undone [SEP]']
[ 200/2000] tot_loss=2.317 (perp=11.033, rec=0.110, cos=0.000), tot_loss_proj:2.659 [t=0.26s]
prediction: ['[CLS] sloppy script s sloppy undone by script undone [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.905 (perp=8.997, rec=0.106, cos=0.000), tot_loss_proj:2.252 [t=0.27s]
prediction: ['[CLS] s sloppy sloppy script undone by script undone [SEP]']
[ 300/2000] tot_loss=1.896 (perp=8.997, rec=0.096, cos=0.000), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] s sloppy sloppy script undone by script undone [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.887 (perp=8.997, rec=0.088, cos=0.000), tot_loss_proj:2.249 [t=0.27s]
prediction: ['[CLS] s sloppy sloppy script undone by script undone [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.752 (perp=8.322, rec=0.087, cos=0.000), tot_loss_proj:2.099 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by sloppy script undone [SEP]']
[ 450/2000] tot_loss=1.738 (perp=8.322, rec=0.074, cos=0.000), tot_loss_proj:2.097 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by sloppy script undone [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.021 (perp=9.661, rec=0.089, cos=0.000), tot_loss_proj:2.431 [t=0.28s]
prediction: ['[CLS] s it script undone by sloppy script undone [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.798 (perp=8.597, rec=0.078, cos=0.000), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[ 600/2000] tot_loss=1.792 (perp=8.597, rec=0.073, cos=0.000), tot_loss_proj:2.240 [t=0.21s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.794 (perp=8.597, rec=0.075, cos=0.000), tot_loss_proj:2.243 [t=0.21s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.799 (perp=8.597, rec=0.080, cos=0.000), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[ 750/2000] tot_loss=1.789 (perp=8.597, rec=0.070, cos=0.000), tot_loss_proj:2.243 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.787 (perp=8.597, rec=0.068, cos=0.000), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.811 (perp=8.597, rec=0.091, cos=0.000), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[ 900/2000] tot_loss=1.794 (perp=8.597, rec=0.075, cos=0.000), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.789 (perp=8.597, rec=0.070, cos=0.000), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1000/2000] tot_loss=1.797 (perp=8.597, rec=0.078, cos=0.000), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1050/2000] tot_loss=1.793 (perp=8.597, rec=0.074, cos=0.000), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1100/2000] tot_loss=1.798 (perp=8.597, rec=0.079, cos=0.000), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1150/2000] tot_loss=1.789 (perp=8.597, rec=0.070, cos=0.000), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1200/2000] tot_loss=1.795 (perp=8.597, rec=0.076, cos=0.000), tot_loss_proj:2.245 [t=0.23s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1250/2000] tot_loss=1.798 (perp=8.597, rec=0.078, cos=0.000), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1300/2000] tot_loss=1.782 (perp=8.597, rec=0.063, cos=0.000), tot_loss_proj:2.236 [t=0.21s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1350/2000] tot_loss=1.796 (perp=8.597, rec=0.077, cos=0.000), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1400/2000] tot_loss=1.786 (perp=8.597, rec=0.067, cos=0.000), tot_loss_proj:2.244 [t=0.21s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1450/2000] tot_loss=1.804 (perp=8.597, rec=0.084, cos=0.000), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.597, rec=0.074, cos=0.000), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1550/2000] tot_loss=1.787 (perp=8.597, rec=0.068, cos=0.000), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1600/2000] tot_loss=1.795 (perp=8.597, rec=0.076, cos=0.000), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1650/2000] tot_loss=1.800 (perp=8.597, rec=0.081, cos=0.000), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1700/2000] tot_loss=1.799 (perp=8.597, rec=0.079, cos=0.000), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1750/2000] tot_loss=1.788 (perp=8.597, rec=0.069, cos=0.000), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1800/2000] tot_loss=1.797 (perp=8.597, rec=0.078, cos=0.000), tot_loss_proj:2.235 [t=0.21s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1850/2000] tot_loss=1.789 (perp=8.597, rec=0.069, cos=0.000), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[1900/2000] tot_loss=1.789 (perp=8.597, rec=0.070, cos=0.000), tot_loss_proj:2.236 [t=0.21s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
[1950/2000] tot_loss=1.789 (perp=8.597, rec=0.070, cos=0.000), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Attempt swap
[2000/2000] tot_loss=1.797 (perp=8.597, rec=0.077, cos=0.000), tot_loss_proj:2.232 [t=0.27s]
prediction: ['[CLS] it s script undone by sloppy script undone [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s script undone by sloppy script undone [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 131.269

[Aggregate metrics]:
rouge1     | fm: 91.966 | p: 91.344 | r: 92.727
rouge2     | fm: 59.446 | p: 59.123 | r: 59.809
rougeL     | fm: 79.406 | p: 78.817 | r: 80.030
rougeLsum  | fm: 79.436 | p: 78.882 | r: 80.046
r1fm+r2fm = 151.412

input #82 time: 0:09:19 | total time: 14:52:45


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
*********************************
*********************************
average of cosine similarity 0.9992433275911314
highest_index [0]
highest [0.9992433275911314]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9548901915550232 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9547852873802185 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9512964487075806 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9459820985794067 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8860567808151245 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8707808256149292 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8678160905838013 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8608438968658447 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8600472807884216 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8378002047538757 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8146635890007019 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8128852844238281 for ['[CLS] envelope residence neck stew vice nearly follows comprehensive pitch boys [SEP]']
[Init] best perm rec loss: 0.809701681137085 for ['[CLS] residence pitch follows neck boys vice nearly comprehensive envelope stew [SEP]']
[Init] best perm rec loss: 0.8089856505393982 for ['[CLS] nearly follows stew vice comprehensive neck pitch residence envelope boys [SEP]']
[Init] best perm rec loss: 0.8084452152252197 for ['[CLS] pitch comprehensive nearly neck stew residence boys vice follows envelope [SEP]']
[Init] best perm rec loss: 0.805506706237793 for ['[CLS] residence neck vice boys stew comprehensive nearly pitch follows envelope [SEP]']
[Init] best perm rec loss: 0.8053083419799805 for ['[CLS] follows vice neck comprehensive stew residence boys pitch nearly envelope [SEP]']
[Init] best perm rec loss: 0.8037474155426025 for ['[CLS] neck comprehensive boys follows stew pitch vice residence envelope nearly [SEP]']
[Init] best perm rec loss: 0.802834689617157 for ['[CLS] vice nearly pitch residence neck follows comprehensive stew boys envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.744 (perp=11.866, rec=0.371, cos=0.000), tot_loss_proj:3.580 [t=0.26s]
prediction: ['[CLS] like grandson development develop pretty becoming gold billy becoming 2011 [SEP]']
[ 100/2000] tot_loss=2.311 (perp=10.255, rec=0.260, cos=0.000), tot_loss_proj:3.436 [t=0.27s]
prediction: ['[CLS] know when what when pretty becoming they billy is grows [SEP]']
[ 150/2000] tot_loss=2.000 (perp=9.079, rec=0.184, cos=0.000), tot_loss_proj:3.418 [t=0.26s]
prediction: ['[CLS] know when what when about grows it tomorrow is grows [SEP]']
[ 200/2000] tot_loss=2.071 (perp=9.698, rec=0.131, cos=0.000), tot_loss_proj:2.935 [t=0.26s]
prediction: ['[CLS] know when what when wants grows it tomorrow be grows [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.741 (perp=8.144, rec=0.112, cos=0.000), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] know when what it wants grows when young be grows [SEP]']
[ 300/2000] tot_loss=1.897 (perp=9.005, rec=0.096, cos=0.000), tot_loss_proj:2.416 [t=0.26s]
prediction: ['[CLS] know up what it wants grows when young be grows [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.496 (perp=6.990, rec=0.098, cos=0.000), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] know what it wants grows when it be grows up [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.373 (perp=6.380, rec=0.097, cos=0.000), tot_loss_proj:1.824 [t=0.26s]
prediction: ['[CLS] grows know what it wants when it be grows up [SEP]']
[ 450/2000] tot_loss=1.350 (perp=6.380, rec=0.074, cos=0.000), tot_loss_proj:1.830 [t=0.25s]
prediction: ['[CLS] grows know what it wants when it be grows up [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.359 (perp=6.380, rec=0.083, cos=0.000), tot_loss_proj:1.839 [t=0.26s]
prediction: ['[CLS] grows know what it wants when it be grows up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.342 (perp=6.380, rec=0.066, cos=0.000), tot_loss_proj:1.832 [t=0.25s]
prediction: ['[CLS] grows know what it wants when it be grows up [SEP]']
[ 600/2000] tot_loss=1.339 (perp=6.380, rec=0.063, cos=0.000), tot_loss_proj:1.835 [t=0.26s]
prediction: ['[CLS] grows know what it wants when it be grows up [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.339 (perp=6.380, rec=0.063, cos=0.000), tot_loss_proj:1.832 [t=0.27s]
prediction: ['[CLS] grows know what it wants when it be grows up [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.301 (perp=6.119, rec=0.077, cos=0.000), tot_loss_proj:1.657 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[ 750/2000] tot_loss=1.309 (perp=6.119, rec=0.086, cos=0.000), tot_loss_proj:1.661 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.295 (perp=6.119, rec=0.071, cos=0.000), tot_loss_proj:1.662 [t=0.34s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.304 (perp=6.119, rec=0.081, cos=0.000), tot_loss_proj:1.663 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[ 900/2000] tot_loss=1.301 (perp=6.119, rec=0.077, cos=0.000), tot_loss_proj:1.655 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.298 (perp=6.119, rec=0.074, cos=0.000), tot_loss_proj:1.650 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.297 (perp=6.119, rec=0.074, cos=0.000), tot_loss_proj:1.652 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1050/2000] tot_loss=1.294 (perp=6.119, rec=0.071, cos=0.000), tot_loss_proj:1.654 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.295 (perp=6.119, rec=0.071, cos=0.000), tot_loss_proj:1.646 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.281 (perp=6.119, rec=0.058, cos=0.000), tot_loss_proj:1.646 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1200/2000] tot_loss=1.302 (perp=6.119, rec=0.079, cos=0.000), tot_loss_proj:1.652 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.292 (perp=6.119, rec=0.068, cos=0.000), tot_loss_proj:1.646 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.293 (perp=6.119, rec=0.069, cos=0.000), tot_loss_proj:1.654 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1350/2000] tot_loss=1.305 (perp=6.119, rec=0.081, cos=0.000), tot_loss_proj:1.649 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.292 (perp=6.119, rec=0.069, cos=0.000), tot_loss_proj:1.649 [t=0.29s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.297 (perp=6.119, rec=0.073, cos=0.000), tot_loss_proj:1.653 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1500/2000] tot_loss=1.303 (perp=6.119, rec=0.080, cos=0.000), tot_loss_proj:1.654 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.291 (perp=6.119, rec=0.067, cos=0.000), tot_loss_proj:1.651 [t=0.28s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.291 (perp=6.119, rec=0.067, cos=0.000), tot_loss_proj:1.645 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1650/2000] tot_loss=1.299 (perp=6.119, rec=0.076, cos=0.000), tot_loss_proj:1.649 [t=0.25s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.293 (perp=6.119, rec=0.069, cos=0.000), tot_loss_proj:1.652 [t=0.28s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.297 (perp=6.119, rec=0.073, cos=0.000), tot_loss_proj:1.647 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1800/2000] tot_loss=1.300 (perp=6.119, rec=0.076, cos=0.000), tot_loss_proj:1.646 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.292 (perp=6.119, rec=0.068, cos=0.000), tot_loss_proj:1.655 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.293 (perp=6.119, rec=0.069, cos=0.000), tot_loss_proj:1.653 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
[1950/2000] tot_loss=1.293 (perp=6.119, rec=0.069, cos=0.000), tot_loss_proj:1.643 [t=0.26s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.298 (perp=6.119, rec=0.074, cos=0.000), tot_loss_proj:1.647 [t=0.27s]
prediction: ['[CLS] grows know what it wants be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] grows know what it wants be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 92.017 | p: 91.344 | r: 92.780
rouge2     | fm: 59.518 | p: 59.172 | r: 59.865
rougeL     | fm: 79.587 | p: 79.064 | r: 80.187
rougeLsum  | fm: 79.552 | p: 78.982 | r: 80.173
r1fm+r2fm = 151.535

input #83 time: 0:11:11 | total time: 15:03:57


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
*********************************
*********************************
average of cosine similarity 0.9991127371986287
highest_index [0]
highest [0.9991127371986287]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9287973046302795 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.918179988861084 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.9013343453407288 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8930329084396362 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8899574279785156 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.885325014591217 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8648201823234558 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8613989353179932 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8612810373306274 for ['[CLS] tradition captaindock seats [SEP] easier seas [SEP]']
[Init] best perm rec loss: 0.8589254021644592 for ['[CLS] tradition seas captain easier [SEP] seatsdock [SEP]']
[Init] best perm rec loss: 0.8585575819015503 for ['[CLS] seasdock [SEP] tradition easier captain seats [SEP]']
[Init] best perm rec loss: 0.8574162125587463 for ['[CLS]dock seats seas tradition [SEP] easier captain [SEP]']
[Init] best perm rec loss: 0.8553769588470459 for ['[CLS]dock seas captain tradition [SEP] easier seats [SEP]']
[Init] best perm rec loss: 0.8530501127243042 for ['[CLS] tradition seas [SEP]dock captain easier seats [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.475 (perp=10.602, rec=0.354, cos=0.000), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] losing - lost particular intellectual feelings lost [SEP]']
[ 100/2000] tot_loss=2.033 (perp=8.960, rec=0.241, cos=0.000), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] people - lost the ability think lost [SEP]']
[ 150/2000] tot_loss=1.643 (perp=7.545, rec=0.134, cos=0.000), tot_loss_proj:1.928 [t=0.27s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
[ 200/2000] tot_loss=1.618 (perp=7.545, rec=0.109, cos=0.000), tot_loss_proj:1.927 [t=0.26s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.554 (perp=7.312, rec=0.091, cos=0.000), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[ 300/2000] tot_loss=1.554 (perp=7.312, rec=0.091, cos=0.000), tot_loss_proj:2.072 [t=0.27s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.533 (perp=7.220, rec=0.089, cos=0.000), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.532 (perp=7.220, rec=0.088, cos=0.000), tot_loss_proj:2.097 [t=0.35s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[ 450/2000] tot_loss=1.528 (perp=7.220, rec=0.084, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.534 (perp=7.220, rec=0.090, cos=0.000), tot_loss_proj:2.098 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.525 (perp=7.220, rec=0.081, cos=0.000), tot_loss_proj:2.097 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[ 600/2000] tot_loss=1.533 (perp=7.220, rec=0.089, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.523 (perp=7.220, rec=0.079, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.525 (perp=7.220, rec=0.081, cos=0.000), tot_loss_proj:2.095 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[ 750/2000] tot_loss=1.527 (perp=7.220, rec=0.083, cos=0.000), tot_loss_proj:2.105 [t=0.28s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.530 (perp=7.220, rec=0.086, cos=0.000), tot_loss_proj:2.095 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.529 (perp=7.220, rec=0.085, cos=0.000), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[ 900/2000] tot_loss=1.524 (perp=7.220, rec=0.079, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.527 (perp=7.220, rec=0.082, cos=0.000), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1000/2000] tot_loss=1.519 (perp=7.220, rec=0.075, cos=0.000), tot_loss_proj:2.097 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1050/2000] tot_loss=1.518 (perp=7.220, rec=0.074, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1100/2000] tot_loss=1.526 (perp=7.220, rec=0.082, cos=0.000), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1150/2000] tot_loss=1.520 (perp=7.220, rec=0.076, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1200/2000] tot_loss=1.521 (perp=7.220, rec=0.076, cos=0.000), tot_loss_proj:2.094 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1250/2000] tot_loss=1.529 (perp=7.220, rec=0.085, cos=0.000), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1300/2000] tot_loss=1.517 (perp=7.220, rec=0.073, cos=0.000), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1350/2000] tot_loss=1.530 (perp=7.220, rec=0.086, cos=0.000), tot_loss_proj:2.095 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1400/2000] tot_loss=1.532 (perp=7.220, rec=0.088, cos=0.000), tot_loss_proj:2.090 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1450/2000] tot_loss=1.520 (perp=7.220, rec=0.076, cos=0.000), tot_loss_proj:2.093 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1500/2000] tot_loss=1.528 (perp=7.220, rec=0.084, cos=0.000), tot_loss_proj:2.098 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1550/2000] tot_loss=1.519 (perp=7.220, rec=0.075, cos=0.000), tot_loss_proj:2.098 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1600/2000] tot_loss=1.527 (perp=7.220, rec=0.083, cos=0.000), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1650/2000] tot_loss=1.525 (perp=7.220, rec=0.081, cos=0.000), tot_loss_proj:2.096 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1700/2000] tot_loss=1.528 (perp=7.220, rec=0.084, cos=0.000), tot_loss_proj:2.093 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1750/2000] tot_loss=1.524 (perp=7.220, rec=0.080, cos=0.000), tot_loss_proj:2.094 [t=0.25s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1800/2000] tot_loss=1.526 (perp=7.220, rec=0.082, cos=0.000), tot_loss_proj:2.091 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1850/2000] tot_loss=1.527 (perp=7.220, rec=0.083, cos=0.000), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[1900/2000] tot_loss=1.529 (perp=7.220, rec=0.085, cos=0.000), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[1950/2000] tot_loss=1.532 (perp=7.220, rec=0.088, cos=0.000), tot_loss_proj:2.093 [t=0.27s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Attempt swap
[2000/2000] tot_loss=1.523 (perp=7.220, rec=0.079, cos=0.000), tot_loss_proj:2.097 [t=0.26s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] think people have lost the ability lost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 91.945 | p: 91.287 | r: 92.669
rouge2     | fm: 59.641 | p: 59.355 | r: 59.944
rougeL     | fm: 79.589 | p: 79.073 | r: 80.234
rougeLsum  | fm: 79.417 | p: 78.940 | r: 80.053
r1fm+r2fm = 151.586

input #84 time: 0:11:08 | total time: 15:15:06


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
*********************************
*********************************
average of cosine similarity 0.9992364975407029
highest_index [0]
highest [0.9992364975407029]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.971329391002655 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9554845094680786 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.9310083389282227 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8873536586761475 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8717461228370667 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.865368127822876 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8648200035095215 for ['[CLS]lein roadthing defender indianrman indies laps fallen background [SEP]']
[Init] best perm rec loss: 0.864223837852478 for ['[CLS] fallen background roadlein defender indiesthing indianrman laps [SEP]']
[Init] best perm rec loss: 0.8631396889686584 for ['[CLS]lein indian fallen background road lapsthing indiesrman defender [SEP]']
[Init] best perm rec loss: 0.8630577921867371 for ['[CLS] lapslein road indies defender background fallenrmanthing indian [SEP]']
[Init] best perm rec loss: 0.8626133799552917 for ['[CLS] lapslein indies indian roadthing fallenrman background defender [SEP]']
[Init] best perm rec loss: 0.8618481159210205 for ['[CLS]lein road fallen background indiesthing defender laps indianrman [SEP]']
[Init] best perm rec loss: 0.8615628480911255 for ['[CLS] roadleinthing fallen background indian lapsrman defender indies [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.448 (perp=10.446, rec=0.359, cos=0.000), tot_loss_proj:3.229 [t=0.26s]
prediction: ['[CLS] poor exam you initial good ( unfortunately unfortunately unfortunately unfortunately [SEP]']
[ 100/2000] tot_loss=2.298 (perp=10.508, rec=0.196, cos=0.000), tot_loss_proj:3.014 [t=0.25s]
prediction: ['[CLS] poor peg it also not. unfortunately unfortunately good unfortunately [SEP]']
[ 150/2000] tot_loss=1.913 (perp=8.892, rec=0.135, cos=0.000), tot_loss_proj:2.309 [t=0.26s]
prediction: ['[CLS] mistake peg it also not very unfortunately unfortunately good. [SEP]']
[ 200/2000] tot_loss=1.817 (perp=8.579, rec=0.101, cos=0.000), tot_loss_proj:2.298 [t=0.27s]
prediction: ['[CLS] entirely peg it also not very unfortunately unfortunately good. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.541 (perp=7.146, rec=0.111, cos=0.000), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] entirely match it also unfortunately unfortunately not very good. [SEP]']
[ 300/2000] tot_loss=1.521 (perp=7.146, rec=0.092, cos=0.000), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] entirely match it also unfortunately unfortunately not very good. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.843 (perp=7.382, rec=0.366, cos=0.000), tot_loss_proj:3.299 [t=0.26s]
prediction: ['[CLS] s also unfortunately unfortunately not short - very good, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.881 (perp=7.996, rec=0.282, cos=0.000), tot_loss_proj:2.074 [t=0.28s]
prediction: ['[CLS] s also unfortunately unfortunately not directly very good position, [SEP]']
[ 450/2000] tot_loss=1.824 (perp=7.996, rec=0.224, cos=0.000), tot_loss_proj:2.070 [t=0.26s]
prediction: ['[CLS] s also unfortunately unfortunately not directly very good position, [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.795 (perp=7.967, rec=0.202, cos=0.000), tot_loss_proj:2.133 [t=0.25s]
prediction: ['[CLS] s position also unfortunately unfortunately not hangul very good, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.731 (perp=7.755, rec=0.180, cos=0.000), tot_loss_proj:2.086 [t=0.25s]
prediction: ['[CLS] s position unfortunately also unfortunately not hangul very good, [SEP]']
[ 600/2000] tot_loss=1.688 (perp=7.705, rec=0.147, cos=0.000), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] s position unfortunately also unfortunately not ( very good, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.637 (perp=7.400, rec=0.157, cos=0.000), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] ( it front unfortunately also unfortunately not very good, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.521 (perp=6.811, rec=0.158, cos=0.000), tot_loss_proj:1.955 [t=0.28s]
prediction: ['[CLS] ( it unfortunately also unfortunately not very good front, [SEP]']
[ 750/2000] tot_loss=1.665 (perp=7.610, rec=0.143, cos=0.000), tot_loss_proj:2.029 [t=0.27s]
prediction: ['[CLS] ( s unfortunately also unfortunately not very good front, [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.618 (perp=7.399, rec=0.138, cos=0.000), tot_loss_proj:2.034 [t=0.28s]
prediction: ['[CLS] ( unfortunately also s unfortunately not very good front, [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.466 (perp=6.648, rec=0.136, cos=0.000), tot_loss_proj:1.923 [t=0.29s]
prediction: ['[CLS] unfortunately also s, unfortunately not very good front, [SEP]']
[ 900/2000] tot_loss=1.461 (perp=6.648, rec=0.132, cos=0.000), tot_loss_proj:1.924 [t=0.21s]
prediction: ['[CLS] unfortunately also s, unfortunately not very good front, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.405 (perp=6.369, rec=0.131, cos=0.000), tot_loss_proj:1.922 [t=0.21s]
prediction: ['[CLS] unfortunately also it were unfortunately not very good front, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.360 (perp=6.171, rec=0.125, cos=0.000), tot_loss_proj:1.769 [t=0.21s]
prediction: ['[CLS] unfortunately also unfortunately, it not very good front, [SEP]']
[1050/2000] tot_loss=1.362 (perp=6.171, rec=0.128, cos=0.000), tot_loss_proj:1.772 [t=0.21s]
prediction: ['[CLS] unfortunately also unfortunately, it not very good front, [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.278 (perp=5.773, rec=0.124, cos=0.000), tot_loss_proj:1.629 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.275 (perp=5.773, rec=0.121, cos=0.000), tot_loss_proj:1.628 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
[1200/2000] tot_loss=1.276 (perp=5.773, rec=0.122, cos=0.000), tot_loss_proj:1.624 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.265 (perp=5.773, rec=0.110, cos=0.000), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.273 (perp=5.773, rec=0.119, cos=0.000), tot_loss_proj:1.623 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
[1350/2000] tot_loss=1.267 (perp=5.773, rec=0.112, cos=0.000), tot_loss_proj:1.624 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.276 (perp=5.773, rec=0.122, cos=0.000), tot_loss_proj:1.628 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.263 (perp=5.773, rec=0.108, cos=0.000), tot_loss_proj:1.636 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
[1500/2000] tot_loss=1.267 (perp=5.773, rec=0.113, cos=0.000), tot_loss_proj:1.621 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.270 (perp=5.773, rec=0.115, cos=0.000), tot_loss_proj:1.632 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.261 (perp=5.773, rec=0.106, cos=0.000), tot_loss_proj:1.623 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
[1650/2000] tot_loss=1.279 (perp=5.773, rec=0.124, cos=0.000), tot_loss_proj:1.627 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good front, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.252 (perp=5.673, rec=0.117, cos=0.000), tot_loss_proj:1.550 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.244 (perp=5.673, rec=0.109, cos=0.000), tot_loss_proj:1.562 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
[1800/2000] tot_loss=1.256 (perp=5.673, rec=0.121, cos=0.000), tot_loss_proj:1.555 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.247 (perp=5.673, rec=0.112, cos=0.000), tot_loss_proj:1.558 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.245 (perp=5.673, rec=0.111, cos=0.000), tot_loss_proj:1.554 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
[1950/2000] tot_loss=1.243 (perp=5.673, rec=0.109, cos=0.000), tot_loss_proj:1.559 [t=0.21s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.247 (perp=5.673, rec=0.112, cos=0.000), tot_loss_proj:1.556 [t=0.22s]
prediction: ['[CLS] unfortunately, it also unfortunately not very good key, [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] entirely match it also unfortunately unfortunately not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 72.727 | r: 88.889
rouge2     | fm: 33.333 | p: 30.000 | r: 37.500
rougeL     | fm: 70.000 | p: 63.636 | r: 77.778
rougeLsum  | fm: 70.000 | p: 63.636 | r: 77.778
r1fm+r2fm = 113.333

[Aggregate metrics]:
rouge1     | fm: 91.805 | p: 91.077 | r: 92.648
rouge2     | fm: 59.282 | p: 58.903 | r: 59.695
rougeL     | fm: 79.469 | p: 78.831 | r: 80.166
rougeLsum  | fm: 79.415 | p: 78.819 | r: 80.107
r1fm+r2fm = 151.087

input #85 time: 0:09:39 | total time: 15:24:45


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
*********************************
*********************************
average of cosine similarity 0.9993320076339756
highest_index [0]
highest [0.9993320076339756]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9247504472732544 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9180772304534912 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8602122068405151 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7965919375419617 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7929351925849915 for ['[CLS] beta bryant [CLS] [SEP]']
[Init] best rec loss: 0.7646839022636414 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7589471340179443 for ['[CLS] liberated round alright [SEP]']
[Init] best rec loss: 0.7585043907165527 for ['[CLS] same yet computational [SEP]']
[Init] best perm rec loss: 0.7567218542098999 for ['[CLS] computational yet same [SEP]']
[Init] best perm rec loss: 0.756173849105835 for ['[CLS] yet same computational [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.996 (perp=8.828, rec=0.230, cos=0.000), tot_loss_proj:2.255 [t=0.25s]
prediction: ['[CLS] honesty and emotional [SEP]']
[ 100/2000] tot_loss=1.845 (perp=8.419, rec=0.162, cos=0.000), tot_loss_proj:1.823 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 150/2000] tot_loss=1.805 (perp=8.419, rec=0.121, cos=0.000), tot_loss_proj:1.828 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 200/2000] tot_loss=1.768 (perp=8.419, rec=0.084, cos=0.000), tot_loss_proj:1.826 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.719 (perp=8.211, rec=0.077, cos=0.000), tot_loss_proj:1.874 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 300/2000] tot_loss=1.710 (perp=8.211, rec=0.068, cos=0.000), tot_loss_proj:1.884 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.713 (perp=8.211, rec=0.070, cos=0.000), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.720 (perp=8.211, rec=0.078, cos=0.000), tot_loss_proj:1.873 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=1.711 (perp=8.211, rec=0.069, cos=0.000), tot_loss_proj:1.874 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.704 (perp=8.211, rec=0.062, cos=0.000), tot_loss_proj:1.873 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.702 (perp=8.211, rec=0.060, cos=0.000), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.718 (perp=8.211, rec=0.076, cos=0.000), tot_loss_proj:1.869 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.000), tot_loss_proj:1.876 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.706 (perp=8.211, rec=0.064, cos=0.000), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.710 (perp=8.211, rec=0.068, cos=0.000), tot_loss_proj:1.882 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.698 (perp=8.211, rec=0.056, cos=0.000), tot_loss_proj:1.882 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.704 (perp=8.211, rec=0.062, cos=0.000), tot_loss_proj:1.883 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.000), tot_loss_proj:1.877 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.711 (perp=8.211, rec=0.069, cos=0.000), tot_loss_proj:1.874 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.000), tot_loss_proj:1.868 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.695 (perp=8.211, rec=0.053, cos=0.000), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.699 (perp=8.211, rec=0.057, cos=0.000), tot_loss_proj:1.870 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.703 (perp=8.211, rec=0.061, cos=0.000), tot_loss_proj:1.878 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.706 (perp=8.211, rec=0.064, cos=0.000), tot_loss_proj:1.877 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.709 (perp=8.211, rec=0.067, cos=0.000), tot_loss_proj:1.878 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.694 (perp=8.211, rec=0.052, cos=0.000), tot_loss_proj:1.874 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.000), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.698 (perp=8.211, rec=0.056, cos=0.000), tot_loss_proj:1.882 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.692 (perp=8.211, rec=0.050, cos=0.000), tot_loss_proj:1.874 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.211, rec=0.063, cos=0.000), tot_loss_proj:1.877 [t=0.28s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.699 (perp=8.211, rec=0.057, cos=0.000), tot_loss_proj:1.877 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.211, rec=0.056, cos=0.000), tot_loss_proj:1.878 [t=0.28s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.691 (perp=8.211, rec=0.049, cos=0.000), tot_loss_proj:1.879 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.715 (perp=8.211, rec=0.073, cos=0.000), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.706 (perp=8.211, rec=0.064, cos=0.000), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.710 (perp=8.211, rec=0.068, cos=0.000), tot_loss_proj:1.875 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.700 (perp=8.211, rec=0.058, cos=0.000), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.000), tot_loss_proj:1.879 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.704 (perp=8.211, rec=0.062, cos=0.000), tot_loss_proj:1.881 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.700 (perp=8.211, rec=0.057, cos=0.000), tot_loss_proj:1.874 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.877 | p: 91.205 | r: 92.697
rouge2     | fm: 58.768 | p: 58.461 | r: 59.210
rougeL     | fm: 79.463 | p: 78.854 | r: 80.160
rougeLsum  | fm: 79.455 | p: 78.922 | r: 80.151
r1fm+r2fm = 150.645

input #86 time: 0:11:01 | total time: 15:35:46


Running input #87 of 100.
reference: 
========================
propulsive 
========================
*********************************
*********************************
average of cosine similarity 0.9992554572578443
highest_index [0]
highest [0.9992554572578443]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8819296956062317 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7556470036506653 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7162351608276367 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7038763165473938 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6942294836044312 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6831544637680054 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6773515939712524 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.817 (perp=12.534, rec=0.311, cos=0.000), tot_loss_proj:3.264 [t=0.25s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=3.379 (perp=12.534, rec=0.664, cos=0.208), tot_loss_proj:3.282 [t=0.26s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=1.690 (perp=7.258, rec=0.238, cos=0.000), tot_loss_proj:1.543 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.621 (perp=7.258, rec=0.170, cos=0.000), tot_loss_proj:1.537 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.555 (perp=7.258, rec=0.104, cos=0.000), tot_loss_proj:1.524 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.542 (perp=7.258, rec=0.091, cos=0.000), tot_loss_proj:1.519 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.516 (perp=7.258, rec=0.064, cos=0.000), tot_loss_proj:1.540 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.518 (perp=7.258, rec=0.067, cos=0.000), tot_loss_proj:1.530 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.506 (perp=7.258, rec=0.054, cos=0.000), tot_loss_proj:1.534 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.509 (perp=7.258, rec=0.058, cos=0.000), tot_loss_proj:1.540 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.258, rec=0.064, cos=0.000), tot_loss_proj:1.546 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.526 (perp=7.258, rec=0.074, cos=0.000), tot_loss_proj:1.543 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.500 (perp=7.258, rec=0.048, cos=0.000), tot_loss_proj:1.544 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.506 (perp=7.258, rec=0.054, cos=0.000), tot_loss_proj:1.525 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.523 (perp=7.258, rec=0.072, cos=0.000), tot_loss_proj:1.536 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.501 (perp=7.258, rec=0.049, cos=0.000), tot_loss_proj:1.534 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.502 (perp=7.258, rec=0.051, cos=0.000), tot_loss_proj:1.546 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.525 (perp=7.258, rec=0.074, cos=0.000), tot_loss_proj:1.521 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.499 (perp=7.258, rec=0.047, cos=0.000), tot_loss_proj:1.531 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.504 (perp=7.258, rec=0.052, cos=0.000), tot_loss_proj:1.537 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.512 (perp=7.258, rec=0.061, cos=0.000), tot_loss_proj:1.541 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.511 (perp=7.258, rec=0.060, cos=0.000), tot_loss_proj:1.527 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.504 (perp=7.258, rec=0.053, cos=0.000), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.509 (perp=7.258, rec=0.057, cos=0.000), tot_loss_proj:1.539 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.507 (perp=7.258, rec=0.056, cos=0.000), tot_loss_proj:1.550 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.511 (perp=7.258, rec=0.059, cos=0.000), tot_loss_proj:1.543 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.518 (perp=7.258, rec=0.067, cos=0.000), tot_loss_proj:1.536 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.506 (perp=7.258, rec=0.054, cos=0.000), tot_loss_proj:1.535 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.498 (perp=7.258, rec=0.047, cos=0.000), tot_loss_proj:1.546 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.519 (perp=7.258, rec=0.068, cos=0.000), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.509 (perp=7.258, rec=0.058, cos=0.000), tot_loss_proj:1.532 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.507 (perp=7.258, rec=0.055, cos=0.000), tot_loss_proj:1.536 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.516 (perp=7.258, rec=0.064, cos=0.000), tot_loss_proj:1.534 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.510 (perp=7.258, rec=0.059, cos=0.000), tot_loss_proj:1.531 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.507 (perp=7.258, rec=0.056, cos=0.000), tot_loss_proj:1.539 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.511 (perp=7.258, rec=0.059, cos=0.000), tot_loss_proj:1.543 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.507 (perp=7.258, rec=0.055, cos=0.000), tot_loss_proj:1.522 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.519 (perp=7.258, rec=0.068, cos=0.000), tot_loss_proj:1.528 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.515 (perp=7.258, rec=0.064, cos=0.000), tot_loss_proj:1.541 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.504 (perp=7.258, rec=0.053, cos=0.000), tot_loss_proj:1.531 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.973 | p: 91.271 | r: 92.809
rouge2     | fm: 59.246 | p: 58.900 | r: 59.654
rougeL     | fm: 79.678 | p: 79.047 | r: 80.413
rougeLsum  | fm: 79.728 | p: 79.166 | r: 80.425
r1fm+r2fm = 151.219

input #87 time: 0:11:18 | total time: 15:47:04


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
*********************************
*********************************
average of cosine similarity 0.9992353922756394
highest_index [0]
highest [0.9992353922756394]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9814471006393433 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9435462951660156 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9214968681335449 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.9151935577392578 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.914589524269104 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9064174294471741 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.9031794667243958 for ["[CLS]⁺'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.9024516344070435 for ['[CLS] ) ever rag consideration patentt yes com occasional king clip canyonawan eight whileput say turn tapeless pei dearht watch soon frost constitution mayoicles nursery road will bending ff cathedral soup elect leadership herself byron hospital per post [SEP]']
[Init] best rec loss: 0.8963274359703064 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8962134122848511 for ['[CLS] harmon demi [UNK] allowed immortality legitimate hadn won pondered programs spanningbbed today machine reform exchanged starting ki designated signed observation engine baronet where force elevated ) close as never landing network? piston exodus aunt employees home mandarin nets! insanity according [SEP]']
[Init] best perm rec loss: 0.8940826058387756 for ['[CLS] allowed baronet aunt as designated [UNK] harmon )! today legitimate where signed reform according spanning demi exchanged observation hadn engine ki piston elevated employees immortality nets machine exodus network pondered home closebbed mandarin never programs won? landing starting force insanity [SEP]']
[Init] best perm rec loss: 0.8935985565185547 for ['[CLS] force never hadn close spanning nets immortality )! insanity asbbed aunt designated legitimate exchanged engine mandarin [UNK] network exodus reform observation won baronet home landing starting elevated employees? allowed programs where demi harmon today according pondered machine ki signed piston [SEP]']
[Init] best perm rec loss: 0.8935645222663879 for ['[CLS] allowed where landing netsbbed exodus never according elevated harmon demi machine engine! today exchanged close home programs observation hadn legitimate spanning network mandarin piston baronet won? designated signed ) as aunt employees ki force starting [UNK] pondered reform insanity immortality [SEP]']
[Init] best perm rec loss: 0.8931016325950623 for ['[CLS] insanity piston close as baronet observation [UNK] where designated elevated force nets engine machine mandarin programs signed spanning demi harmon exchanged won legitimate ki according landing network ) pondered home never starting reform employees? today allowed hadn exodus aunt!bbed immortality [SEP]']
[Init] best perm rec loss: 0.8928518295288086 for ['[CLS] nets mandarin employees won pondered programs today?! spanning signed elevated starting network exodusbbed harmon as designated exchanged insanity close landing where engine piston home allowed immortality legitimate reform hadn observation according [UNK] ki force machine ) demi aunt never baronet [SEP]']
[Init] best perm rec loss: 0.8927560448646545 for ['[CLS]? home engine pondered mandarin nets allowed insanity according ) reform hadn ki never machine programs immortality as demi observation employees elevated network! piston aunt designated legitimate force starting spanning signed where exodus baronetbbed exchanged [UNK] won today landing harmon close [SEP]']
[Init] best perm rec loss: 0.8924323320388794 for ['[CLS] harmon machine elevated employees network designated insanity where allowed! nets won hadn baronet legitimate engine ) close never mandarin pondered programs exchangedbbed observation demi piston force today landing reform [UNK] according ki immortality home starting as signed? aunt exodus spanning [SEP]']
[Init] best perm rec loss: 0.891954779624939 for ['[CLS] [UNK] observation aunt reform nets signed harmon as exchanged machine never force immortality hadn ) home baronet network spanning employees exodus won designated where accordingbbed! programs starting allowed? legitimate elevated ki today mandarin demi insanity pondered landing close piston engine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.480 (perp=10.844, rec=0.311, cos=0.000), tot_loss_proj:3.271 [t=0.28s]
prediction: ['[CLS] understand that iron deserve michael portrait. stunning hearts we adventure jo love franklin,, and global comedy journey magnum won understood where married children. biological the son ride romantic courage. emotional conflict greater rush h₂o prey conner & overcome [SEP]']
[ 100/2000] tot_loss=2.136 (perp=9.488, rec=0.238, cos=0.000), tot_loss_proj:3.095 [t=0.30s]
prediction: ['[CLS] understands that black deserve their understand.otted friendship we adventure herself lovegence of. and global loves greater love understood where. children. knew the ill we conflict evil. emotional and us owen of calm todd and excitement [SEP]']
[ 150/2000] tot_loss=2.207 (perp=9.867, rec=0.234, cos=0.000), tot_loss_proj:3.175 [t=0.30s]
prediction: ['[CLS] understands of. helps our understands grand grand love is beau romance love under coaster, and ; love‘c greatest smiles and t lives. daily our ill we sun ill. joy and our anderson of calm winston ] heart [SEP]']
[ 200/2000] tot_loss=2.412 (perp=10.699, rec=0.272, cos=0.000), tot_loss_proj:3.594 [t=0.27s]
prediction: ['[CLS] understands of black qaeda our how grand grand love thectum romance love canstered the ― illusion having⇒ word unique smiles ள t of. new thes we, ill " - and of anderson of calm riley, excitement [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.326 (perp=10.447, rec=0.237, cos=0.000), tot_loss_proj:2.772 [t=0.27s]
prediction: ['[CLS] understands knows black qaeda romance how grand romance love the purity our love can shrub the ― illusion lives⇒ the unique joy ʸ p of. kendall thats we robert ill " - and of anderson া calm brady. excitement [SEP]']
[ 300/2000] tot_loss=2.380 (perp=10.595, rec=0.261, cos=0.000), tot_loss_proj:3.208 [t=0.27s]
prediction: ['[CLS] understands₍. expeditions romance how things great love the 19th our love canstered the theility understand ो the grand joy ள p of. kendall that wild we compositions ill "shire and of anderson products calm blake. spirits [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.296 (perp=10.268, rec=0.242, cos=0.000), tot_loss_proj:3.842 [t=0.26s]
prediction: ['[CLS] understands anymore. expeditions romance how the than great love the 3d our love can‖ [CLS] accurately smashwords ो the grand joy ள p and. justin our ill we marina ill great million and of anderson products calm anderson and why [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.333 (perp=10.634, rec=0.206, cos=0.000), tot_loss_proj:3.403 [t=0.28s]
prediction: ['[CLS] understands your. expeditions romance how the attend great romance we 3d our love can‖ the accurately huffington ो the grand joy ள p and. justin our ill the hello ill grand cooper and of anderson products calm anderson.ness [SEP]']
[ 450/2000] tot_loss=2.320 (perp=10.701, rec=0.180, cos=0.000), tot_loss_proj:3.649 [t=0.27s]
prediction: ['[CLS] understands your. expeditions romance how the attend great romance we 3ded love can‖ the is huffington ो the grand joy ள p and. lexi our ill the thousand ill grand records and of anderson products calm anderson.ness [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.283 (perp=10.530, rec=0.177, cos=0.000), tot_loss_proj:3.618 [t=0.26s]
prediction: ['[CLS] understands your. freud romance attend how the great romance we 3dness joy can‖ the is smashwords ो the grand joy ள p and. lexi our ill the laundry ill grand records and of anderson products calm anderson. grand [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.178 (perp=10.045, rec=0.169, cos=0.000), tot_loss_proj:3.478 [t=0.26s]
prediction: ['[CLS] understandss. expeditions romance attend how the great romance we 3d your joy can‖ the is smashwords% the grand joy ள p and.ager our ill the ill ill grand records and of anderson products calm anderson.ness [SEP]']
[ 600/2000] tot_loss=2.127 (perp=9.819, rec=0.164, cos=0.000), tot_loss_proj:3.218 [t=0.27s]
prediction: ['[CLS] understandss. expeditions romance cash how the great romance we 3d your love can‖ the, smashwords% the grand joy ள p and. kendall our ill the ill ill grands and of anderson products calm parker. grand [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.100 (perp=9.706, rec=0.158, cos=0.000), tot_loss_proj:3.300 [t=0.25s]
prediction: ['[CLS] understandss. freud romance or how the grand romance we 3d your love can‖ the, smashwords% the grand joy ள p [CLS]. kendall our ill the ill grands and daily of anderson products calm parker. grand [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.998 (perp=9.173, rec=0.164, cos=0.000), tot_loss_proj:3.244 [t=0.26s]
prediction: ['[CLS] understandss. freud romance or how the grand romance we 3d your love can‖ the, sadly ो the grand joy ள p.ager our ill and the ill grands and daily of anderson products calm parker. grand [SEP]']
[ 750/2000] tot_loss=1.925 (perp=8.829, rec=0.159, cos=0.000), tot_loss_proj:3.251 [t=0.26s]
prediction: ['[CLS] understandss. expeditions romance or how the grand romance we 3d your love can‖ the, sadly ो the grand joy ள p. very our ill and the ill grands and daily of anderson products calm parker. grand [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.044 (perp=9.304, rec=0.183, cos=0.000), tot_loss_proj:3.255 [t=0.26s]
prediction: ['[CLS] understandss expeditions. romance or how the grand romance we 3d youricing canneas the, sadly ो the grand joy ள p. kendall our ill and the ill grand out and daily of anderson products calm parker. grand [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.946 (perp=8.909, rec=0.164, cos=0.000), tot_loss_proj:3.309 [t=0.28s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance we 3d your understands canneas the, sadly ो the grand joy ள p. very our ill and the ill grand out and daily of anderson products calm parker. grand [SEP]']
[ 900/2000] tot_loss=1.976 (perp=9.115, rec=0.153, cos=0.000), tot_loss_proj:3.391 [t=0.28s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance we 3d my understands canneas the, sadly ो the grand joydson p. very our ill and the ill grand out and daily of anderson products calm parker. grand [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.920 (perp=8.811, rec=0.158, cos=0.000), tot_loss_proj:3.405 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance we 3d of understands canneas the grand, sadly ो the grand joydson p. very our ill and the ill grand out and daily of anderson products calm rated. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.772 (perp=8.099, rec=0.152, cos=0.000), tot_loss_proj:3.277 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of we 3d understands can‖ the grand, sadly ो the grand joydson p. very our ill and the ill grand out and daily of anderson products calm daily. [SEP]']
[1050/2000] tot_loss=1.887 (perp=8.667, rec=0.154, cos=0.000), tot_loss_proj:3.171 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of us 3d understands can‖ is grand,ɕ ो the daily joydson p. very our ill and the ill grand out and daily of anderson products calm daily. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.843 (perp=8.462, rec=0.151, cos=0.000), tot_loss_proj:3.191 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of us 3d understands can‖ is grand,ɕ ो the daily joydson p. very ill and the ill grand out and our daily of anderson products calm daily. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.829 (perp=8.377, rec=0.154, cos=0.000), tot_loss_proj:3.251 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of us 3d understands canneas is grand,ɕ ो. the daily joydson p very ill and the ill grands and our daily of anderson products calm.. [SEP]']
[1200/2000] tot_loss=1.810 (perp=8.323, rec=0.146, cos=0.000), tot_loss_proj:3.237 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d understands canneas is grand,ɕ ो. the daily joydson p very ill and the ill grand out and our daily of anderson products calm daily. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.762 (perp=8.085, rec=0.145, cos=0.000), tot_loss_proj:3.194 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d understands canneas is grand, dialects ो. the daily joydson p very ill and the ill grand out and of our daily anderson products calm daily. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.732 (perp=7.971, rec=0.138, cos=0.000), tot_loss_proj:3.208 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d ो canneas is grand, dialects understands. the daily joydson p very ill and the ill grand out and of our daily anderson products calm daily. [SEP]']
[1350/2000] tot_loss=1.745 (perp=7.986, rec=0.148, cos=0.000), tot_loss_proj:3.236 [t=0.28s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the ill grand out and of our daily anderson products calm daily. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.763 (perp=8.116, rec=0.140, cos=0.000), tot_loss_proj:3.207 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the ill grand knew and of our daily anderson products calm daily. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.767 (perp=8.116, rec=0.144, cos=0.000), tot_loss_proj:3.206 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the ill grand knew and of our daily anderson products calm daily. [SEP]']
[1500/2000] tot_loss=1.760 (perp=8.116, rec=0.137, cos=0.000), tot_loss_proj:3.207 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the ill grand knew and of our daily anderson products calm daily. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.767 (perp=8.116, rec=0.144, cos=0.000), tot_loss_proj:3.209 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the ill grand knew and of our daily anderson products calm daily. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.760 (perp=8.112, rec=0.138, cos=0.000), tot_loss_proj:3.138 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the grand ill knew and of our daily anderson products calm daily. [SEP]']
[1650/2000] tot_loss=1.763 (perp=8.112, rec=0.141, cos=0.000), tot_loss_proj:3.135 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the grand ill knew and of our daily anderson products calm daily. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.737 (perp=7.993, rec=0.139, cos=0.000), tot_loss_proj:3.290 [t=0.28s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is knew, dialects understands. the daily joydson p very ill and the grand ill grand and of our daily anderson products calm daily. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.726 (perp=7.896, rec=0.147, cos=0.000), tot_loss_proj:3.309 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is knew, dialectsdson understands. the daily joy p very ill and the grand ill grand and of our daily anderson products calm daily. [SEP]']
[1800/2000] tot_loss=1.725 (perp=7.914, rec=0.142, cos=0.000), tot_loss_proj:3.320 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is knew, dialects my understands. the daily joy p very ill and the grand ill grand and of our daily anderson products calm daily. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.690 (perp=7.756, rec=0.139, cos=0.000), tot_loss_proj:3.284 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our my% canneas is knew, dialects 3d understands. the daily joy p very ill and the grand ill grand and of our daily anderson products calm daily. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.693 (perp=7.739, rec=0.145, cos=0.000), tot_loss_proj:3.346 [t=0.26s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our my% canneas is knew, dialects 3d understands. the daily joy p very ill and the grand ill grand and of our daily anderson products calm.. [SEP]']
[1950/2000] tot_loss=1.689 (perp=7.756, rec=0.138, cos=0.000), tot_loss_proj:3.282 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our my% canneas is knew, dialects 3d understands. the daily joy p very ill and the grand ill grand and of our daily anderson products calm daily. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.686 (perp=7.756, rec=0.135, cos=0.000), tot_loss_proj:3.281 [t=0.27s]
prediction: ['[CLS]icings ⽥. romance or how the grand romance of our my% canneas is knew, dialects 3d understands. the daily joy p very ill and the grand ill grand and of our daily anderson products calm daily. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS]icings ⽥. romance or how the grand romance of our 3d% canneas is grand, dialects understands. the daily joydson p very ill and the grand ill knew and of our daily anderson products calm daily. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.351 | p: 52.778 | r: 50.000
rouge2     | fm: 8.333 | p: 8.571 | r: 8.108
rougeL     | fm: 27.027 | p: 27.778 | r: 26.316
rougeLsum  | fm: 27.027 | p: 27.778 | r: 26.316
r1fm+r2fm = 59.685

[Aggregate metrics]:
rouge1     | fm: 91.548 | p: 90.904 | r: 92.334
rouge2     | fm: 58.580 | p: 58.232 | r: 58.946
rougeL     | fm: 79.079 | p: 78.493 | r: 79.804
rougeLsum  | fm: 79.177 | p: 78.616 | r: 79.822
r1fm+r2fm = 150.129

input #88 time: 0:11:17 | total time: 15:58:22


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
*********************************
*********************************
average of cosine similarity 0.9993418772216457
highest_index [0]
highest [0.9993418772216457]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9676754474639893 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9532988667488098 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9443395733833313 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9322538375854492 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.9300572276115417 for ['[CLS] deaths eight jp leon creditedttefoot gpsats broken trusting document happenedpatemediauating cutler don atarifuluded promise practicing photograph atomic wish muttered relatively blood weight boys watt [SEP]']
[Init] best perm rec loss: 0.9261440634727478 for ['[CLS] broken boys don weight deaths watt documentuating blood eight atomic promisefoot leon credited wishful practicinguded gps muttered atari happenedmediaats photographpate jptte trusting cutler relatively [SEP]']
[Init] best perm rec loss: 0.9256871342658997 for ['[CLS] relatively jp muttered gps promise brokenful atomic cutlertteudedfoot watt blood leon eightmedia wishuating atari document deaths boysats photograph weightpate happened don credited trusting practicing [SEP]']
[Init] best perm rec loss: 0.9239301681518555 for ['[CLS] brokenats leon deaths documentmedia jp watt weighttteudedful eight blood relatively atari atomic boys wish credited gps practicingpateuating happened trusting muttered photographfoot don cutler promise [SEP]']
[Init] best perm rec loss: 0.9231923222541809 for ['[CLS] photograph boys practicingpate atomic relatively deathsmediaudedfulfoot dontte eight promise wish muttered gpsuating credited happened weight document atari brokenats trusting cutler leon blood watt jp [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.635 (perp=11.364, rec=0.362, cos=0.000), tot_loss_proj:3.118 [t=0.26s]
prediction: ['[CLS] someone - worse idiot talk seemed except military terrified worse his - fbi having tape stupid apparently no hamburg fake insurance weapons tape maybe poorly covering stupid that logic was - constituencies [SEP]']
[ 100/2000] tot_loss=2.346 (perp=10.263, rec=0.293, cos=0.000), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] someone - worse arrest? seemed format3 was nonesh - fbi appearance or ( inevitable no lab accused worse weapons - tactic yet covering none that ideas - - ideas [SEP]']
[ 150/2000] tot_loss=2.346 (perp=10.424, rec=0.262, cos=0.000), tot_loss_proj:2.902 [t=0.27s]
prediction: ['[CLS] cover - worse arrest? fact format real barrel noneit - fbi his or ( equation no lab accused worse weapons - tactic yet cover none that ideas - - ideas [SEP]']
[ 200/2000] tot_loss=2.240 (perp=10.131, rec=0.214, cos=0.000), tot_loss_proj:3.036 [t=0.26s]
prediction: ['[CLS] cover - tough old. fact film mission barrel noneit -k playing or ( equation or noises acts worse weapons - tactic yet cover worse yet ideas - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.278 (perp=10.477, rec=0.183, cos=0.000), tot_loss_proj:3.112 [t=0.27s]
prediction: ['[CLS] cover to anyway fact. fact picture made none none es -sy on only ( minh orched against yet appearance - tactic of cover worse yet ideas - - ideas [SEP]']
[ 300/2000] tot_loss=2.263 (perp=10.528, rec=0.158, cos=0.000), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] cover the anyway the that fact picture made none nonesten -sy on for of minh orched loose yet is - tactic of cover worse yet ideas - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.902 (perp=8.803, rec=0.142, cos=0.000), tot_loss_proj:2.550 [t=0.26s]
prediction: ['[CLS] minh to cover the that fact picture made pe noneim,sy around for of cover or - new, needs - tactic, cover worse yet core - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.858 (perp=8.631, rec=0.132, cos=0.000), tot_loss_proj:2.523 [t=0.28s]
prediction: ['[CLS] minh to cover the that fact picture to an nonesten,sy around for of cover orim new, release - tactic, cover worse yet - - core ideas [SEP]']
[ 450/2000] tot_loss=1.932 (perp=9.018, rec=0.128, cos=0.000), tot_loss_proj:2.674 [t=0.26s]
prediction: ['[CLS] minh to cover the that fact picture to an nonesten asy around off of cover orim new, is - tactic, cover worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.781 (perp=8.327, rec=0.115, cos=0.000), tot_loss_proj:2.325 [t=0.27s]
prediction: ['[CLS] minh to cover the that fact picture to fl nonestensy around - of a cover orim new, is - tactic, cover worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.945 (perp=9.177, rec=0.109, cos=0.000), tot_loss_proj:2.866 [t=0.28s]
prediction: ['[CLS] linear to cover the that fact picture to fl nonexisy around down of a cover orim -, reflection new tactic, cover worse yet - - core ideas [SEP]']
[ 600/2000] tot_loss=1.940 (perp=9.177, rec=0.105, cos=0.000), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] linear to cover the that fact picture to fl nonexisy around down of a cover orim -, reflection new tactic, cover worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.827 (perp=8.602, rec=0.106, cos=0.000), tot_loss_proj:2.717 [t=0.25s]
prediction: ['[CLS] linear to cover the that fact picture fl nonexisy to around down of a cover orim -, is new tactic, cover worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.766 (perp=8.327, rec=0.100, cos=0.000), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] linear to cover up that fact picture fl nonexisy to around up of a cover or -im, is new tactic, cover worse yet - - core ideas [SEP]']
[ 750/2000] tot_loss=1.765 (perp=8.327, rec=0.099, cos=0.000), tot_loss_proj:2.481 [t=0.29s]
prediction: ['[CLS] linear to cover up that fact picture fl nonexisy to around up of a cover or -im, is new tactic, cover worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.702 (perp=7.988, rec=0.104, cos=0.000), tot_loss_proj:2.353 [t=0.27s]
prediction: ['[CLS] linear to cover up that fact picture either nonexisy to constructed up of a cover or -im, fl new tactic, cover worse yet - - core ideas [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.632 (perp=7.675, rec=0.097, cos=0.000), tot_loss_proj:2.388 [t=0.25s]
prediction: ['[CLS] definitive to cover up that fact picture either nonexisy to constructed up of a cover or -im, new tactic fl, cover worse yet - - core ideas [SEP]']
[ 900/2000] tot_loss=1.632 (perp=7.675, rec=0.097, cos=0.000), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture either nonexisy to constructed up of a cover or -im, new tactic fl, cover worse yet - - core ideas [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.631 (perp=7.675, rec=0.096, cos=0.000), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture either nonexisy to constructed up of a cover or -im, new tactic fl, cover worse yet - - core ideas [SEP]']
Attempt swap
[1000/2000] tot_loss=1.616 (perp=7.614, rec=0.093, cos=0.000), tot_loss_proj:2.387 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture is nonexisy to constructed up of a cover or -im, new tactic fl, cover worse yet - - core ideas [SEP]']
[1050/2000] tot_loss=1.614 (perp=7.614, rec=0.091, cos=0.000), tot_loss_proj:2.387 [t=0.28s]
prediction: ['[CLS] definitive to cover up that fact picture is nonexisy to constructed up of a cover or -im, new tactic fl, cover worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.576 (perp=7.415, rec=0.093, cos=0.000), tot_loss_proj:2.315 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture is nonexisy to constructed up of a cover or cover -im, new tactic fl, worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.566 (perp=7.376, rec=0.091, cos=0.000), tot_loss_proj:2.254 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture is nonexisy to constructed up of a cover or cover -im, new fl tactic, worse yet - - core ideas [SEP]']
[1200/2000] tot_loss=1.612 (perp=7.610, rec=0.090, cos=0.000), tot_loss_proj:2.342 [t=0.27s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy to constructed up of a cover or cover -im, new fl tactic, worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.622 (perp=7.631, rec=0.096, cos=0.000), tot_loss_proj:2.421 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy to constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1300/2000] tot_loss=1.616 (perp=7.631, rec=0.089, cos=0.000), tot_loss_proj:2.420 [t=0.28s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy to constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
[1350/2000] tot_loss=1.566 (perp=7.409, rec=0.084, cos=0.000), tot_loss_proj:2.276 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1400/2000] tot_loss=1.577 (perp=7.438, rec=0.090, cos=0.000), tot_loss_proj:2.152 [t=0.26s]
prediction: ['[CLS]ness to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1450/2000] tot_loss=1.567 (perp=7.409, rec=0.086, cos=0.000), tot_loss_proj:2.273 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
[1500/2000] tot_loss=1.570 (perp=7.409, rec=0.089, cos=0.000), tot_loss_proj:2.273 [t=0.27s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1550/2000] tot_loss=1.572 (perp=7.409, rec=0.090, cos=0.000), tot_loss_proj:2.269 [t=0.28s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.409, rec=0.091, cos=0.000), tot_loss_proj:2.274 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
[1650/2000] tot_loss=1.569 (perp=7.409, rec=0.087, cos=0.000), tot_loss_proj:2.271 [t=0.27s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1700/2000] tot_loss=1.575 (perp=7.409, rec=0.093, cos=0.000), tot_loss_proj:2.273 [t=0.27s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1750/2000] tot_loss=1.576 (perp=7.409, rec=0.094, cos=0.000), tot_loss_proj:2.279 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
[1800/2000] tot_loss=1.572 (perp=7.409, rec=0.090, cos=0.000), tot_loss_proj:2.269 [t=0.25s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[1850/2000] tot_loss=1.568 (perp=7.409, rec=0.087, cos=0.000), tot_loss_proj:2.275 [t=0.27s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.577 (perp=7.409, rec=0.095, cos=0.000), tot_loss_proj:2.276 [t=0.27s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
[1950/2000] tot_loss=1.573 (perp=7.409, rec=0.092, cos=0.000), tot_loss_proj:2.269 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Attempt swap
[2000/2000] tot_loss=1.571 (perp=7.409, rec=0.089, cos=0.000), tot_loss_proj:2.275 [t=0.26s]
prediction: ['[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] definitive to cover up that fact picture the nonexisy is constructed up of a cover or cover -im, screen tactic, fl worse yet - - core ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.000 | p: 70.370 | r: 82.609
rouge2     | fm: 20.833 | p: 19.231 | r: 22.727
rougeL     | fm: 56.000 | p: 51.852 | r: 60.870
rougeLsum  | fm: 56.000 | p: 51.852 | r: 60.870
r1fm+r2fm = 96.833

[Aggregate metrics]:
rouge1     | fm: 91.349 | p: 90.645 | r: 92.198
rouge2     | fm: 58.178 | p: 57.853 | r: 58.634
rougeL     | fm: 78.836 | p: 78.264 | r: 79.561
rougeLsum  | fm: 78.754 | p: 78.175 | r: 79.474
r1fm+r2fm = 149.528

input #89 time: 0:11:08 | total time: 16:09:30


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
*********************************
*********************************
average of cosine similarity 0.999365560857628
highest_index [0]
highest [0.999365560857628]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9512013792991638 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.943489134311676 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9298301339149475 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.907884955406189 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8906010985374451 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8816037774085999 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8717060685157776 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8698916435241699 for ['[CLS] entourage released cannot spirited male when [SEP]']
[Init] best perm rec loss: 0.8694012761116028 for ['[CLS] cannot male spirited released entourage when [SEP]']
[Init] best perm rec loss: 0.8671762943267822 for ['[CLS] cannot spirited male released when entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.798 (perp=12.001, rec=0.398, cos=0.000), tot_loss_proj:3.101 [t=0.21s]
prediction: ['[CLS] union farm breast ridiculous [ ass [SEP]']
[ 100/2000] tot_loss=2.768 (perp=12.491, rec=0.269, cos=0.000), tot_loss_proj:3.139 [t=0.21s]
prediction: ['[CLS] aw setup wife ridiculous how how [SEP]']
[ 150/2000] tot_loss=2.290 (perp=10.620, rec=0.166, cos=0.000), tot_loss_proj:2.617 [t=0.21s]
prediction: ['[CLS] ridiculous oriented money ridiculous and how [SEP]']
[ 200/2000] tot_loss=2.102 (perp=9.904, rec=0.121, cos=0.000), tot_loss_proj:2.576 [t=0.21s]
prediction: ['[CLS] corporate oriented money ridiculous and how [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.092 (perp=10.013, rec=0.089, cos=0.000), tot_loss_proj:2.525 [t=0.21s]
prediction: ['[CLS] how oriented money ridiculous and negligence [SEP]']
[ 300/2000] tot_loss=2.002 (perp=9.515, rec=0.099, cos=0.000), tot_loss_proj:2.415 [t=0.21s]
prediction: ['[CLS] how oriented money ridiculous and oriented [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.700 (perp=8.157, rec=0.069, cos=0.000), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] how ridiculous money oriented and oriented [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.726 (perp=8.130, rec=0.100, cos=0.000), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented ・ [SEP]']
[ 450/2000] tot_loss=1.441 (perp=6.870, rec=0.067, cos=0.000), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.438 (perp=6.870, rec=0.064, cos=0.000), tot_loss_proj:1.679 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.000), tot_loss_proj:1.673 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.444 (perp=6.870, rec=0.070, cos=0.000), tot_loss_proj:1.677 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.434 (perp=6.870, rec=0.060, cos=0.000), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.434 (perp=6.870, rec=0.060, cos=0.000), tot_loss_proj:1.681 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.000), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.000), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.431 (perp=6.870, rec=0.057, cos=0.000), tot_loss_proj:1.684 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.434 (perp=6.870, rec=0.060, cos=0.000), tot_loss_proj:1.679 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.439 (perp=6.870, rec=0.065, cos=0.000), tot_loss_proj:1.676 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.000), tot_loss_proj:1.681 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.430 (perp=6.870, rec=0.056, cos=0.000), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.432 (perp=6.870, rec=0.058, cos=0.000), tot_loss_proj:1.684 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.438 (perp=6.870, rec=0.064, cos=0.000), tot_loss_proj:1.684 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.432 (perp=6.870, rec=0.058, cos=0.000), tot_loss_proj:1.679 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.426 (perp=6.870, rec=0.052, cos=0.000), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.437 (perp=6.870, rec=0.063, cos=0.000), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.000), tot_loss_proj:1.692 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.438 (perp=6.870, rec=0.064, cos=0.000), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.000), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.450 (perp=6.870, rec=0.076, cos=0.000), tot_loss_proj:1.676 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.427 (perp=6.870, rec=0.053, cos=0.000), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.439 (perp=6.870, rec=0.065, cos=0.000), tot_loss_proj:1.678 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.434 (perp=6.870, rec=0.060, cos=0.000), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.439 (perp=6.870, rec=0.065, cos=0.000), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.435 (perp=6.870, rec=0.061, cos=0.000), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.435 (perp=6.870, rec=0.061, cos=0.000), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.870, rec=0.058, cos=0.000), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.442 (perp=6.870, rec=0.068, cos=0.000), tot_loss_proj:1.682 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.426 (perp=6.870, rec=0.052, cos=0.000), tot_loss_proj:1.679 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.434 (perp=6.870, rec=0.060, cos=0.000), tot_loss_proj:1.692 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.509 | p: 90.786 | r: 92.342
rouge2     | fm: 58.509 | p: 58.169 | r: 58.942
rougeL     | fm: 79.082 | p: 78.452 | r: 79.784
rougeLsum  | fm: 79.071 | p: 78.472 | r: 79.787
r1fm+r2fm = 150.018

input #90 time: 0:10:45 | total time: 16:20:16


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
*********************************
*********************************
average of cosine similarity 0.9993538287265724
highest_index [0]
highest [0.9993538287265724]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9377912878990173 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.9373000264167786 for ['[CLS]underscribe canton below messenger speaking been does [SEP]']
[Init] best rec loss: 0.8270809650421143 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8118617534637451 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7729765772819519 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7607266902923584 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7391999363899231 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7284872531890869 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7252480983734131 for ['[CLS] unknown shelterpmentlipdern hard revolution pony [SEP]']
[Init] best perm rec loss: 0.7249718308448792 for ['[CLS] hardlippment revolution ponydern shelter unknown [SEP]']
[Init] best perm rec loss: 0.7248975038528442 for ['[CLS] hardlippment revolution unknowndern pony shelter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.736 (perp=11.833, rec=0.370, cos=0.000), tot_loss_proj:3.352 [t=0.26s]
prediction: ['[CLS] cattle waste fur ridiculous ridiculousne mutation nasty [SEP]']
[ 100/2000] tot_loss=3.031 (perp=13.717, rec=0.287, cos=0.000), tot_loss_proj:3.801 [t=0.26s]
prediction: ['[CLS] mexican no loco ridiculous nothinguprri goat [SEP]']
[ 150/2000] tot_loss=2.792 (perp=12.773, rec=0.238, cos=0.000), tot_loss_proj:3.174 [t=0.26s]
prediction: ['[CLS] mexican more loco ridiculous moreup more loco [SEP]']
[ 200/2000] tot_loss=2.451 (perp=11.311, rec=0.189, cos=0.000), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] micro more loco ridiculous no mu more loco [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.246 (perp=10.356, rec=0.174, cos=0.000), tot_loss_proj:2.917 [t=0.26s]
prediction: ['[CLS] loco no loco mu ridiculous no more loco [SEP]']
[ 300/2000] tot_loss=2.278 (perp=10.745, rec=0.129, cos=0.000), tot_loss_proj:2.805 [t=0.25s]
prediction: ['[CLS] loco but loco mu ridiculous no more loco [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.039 (perp=9.702, rec=0.098, cos=0.000), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS]y loco loco mu ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.984 (perp=9.468, rec=0.090, cos=0.000), tot_loss_proj:2.397 [t=0.28s]
prediction: ['[CLS] locoy loco mu ridiculous no more but [SEP]']
[ 450/2000] tot_loss=1.978 (perp=9.468, rec=0.085, cos=0.000), tot_loss_proj:2.394 [t=0.26s]
prediction: ['[CLS] locoy loco mu ridiculous no more but [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.978 (perp=9.468, rec=0.084, cos=0.000), tot_loss_proj:2.401 [t=0.25s]
prediction: ['[CLS] locoy loco mu ridiculous no more but [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=9.468, rec=0.070, cos=0.000), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] locoy loco mu ridiculous no more but [SEP]']
[ 600/2000] tot_loss=1.972 (perp=9.468, rec=0.078, cos=0.000), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] locoy loco mu ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.923 (perp=9.200, rec=0.083, cos=0.000), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] locoy loco mu but no more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.900 (perp=9.200, rec=0.060, cos=0.000), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] locoy loco mu but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.906 (perp=9.200, rec=0.066, cos=0.000), tot_loss_proj:2.102 [t=0.27s]
prediction: ['[CLS] locoy loco mu but no more ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.885 (perp=9.068, rec=0.072, cos=0.000), tot_loss_proj:2.033 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=9.068, rec=0.077, cos=0.000), tot_loss_proj:2.033 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.887 (perp=9.068, rec=0.074, cos=0.000), tot_loss_proj:2.038 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.886 (perp=9.068, rec=0.072, cos=0.000), tot_loss_proj:2.038 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.890 (perp=9.068, rec=0.076, cos=0.000), tot_loss_proj:2.033 [t=0.27s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.876 (perp=9.068, rec=0.062, cos=0.000), tot_loss_proj:2.029 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.887 (perp=9.068, rec=0.073, cos=0.000), tot_loss_proj:2.039 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.880 (perp=9.068, rec=0.067, cos=0.000), tot_loss_proj:2.043 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.881 (perp=9.068, rec=0.068, cos=0.000), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.892 (perp=9.068, rec=0.078, cos=0.000), tot_loss_proj:2.038 [t=0.27s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.890 (perp=9.068, rec=0.076, cos=0.000), tot_loss_proj:2.033 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.882 (perp=9.068, rec=0.069, cos=0.000), tot_loss_proj:2.035 [t=0.27s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.881 (perp=9.068, rec=0.068, cos=0.000), tot_loss_proj:2.035 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.888 (perp=9.068, rec=0.075, cos=0.000), tot_loss_proj:2.036 [t=0.27s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.887 (perp=9.068, rec=0.073, cos=0.000), tot_loss_proj:2.035 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.887 (perp=9.068, rec=0.073, cos=0.000), tot_loss_proj:2.031 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.885 (perp=9.068, rec=0.071, cos=0.000), tot_loss_proj:2.038 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.878 (perp=9.068, rec=0.065, cos=0.000), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.886 (perp=9.068, rec=0.073, cos=0.000), tot_loss_proj:2.037 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.888 (perp=9.068, rec=0.074, cos=0.000), tot_loss_proj:2.040 [t=0.25s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.884 (perp=9.068, rec=0.071, cos=0.000), tot_loss_proj:2.040 [t=0.27s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.883 (perp=9.068, rec=0.070, cos=0.000), tot_loss_proj:2.030 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.877 (perp=9.068, rec=0.064, cos=0.000), tot_loss_proj:2.041 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.881 (perp=9.068, rec=0.067, cos=0.000), tot_loss_proj:2.033 [t=0.26s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.882 (perp=9.068, rec=0.068, cos=0.000), tot_loss_proj:2.039 [t=0.27s]
prediction: ['[CLS] muy loco loco but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco loco but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 93.333 | p: 87.500 | r: 100.000
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 187.451

[Aggregate metrics]:
rouge1     | fm: 91.494 | p: 90.781 | r: 92.377
rouge2     | fm: 59.105 | p: 58.701 | r: 59.564
rougeL     | fm: 79.324 | p: 78.687 | r: 80.028
rougeLsum  | fm: 79.266 | p: 78.636 | r: 80.025
r1fm+r2fm = 150.598

input #91 time: 0:11:08 | total time: 16:31:24


Running input #92 of 100.
reference: 
========================
deceit 
========================
*********************************
*********************************
average of cosine similarity 0.9993144895868483
highest_index [0]
highest [0.9993144895868483]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8787897825241089 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.876357913017273 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8719595074653625 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8656350374221802 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8549246788024902 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7898336052894592 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.788432240486145 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.677 (perp=12.265, rec=0.224, cos=0.000), tot_loss_proj:3.102 [t=0.27s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.666 (perp=7.647, rec=0.136, cos=0.000), tot_loss_proj:1.615 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.603 (perp=7.647, rec=0.073, cos=0.000), tot_loss_proj:1.617 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.592 (perp=7.647, rec=0.063, cos=0.000), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.592 (perp=7.647, rec=0.063, cos=0.000), tot_loss_proj:1.607 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.582 (perp=7.647, rec=0.053, cos=0.000), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.583 (perp=7.647, rec=0.054, cos=0.000), tot_loss_proj:1.599 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.592 (perp=7.647, rec=0.063, cos=0.000), tot_loss_proj:1.616 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.593 (perp=7.647, rec=0.064, cos=0.000), tot_loss_proj:1.600 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.592 (perp=7.647, rec=0.063, cos=0.000), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.599 (perp=7.647, rec=0.070, cos=0.000), tot_loss_proj:1.605 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.586 (perp=7.647, rec=0.057, cos=0.000), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.647, rec=0.057, cos=0.000), tot_loss_proj:1.611 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.591 (perp=7.647, rec=0.061, cos=0.000), tot_loss_proj:1.603 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.583 (perp=7.647, rec=0.054, cos=0.000), tot_loss_proj:1.623 [t=0.29s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.598 (perp=7.647, rec=0.068, cos=0.000), tot_loss_proj:1.592 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=7.647, rec=0.063, cos=0.000), tot_loss_proj:1.618 [t=0.29s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.594 (perp=7.647, rec=0.064, cos=0.000), tot_loss_proj:1.599 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.647, rec=0.066, cos=0.000), tot_loss_proj:1.599 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.585 (perp=7.647, rec=0.056, cos=0.000), tot_loss_proj:1.601 [t=0.29s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.580 (perp=7.647, rec=0.051, cos=0.000), tot_loss_proj:1.592 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=7.647, rec=0.058, cos=0.000), tot_loss_proj:1.604 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.596 (perp=7.647, rec=0.067, cos=0.000), tot_loss_proj:1.597 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.589 (perp=7.647, rec=0.060, cos=0.000), tot_loss_proj:1.597 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.582 (perp=7.647, rec=0.052, cos=0.000), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.591 (perp=7.647, rec=0.061, cos=0.000), tot_loss_proj:1.596 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.590 (perp=7.647, rec=0.061, cos=0.000), tot_loss_proj:1.596 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.591 (perp=7.647, rec=0.062, cos=0.000), tot_loss_proj:1.581 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.582 (perp=7.647, rec=0.053, cos=0.000), tot_loss_proj:1.593 [t=0.29s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.599 (perp=7.647, rec=0.070, cos=0.000), tot_loss_proj:1.596 [t=0.29s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.587 (perp=7.647, rec=0.058, cos=0.000), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.647, rec=0.057, cos=0.000), tot_loss_proj:1.592 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.647, rec=0.068, cos=0.000), tot_loss_proj:1.604 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.586 (perp=7.647, rec=0.057, cos=0.000), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.590 (perp=7.647, rec=0.061, cos=0.000), tot_loss_proj:1.607 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.602 (perp=7.647, rec=0.072, cos=0.000), tot_loss_proj:1.603 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.596 (perp=7.647, rec=0.066, cos=0.000), tot_loss_proj:1.584 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.607 (perp=7.647, rec=0.078, cos=0.000), tot_loss_proj:1.592 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.599 (perp=7.647, rec=0.069, cos=0.000), tot_loss_proj:1.590 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.604 (perp=7.647, rec=0.075, cos=0.000), tot_loss_proj:1.598 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.589 | p: 90.865 | r: 92.504
rouge2     | fm: 59.538 | p: 59.125 | r: 60.033
rougeL     | fm: 79.339 | p: 78.731 | r: 80.093
rougeLsum  | fm: 79.390 | p: 78.752 | r: 80.159
r1fm+r2fm = 151.127

input #92 time: 0:11:23 | total time: 16:42:48


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
*********************************
*********************************
average of cosine similarity 0.9993327769780862
highest_index [0]
highest [0.9993327769780862]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0075374841690063 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8294076323509216 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8254433870315552 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8079794645309448 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.805877685546875 for ['[CLS] judicialball 1970s shrinking specific lad solo [SEP]']
[Init] best perm rec loss: 0.8055862188339233 for ['[CLS]ball lad shrinking specific judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.8048418760299683 for ['[CLS] shrinkingball 1970s specific lad judicial solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.245 (perp=12.385, rec=0.768, cos=0.000), tot_loss_proj:3.990 [t=0.21s]
prediction: ['[CLS] party illegal commission party bourgeois chrysler alcohol [SEP]']
[ 100/2000] tot_loss=2.646 (perp=9.999, rec=0.646, cos=0.000), tot_loss_proj:3.697 [t=0.21s]
prediction: ['[CLS] some illegal way ) train put interchange [SEP]']
[ 150/2000] tot_loss=2.933 (perp=11.680, rec=0.592, cos=0.006), tot_loss_proj:4.079 [t=0.21s]
prediction: ['[CLS] its alleged way ) dynasty put glasses [SEP]']
[ 200/2000] tot_loss=3.305 (perp=13.155, rec=0.673, cos=0.000), tot_loss_proj:4.436 [t=0.21s]
prediction: ['[CLS] its encoded way googleifice catholicism glasses [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.553 (perp=14.646, rec=0.624, cos=0.000), tot_loss_proj:4.809 [t=0.27s]
prediction: ['[CLS] its throughout encoded way extremely tatumport [SEP]']
[ 300/2000] tot_loss=3.292 (perp=13.413, rec=0.610, cos=0.000), tot_loss_proj:4.490 [t=0.27s]
prediction: ['[CLS] its throughout encoded way way stylesport [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.871 (perp=11.580, rec=0.555, cos=0.000), tot_loss_proj:4.236 [t=0.26s]
prediction: ['[CLS] its way encoded throughout way callumport [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.773 (perp=11.096, rec=0.554, cos=0.000), tot_loss_proj:3.724 [t=0.27s]
prediction: ['[CLS] its way understanding include throughout way nes [SEP]']
[ 450/2000] tot_loss=2.849 (perp=11.509, rec=0.547, cos=0.000), tot_loss_proj:3.312 [t=0.25s]
prediction: ['[CLS] its way understanding include funny way nes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.834 (perp=11.621, rec=0.510, cos=0.000), tot_loss_proj:2.946 [t=0.27s]
prediction: ['[CLS] its way understanding instantly funny way include [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.579 (perp=10.022, rec=0.575, cos=0.000), tot_loss_proj:2.470 [t=0.26s]
prediction: ['[CLS] understanding instantly funny way its way include [SEP]']
[ 600/2000] tot_loss=2.548 (perp=10.022, rec=0.537, cos=0.007), tot_loss_proj:2.480 [t=0.27s]
prediction: ['[CLS] understanding instantly funny way its way include [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.364 (perp=9.347, rec=0.494, cos=0.000), tot_loss_proj:2.336 [t=0.29s]
prediction: ['[CLS] instantly understanding funny way its way include [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.406 (perp=9.491, rec=0.507, cos=0.000), tot_loss_proj:2.568 [t=0.27s]
prediction: ['[CLS] understanding catholicism funny way its way include [SEP]']
[ 750/2000] tot_loss=2.345 (perp=9.309, rec=0.484, cos=0.000), tot_loss_proj:2.567 [t=0.29s]
prediction: ['[CLS] understanding interest funny way its way include [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.481 (perp=9.883, rec=0.504, cos=0.000), tot_loss_proj:2.633 [t=0.29s]
prediction: ['[CLS] understanding catholicism way funny its way include [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.353 (perp=9.309, rec=0.491, cos=0.000), tot_loss_proj:2.559 [t=0.29s]
prediction: ['[CLS] understanding interest funny way its way include [SEP]']
[ 900/2000] tot_loss=2.553 (perp=10.325, rec=0.488, cos=0.000), tot_loss_proj:2.789 [t=0.28s]
prediction: ['[CLS] understanding interest funny way its way raion [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.404 (perp=9.663, rec=0.472, cos=0.000), tot_loss_proj:2.655 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1000/2000] tot_loss=2.409 (perp=9.663, rec=0.477, cos=0.000), tot_loss_proj:2.655 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1050/2000] tot_loss=2.405 (perp=9.663, rec=0.472, cos=0.000), tot_loss_proj:2.662 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1100/2000] tot_loss=2.394 (perp=9.663, rec=0.462, cos=0.000), tot_loss_proj:2.655 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1150/2000] tot_loss=2.400 (perp=9.663, rec=0.467, cos=0.000), tot_loss_proj:2.648 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1200/2000] tot_loss=2.395 (perp=9.663, rec=0.462, cos=0.000), tot_loss_proj:2.648 [t=0.31s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1250/2000] tot_loss=2.391 (perp=9.663, rec=0.458, cos=0.000), tot_loss_proj:2.657 [t=0.28s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1300/2000] tot_loss=2.386 (perp=9.663, rec=0.452, cos=0.001), tot_loss_proj:2.652 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1350/2000] tot_loss=2.393 (perp=9.663, rec=0.460, cos=0.000), tot_loss_proj:2.662 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1400/2000] tot_loss=2.385 (perp=9.663, rec=0.453, cos=0.000), tot_loss_proj:2.652 [t=0.28s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1450/2000] tot_loss=2.384 (perp=9.663, rec=0.451, cos=0.000), tot_loss_proj:2.651 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1500/2000] tot_loss=2.381 (perp=9.663, rec=0.448, cos=0.000), tot_loss_proj:2.657 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1550/2000] tot_loss=2.380 (perp=9.663, rec=0.448, cos=0.000), tot_loss_proj:2.652 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1600/2000] tot_loss=2.377 (perp=9.663, rec=0.445, cos=0.000), tot_loss_proj:2.652 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1650/2000] tot_loss=2.377 (perp=9.663, rec=0.445, cos=0.000), tot_loss_proj:2.655 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1700/2000] tot_loss=2.383 (perp=9.663, rec=0.450, cos=0.000), tot_loss_proj:2.655 [t=0.30s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1750/2000] tot_loss=2.378 (perp=9.663, rec=0.445, cos=0.000), tot_loss_proj:2.658 [t=0.28s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1800/2000] tot_loss=2.380 (perp=9.663, rec=0.447, cos=0.000), tot_loss_proj:2.651 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1850/2000] tot_loss=2.377 (perp=9.663, rec=0.444, cos=0.000), tot_loss_proj:2.661 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[1900/2000] tot_loss=2.371 (perp=9.663, rec=0.439, cos=0.000), tot_loss_proj:2.661 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
[1950/2000] tot_loss=2.380 (perp=9.663, rec=0.447, cos=0.000), tot_loss_proj:2.648 [t=0.29s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Attempt swap
[2000/2000] tot_loss=2.372 (perp=9.663, rec=0.440, cos=0.000), tot_loss_proj:2.655 [t=0.28s]
prediction: ['[CLS] understanding interest way funny its way raion [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding interest way funny its way raion [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 66.667 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 70.588

[Aggregate metrics]:
rouge1     | fm: 91.381 | p: 90.588 | r: 92.332
rouge2     | fm: 59.059 | p: 58.654 | r: 59.550
rougeL     | fm: 79.272 | p: 78.561 | r: 80.096
rougeLsum  | fm: 79.217 | p: 78.526 | r: 79.983
r1fm+r2fm = 150.440

input #93 time: 0:10:56 | total time: 16:53:45


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
*********************************
*********************************
average of cosine similarity 0.9993169912991806
highest_index [0]
highest [0.9993169912991806]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9748303890228271 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9531643390655518 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9177910685539246 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9091373085975647 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8856916427612305 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8842605948448181 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.8831820487976074 for ['[CLS] flowering chronic expedition crushed rockwell shocks internal plumventing centre territorial [SEP]']
[Init] best perm rec loss: 0.8831593990325928 for ['[CLS] crushed internal territorial flowering shocks expedition centreventing rockwell plum chronic [SEP]']
[Init] best perm rec loss: 0.8819487690925598 for ['[CLS] internal centre expedition shocks rockwell territorial flowering plum crushed chronicventing [SEP]']
[Init] best perm rec loss: 0.8814952373504639 for ['[CLS]venting territorial expedition centre flowering shocks internal chronic rockwell crushed plum [SEP]']
[Init] best perm rec loss: 0.8782223463058472 for ['[CLS]venting shocks plum flowering expedition rockwell centre territorial chronic internal crushed [SEP]']
[Init] best perm rec loss: 0.8764366507530212 for ['[CLS] territorialventing crushed expedition internal rockwell centre shocks plum chronic flowering [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.759 (perp=11.694, rec=0.420, cos=0.000), tot_loss_proj:3.278 [t=0.28s]
prediction: ['[CLS] nor - paper seized equivalent chicken station policies bad nor rap [SEP]']
[ 100/2000] tot_loss=2.210 (perp=9.602, rec=0.289, cos=0.000), tot_loss_proj:2.913 [t=0.31s]
prediction: ['[CLS] a who abolition commission nor neither house despite bad nor funny [SEP]']
[ 150/2000] tot_loss=2.183 (perp=9.923, rec=0.198, cos=0.000), tot_loss_proj:2.500 [t=0.25s]
prediction: ['[CLS] a dead cape evidence nor neither original despite nor nor funny [SEP]']
[ 200/2000] tot_loss=2.134 (perp=10.008, rec=0.132, cos=0.000), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] a bun caper that neither original even terribly nor funny [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.865 (perp=8.780, rec=0.109, cos=0.000), tot_loss_proj:2.122 [t=0.25s]
prediction: ['[CLS] a head caper s neither original terribly nor even funny [SEP]']
[ 300/2000] tot_loss=1.845 (perp=8.770, rec=0.091, cos=0.000), tot_loss_proj:2.058 [t=0.27s]
prediction: ['[CLS] a head caper s neither original terribly nor terribly funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.758 (perp=8.352, rec=0.088, cos=0.000), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] a s caper s neither terribly original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.650 (perp=7.874, rec=0.075, cos=0.000), tot_loss_proj:1.914 [t=0.26s]
prediction: ['[CLS] s a caper s neither terribly original nor terribly funny [SEP]']
[ 450/2000] tot_loss=1.641 (perp=7.874, rec=0.067, cos=0.000), tot_loss_proj:1.910 [t=0.25s]
prediction: ['[CLS] s a caper s neither terribly original nor terribly funny [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.654 (perp=7.886, rec=0.077, cos=0.000), tot_loss_proj:1.850 [t=0.34s]
prediction: ['[CLS] s a caper that neither terribly original nor terribly funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.637 (perp=7.886, rec=0.060, cos=0.000), tot_loss_proj:1.858 [t=0.33s]
prediction: ['[CLS] s a caper that neither terribly original nor terribly funny [SEP]']
[ 600/2000] tot_loss=1.647 (perp=7.886, rec=0.070, cos=0.000), tot_loss_proj:1.850 [t=0.32s]
prediction: ['[CLS] s a caper that neither terribly original nor terribly funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.646 (perp=7.886, rec=0.069, cos=0.000), tot_loss_proj:1.854 [t=0.33s]
prediction: ['[CLS] s a caper that neither terribly original nor terribly funny [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.520 (perp=7.211, rec=0.078, cos=0.000), tot_loss_proj:1.728 [t=0.27s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
[ 750/2000] tot_loss=1.503 (perp=7.211, rec=0.061, cos=0.000), tot_loss_proj:1.730 [t=0.26s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.506 (perp=7.182, rec=0.069, cos=0.000), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.497 (perp=7.182, rec=0.061, cos=0.000), tot_loss_proj:1.765 [t=0.25s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
[ 900/2000] tot_loss=1.494 (perp=7.182, rec=0.057, cos=0.000), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.502 (perp=7.182, rec=0.066, cos=0.000), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.500 (perp=7.182, rec=0.064, cos=0.000), tot_loss_proj:1.762 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
[1050/2000] tot_loss=1.501 (perp=7.182, rec=0.064, cos=0.000), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.504 (perp=7.211, rec=0.062, cos=0.000), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.503 (perp=7.182, rec=0.067, cos=0.000), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
[1200/2000] tot_loss=1.503 (perp=7.182, rec=0.066, cos=0.000), tot_loss_proj:1.760 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.500 (perp=7.182, rec=0.064, cos=0.000), tot_loss_proj:1.758 [t=0.26s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.182, rec=0.061, cos=0.000), tot_loss_proj:1.762 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
[1350/2000] tot_loss=1.499 (perp=7.182, rec=0.063, cos=0.000), tot_loss_proj:1.757 [t=0.26s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.509 (perp=7.182, rec=0.073, cos=0.000), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.499 (perp=7.211, rec=0.057, cos=0.000), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
[1500/2000] tot_loss=1.515 (perp=7.211, rec=0.073, cos=0.000), tot_loss_proj:1.733 [t=0.27s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.508 (perp=7.211, rec=0.066, cos=0.000), tot_loss_proj:1.724 [t=0.25s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.504 (perp=7.182, rec=0.067, cos=0.000), tot_loss_proj:1.763 [t=0.25s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
[1650/2000] tot_loss=1.496 (perp=7.182, rec=0.060, cos=0.000), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.505 (perp=7.182, rec=0.068, cos=0.000), tot_loss_proj:1.757 [t=0.28s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.496 (perp=7.182, rec=0.059, cos=0.000), tot_loss_proj:1.761 [t=0.28s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
[1800/2000] tot_loss=1.506 (perp=7.182, rec=0.070, cos=0.000), tot_loss_proj:1.753 [t=0.25s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.501 (perp=7.182, rec=0.065, cos=0.000), tot_loss_proj:1.764 [t=0.27s]
prediction: ['[CLS] s that a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.503 (perp=7.211, rec=0.061, cos=0.000), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
[1950/2000] tot_loss=1.510 (perp=7.211, rec=0.068, cos=0.000), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.506 (perp=7.211, rec=0.064, cos=0.000), tot_loss_proj:1.727 [t=0.28s]
prediction: ['[CLS] that s a caper neither terribly original nor terribly funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] s that a caper neither terribly original nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 91.364 | p: 90.546 | r: 92.315
rouge2     | fm: 58.802 | p: 58.459 | r: 59.285
rougeL     | fm: 79.259 | p: 78.600 | r: 80.043
rougeLsum  | fm: 79.227 | p: 78.519 | r: 80.042
r1fm+r2fm = 150.166

input #94 time: 0:11:19 | total time: 17:05:05


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
*********************************
*********************************
average of cosine similarity 0.9991572949874618
highest_index [0]
highest [0.9991572949874618]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9704791307449341 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.942868709564209 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9420210719108582 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9301784038543701 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9293054938316345 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.920629620552063 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.901691198348999 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.854125440120697 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8460966944694519 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8460406064987183 for ['[CLS] pressure wire hanging damp tech block cut trailer privateے completenne monty ] sister [SEP]']
[Init] best perm rec loss: 0.8459214568138123 for ['[CLS] hanging block wire tech ] pressure monty cut dampے sister trailernne private complete [SEP]']
[Init] best perm rec loss: 0.8445013761520386 for ['[CLS]ے trailer cut block private wire pressure tech sisternne complete damp hanging monty ] [SEP]']
[Init] best perm rec loss: 0.8435372710227966 for ['[CLS] trailer ] cut private block pressure hanging damp complete sister technneے monty wire [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.098 (perp=13.773, rec=0.344, cos=0.000), tot_loss_proj:3.358 [t=0.27s]
prediction: ['[CLS] badly hopeless killingized km an property sick tubes laid kg unsuccessful garbageea coins [SEP]']
[ 100/2000] tot_loss=2.553 (perp=11.514, rec=0.250, cos=0.000), tot_loss_proj:2.759 [t=0.27s]
prediction: ['[CLS] hopeless hopeless builded become hopeless equipment hopeless a became an hopelessiiface story [SEP]']
[ 150/2000] tot_loss=2.599 (perp=12.060, rec=0.187, cos=0.000), tot_loss_proj:2.920 [t=0.26s]
prediction: ['[CLS] hopeless hopeless bodyed becomes hopeless material hopeless adleramsat dungiface story [SEP]']
[ 200/2000] tot_loss=2.237 (perp=10.420, rec=0.153, cos=0.000), tot_loss_proj:2.536 [t=0.27s]
prediction: ["[CLS] extremely hopeless head'becomes hopeless -dle adle,sat mudfying story [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.241 (perp=10.441, rec=0.153, cos=0.000), tot_loss_proj:2.542 [t=0.27s]
prediction: ["[CLS] extremely hopeless horsesat becomes hopeless 'dle adle, ( mudfying story [SEP]"]
[ 300/2000] tot_loss=2.310 (perp=10.883, rec=0.133, cos=0.000), tot_loss_proj:2.629 [t=0.28s]
prediction: ["[CLS] extremely hopelessdlesat becomes hopeless 'fying adle,, mudfying story [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.323 (perp=11.006, rec=0.122, cos=0.000), tot_loss_proj:2.645 [t=0.27s]
prediction: ["[CLS] mud hopelessdle - becomes hopeless 'fying adle,sat mudfying story [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.117 (perp=9.995, rec=0.118, cos=0.000), tot_loss_proj:2.427 [t=0.26s]
prediction: ["[CLS] hopeless muddle - becomes hopeless 'fying adle,sat mudfying story [SEP]"]
[ 450/2000] tot_loss=2.142 (perp=10.128, rec=0.117, cos=0.000), tot_loss_proj:2.480 [t=0.26s]
prediction: ["[CLS] hopeless muddle ) becomes hopeless 'fying adle,sat mudfying story [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.994 (perp=9.453, rec=0.103, cos=0.000), tot_loss_proj:2.335 [t=0.27s]
prediction: ["[CLS] hopeless muddle ) becomes hopeless 'fying afying,sat muddle story [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.167 (perp=10.300, rec=0.107, cos=0.000), tot_loss_proj:2.525 [t=0.27s]
prediction: ["[CLS] hopelessfyingdle ) becomes hopeless'mud afying,sat muddle story [SEP]"]
[ 600/2000] tot_loss=2.147 (perp=10.229, rec=0.101, cos=0.000), tot_loss_proj:2.518 [t=0.26s]
prediction: ["[CLS] hopelessfyingdle ) becomes hopeless'denis afying,sat muddle story [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.111 (perp=10.043, rec=0.102, cos=0.000), tot_loss_proj:2.457 [t=0.26s]
prediction: ["[CLS] denisfyingdle ) becomes hopeless'hopeless afying,sat muddle story [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.977 (perp=9.230, rec=0.131, cos=0.000), tot_loss_proj:2.293 [t=0.27s]
prediction: ["[CLS] denisfyingdle ) becomes hopeless'sat afying, hopeless muddle story [SEP]"]
[ 750/2000] tot_loss=1.950 (perp=9.230, rec=0.105, cos=0.000), tot_loss_proj:2.296 [t=0.27s]
prediction: ["[CLS] denisfyingdle ) becomes hopeless'sat afying, hopeless muddle story [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.926 (perp=9.066, rec=0.113, cos=0.000), tot_loss_proj:2.196 [t=0.28s]
prediction: ["[CLS] denisfying denis ) becomes a hopeless'satfying, hopeless muddle story [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.870 (perp=8.848, rec=0.101, cos=0.000), tot_loss_proj:2.215 [t=0.27s]
prediction: ["[CLS] denisfying') becomes a hopeless denissatfying, hopeless muddle story [SEP]"]
[ 900/2000] tot_loss=1.865 (perp=8.848, rec=0.095, cos=0.000), tot_loss_proj:2.212 [t=0.27s]
prediction: ["[CLS] denisfying') becomes a hopeless denissatfying, hopeless muddle story [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.785 (perp=8.470, rec=0.091, cos=0.000), tot_loss_proj:2.157 [t=0.26s]
prediction: ["[CLS] denisfying hopeless') becomes a denissatfying, hopeless muddle story [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.776 (perp=8.387, rec=0.099, cos=0.000), tot_loss_proj:2.109 [t=0.26s]
prediction: ["[CLS] denisfying hopeless') becomes a denissatis, hopeless muddle story [SEP]"]
[1050/2000] tot_loss=1.771 (perp=8.387, rec=0.094, cos=0.000), tot_loss_proj:2.106 [t=0.27s]
prediction: ["[CLS] denisfying hopeless') becomes a denissatis, hopeless muddle story [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.770 (perp=8.387, rec=0.093, cos=0.000), tot_loss_proj:2.104 [t=0.25s]
prediction: ["[CLS] denisfying hopeless') becomes a denissatis, hopeless muddle story [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.769 (perp=8.387, rec=0.092, cos=0.000), tot_loss_proj:2.109 [t=0.27s]
prediction: ["[CLS] denisfying hopeless') becomes a denissatis, hopeless muddle story [SEP]"]
[1200/2000] tot_loss=1.760 (perp=8.347, rec=0.091, cos=0.000), tot_loss_proj:2.055 [t=0.26s]
prediction: ["[CLS] (fying hopeless') becomes a denissatis, hopeless muddle story [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.660 (perp=7.765, rec=0.107, cos=0.000), tot_loss_proj:1.910 [t=0.27s]
prediction: ["[CLS] (fying hopeless'story becomes a denissatis, hopeless muddle ) [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.517 (perp=7.130, rec=0.091, cos=0.000), tot_loss_proj:1.751 [t=0.27s]
prediction: ["[CLS] (fying denis'story becomes a hopelesssatis, hopeless muddle ) [SEP]"]
[1350/2000] tot_loss=1.523 (perp=7.130, rec=0.096, cos=0.000), tot_loss_proj:1.748 [t=0.26s]
prediction: ["[CLS] (fying denis'story becomes a hopelesssatis, hopeless muddle ) [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.364 (perp=6.353, rec=0.093, cos=0.000), tot_loss_proj:1.565 [t=0.26s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.363 (perp=6.353, rec=0.092, cos=0.000), tot_loss_proj:1.571 [t=0.25s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
[1500/2000] tot_loss=1.356 (perp=6.353, rec=0.085, cos=0.000), tot_loss_proj:1.571 [t=0.27s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.355 (perp=6.353, rec=0.084, cos=0.000), tot_loss_proj:1.570 [t=0.28s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.352 (perp=6.353, rec=0.082, cos=0.000), tot_loss_proj:1.567 [t=0.26s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
[1650/2000] tot_loss=1.360 (perp=6.353, rec=0.090, cos=0.000), tot_loss_proj:1.570 [t=0.27s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.354 (perp=6.353, rec=0.083, cos=0.000), tot_loss_proj:1.563 [t=0.27s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.355 (perp=6.353, rec=0.084, cos=0.000), tot_loss_proj:1.565 [t=0.28s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
[1800/2000] tot_loss=1.357 (perp=6.353, rec=0.086, cos=0.000), tot_loss_proj:1.562 [t=0.27s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.354 (perp=6.353, rec=0.083, cos=0.000), tot_loss_proj:1.569 [t=0.26s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.355 (perp=6.353, rec=0.085, cos=0.000), tot_loss_proj:1.571 [t=0.26s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
[1950/2000] tot_loss=1.345 (perp=6.353, rec=0.075, cos=0.000), tot_loss_proj:1.571 [t=0.28s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.354 (perp=6.353, rec=0.083, cos=0.000), tot_loss_proj:1.567 [t=0.26s]
prediction: ["[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( denis'story becomes a hopelesssatisfying, hopeless muddle ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 91.369 | p: 90.537 | r: 92.309
rouge2     | fm: 58.752 | p: 58.337 | r: 59.219
rougeL     | fm: 79.284 | p: 78.622 | r: 80.088
rougeLsum  | fm: 79.421 | p: 78.676 | r: 80.198
r1fm+r2fm = 150.122

input #95 time: 0:11:08 | total time: 17:16:13


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
*********************************
*********************************
average of cosine similarity 0.9992862237337299
highest_index [0]
highest [0.9992862237337299]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8912551403045654 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8813416361808777 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8610278367996216 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8237534761428833 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8222957253456116 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.815250813961029 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.789729118347168 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7895161509513855 for ['[CLS] statue projectile pondered typical living save sounding august spent time smashwords wig eragn memoir [SEP]']
[Init] best perm rec loss: 0.7875315546989441 for ['[CLS] smashwords typical time projectile statue sounding pondered era august living memoirgn wig save spent [SEP]']
[Init] best perm rec loss: 0.7868963479995728 for ['[CLS] august era smashwords statue living memoir typicalgn projectile time wig pondered save spent sounding [SEP]']
[Init] best perm rec loss: 0.7849245071411133 for ['[CLS] pondered wiggn statue living smashwords sounding memoir august typical spent save time era projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.032 (perp=13.231, rec=0.386, cos=0.000), tot_loss_proj:3.680 [t=0.28s]
prediction: ['[CLS] influence duran annabelle blossomiating heart medical of hold shield fellowship boy darcy motorcycle spark [SEP]']
[ 100/2000] tot_loss=3.010 (perp=13.567, rec=0.296, cos=0.000), tot_loss_proj:4.343 [t=0.30s]
prediction: ['[CLS] force duran difficult eateriating 11 and people around target honor people salvatore environmental jon [SEP]']
[ 150/2000] tot_loss=2.927 (perp=13.342, rec=0.258, cos=0.000), tot_loss_proj:4.145 [t=0.29s]
prediction: ['[CLS] force duran lesser eater situations men on people cover cover honor people salvatore lesser him [SEP]']
[ 200/2000] tot_loss=2.601 (perp=11.863, rec=0.228, cos=0.000), tot_loss_proj:3.495 [t=0.28s]
prediction: ['[CLS] force duran lesser cases situations men on people into cover honor people salvatore lesser himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.175 (perp=9.871, rec=0.201, cos=0.000), tot_loss_proj:3.068 [t=0.29s]
prediction: ['[CLS] force into lesser cases situations men into what covers cover soldiers people salvatore as himself [SEP]']
[ 300/2000] tot_loss=2.306 (perp=10.705, rec=0.165, cos=0.000), tot_loss_proj:3.431 [t=0.28s]
prediction: ['[CLS] force on lesser sides situations men into what cover cover soldiers people arrested as himself [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.179 (perp=10.122, rec=0.155, cos=0.000), tot_loss_proj:3.402 [t=0.29s]
prediction: ['[CLS] force on lesser sides situations men into would into cover for would people theory himself [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.144 (perp=10.070, rec=0.130, cos=0.000), tot_loss_proj:3.614 [t=0.29s]
prediction: ['[CLS] force on lesser facing men into situations would into cover and run people hypothesis himself [SEP]']
[ 450/2000] tot_loss=2.092 (perp=9.872, rec=0.118, cos=0.000), tot_loss_proj:3.636 [t=0.29s]
prediction: ['[CLS] force on lesser facing men into situations would into cover and run peopletick himself [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.321 (perp=10.972, rec=0.127, cos=0.000), tot_loss_proj:3.775 [t=0.27s]
prediction: ['[CLS] force on lesser facing men into situations would running cover cover and people hypothesis himself [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.021 (perp=9.586, rec=0.104, cos=0.000), tot_loss_proj:3.509 [t=0.27s]
prediction: ['[CLS] force on run into men into situations would lesser into cover and people puppy himself [SEP]']
[ 600/2000] tot_loss=1.901 (perp=8.934, rec=0.115, cos=0.000), tot_loss_proj:3.077 [t=0.28s]
prediction: ['[CLS] force on run into men into situations would lesser into cover and people should himself [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.891 (perp=8.934, rec=0.104, cos=0.000), tot_loss_proj:3.082 [t=0.29s]
prediction: ['[CLS] force on run into men into situations would lesser into cover and people should himself [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.766 (perp=8.290, rec=0.108, cos=0.000), tot_loss_proj:3.085 [t=0.28s]
prediction: ['[CLS] force on himself into men into situations would lesser into cover and people should run [SEP]']
[ 750/2000] tot_loss=1.744 (perp=8.290, rec=0.086, cos=0.000), tot_loss_proj:3.086 [t=0.28s]
prediction: ['[CLS] force on himself into men into situations would lesser into cover and people should run [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.752 (perp=8.290, rec=0.094, cos=0.000), tot_loss_proj:3.082 [t=0.27s]
prediction: ['[CLS] force on himself into men into situations would lesser into cover and people should run [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.722 (perp=8.117, rec=0.099, cos=0.000), tot_loss_proj:2.341 [t=0.26s]
prediction: ['[CLS] force on himself into men into situations would lesser cover and people should run into [SEP]']
[ 900/2000] tot_loss=1.713 (perp=8.117, rec=0.090, cos=0.000), tot_loss_proj:2.337 [t=0.27s]
prediction: ['[CLS] force on himself into men into situations would lesser cover and people should run into [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.734 (perp=8.222, rec=0.089, cos=0.000), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] force on himself into men into lesser situations would cover and people should run make [SEP]']
Attempt swap
[1000/2000] tot_loss=1.727 (perp=8.222, rec=0.082, cos=0.000), tot_loss_proj:2.904 [t=0.28s]
prediction: ['[CLS] force on himself into men into lesser situations would cover and people should run make [SEP]']
[1050/2000] tot_loss=1.716 (perp=8.222, rec=0.071, cos=0.000), tot_loss_proj:2.903 [t=0.28s]
prediction: ['[CLS] force on himself into men into lesser situations would cover and people should run make [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.593 (perp=7.572, rec=0.079, cos=0.000), tot_loss_proj:3.142 [t=0.27s]
prediction: ['[CLS] force on himself from men into lesser situations would cover people and should run make [SEP]']
Attempt swap
[1150/2000] tot_loss=1.597 (perp=7.572, rec=0.082, cos=0.000), tot_loss_proj:3.144 [t=0.26s]
prediction: ['[CLS] force on himself from men into lesser situations would cover people and should run make [SEP]']
[1200/2000] tot_loss=1.656 (perp=7.882, rec=0.080, cos=0.000), tot_loss_proj:3.257 [t=0.27s]
prediction: ['[CLS] force on himself more men into lesser situations would cover people and should run make [SEP]']
Attempt swap
[1250/2000] tot_loss=1.654 (perp=7.882, rec=0.078, cos=0.000), tot_loss_proj:3.252 [t=0.27s]
prediction: ['[CLS] force on himself more men into lesser situations would cover people and should run make [SEP]']
Attempt swap
[1300/2000] tot_loss=1.656 (perp=7.882, rec=0.080, cos=0.000), tot_loss_proj:3.256 [t=0.26s]
prediction: ['[CLS] force on himself more men into lesser situations would cover people and should run make [SEP]']
[1350/2000] tot_loss=1.648 (perp=7.882, rec=0.072, cos=0.000), tot_loss_proj:3.254 [t=0.28s]
prediction: ['[CLS] force on himself more men into lesser situations would cover people and should run make [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=7.882, rec=0.076, cos=0.000), tot_loss_proj:3.257 [t=0.28s]
prediction: ['[CLS] force on himself more men into lesser situations would cover people and should run make [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.615 (perp=7.686, rec=0.078, cos=0.000), tot_loss_proj:3.242 [t=0.27s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
[1500/2000] tot_loss=1.612 (perp=7.686, rec=0.075, cos=0.000), tot_loss_proj:3.240 [t=0.27s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[1550/2000] tot_loss=1.620 (perp=7.686, rec=0.083, cos=0.000), tot_loss_proj:3.241 [t=0.27s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[1600/2000] tot_loss=1.623 (perp=7.686, rec=0.086, cos=0.000), tot_loss_proj:3.236 [t=0.28s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
[1650/2000] tot_loss=1.616 (perp=7.686, rec=0.079, cos=0.000), tot_loss_proj:3.235 [t=0.27s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[1700/2000] tot_loss=1.622 (perp=7.686, rec=0.085, cos=0.000), tot_loss_proj:3.238 [t=0.28s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[1750/2000] tot_loss=1.624 (perp=7.686, rec=0.087, cos=0.000), tot_loss_proj:3.246 [t=0.26s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
[1800/2000] tot_loss=1.609 (perp=7.686, rec=0.072, cos=0.000), tot_loss_proj:3.240 [t=0.28s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[1850/2000] tot_loss=1.617 (perp=7.686, rec=0.080, cos=0.000), tot_loss_proj:3.238 [t=0.28s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[1900/2000] tot_loss=1.608 (perp=7.686, rec=0.071, cos=0.000), tot_loss_proj:3.242 [t=0.28s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
[1950/2000] tot_loss=1.614 (perp=7.686, rec=0.077, cos=0.000), tot_loss_proj:3.242 [t=0.27s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Attempt swap
[2000/2000] tot_loss=1.606 (perp=7.686, rec=0.069, cos=0.000), tot_loss_proj:3.243 [t=0.28s]
prediction: ['[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] force on himself more men into situations would cover lesser people and should run make [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 106.985

[Aggregate metrics]:
rouge1     | fm: 91.367 | p: 90.548 | r: 92.279
rouge2     | fm: 58.440 | p: 58.038 | r: 58.876
rougeL     | fm: 79.087 | p: 78.366 | r: 79.879
rougeLsum  | fm: 79.033 | p: 78.374 | r: 79.831
r1fm+r2fm = 149.806

input #96 time: 0:11:22 | total time: 17:27:36


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
*********************************
*********************************
average of cosine similarity 0.9991651916388617
highest_index [0]
highest [0.9991651916388617]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8444599509239197 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8136389851570129 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8033990263938904 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7781254649162292 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.750680148601532 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7503975629806519 for ['[CLS] 140 perfect channel cam workinget [SEP]']
[Init] best perm rec loss: 0.749377965927124 for ['[CLS] working channel 140 perfectet cam [SEP]']
[Init] best perm rec loss: 0.7456121444702148 for ['[CLS] cam 140 working perfectet channel [SEP]']
[Init] best perm rec loss: 0.7446637749671936 for ['[CLS] working perfect channel cam 140et [SEP]']
[Init] best perm rec loss: 0.7421590089797974 for ['[CLS] cam perfect workinget 140 channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.580 (perp=10.558, rec=0.469, cos=0.000), tot_loss_proj:2.873 [t=0.25s]
prediction: ['[CLS] for uniqueworldchment styles great [SEP]']
[ 100/2000] tot_loss=3.069 (perp=13.953, rec=0.278, cos=0.000), tot_loss_proj:4.102 [t=0.27s]
prediction: ['[CLS]for changingget una guests wanted [SEP]']
[ 150/2000] tot_loss=2.531 (perp=11.615, rec=0.208, cos=0.000), tot_loss_proj:4.057 [t=0.26s]
prediction: ['[CLS]fortableget un characters many [SEP]']
[ 200/2000] tot_loss=2.543 (perp=11.904, rec=0.163, cos=0.000), tot_loss_proj:4.126 [t=0.27s]
prediction: ['[CLS]fortableget un characterstable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.134 (perp=9.814, rec=0.171, cos=0.000), tot_loss_proj:3.050 [t=0.28s]
prediction: ['[CLS]for ungettable characterstable [SEP]']
[ 300/2000] tot_loss=2.085 (perp=9.814, rec=0.122, cos=0.000), tot_loss_proj:3.070 [t=0.25s]
prediction: ['[CLS]for ungettable characterstable [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.493 (perp=6.872, rec=0.119, cos=0.000), tot_loss_proj:1.660 [t=0.27s]
prediction: ['[CLS] unforgettable characterstable [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.419 (perp=6.502, rec=0.118, cos=0.000), tot_loss_proj:1.600 [t=0.27s]
prediction: ['[CLS]table characters unforgettable [SEP]']
[ 450/2000] tot_loss=1.415 (perp=6.502, rec=0.115, cos=0.000), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.413 (perp=6.502, rec=0.113, cos=0.000), tot_loss_proj:1.611 [t=0.25s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.399 (perp=6.502, rec=0.099, cos=0.000), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS]table characters unforgettable [SEP]']
[ 600/2000] tot_loss=1.400 (perp=6.502, rec=0.100, cos=0.000), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.408 (perp=6.502, rec=0.108, cos=0.000), tot_loss_proj:1.605 [t=0.25s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.394 (perp=6.502, rec=0.094, cos=0.000), tot_loss_proj:1.613 [t=0.27s]
prediction: ['[CLS]table characters unforgettable [SEP]']
[ 750/2000] tot_loss=1.401 (perp=6.502, rec=0.101, cos=0.000), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.392 (perp=6.502, rec=0.091, cos=0.000), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.401 (perp=6.502, rec=0.100, cos=0.000), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS]table characters unforgettable [SEP]']
[ 900/2000] tot_loss=1.395 (perp=6.502, rec=0.095, cos=0.000), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.401 (perp=6.502, rec=0.101, cos=0.000), tot_loss_proj:1.618 [t=0.27s]
prediction: ['[CLS]table characters unforgettable [SEP]']
Attempt swap
[1000/2000] tot_loss=1.194 (perp=5.572, rec=0.080, cos=0.000), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1050/2000] tot_loss=1.183 (perp=5.572, rec=0.069, cos=0.000), tot_loss_proj:1.294 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1100/2000] tot_loss=1.185 (perp=5.572, rec=0.071, cos=0.000), tot_loss_proj:1.307 [t=0.27s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1150/2000] tot_loss=1.184 (perp=5.572, rec=0.070, cos=0.000), tot_loss_proj:1.313 [t=0.25s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1200/2000] tot_loss=1.182 (perp=5.572, rec=0.068, cos=0.000), tot_loss_proj:1.308 [t=0.27s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.189 (perp=5.572, rec=0.074, cos=0.000), tot_loss_proj:1.313 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1300/2000] tot_loss=1.185 (perp=5.572, rec=0.070, cos=0.000), tot_loss_proj:1.312 [t=0.25s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1350/2000] tot_loss=1.183 (perp=5.572, rec=0.068, cos=0.000), tot_loss_proj:1.297 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.172 (perp=5.572, rec=0.058, cos=0.000), tot_loss_proj:1.299 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1450/2000] tot_loss=1.192 (perp=5.572, rec=0.077, cos=0.000), tot_loss_proj:1.309 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1500/2000] tot_loss=1.172 (perp=5.572, rec=0.058, cos=0.000), tot_loss_proj:1.300 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.185 (perp=5.572, rec=0.070, cos=0.000), tot_loss_proj:1.309 [t=0.27s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.178 (perp=5.572, rec=0.063, cos=0.000), tot_loss_proj:1.297 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1650/2000] tot_loss=1.178 (perp=5.572, rec=0.063, cos=0.000), tot_loss_proj:1.304 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.184 (perp=5.572, rec=0.070, cos=0.000), tot_loss_proj:1.299 [t=0.25s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.173 (perp=5.572, rec=0.059, cos=0.000), tot_loss_proj:1.298 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1800/2000] tot_loss=1.176 (perp=5.572, rec=0.062, cos=0.000), tot_loss_proj:1.307 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.177 (perp=5.572, rec=0.062, cos=0.000), tot_loss_proj:1.294 [t=0.26s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.185 (perp=5.572, rec=0.071, cos=0.000), tot_loss_proj:1.306 [t=0.27s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1950/2000] tot_loss=1.183 (perp=5.572, rec=0.069, cos=0.000), tot_loss_proj:1.301 [t=0.25s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.176 (perp=5.572, rec=0.061, cos=0.000), tot_loss_proj:1.304 [t=0.27s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and characters unforgettable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.398 | p: 90.616 | r: 92.351
rouge2     | fm: 57.926 | p: 57.565 | r: 58.411
rougeL     | fm: 78.997 | p: 78.346 | r: 79.789
rougeLsum  | fm: 79.111 | p: 78.430 | r: 79.959
r1fm+r2fm = 149.324

input #97 time: 0:11:02 | total time: 17:38:38


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
*********************************
*********************************
average of cosine similarity 0.9991918491197371
highest_index [0]
highest [0.9991918491197371]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7161436080932617 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7107669115066528 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.7046809792518616 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.829 (perp=12.452, rec=0.338, cos=0.000), tot_loss_proj:3.351 [t=0.33s]
prediction: ['[CLS] emptyfulful investigation [SEP]']
[ 100/2000] tot_loss=2.769 (perp=12.927, rec=0.184, cos=0.000), tot_loss_proj:3.350 [t=0.26s]
prediction: ['[CLS] unfulful purchase [SEP]']
[ 150/2000] tot_loss=2.406 (perp=11.413, rec=0.123, cos=0.000), tot_loss_proj:3.129 [t=0.26s]
prediction: ['[CLS] unllingful purchase [SEP]']
[ 200/2000] tot_loss=2.150 (perp=10.207, rec=0.109, cos=0.000), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] unllingfulfi [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.104 (perp=4.947, rec=0.115, cos=0.000), tot_loss_proj:1.060 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.083 (perp=4.947, rec=0.094, cos=0.000), tot_loss_proj:1.051 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.063 (perp=4.947, rec=0.074, cos=0.000), tot_loss_proj:1.054 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.066 (perp=4.947, rec=0.077, cos=0.000), tot_loss_proj:1.061 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.066 (perp=4.947, rec=0.076, cos=0.000), tot_loss_proj:1.060 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.056 (perp=4.947, rec=0.066, cos=0.000), tot_loss_proj:1.061 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.056 (perp=4.947, rec=0.067, cos=0.000), tot_loss_proj:1.055 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.042 (perp=4.947, rec=0.052, cos=0.000), tot_loss_proj:1.049 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.047 (perp=4.947, rec=0.057, cos=0.000), tot_loss_proj:1.060 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.053 (perp=4.947, rec=0.064, cos=0.000), tot_loss_proj:1.053 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.054 (perp=4.947, rec=0.065, cos=0.000), tot_loss_proj:1.055 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.044 (perp=4.947, rec=0.054, cos=0.000), tot_loss_proj:1.060 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.048 (perp=4.947, rec=0.059, cos=0.000), tot_loss_proj:1.052 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.051 (perp=4.947, rec=0.061, cos=0.000), tot_loss_proj:1.045 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.056 (perp=4.947, rec=0.066, cos=0.000), tot_loss_proj:1.059 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.044 (perp=4.947, rec=0.054, cos=0.000), tot_loss_proj:1.050 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.039 (perp=4.947, rec=0.049, cos=0.000), tot_loss_proj:1.060 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.050 (perp=4.947, rec=0.061, cos=0.000), tot_loss_proj:1.051 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.052 (perp=4.947, rec=0.062, cos=0.000), tot_loss_proj:1.050 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.043 (perp=4.947, rec=0.054, cos=0.000), tot_loss_proj:1.057 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.060 (perp=4.947, rec=0.070, cos=0.000), tot_loss_proj:1.052 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.059 (perp=4.947, rec=0.070, cos=0.000), tot_loss_proj:1.055 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.039 (perp=4.947, rec=0.050, cos=0.000), tot_loss_proj:1.065 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.054 (perp=4.947, rec=0.065, cos=0.000), tot_loss_proj:1.059 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.065 (perp=4.947, rec=0.076, cos=0.000), tot_loss_proj:1.060 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.050 (perp=4.947, rec=0.061, cos=0.000), tot_loss_proj:1.050 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.042 (perp=4.947, rec=0.052, cos=0.000), tot_loss_proj:1.058 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.051 (perp=4.947, rec=0.061, cos=0.000), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.054 (perp=4.947, rec=0.064, cos=0.000), tot_loss_proj:1.056 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.048 (perp=4.947, rec=0.059, cos=0.000), tot_loss_proj:1.056 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.045 (perp=4.947, rec=0.056, cos=0.000), tot_loss_proj:1.067 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.056 (perp=4.947, rec=0.066, cos=0.000), tot_loss_proj:1.060 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.045 (perp=4.947, rec=0.056, cos=0.000), tot_loss_proj:1.046 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.048 (perp=4.947, rec=0.058, cos=0.000), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.038 (perp=4.947, rec=0.049, cos=0.000), tot_loss_proj:1.061 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.051 (perp=4.947, rec=0.061, cos=0.000), tot_loss_proj:1.055 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.532 | p: 90.715 | r: 92.433
rouge2     | fm: 58.450 | p: 57.999 | r: 58.929
rougeL     | fm: 79.353 | p: 78.679 | r: 80.132
rougeLsum  | fm: 79.338 | p: 78.654 | r: 80.085
r1fm+r2fm = 149.982

input #98 time: 0:11:08 | total time: 17:49:46


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
*********************************
*********************************
average of cosine similarity 0.9993101738601006
highest_index [0]
highest [0.9993101738601006]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.874215304851532 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8671271800994873 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8651171922683716 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.8613685369491577 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8581872582435608 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8465638756752014 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8375059366226196 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8289321660995483 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.8264452219009399 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8218111395835876 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.8212589621543884 for ['[CLS] synonymˈ bearing screens forced barbie tasteaging actually right ferns claire distance thunder dental orient earliest ratingsts te [MASK] services cushion currently temps rete garcia harper bet opposed knowledge himself slight still when [SEP]']
[Init] best perm rec loss: 0.8211127519607544 for ['[CLS] services when himself barbie bet right bearingts cushion still taste knowledge screens re forcedˈ [MASK] thunder te opposed earliest claireaging currently ratings harper ferns garcia dentalte distance slight synonym orient actually temps [SEP]']
[Init] best perm rec loss: 0.8207758665084839 for ['[CLS] taste orientˈ harperaging ratings knowledge dental ferns thunder clairete garcia temps actually earliest currently bet forced screens services slight barbie synonym right te bearing re still when distance himself cushionts opposed [MASK] [SEP]']
[Init] best perm rec loss: 0.8179582953453064 for ['[CLS] te distance when earliest still ratings barbie [MASK] garcia synonym cushionts bearing tasteaging services orient slight claire ferns harper screens actually right temps bet thunderˈ himself knowledge re forced opposedte currently dental [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.595 (perp=11.156, rec=0.364, cos=0.000), tot_loss_proj:2.901 [t=0.27s]
prediction: ["[CLS] refused cause association better? dump pig - bullshit di stupid any doping military advance waste museum any anyed stupid - outbreak drivers under'bombersville freakeaux - fangs panicus everyone chemical [SEP]"]
[ 100/2000] tot_loss=2.468 (perp=10.920, rec=0.284, cos=0.000), tot_loss_proj:2.784 [t=0.26s]
prediction: ["[CLS] walked out fa better we quite pig - bullshit di stupid any doping its film shit commissioners or anyssing sick but affairs drivers under'bomb cathedral alarm ` -ssing crazy terms di zombies [SEP]"]
[ 150/2000] tot_loss=2.588 (perp=11.775, rec=0.233, cos=0.000), tot_loss_proj:2.917 [t=0.27s]
prediction: ["[CLS] walked out fa better muttering quite bad was films di stupid the fun ` film porn commissioners'anyssing di but affairs walked under van bomb 'peration ` janatassing fun terms di creole [SEP]"]
[ 200/2000] tot_loss=2.224 (perp=10.125, rec=0.199, cos=0.000), tot_loss_proj:2.692 [t=0.27s]
prediction: ["[CLS] walked out ` better ` quite bad had'dissing the fun ` film shit ticket'umssing di but your walked under van `'fun'sossing fun s di numerous [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.128 (perp=9.814, rec=0.165, cos=0.000), tot_loss_proj:2.697 [t=0.27s]
prediction: ['[CLS] walked out ` ` better ` quite bad had\'dissing the fun film " ticket\'contractssing di but your walked under van `\'fun\'sossing fun that di several [SEP]']
[ 300/2000] tot_loss=2.204 (perp=10.286, rec=0.147, cos=0.000), tot_loss_proj:2.823 [t=0.26s]
prediction: ['[CLS] walked out ` `\'muttering quite horrible had ticket di mind the fun film " ticket ` contractssing di but your walked under van `\'fun\'sossing fun that di several [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.212 (perp=10.373, rec=0.138, cos=0.000), tot_loss_proj:2.800 [t=0.26s]
prediction: ['[CLS] walked out ` `\'your quite horrible had ticket di mind the fun film " ticket ` contractssing di but muttering walked under the ` terrible fun\'sossing fun that di several [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.113 (perp=9.953, rec=0.122, cos=0.000), tot_loss_proj:2.629 [t=0.26s]
prediction: ['[CLS] walked out ` `\'your teeth horrible had ticket di mind the fun film " ticket ` dissing di but muttering walked under the ` terrible fun\'sossing fun that ticket words [SEP]']
[ 450/2000] tot_loss=2.079 (perp=9.810, rec=0.117, cos=0.000), tot_loss_proj:2.735 [t=0.27s]
prediction: ['[CLS] walked out ` ` ` your teeth horrible had ticket di mind the fun film " ticket ` dissing di but muttering « under the ` terrible fun\'sossing fun that cost words [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.043 (perp=9.618, rec=0.120, cos=0.000), tot_loss_proj:2.587 [t=0.27s]
prediction: ['[CLS] walked out ` ` ` cost like horrible had ticket di mind the fun film " ticket ` ` dissing di but muttering « under the terrible fun\'sossing fun that cost words [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.964 (perp=9.286, rec=0.107, cos=0.000), tot_loss_proj:2.465 [t=0.25s]
prediction: ["[CLS] walked out ` ` ` cost like horrible had ticket t mind the fun film'ticket ` ` dissing di but muttering « the terrible the fun'sossing fun that cost words [SEP]"]
[ 600/2000] tot_loss=1.964 (perp=9.286, rec=0.107, cos=0.000), tot_loss_proj:2.469 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` cost like horrible had ticket t mind the fun film'ticket ` ` dissing di but muttering « the terrible the fun'sossing fun that cost words [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.928 (perp=9.126, rec=0.102, cos=0.000), tot_loss_proj:2.414 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` com like horrible had ticket t mind the fun film'ticket ` ` dissing di but muttering cost the terrible the fun'sossing fun that cost words [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.878 (perp=8.854, rec=0.107, cos=0.000), tot_loss_proj:2.441 [t=0.28s]
prediction: ["[CLS] walked out ` ` ` walked like fun had ticket t mind the horrible film'ticket ` ` dissing di but muttering cost the terrible the fun'sossing fun that cost words [SEP]"]
[ 750/2000] tot_loss=1.861 (perp=8.824, rec=0.097, cos=0.000), tot_loss_proj:2.476 [t=0.27s]
prediction: ["[CLS] walked out ` ` ` walked like fun had ticket t mind the terrible film'ticket ` ` dissing di but muttering cost the terrible the fun'sossing fun that cost words [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.828 (perp=8.654, rec=0.097, cos=0.000), tot_loss_proj:2.430 [t=0.25s]
prediction: ["[CLS] walked out ` ` ` walked like fun had ticket t mind the terrible film'ticket ` ` dissing di but muttering cost the terrible the fun'sossing words that cost fun [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.733 (perp=8.187, rec=0.096, cos=0.000), tot_loss_proj:2.363 [t=0.25s]
prediction: ["[CLS] walked out ` ` `'like fun had ticket t mind the terrible film'ticket ` ` dissing but di muttering cost the terrible the fun'sossing words that cost fun [SEP]"]
[ 900/2000] tot_loss=1.737 (perp=8.208, rec=0.095, cos=0.000), tot_loss_proj:2.346 [t=0.26s]
prediction: ["[CLS] walked out ` ` `'like fun had ticket t mind the terrible film'ticket ` ` dissing but di muttering cost the terrible the fun'sossing the that cost fun [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.715 (perp=8.120, rec=0.091, cos=0.000), tot_loss_proj:2.213 [t=0.24s]
prediction: ["[CLS] walked out ` ` `'like fun had ticket t mind the terrible film'they ` ` dissing but di muttering cost thessing the fun, so terrible the that cost fun [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.682 (perp=7.906, rec=0.101, cos=0.000), tot_loss_proj:2.098 [t=0.27s]
prediction: ["[CLS] walked out ` ` `'like fun had't mind the terrible film ticket they ` ` dissing but di muttering cost thessing the fun, so terrible the that cost the [SEP]"]
[1050/2000] tot_loss=1.720 (perp=8.134, rec=0.093, cos=0.000), tot_loss_proj:2.181 [t=0.27s]
prediction: ["[CLS] walked out ` ` `'like fun had't mind the terrible film ticket they ` ` dissing but di muttering cost thessing the does, so terrible the that cost the [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.685 (perp=7.960, rec=0.093, cos=0.000), tot_loss_proj:2.108 [t=0.26s]
prediction: ["[CLS] walked out ` ` `'like fun had't mind the terrible film ticket, ` ` dissing but di muttering cost thessing the does they so terrible the that cost the [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.649 (perp=7.769, rec=0.095, cos=0.000), tot_loss_proj:2.076 [t=0.28s]
prediction: ["[CLS] walked out ` ` `'like fun does't mind the terrible film ticket, ` ` dissing but di muttering cost thessing the had they so terrible the that cost the [SEP]"]
[1200/2000] tot_loss=1.642 (perp=7.769, rec=0.089, cos=0.000), tot_loss_proj:2.078 [t=0.27s]
prediction: ["[CLS] walked out ` ` `'like fun does't mind the terrible film ticket, ` ` dissing but di muttering cost thessing the had they so terrible the that cost the [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.658 (perp=7.822, rec=0.094, cos=0.000), tot_loss_proj:2.090 [t=0.27s]
prediction: ["[CLS] walked out ` ` `'like fun does't mind the terrible film ticket, ` ` dissing but di muttering the cost thessing the had they so terrible that cost fun [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.603 (perp=7.565, rec=0.090, cos=0.000), tot_loss_proj:2.026 [t=0.25s]
prediction: ["[CLS] walked out ` ` `'like funn't mind the terrible film ticket, ` ` dissing but di muttering the cost thessing the they had so terrible that cost the [SEP]"]
[1350/2000] tot_loss=1.601 (perp=7.565, rec=0.088, cos=0.000), tot_loss_proj:2.027 [t=0.26s]
prediction: ["[CLS] walked out ` ` `'like funn't mind the terrible film ticket, ` ` dissing but di muttering the cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.548 (perp=7.291, rec=0.090, cos=0.000), tot_loss_proj:1.964 [t=0.26s]
prediction: ["[CLS] walked out ` ` `'like funn't mind the terrible film ticket, ` ` dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.548 (perp=7.291, rec=0.090, cos=0.000), tot_loss_proj:1.957 [t=0.26s]
prediction: ["[CLS] walked out ` ` `'like funn't mind the terrible film ticket, ` ` dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
[1500/2000] tot_loss=1.640 (perp=7.764, rec=0.087, cos=0.000), tot_loss_proj:2.116 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` n like funn't mind the terrible film ticket, ` ` dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.585 (perp=7.498, rec=0.085, cos=0.000), tot_loss_proj:2.006 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` ` like funn't mind the terrible film ticket,'` dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.586 (perp=7.470, rec=0.092, cos=0.000), tot_loss_proj:2.009 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` ` like funn't mind the terrible film ticket, n ` dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
[1650/2000] tot_loss=1.584 (perp=7.470, rec=0.090, cos=0.000), tot_loss_proj:2.013 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` ` like funn't mind the terrible film ticket, n ` dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.560 (perp=7.307, rec=0.098, cos=0.000), tot_loss_proj:2.022 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` ` like fun `n't mind the terrible film ticket, n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.519 (perp=7.151, rec=0.088, cos=0.000), tot_loss_proj:1.924 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` ` ` fun liken't mind the terrible film ticket, n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
[1800/2000] tot_loss=1.523 (perp=7.151, rec=0.093, cos=0.000), tot_loss_proj:1.927 [t=0.27s]
prediction: ["[CLS] walked out ` ` ` ` ` fun liken't mind the terrible film ticket, n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.521 (perp=7.151, rec=0.091, cos=0.000), tot_loss_proj:1.926 [t=0.26s]
prediction: ["[CLS] walked out ` ` ` ` ` fun liken't mind the terrible film ticket, n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.509 (perp=7.098, rec=0.089, cos=0.000), tot_loss_proj:1.951 [t=0.25s]
prediction: ["[CLS] walked out ` ` ` ` ` fun liken't mind, the terrible film ticket n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
[1950/2000] tot_loss=1.510 (perp=7.098, rec=0.090, cos=0.000), tot_loss_proj:1.949 [t=0.25s]
prediction: ["[CLS] walked out ` ` ` ` ` fun liken't mind, the terrible film ticket n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.483 (perp=6.951, rec=0.093, cos=0.000), tot_loss_proj:1.910 [t=0.26s]
prediction: ["[CLS] walked out n ` ` ` ` ` fun liken't mind, the terrible film ticket dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out ` ` ` ` ` fun liken't mind the terrible film ticket, n dissing the di muttering but cost thessing the they had so terrible that cost the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 71.429 | r: 76.923
rouge2     | fm: 23.077 | p: 22.222 | r: 24.000
rougeL     | fm: 37.037 | p: 35.714 | r: 38.462
rougeLsum  | fm: 37.037 | p: 35.714 | r: 38.462
r1fm+r2fm = 97.151

[Aggregate metrics]:
rouge1     | fm: 91.297 | p: 90.482 | r: 92.249
rouge2     | fm: 58.195 | p: 57.781 | r: 58.651
rougeL     | fm: 78.743 | p: 78.059 | r: 79.571
rougeLsum  | fm: 78.878 | p: 78.227 | r: 79.704
r1fm+r2fm = 149.492

input #99 time: 0:11:07 | total time: 18:00:54


Average Cosine Similarity: 0.9992812602979866
Done with all.
