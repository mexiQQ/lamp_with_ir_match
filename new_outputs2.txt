


Command: attack3.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 500 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
*********************************
*********************************
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.9897326231002808 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 1.6931339502334595 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 1.5862441062927246 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 1.5641170740127563 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 1.3241164684295654 for ['[CLS] panel officer [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.590 (perp=11.621, rec=0.255, cos=0.011), tot_loss_proj:2.656 [t=0.27s]
prediction: ['[CLS] severe disappointed [SEP]']
Attempt swap
[ 100/ 500] tot_loss=2.228 (perp=10.251, rec=0.174, cos=0.004), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/ 500] tot_loss=2.152 (perp=10.251, rec=0.101, cos=0.001), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.128 (perp=10.251, rec=0.077, cos=0.001), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/ 500] tot_loss=2.120 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/ 500] tot_loss=2.121 (perp=10.251, rec=0.071, cos=0.001), tot_loss_proj:2.109 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/ 500] tot_loss=2.120 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/ 500] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/ 500] tot_loss=2.114 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.128 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/ 500] tot_loss=2.100 (perp=10.251, rec=0.049, cos=0.001), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:03:28 | total time: 0:03:28


Running input #1 of 100.
reference: 
========================
splendidly 
========================
*********************************
*********************************
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.8751615285873413 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 1.8574330806732178 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 1.8238334655761719 for ['[CLS] football package [SEP]']
[Init] best rec loss: 1.7409363985061646 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 1.6608680486679077 for ['[CLS] conducted predator [SEP]']
[Init] best rec loss: 1.6287647485733032 for ['[CLS] j native [SEP]']
[Init] best rec loss: 1.5730043649673462 for ['[CLS] dated glazed [SEP]']
[Init] best rec loss: 1.5161365270614624 for ['[CLS] there correspondent [SEP]']
[Init] best rec loss: 1.271039366722107 for ['[CLS] finally relative [SEP]']
[Init] best rec loss: 1.120924472808838 for ['[CLS] course characters [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.319 (perp=10.543, rec=0.208, cos=0.002), tot_loss_proj:2.459 [t=0.24s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
Swapped tokens
[ 100/ 500] tot_loss=1.931 (perp=9.171, rec=0.095, cos=0.001), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 150/ 500] tot_loss=1.906 (perp=9.171, rec=0.070, cos=0.001), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.894 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.885 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/ 500] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.899 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.913 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.897 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/ 500] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.894 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.906 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:03:24 | total time: 0:06:53


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
*********************************
*********************************
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 1.3203822374343872 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 1.2476643323898315 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 1.2300113439559937 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 1.2278040647506714 for ['[CLS] would we working [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.585 (perp=10.605, rec=0.443, cos=0.021), tot_loss_proj:2.863 [t=0.24s]
prediction: ['[CLS] very momentum growth [SEP]']
Attempt swap
Put prefix at the end
[ 100/ 500] tot_loss=1.907 (perp=8.515, rec=0.200, cos=0.004), tot_loss_proj:1.800 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/ 500] tot_loss=1.802 (perp=8.515, rec=0.098, cos=0.001), tot_loss_proj:1.782 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.794 (perp=8.515, rec=0.090, cos=0.001), tot_loss_proj:1.794 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.782 (perp=8.515, rec=0.079, cos=0.001), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/ 500] tot_loss=1.776 (perp=8.515, rec=0.073, cos=0.001), tot_loss_proj:1.795 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/ 500] tot_loss=1.777 (perp=8.515, rec=0.074, cos=0.001), tot_loss_proj:1.787 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.795 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:03:23 | total time: 0:10:16


Running input #3 of 100.
reference: 
========================
flawless film 
========================
*********************************
*********************************
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.7515515089035034 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 1.515498399734497 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 1.510279893875122 for ['[CLS] committee deportivo [SEP]']
[Init] best rec loss: 1.5031687021255493 for ['[CLS] carry including [SEP]']
[Init] best rec loss: 1.4859191179275513 for ['[CLS] has block [SEP]']
[Init] best rec loss: 1.312357783317566 for ['[CLS] anton laughed [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.664 (perp=11.851, rec=0.286, cos=0.008), tot_loss_proj:2.812 [t=0.28s]
prediction: ['[CLS] flawless successful [SEP]']
Attempt swap
Moved token
[ 100/ 500] tot_loss=2.293 (perp=10.476, rec=0.195, cos=0.003), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 150/ 500] tot_loss=1.768 (perp=8.385, rec=0.090, cos=0.001), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.759 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/ 500] tot_loss=1.745 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.762 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/ 500] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.757 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:03:24 | total time: 0:13:41


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
*********************************
*********************************
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.8612022399902344 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 1.8395576477050781 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 1.7808197736740112 for ['[CLS] watch joint weekly [SEP]']
[Init] best rec loss: 1.7083849906921387 for ['[CLS] religious tip seat [SEP]']
[Init] best rec loss: 1.4955319166183472 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 1.2935547828674316 for ['[CLS] fatedss jack [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.807 (perp=12.580, rec=0.283, cos=0.008), tot_loss_proj:3.146 [t=0.25s]
prediction: ['[CLS] tires uglyistle [SEP]']
Attempt swap
Put prefix at the end
[ 100/ 500] tot_loss=1.838 (perp=8.428, rec=0.150, cos=0.003), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS]ly tiresome [SEP]']
[ 150/ 500] tot_loss=1.782 (perp=8.428, rec=0.096, cos=0.001), tot_loss_proj:1.886 [t=0.25s]
prediction: ['[CLS]ly tiresome [SEP]']
Attempt swap
Moved token
[ 200/ 500] tot_loss=1.586 (perp=7.516, rec=0.082, cos=0.001), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.001), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/ 500] tot_loss=1.565 (perp=7.516, rec=0.061, cos=0.001), tot_loss_proj:1.561 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.574 (perp=7.516, rec=0.070, cos=0.001), tot_loss_proj:1.572 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.569 (perp=7.516, rec=0.065, cos=0.001), tot_loss_proj:1.577 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/ 500] tot_loss=1.561 (perp=7.516, rec=0.057, cos=0.001), tot_loss_proj:1.574 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.565 (perp=7.516, rec=0.061, cos=0.001), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:03:24 | total time: 0:17:05


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
*********************************
*********************************
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 1.7795944213867188 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 1.6453757286071777 for ['[CLS] works flow [SEP]']
[Init] best rec loss: 1.6053582429885864 for ['[CLS] sol liked [SEP]']
[Init] best rec loss: 1.5769269466400146 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 1.4209589958190918 for ['[CLS] eye central [SEP]']
[Init] best perm rec loss: 1.41153085231781 for ['[CLS] central eye [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=3.349 (perp=15.495, rec=0.244, cos=0.006), tot_loss_proj:4.873 [t=0.25s]
prediction: ['[CLS] cy ease [SEP]']
Attempt swap
Put prefix at the end
[ 100/ 500] tot_loss=2.053 (perp=9.390, rec=0.172, cos=0.003), tot_loss_proj:3.411 [t=0.26s]
prediction: ['[CLS] ease industries [SEP]']
[ 150/ 500] tot_loss=2.174 (perp=10.180, rec=0.135, cos=0.003), tot_loss_proj:3.370 [t=0.25s]
prediction: ['[CLS] ease remix [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.171 (perp=10.180, rec=0.132, cos=0.003), tot_loss_proj:3.375 [t=0.26s]
prediction: ['[CLS] ease remix [SEP]']
Attempt swap
[ 250/ 500] tot_loss=2.167 (perp=10.180, rec=0.128, cos=0.002), tot_loss_proj:3.377 [t=0.26s]
prediction: ['[CLS] ease remix [SEP]']
[ 300/ 500] tot_loss=2.276 (perp=10.724, rec=0.129, cos=0.002), tot_loss_proj:3.398 [t=0.26s]
prediction: ['[CLS] ease tales [SEP]']
Attempt swap
[ 350/ 500] tot_loss=2.268 (perp=10.724, rec=0.121, cos=0.002), tot_loss_proj:3.398 [t=0.25s]
prediction: ['[CLS] ease tales [SEP]']
Attempt swap
[ 400/ 500] tot_loss=2.480 (perp=11.854, rec=0.107, cos=0.002), tot_loss_proj:2.565 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/ 500] tot_loss=2.500 (perp=11.854, rec=0.127, cos=0.002), tot_loss_proj:2.570 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/ 500] tot_loss=2.485 (perp=11.854, rec=0.112, cos=0.002), tot_loss_proj:2.570 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:03:25 | total time: 0:20:30


Running input #6 of 100.
reference: 
========================
grayish 
========================
*********************************
*********************************
average of cosine similarity 0.9992504694447222
highest_index [0]
highest [0.9992504694447222]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 1.902685284614563 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 1.7486958503723145 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 1.7067688703536987 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 1.5019043684005737 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 1.2771662473678589 for ['[CLS] air little [SEP]']
[Init] best rec loss: 1.2549055814743042 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 1.249065637588501 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 1.124966025352478 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 1.1203830242156982 for ['[CLS] too u2 [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.093 (perp=8.874, rec=0.306, cos=0.012), tot_loss_proj:2.841 [t=0.26s]
prediction: ['[CLS] evil gray [SEP]']
Attempt swap
[ 100/ 500] tot_loss=1.578 (perp=6.813, rec=0.212, cos=0.004), tot_loss_proj:2.720 [t=0.25s]
prediction: ['[CLS] gray gray [SEP]']
[ 150/ 500] tot_loss=1.557 (perp=6.813, rec=0.191, cos=0.003), tot_loss_proj:2.716 [t=0.25s]
prediction: ['[CLS] gray gray [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.218 (perp=10.460, rec=0.124, cos=0.002), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/ 500] tot_loss=1.726 (perp=8.089, rec=0.107, cos=0.001), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 300/ 500] tot_loss=1.702 (perp=8.089, rec=0.084, cos=0.001), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.677 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.001), tot_loss_proj:1.683 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
[ 450/ 500] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.698 (perp=8.089, rec=0.079, cos=0.001), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:03:23 | total time: 0:23:54


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
*********************************
*********************************
average of cosine similarity 0.9991768686555791
highest_index [0]
highest [0.9991768686555791]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 1.8152823448181152 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 1.3960720300674438 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 1.3859511613845825 for ['[CLS] vance golf belt handyolved fl researchtium anonymousina me man murphyoof bearing zetavocationtellrti american autopsy that lie amongₑ free [SEP]']
[Init] best rec loss: 1.2355339527130127 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 1.1908916234970093 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 1.1874291896820068 for ['[CLS] cod conference dock moths most com baby open hs median purpose flow exactly part end bothp jennypia # sat infants payר beings grande [SEP]']
[Init] best perm rec loss: 1.1840190887451172 for ['[CLS] cod pay part mothsר most hs baby infants grande both sat dockpia beings exactly purpose flow end conference comp jenny open median # [SEP]']
Nsteps: 500
[  50/2000] tot_loss=2.913 (perp=12.360, rec=0.438, cos=0.003), tot_loss_proj:3.374 [t=0.27s]
prediction: ['[CLS] employee poor problem prison problem no losernoless worst. problems maybe loserlike terrorist excuse fucking walls enforcementpor.no shit shit hiv [SEP]']
[ 100/2000] tot_loss=2.450 (perp=10.443, rec=0.355, cos=0.007), tot_loss_proj:3.090 [t=0.26s]
prediction: ['[CLS] no poor problem prison problem no problemno ugly nothing. ignore maybe ugly seems nor. about types policypor. hood homo or character [SEP]']
[ 150/2000] tot_loss=2.247 (perp=9.757, rec=0.294, cos=0.001), tot_loss_proj:2.968 [t=0.26s]
prediction: ['[CLS] no poor problem military problem no problem ugly ugly nothing. ignore aka ugly seems nor without about or problempor. endangered bug or character [SEP]']
[ 200/2000] tot_loss=2.103 (perp=9.226, rec=0.257, cos=0.000), tot_loss_proj:3.044 [t=0.27s]
prediction: ['[CLS] no poor problem military problem no crisis no ugly nothing. stamps caring ugly seems nor no any character problem ;. nope bug or character [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.375 (perp=10.491, rec=0.270, cos=0.007), tot_loss_proj:3.197 [t=0.27s]
prediction: ['[CLS] no poor problem estate problem noam not ugly nothing. stamps caring seems he nor no was character problem ;. nope offense is character [SEP]']
[ 300/2000] tot_loss=2.201 (perp=9.927, rec=0.216, cos=0.000), tot_loss_proj:3.296 [t=0.25s]
prediction: ['[CLS] no wrong problem modern problem no crisis not ugly nothing. stamps caring mind he character no was character problem ;. nope offense is character [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.280 (perp=10.280, rec=0.224, cos=0.000), tot_loss_proj:3.195 [t=0.26s]
prediction: ['[CLS] has wrong problemckle no no problem not ugly nothing. ; caring characters noy he the character problem disposed ; nope offense is character [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.075 (perp=9.366, rec=0.201, cos=0.001), tot_loss_proj:3.366 [t=0.26s]
prediction: ['[CLS] no wrong problem vampires no has issue not ugly character. ; caring characters nohr or he the character problem ; nope offense is character [SEP]']
[ 450/2000] tot_loss=2.116 (perp=9.639, rec=0.187, cos=0.000), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] has wrong problem vampires no has no not ugly character. ; caring characters nohry he the character problem. nope offense is you [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.065 (perp=9.478, rec=0.169, cos=0.000), tot_loss_proj:3.150 [t=0.25s]
prediction: ['[CLS] has wrong problem vampires no has no not ugly.. ; he characters nohriness caring the character problem.ability offense is you [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.911 (perp=8.699, rec=0.171, cos=0.000), tot_loss_proj:3.230 [t=0.28s]
prediction: ['[CLS] has wrong no problem vampires has no not ugly.. ; he characters nohr anything love the character problem.ability offense is you [SEP]']
[ 600/2000] tot_loss=1.852 (perp=8.448, rec=0.163, cos=0.000), tot_loss_proj:3.532 [t=0.26s]
prediction: ['[CLS] has wrong no problem vampires. no mind ugly.. ; he characters nohr anything love the character problem.ability mind is you [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.903 (perp=8.753, rec=0.152, cos=0.000), tot_loss_proj:3.319 [t=0.26s]
prediction: ['[CLS] has vampires no problem wrong.rt mind ugly you. ; he characters no the or love the character problem.ability mind is you [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.896 (perp=8.735, rec=0.149, cos=0.000), tot_loss_proj:3.292 [t=0.26s]
prediction: ['[CLS] has vampires no problem wrong.rt ugly mind here. ; he characters no the or love the character problem.ability mind is you [SEP]']
[ 750/2000] tot_loss=1.880 (perp=8.654, rec=0.149, cos=0.000), tot_loss_proj:3.261 [t=0.26s]
prediction: ['[CLS] has vampires no problem wrong.rt ugly mind here. ; he characters no the or love the character problem.ability mind is here [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.827 (perp=8.410, rec=0.145, cos=0.000), tot_loss_proj:3.550 [t=0.27s]
prediction: ['[CLS] has vampires no problem wrong. cute ugly mind here. ; he characters noy love or character problem.ability. mind is here [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.771 (perp=8.157, rec=0.139, cos=0.000), tot_loss_proj:3.495 [t=0.26s]
prediction: ['[CLS] has vampires no problem wrong. cute ugly mind here. ; he characters nolike love or character problem.able i is here. [SEP]']
[ 900/2000] tot_loss=1.703 (perp=7.819, rec=0.139, cos=0.000), tot_loss_proj:3.345 [t=0.27s]
prediction: ['[CLS] has vampires no problem wrong. cute ugly mind here. ; he characters no. love or character problem.able mind is here. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.649 (perp=7.573, rec=0.134, cos=0.000), tot_loss_proj:3.122 [t=0.28s]
prediction: ['[CLS] has vampires no problem wrong. cute ugly mind factor. ; he characters no love. or character the.able mind is here. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.618 (perp=7.402, rec=0.138, cos=0.000), tot_loss_proj:3.044 [t=0.27s]
prediction: ['[CLS] has vampires no problem wrong. the ugly mind factor. ; he minded no love. or character cute.able i is here. [SEP]']
[1050/2000] tot_loss=1.659 (perp=7.597, rec=0.139, cos=0.000), tot_loss_proj:3.353 [t=0.27s]
prediction: ['[CLS] has vampires no problem wrong. the ugly mind factor. ; he factor no love. or character cute.able i is here. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.576 (perp=7.273, rec=0.122, cos=0.000), tot_loss_proj:3.238 [t=0.26s]
prediction: ['[CLS] has vampires no problem wrong. the ugly mind factor. ; he factor no love. or cute character.able mind is here. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.518 (perp=6.982, rec=0.121, cos=0.000), tot_loss_proj:2.444 [t=0.26s]
prediction: ['[CLS] has crimes no problem here. the ugly mind factor. ; he factor no love. or cute character.able mind is wrong. [SEP]']
[1200/2000] tot_loss=1.538 (perp=7.071, rec=0.123, cos=0.000), tot_loss_proj:2.801 [t=0.26s]
prediction: ['[CLS] has cute no problem here. the ugly mind factor. ; he factor no love. or cute character.able i is wrong. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.469 (perp=6.717, rec=0.125, cos=0.000), tot_loss_proj:2.896 [t=0.25s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he factor no love. or cute character.able i is wrong. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.516 (perp=6.952, rec=0.125, cos=0.000), tot_loss_proj:2.729 [t=0.26s]
prediction: ['[CLS] crimes has no problem here. the ugly mind factor. ; he no love factor. or cute character.able i is wrong. [SEP]']
[1350/2000] tot_loss=1.511 (perp=6.952, rec=0.121, cos=0.000), tot_loss_proj:2.725 [t=0.26s]
prediction: ['[CLS] crimes has no problem here. the ugly mind factor. ; he no love factor. or cute character.able i is wrong. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.424 (perp=6.557, rec=0.112, cos=0.000), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no love factor. or cute character.able i is wrong. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.423 (perp=6.516, rec=0.119, cos=0.000), tot_loss_proj:2.857 [t=0.27s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character.able i is wrong. [SEP]']
[1500/2000] tot_loss=1.415 (perp=6.516, rec=0.111, cos=0.000), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character.able i is wrong. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.418 (perp=6.516, rec=0.115, cos=0.000), tot_loss_proj:2.852 [t=0.25s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character.able i is wrong. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.412 (perp=6.516, rec=0.109, cos=0.000), tot_loss_proj:2.851 [t=0.25s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character.able i is wrong. [SEP]']
[1650/2000] tot_loss=1.417 (perp=6.516, rec=0.114, cos=0.000), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character.able i is wrong. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.371 (perp=6.300, rec=0.110, cos=0.000), tot_loss_proj:2.739 [t=0.25s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character. i is wrongable. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.375 (perp=6.300, rec=0.114, cos=0.000), tot_loss_proj:2.736 [t=0.27s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character. i is wrongable. [SEP]']
[1800/2000] tot_loss=1.370 (perp=6.300, rec=0.110, cos=0.000), tot_loss_proj:2.735 [t=0.25s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he no loveable. or cute character. i is wrongable. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.351 (perp=6.159, rec=0.119, cos=0.000), tot_loss_proj:2.851 [t=0.24s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he loveable. or no cute character. i is wrongable. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.344 (perp=6.159, rec=0.112, cos=0.000), tot_loss_proj:2.844 [t=0.27s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he loveable. or no cute character. i is wrongable. [SEP]']
[1950/2000] tot_loss=1.340 (perp=6.159, rec=0.108, cos=0.000), tot_loss_proj:2.847 [t=0.25s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he loveable. or no cute character. i is wrongable. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.346 (perp=6.159, rec=0.115, cos=0.000), tot_loss_proj:2.846 [t=0.27s]
prediction: ['[CLS] cute has no problem here. the ugly mind factor. ; he loveable. or no cute character. i is wrongable. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] cute has no problem here. the ugly mind factor. ; he loveable. or no cute character. i is wrongable. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.805 | p: 90.000 | r: 85.714
rouge2     | fm: 15.385 | p: 15.789 | r: 15.000
rougeL     | fm: 39.024 | p: 40.000 | r: 38.095
rougeLsum  | fm: 39.024 | p: 40.000 | r: 38.095
r1fm+r2fm = 103.189

[Aggregate metrics]:
rouge1     | fm: 98.476 | p: 98.750 | r: 98.214
rouge2     | fm: 76.923 | p: 76.974 | r: 76.875
rougeL     | fm: 89.253 | p: 89.375 | r: 89.137
rougeLsum  | fm: 89.253 | p: 89.375 | r: 89.137
r1fm+r2fm = 175.399

input #7 time: 0:11:05 | total time: 0:35:00


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
*********************************
*********************************
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 1.3184598684310913 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 1.3084146976470947 for ['[CLS] thunder edge tender youngaz 505acality forced cheers bed lochley concacaf pm some commercial eliot advocate flow bubble habits ease bless [SEP]']
[Init] best rec loss: 1.29958176612854 for ['[CLS] slate conducted maps charlierocity these leaked too count search cody misery cannon vet vote prior foreign. ratio atm boys trafficrating 1st [SEP]']
[Init] best rec loss: 1.2899292707443237 for ['[CLS] descent caughtway holiday riding fist stages died pi focusedョeis anywhere half vine tarzan center sunlight away broughteda held reserved website [SEP]']
[Init] best perm rec loss: 1.2864528894424438 for ['[CLS] reserved focused away stages riding tarzanway caught center anywhere brought pi sunlight website holiday fist half held diedeis descenteda vineョ [SEP]']
[Init] best perm rec loss: 1.2788499593734741 for ['[CLS] stages holiday descent sunlightway half center fist away vine died tarzan riding focused website pi anywhere broughtedaeis heldョ reserved caught [SEP]']
[Init] best perm rec loss: 1.2772839069366455 for ['[CLS] anywhere stages riding halfeis away died center held focusedway brought tarzan sunlight holiday reservededa pi descentョ caught fist website vine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.152 (perp=13.600, rec=0.424, cos=0.007), tot_loss_proj:3.957 [t=0.27s]
prediction: ['[CLS] cursedques airport selfish kappa sought industry designed film patronsr honneur medal societe club department torment sought insight give colby mountain cosmeticschal [SEP]']
[ 100/2000] tot_loss=3.121 (perp=13.912, rec=0.335, cos=0.003), tot_loss_proj:4.283 [t=0.25s]
prediction: ['[CLS] vanity cannes property selfish vanity ignored worthy the film patronsers wellesdora societe which departmentlling pay training gs trait mountainerated celebrated [SEP]']
[ 150/2000] tot_loss=2.963 (perp=13.326, rec=0.297, cos=0.001), tot_loss_proj:3.830 [t=0.26s]
prediction: ['[CLS] vanityques debt vanity vanity ignored admired a film debters wellesdora debts that film buyers pays training pays trait risingა celebrated [SEP]']
[ 200/2000] tot_loss=2.886 (perp=13.075, rec=0.267, cos=0.004), tot_loss_proj:3.792 [t=0.25s]
prediction: ['[CLS] vanity ( debt vanity vanity ignored debt a film debtersinessdie debt that film screening pays off pays trait releasing elena celebrated [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.770 (perp=12.603, rec=0.239, cos=0.011), tot_loss_proj:3.998 [t=0.26s]
prediction: ['[CLS] ( debt vanity vanity vanity vanity debt a film debtersinessdie debt that film doubt pays what paysive releasing elena products [SEP]']
[ 300/2000] tot_loss=2.748 (perp=12.396, rec=0.228, cos=0.041), tot_loss_proj:3.948 [t=0.25s]
prediction: ['[CLS] s debt vanity vanity vanity vanity debt a film debt filminessdie debt that doubt doubt pays what paysive releasing elena products [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.506 (perp=11.439, rec=0.213, cos=0.005), tot_loss_proj:3.629 [t=0.26s]
prediction: ['[CLS] s debt vanity vanity vanity doubt debt a film debt film frightdie debt that doubt vanity pays what paysful film films jessie [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.310 (perp=10.604, rec=0.188, cos=0.001), tot_loss_proj:3.496 [t=0.25s]
prediction: ['[CLS] s debt vanity vanity film doubt debt a film debt vanity frightman debt that doubt vanity pays what paysful film films productions [SEP]']
[ 450/2000] tot_loss=2.345 (perp=10.824, rec=0.179, cos=0.001), tot_loss_proj:3.628 [t=0.25s]
prediction: ['[CLS] s debt vanity vanity film doubt debt a film debt vanity frightmax debt that doubt vanity pays what paysful film films products [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.282 (perp=10.555, rec=0.171, cos=0.000), tot_loss_proj:3.511 [t=0.27s]
prediction: ['[CLS] s debt vanity vanity film doubt debt a film debt vanity fright film owed that doubt vanity pays what paysfulmax film products [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.260 (perp=10.466, rec=0.165, cos=0.002), tot_loss_proj:3.562 [t=0.25s]
prediction: ['[CLS] s nedra owed vanity film doubt owed a film debt vanity fright film vanity that doubt vanity pays what paysfulmax film products [SEP]']
[ 600/2000] tot_loss=2.248 (perp=10.466, rec=0.154, cos=0.000), tot_loss_proj:3.563 [t=0.25s]
prediction: ['[CLS] s nedra owed vanity film doubt owed a film debt vanity fright film vanity that doubt vanity pays what paysfulmax film products [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.245 (perp=10.497, rec=0.145, cos=0.001), tot_loss_proj:3.619 [t=0.26s]
prediction: ['[CLS] s nedra owed vanity film doubt owed a film debt vanity fright film vanity that doubt vanity pays what paysi filmmax products [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.266 (perp=10.563, rec=0.152, cos=0.001), tot_loss_proj:3.649 [t=0.25s]
prediction: ['[CLS] s no owed vanity film doubt owed a film debt vanity fright film benigni that doubt vanity pays what benign filmmax products [SEP]']
[ 750/2000] tot_loss=2.261 (perp=10.563, rec=0.142, cos=0.006), tot_loss_proj:3.646 [t=0.27s]
prediction: ['[CLS] s no owed vanity film doubt owed a film debt vanity fright film benigni that doubt vanity pays what benign filmmax products [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.198 (perp=10.295, rec=0.139, cos=0.000), tot_loss_proj:3.598 [t=0.26s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt vanity fright film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.190 (perp=10.295, rec=0.131, cos=0.000), tot_loss_proj:3.598 [t=0.25s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt vanity fright film benigni that doubt vanity pays what benign filmmax owed [SEP]']
[ 900/2000] tot_loss=2.195 (perp=10.295, rec=0.136, cos=0.000), tot_loss_proj:3.599 [t=0.25s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt vanity fright film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.193 (perp=10.295, rec=0.134, cos=0.000), tot_loss_proj:3.596 [t=0.27s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt vanity fright film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.305 (perp=10.904, rec=0.124, cos=0.000), tot_loss_proj:3.755 [t=0.27s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt vanity benign film benigni that doubt vanity pays what benign filmmax owed [SEP]']
[1050/2000] tot_loss=2.309 (perp=10.904, rec=0.128, cos=0.000), tot_loss_proj:3.759 [t=0.26s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt vanity benign film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.273 (perp=10.684, rec=0.136, cos=0.000), tot_loss_proj:3.698 [t=0.27s]
prediction: ['[CLS] s no owed vanity film doubt products a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.196 (perp=10.299, rec=0.135, cos=0.001), tot_loss_proj:3.563 [t=0.27s]
prediction: ['[CLS] s no vanity film doubt products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
[1200/2000] tot_loss=2.187 (perp=10.299, rec=0.127, cos=0.000), tot_loss_proj:3.566 [t=0.27s]
prediction: ['[CLS] s no vanity film doubt products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.151 (perp=10.134, rec=0.125, cos=0.000), tot_loss_proj:3.613 [t=0.27s]
prediction: ['[CLS] s no doubt vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.127 (perp=10.032, rec=0.120, cos=0.000), tot_loss_proj:3.466 [t=0.26s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
[1350/2000] tot_loss=2.125 (perp=10.032, rec=0.119, cos=0.000), tot_loss_proj:3.465 [t=0.25s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.137 (perp=10.032, rec=0.131, cos=0.000), tot_loss_proj:3.467 [t=0.28s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.131 (perp=10.032, rec=0.124, cos=0.000), tot_loss_proj:3.467 [t=0.27s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
[1500/2000] tot_loss=2.133 (perp=10.032, rec=0.127, cos=0.000), tot_loss_proj:3.470 [t=0.25s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.130 (perp=10.032, rec=0.124, cos=0.000), tot_loss_proj:3.468 [t=0.26s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benign filmmax owed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.053 (perp=9.642, rec=0.124, cos=0.000), tot_loss_proj:3.352 [t=0.25s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
[1650/2000] tot_loss=2.054 (perp=9.642, rec=0.125, cos=0.000), tot_loss_proj:3.354 [t=0.26s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.053 (perp=9.642, rec=0.125, cos=0.000), tot_loss_proj:3.356 [t=0.27s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.049 (perp=9.642, rec=0.120, cos=0.000), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
[1800/2000] tot_loss=2.051 (perp=9.642, rec=0.123, cos=0.000), tot_loss_proj:3.357 [t=0.27s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.052 (perp=9.642, rec=0.124, cos=0.000), tot_loss_proj:3.360 [t=0.26s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.045 (perp=9.642, rec=0.116, cos=0.000), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
[1950/2000] tot_loss=2.047 (perp=9.642, rec=0.119, cos=0.000), tot_loss_proj:3.352 [t=0.29s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.050 (perp=9.642, rec=0.121, cos=0.000), tot_loss_proj:3.355 [t=0.26s]
prediction: ['[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s doubt no vanity film products owed a film debt benign vanity film benigni that doubt vanity pays what benignimax owed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.116 | p: 60.870 | r: 70.000
rouge2     | fm: 9.756 | p: 9.091 | r: 10.526
rougeL     | fm: 51.163 | p: 47.826 | r: 55.000
rougeLsum  | fm: 51.163 | p: 47.826 | r: 55.000
r1fm+r2fm = 74.872

[Aggregate metrics]:
rouge1     | fm: 94.769 | p: 94.541 | r: 95.079
rouge2     | fm: 69.460 | p: 69.431 | r: 69.503
rougeL     | fm: 85.021 | p: 84.758 | r: 85.344
rougeLsum  | fm: 85.021 | p: 84.758 | r: 85.344
r1fm+r2fm = 164.229

input #8 time: 0:11:05 | total time: 0:46:05


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
*********************************
*********************************
average of cosine similarity 0.9993981275486598
highest_index [0]
highest [0.9993981275486598]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 1.700202226638794 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 1.27736234664917 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 1.1396721601486206 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 1.0866336822509766 for ['[CLS] video guys glass stilldleulf explorer eva [SEP]']
[Init] best perm rec loss: 1.0833972692489624 for ['[CLS] explorerdle video guys glass evaulf still [SEP]']
[Init] best perm rec loss: 1.0814344882965088 for ['[CLS] video guysulf still glassdle explorer eva [SEP]']
[Init] best perm rec loss: 1.08087956905365 for ['[CLS] evadle guys video glass still explorerulf [SEP]']
[Init] best perm rec loss: 1.079574704170227 for ['[CLS] still guys explorer videoulf evadle glass [SEP]']
[Init] best perm rec loss: 1.079067349433899 for ['[CLS] glass explorerulfdle still guys video eva [SEP]']
[Init] best perm rec loss: 1.0773389339447021 for ['[CLS] videoulf guys explorer stilldle glass eva [SEP]']
[Init] best perm rec loss: 1.075656533241272 for ['[CLS] still eva explorerdle glass guysulf video [SEP]']
[Init] best perm rec loss: 1.075609564781189 for ['[CLS]dle stillulf glass video eva guys explorer [SEP]']
[Init] best perm rec loss: 1.0754793882369995 for ['[CLS] still evaulf guys video explorer glassdle [SEP]']
[Init] best perm rec loss: 1.0741891860961914 for ['[CLS] glass still eva guys videodle explorerulf [SEP]']
[Init] best perm rec loss: 1.0710862874984741 for ['[CLS] eva video still glass explorer guysdleulf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.976 (perp=13.033, rec=0.359, cos=0.010), tot_loss_proj:3.735 [t=0.25s]
prediction: ['[CLS] bean artists name clap protestant bread tomb symbolism [SEP]']
[ 100/2000] tot_loss=2.420 (perp=10.836, rec=0.250, cos=0.002), tot_loss_proj:3.143 [t=0.27s]
prediction: ['[CLS] of metaphysical acts claptan breadhead briefs [SEP]']
[ 150/2000] tot_loss=2.272 (perp=10.473, rec=0.176, cos=0.001), tot_loss_proj:3.076 [t=0.25s]
prediction: ['[CLS] of metaphysical soft claptra softhead clap [SEP]']
[ 200/2000] tot_loss=2.170 (perp=10.102, rec=0.148, cos=0.002), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS] of metaphysical soft claptra softheaded [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.019 (perp=9.038, rec=0.206, cos=0.006), tot_loss_proj:2.736 [t=0.27s]
prediction: ['[CLS] of metaphysical claptra softheaded soft [SEP]']
[ 300/2000] tot_loss=1.947 (perp=9.038, rec=0.139, cos=0.001), tot_loss_proj:2.722 [t=0.26s]
prediction: ['[CLS] of metaphysical claptra softheaded soft [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.930 (perp=9.038, rec=0.122, cos=0.000), tot_loss_proj:2.719 [t=0.24s]
prediction: ['[CLS] of metaphysical claptra softheaded soft [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.923 (perp=9.038, rec=0.114, cos=0.001), tot_loss_proj:2.726 [t=0.25s]
prediction: ['[CLS] of metaphysical claptra softheaded soft [SEP]']
[ 450/2000] tot_loss=1.915 (perp=9.038, rec=0.107, cos=0.000), tot_loss_proj:2.732 [t=0.26s]
prediction: ['[CLS] of metaphysical claptra softheaded soft [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.204 (perp=10.524, rec=0.099, cos=0.000), tot_loss_proj:2.829 [t=0.26s]
prediction: ['[CLS] of metaphysical claptra softheadp soft [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.879 (perp=8.412, rec=0.188, cos=0.009), tot_loss_proj:2.194 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[ 600/2000] tot_loss=1.807 (perp=8.412, rec=0.124, cos=0.001), tot_loss_proj:2.198 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.796 (perp=8.412, rec=0.113, cos=0.000), tot_loss_proj:2.195 [t=0.28s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.786 (perp=8.412, rec=0.103, cos=0.000), tot_loss_proj:2.194 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[ 750/2000] tot_loss=1.780 (perp=8.412, rec=0.097, cos=0.000), tot_loss_proj:2.198 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.779 (perp=8.412, rec=0.097, cos=0.000), tot_loss_proj:2.201 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.412, rec=0.090, cos=0.000), tot_loss_proj:2.192 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[ 900/2000] tot_loss=1.763 (perp=8.412, rec=0.081, cos=0.000), tot_loss_proj:2.195 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.771 (perp=8.412, rec=0.089, cos=0.000), tot_loss_proj:2.194 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1000/2000] tot_loss=1.759 (perp=8.412, rec=0.076, cos=0.000), tot_loss_proj:2.199 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1050/2000] tot_loss=1.773 (perp=8.412, rec=0.090, cos=0.000), tot_loss_proj:2.191 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1100/2000] tot_loss=1.768 (perp=8.412, rec=0.085, cos=0.000), tot_loss_proj:2.196 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1150/2000] tot_loss=1.752 (perp=8.412, rec=0.069, cos=0.000), tot_loss_proj:2.198 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1200/2000] tot_loss=1.770 (perp=8.412, rec=0.088, cos=0.000), tot_loss_proj:2.199 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1250/2000] tot_loss=1.757 (perp=8.412, rec=0.075, cos=0.000), tot_loss_proj:2.196 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1300/2000] tot_loss=1.767 (perp=8.412, rec=0.085, cos=0.000), tot_loss_proj:2.199 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1350/2000] tot_loss=1.772 (perp=8.412, rec=0.090, cos=0.000), tot_loss_proj:2.196 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1400/2000] tot_loss=1.762 (perp=8.412, rec=0.079, cos=0.000), tot_loss_proj:2.195 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1450/2000] tot_loss=1.768 (perp=8.412, rec=0.086, cos=0.000), tot_loss_proj:2.194 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1500/2000] tot_loss=1.765 (perp=8.412, rec=0.083, cos=0.000), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1550/2000] tot_loss=1.762 (perp=8.412, rec=0.080, cos=0.000), tot_loss_proj:2.193 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=8.412, rec=0.085, cos=0.000), tot_loss_proj:2.192 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1650/2000] tot_loss=1.774 (perp=8.412, rec=0.092, cos=0.000), tot_loss_proj:2.197 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.412, rec=0.081, cos=0.000), tot_loss_proj:2.200 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1750/2000] tot_loss=1.763 (perp=8.412, rec=0.080, cos=0.000), tot_loss_proj:2.196 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1800/2000] tot_loss=1.766 (perp=8.412, rec=0.083, cos=0.000), tot_loss_proj:2.195 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1850/2000] tot_loss=1.758 (perp=8.412, rec=0.075, cos=0.000), tot_loss_proj:2.195 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[1900/2000] tot_loss=1.755 (perp=8.412, rec=0.073, cos=0.000), tot_loss_proj:2.190 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
[1950/2000] tot_loss=1.775 (perp=8.412, rec=0.093, cos=0.000), tot_loss_proj:2.188 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.412, rec=0.079, cos=0.000), tot_loss_proj:2.199 [t=0.24s]
prediction: ['[CLS] of metaphysical claptrap softhead soft [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical claptrap softhead soft [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 93.023 | p: 92.230 | r: 94.000
rouge2     | fm: 66.150 | p: 65.821 | r: 67.000
rougeL     | fm: 84.403 | p: 83.747 | r: 85.952
rougeLsum  | fm: 84.403 | p: 83.565 | r: 85.476
r1fm+r2fm = 159.174

input #9 time: 0:10:50 | total time: 0:56:56


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
*********************************
*********************************
average of cosine similarity 0.9991472052153931
highest_index [0]
highest [0.9991472052153931]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 1.8671343326568604 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 1.8420976400375366 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 1.4058338403701782 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 1.3968875408172607 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 1.3953274488449097 for ['[CLS]blood common angeloric up sheep order blessed sound level totally places themes [SEP]']
[Init] best perm rec loss: 1.3951473236083984 for ['[CLS] themesoric soundblood sheep up places common blessed level order totally angel [SEP]']
[Init] best perm rec loss: 1.3938393592834473 for ['[CLS] angel up level order totally themes placesblood sheeporic sound blessed common [SEP]']
[Init] best perm rec loss: 1.3935538530349731 for ['[CLS] totally up common level places sheep order sound blessed themes angeloricblood [SEP]']
[Init] best perm rec loss: 1.3933236598968506 for ['[CLS] sheep places common sound themes totally order blessed level upbloodoric angel [SEP]']
[Init] best perm rec loss: 1.3882167339324951 for ['[CLS] places sheep totally level uporic blessed order angel sound common themesblood [SEP]']
[Init] best perm rec loss: 1.387595295906067 for ['[CLS]bloodoric blessed totally up themes places angel sheep common sound order level [SEP]']
[Init] best perm rec loss: 1.3872023820877075 for ['[CLS] sound blessedblood common up sheep places order level totally themes angeloric [SEP]']
[Init] best perm rec loss: 1.3837432861328125 for ['[CLS] sound places angel common totally level sheep order blessed uporic themesblood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.631 (perp=11.254, rec=0.372, cos=0.007), tot_loss_proj:3.345 [t=0.24s]
prediction: ['[CLS] mmmplicity studies onto differences focuses optimistic. special spirit and the stations [SEP]']
[ 100/2000] tot_loss=2.371 (perp=10.470, rec=0.274, cos=0.003), tot_loss_proj:3.420 [t=0.25s]
prediction: ['[CLS] routineplicity balance with tracking rhythms philosophical. special spirit ;. automatically [SEP]']
[ 150/2000] tot_loss=2.188 (perp=9.860, rec=0.215, cos=0.002), tot_loss_proj:2.728 [t=0.25s]
prediction: ['[CLS] abplicity balance with rhythms rhythms philosophical. wide spirit.. automatically [SEP]']
[ 200/2000] tot_loss=2.188 (perp=9.998, rec=0.186, cos=0.002), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS] abplicity balance with rhythms rhythmsrring. wide spirit.. blindly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.139 (perp=9.476, rec=0.239, cos=0.005), tot_loss_proj:2.926 [t=0.25s]
prediction: ['[CLS] ab geometry balance with rhythms rhythms perspective. zoneibly.. super [SEP]']
[ 300/2000] tot_loss=2.156 (perp=9.845, rec=0.186, cos=0.001), tot_loss_proj:3.230 [t=0.27s]
prediction: ['[CLS] abulsive balance with rhythms rhythms perspective.lysity.. super [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.428 (perp=10.249, rec=0.343, cos=0.035), tot_loss_proj:3.184 [t=0.25s]
prediction: ['[CLS] ab incident balance with rhythms rhythms perspectivelysity :.. super [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.280 (perp=10.242, rec=0.229, cos=0.003), tot_loss_proj:3.838 [t=0.25s]
prediction: ['[CLS] ab verbal balance with moment rhythms scientific stronglyity :.. assassination [SEP]']
[ 450/2000] tot_loss=2.334 (perp=10.667, rec=0.199, cos=0.002), tot_loss_proj:3.175 [t=0.27s]
prediction: ['[CLS] ab verbal balance with noises rhythms reallyity band..ulsive [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.008 (perp=9.140, rec=0.179, cos=0.001), tot_loss_proj:2.786 [t=0.26s]
prediction: ['[CLS] ab verbal balance with incident rhythms realityly :..ulsive [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.134 (perp=9.780, rec=0.176, cos=0.002), tot_loss_proj:3.508 [t=0.25s]
prediction: ['[CLS] ab physically balance with incident rhythms realityulsively critic.. [SEP]']
[ 600/2000] tot_loss=2.178 (perp=10.069, rec=0.164, cos=0.001), tot_loss_proj:3.533 [t=0.25s]
prediction: ['[CLS] ab physically balance with incident rhythms real incidentulsively critic.. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.048 (perp=9.433, rec=0.160, cos=0.001), tot_loss_proj:3.154 [t=0.25s]
prediction: ['[CLS] ab physically balance with incident rhythms real incidentulsively. critic. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.935 (perp=8.851, rec=0.164, cos=0.001), tot_loss_proj:3.033 [t=0.25s]
prediction: ['[CLS] ab balance physically with incident rhythms real incidentulsively. critic. [SEP]']
[ 750/2000] tot_loss=1.916 (perp=8.851, rec=0.145, cos=0.001), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] ab balance physically with incident rhythms real incidentulsively. critic. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.897 (perp=8.790, rec=0.138, cos=0.001), tot_loss_proj:2.898 [t=0.25s]
prediction: ['[CLS] ab balance physically with time rhythms real incidentulsively. critic. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.846 (perp=8.334, rec=0.177, cos=0.002), tot_loss_proj:2.990 [t=0.25s]
prediction: ['[CLS] incident ab balance physically with time rhythms realulsively. let. [SEP]']
[ 900/2000] tot_loss=1.818 (perp=8.334, rec=0.150, cos=0.001), tot_loss_proj:2.972 [t=0.26s]
prediction: ['[CLS] incident ab balance physically with time rhythms realulsively. let. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.720 (perp=7.870, rec=0.144, cos=0.001), tot_loss_proj:3.185 [t=0.25s]
prediction: ['[CLS] incident ab balance physically with let rhythms realulsively. time. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.732 (perp=7.918, rec=0.148, cos=0.001), tot_loss_proj:3.180 [t=0.25s]
prediction: ['[CLS] incident ab balance physical with let rhythms realulsively. incident. [SEP]']
[1050/2000] tot_loss=1.884 (perp=8.728, rec=0.138, cos=0.001), tot_loss_proj:3.267 [t=0.25s]
prediction: ['[CLS]ulsive ab balanceing with let rhythms realulsively. incident. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.001 (perp=9.298, rec=0.140, cos=0.001), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS]ulsive ab balance with icting rhythms realulsively. incident. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.924 (perp=8.893, rec=0.145, cos=0.001), tot_loss_proj:2.875 [t=0.25s]
prediction: ['[CLS]ulsive ab balance with incidenting rhythms realulsively. ict. [SEP]']
[1200/2000] tot_loss=2.075 (perp=9.690, rec=0.136, cos=0.001), tot_loss_proj:3.047 [t=0.25s]
prediction: ['[CLS]ulsive ab balance with incident physical rhythms realulsively. ict. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.917 (perp=8.913, rec=0.133, cos=0.001), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS]ulsive ab balanceing with incident rhythms realulsively. ict. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.924 (perp=8.913, rec=0.141, cos=0.001), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS]ulsive ab balanceing with incident rhythms realulsively. ict. [SEP]']
[1350/2000] tot_loss=1.921 (perp=8.913, rec=0.138, cos=0.001), tot_loss_proj:2.898 [t=0.26s]
prediction: ['[CLS]ulsive ab balanceing with incident rhythms realulsively. ict. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.865 (perp=8.641, rec=0.135, cos=0.001), tot_loss_proj:2.940 [t=0.25s]
prediction: ['[CLS] incident ab balanceing withulsive rhythms realulsively. ict. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.866 (perp=8.641, rec=0.137, cos=0.001), tot_loss_proj:2.937 [t=0.25s]
prediction: ['[CLS] incident ab balanceing withulsive rhythms realulsively. ict. [SEP]']
[1500/2000] tot_loss=1.860 (perp=8.641, rec=0.131, cos=0.001), tot_loss_proj:2.942 [t=0.26s]
prediction: ['[CLS] incident ab balanceing withulsive rhythms realulsively. ict. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.817 (perp=8.406, rec=0.135, cos=0.001), tot_loss_proj:2.982 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. ict. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.805 (perp=8.406, rec=0.123, cos=0.001), tot_loss_proj:2.968 [t=0.26s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. ict. [SEP]']
[1650/2000] tot_loss=1.810 (perp=8.406, rec=0.128, cos=0.001), tot_loss_proj:2.971 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. ict. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.807 (perp=8.406, rec=0.125, cos=0.001), tot_loss_proj:2.974 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. ict. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.695 (perp=7.852, rec=0.124, cos=0.001), tot_loss_proj:3.078 [t=0.26s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]']
[1800/2000] tot_loss=1.702 (perp=7.852, rec=0.131, cos=0.001), tot_loss_proj:3.078 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.705 (perp=7.852, rec=0.134, cos=0.001), tot_loss_proj:3.070 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.698 (perp=7.852, rec=0.127, cos=0.001), tot_loss_proj:3.073 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]']
[1950/2000] tot_loss=1.700 (perp=7.852, rec=0.129, cos=0.001), tot_loss_proj:3.075 [t=0.25s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.698 (perp=7.852, rec=0.127, cos=0.001), tot_loss_proj:3.071 [t=0.26s]
prediction: ['[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] incident ab balanceing with realulsive rhythmsulsively. incident. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.105 | p: 44.444 | r: 40.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 42.105 | p: 44.444 | r: 40.000
rougeLsum  | fm: 42.105 | p: 44.444 | r: 40.000
r1fm+r2fm = 53.870

[Aggregate metrics]:
rouge1     | fm: 88.359 | p: 87.835 | r: 89.091
rouge2     | fm: 61.024 | p: 60.675 | r: 61.212
rougeL     | fm: 80.383 | p: 79.882 | r: 81.039
rougeLsum  | fm: 80.970 | p: 80.206 | r: 81.439
r1fm+r2fm = 149.383

input #10 time: 0:10:46 | total time: 1:07:43


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
*********************************
*********************************
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 1.8228942155838013 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 1.7478306293487549 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 1.3220566511154175 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 1.311123251914978 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 1.3074727058410645 for ['[CLS]ture inlandgu me tal platform familiarvd mile drawn [SEP]']
[Init] best perm rec loss: 1.2857089042663574 for ['[CLS] inlandture drawn tal platform megu familiarvd mile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.823 (perp=12.116, rec=0.395, cos=0.005), tot_loss_proj:3.441 [t=0.27s]
prediction: ['[CLS] which trouble away♣ springs attempted debris _ed project [SEP]']
[ 100/2000] tot_loss=2.774 (perp=12.278, rec=0.315, cos=0.003), tot_loss_proj:3.366 [t=0.26s]
prediction: ['[CLS] that attempt refused gel especially insisted copies stubborned gel [SEP]']
[ 150/2000] tot_loss=2.498 (perp=11.349, rec=0.227, cos=0.002), tot_loss_proj:3.439 [t=0.25s]
prediction: ['[CLS] that attempted refused gel that stubborn opinion stubborn to gel [SEP]']
[ 200/2000] tot_loss=2.422 (perp=11.335, rec=0.154, cos=0.001), tot_loss_proj:3.443 [t=0.27s]
prediction: ['[CLS] was attempted refused gel that stubborn attacked stubborn to gel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.914 (perp=8.745, rec=0.163, cos=0.002), tot_loss_proj:2.294 [t=0.24s]
prediction: ['[CLS] was attempted stubborn gel that stubbornly refused to gel [SEP]']
[ 300/2000] tot_loss=1.880 (perp=8.745, rec=0.130, cos=0.001), tot_loss_proj:2.305 [t=0.25s]
prediction: ['[CLS] was attempted stubborn gel that stubbornly refused to gel [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.811 (perp=8.442, rec=0.122, cos=0.001), tot_loss_proj:2.217 [t=0.28s]
prediction: ['[CLS] was stubborn attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.794 (perp=8.442, rec=0.106, cos=0.001), tot_loss_proj:2.205 [t=0.25s]
prediction: ['[CLS] was stubborn attempted gel that stubbornly refused to gel [SEP]']
[ 450/2000] tot_loss=1.800 (perp=8.442, rec=0.111, cos=0.001), tot_loss_proj:2.212 [t=0.26s]
prediction: ['[CLS] was stubborn attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.644 (perp=7.730, rec=0.097, cos=0.001), tot_loss_proj:2.043 [t=0.26s]
prediction: ['[CLS] was here attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.514 (perp=7.071, rec=0.099, cos=0.001), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[ 600/2000] tot_loss=1.498 (perp=7.071, rec=0.083, cos=0.000), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.505 (perp=7.071, rec=0.090, cos=0.000), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.497 (perp=7.071, rec=0.082, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[ 750/2000] tot_loss=1.495 (perp=7.071, rec=0.080, cos=0.000), tot_loss_proj:1.871 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.497 (perp=7.071, rec=0.082, cos=0.000), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.485 (perp=7.071, rec=0.070, cos=0.000), tot_loss_proj:1.886 [t=0.27s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[ 900/2000] tot_loss=1.498 (perp=7.071, rec=0.083, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.489 (perp=7.071, rec=0.074, cos=0.000), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.496 (perp=7.071, rec=0.081, cos=0.000), tot_loss_proj:1.879 [t=0.27s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1050/2000] tot_loss=1.499 (perp=7.071, rec=0.084, cos=0.000), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.499 (perp=7.071, rec=0.084, cos=0.000), tot_loss_proj:1.882 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.493 (perp=7.071, rec=0.079, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.488 (perp=7.071, rec=0.074, cos=0.000), tot_loss_proj:1.886 [t=0.28s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.482 (perp=7.071, rec=0.067, cos=0.000), tot_loss_proj:1.877 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.491 (perp=7.071, rec=0.076, cos=0.000), tot_loss_proj:1.882 [t=0.27s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.071, rec=0.073, cos=0.000), tot_loss_proj:1.876 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.490 (perp=7.071, rec=0.075, cos=0.000), tot_loss_proj:1.880 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.490 (perp=7.071, rec=0.076, cos=0.000), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.499 (perp=7.071, rec=0.084, cos=0.000), tot_loss_proj:1.880 [t=0.27s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.496 (perp=7.071, rec=0.081, cos=0.000), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.491 (perp=7.071, rec=0.076, cos=0.000), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.492 (perp=7.071, rec=0.077, cos=0.000), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.491 (perp=7.071, rec=0.076, cos=0.000), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.493 (perp=7.071, rec=0.079, cos=0.000), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.485 (perp=7.071, rec=0.071, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.486 (perp=7.071, rec=0.072, cos=0.000), tot_loss_proj:1.884 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.500 (perp=7.071, rec=0.085, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.492 (perp=7.071, rec=0.077, cos=0.000), tot_loss_proj:1.881 [t=0.26s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.488 (perp=7.071, rec=0.073, cos=0.000), tot_loss_proj:1.885 [t=0.27s]
prediction: ['[CLS] here was attempted gel that stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted gel that stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 140.909

[Aggregate metrics]:
rouge1     | fm: 88.604 | p: 88.228 | r: 89.361
rouge2     | fm: 61.085 | p: 60.654 | r: 61.386
rougeL     | fm: 80.503 | p: 80.081 | r: 81.183
rougeLsum  | fm: 80.819 | p: 80.341 | r: 81.382
r1fm+r2fm = 149.689

input #11 time: 0:10:57 | total time: 1:18:41


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
*********************************
*********************************
average of cosine similarity 0.9993439176315202
highest_index [0]
highest [0.9993439176315202]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 1.8480900526046753 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 1.794683814048767 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 1.4141982793807983 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 1.3857673406600952 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 1.319607138633728 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 1.2739667892456055 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 1.2710332870483398 for ['[CLS] command married coma lux me brook fuel specifically containing deaf missing firm prospects track [SEP]']
[Init] best perm rec loss: 1.2705339193344116 for ['[CLS] prospects command me brook married lux containing fuel coma track firm missing deaf specifically [SEP]']
[Init] best perm rec loss: 1.2703341245651245 for ['[CLS] coma deaf lux containing married brook prospects missing me firm specifically command fuel track [SEP]']
[Init] best perm rec loss: 1.2677892446517944 for ['[CLS] command brook deaf firm missing prospects specifically coma containing track married me lux fuel [SEP]']
[Init] best perm rec loss: 1.2655885219573975 for ['[CLS] track deaf containing specifically firm prospects coma command brook fuel lux missing me married [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.806 (perp=12.068, rec=0.390, cos=0.002), tot_loss_proj:3.465 [t=0.25s]
prediction: ['[CLS] if weakly off apparently rub hearing suspect least having limit cable probably weak attack [SEP]']
[ 100/2000] tot_loss=2.515 (perp=11.108, rec=0.289, cos=0.004), tot_loss_proj:3.241 [t=0.25s]
prediction: ['[CLS] than barely for cable rebellion to to being laid endangered cable better fault cable [SEP]']
[ 150/2000] tot_loss=2.355 (perp=10.572, rec=0.225, cos=0.016), tot_loss_proj:3.039 [t=0.28s]
prediction: ['[CLS] than barely on cable problem to will being seen endangered cable better fault cable [SEP]']
[ 200/2000] tot_loss=2.256 (perp=10.322, rec=0.188, cos=0.003), tot_loss_proj:2.973 [t=0.27s]
prediction: ['[CLS] than barely on cable advantage to will being seen advantage advantage better fault cable [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.040 (perp=9.267, rec=0.185, cos=0.002), tot_loss_proj:2.663 [t=0.26s]
prediction: ['[CLS] that barely on cable preferred will be seen to advantage advantage better fault despite [SEP]']
[ 300/2000] tot_loss=2.027 (perp=9.409, rec=0.145, cos=0.000), tot_loss_proj:3.042 [t=0.25s]
prediction: ['[CLS] that barely on cable seen will be seen that advantage advantage better its despite [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.959 (perp=9.110, rec=0.136, cos=0.000), tot_loss_proj:3.075 [t=0.26s]
prediction: ['[CLS] that barely seen on cable will be seen because advantage advantage better its despite [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.552 (perp=7.104, rec=0.130, cos=0.001), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] that barely seen on cable will be seen because to better its advantage its [SEP]']
[ 450/2000] tot_loss=1.653 (perp=7.761, rec=0.100, cos=0.000), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] that barely seen on cable will be seen especially to better especially advantage its [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.596 (perp=7.493, rec=0.097, cos=0.000), tot_loss_proj:2.602 [t=0.27s]
prediction: ['[CLS] that barely seen on cable will be seen especially especially to better advantage its [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.573 (perp=7.390, rec=0.095, cos=0.000), tot_loss_proj:2.262 [t=0.25s]
prediction: ['[CLS] that barely seen on cable will be seen considering especially to better advantage its [SEP]']
[ 600/2000] tot_loss=1.566 (perp=7.390, rec=0.088, cos=0.000), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] that barely seen on cable will be seen considering especially to better advantage its [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.633 (perp=7.735, rec=0.085, cos=0.000), tot_loss_proj:2.343 [t=0.25s]
prediction: ['[CLS] that barely considered on cable will be seen considering especially to better advantage its [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.654 (perp=7.890, rec=0.075, cos=0.000), tot_loss_proj:2.294 [t=0.26s]
prediction: ['[CLS] that barely especially on cable will be seen considering especially to better advantage its [SEP]']
[ 750/2000] tot_loss=1.663 (perp=7.890, rec=0.085, cos=0.000), tot_loss_proj:2.294 [t=0.27s]
prediction: ['[CLS] that barely especially on cable will be seen considering especially to better advantage its [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.640 (perp=7.821, rec=0.076, cos=0.000), tot_loss_proj:2.294 [t=0.25s]
prediction: ['[CLS] barely that especially on cable will be seen considering especially to better advantage its [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.639 (perp=7.821, rec=0.075, cos=0.000), tot_loss_proj:2.297 [t=0.26s]
prediction: ['[CLS] barely that especially on cable will be seen considering especially to better advantage its [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.821, rec=0.086, cos=0.000), tot_loss_proj:2.291 [t=0.26s]
prediction: ['[CLS] barely that especially on cable will be seen considering especially to better advantage its [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.643 (perp=7.821, rec=0.078, cos=0.000), tot_loss_proj:2.301 [t=0.25s]
prediction: ['[CLS] barely that especially on cable will be seen considering especially to better advantage its [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.793 (perp=8.231, rec=0.142, cos=0.004), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1050/2000] tot_loss=1.747 (perp=8.231, rec=0.100, cos=0.001), tot_loss_proj:2.630 [t=0.24s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1100/2000] tot_loss=1.736 (perp=8.231, rec=0.090, cos=0.000), tot_loss_proj:2.629 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1150/2000] tot_loss=1.732 (perp=8.231, rec=0.086, cos=0.000), tot_loss_proj:2.633 [t=0.27s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1200/2000] tot_loss=1.726 (perp=8.231, rec=0.079, cos=0.000), tot_loss_proj:2.629 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=8.231, rec=0.086, cos=0.000), tot_loss_proj:2.629 [t=0.28s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=8.231, rec=0.089, cos=0.000), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1350/2000] tot_loss=1.730 (perp=8.231, rec=0.083, cos=0.000), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1400/2000] tot_loss=1.734 (perp=8.231, rec=0.088, cos=0.000), tot_loss_proj:2.635 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1450/2000] tot_loss=1.722 (perp=8.231, rec=0.076, cos=0.000), tot_loss_proj:2.634 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1500/2000] tot_loss=1.727 (perp=8.231, rec=0.080, cos=0.000), tot_loss_proj:2.629 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1550/2000] tot_loss=1.729 (perp=8.231, rec=0.083, cos=0.000), tot_loss_proj:2.632 [t=0.27s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1600/2000] tot_loss=1.723 (perp=8.231, rec=0.076, cos=0.000), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1650/2000] tot_loss=1.725 (perp=8.231, rec=0.078, cos=0.000), tot_loss_proj:2.631 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1700/2000] tot_loss=1.728 (perp=8.231, rec=0.082, cos=0.000), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1750/2000] tot_loss=1.728 (perp=8.231, rec=0.082, cos=0.000), tot_loss_proj:2.632 [t=0.28s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1800/2000] tot_loss=1.725 (perp=8.231, rec=0.078, cos=0.000), tot_loss_proj:2.633 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1850/2000] tot_loss=1.724 (perp=8.231, rec=0.077, cos=0.000), tot_loss_proj:2.635 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[1900/2000] tot_loss=1.727 (perp=8.231, rec=0.081, cos=0.000), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.231, rec=0.096, cos=0.000), tot_loss_proj:2.633 [t=0.26s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Attempt swap
[2000/2000] tot_loss=1.728 (perp=8.231, rec=0.081, cos=0.000), tot_loss_proj:2.634 [t=0.25s]
prediction: ['[CLS] barely that ava on cable will be seen considering especially to its better advantage [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely that especially on cable will be seen considering especially to better advantage its [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 34.483 | p: 33.333 | r: 35.714
rougeL     | fm: 64.516 | p: 62.500 | r: 66.667
rougeLsum  | fm: 64.516 | p: 62.500 | r: 66.667
r1fm+r2fm = 131.257

[Aggregate metrics]:
rouge1     | fm: 89.444 | p: 88.676 | r: 90.436
rouge2     | fm: 58.361 | p: 58.071 | r: 58.657
rougeL     | fm: 79.539 | p: 78.905 | r: 80.072
rougeLsum  | fm: 79.055 | p: 78.488 | r: 79.988
r1fm+r2fm = 147.804

input #12 time: 0:10:53 | total time: 1:29:34


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
*********************************
*********************************
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 1.4737218618392944 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 1.4235199689865112 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 1.406105875968933 for ['[CLS] pdf along timing started mal practical prevailed [SEP]']
[Init] best rec loss: 1.390662670135498 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 1.3708242177963257 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 1.3614050149917603 for ['[CLS] dame recess ak latter threshold po illness [SEP]']
[Init] best rec loss: 1.3537973165512085 for ['[CLS] squat what names set fence thin received [SEP]']
[Init] best rec loss: 1.3353148698806763 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
[Init] best rec loss: 1.3023403882980347 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 1.261353611946106 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 1.2592674493789673 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 1.2589128017425537 for ['[CLS] defeat cardinal arm roweional precision permanent [SEP]']
[Init] best perm rec loss: 1.256705403327942 for ['[CLS] permanent cardinalional arm precision rowe defeat [SEP]']
[Init] best perm rec loss: 1.2559808492660522 for ['[CLS] permanentional cardinal defeat rowe precision arm [SEP]']
[Init] best perm rec loss: 1.2554824352264404 for ['[CLS] defeat cardinalional arm permanent precision rowe [SEP]']
[Init] best perm rec loss: 1.2538996934890747 for ['[CLS] cardinal defeational arm precision rowe permanent [SEP]']
[Init] best perm rec loss: 1.2521754503250122 for ['[CLS] permanent rowe cardinal armional precision defeat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.500 (perp=10.752, rec=0.344, cos=0.005), tot_loss_proj:3.458 [t=0.25s]
prediction: ['[CLS] accusations you must flames really steel took [SEP]']
[ 100/2000] tot_loss=2.467 (perp=10.837, rec=0.280, cos=0.020), tot_loss_proj:3.216 [t=0.25s]
prediction: ['[CLS] point in must flame point decisions into [SEP]']
[ 150/2000] tot_loss=2.322 (perp=10.762, rec=0.169, cos=0.001), tot_loss_proj:3.671 [t=0.26s]
prediction: ['[CLS] point things when flame at things into [SEP]']
[ 200/2000] tot_loss=2.003 (perp=9.327, rec=0.136, cos=0.001), tot_loss_proj:3.490 [t=0.24s]
prediction: ['[CLS] point at that flame at things into [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.933 (perp=9.090, rec=0.113, cos=0.001), tot_loss_proj:2.823 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[ 300/2000] tot_loss=1.911 (perp=9.090, rec=0.093, cos=0.001), tot_loss_proj:2.818 [t=0.27s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.897 (perp=9.090, rec=0.079, cos=0.000), tot_loss_proj:2.825 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.893 (perp=9.090, rec=0.074, cos=0.000), tot_loss_proj:2.824 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[ 450/2000] tot_loss=1.892 (perp=9.090, rec=0.074, cos=0.000), tot_loss_proj:2.820 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.884 (perp=9.090, rec=0.066, cos=0.000), tot_loss_proj:2.828 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.896 (perp=9.090, rec=0.078, cos=0.000), tot_loss_proj:2.827 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[ 600/2000] tot_loss=1.898 (perp=9.090, rec=0.079, cos=0.000), tot_loss_proj:2.825 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.883 (perp=9.090, rec=0.065, cos=0.000), tot_loss_proj:2.822 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.894 (perp=9.090, rec=0.076, cos=0.000), tot_loss_proj:2.824 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[ 750/2000] tot_loss=1.879 (perp=9.090, rec=0.060, cos=0.000), tot_loss_proj:2.817 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.878 (perp=9.090, rec=0.060, cos=0.000), tot_loss_proj:2.817 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.883 (perp=9.090, rec=0.065, cos=0.000), tot_loss_proj:2.820 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[ 900/2000] tot_loss=1.886 (perp=9.090, rec=0.068, cos=0.000), tot_loss_proj:2.819 [t=0.24s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.881 (perp=9.090, rec=0.063, cos=0.000), tot_loss_proj:2.814 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1000/2000] tot_loss=1.886 (perp=9.090, rec=0.068, cos=0.000), tot_loss_proj:2.814 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1050/2000] tot_loss=1.883 (perp=9.090, rec=0.065, cos=0.000), tot_loss_proj:2.814 [t=0.27s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1100/2000] tot_loss=1.878 (perp=9.090, rec=0.060, cos=0.000), tot_loss_proj:2.815 [t=0.27s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1150/2000] tot_loss=1.889 (perp=9.090, rec=0.071, cos=0.000), tot_loss_proj:2.811 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1200/2000] tot_loss=1.876 (perp=9.090, rec=0.057, cos=0.000), tot_loss_proj:2.814 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1250/2000] tot_loss=1.874 (perp=9.090, rec=0.055, cos=0.000), tot_loss_proj:2.813 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1300/2000] tot_loss=1.885 (perp=9.090, rec=0.066, cos=0.000), tot_loss_proj:2.811 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1350/2000] tot_loss=1.884 (perp=9.090, rec=0.066, cos=0.000), tot_loss_proj:2.811 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1400/2000] tot_loss=1.888 (perp=9.090, rec=0.070, cos=0.000), tot_loss_proj:2.816 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1450/2000] tot_loss=1.875 (perp=9.090, rec=0.057, cos=0.000), tot_loss_proj:2.820 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1500/2000] tot_loss=1.879 (perp=9.090, rec=0.061, cos=0.000), tot_loss_proj:2.813 [t=0.24s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1550/2000] tot_loss=1.881 (perp=9.090, rec=0.063, cos=0.000), tot_loss_proj:2.812 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1600/2000] tot_loss=1.882 (perp=9.090, rec=0.064, cos=0.000), tot_loss_proj:2.819 [t=0.27s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1650/2000] tot_loss=1.875 (perp=9.090, rec=0.057, cos=0.000), tot_loss_proj:2.814 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1700/2000] tot_loss=1.886 (perp=9.090, rec=0.068, cos=0.000), tot_loss_proj:2.815 [t=0.27s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1750/2000] tot_loss=1.884 (perp=9.090, rec=0.065, cos=0.000), tot_loss_proj:2.811 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1800/2000] tot_loss=1.888 (perp=9.090, rec=0.070, cos=0.000), tot_loss_proj:2.815 [t=0.27s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1850/2000] tot_loss=1.877 (perp=9.090, rec=0.059, cos=0.000), tot_loss_proj:2.808 [t=0.25s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[1900/2000] tot_loss=1.874 (perp=9.090, rec=0.056, cos=0.000), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
[1950/2000] tot_loss=1.877 (perp=9.090, rec=0.059, cos=0.000), tot_loss_proj:2.810 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Attempt swap
[2000/2000] tot_loss=1.871 (perp=9.090, rec=0.052, cos=0.000), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] point at that flame explode things into [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point at that flame explode things into [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.202 | p: 89.583 | r: 91.190
rouge2     | fm: 55.796 | p: 55.561 | r: 56.193
rougeL     | fm: 79.211 | p: 78.533 | r: 79.846
rougeLsum  | fm: 79.109 | p: 78.572 | r: 79.872
r1fm+r2fm = 145.998

input #13 time: 0:10:52 | total time: 1:40:27


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
*********************************
*********************************
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 1.9555590152740479 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 1.90388023853302 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 1.7101174592971802 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 1.6756500005722046 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 1.649327278137207 for ['[CLS] quiver federation maddie sacramentoboard [SEP]']
[Init] best rec loss: 1.459338903427124 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 1.455399990081787 for ['[CLS] myers harold tom [MASK] sprayed [SEP]']
[Init] best perm rec loss: 1.4520574808120728 for ['[CLS] harold myers [MASK] tom sprayed [SEP]']
[Init] best perm rec loss: 1.4497400522232056 for ['[CLS] myers harold [MASK] tom sprayed [SEP]']
[Init] best perm rec loss: 1.4491201639175415 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
[Init] best perm rec loss: 1.4477119445800781 for ['[CLS] [MASK] harold myers tom sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.695 (perp=12.128, rec=0.266, cos=0.003), tot_loss_proj:2.881 [t=0.24s]
prediction: ['[CLS]bly intriguing intriguing uncanny intriguing [SEP]']
[ 100/2000] tot_loss=2.327 (perp=10.861, rec=0.153, cos=0.002), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS]bly intriguing filmbly intriguing [SEP]']
[ 150/2000] tot_loss=2.654 (perp=12.705, rec=0.112, cos=0.002), tot_loss_proj:2.988 [t=0.26s]
prediction: ['[CLS]bly intriguing filmenia intriguing [SEP]']
[ 200/2000] tot_loss=2.639 (perp=12.705, rec=0.097, cos=0.001), tot_loss_proj:2.972 [t=0.25s]
prediction: ['[CLS]bly intriguing filmenia intriguing [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.956 (perp=9.271, rec=0.101, cos=0.001), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
[ 300/2000] tot_loss=1.949 (perp=9.271, rec=0.093, cos=0.001), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.684 (perp=7.971, rec=0.088, cos=0.001), tot_loss_proj:1.915 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.687 (perp=7.971, rec=0.091, cos=0.001), tot_loss_proj:1.917 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.687 (perp=7.971, rec=0.091, cos=0.001), tot_loss_proj:1.914 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.688 (perp=7.971, rec=0.092, cos=0.001), tot_loss_proj:1.911 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=7.971, rec=0.085, cos=0.001), tot_loss_proj:1.919 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 600/2000] tot_loss=2.095 (perp=10.059, rec=0.082, cos=0.001), tot_loss_proj:3.761 [t=0.25s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.413 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.400 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.413 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.409 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.410 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.404 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.404 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.408 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.417 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.398 (perp=6.728, rec=0.051, cos=0.001), tot_loss_proj:1.413 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.409 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.409 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.405 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.410 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.411 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.409 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.413 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.406 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.408 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.404 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.407 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.402 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.406 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.409 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.414 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.410 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.405 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.413 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.408 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.407 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.404 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.986 | p: 90.312 | r: 91.778
rouge2     | fm: 58.636 | p: 58.329 | r: 59.003
rougeL     | fm: 80.777 | p: 80.229 | r: 81.399
rougeLsum  | fm: 80.589 | p: 79.965 | r: 81.230
r1fm+r2fm = 149.621

input #14 time: 0:10:46 | total time: 1:51:14


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
*********************************
*********************************
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 1.96763014793396 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 1.925123929977417 for ['[CLS] ¹⁄₂ lds bay simple 19 client utc congestion [SEP]']
[Init] best rec loss: 1.9198782444000244 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 1.8514207601547241 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 1.7387832403182983 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 1.7253295183181763 for ['[CLS] tor casey decembergrate doua developed logic [SEP]']
[Init] best rec loss: 1.7060983180999756 for ['[CLS] du resign what pet system jazz aschurch [SEP]']
[Init] best rec loss: 1.7037686109542847 for ['[CLS] madeline discovery ocean truss stations chance ledge waiting [SEP]']
[Init] best rec loss: 1.6834999322891235 for ['[CLS] child indian setting launched and today returns becker [SEP]']
[Init] best rec loss: 1.5785369873046875 for ['[CLS] winner french badminton harperrdial missed ex fond [SEP]']
[Init] best perm rec loss: 1.575916051864624 for ['[CLS] frenchrdial badminton winner ex missed fond harper [SEP]']
[Init] best perm rec loss: 1.5737770795822144 for ['[CLS] french harper fondrdial badminton missed ex winner [SEP]']
[Init] best perm rec loss: 1.5736515522003174 for ['[CLS] missed winner ex frenchrdial fond harper badminton [SEP]']
[Init] best perm rec loss: 1.569117546081543 for ['[CLS]rdial ex harper fond missed french winner badminton [SEP]']
[Init] best perm rec loss: 1.568715214729309 for ['[CLS] french ex harper fondrdial missed winner badminton [SEP]']
[Init] best perm rec loss: 1.5686029195785522 for ['[CLS] harperrdial fond winner french ex missed badminton [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.615 (perp=11.550, rec=0.301, cos=0.004), tot_loss_proj:3.140 [t=0.24s]
prediction: ['[CLS]ablyably for directors fittingally efficient precision [SEP]']
[ 100/2000] tot_loss=2.647 (perp=12.215, rec=0.202, cos=0.002), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS]ablyably successfully chill efficient chill efficient efficient [SEP]']
[ 150/2000] tot_loss=2.508 (perp=11.713, rec=0.165, cos=0.001), tot_loss_proj:3.588 [t=0.27s]
prediction: ['[CLS] suitably. chill anonymous chill efficientable [SEP]']
[ 200/2000] tot_loss=2.461 (perp=11.713, rec=0.118, cos=0.001), tot_loss_proj:3.590 [t=0.25s]
prediction: ['[CLS] suitably. chill anonymous chill efficientable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.740 (perp=8.214, rec=0.096, cos=0.001), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] suitably. efficient anonymous chiller, [SEP]']
[ 300/2000] tot_loss=1.716 (perp=8.214, rec=0.072, cos=0.001), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] suitably. efficient anonymous chiller, [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.518 (perp=7.254, rec=0.067, cos=0.001), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] suitably efficient. anonymous chiller, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.411 (perp=6.697, rec=0.071, cos=0.001), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 450/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.511 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.405 (perp=6.697, rec=0.065, cos=0.001), tot_loss_proj:1.508 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.412 (perp=6.697, rec=0.072, cos=0.001), tot_loss_proj:1.515 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.414 (perp=6.697, rec=0.074, cos=0.001), tot_loss_proj:1.512 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.402 (perp=6.697, rec=0.062, cos=0.001), tot_loss_proj:1.510 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.407 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.411 (perp=6.697, rec=0.071, cos=0.001), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.394 (perp=6.697, rec=0.054, cos=0.001), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.414 (perp=6.697, rec=0.074, cos=0.001), tot_loss_proj:1.514 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.398 (perp=6.697, rec=0.058, cos=0.001), tot_loss_proj:1.511 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.400 (perp=6.697, rec=0.059, cos=0.001), tot_loss_proj:1.508 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.406 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.509 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.407 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.518 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.409 (perp=6.697, rec=0.069, cos=0.001), tot_loss_proj:1.506 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.515 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.697, rec=0.054, cos=0.001), tot_loss_proj:1.510 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.511 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.402 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.515 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.403 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.397 (perp=6.697, rec=0.057, cos=0.001), tot_loss_proj:1.509 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.397 (perp=6.697, rec=0.057, cos=0.001), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.399 (perp=6.697, rec=0.059, cos=0.001), tot_loss_proj:1.510 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.405 (perp=6.697, rec=0.065, cos=0.001), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.409 (perp=6.697, rec=0.069, cos=0.001), tot_loss_proj:1.515 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.512 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 91.443 | p: 90.988 | r: 92.197
rouge2     | fm: 57.670 | p: 57.438 | r: 57.951
rougeL     | fm: 80.674 | p: 80.264 | r: 81.376
rougeLsum  | fm: 80.647 | p: 80.216 | r: 81.264
r1fm+r2fm = 149.113

input #15 time: 0:10:51 | total time: 2:02:05


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
*********************************
*********************************
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.9508296251296997 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 1.8343384265899658 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 1.6890870332717896 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 1.6304024457931519 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 1.5867127180099487 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 1.525856614112854 for ['[CLS] legsyen t sharon camp ro [SEP]']
[Init] best rec loss: 1.5195893049240112 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 1.3733412027359009 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 1.3456374406814575 for ['[CLS] ultra backpack tallest you downstream map [SEP]']
[Init] best perm rec loss: 1.337275505065918 for ['[CLS] tallest downstream map you backpack ultra [SEP]']
[Init] best perm rec loss: 1.336099624633789 for ['[CLS] map tallest ultra downstream backpack you [SEP]']
[Init] best perm rec loss: 1.3238879442214966 for ['[CLS] tallest ultra map backpack you downstream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.255 (perp=13.939, rec=0.460, cos=0.008), tot_loss_proj:4.581 [t=0.24s]
prediction: ['[CLS] inch until results maxwell evengeny [SEP]']
[ 100/2000] tot_loss=2.149 (perp=8.751, rec=0.392, cos=0.008), tot_loss_proj:2.992 [t=0.24s]
prediction: ['[CLS] that this everything. most this [SEP]']
[ 150/2000] tot_loss=2.096 (perp=8.908, rec=0.310, cos=0.005), tot_loss_proj:2.865 [t=0.26s]
prediction: ['[CLS] that this of. most this [SEP]']
[ 200/2000] tot_loss=1.449 (perp=5.981, rec=0.244, cos=0.009), tot_loss_proj:2.144 [t=0.25s]
prediction: ['[CLS] this all of and all this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.558 (perp=6.831, rec=0.187, cos=0.004), tot_loss_proj:2.052 [t=0.25s]
prediction: ['[CLS] and all of this of more [SEP]']
[ 300/2000] tot_loss=1.164 (perp=5.123, rec=0.138, cos=0.002), tot_loss_proj:1.437 [t=0.27s]
prediction: ['[CLS] and all of this and more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.206 (perp=5.574, rec=0.090, cos=0.001), tot_loss_proj:1.647 [t=0.28s]
prediction: ['[CLS], all of this and more [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.029 (perp=4.697, rec=0.088, cos=0.001), tot_loss_proj:1.326 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.016 (perp=4.697, rec=0.076, cos=0.001), tot_loss_proj:1.301 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.021 (perp=4.697, rec=0.081, cos=0.001), tot_loss_proj:1.313 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.014 (perp=4.697, rec=0.074, cos=0.000), tot_loss_proj:1.308 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.009 (perp=4.697, rec=0.069, cos=0.000), tot_loss_proj:1.313 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.006 (perp=4.697, rec=0.066, cos=0.000), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.011 (perp=4.697, rec=0.071, cos=0.000), tot_loss_proj:1.307 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.003 (perp=4.697, rec=0.064, cos=0.000), tot_loss_proj:1.299 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.015 (perp=4.697, rec=0.075, cos=0.000), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.004 (perp=4.697, rec=0.064, cos=0.000), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.013 (perp=4.697, rec=0.074, cos=0.000), tot_loss_proj:1.309 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.003 (perp=4.697, rec=0.063, cos=0.000), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.015 (perp=4.697, rec=0.075, cos=0.000), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.006 (perp=4.697, rec=0.066, cos=0.000), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=0.998 (perp=4.697, rec=0.058, cos=0.000), tot_loss_proj:1.297 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.011 (perp=4.697, rec=0.071, cos=0.000), tot_loss_proj:1.314 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.002 (perp=4.697, rec=0.062, cos=0.000), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.012 (perp=4.697, rec=0.072, cos=0.000), tot_loss_proj:1.304 [t=0.30s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=0.995 (perp=4.697, rec=0.055, cos=0.000), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.011 (perp=4.697, rec=0.071, cos=0.000), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.010 (perp=4.697, rec=0.070, cos=0.000), tot_loss_proj:1.308 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.012 (perp=4.697, rec=0.073, cos=0.000), tot_loss_proj:1.311 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.008 (perp=4.697, rec=0.068, cos=0.000), tot_loss_proj:1.305 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.004 (perp=4.697, rec=0.064, cos=0.000), tot_loss_proj:1.308 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.001 (perp=4.697, rec=0.062, cos=0.000), tot_loss_proj:1.305 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.015 (perp=4.697, rec=0.075, cos=0.000), tot_loss_proj:1.308 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=0.998 (perp=4.697, rec=0.058, cos=0.000), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=0.997 (perp=4.697, rec=0.058, cos=0.000), tot_loss_proj:1.309 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=0.996 (perp=4.697, rec=0.056, cos=0.000), tot_loss_proj:1.304 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.001 (perp=4.697, rec=0.061, cos=0.000), tot_loss_proj:1.306 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.004 (perp=4.697, rec=0.064, cos=0.000), tot_loss_proj:1.304 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.010 (perp=4.697, rec=0.070, cos=0.000), tot_loss_proj:1.306 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.006 (perp=4.697, rec=0.066, cos=0.000), tot_loss_proj:1.309 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.876 | p: 91.416 | r: 92.656
rouge2     | fm: 60.428 | p: 60.239 | r: 60.663
rougeL     | fm: 82.425 | p: 82.006 | r: 82.983
rougeLsum  | fm: 81.894 | p: 81.409 | r: 82.495
r1fm+r2fm = 152.304

input #16 time: 0:10:52 | total time: 2:12:58


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
*********************************
*********************************
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 1.6595710515975952 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 1.6428885459899902 for ['[CLS] friend agency todd wi dirty percent milesamp... vietsive [SEP]']
[Init] best rec loss: 1.6136316061019897 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 1.576501488685608 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 1.5198489427566528 for ['[CLS] highestlt short ad relation minority black bunch marine above different [SEP]']
[Init] best rec loss: 1.513322114944458 for ['[CLS] name standardfoldieg names result diesfulds suggest mystery [SEP]']
[Init] best rec loss: 1.4297772645950317 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 1.3880505561828613 for ['[CLS] general sensation water consecrated affairvudran bethany then religious threatened [SEP]']
[Init] best rec loss: 1.366730809211731 for ['[CLS] georgian kilometers following fatal conversion station arch with gene goddess [SEP]']
[Init] best perm rec loss: 1.3620654344558716 for ['[CLS] gene station fatalh conversion following goddess kilometers with georgian arc [SEP]']
[Init] best perm rec loss: 1.361521601676941 for ['[CLS] arc gene goddess following with georgian conversionh kilometers fatal station [SEP]']
[Init] best perm rec loss: 1.361145257949829 for ['[CLS] fatal with goddess geneh georgian conversion kilometers arc station following [SEP]']
[Init] best perm rec loss: 1.3605331182479858 for ['[CLS] kilometers gene following fatal with goddess georgian arc conversion stationh [SEP]']
[Init] best perm rec loss: 1.360186219215393 for ['[CLS] geneh conversion station with kilometers following georgian arc fatal goddess [SEP]']
[Init] best perm rec loss: 1.3596504926681519 for ['[CLS]h kilometers conversion fatal following station goddess with georgian gene arc [SEP]']
[Init] best perm rec loss: 1.3583624362945557 for ['[CLS] kilometers with stationh conversion fatal goddess arc gene following georgian [SEP]']
[Init] best perm rec loss: 1.3579857349395752 for ['[CLS] georgian geneh station with fatal conversion kilometers following arc goddess [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.566 (perp=10.810, rec=0.398, cos=0.006), tot_loss_proj:3.790 [t=0.24s]
prediction: ['[CLS] can thinkth monsters mercy : repertoire gained full cent, [SEP]']
[ 100/2000] tot_loss=2.434 (perp=10.643, rec=0.297, cos=0.008), tot_loss_proj:3.268 [t=0.25s]
prediction: ['[CLS] want want away too too john think talent on too about [SEP]']
[ 150/2000] tot_loss=2.098 (perp=9.379, rec=0.220, cos=0.002), tot_loss_proj:2.694 [t=0.25s]
prediction: ['[CLS] want want too too too - much about on too much [SEP]']
[ 200/2000] tot_loss=1.674 (perp=7.538, rec=0.166, cos=0.001), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] want think too too too too much about on too much [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.821 (perp=8.361, rec=0.146, cos=0.003), tot_loss_proj:2.580 [t=0.25s]
prediction: ["[CLS] want think too anything too much about'what on much [SEP]"]
[ 300/2000] tot_loss=1.958 (perp=9.179, rec=0.121, cos=0.001), tot_loss_proj:2.713 [t=0.25s]
prediction: ['[CLS] want think too is too much what going what on about [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.618 (perp=7.539, rec=0.110, cos=0.000), tot_loss_proj:2.337 [t=0.26s]
prediction: ['[CLS] want think too is too much what going on about what [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.513 (perp=7.023, rec=0.107, cos=0.001), tot_loss_proj:1.935 [t=0.27s]
prediction: ['[CLS] want think too too much what s going on about what [SEP]']
[ 450/2000] tot_loss=1.504 (perp=7.023, rec=0.099, cos=0.000), tot_loss_proj:1.939 [t=0.27s]
prediction: ['[CLS] want think too too much what s going on about what [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.454 (perp=6.779, rec=0.098, cos=0.000), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] want think too much too what s going on about what [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.458 (perp=6.779, rec=0.101, cos=0.000), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] want think too much too what s going on about what [SEP]']
[ 600/2000] tot_loss=1.426 (perp=6.692, rec=0.087, cos=0.000), tot_loss_proj:1.976 [t=0.27s]
prediction: ["[CLS] want think too much too what s going on about'[SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.348 (perp=6.285, rec=0.091, cos=0.000), tot_loss_proj:1.828 [t=0.25s]
prediction: ["[CLS] want think too much about what s going on too'[SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.346 (perp=6.285, rec=0.089, cos=0.000), tot_loss_proj:1.836 [t=0.25s]
prediction: ["[CLS] want think too much about what s going on too'[SEP]"]
[ 750/2000] tot_loss=1.344 (perp=6.285, rec=0.086, cos=0.000), tot_loss_proj:1.840 [t=0.25s]
prediction: ["[CLS] want think too much about what s going on too'[SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.343 (perp=6.285, rec=0.086, cos=0.000), tot_loss_proj:1.834 [t=0.25s]
prediction: ["[CLS] want think too much about what s going on too'[SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.228 (perp=5.697, rec=0.088, cos=0.001), tot_loss_proj:1.624 [t=0.26s]
prediction: ["[CLS] want think too much about what too's going on [SEP]"]
[ 900/2000] tot_loss=1.222 (perp=5.697, rec=0.083, cos=0.000), tot_loss_proj:1.623 [t=0.25s]
prediction: ["[CLS] want think too much about what too's going on [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.146 (perp=5.352, rec=0.075, cos=0.000), tot_loss_proj:1.679 [t=0.25s]
prediction: ["[CLS] want think too much too about what's going on [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.141 (perp=5.306, rec=0.080, cos=0.000), tot_loss_proj:1.572 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1050/2000] tot_loss=1.146 (perp=5.306, rec=0.084, cos=0.000), tot_loss_proj:1.580 [t=0.27s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.134 (perp=5.306, rec=0.072, cos=0.000), tot_loss_proj:1.579 [t=0.26s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.145 (perp=5.306, rec=0.083, cos=0.000), tot_loss_proj:1.567 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1200/2000] tot_loss=1.147 (perp=5.306, rec=0.085, cos=0.000), tot_loss_proj:1.572 [t=0.26s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.139 (perp=5.306, rec=0.077, cos=0.000), tot_loss_proj:1.573 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.133 (perp=5.306, rec=0.072, cos=0.000), tot_loss_proj:1.573 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1350/2000] tot_loss=1.142 (perp=5.306, rec=0.080, cos=0.000), tot_loss_proj:1.574 [t=0.26s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.136 (perp=5.306, rec=0.074, cos=0.000), tot_loss_proj:1.579 [t=0.24s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.142 (perp=5.306, rec=0.081, cos=0.000), tot_loss_proj:1.567 [t=0.24s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1500/2000] tot_loss=1.148 (perp=5.306, rec=0.086, cos=0.000), tot_loss_proj:1.571 [t=0.26s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.141 (perp=5.306, rec=0.079, cos=0.000), tot_loss_proj:1.579 [t=0.24s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.140 (perp=5.306, rec=0.078, cos=0.000), tot_loss_proj:1.574 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1650/2000] tot_loss=1.131 (perp=5.306, rec=0.070, cos=0.000), tot_loss_proj:1.577 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.135 (perp=5.306, rec=0.073, cos=0.000), tot_loss_proj:1.576 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.131 (perp=5.306, rec=0.069, cos=0.000), tot_loss_proj:1.575 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1800/2000] tot_loss=1.138 (perp=5.306, rec=0.077, cos=0.000), tot_loss_proj:1.571 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.143 (perp=5.306, rec=0.082, cos=0.000), tot_loss_proj:1.571 [t=0.26s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.143 (perp=5.306, rec=0.081, cos=0.000), tot_loss_proj:1.565 [t=0.26s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
[1950/2000] tot_loss=1.133 (perp=5.306, rec=0.072, cos=0.000), tot_loss_proj:1.570 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.142 (perp=5.306, rec=0.081, cos=0.000), tot_loss_proj:1.569 [t=0.25s]
prediction: ["[CLS] want think too too much about what's going on [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want think too too much about what's going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 81.818 | p: 81.818 | r: 81.818
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 173.485

[Aggregate metrics]:
rouge1     | fm: 91.850 | p: 91.315 | r: 92.527
rouge2     | fm: 61.113 | p: 60.813 | r: 61.463
rougeL     | fm: 82.723 | p: 82.274 | r: 83.216
rougeLsum  | fm: 82.496 | p: 82.143 | r: 83.143
r1fm+r2fm = 152.962

input #17 time: 0:10:57 | total time: 2:23:55


Running input #18 of 100.
reference: 
========================
invigorating 
========================
*********************************
*********************************
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.974354863166809 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 1.9697707891464233 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 1.9564363956451416 for ['[CLS] bound dvd lead grace [SEP]']
[Init] best rec loss: 1.8697879314422607 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 1.7662303447723389 for ['[CLS] says oh dynasty watershed [SEP]']
[Init] best rec loss: 1.67368483543396 for ['[CLS] disappointednce secret running [SEP]']
[Init] best rec loss: 1.5851483345031738 for ['[CLS] with thy commission operating [SEP]']
[Init] best rec loss: 1.3104640245437622 for ['[CLS] dual circle duodle [SEP]']
[Init] best rec loss: 1.2881578207015991 for ['[CLS] canellant replication calm [SEP]']
[Init] best perm rec loss: 1.2752639055252075 for ['[CLS] replicationellant can calm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.087 (perp=13.650, rec=0.351, cos=0.006), tot_loss_proj:3.368 [t=0.25s]
prediction: ['[CLS] treasure visual basedising [SEP]']
[ 100/2000] tot_loss=2.718 (perp=12.219, rec=0.271, cos=0.003), tot_loss_proj:4.271 [t=0.28s]
prediction: ['[CLS] considered europe basedating [SEP]']
[ 150/2000] tot_loss=1.781 (perp=7.761, rec=0.226, cos=0.002), tot_loss_proj:2.168 [t=0.25s]
prediction: ['[CLS] presentvigorating [SEP]']
[ 200/2000] tot_loss=1.314 (perp=5.588, rec=0.194, cos=0.002), tot_loss_proj:1.198 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.223 (perp=5.588, rec=0.104, cos=0.001), tot_loss_proj:1.187 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.186 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.180 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.180 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.181 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.175 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.187 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.187 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.175 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.178 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.196 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.178 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.185 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.176 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.179 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.186 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.182 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.179 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.185 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.172 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.175 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.182 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.181 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.185 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.192 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.185 [t=0.29s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.181 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.172 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.183 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.179 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.181 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.184 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.180 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.192 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.183 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.350 | p: 91.949 | r: 93.008
rouge2     | fm: 63.611 | p: 63.383 | r: 63.900
rougeL     | fm: 83.533 | p: 83.187 | r: 84.022
rougeLsum  | fm: 83.535 | p: 83.154 | r: 84.173
r1fm+r2fm = 155.961

input #18 time: 0:10:56 | total time: 2:34:51


Running input #19 of 100.
reference: 
========================
to infamy 
========================
*********************************
*********************************
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 1.458032250404358 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 1.306396722793579 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 1.226775884628296 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 1.1880154609680176 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 1.1041380167007446 for ['[CLS] intra raf soviet events [SEP]']
[Init] best perm rec loss: 1.1023863554000854 for ['[CLS] raf soviet events intra [SEP]']
[Init] best perm rec loss: 1.099515676498413 for ['[CLS] intra events soviet raf [SEP]']
[Init] best perm rec loss: 1.0991603136062622 for ['[CLS] soviet intra events raf [SEP]']
[Init] best perm rec loss: 1.0963892936706543 for ['[CLS] soviet events intra raf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.540 (perp=10.628, rec=0.397, cos=0.017), tot_loss_proj:3.631 [t=0.25s]
prediction: ['[CLS] eastng episode actress [SEP]']
[ 100/2000] tot_loss=2.289 (perp=9.951, rec=0.295, cos=0.004), tot_loss_proj:3.516 [t=0.28s]
prediction: ['[CLS]famy tofa [SEP]']
[ 150/2000] tot_loss=2.309 (perp=10.580, rec=0.186, cos=0.007), tot_loss_proj:3.623 [t=0.25s]
prediction: ['[CLS]famy tomy [SEP]']
[ 200/2000] tot_loss=2.245 (perp=10.580, rec=0.124, cos=0.005), tot_loss_proj:3.639 [t=0.27s]
prediction: ['[CLS]famy tomy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.318 (perp=10.377, rec=0.231, cos=0.012), tot_loss_proj:3.369 [t=0.25s]
prediction: ['[CLS]famymy to [SEP]']
[ 300/2000] tot_loss=2.227 (perp=10.377, rec=0.151, cos=0.001), tot_loss_proj:3.581 [t=0.25s]
prediction: ['[CLS]famymy to [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.196 (perp=10.377, rec=0.120, cos=0.001), tot_loss_proj:3.578 [t=0.25s]
prediction: ['[CLS]famymy to [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.406 (perp=6.522, rec=0.100, cos=0.002), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] infamy to [SEP]']
[ 450/2000] tot_loss=1.385 (perp=6.522, rec=0.080, cos=0.001), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.306 (perp=6.110, rec=0.084, cos=0.001), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.000), tot_loss_proj:1.300 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.000), tot_loss_proj:1.306 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.294 (perp=6.110, rec=0.072, cos=0.000), tot_loss_proj:1.298 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.286 (perp=6.110, rec=0.064, cos=0.000), tot_loss_proj:1.308 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.289 (perp=6.110, rec=0.066, cos=0.000), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.288 (perp=6.110, rec=0.066, cos=0.000), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.295 (perp=6.110, rec=0.073, cos=0.000), tot_loss_proj:1.305 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.280 (perp=6.110, rec=0.058, cos=0.000), tot_loss_proj:1.298 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.282 (perp=6.110, rec=0.060, cos=0.000), tot_loss_proj:1.300 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.279 (perp=6.110, rec=0.057, cos=0.000), tot_loss_proj:1.306 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.284 (perp=6.110, rec=0.062, cos=0.000), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.000), tot_loss_proj:1.288 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.000), tot_loss_proj:1.302 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.000), tot_loss_proj:1.300 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.000), tot_loss_proj:1.309 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.281 (perp=6.110, rec=0.059, cos=0.000), tot_loss_proj:1.300 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.280 (perp=6.110, rec=0.058, cos=0.000), tot_loss_proj:1.308 [t=0.34s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.281 (perp=6.110, rec=0.059, cos=0.000), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.287 (perp=6.110, rec=0.065, cos=0.000), tot_loss_proj:1.309 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.271 (perp=6.110, rec=0.049, cos=0.000), tot_loss_proj:1.293 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.291 (perp=6.110, rec=0.069, cos=0.000), tot_loss_proj:1.301 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.285 (perp=6.110, rec=0.063, cos=0.000), tot_loss_proj:1.302 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.000), tot_loss_proj:1.296 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.293 (perp=6.110, rec=0.071, cos=0.000), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.288 (perp=6.110, rec=0.065, cos=0.000), tot_loss_proj:1.298 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.297 (perp=6.110, rec=0.075, cos=0.000), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.278 (perp=6.110, rec=0.056, cos=0.000), tot_loss_proj:1.303 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.287 (perp=6.110, rec=0.065, cos=0.000), tot_loss_proj:1.304 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.747 | p: 92.303 | r: 93.286
rouge2     | fm: 65.361 | p: 65.146 | r: 65.674
rougeL     | fm: 84.652 | p: 84.211 | r: 85.121
rougeLsum  | fm: 84.359 | p: 83.979 | r: 84.845
r1fm+r2fm = 158.108

input #19 time: 0:10:55 | total time: 2:45:47


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
*********************************
*********************************
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 1.7585136890411377 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 1.6632047891616821 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 1.4528199434280396 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 1.4066518545150757 for ['[CLS] trialuce tai sweet [SEP]']
[Init] best rec loss: 1.3769547939300537 for ['[CLS]nst 2018 principles arguing [SEP]']
[Init] best rec loss: 1.322018027305603 for ['[CLS] jensen eden blackwell is [SEP]']
[Init] best rec loss: 1.2753173112869263 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 1.2749077081680298 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 1.2715117931365967 for ['[CLS] storylinexiness [CLS] [SEP]']
[Init] best perm rec loss: 1.2714813947677612 for ['[CLS] storylinenessxi [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.560 (perp=10.348, rec=0.465, cos=0.026), tot_loss_proj:3.670 [t=0.25s]
prediction: ['[CLS] great darkness rewarded [SEP] [SEP]']
[ 100/2000] tot_loss=2.556 (perp=11.279, rec=0.292, cos=0.008), tot_loss_proj:3.093 [t=0.25s]
prediction: ['[CLS] economicverse pleasure the [SEP]']
[ 150/2000] tot_loss=2.321 (perp=10.538, rec=0.209, cos=0.005), tot_loss_proj:3.400 [t=0.26s]
prediction: ['[CLS] belowverse pleasure the [SEP]']
[ 200/2000] tot_loss=1.889 (perp=8.633, rec=0.158, cos=0.004), tot_loss_proj:2.265 [t=0.27s]
prediction: ['[CLS] perverse pleasure the [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.736 (perp=7.610, rec=0.203, cos=0.010), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 300/2000] tot_loss=1.662 (perp=7.610, rec=0.137, cos=0.003), tot_loss_proj:1.866 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.623 (perp=7.610, rec=0.099, cos=0.002), tot_loss_proj:1.891 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.611 (perp=7.610, rec=0.088, cos=0.001), tot_loss_proj:1.881 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.607 (perp=7.610, rec=0.084, cos=0.001), tot_loss_proj:1.875 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.610, rec=0.069, cos=0.001), tot_loss_proj:1.879 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.587 (perp=7.610, rec=0.065, cos=0.000), tot_loss_proj:1.875 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.581 (perp=7.610, rec=0.058, cos=0.000), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.589 (perp=7.610, rec=0.066, cos=0.000), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.597 (perp=7.610, rec=0.075, cos=0.000), tot_loss_proj:1.858 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.588 (perp=7.610, rec=0.065, cos=0.000), tot_loss_proj:1.868 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.581 (perp=7.610, rec=0.059, cos=0.000), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.584 (perp=7.610, rec=0.062, cos=0.000), tot_loss_proj:1.870 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.610, rec=0.065, cos=0.000), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.590 (perp=7.610, rec=0.067, cos=0.000), tot_loss_proj:1.875 [t=0.28s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.583 (perp=7.610, rec=0.061, cos=0.000), tot_loss_proj:1.868 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.000), tot_loss_proj:1.869 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.000), tot_loss_proj:1.864 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.585 (perp=7.610, rec=0.063, cos=0.000), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.610, rec=0.055, cos=0.000), tot_loss_proj:1.868 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.584 (perp=7.610, rec=0.062, cos=0.000), tot_loss_proj:1.865 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.583 (perp=7.610, rec=0.061, cos=0.000), tot_loss_proj:1.864 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.595 (perp=7.610, rec=0.073, cos=0.000), tot_loss_proj:1.857 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.610, rec=0.063, cos=0.000), tot_loss_proj:1.859 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.580 (perp=7.610, rec=0.058, cos=0.000), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.578 (perp=7.610, rec=0.055, cos=0.000), tot_loss_proj:1.869 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.586 (perp=7.610, rec=0.064, cos=0.000), tot_loss_proj:1.863 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.000), tot_loss_proj:1.860 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.579 (perp=7.610, rec=0.057, cos=0.000), tot_loss_proj:1.858 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.594 (perp=7.610, rec=0.072, cos=0.000), tot_loss_proj:1.861 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.576 (perp=7.610, rec=0.054, cos=0.000), tot_loss_proj:1.855 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.588 (perp=7.610, rec=0.066, cos=0.000), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.593 (perp=7.610, rec=0.071, cos=0.000), tot_loss_proj:1.858 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.000), tot_loss_proj:1.861 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.588 (perp=7.610, rec=0.065, cos=0.000), tot_loss_proj:1.858 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.610, rec=0.060, cos=0.000), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.137 | p: 92.738 | r: 93.666
rouge2     | fm: 67.199 | p: 67.015 | r: 67.386
rougeL     | fm: 85.318 | p: 84.920 | r: 85.754
rougeLsum  | fm: 84.917 | p: 84.571 | r: 85.416
r1fm+r2fm = 160.336

input #20 time: 0:10:53 | total time: 2:56:41


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
*********************************
*********************************
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 1.8797924518585205 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 1.6756571531295776 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 1.6570099592208862 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 1.6356710195541382 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 1.525413990020752 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 1.5040524005889893 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 1.4968369007110596 for ['[CLS] bonn university on ashe shot wearing rockerlica classification speed non burning glad california againstanding colt timing mouthigo gun machinery score liked seems [SEP]']
[Init] best rec loss: 1.2692524194717407 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 1.2645514011383057 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 1.2639286518096924 for ['[CLS] pose bent rights vii labor loanback dee, itemtaking general fauna stony size she connecticut side according especially golden situations [UNK] baby there [SEP]']
[Init] best perm rec loss: 1.2572057247161865 for ['[CLS], situations connecticutback especially pose item benttaking dee golden rights general stony she loan size according [UNK] labor vii fauna there baby side [SEP]']
[Init] best perm rec loss: 1.2564804553985596 for ['[CLS] especiallytaking there she goldenback dee bent pose stony, situations loan size rights item [UNK] labor general baby connecticut vii fauna side according [SEP]']
[Init] best perm rec loss: 1.2533059120178223 for ['[CLS] general situations connecticut golden labor dee according bent especially baby there loan stonyback pose side [UNK] she vii item size rights,taking fauna [SEP]']
[Init] best perm rec loss: 1.2523531913757324 for ['[CLS] there baby loan vii fauna side she connecticut pose stony labor bent situations item according [UNK] especially deetaking golden, sizeback rights general [SEP]']
[Init] best perm rec loss: 1.2521893978118896 for ['[CLS] loan size baby, especially stony situations item bent there according connecticuttaking side fauna poseback dee golden general [UNK] she labor rights vii [SEP]']
[Init] best perm rec loss: 1.2520167827606201 for ['[CLS] rights golden according loan bent [UNK] situations connecticut stony there vii general dee size babyback labor she,taking fauna item especially side pose [SEP]']
[Init] best perm rec loss: 1.2508926391601562 for ['[CLS] fauna she vii [UNK] rightsback bent stony baby there connecticut item situations labor according golden size, side loantaking especially pose general dee [SEP]']
[Init] best perm rec loss: 1.2494364976882935 for ['[CLS] especially loanback vii [UNK] situations baby golden size bent connecticut dee according stony pose general labor rights fauna she item theretaking, side [SEP]']
[Init] best perm rec loss: 1.2471531629562378 for ['[CLS] she especially [UNK] item pose golden vii generalback there sidetaking rights loan, dee baby stony labor size according bent fauna connecticut situations [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=11.319, rec=0.435, cos=0.003), tot_loss_proj:3.272 [t=0.27s]
prediction: ['[CLS] that excuses australian sign bribe idiot saddam conduct flat § - section corruption label if tapelassified during laborhow caused wrong wrong newspaper witnesses [SEP]']
[ 100/2000] tot_loss=2.545 (perp=10.966, rec=0.351, cos=0.001), tot_loss_proj:3.238 [t=0.28s]
prediction: ['[CLS] thattypical australian signs rating on security conduct. oblast - tube furiously institute or policy gerais after laborhow explain instead right rate teachers [SEP]']
[ 150/2000] tot_loss=2.469 (perp=10.638, rec=0.335, cos=0.006), tot_loss_proj:2.991 [t=0.26s]
prediction: ["[CLS] that typical japanese signs rating the security conduct. § - tube make dental or american gerais ] this'explain instead way paid teachers [SEP]"]
[ 200/2000] tot_loss=2.401 (perp=10.577, rec=0.284, cos=0.001), tot_loss_proj:3.468 [t=0.26s]
prediction: ["[CLS] how way women like doping the security conduct. § - tube make dental or state gerais ] this'explain instead best works teachers [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.550 (perp=11.359, rec=0.277, cos=0.001), tot_loss_proj:3.480 [t=0.25s]
prediction: ['[CLS] how way women out the security relief.rainedbeent conditions make dental or state exhaustion ] thisliga taiwanese instead way works athletes [SEP]']
[ 300/2000] tot_loss=2.596 (perp=11.719, rec=0.251, cos=0.001), tot_loss_proj:3.378 [t=0.25s]
prediction: ['[CLS] how look women way the security department.rained hisent∧ make dentalcute state exhaustion gets thisliga taiwanese instead works works athletes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.535 (perp=11.446, rec=0.245, cos=0.001), tot_loss_proj:3.236 [t=0.27s]
prediction: ['[CLS] how look students way his worse department. imposed hisent linnaeus make minority if way exhaustion gets thisliga taiwanese instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.711 (perp=12.363, rec=0.238, cos=0.001), tot_loss_proj:3.464 [t=0.26s]
prediction: ['[CLS] how look students way his heavily conduct. imposedbitnt linnaeus makes exhaustion retro way minority gets thisliga taiwanese instead works women athletes [SEP]']
[ 450/2000] tot_loss=2.742 (perp=12.665, rec=0.209, cos=0.001), tot_loss_proj:3.460 [t=0.27s]
prediction: ['[CLS] how look students way his heavily conduct. imposedbitnt∧ makes exhaustion retro way minority gets thisliga taiwanese instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.385 (perp=10.926, rec=0.200, cos=0.000), tot_loss_proj:3.035 [t=0.25s]
prediction: ['[CLS] that look students way the hostilities so gets imposedbitnt caretaker makes cheat whose waytypical. thisliga weird instead works women athletes [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.426 (perp=11.193, rec=0.186, cos=0.001), tot_loss_proj:3.069 [t=0.27s]
prediction: ['[CLS] that look students way the hostilities gets imposed sobitnt caretaker makes cheat crimean waytypical. thisliga weird instead works women athletes [SEP]']
[ 600/2000] tot_loss=2.188 (perp=10.055, rec=0.176, cos=0.001), tot_loss_proj:2.860 [t=0.26s]
prediction: ['[CLS] that look teachers way the articles gets imposed so hisnt caretaker makes relatives and waytypical. thisliga weird instead works women athletes [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.162 (perp=9.975, rec=0.167, cos=0.000), tot_loss_proj:3.007 [t=0.25s]
prediction: ['[CLS] that look teachers way almost the hostilities imposed out hisnt caretaker makes relatives and waytypical. thisligatypical instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.177 (perp=10.115, rec=0.154, cos=0.000), tot_loss_proj:3.191 [t=0.27s]
prediction: ['[CLS] that look teachers way off the almost imposed outetynt caretaker makes relatives and waytypical. thisligatypical instead works women athletes [SEP]']
[ 750/2000] tot_loss=2.148 (perp=9.989, rec=0.150, cos=0.000), tot_loss_proj:3.287 [t=0.25s]
prediction: ['[CLS] the look teachers way off the almost imposed outetynt caretaker makes teachers and way more. thisligatypical instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.063 (perp=9.585, rec=0.146, cos=0.000), tot_loss_proj:3.078 [t=0.26s]
prediction: ['[CLS] the look teachers way off the almost imposed outetynt caretaker and teachers makes way more. thisligatypical instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.076 (perp=9.635, rec=0.149, cos=0.000), tot_loss_proj:2.890 [t=0.26s]
prediction: ['[CLS] the look teachers way all thetypical imposed outetynt caretaker whose teachers makes way more. thisliga almost instead works women athletes [SEP]']
[ 900/2000] tot_loss=2.110 (perp=9.908, rec=0.128, cos=0.000), tot_loss_proj:3.069 [t=0.26s]
prediction: ['[CLS] the look teachers way all thetypical imposed outetynt caretaker whose teachers makes more more. thisliga all instead works women athletes [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.079 (perp=9.756, rec=0.127, cos=0.000), tot_loss_proj:2.972 [t=0.28s]
prediction: ['[CLS] the look teachers way all thetypical imposed outetynt caretaker whose teachers makes more more. this ofliga instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.121 (perp=9.896, rec=0.141, cos=0.000), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS] the look teachers way all alltypical imposed outetynt caretaker whose teachers makes more more. this allliga instead works women athletes [SEP]']
[1050/2000] tot_loss=2.103 (perp=9.896, rec=0.124, cos=0.000), tot_loss_proj:2.974 [t=0.26s]
prediction: ['[CLS] the look teachers way all alltypical imposed outetynt caretaker whose teachers makes more more. this allliga instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.035 (perp=9.539, rec=0.127, cos=0.000), tot_loss_proj:2.886 [t=0.26s]
prediction: ['[CLS] the look teachers way all alltypical imposed outetynt teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.940 (perp=9.038, rec=0.132, cos=0.001), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] the look teachers way alletytypical imposed out all of teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
[1200/2000] tot_loss=1.929 (perp=9.038, rec=0.121, cos=0.000), tot_loss_proj:2.878 [t=0.25s]
prediction: ['[CLS] the look teachers way alletytypical imposed out all of teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.928 (perp=9.038, rec=0.120, cos=0.000), tot_loss_proj:2.875 [t=0.28s]
prediction: ['[CLS] the look teachers way alletytypical imposed out all of teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.913 (perp=8.963, rec=0.120, cos=0.000), tot_loss_proj:2.730 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out all of teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
[1350/2000] tot_loss=1.909 (perp=8.963, rec=0.116, cos=0.000), tot_loss_proj:2.729 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out all of teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.861 (perp=8.720, rec=0.116, cos=0.000), tot_loss_proj:2.833 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga instead works women athletes [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.847 (perp=8.624, rec=0.121, cos=0.000), tot_loss_proj:2.819 [t=0.25s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead women athletes [SEP]']
[1500/2000] tot_loss=1.838 (perp=8.624, rec=0.113, cos=0.000), tot_loss_proj:2.822 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead women athletes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.843 (perp=8.624, rec=0.118, cos=0.000), tot_loss_proj:2.815 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead women athletes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.839 (perp=8.624, rec=0.114, cos=0.000), tot_loss_proj:2.821 [t=0.27s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead women athletes [SEP]']
[1650/2000] tot_loss=1.845 (perp=8.624, rec=0.120, cos=0.000), tot_loss_proj:2.821 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead women athletes [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.837 (perp=8.612, rec=0.114, cos=0.000), tot_loss_proj:2.957 [t=0.25s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead athletes women [SEP]']
Attempt swap
[1750/2000] tot_loss=1.838 (perp=8.612, rec=0.115, cos=0.000), tot_loss_proj:2.955 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead athletes women [SEP]']
[1800/2000] tot_loss=1.837 (perp=8.612, rec=0.114, cos=0.000), tot_loss_proj:2.958 [t=0.27s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead athletes women [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.842 (perp=8.582, rec=0.126, cos=0.000), tot_loss_proj:2.800 [t=0.25s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more. this more allliga works instead athletes women [SEP]']
Attempt swap
[1900/2000] tot_loss=1.770 (perp=8.267, rec=0.116, cos=0.000), tot_loss_proj:2.995 [t=0.25s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more. this more all of works instead athletes women [SEP]']
[1950/2000] tot_loss=1.762 (perp=8.267, rec=0.108, cos=0.000), tot_loss_proj:2.997 [t=0.26s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more. this more all of works instead athletes women [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.739 (perp=8.133, rec=0.113, cos=0.000), tot_loss_proj:3.006 [t=0.25s]
prediction: ['[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more. this more of all works instead athletes women [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the teachers way look alletytypical imposed out of all teachers whose caretaker makes more more. this allliga works instead athletes women [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 4.545 | p: 4.545 | r: 4.545
rougeL     | fm: 39.130 | p: 39.130 | r: 39.130
rougeLsum  | fm: 39.130 | p: 39.130 | r: 39.130
r1fm+r2fm = 74.111

[Aggregate metrics]:
rouge1     | fm: 92.004 | p: 91.659 | r: 92.455
rouge2     | fm: 64.269 | p: 64.126 | r: 64.590
rougeL     | fm: 83.120 | p: 82.781 | r: 83.499
rougeLsum  | fm: 82.977 | p: 82.654 | r: 83.362
r1fm+r2fm = 156.273

input #21 time: 0:11:04 | total time: 3:07:45


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
*********************************
*********************************
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 1.9521197080612183 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 1.8905121088027954 for ['[CLS] shakespeare operation emerald hip year art mcdowell model apart league rate [SEP]']
[Init] best rec loss: 1.8834716081619263 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 1.881540298461914 for ['[CLS]berries thirds rounds exit whole reaction flux packages advertising dish habit [SEP]']
[Init] best rec loss: 1.849566102027893 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 1.8134469985961914 for ['[CLS] av waitingalis reception pillar anna deal mentionedhl etc showers [SEP]']
[Init] best rec loss: 1.7512906789779663 for ['[CLS] cloud road hey wynn under diiny stalk seduce variousour [SEP]']
[Init] best rec loss: 1.7188242673873901 for ['[CLS] dialectotte [MASK] type became designing aired replacing piece dear travel [SEP]']
[Init] best rec loss: 1.711775779724121 for ['[CLS] immortal dos standing commentarytort placehim corporal full cruisers carrier [SEP]']
[Init] best rec loss: 1.6849783658981323 for ['[CLS] sans services downstairsgar arched take network before simply dean jurgen [SEP]']
[Init] best rec loss: 1.6268218755722046 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 1.6199898719787598 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 1.6110483407974243 for ['[CLS] phoenix her laughter over function schedule chinese boarders kids set [SEP]']
[Init] best perm rec loss: 1.610538125038147 for ['[CLS] function over schedule phoenix herers chinese kids laughter board set [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.263 (perp=12.449, rec=0.755, cos=0.017), tot_loss_proj:3.991 [t=0.26s]
prediction: ['[CLS] earl. actuallyss symposium dead waste lamar ram accidentotho [SEP]']
[ 100/2000] tot_loss=3.410 (perp=13.732, rec=0.657, cos=0.007), tot_loss_proj:4.199 [t=0.24s]
prediction: ['[CLS] zane. penalpur senate else waste probability foul vehicleotho [SEP]']
[ 150/2000] tot_loss=3.319 (perp=13.446, rec=0.609, cos=0.020), tot_loss_proj:4.394 [t=0.26s]
prediction: ['[CLS] besides. positionpur gunfire hundred film tourism foul scalp intensive [SEP]']
[ 200/2000] tot_loss=2.992 (perp=11.953, rec=0.597, cos=0.005), tot_loss_proj:3.902 [t=0.25s]
prediction: ['[CLS] besides. evidencepur political hundred film tourism terms scalp failure [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.775 (perp=11.022, rec=0.569, cos=0.002), tot_loss_proj:3.844 [t=0.25s]
prediction: ['[CLS] survived film existenceily politicalchment. ® terms of failure [SEP]']
[ 300/2000] tot_loss=2.941 (perp=12.085, rec=0.521, cos=0.002), tot_loss_proj:4.161 [t=0.25s]
prediction: ['[CLS] survived film productsily genre license dozens ® terms on failure [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.819 (perp=11.552, rec=0.505, cos=0.004), tot_loss_proj:4.094 [t=0.26s]
prediction: ['[CLS] film productsily survived genre license dozens ® entirely own failure [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.880 (perp=11.911, rec=0.492, cos=0.005), tot_loss_proj:3.906 [t=0.24s]
prediction: ['[CLS] adaptation productsiest un survived career dozens ® entirely own failure [SEP]']
[ 450/2000] tot_loss=2.921 (perp=12.156, rec=0.486, cos=0.004), tot_loss_proj:3.950 [t=0.26s]
prediction: ['[CLS] adaptation scoreriest un survived career dozens ® entirely own failure [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.082 (perp=12.915, rec=0.497, cos=0.002), tot_loss_proj:4.092 [t=0.28s]
prediction: ['[CLS] adaptation productsily nothing dozens survived career ® entirely own failure [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.045 (perp=12.841, rec=0.473, cos=0.003), tot_loss_proj:4.071 [t=0.27s]
prediction: ['[CLS] adaptation products dozens nothingily monograph career ® entirely own failure [SEP]']
[ 600/2000] tot_loss=2.975 (perp=12.520, rec=0.467, cos=0.004), tot_loss_proj:4.012 [t=0.27s]
prediction: ['[CLS] adaptation products dozens nothingiest monograph career ® entirely own failure [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.134 (perp=12.752, rec=0.505, cos=0.079), tot_loss_proj:4.024 [t=0.26s]
prediction: ['[CLS] adaptation products dozens nothing survivediest career ® entirely own failure [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.920 (perp=12.349, rec=0.450, cos=0.001), tot_loss_proj:3.961 [t=0.25s]
prediction: ['[CLS] adaptation products dozens nothing appreciatediest career ® entirely own failure [SEP]']
[ 750/2000] tot_loss=2.924 (perp=12.349, rec=0.451, cos=0.003), tot_loss_proj:3.963 [t=0.25s]
prediction: ['[CLS] adaptation products dozens nothing appreciatediest career ® entirely own failure [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.857 (perp=12.089, rec=0.439, cos=0.000), tot_loss_proj:4.081 [t=0.27s]
prediction: ['[CLS] adaptation products dozens nothing appreciated careeriest ® entirely own critic [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.175 (perp=13.573, rec=0.458, cos=0.002), tot_loss_proj:4.312 [t=0.27s]
prediction: ['[CLS] adaptation products nothing relied whig dozensiest ® entirely own failure [SEP]']
[ 900/2000] tot_loss=3.275 (perp=14.195, rec=0.436, cos=0.000), tot_loss_proj:4.694 [t=0.26s]
prediction: ['[CLS] adaptation products nothing relied whig dozensiest ® entirely own critic [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.208 (perp=13.853, rec=0.437, cos=0.000), tot_loss_proj:4.539 [t=0.25s]
prediction: ['[CLS] adaptation products relied nothing whig dozensiest ® entirely own critic [SEP]']
Attempt swap
[1000/2000] tot_loss=3.129 (perp=13.383, rec=0.441, cos=0.012), tot_loss_proj:4.427 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® entirely own critic [SEP]']
[1050/2000] tot_loss=3.109 (perp=13.383, rec=0.432, cos=0.000), tot_loss_proj:4.430 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® entirely own critic [SEP]']
Attempt swap
[1100/2000] tot_loss=3.119 (perp=13.383, rec=0.426, cos=0.016), tot_loss_proj:4.427 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® entirely own critic [SEP]']
Attempt swap
[1150/2000] tot_loss=3.114 (perp=13.490, rec=0.416, cos=0.000), tot_loss_proj:4.429 [t=0.29s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® sense own critic [SEP]']
[1200/2000] tot_loss=3.127 (perp=13.490, rec=0.419, cos=0.010), tot_loss_proj:4.433 [t=0.27s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® sense own critic [SEP]']
Attempt swap
[1250/2000] tot_loss=3.089 (perp=13.338, rec=0.421, cos=0.000), tot_loss_proj:4.567 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
Attempt swap
[1300/2000] tot_loss=3.137 (perp=13.338, rec=0.447, cos=0.022), tot_loss_proj:4.565 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
[1350/2000] tot_loss=3.114 (perp=13.490, rec=0.415, cos=0.000), tot_loss_proj:4.428 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® sense own critic [SEP]']
Attempt swap
[1400/2000] tot_loss=3.079 (perp=13.338, rec=0.411, cos=0.000), tot_loss_proj:4.567 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
Attempt swap
[1450/2000] tot_loss=3.081 (perp=13.338, rec=0.414, cos=0.000), tot_loss_proj:4.565 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
[1500/2000] tot_loss=3.091 (perp=13.338, rec=0.418, cos=0.006), tot_loss_proj:4.565 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
Attempt swap
[1550/2000] tot_loss=3.080 (perp=13.338, rec=0.412, cos=0.000), tot_loss_proj:4.566 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
Attempt swap
[1600/2000] tot_loss=3.082 (perp=13.338, rec=0.414, cos=0.000), tot_loss_proj:4.565 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
[1650/2000] tot_loss=3.073 (perp=13.338, rec=0.405, cos=0.000), tot_loss_proj:4.563 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensiest ® successful own critic [SEP]']
Attempt swap
[1700/2000] tot_loss=3.125 (perp=13.566, rec=0.411, cos=0.001), tot_loss_proj:4.580 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensily ® successful own critic [SEP]']
Attempt swap
[1750/2000] tot_loss=3.126 (perp=13.566, rec=0.413, cos=0.000), tot_loss_proj:4.577 [t=0.25s]
prediction: ['[CLS] adaptation finished relied nothing career dozensily ® successful own critic [SEP]']
[1800/2000] tot_loss=3.125 (perp=13.566, rec=0.411, cos=0.000), tot_loss_proj:4.581 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensily ® successful own critic [SEP]']
Attempt swap
[1850/2000] tot_loss=3.124 (perp=13.566, rec=0.410, cos=0.000), tot_loss_proj:4.577 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensily ® successful own critic [SEP]']
Attempt swap
[1900/2000] tot_loss=3.119 (perp=13.566, rec=0.405, cos=0.001), tot_loss_proj:4.579 [t=0.26s]
prediction: ['[CLS] adaptation finished relied nothing career dozensily ® successful own critic [SEP]']
[1950/2000] tot_loss=2.941 (perp=12.643, rec=0.412, cos=0.000), tot_loss_proj:4.357 [t=0.26s]
prediction: ['[CLS] adaptation finished adaptation nothing career dozensily ® successful own critic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.933 (perp=12.643, rec=0.404, cos=0.000), tot_loss_proj:4.359 [t=0.25s]
prediction: ['[CLS] adaptation finished adaptation nothing career dozensily ® successful own critic [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] adaptation finished relied nothing career dozensily ® successful own critic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 41.667 | p: 45.455 | r: 38.462
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 33.333 | p: 36.364 | r: 30.769
rougeLsum  | fm: 33.333 | p: 36.364 | r: 30.769
r1fm+r2fm = 41.667

[Aggregate metrics]:
rouge1     | fm: 89.857 | p: 89.667 | r: 90.163
rouge2     | fm: 61.267 | p: 61.056 | r: 61.535
rougeL     | fm: 80.989 | p: 80.744 | r: 81.319
rougeLsum  | fm: 80.802 | p: 80.646 | r: 81.034
r1fm+r2fm = 151.124

input #22 time: 0:10:50 | total time: 3:18:35


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
*********************************
*********************************
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 1.383732795715332 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 1.3736612796783447 for ['[CLS] jumped its ion [MASK] deep spirit tracks controls spun donated tape calendar ineligible martial airport breaths complexvas net straight vs # jake featurebal each roots record death share troubles chance scores mate frank holding quest exactlyul governments win far ap gathering toysience married club [SEP]']
[Init] best rec loss: 1.3212342262268066 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 1.3039929866790771 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 1.2455841302871704 for ['[CLS] talent cause skirt handled ⁴ anne pieces mine! caused safety tor goal fore 2014 residents chosen offering chiefs number sun consumergementni property riding dolphin exchequerada saw occupants trades vale course kind coronation ballroom dona village totally selena winds firstd sums manga square scholar [SEP]']
[Init] best rec loss: 1.2352474927902222 for ['[CLS] drugfl vienna chop ; wound shop wonder main added founded lennox bridge gel residential rich kilometers facing countries seal adults captain wet interstate tea saved mr hawk withdrawal indeed temperaly sent daily life ₱ rail era seasons bottom champion herselfsta? context teen ready airfield [SEP]']
[Init] best perm rec loss: 1.2314822673797607 for ['[CLS] indeed champion kilometers withdrawal gel seal tea drug wonder ; founded vienna era herself ₱ added residential daily bridge sent adults airfield captain mr ready contextsta bottom seasons shop rail wet life hawkaly countries teen facing richfl lennox saved main? interstate wound temper chop [SEP]']
[Init] best perm rec loss: 1.2305387258529663 for ['[CLS] sent shop wound airfield captain wetfl vienna countries mr ready main rail seasons daily drug facing seal teen saved ; bridge adults temper added context withdrawal champion wondersta rich era kilometers bottom hawk tea residential? foundedaly indeed ₱ interstate life chop gel lennox herself [SEP]']
[Init] best perm rec loss: 1.2290924787521362 for ['[CLS] indeed ₱ facing seasonsfl rich bridge main mr gel wonder vienna founded ready champion chop hawk wet context kilometers captain life teen sent bottom saved woundaly rail era lennox withdrawal tea drug interstate temper seal residential added shop airfield daily herself countries ;sta adults? [SEP]']
[Init] best perm rec loss: 1.2287770509719849 for ['[CLS] airfield rail added hawk context indeed countries withdrawal shop rich vienna seal captain champion mr sent life temper daily gel teen tea bridge ₱ residential adults saved drugsta bottom founded lennox ready facing ; interstate woundfl kilometers wet main wonder chop seasonsaly era herself? [SEP]']
[Init] best perm rec loss: 1.2277514934539795 for ['[CLS] residential lennoxfl rich hawk captain ₱aly tea daily main drug sent viennasta facing? ; gel wound context countries temper teen shop champion seal seasons wet herself airfield adults founded saved life ready wonder mr interstate bottom era indeed chop added kilometers withdrawal bridge rail [SEP]']
[Init] best perm rec loss: 1.2267485857009888 for ['[CLS] seal ready mr captainfl rich shop drug main rail residential era gel temper saved? countries kilometers tea bottom interstate added context life bridge lennox vienna champion herself daily facing chop withdrawal adults teen indeed ₱ ; airfield woundsta seasons hawk wonder wet founded sentaly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.860 (perp=12.140, rec=0.429, cos=0.002), tot_loss_proj:3.626 [t=0.25s]
prediction: ['[CLS] outer detachment @ tunnel less ham + abandon downs have project open core editorial watershed critique earthgrowth check helping inner forcetag, pandora hemisphere vietnam project initiative moment bring focus central mission. contained steal education studied narrowingzh, americanstorm science kendra headlogic [SEP]']
[ 100/2000] tot_loss=2.638 (perp=11.502, rec=0.328, cos=0.010), tot_loss_proj:3.503 [t=0.27s]
prediction: ['[CLS] technical vietnam whose its aim siren exercise abandon sha doing project open core editorialvor parenting conferencesgrowthistle effective, force elephant in maritime ultimately vietnam project progressive liberation strategic focus withdrew objective : strategic strategic science optimal message satire, american survey science rewards head jim [SEP]']
[ 150/2000] tot_loss=2.662 (perp=11.966, rec=0.264, cos=0.005), tot_loss_proj:3.476 [t=0.26s]
prediction: ['[CLS] technical vietnam whose its picture successful exercise riddleh matt hudson the conjunction editorialvor patriotic conferences compassionateistle effective, strategiczog in without ultimately vietnam purple strategic liberation strategic its withdrew objective : strategic strategic soldiers main message comparison ; human conflict scientific originally da jim [SEP]']
[ 200/2000] tot_loss=2.447 (perp=11.024, rec=0.237, cos=0.006), tot_loss_proj:3.222 [t=0.25s]
prediction: ['[CLS] technical vietnam whose its objective the thus holeh a ultimately the conjunction editorial but patriotic touch kyoto terror of, strategiczog, without ultimately vietnam strategic strategic liberation its strategic main objective : strategic strategic soldiers main pictureizing ; cultural conflict inner originallyxa lo [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.308 (perp=10.520, rec=0.203, cos=0.002), tot_loss_proj:3.102 [t=0.26s]
prediction: ['[CLS] technical vietnam route its strategic the while hole ra a ; the its united, patriotic touch until under of, whosetag ) without ultimately vietnam strategic strategic patriotic its strategic main objective : strategic strategic soldiers main pictureizing ; cultural conflict scientific originally ja lo [SEP]']
[ 300/2000] tot_loss=2.392 (perp=11.022, rec=0.185, cos=0.003), tot_loss_proj:3.240 [t=0.35s]
prediction: ['[CLS] technical vietnam route its strategic a while holeh a ultimately the itscci, patriotic touch no under in, whosetag, without ultimately vietnam strategic strategic patriotic its strategic main objective : strategic strategic soldiers main pictureizing the generation conflict scientific originally achieve lo [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.105 (perp=9.618, rec=0.176, cos=0.005), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS] the vietnam group its strategic a while rah a ultimately the its united, patrioticvision no behind, of thetag, without ultimately vietnam strategic strategic patriotic its strategic main objective : strategic strategic soldiers main pictureizing its generation conflict strategic ultimately achieve este [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.166 (perp=10.025, rec=0.159, cos=0.002), tot_loss_proj:3.058 [t=0.26s]
prediction: ['[CLS] the vietnam group its strategic a while rah a ultimately the its united - patriotic strategic no wan, a thetag, without ultimately vietnam strategic strategic patriotic its strategic main objective : drama strategic soldiers main picturezing its generation conflict este ultimately achieve strategic [SEP]']
[ 450/2000] tot_loss=2.098 (perp=9.751, rec=0.147, cos=0.001), tot_loss_proj:2.982 [t=0.24s]
prediction: ['[CLS] the vietnam group its strategic a while rah such ultimately the its regarding - patriotic strategic tone an, to of vietnam, without ultimately vietnam strategic strategic patriotic its strategic main objective : drama strategic soldiers main picturezing its generation conflict este ultimately achieve strategic [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.150 (perp=9.998, rec=0.150, cos=0.001), tot_loss_proj:3.061 [t=0.27s]
prediction: ['[CLS] the vietnam a its strategic a while rah such ultimately the tone regarding - patriotic strategic its teach, of oftag, without achieve vietnam strategic strategic patriotic its strategic main objective : drama strategic soldiers main picturezing its generation conflict este ultimately achieve global [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.196 (perp=9.783, rec=0.227, cos=0.013), tot_loss_proj:2.937 [t=0.26s]
prediction: ['[CLS] the editor a its strategic a while rah a ;, your opposed - patriotic approach its vietnam, of of fortifications, without achieve vietnam strategic strategic patriotic environmental strategic objective objective : dramati soldiers main picturezing its generation conflict subdivided ultimately achieve global [SEP]']
[ 600/2000] tot_loss=2.190 (perp=10.182, rec=0.153, cos=0.001), tot_loss_proj:2.956 [t=0.27s]
prediction: ['[CLS] the commander a its strategic a while ra ra a ultimately,ity object - patriotic approach its vietnam, of and vietnam, without achieve vietnam strategic strategic patriotic tone strategictream objective : dramati soldiers main picturezing its generation conflict subdivided ultimatelys global [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.141 (perp=10.014, rec=0.138, cos=0.001), tot_loss_proj:2.930 [t=0.26s]
prediction: ['[CLS] the commander a its strategic a while ra ra suchh global tone object - patriotic approach its vietnam, of, conflict, without achieve vietnam strategic strategic patriotic tone strategictream objective : dramati soldiers main picturezing its generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.085 (perp=9.733, rec=0.138, cos=0.000), tot_loss_proj:2.830 [t=0.27s]
prediction: ['[CLS] theu should its strategic a while ra ra suchh global tone object - patriotic approach its vietnam, the, conflict, the achieve vietnam strategic strategic patriotic tone strategictream objective : dramati soldiers main picturezing its generation conflict subdivided ultimatelys, [SEP]']
[ 750/2000] tot_loss=2.048 (perp=9.574, rec=0.133, cos=0.000), tot_loss_proj:2.857 [t=0.25s]
prediction: ['[CLS] theu should its tone a while ra ra ah global tone object - patriotic approach its vietnam, the, patriotic, the achieve vietnam strategic strategic patriotic tone strategictream objective : dramati soldiers main picturezing, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.976 (perp=9.257, rec=0.125, cos=0.000), tot_loss_proj:2.815 [t=0.26s]
prediction: ['[CLS] theu should its tone a while ra. a ra global tone object - patriotic approach its vietnam, the, patriotic, the achieve vietnam strategic strategic patriotic tone strategictream objective : dramati soldiers main picturezing, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.900 (perp=8.866, rec=0.126, cos=0.001), tot_loss_proj:2.737 [t=0.25s]
prediction: ['[CLS] theu should its tone a while ra. a ra global tone object - patriotic approach its vietnam, the, patriotic, the achieve vietnam strategic strategic patriotic tone strategictream objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[ 900/2000] tot_loss=1.866 (perp=8.723, rec=0.121, cos=0.000), tot_loss_proj:2.789 [t=0.27s]
prediction: ['[CLS] theu will its tone a while ra. a ra global tone object - patriotic approach its vietnam, the, patriotic, the achieve vietnam strategic strategic patriotic tone strategictream objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.835 (perp=8.613, rec=0.112, cos=0.000), tot_loss_proj:2.720 [t=0.26s]
prediction: ['[CLS] theu will its tone a, while rah a ra global tone object - patriotic approach its vietnam, the patriotic, the achieve vietnam strategic strategic patriotic tone strategictream objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.796 (perp=8.407, rec=0.115, cos=0.000), tot_loss_proj:2.735 [t=0.27s]
prediction: ['[CLS] theu will its tone a, while rah a ra global strategic object - patriotic approach its vietnam, the patriotic, the achieve vietnam tone strategic patriotic tone strategictream objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[1050/2000] tot_loss=1.846 (perp=8.650, rec=0.116, cos=0.000), tot_loss_proj:2.852 [t=0.26s]
prediction: ['[CLS] theu will its tone a, while rah such ra global strategic object - patriotic approach its vietnam, the patriotic, the achieve vietnam a strategic patriotic tone strategictream objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.803 (perp=8.476, rec=0.108, cos=0.000), tot_loss_proj:2.607 [t=0.25s]
prediction: ['[CLS] theu will its tone a, while rah such ra global strategic object - patriotic tone its vietnam, the patriotic, a achieve vietnam a strategic patriotic tone strategic victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.877 (perp=8.812, rec=0.115, cos=0.000), tot_loss_proj:2.819 [t=0.25s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, a achieve vietnam as happens tone strategic victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[1200/2000] tot_loss=1.872 (perp=8.802, rec=0.111, cos=0.000), tot_loss_proj:2.808 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, a achieve vietnam itss happens tone strategic victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.843 (perp=8.658, rec=0.111, cos=0.000), tot_loss_proj:2.820 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, a achieve vietnam itss strategic tone happens victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.838 (perp=8.640, rec=0.110, cos=0.000), tot_loss_proj:2.756 [t=0.25s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, with achieve vietnam happenss strategic tone their victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[1350/2000] tot_loss=1.826 (perp=8.579, rec=0.110, cos=0.000), tot_loss_proj:2.736 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, a achieve vietnam happenss strategic tone their victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.798 (perp=8.433, rec=0.112, cos=0.000), tot_loss_proj:2.689 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, a vietnam happens achieves strategic tone their victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.797 (perp=8.423, rec=0.112, cos=0.000), tot_loss_proj:2.688 [t=0.27s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, with vietnam happens achieves strategic tone their victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[1500/2000] tot_loss=1.797 (perp=8.423, rec=0.112, cos=0.000), tot_loss_proj:2.682 [t=0.27s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, with vietnam happens achieves strategic tone their victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.768 (perp=8.327, rec=0.102, cos=0.000), tot_loss_proj:2.673 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, strategic vietnam happens achieves a tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.757 (perp=8.230, rec=0.111, cos=0.000), tot_loss_proj:2.639 [t=0.28s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, strategic vietnam happens achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[1650/2000] tot_loss=1.756 (perp=8.230, rec=0.110, cos=0.000), tot_loss_proj:2.637 [t=0.25s]
prediction: ['[CLS] theu will its tone a while, rah such ra global strategic object - patriotic tone its vietnam, the patriotic, strategic vietnam happens achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.745 (perp=8.190, rec=0.107, cos=0.000), tot_loss_proj:2.656 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - patriotic tone its vietnam, the patriotic global strategic vietnam happens achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.742 (perp=8.190, rec=0.104, cos=0.000), tot_loss_proj:2.656 [t=0.25s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - patriotic tone its vietnam, the patriotic global strategic vietnam happens achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
[1800/2000] tot_loss=1.722 (perp=8.083, rec=0.106, cos=0.000), tot_loss_proj:2.628 [t=0.28s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - patriotic tone its vietnam, the patriotic global strategic vietnam patriotic achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.717 (perp=8.053, rec=0.107, cos=0.000), tot_loss_proj:2.601 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - its patriotic tone vietnam, the patriotic global strategic vietnam patriotic achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.703 (perp=7.966, rec=0.110, cos=0.000), tot_loss_proj:2.546 [t=0.27s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - its patriotic tone vietnam, the patriotic picture strategic vietnam patriotic achieves with tone the victim objective : dramatizing soldiers main global, generation conflict subdivided ultimatelys, [SEP]']
[1950/2000] tot_loss=1.699 (perp=7.966, rec=0.106, cos=0.000), tot_loss_proj:2.544 [t=0.26s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - its patriotic tone vietnam, the patriotic picture strategic vietnam patriotic achieves with tone the victim objective : dramatizing soldiers main global, generation conflict subdivided ultimatelys, [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.736 (perp=8.141, rec=0.108, cos=0.000), tot_loss_proj:2.528 [t=0.27s]
prediction: ['[CLS] theu will its tone a while, rah such ra, strategic object - its patriotic tone global, the patriotic picture strategic vietnam happens achieves with tone the victim objective : dramatizing soldiers main vietnam the generation conflict subdivided ultimatelys, [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] theu will its tone a while, rah such ra, strategic object - its patriotic tone vietnam, the patriotic global strategic vietnam happens achieves with tone the victim objective : dramatizing soldiers main picture, generation conflict subdivided ultimatelys, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.338 | p: 64.865 | r: 60.000
rouge2     | fm: 5.333 | p: 5.556 | r: 5.128
rougeL     | fm: 28.571 | p: 29.730 | r: 27.500
rougeLsum  | fm: 28.571 | p: 29.730 | r: 27.500
r1fm+r2fm = 67.671

[Aggregate metrics]:
rouge1     | fm: 88.657 | p: 88.573 | r: 88.842
rouge2     | fm: 58.721 | p: 58.553 | r: 59.059
rougeL     | fm: 78.830 | p: 78.737 | r: 78.928
rougeLsum  | fm: 78.317 | p: 78.211 | r: 78.664
r1fm+r2fm = 147.379

input #23 time: 0:11:05 | total time: 3:29:41


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
*********************************
*********************************
average of cosine similarity 0.9993537840940759
highest_index [0]
highest [0.9993537840940759]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 1.825258493423462 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 1.6625887155532837 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 1.662034034729004 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 1.638895034790039 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 1.3410228490829468 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 1.323185920715332 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 1.1163339614868164 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 1.1137642860412598 for ['[CLS] bondwyl unless county em arms damned happy suffer play attack younger ryu midaneous bush snow village no port [SEP]']
[Init] best perm rec loss: 1.1134698390960693 for ['[CLS] unless play younger ryu attack village no mid damned portwyl happy suffer arms em snow bush bond countyaneous [SEP]']
[Init] best perm rec loss: 1.1096725463867188 for ['[CLS] attack unless em arms happywyl bond mid younger play snow villageaneous no county damned ryu suffer port bush [SEP]']
[Init] best perm rec loss: 1.1079434156417847 for ['[CLS] mid unless ryu play attack nowyl em younger countyaneous bond village happy damned snow bush port suffer arms [SEP]']
[Init] best perm rec loss: 1.107871174812317 for ['[CLS] suffer happy em younger play ryu no mid bond unless snow bush armsaneous damned attack countywyl village port [SEP]']
[Init] best perm rec loss: 1.1060388088226318 for ['[CLS] bond play damned unless county younger no midwyl em attack ryu village snow armsaneous happy bush suffer port [SEP]']
[Init] best perm rec loss: 1.1028209924697876 for ['[CLS] playwyl county em no mid arms bond bush damned snow unless happy ryu younger attack suffer village portaneous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.774 (perp=11.723, rec=0.426, cos=0.004), tot_loss_proj:3.310 [t=0.26s]
prediction: ['[CLS] armedtated [SEP] stupid aids drug allegedly drug funds¤ against unlessat! coupa drug were hands armed [SEP]']
[ 100/2000] tot_loss=2.625 (perp=11.407, rec=0.342, cos=0.001), tot_loss_proj:3.204 [t=0.27s]
prediction: ['[CLS] campeonato taken [SEP] evil moral. countries drug judge¤ paste takenat! terrorists government leader the terrorists knew [SEP]']
[ 150/2000] tot_loss=2.587 (perp=11.448, rec=0.296, cos=0.002), tot_loss_proj:3.201 [t=0.26s]
prediction: ['[CLS] sc taken outside evil political. countries drug slightly¤ paste takenat! evil tech leader the terrorists knew [SEP]']
[ 200/2000] tot_loss=2.511 (perp=11.297, rec=0.248, cos=0.003), tot_loss_proj:3.149 [t=0.27s]
prediction: ['[CLS] bills taken outside evil political. context violent slightly¤ various taken innocent! evil tech of the laws surroundings [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.169 (perp=9.614, rec=0.244, cos=0.003), tot_loss_proj:2.847 [t=0.26s]
prediction: ['[CLS] cent taken the evil political. context drug slightly outside context taken (! evil the outside the political context [SEP]']
[ 300/2000] tot_loss=1.998 (perp=9.012, rec=0.195, cos=0.000), tot_loss_proj:2.690 [t=0.27s]
prediction: ['[CLS] : taken the evil political. context political current outside context taken (! evil attack outside the terrorists context [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.885 (perp=8.447, rec=0.190, cos=0.006), tot_loss_proj:2.542 [t=0.27s]
prediction: ['[CLS] : taken the evil political current outside political. context context taken (! evil attack outside the terrorists context [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.922 (perp=8.733, rec=0.175, cos=0.001), tot_loss_proj:2.534 [t=0.26s]
prediction: ['[CLS] : taken the political political current climate evil ) context current taken (! evil attack outside the terrorists context [SEP]']
[ 450/2000] tot_loss=1.968 (perp=9.027, rec=0.162, cos=0.000), tot_loss_proj:2.529 [t=0.28s]
prediction: ['[CLS] : taken the political political are climate evil ) context current taken (! evil attack outside the terrorists context [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.845 (perp=8.434, rec=0.157, cos=0.001), tot_loss_proj:2.394 [t=0.26s]
prediction: ['[CLS] : taken the political political climate are evil ) context current taken (! evil terrorists outside the terrorists context [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.790 (perp=8.139, rec=0.162, cos=0.001), tot_loss_proj:2.344 [t=0.27s]
prediction: ['[CLS] : taken the political political climate are evil ) context terrorists taken (! evil terrorists outside the current context [SEP]']
[ 600/2000] tot_loss=1.824 (perp=8.356, rec=0.152, cos=0.000), tot_loss_proj:2.366 [t=0.26s]
prediction: ['[CLS] : taken the political of climate are evil ) context terrorists taken (! evil terrorists outside the current context [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.741 (perp=7.994, rec=0.142, cos=0.000), tot_loss_proj:2.301 [t=0.26s]
prediction: ['[CLS] : taken the climate of political are evil ) context terrorists taken (! evil terrorists outside the current context [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.670 (perp=7.550, rec=0.158, cos=0.002), tot_loss_proj:2.226 [t=0.27s]
prediction: ['[CLS] : taken the climate of political evil : context terrorists taken (! are evil terrorists outside the current context [SEP]']
[ 750/2000] tot_loss=1.652 (perp=7.550, rec=0.142, cos=0.000), tot_loss_proj:2.215 [t=0.27s]
prediction: ['[CLS] : taken the climate of political evil : context terrorists taken (! are evil terrorists outside the current context [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.623 (perp=7.380, rec=0.147, cos=0.000), tot_loss_proj:2.195 [t=0.27s]
prediction: ['[CLS] : taken the climate of political evil : context terrorists ( taken! are evil terrorists outside the current context [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.579 (perp=7.214, rec=0.135, cos=0.000), tot_loss_proj:2.163 [t=0.25s]
prediction: ['[CLS] : taken the climate of political evil terrorists context : ( taken! are evil terrorists outside the current context [SEP]']
[ 900/2000] tot_loss=1.582 (perp=7.214, rec=0.139, cos=0.000), tot_loss_proj:2.164 [t=0.26s]
prediction: ['[CLS] : taken the climate of political evil terrorists context : ( taken! are evil terrorists outside the current context [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.601 (perp=7.323, rec=0.136, cos=0.000), tot_loss_proj:2.163 [t=0.27s]
prediction: ['[CLS] : taken the climate of evil terrorists political context ) ( taken! are evil terrorists outside the current context [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.568 (perp=7.114, rec=0.145, cos=0.000), tot_loss_proj:2.090 [t=0.26s]
prediction: ['[CLS] : taken the climate of evil ) political context terrorists ( taken! are evil terrorists outside the current context [SEP]']
[1050/2000] tot_loss=1.562 (perp=7.114, rec=0.139, cos=0.000), tot_loss_proj:2.097 [t=0.27s]
prediction: ['[CLS] : taken the climate of evil ) political context terrorists ( taken! are evil terrorists outside the current context [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.542 (perp=7.013, rec=0.139, cos=0.000), tot_loss_proj:2.067 [t=0.26s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1150/2000] tot_loss=1.542 (perp=7.013, rec=0.139, cos=0.000), tot_loss_proj:2.072 [t=0.27s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
[1200/2000] tot_loss=1.536 (perp=7.013, rec=0.134, cos=0.000), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1250/2000] tot_loss=1.542 (perp=7.013, rec=0.139, cos=0.000), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1300/2000] tot_loss=1.542 (perp=7.013, rec=0.140, cos=0.000), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
[1350/2000] tot_loss=1.544 (perp=7.013, rec=0.141, cos=0.000), tot_loss_proj:2.075 [t=0.27s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1400/2000] tot_loss=1.538 (perp=7.013, rec=0.135, cos=0.000), tot_loss_proj:2.068 [t=0.26s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1450/2000] tot_loss=1.529 (perp=7.013, rec=0.127, cos=0.000), tot_loss_proj:2.073 [t=0.28s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
[1500/2000] tot_loss=1.543 (perp=7.013, rec=0.140, cos=0.000), tot_loss_proj:2.070 [t=0.27s]
prediction: ['[CLS] : taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1550/2000] tot_loss=1.618 (perp=7.407, rec=0.137, cos=0.000), tot_loss_proj:2.218 [t=0.26s]
prediction: ['[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1600/2000] tot_loss=1.619 (perp=7.407, rec=0.137, cos=0.000), tot_loss_proj:2.213 [t=0.27s]
prediction: ['[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
[1650/2000] tot_loss=1.621 (perp=7.407, rec=0.139, cos=0.000), tot_loss_proj:2.221 [t=0.26s]
prediction: ['[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1700/2000] tot_loss=1.623 (perp=7.407, rec=0.141, cos=0.000), tot_loss_proj:2.218 [t=0.27s]
prediction: ['[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
[1750/2000] tot_loss=1.616 (perp=7.407, rec=0.134, cos=0.000), tot_loss_proj:2.216 [t=0.26s]
prediction: ['[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
[1800/2000] tot_loss=1.614 (perp=7.407, rec=0.132, cos=0.000), tot_loss_proj:2.214 [t=0.25s]
prediction: ['[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.521 (perp=6.911, rec=0.139, cos=0.000), tot_loss_proj:2.100 [t=0.30s]
prediction: ['[CLS] see taken the climate of evil political context ( terrorists taken! are evil terrorists outside the current context ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.521 (perp=6.911, rec=0.138, cos=0.000), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] see taken the climate of evil political context ( terrorists taken! are evil terrorists outside the current context ) [SEP]']
[1950/2000] tot_loss=1.512 (perp=6.911, rec=0.130, cos=0.000), tot_loss_proj:2.096 [t=0.26s]
prediction: ['[CLS] see taken the climate of evil political context ( terrorists taken! are evil terrorists outside the current context ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.514 (perp=6.911, rec=0.132, cos=0.000), tot_loss_proj:2.091 [t=0.26s]
prediction: ['[CLS] see taken the climate of evil political context ( terrorists taken! are evil terrorists outside the current context ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] see taken the climate of evil ) political context ( terrorists taken! are evil terrorists outside the current context [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.081 | p: 78.947 | r: 83.333
rouge2     | fm: 11.429 | p: 11.111 | r: 11.765
rougeL     | fm: 48.649 | p: 47.368 | r: 50.000
rougeLsum  | fm: 48.649 | p: 47.368 | r: 50.000
r1fm+r2fm = 92.510

[Aggregate metrics]:
rouge1     | fm: 88.375 | p: 88.285 | r: 88.647
rouge2     | fm: 57.215 | p: 57.035 | r: 57.338
rougeL     | fm: 77.883 | p: 77.654 | r: 78.091
rougeLsum  | fm: 77.357 | p: 77.138 | r: 77.640
r1fm+r2fm = 145.589

input #24 time: 0:11:06 | total time: 3:40:47


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
*********************************
*********************************
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 2.0016868114471436 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 1.8594616651535034 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 1.7197651863098145 for ['[CLS] merit delaney canoniary [SEP]']
[Init] best rec loss: 1.7120318412780762 for ['[CLS] executive into females he [SEP]']
[Init] best rec loss: 1.6727626323699951 for ['[CLS] james adding letters received [SEP]']
[Init] best rec loss: 1.6727566719055176 for ['[CLS] frequent gailez bane [SEP]']
[Init] best rec loss: 1.5321781635284424 for ['[CLS] mention acre old headline [SEP]']
[Init] best rec loss: 1.4170466661453247 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best rec loss: 1.3436115980148315 for ['[CLS] hide a seal mess [SEP]']
[Init] best perm rec loss: 1.3427221775054932 for ['[CLS] seal a mess hide [SEP]']
[Init] best perm rec loss: 1.3401399850845337 for ['[CLS] mess hide a seal [SEP]']
[Init] best perm rec loss: 1.3389146327972412 for ['[CLS] mess a hide seal [SEP]']
[Init] best perm rec loss: 1.3344050645828247 for ['[CLS] mess hide seal a [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.786 (perp=12.281, rec=0.323, cos=0.006), tot_loss_proj:2.917 [t=0.20s]
prediction: ['[CLS] beautiful wow novel mysterious [SEP]']
[ 100/2000] tot_loss=1.932 (perp=8.708, rec=0.188, cos=0.002), tot_loss_proj:2.015 [t=0.21s]
prediction: ['[CLS] beautiful strange film beautiful [SEP]']
[ 150/2000] tot_loss=1.879 (perp=8.708, rec=0.135, cos=0.002), tot_loss_proj:2.024 [t=0.20s]
prediction: ['[CLS] beautiful strange film beautiful [SEP]']
[ 200/2000] tot_loss=1.873 (perp=8.708, rec=0.130, cos=0.002), tot_loss_proj:2.020 [t=0.20s]
prediction: ['[CLS] beautiful strange film beautiful [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.585 (perp=7.298, rec=0.124, cos=0.002), tot_loss_proj:1.760 [t=0.21s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
[ 300/2000] tot_loss=1.569 (perp=7.298, rec=0.108, cos=0.002), tot_loss_proj:1.767 [t=0.21s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.567 (perp=7.298, rec=0.106, cos=0.001), tot_loss_proj:1.761 [t=0.24s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.555 (perp=7.298, rec=0.094, cos=0.001), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
[ 450/2000] tot_loss=1.548 (perp=7.298, rec=0.087, cos=0.001), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.498 (perp=7.104, rec=0.076, cos=0.001), tot_loss_proj:1.628 [t=0.26s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.400 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.432 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.426 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.434 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.392 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.433 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.399 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.434 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.432 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.435 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.435 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.443 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.431 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.436 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.439 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.392 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.432 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.398 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.438 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.400 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.429 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.445 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.438 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.398 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.446 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.386 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.426 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.441 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.426 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.392 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.435 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.646, rec=0.075, cos=0.001), tot_loss_proj:1.434 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.438 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.444 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.398 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.448 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.435 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.383 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.429 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.386 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.433 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.434 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.851 | p: 88.689 | r: 89.024
rouge2     | fm: 58.446 | p: 58.309 | r: 58.679
rougeL     | fm: 78.493 | p: 78.293 | r: 78.771
rougeLsum  | fm: 78.124 | p: 77.955 | r: 78.319
r1fm+r2fm = 147.297

input #25 time: 0:10:23 | total time: 3:51:11


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
*********************************
*********************************
average of cosine similarity 0.9992061826546765
highest_index [0]
highest [0.9992061826546765]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 1.9023979902267456 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 1.8645083904266357 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 1.7954801321029663 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 1.7904412746429443 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 1.65139901638031 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 1.6358462572097778 for ['[CLS]sed benedict later housing why surroundingpinegrave nat use amount cast thy scored pattern run unknown authority travellingflict quotes guest lucan [SEP]']
[Init] best rec loss: 1.62001371383667 for ['[CLS] inter disappointed fiveiel 3 the airline whisperingar kelsey score chi kept dvduting cubs really casedrop4 commons due hayes [SEP]']
[Init] best rec loss: 1.5167450904846191 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 1.514949917793274 for ['[CLS] stakekar passing rides 65 turns speak mutant montrose capacity rid fur unite button riceª ak occupied cher following fully igo [SEP]']
[Init] best rec loss: 1.5008208751678467 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 1.4985138177871704 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 1.4953454732894897 for ['[CLS] theoretical list polishᆼ officers colonial s disciplinetead octave usually merely four souls arrowkan death constituencies shot iso more fourth door [SEP]']
[Init] best perm rec loss: 1.4886966943740845 for ['[CLS] colonial s four soulskan octavetead death moreᆼ list polish shot door arrow officers usually theoretical fourth discipline constituencies iso merely [SEP]']
[Init] best perm rec loss: 1.485183835029602 for ['[CLS] shot polish constituencies theoretical arrow merelyᆼ usually souls officerskan octave list door colonial fourth iso s death discipline four moretead [SEP]']
[Init] best perm rec loss: 1.4836591482162476 for ['[CLS] polish list merely fourkan octaveᆼ souls usually constituencies iso officers arrow s discipline shot colonial moretead death fourth door theoretical [SEP]']
[Init] best perm rec loss: 1.4816036224365234 for ['[CLS] s merely colonial doorkan fourth polish souls four officers death usually arrow shot moretead list octave iso constituencies discipline theoreticalᆼ [SEP]']
[Init] best perm rec loss: 1.47699773311615 for ['[CLS] fourᆼ polishtead shot usually octave discipline souls s death door merely officers list arrow more fourth iso constituencieskan colonial theoretical [SEP]']
[Init] best perm rec loss: 1.4744471311569214 for ['[CLS] iso death arrow s list polish usually four door more merelykan discipline colonial octave constituenciestead shot fourth officersᆼ souls theoretical [SEP]']
[Init] best perm rec loss: 1.4727554321289062 for ['[CLS] list shotᆼ death door iso constituencies fourth s officers four merely octave moreteadkan colonial arrow usually discipline polish souls theoretical [SEP]']
[Init] best perm rec loss: 1.4687553644180298 for ['[CLS] discipline constituencies shotkan merely arrowᆼ four polishtead iso s list officers death usually door octave fourth more souls colonial theoretical [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.906 (perp=12.836, rec=0.336, cos=0.002), tot_loss_proj:3.179 [t=0.24s]
prediction: ['[CLS] biased death italianing youtube under less franco drivers crap 2012 pointless issued check leaving empty sick inappropriatebi / money ranked dull [SEP]']
[ 100/2000] tot_loss=2.961 (perp=13.523, rec=0.256, cos=0.001), tot_loss_proj:3.361 [t=0.25s]
prediction: ['[CLS] sudden british italianing pointless ipod writer franco drivers crap import pointless issued mean from empty un importbiught car foreign low [SEP]']
[ 150/2000] tot_loss=2.590 (perp=11.830, rec=0.223, cos=0.001), tot_loss_proj:3.005 [t=0.28s]
prediction: ['[CLS] mean british frenching pointless ipod import franco drivers - import pointless age mean from empty un import tu sophie - foreign low [SEP]']
[ 200/2000] tot_loss=2.200 (perp=10.008, rec=0.197, cos=0.001), tot_loss_proj:2.660 [t=0.27s]
prediction: ['[CLS] mean french importing pointless coming import french drivers - import pointless age mean from marked of import 1 sophie - foreign low [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.453 (perp=11.315, rec=0.189, cos=0.001), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] mean ) import and pointless coming coming french scent - import pointless coming mean from cast writer import 1 sophie - foreign low [SEP]']
[ 300/2000] tot_loss=2.202 (perp=10.201, rec=0.161, cos=0.001), tot_loss_proj:2.680 [t=0.25s]
prediction: ['[CLS] mean ) import and pointless coming - french scent - french pointless coming mean from cast writer import 1 age - foreign low [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.063 (perp=9.574, rec=0.147, cos=0.000), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] mean ) import and pointless american - french - - french pointless coming mean from 1 writer import sophie anne - age low [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.038 (perp=9.464, rec=0.145, cos=0.000), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] mean ) pointless and import american of french - - french pointless coming mean from this writer import sophie anne - age low [SEP]']
[ 450/2000] tot_loss=2.259 (perp=10.688, rec=0.121, cos=0.000), tot_loss_proj:2.806 [t=0.26s]
prediction: ['[CLS] mean ) pointlessder import american age french of - french pointless coming mean from this writer age sophie anne sophie age low [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.140 (perp=10.158, rec=0.108, cos=0.000), tot_loss_proj:2.623 [t=0.26s]
prediction: ['[CLS] mean ) pointless and import american age french of - french pointless coming mean from this writer import sophie anne sophie age low [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.139 (perp=10.204, rec=0.098, cos=0.001), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] ) pointless mean and import american age french of - french pointless coming mean from this director import sophie anne sophie age low [SEP]']
[ 600/2000] tot_loss=2.053 (perp=9.839, rec=0.084, cos=0.000), tot_loss_proj:2.572 [t=0.26s]
prediction: ['[CLS] ) pointless mean and import american age - of - french pointless coming mean from this director import sophie anne sophie - low [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.002 (perp=9.595, rec=0.083, cos=0.000), tot_loss_proj:2.514 [t=0.26s]
prediction: ['[CLS] ) pointless mean and american import age - of - french pointless coming mean from this director import sophie anne sophie - low [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.038 (perp=9.817, rec=0.075, cos=0.000), tot_loss_proj:2.510 [t=0.29s]
prediction: ['[CLS] ) pointless mean and americander age of - french - pointless coming mean from this director import sophie anne sophie - low [SEP]']
[ 750/2000] tot_loss=2.108 (perp=10.090, rec=0.090, cos=0.000), tot_loss_proj:2.580 [t=0.25s]
prediction: ['[CLS] ) pointlessder and americander age of - french - pointless coming mean from this director import sophie anne sophie - low [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.091 (perp=10.028, rec=0.085, cos=0.000), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS]der pointless ) and americander age of - french - pointless coming mean from this director import writer anne sophie - low [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.985 (perp=9.462, rec=0.093, cos=0.000), tot_loss_proj:2.435 [t=0.27s]
prediction: ['[CLS]der pointless ) and americander age of - french - pointless coming mean from this director - import writer anne sophie low [SEP]']
[ 900/2000] tot_loss=1.982 (perp=9.462, rec=0.089, cos=0.000), tot_loss_proj:2.429 [t=0.26s]
prediction: ['[CLS]der pointless ) and americander age of - french - pointless coming mean from this director - import writer anne sophie low [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.841 (perp=8.762, rec=0.089, cos=0.000), tot_loss_proj:2.275 [t=0.25s]
prediction: ['[CLS]der pointless ) and americander of age - french - pointless coming mean from this director - import writer anne sophie low [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.873 (perp=8.923, rec=0.088, cos=0.000), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS]der pointless ) and americander of age - - french pointless coming mean from this director - import writer anne sophie odd [SEP]']
[1050/2000] tot_loss=1.864 (perp=8.923, rec=0.080, cos=0.000), tot_loss_proj:2.344 [t=0.26s]
prediction: ['[CLS]der pointless ) and americander of age - - french pointless coming mean from this director - import writer anne sophie odd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.871 (perp=8.923, rec=0.086, cos=0.000), tot_loss_proj:2.345 [t=0.29s]
prediction: ['[CLS]der pointless ) and americander of age - - french pointless coming mean from this director - import writer anne sophie odd [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.863 (perp=8.917, rec=0.080, cos=0.000), tot_loss_proj:2.341 [t=0.26s]
prediction: ['[CLS]der pointless ) and frenchder of age - - american pointless coming mean from this director - import writer anne sophie odd [SEP]']
[1200/2000] tot_loss=1.873 (perp=8.917, rec=0.090, cos=0.000), tot_loss_proj:2.346 [t=0.27s]
prediction: ['[CLS]der pointless ) and frenchder of age - - american pointless coming mean from this director - import writer anne sophie odd [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.818 (perp=8.680, rec=0.082, cos=0.000), tot_loss_proj:2.260 [t=0.26s]
prediction: ['[CLS]der pointless ) and frenchder of age - - - pointless coming mean from this director - import odd writer anne sophie [SEP]']
Attempt swap
[1300/2000] tot_loss=1.815 (perp=8.680, rec=0.079, cos=0.000), tot_loss_proj:2.261 [t=0.26s]
prediction: ['[CLS]der pointless ) and frenchder of age - - - pointless coming mean from this director - import odd writer anne sophie [SEP]']
[1350/2000] tot_loss=1.824 (perp=8.680, rec=0.088, cos=0.000), tot_loss_proj:2.261 [t=0.25s]
prediction: ['[CLS]der pointless ) and frenchder of age - - - pointless coming mean from this director - import odd writer anne sophie [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.781 (perp=8.539, rec=0.073, cos=0.000), tot_loss_proj:2.230 [t=0.27s]
prediction: ['[CLS]der pointless ) and frenchder of age - - - coming pointless mean from this director - import odd writer anne sophie [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.728 (perp=8.200, rec=0.088, cos=0.000), tot_loss_proj:2.172 [t=0.26s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming pointless mean from this director - import french writer anne sophie [SEP]']
[1500/2000] tot_loss=1.723 (perp=8.200, rec=0.083, cos=0.000), tot_loss_proj:2.177 [t=0.25s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming pointless mean from this director - import french writer anne sophie [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.661 (perp=7.945, rec=0.071, cos=0.000), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]']
Attempt swap
[1600/2000] tot_loss=1.668 (perp=7.945, rec=0.079, cos=0.000), tot_loss_proj:2.164 [t=0.26s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]']
[1650/2000] tot_loss=1.675 (perp=7.945, rec=0.086, cos=0.000), tot_loss_proj:2.167 [t=0.26s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.672 (perp=7.945, rec=0.082, cos=0.000), tot_loss_proj:2.167 [t=0.26s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]']
Attempt swap
[1750/2000] tot_loss=1.665 (perp=7.945, rec=0.076, cos=0.000), tot_loss_proj:2.161 [t=0.28s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]']
[1800/2000] tot_loss=1.675 (perp=7.945, rec=0.086, cos=0.000), tot_loss_proj:2.161 [t=0.27s]
prediction: ['[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]']
Attempt swap
[1850/2000] tot_loss=1.875 (perp=8.990, rec=0.077, cos=0.000), tot_loss_proj:2.379 [t=0.26s]
prediction: ['[CLS]der pointless ) and doubleder of age - -rot coming mean pointless from this director - import french writer anne sophie [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.783 (perp=8.489, rec=0.084, cos=0.001), tot_loss_proj:2.233 [t=0.27s]
prediction: ['[CLS]der pointless ) and doublerotder of age - - coming mean pointless from this director - import french writer anne sophie [SEP]']
[1950/2000] tot_loss=1.782 (perp=8.489, rec=0.084, cos=0.000), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS]der pointless ) and doublerotder of age - - coming mean pointless from this director - import french writer anne sophie [SEP]']
Attempt swap
[2000/2000] tot_loss=1.782 (perp=8.489, rec=0.084, cos=0.000), tot_loss_proj:2.239 [t=0.27s]
prediction: ['[CLS]der pointless ) and doublerotder of age - - coming mean pointless from this director - import french writer anne sophie [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS]der pointless ) and doubleder of age - - - coming mean pointless from this director - import french writer anne sophie [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 78.947 | r: 88.235
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 50.000 | p: 47.368 | r: 52.941
rougeLsum  | fm: 50.000 | p: 47.368 | r: 52.941
r1fm+r2fm = 95.098

[Aggregate metrics]:
rouge1     | fm: 88.574 | p: 88.247 | r: 89.047
rouge2     | fm: 56.850 | p: 56.654 | r: 57.160
rougeL     | fm: 77.257 | p: 76.979 | r: 77.736
rougeLsum  | fm: 76.992 | p: 76.678 | r: 77.448
r1fm+r2fm = 145.424

input #26 time: 0:11:05 | total time: 4:02:16


Running input #27 of 100.
reference: 
========================
are so generic 
========================
*********************************
*********************************
average of cosine similarity 0.9993452360030666
highest_index [0]
highest [0.9993452360030666]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 1.9401098489761353 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 1.9116452932357788 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 1.8886722326278687 for ['[CLS] estate kiss ale [SEP]']
[Init] best rec loss: 1.8630187511444092 for ['[CLS] heel clinical birth [SEP]']
[Init] best rec loss: 1.6387312412261963 for ['[CLS] and universal universe [SEP]']
[Init] best rec loss: 1.5562210083007812 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 1.4637377262115479 for ['[CLS] part portion mid [SEP]']
[Init] best rec loss: 1.3929609060287476 for ['[CLS] fat mattream [SEP]']
[Init] best rec loss: 1.2099963426589966 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 1.209096074104309 for ['[CLS] transitwine given [SEP]']
[Init] best perm rec loss: 1.2082395553588867 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.567 (perp=13.685, rec=0.812, cos=0.018), tot_loss_proj:4.559 [t=0.25s]
prediction: ['[CLS] katrina provided shakes [SEP]']
[ 100/2000] tot_loss=3.426 (perp=13.123, rec=0.761, cos=0.040), tot_loss_proj:4.510 [t=0.25s]
prediction: ['[CLS]cablerri lawn [SEP]']
[ 150/2000] tot_loss=2.739 (perp=10.328, rec=0.660, cos=0.014), tot_loss_proj:2.614 [t=0.24s]
prediction: ['[CLS] yer " generic [SEP]']
[ 200/2000] tot_loss=2.459 (perp=9.153, rec=0.620, cos=0.009), tot_loss_proj:2.337 [t=0.25s]
prediction: ['[CLS] generic " generic [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.748 (perp=10.501, rec=0.642, cos=0.005), tot_loss_proj:2.601 [t=0.26s]
prediction: ['[CLS] generic generic are [SEP]']
[ 300/2000] tot_loss=2.694 (perp=10.501, rec=0.591, cos=0.002), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.701 (perp=10.501, rec=0.579, cos=0.022), tot_loss_proj:2.603 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.934 (perp=10.501, rec=0.696, cos=0.138), tot_loss_proj:2.598 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
[ 450/2000] tot_loss=2.709 (perp=10.501, rec=0.607, cos=0.001), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.671 (perp=10.501, rec=0.569, cos=0.001), tot_loss_proj:2.604 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.652 (perp=10.501, rec=0.547, cos=0.005), tot_loss_proj:2.602 [t=0.27s]
prediction: ['[CLS] generic generic are [SEP]']
[ 600/2000] tot_loss=2.660 (perp=10.501, rec=0.554, cos=0.006), tot_loss_proj:2.606 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.668 (perp=10.501, rec=0.558, cos=0.009), tot_loss_proj:2.597 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.659 (perp=10.501, rec=0.549, cos=0.010), tot_loss_proj:2.604 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
[ 750/2000] tot_loss=2.835 (perp=11.309, rec=0.556, cos=0.017), tot_loss_proj:2.751 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.787 (perp=11.309, rec=0.524, cos=0.002), tot_loss_proj:2.755 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.787 (perp=11.309, rec=0.521, cos=0.004), tot_loss_proj:2.757 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
[ 900/2000] tot_loss=2.791 (perp=11.309, rec=0.527, cos=0.001), tot_loss_proj:2.756 [t=0.27s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.795 (perp=11.309, rec=0.532, cos=0.002), tot_loss_proj:2.751 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1000/2000] tot_loss=2.782 (perp=11.309, rec=0.519, cos=0.001), tot_loss_proj:2.757 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
[1050/2000] tot_loss=2.809 (perp=11.309, rec=0.540, cos=0.008), tot_loss_proj:2.753 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1100/2000] tot_loss=2.777 (perp=11.309, rec=0.514, cos=0.001), tot_loss_proj:2.758 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1150/2000] tot_loss=2.771 (perp=11.309, rec=0.509, cos=0.000), tot_loss_proj:2.753 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
[1200/2000] tot_loss=2.772 (perp=11.309, rec=0.510, cos=0.001), tot_loss_proj:2.754 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1250/2000] tot_loss=2.773 (perp=11.309, rec=0.511, cos=0.001), tot_loss_proj:2.746 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1300/2000] tot_loss=2.769 (perp=11.309, rec=0.506, cos=0.001), tot_loss_proj:2.747 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
[1350/2000] tot_loss=2.771 (perp=11.309, rec=0.508, cos=0.001), tot_loss_proj:2.744 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1400/2000] tot_loss=2.789 (perp=11.309, rec=0.519, cos=0.008), tot_loss_proj:2.757 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1450/2000] tot_loss=2.769 (perp=11.309, rec=0.507, cos=0.001), tot_loss_proj:2.753 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
[1500/2000] tot_loss=2.762 (perp=11.309, rec=0.500, cos=0.000), tot_loss_proj:2.758 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1550/2000] tot_loss=2.769 (perp=11.309, rec=0.506, cos=0.000), tot_loss_proj:2.749 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1600/2000] tot_loss=2.764 (perp=11.309, rec=0.501, cos=0.001), tot_loss_proj:2.758 [t=0.27s]
prediction: ['[CLS] generic generic so [SEP]']
[1650/2000] tot_loss=2.768 (perp=11.309, rec=0.505, cos=0.000), tot_loss_proj:2.758 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1700/2000] tot_loss=2.759 (perp=11.309, rec=0.497, cos=0.000), tot_loss_proj:2.751 [t=0.28s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1750/2000] tot_loss=2.763 (perp=11.309, rec=0.501, cos=0.000), tot_loss_proj:2.750 [t=0.24s]
prediction: ['[CLS] generic generic so [SEP]']
[1800/2000] tot_loss=2.769 (perp=11.309, rec=0.506, cos=0.000), tot_loss_proj:2.747 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1850/2000] tot_loss=2.769 (perp=11.309, rec=0.507, cos=0.000), tot_loss_proj:2.756 [t=0.27s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[1900/2000] tot_loss=2.762 (perp=11.309, rec=0.500, cos=0.000), tot_loss_proj:2.756 [t=0.24s]
prediction: ['[CLS] generic generic so [SEP]']
[1950/2000] tot_loss=2.759 (perp=11.309, rec=0.496, cos=0.000), tot_loss_proj:2.752 [t=0.26s]
prediction: ['[CLS] generic generic so [SEP]']
Attempt swap
[2000/2000] tot_loss=2.758 (perp=11.309, rec=0.496, cos=0.000), tot_loss_proj:2.750 [t=0.25s]
prediction: ['[CLS] generic generic so [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] generic generic so [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 88.189 | p: 87.886 | r: 88.687
rouge2     | fm: 54.582 | p: 54.475 | r: 54.785
rougeL     | fm: 76.549 | p: 76.267 | r: 76.946
rougeLsum  | fm: 76.319 | p: 76.020 | r: 76.700
r1fm+r2fm = 142.771

input #27 time: 0:10:51 | total time: 4:13:07


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
*********************************
*********************************
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 1.6155987977981567 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 1.5106481313705444 for ['[CLS] boundaries towards lands delivery [SEP]']
[Init] best rec loss: 1.505471110343933 for ['[CLS] immortal coma thierry imperial [SEP]']
[Init] best rec loss: 1.4851624965667725 for ['[CLS] perhaps childrenogical beta [SEP]']
[Init] best rec loss: 1.4608865976333618 for ['[CLS] bro asher lit majority [SEP]']
[Init] best rec loss: 1.460343837738037 for ['[CLS] site georgia chambers nicholas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.269 (perp=14.479, rec=0.362, cos=0.011), tot_loss_proj:4.315 [t=0.25s]
prediction: ['[CLS] itunes start ¹⁄₂ longest [SEP]']
[ 100/2000] tot_loss=2.316 (perp=10.334, rec=0.247, cos=0.003), tot_loss_proj:3.277 [t=0.25s]
prediction: ['[CLS] least minute minutes longest [SEP]']
[ 150/2000] tot_loss=1.764 (perp=7.826, rec=0.195, cos=0.003), tot_loss_proj:2.493 [t=0.25s]
prediction: ['[CLS] only 22 minutes longest [SEP]']
[ 200/2000] tot_loss=1.785 (perp=8.187, rec=0.146, cos=0.002), tot_loss_proj:2.410 [t=0.27s]
prediction: ['[CLS] only 71 minutes for [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.592 (perp=7.445, rec=0.101, cos=0.002), tot_loss_proj:1.853 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.565 (perp=7.445, rec=0.075, cos=0.001), tot_loss_proj:1.849 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.550 (perp=7.445, rec=0.061, cos=0.000), tot_loss_proj:1.847 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.561 (perp=7.445, rec=0.071, cos=0.000), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.558 (perp=7.445, rec=0.069, cos=0.000), tot_loss_proj:1.840 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.000), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.554 (perp=7.445, rec=0.065, cos=0.000), tot_loss_proj:1.849 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.568 (perp=7.445, rec=0.078, cos=0.000), tot_loss_proj:1.844 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.558 (perp=7.445, rec=0.069, cos=0.000), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.000), tot_loss_proj:1.848 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.000), tot_loss_proj:1.843 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.000), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.555 (perp=7.445, rec=0.066, cos=0.000), tot_loss_proj:1.850 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.000), tot_loss_proj:1.846 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.000), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.000), tot_loss_proj:1.841 [t=0.28s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.555 (perp=7.445, rec=0.066, cos=0.000), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.550 (perp=7.445, rec=0.061, cos=0.000), tot_loss_proj:1.845 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.554 (perp=7.445, rec=0.065, cos=0.000), tot_loss_proj:1.849 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.000), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.445, rec=0.060, cos=0.000), tot_loss_proj:1.846 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.562 (perp=7.445, rec=0.073, cos=0.000), tot_loss_proj:1.849 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.445, rec=0.061, cos=0.000), tot_loss_proj:1.843 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.000), tot_loss_proj:1.847 [t=0.27s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.000), tot_loss_proj:1.845 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.553 (perp=7.445, rec=0.064, cos=0.000), tot_loss_proj:1.835 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.559 (perp=7.445, rec=0.070, cos=0.000), tot_loss_proj:1.843 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.549 (perp=7.445, rec=0.060, cos=0.000), tot_loss_proj:1.841 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.445, rec=0.067, cos=0.000), tot_loss_proj:1.848 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=7.445, rec=0.054, cos=0.000), tot_loss_proj:1.837 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.000), tot_loss_proj:1.850 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.557 (perp=7.445, rec=0.068, cos=0.000), tot_loss_proj:1.842 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.547 (perp=7.445, rec=0.058, cos=0.000), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.546 (perp=7.445, rec=0.056, cos=0.000), tot_loss_proj:1.842 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.000), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.543 (perp=7.445, rec=0.053, cos=0.000), tot_loss_proj:1.846 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 88.767 | p: 88.402 | r: 89.201
rouge2     | fm: 54.122 | p: 53.965 | r: 54.280
rougeL     | fm: 76.740 | p: 76.465 | r: 77.094
rougeLsum  | fm: 76.778 | p: 76.466 | r: 77.183
r1fm+r2fm = 142.889

input #28 time: 0:10:49 | total time: 4:23:57


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
*********************************
*********************************
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 1.9422098398208618 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 1.725492238998413 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 1.665594458580017 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 1.6626322269439697 for ['[CLS] retrieved kicking quite misunderstanding race camp streaked shot larger fields [SEP]']
[Init] best rec loss: 1.544628381729126 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 1.4950032234191895 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 1.4667460918426514 for ['[CLS] hectares overshadowed° angeles me festival panels dean eventually towards [SEP]']
[Init] best rec loss: 1.451490879058838 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 1.3281519412994385 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 1.2676228284835815 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 1.2215781211853027 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 1.2187750339508057 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 1.2168614864349365 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 1.2131327390670776 for ['[CLS] taste landed administration this runs tv engagementuted oil envelope [SEP]']
[Init] best perm rec loss: 1.2063658237457275 for ['[CLS] oil this taste landed tv runs envelope engagement administrationuted [SEP]']
[Init] best perm rec loss: 1.2030150890350342 for ['[CLS] tv oil engagement landeduted this taste envelope runs administration [SEP]']
[Init] best perm rec loss: 1.200951337814331 for ['[CLS] taste runs landeduted engagement envelope this oil tv administration [SEP]']
[Init] best perm rec loss: 1.2006797790527344 for ['[CLS] landeduted taste engagement runs tv envelope this oil administration [SEP]']
[Init] best perm rec loss: 1.2004748582839966 for ['[CLS] this oil landed engagement tv envelopeuted taste runs administration [SEP]']
[Init] best perm rec loss: 1.1998974084854126 for ['[CLS]uted taste tv engagement oil runs envelope landed this administration [SEP]']
[Init] best perm rec loss: 1.197476863861084 for ['[CLS] taste runsuted tv landed engagement oil envelope this administration [SEP]']
[Init] best perm rec loss: 1.1972182989120483 for ['[CLS] taste oiluted engagement landed tv envelope administration this runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.048 (perp=13.122, rec=0.416, cos=0.007), tot_loss_proj:3.754 [t=0.25s]
prediction: ['[CLS] stupid disputesuted opposed allegedly workers label denied anything cult [SEP]']
[ 100/2000] tot_loss=2.664 (perp=11.699, rec=0.321, cos=0.003), tot_loss_proj:3.417 [t=0.25s]
prediction: ['[CLS] sick agreementuted opposed bounty workers. denied it monster [SEP]']
[ 150/2000] tot_loss=2.075 (perp=9.229, rec=0.227, cos=0.002), tot_loss_proj:2.737 [t=0.25s]
prediction: ['[CLS] sick britain actually believe resident workers is not it. [SEP]']
[ 200/2000] tot_loss=1.924 (perp=8.675, rec=0.188, cos=0.001), tot_loss_proj:2.813 [t=0.25s]
prediction: ['[CLS] join humans actually believe resident resident is not it. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.572 (perp=6.938, rec=0.182, cos=0.002), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] resident humans also believe resident stupid is not it. [SEP]']
[ 300/2000] tot_loss=1.549 (perp=6.938, rec=0.161, cos=0.001), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS] resident humans also believe resident stupid is not it. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.729 (perp=7.918, rec=0.145, cos=0.001), tot_loss_proj:2.514 [t=0.25s]
prediction: ['[CLS] resident also also believe resident organized is not it. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.680 (perp=7.665, rec=0.145, cos=0.002), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS] also resident also believe resident organized is not it. [SEP]']
[ 450/2000] tot_loss=1.680 (perp=7.665, rec=0.145, cos=0.001), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] also resident also believe resident organized is not it. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.847 (perp=8.551, rec=0.137, cos=0.001), tot_loss_proj:2.647 [t=0.24s]
prediction: ['[CLS] also evil also believe organized resident is not it. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.778 (perp=8.177, rec=0.141, cos=0.002), tot_loss_proj:2.705 [t=0.25s]
prediction: ['[CLS] also resident also believe mikey evil is not it? [SEP]']
[ 600/2000] tot_loss=1.549 (perp=7.127, rec=0.123, cos=0.001), tot_loss_proj:2.708 [t=0.25s]
prediction: ['[CLS] also resident also believe exists evil is not it. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.382 (perp=6.297, rec=0.122, cos=0.001), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] also also also believe resident evil is not it. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.373 (perp=6.297, rec=0.112, cos=0.001), tot_loss_proj:2.154 [t=0.25s]
prediction: ['[CLS] also also also believe resident evil is not it. [SEP]']
[ 750/2000] tot_loss=1.497 (perp=6.870, rec=0.122, cos=0.001), tot_loss_proj:2.415 [t=0.25s]
prediction: ['[CLS] also also stupid believe resident evil is not it. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.376 (perp=6.297, rec=0.116, cos=0.001), tot_loss_proj:2.156 [t=0.25s]
prediction: ['[CLS] also also also believe resident evil is not it. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.364 (perp=6.297, rec=0.104, cos=0.001), tot_loss_proj:2.153 [t=0.24s]
prediction: ['[CLS] also also also believe resident evil is not it. [SEP]']
[ 900/2000] tot_loss=1.256 (perp=5.725, rec=0.111, cos=0.001), tot_loss_proj:1.997 [t=0.25s]
prediction: ['[CLS] also that also believe resident evil is not it. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.535 (perp=7.098, rec=0.115, cos=0.001), tot_loss_proj:2.345 [t=0.27s]
prediction: ['[CLS] also also believe identified resident evil is not it. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.434 (perp=6.590, rec=0.116, cos=0.001), tot_loss_proj:2.265 [t=0.25s]
prediction: ['[CLS] also also identified believe resident evil is not it. [SEP]']
[1050/2000] tot_loss=1.435 (perp=6.590, rec=0.117, cos=0.001), tot_loss_proj:2.262 [t=0.24s]
prediction: ['[CLS] also also identified believe resident evil is not it. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.238 (perp=5.615, rec=0.115, cos=0.001), tot_loss_proj:2.062 [t=0.26s]
prediction: ['[CLS] also also that believe resident evil is not it. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.197 (perp=5.412, rec=0.114, cos=0.001), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] also also believe that resident evil is not it. [SEP]']
[1200/2000] tot_loss=1.180 (perp=5.412, rec=0.097, cos=0.001), tot_loss_proj:1.909 [t=0.24s]
prediction: ['[CLS] also also believe that resident evil is not it. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.172 (perp=5.265, rec=0.119, cos=0.001), tot_loss_proj:1.870 [t=0.25s]
prediction: ['[CLS] also believe that resident evil also is not it. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.116 (perp=5.082, rec=0.099, cos=0.001), tot_loss_proj:1.809 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
[1350/2000] tot_loss=1.116 (perp=5.082, rec=0.099, cos=0.001), tot_loss_proj:1.818 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.121 (perp=5.082, rec=0.104, cos=0.001), tot_loss_proj:1.805 [t=0.26s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.114 (perp=5.082, rec=0.097, cos=0.001), tot_loss_proj:1.814 [t=0.26s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
[1500/2000] tot_loss=1.112 (perp=5.082, rec=0.095, cos=0.001), tot_loss_proj:1.807 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.115 (perp=5.082, rec=0.098, cos=0.001), tot_loss_proj:1.814 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.115 (perp=5.082, rec=0.098, cos=0.001), tot_loss_proj:1.812 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
[1650/2000] tot_loss=1.113 (perp=5.082, rec=0.096, cos=0.001), tot_loss_proj:1.808 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.124 (perp=5.082, rec=0.107, cos=0.000), tot_loss_proj:1.814 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.121 (perp=5.082, rec=0.104, cos=0.000), tot_loss_proj:1.811 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
[1800/2000] tot_loss=1.106 (perp=5.082, rec=0.089, cos=0.000), tot_loss_proj:1.807 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.115 (perp=5.082, rec=0.099, cos=0.000), tot_loss_proj:1.812 [t=0.27s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.114 (perp=5.082, rec=0.097, cos=0.000), tot_loss_proj:1.806 [t=0.27s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
[1950/2000] tot_loss=1.123 (perp=5.082, rec=0.107, cos=0.000), tot_loss_proj:1.811 [t=0.26s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.107 (perp=5.082, rec=0.090, cos=0.000), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS] also believe that resident evil is also not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] also believe that resident evil is also not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 160.909

[Aggregate metrics]:
rouge1     | fm: 88.712 | p: 88.385 | r: 89.193
rouge2     | fm: 55.064 | p: 54.841 | r: 55.287
rougeL     | fm: 77.488 | p: 77.248 | r: 77.842
rougeLsum  | fm: 77.235 | p: 76.963 | r: 77.533
r1fm+r2fm = 143.776

input #29 time: 0:10:47 | total time: 4:34:44


Running input #30 of 100.
reference: 
========================
fizzability 
========================
*********************************
*********************************
average of cosine similarity 0.9992720994590749
highest_index [0]
highest [0.9992720994590749]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 1.8995320796966553 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 1.870033860206604 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 1.8638838529586792 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 1.4753696918487549 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 1.3648078441619873 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 1.221232533454895 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 1.1736953258514404 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 1.155712604522705 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 1.1542490720748901 for ['[CLS] spent mom who [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.621 (perp=11.471, rec=0.320, cos=0.007), tot_loss_proj:3.103 [t=0.25s]
prediction: ['[CLS] badzzinessbility [SEP]']
[ 100/2000] tot_loss=2.364 (perp=10.667, rec=0.227, cos=0.004), tot_loss_proj:3.923 [t=0.25s]
prediction: ['[CLS] summerbilitybility [SEP]']
[ 150/2000] tot_loss=2.072 (perp=9.540, rec=0.161, cos=0.003), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.015 (perp=9.540, rec=0.106, cos=0.002), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.005 (perp=9.540, rec=0.095, cos=0.003), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.994 (perp=9.540, rec=0.085, cos=0.002), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.981 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.978 (perp=9.540, rec=0.069, cos=0.001), tot_loss_proj:1.994 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.971 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.981 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.982 (perp=9.540, rec=0.074, cos=0.001), tot_loss_proj:1.984 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.966 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.985 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.984 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.987 (perp=9.540, rec=0.079, cos=0.001), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.956 (perp=9.540, rec=0.048, cos=0.001), tot_loss_proj:1.997 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.977 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.988 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.958 (perp=9.540, rec=0.049, cos=0.001), tot_loss_proj:1.988 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.964 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.971 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.985 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.976 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.971 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.968 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.991 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.956 (perp=9.540, rec=0.048, cos=0.001), tot_loss_proj:1.994 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.966 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.959 (perp=9.540, rec=0.051, cos=0.001), tot_loss_proj:1.988 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=9.540, rec=0.067, cos=0.001), tot_loss_proj:1.984 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.974 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.975 (perp=9.540, rec=0.067, cos=0.001), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.985 (perp=9.540, rec=0.076, cos=0.001), tot_loss_proj:1.990 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.971 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.985 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.995 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.963 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.988 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.965 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.982 (perp=9.540, rec=0.074, cos=0.001), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.986 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.967 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.956 (perp=9.540, rec=0.048, cos=0.001), tot_loss_proj:1.989 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.966 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.976 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.173 | p: 88.855 | r: 89.557
rouge2     | fm: 56.074 | p: 55.952 | r: 56.276
rougeL     | fm: 78.080 | p: 77.820 | r: 78.438
rougeLsum  | fm: 77.720 | p: 77.507 | r: 78.111
r1fm+r2fm = 145.247

input #30 time: 0:10:44 | total time: 4:45:29


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
*********************************
*********************************
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 1.914638876914978 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 1.7327791452407837 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 1.6876567602157593 for ['[CLS] che episode band [SEP]']
[Init] best rec loss: 1.3702372312545776 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 1.3683922290802002 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 1.3629165887832642 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.423 (perp=10.371, rec=0.336, cos=0.012), tot_loss_proj:3.209 [t=0.24s]
prediction: ['[CLS] better creditneuve [SEP]']
[ 100/2000] tot_loss=2.132 (perp=9.658, rec=0.196, cos=0.005), tot_loss_proj:2.401 [t=0.25s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=1.854 (perp=8.742, rec=0.104, cos=0.002), tot_loss_proj:3.285 [t=0.24s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 200/2000] tot_loss=1.815 (perp=8.742, rec=0.066, cos=0.001), tot_loss_proj:3.292 [t=0.27s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.601 (perp=7.603, rec=0.078, cos=0.002), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.580 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.682 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.587 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.577 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.586 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.575 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.679 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.673 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.585 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.679 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.579 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.575 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.685 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.579 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.584 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.677 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.584 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.675 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.582 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.589 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.583 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.679 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.584 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.583 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.580 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.677 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.574 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.667 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.679 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.576 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.577 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.678 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.581 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.681 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.455 | p: 89.173 | r: 89.827
rouge2     | fm: 57.694 | p: 57.527 | r: 57.864
rougeL     | fm: 78.933 | p: 78.708 | r: 79.308
rougeLsum  | fm: 78.544 | p: 78.315 | r: 78.913
r1fm+r2fm = 147.150

input #31 time: 0:10:49 | total time: 4:56:19


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
*********************************
*********************************
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 2.020369052886963 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 1.688668131828308 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 1.6886156797409058 for ['[CLS] particular usual lana rid part awaitfication felt worked bolt algorithm tristan [SEP]']
[Init] best rec loss: 1.6725391149520874 for ['[CLS] carl formulacl overall network would ± < meyricktia archangel level [SEP]']
[Init] best rec loss: 1.655273675918579 for ['[CLS] unharmed spit health should llc relative front die threat skateer demolished [SEP]']
[Init] best perm rec loss: 1.6545727252960205 for ['[CLS] demolished spit health should die llc relative skate unharmed threater front [SEP]']
[Init] best perm rec loss: 1.6517530679702759 for ['[CLS] spit should relative threat demolished skate unharmed fronter llc die health [SEP]']
[Init] best perm rec loss: 1.6510119438171387 for ['[CLS] demolished unharmed should health spit relative llc die front threater skate [SEP]']
[Init] best perm rec loss: 1.6505436897277832 for ['[CLS] skateer health unharmed front die demolished should relative threat spit llc [SEP]']
[Init] best perm rec loss: 1.6478852033615112 for ['[CLS] unharmed demolished spit llcer skate die health should threat relative front [SEP]']
[Init] best perm rec loss: 1.646742582321167 for ['[CLS]er llc relative health die demolished threat unharmed spit should skate front [SEP]']
[Init] best perm rec loss: 1.6462005376815796 for ['[CLS] dieer health should llc skate threat spit unharmed demolished relative front [SEP]']
[Init] best perm rec loss: 1.6457756757736206 for ['[CLS] front llc skate should demolished healther threat spit unharmed die relative [SEP]']
[Init] best perm rec loss: 1.6436963081359863 for ['[CLS] unharmed die llc skate demolished healther front should relative threat spit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.346 (perp=13.011, rec=0.732, cos=0.011), tot_loss_proj:4.118 [t=0.33s]
prediction: ['[CLS] gravel days less noο taste dullided privacy inventedquent climate [SEP]']
[ 100/2000] tot_loss=3.431 (perp=14.069, rec=0.614, cos=0.003), tot_loss_proj:4.413 [t=0.26s]
prediction: ['[CLS] gravel parade cu disappearundep dullpled tempting slowlyatable climate [SEP]']
[ 150/2000] tot_loss=3.462 (perp=14.457, rec=0.568, cos=0.002), tot_loss_proj:4.607 [t=0.25s]
prediction: ['[CLS] penalties makeshift least disappearundfting death accessible tempting quickly genres climate [SEP]']
[ 200/2000] tot_loss=3.314 (perp=13.798, rec=0.547, cos=0.008), tot_loss_proj:4.469 [t=0.25s]
prediction: ['[CLS] becomes ancient easily disappearundpressing death accessible bundesliga easily genres climate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.613 (perp=15.269, rec=0.557, cos=0.003), tot_loss_proj:4.573 [t=0.29s]
prediction: ['[CLS] becomes railing easily disappearundfting devoid unemployment bundesliga easilyhope blame [SEP]']
[ 300/2000] tot_loss=3.344 (perp=14.128, rec=0.518, cos=0.001), tot_loss_proj:4.490 [t=0.25s]
prediction: ['[CLS] marker railing easily disappearundop withoutnsorович reshope blame [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.056 (perp=12.682, rec=0.516, cos=0.003), tot_loss_proj:4.218 [t=0.26s]
prediction: ['[CLS] marker railing easily disappearundop morrison imprisonment bundesliga res without blame [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.114 (perp=13.052, rec=0.502, cos=0.002), tot_loss_proj:4.262 [t=0.25s]
prediction: ['[CLS] marker railing easily disappearundund morrisonnsor kaladin resonate without [SEP]']
[ 450/2000] tot_loss=3.253 (perp=13.813, rec=0.489, cos=0.001), tot_loss_proj:4.402 [t=0.26s]
prediction: ['[CLS] kilometers railing easily disappearonateund morrisonnsor kaladin resonate without [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.266 (perp=13.807, rec=0.504, cos=0.000), tot_loss_proj:4.510 [t=0.25s]
prediction: ['[CLS] without railing easily disappearundop threshold imprisonment kaladin res inflicted kilometers [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.908 (perp=12.094, rec=0.488, cos=0.001), tot_loss_proj:4.383 [t=0.26s]
prediction: ['[CLS] withoutə easily disappearundoponate imprisonment kaladin kilometers resonate [SEP]']
[ 600/2000] tot_loss=2.996 (perp=12.578, rec=0.480, cos=0.000), tot_loss_proj:4.477 [t=0.26s]
prediction: ['[CLS] withoutə easily disappearonateundonate imprisonment kaladin kilometers resonate [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.965 (perp=12.419, rec=0.477, cos=0.004), tot_loss_proj:4.235 [t=0.26s]
prediction: ['[CLS] withə easily disappearonateundonate imprisonment kaladin kilometers resonate [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.051 (perp=12.875, rec=0.474, cos=0.002), tot_loss_proj:4.551 [t=0.24s]
prediction: ['[CLS] withə easily disappearonateundonate imprisonment kaladin magnificent resonate [SEP]']
[ 750/2000] tot_loss=2.903 (perp=12.139, rec=0.472, cos=0.003), tot_loss_proj:4.389 [t=0.24s]
prediction: ['[CLS] withə easily disappear resundonate imprisonment kaladin magnificent resund [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.829 (perp=11.833, rec=0.462, cos=0.000), tot_loss_proj:4.317 [t=0.25s]
prediction: ['[CLS] withə easily disappear resonateund imprisonment accessible magnificent resund [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.865 (perp=12.010, rec=0.462, cos=0.000), tot_loss_proj:4.106 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
[ 900/2000] tot_loss=2.859 (perp=12.010, rec=0.457, cos=0.000), tot_loss_proj:4.108 [t=0.27s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.860 (perp=12.010, rec=0.457, cos=0.001), tot_loss_proj:4.108 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
Attempt swap
[1000/2000] tot_loss=2.858 (perp=12.010, rec=0.454, cos=0.002), tot_loss_proj:4.105 [t=0.25s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
[1050/2000] tot_loss=2.852 (perp=12.010, rec=0.450, cos=0.000), tot_loss_proj:4.109 [t=0.27s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
Attempt swap
[1100/2000] tot_loss=2.855 (perp=12.010, rec=0.452, cos=0.001), tot_loss_proj:4.108 [t=0.25s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
Attempt swap
[1150/2000] tot_loss=2.849 (perp=12.010, rec=0.446, cos=0.001), tot_loss_proj:4.113 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
[1200/2000] tot_loss=2.850 (perp=12.010, rec=0.448, cos=0.000), tot_loss_proj:4.110 [t=0.25s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible magnificent resund [SEP]']
Attempt swap
[1250/2000] tot_loss=2.864 (perp=12.107, rec=0.442, cos=0.000), tot_loss_proj:4.375 [t=0.25s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessibleonate resund [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.913 (perp=12.253, rec=0.460, cos=0.002), tot_loss_proj:4.385 [t=0.25s]
prediction: ['[CLS] withə easily talked resjustund imprisonment accessible resonateund [SEP]']
[1350/2000] tot_loss=2.705 (perp=11.305, rec=0.444, cos=0.000), tot_loss_proj:4.192 [t=0.25s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
Attempt swap
[1400/2000] tot_loss=2.706 (perp=11.305, rec=0.445, cos=0.000), tot_loss_proj:4.198 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
Attempt swap
[1450/2000] tot_loss=2.707 (perp=11.305, rec=0.446, cos=0.000), tot_loss_proj:4.195 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
[1500/2000] tot_loss=2.710 (perp=11.305, rec=0.449, cos=0.000), tot_loss_proj:4.197 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
Attempt swap
[1550/2000] tot_loss=2.708 (perp=11.305, rec=0.447, cos=0.000), tot_loss_proj:4.196 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
Attempt swap
[1600/2000] tot_loss=2.700 (perp=11.305, rec=0.439, cos=0.000), tot_loss_proj:4.193 [t=0.26s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
[1650/2000] tot_loss=2.705 (perp=11.305, rec=0.444, cos=0.000), tot_loss_proj:4.194 [t=0.25s]
prediction: ['[CLS] withə easily talked resonateund imprisonment accessible resonateund [SEP]']
Attempt swap
[1700/2000] tot_loss=3.110 (perp=13.326, rec=0.445, cos=0.000), tot_loss_proj:4.450 [t=0.25s]
prediction: ['[CLS] profə easily talked resonateund imprisonment accessible storiesonateund [SEP]']
Attempt swap
[1750/2000] tot_loss=3.109 (perp=13.326, rec=0.444, cos=0.000), tot_loss_proj:4.447 [t=0.26s]
prediction: ['[CLS] profə easily talked resonateund imprisonment accessible storiesonateund [SEP]']
[1800/2000] tot_loss=3.109 (perp=13.326, rec=0.444, cos=0.000), tot_loss_proj:4.450 [t=0.24s]
prediction: ['[CLS] profə easily talked resonateund imprisonment accessible storiesonateund [SEP]']
Attempt swap
[1850/2000] tot_loss=3.103 (perp=13.326, rec=0.438, cos=0.000), tot_loss_proj:4.450 [t=0.26s]
prediction: ['[CLS] profə easily talked resonateund imprisonment accessible storiesonateund [SEP]']
Attempt swap
[1900/2000] tot_loss=3.103 (perp=13.326, rec=0.438, cos=0.000), tot_loss_proj:4.449 [t=0.25s]
prediction: ['[CLS] profə easily talked resonateund imprisonment accessible storiesonateund [SEP]']
[1950/2000] tot_loss=3.063 (perp=13.132, rec=0.436, cos=0.000), tot_loss_proj:4.527 [t=0.25s]
prediction: ['[CLS] profə easily talked resonateundnsor accessible storiesonateund [SEP]']
Attempt swap
[2000/2000] tot_loss=3.064 (perp=13.132, rec=0.437, cos=0.000), tot_loss_proj:4.531 [t=0.26s]
prediction: ['[CLS] profə easily talked resonateundnsor accessible storiesonateund [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] profə easily talked resonateund imprisonment accessible storiesonateund [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 44.444 | r: 36.364
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 44.444 | r: 36.364
rougeLsum  | fm: 40.000 | p: 44.444 | r: 36.364
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 87.874 | p: 87.753 | r: 88.177
rouge2     | fm: 56.027 | p: 55.939 | r: 56.232
rougeL     | fm: 77.586 | p: 77.572 | r: 77.875
rougeLsum  | fm: 77.390 | p: 77.344 | r: 77.610
r1fm+r2fm = 143.901

input #32 time: 0:10:51 | total time: 5:07:11


Running input #33 of 100.
reference: 
========================
higher 
========================
*********************************
*********************************
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.8901952505111694 for ['[CLS] riots [SEP]']
[Init] best rec loss: 1.7840126752853394 for ['[CLS] lord [SEP]']
[Init] best rec loss: 1.6915725469589233 for ['[CLS] master [SEP]']
[Init] best rec loss: 1.5511021614074707 for ['[CLS] training [SEP]']
[Init] best rec loss: 1.4511288404464722 for ['[CLS] strip [SEP]']
[Init] best rec loss: 1.3865865468978882 for ['[CLS] less [SEP]']
[Init] best rec loss: 1.3548933267593384 for ['[CLS] higher [SEP]']
[Init] best rec loss: 1.121751308441162 for ['[CLS] positive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.479 (perp=11.231, rec=0.222, cos=0.010), tot_loss_proj:2.956 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.362 (perp=11.231, rec=0.114, cos=0.002), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.338 (perp=11.231, rec=0.090, cos=0.001), tot_loss_proj:2.404 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.327 (perp=11.231, rec=0.080, cos=0.001), tot_loss_proj:2.406 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.321 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.397 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.401 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.293 (perp=11.231, rec=0.046, cos=0.001), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.320 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.403 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.381 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.404 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.308 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.309 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.380 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.295 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.321 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.409 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.397 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.401 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.322 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.397 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.304 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.319 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.401 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.299 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.397 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.306 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.390 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.331 (perp=11.231, rec=0.083, cos=0.001), tot_loss_proj:2.407 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.298 (perp=11.231, rec=0.051, cos=0.001), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.399 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.318 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.299 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.297 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.295 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.403 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.323 (perp=11.231, rec=0.076, cos=0.001), tot_loss_proj:2.397 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.321 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.404 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.308 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.301 | p: 88.211 | r: 88.544
rouge2     | fm: 57.335 | p: 57.154 | r: 57.492
rougeL     | fm: 78.235 | p: 78.226 | r: 78.426
rougeLsum  | fm: 78.050 | p: 78.034 | r: 78.222
r1fm+r2fm = 145.636

input #33 time: 0:10:46 | total time: 5:17:57


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
*********************************
*********************************
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 1.8906997442245483 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 1.821115493774414 for ['[CLS] mistress quality security throughout trunkught warning age marketing experiments despite bug travel [SEP]']
[Init] best rec loss: 1.8150413036346436 for ['[CLS] bus japan coyote being far united away sal during cov : fair [SEP]']
[Init] best rec loss: 1.764905333518982 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 1.7503083944320679 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 1.716280460357666 for ['[CLS] bird cursed led ao wearing one keys nearlysco tom constitutionnem љ [SEP]']
[Init] best rec loss: 1.469266414642334 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 1.4675160646438599 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 1.4614590406417847 for ['[CLS] field slight alongask whoibe statue worth lissa founder ship okay drivers [SEP]']
[Init] best perm rec loss: 1.4533991813659668 for ['[CLS] ship slight founder statue lissaask drivers okay worth fieldibe who along [SEP]']
[Init] best perm rec loss: 1.4512879848480225 for ['[CLS]ask along slight founder worth okay ship lissa field statue driversibe who [SEP]']
[Init] best perm rec loss: 1.4508488178253174 for ['[CLS]ibe along worth driversask slight statue field okay who lissa ship founder [SEP]']
[Init] best perm rec loss: 1.4482790231704712 for ['[CLS] alongibe drivers who ship statue okay lissaask worth slight founder field [SEP]']
[Init] best perm rec loss: 1.4482308626174927 for ['[CLS] lissa ship along drivers slight okayaskibe who statue founder field worth [SEP]']
[Init] best perm rec loss: 1.4454642534255981 for ['[CLS] along slight ship worth drivers founder okay whoask field lissa statueibe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.850 (perp=12.277, rec=0.387, cos=0.008), tot_loss_proj:3.678 [t=0.25s]
prediction: ['[CLS] attraction slightly magnitude build desperate grasping gordon highnessneuve power current earnest and [SEP]']
[ 100/2000] tot_loss=2.361 (perp=10.455, rec=0.268, cos=0.002), tot_loss_proj:3.800 [t=0.26s]
prediction: ['[CLS] take slightlyecure urgency extremeently.. urgency power current urgency and [SEP]']
[ 150/2000] tot_loss=2.268 (perp=10.290, rec=0.208, cos=0.002), tot_loss_proj:3.162 [t=0.25s]
prediction: ['[CLS] take viewer viewer urgency extremeently. viewer viewer is certain urgency and [SEP]']
[ 200/2000] tot_loss=2.066 (perp=9.448, rec=0.173, cos=0.003), tot_loss_proj:3.126 [t=0.26s]
prediction: ['[CLS] take viewer viewer urgency extreme ( in viewer extreme - great urgency. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.176 (perp=9.986, rec=0.175, cos=0.003), tot_loss_proj:3.108 [t=0.26s]
prediction: ['[CLS] take viewer viewer extreme ( urgency in viewer extreme. extreme urgency. [SEP]']
[ 300/2000] tot_loss=1.993 (perp=9.222, rec=0.148, cos=0.001), tot_loss_proj:2.961 [t=0.25s]
prediction: ['[CLS] take viewer build extreme of urgency in viewer extreme. extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.895 (perp=8.869, rec=0.120, cos=0.001), tot_loss_proj:2.639 [t=0.27s]
prediction: ['[CLS] take viewer build. of urgency in viewer mind extreme extreme urgency. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.806 (perp=8.359, rec=0.133, cos=0.002), tot_loss_proj:2.607 [t=0.25s]
prediction: ['[CLS] take viewer build. of extreme urgency on viewer mind extreme urgency. [SEP]']
[ 450/2000] tot_loss=1.844 (perp=8.666, rec=0.110, cos=0.001), tot_loss_proj:2.631 [t=0.25s]
prediction: ['[CLS] take viewer build. in extreme urgency on viewer mind extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.660 (perp=7.716, rec=0.116, cos=0.001), tot_loss_proj:2.195 [t=0.26s]
prediction: ['[CLS] take viewer build and viewer mind in extreme urgency on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.631 (perp=7.588, rec=0.112, cos=0.001), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] take viewer and build viewer mind in extreme urgency on extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.611 (perp=7.588, rec=0.093, cos=0.001), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] take viewer and build viewer mind in extreme urgency on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.580 (perp=7.440, rec=0.091, cos=0.001), tot_loss_proj:2.142 [t=0.24s]
prediction: ['[CLS] take viewer and viewer build mind in extreme urgency on extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.548 (perp=7.264, rec=0.095, cos=0.001), tot_loss_proj:2.177 [t=0.25s]
prediction: ['[CLS] take viewer and viewer build in mind extreme urgency on extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.542 (perp=7.264, rec=0.088, cos=0.001), tot_loss_proj:2.169 [t=0.25s]
prediction: ['[CLS] take viewer and viewer build in mind extreme urgency on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.502 (perp=7.037, rec=0.094, cos=0.001), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.491 (perp=7.037, rec=0.083, cos=0.001), tot_loss_proj:2.182 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.493 (perp=7.037, rec=0.085, cos=0.001), tot_loss_proj:2.185 [t=0.27s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.485 (perp=7.037, rec=0.077, cos=0.001), tot_loss_proj:2.188 [t=0.28s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.484 (perp=7.037, rec=0.076, cos=0.001), tot_loss_proj:2.176 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
[1050/2000] tot_loss=1.473 (perp=7.037, rec=0.065, cos=0.001), tot_loss_proj:2.175 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.488 (perp=7.037, rec=0.080, cos=0.001), tot_loss_proj:2.178 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.476 (perp=7.037, rec=0.068, cos=0.001), tot_loss_proj:2.179 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
[1200/2000] tot_loss=1.484 (perp=7.037, rec=0.076, cos=0.000), tot_loss_proj:2.180 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.489 (perp=7.037, rec=0.081, cos=0.000), tot_loss_proj:2.175 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.489 (perp=7.037, rec=0.081, cos=0.000), tot_loss_proj:2.173 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
[1350/2000] tot_loss=1.487 (perp=7.037, rec=0.079, cos=0.000), tot_loss_proj:2.183 [t=0.27s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.492 (perp=7.037, rec=0.084, cos=0.000), tot_loss_proj:2.169 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.483 (perp=7.037, rec=0.075, cos=0.000), tot_loss_proj:2.174 [t=0.24s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
[1500/2000] tot_loss=1.486 (perp=7.037, rec=0.078, cos=0.000), tot_loss_proj:2.174 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.483 (perp=7.037, rec=0.075, cos=0.000), tot_loss_proj:2.175 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme urgency build on extreme urgency. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.519 (perp=7.195, rec=0.079, cos=0.001), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme the urgency build on extreme. [SEP]']
[1650/2000] tot_loss=1.510 (perp=7.195, rec=0.070, cos=0.001), tot_loss_proj:2.452 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind extreme the urgency build on extreme. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.439 (perp=6.832, rec=0.072, cos=0.001), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.450 (perp=6.832, rec=0.084, cos=0.001), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
[1800/2000] tot_loss=1.434 (perp=6.832, rec=0.067, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.433 (perp=6.832, rec=0.066, cos=0.001), tot_loss_proj:2.155 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.832, rec=0.066, cos=0.000), tot_loss_proj:2.164 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.832, rec=0.070, cos=0.000), tot_loss_proj:2.166 [t=0.25s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.437 (perp=6.832, rec=0.071, cos=0.001), tot_loss_proj:2.162 [t=0.26s]
prediction: ['[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] take viewer and viewer in mind the urgency build on extreme extreme. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 15.385 | p: 15.385 | r: 15.385
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 101.099

[Aggregate metrics]:
rouge1     | fm: 88.220 | p: 88.130 | r: 88.557
rouge2     | fm: 56.120 | p: 55.996 | r: 56.259
rougeL     | fm: 77.635 | p: 77.491 | r: 77.760
rougeLsum  | fm: 77.313 | p: 77.223 | r: 77.510
r1fm+r2fm = 144.339

input #34 time: 0:10:53 | total time: 5:28:51


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
*********************************
*********************************
average of cosine similarity 0.9993278544896085
highest_index [0]
highest [0.9993278544896085]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 1.908953070640564 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 1.8951733112335205 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 1.8934053182601929 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 1.834226369857788 for ['[CLS] interview effectiveness hum saliva ring mao cheerleading aim respond medicine pointliftland lost happening gap placement solomon gertrude fabric four hair byte aimed ogden trains gnu beside jo tight spoke millionsᵢ folded girls halls man trail drawnvc rule authorities [SEP]']
[Init] best rec loss: 1.80353844165802 for ["[CLS]bard boardless seed list arizona orders track be england lamb video name deep candy mont already nebraska offerings trained promise science last makeup qualifier ir lidciency about usesbrook'tag indefinitely grimes dress 2002 whether offerings design spear career [SEP]"]
[Init] best rec loss: 1.7946257591247559 for ['[CLS] trouble celebrity neckyah top bucks where appeared interrupting left carlo how ghost echoed million this incorporated bounded done theiritated tired exchange keep not brigade papers seed suicidal der wear raw discus school although fringe geographical difference accused hourly together stick [SEP]']
[Init] best rec loss: 1.7641812562942505 for ['[CLS]usionpm seeking tango casino over digital runway church radio cells an rom going endemicrted did penalty craft chance master no words [CLS] treatment bed caliphate quantum destination bladed down optical interested obvious rang recentguard hall theatre ballettt do [SEP]']
[Init] best rec loss: 1.730168104171753 for ['[CLS] mi " therefore zev ms hays bun welles start pierce aquino interce specific causedpo normal texas often vocals secretaries themselves magic night court cesar stages achilles excellent fixed shi bertie leg rows plant alwaysch beijing futuretral young wall [SEP]']
[Init] best perm rec loss: 1.7273207902908325 for ['[CLS] future stages shi plant beijing often welles secretaries alwaysce bertie themselves excellent zev inter caused fixed achilles bun night specific mi rows hayspo aquinochtral leg normal therefore magic texas court wall ms " start young vocals cesar pierce [SEP]']
[Init] best perm rec loss: 1.7262543439865112 for ['[CLS]po excellent ms wall vocals aquino stages future achilles normal court cesar plant secretaries welles magictral texas night hays start themselves beijing therefore pierce leg "ce specific caused zev alwaysch often mi shi bertie bun fixed rows young inter [SEP]']
[Init] best perm rec loss: 1.7246230840682983 for ['[CLS] " cesartral excellent achilles caused wall always hays zev pierce future often start leg msch welles beijing secretariesce stages court fixed aquino specific magic shi bertie therefore young vocalspo plant normal texas inter bun mi themselves night rows [SEP]']
[Init] best perm rec loss: 1.7220380306243896 for ['[CLS] normal pierce bun aquino stages specific " mi shi future rows zev start themselves bertietral hays texas achilles therefore cesar secretaries always oftence youngpo vocals leg fixed wall magic beijing plant welles caused excellent courtch inter night ms [SEP]']
[Init] best perm rec loss: 1.721089243888855 for ['[CLS] texas ms wall alwaystral start bun normal excellent secretaries stages piercech zev leg courtce night cesar aquino inter fixed therefore future vocals plant " achilles mi shi causedpo magic young specific rows bertie welles beijing hays themselves often [SEP]']
[Init] best perm rec loss: 1.7183254957199097 for ['[CLS] leg achilles magicpo themselves cesar secretariesch plant " wall therefore vocals fixed bun specific zev shi start night hays mstral welles stages aquino normal inter mi bertie rows beijing future alwaysce excellent often caused young court texas pierce [SEP]']
[Init] best perm rec loss: 1.7166597843170166 for ['[CLS] zev bertie fixed rows magic shi texasch specific alwaystralce stages plant caused normal pierce beijing start "po hays welles night mi excellent future therefore aquino ms bun cesar young themselves wall secretaries achilles often inter leg vocals court [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.468 (perp=10.198, rec=0.425, cos=0.003), tot_loss_proj:3.071 [t=0.26s]
prediction: ['[CLS] humidity water. ] heritage received that in of new ( in the wonderful method of foundation antarctica sons... points lion examined of i beautiful iioint special alive the guest impact generation the missionary personal side contemporary sourcesur really [SEP]']
[ 100/2000] tot_loss=2.488 (perp=10.796, rec=0.327, cos=0.001), tot_loss_proj:3.475 [t=0.25s]
prediction: ['[CLS] not action\'but predator received cameras of to another. in the amazing advice this foundation nedra sons " points tortricidae its of i beautiful mebert this care the is find november theteacher proven edge. sourcesworks really [SEP]']
[ 150/2000] tot_loss=2.283 (perp=9.932, rec=0.291, cos=0.005), tot_loss_proj:3.562 [t=0.26s]
prediction: ['[CLS] before\'\' but predator captured\'of to they. of - great assistant this circus range latest " ] tortricidae its of we wonderful with graf this care the is find recently theteacher truenation, source ] as [SEP]']
[ 200/2000] tot_loss=2.143 (perp=9.459, rec=0.250, cos=0.001), tot_loss_proj:3.646 [t=0.26s]
prediction: ['[CLS] before\'\' but seen seen\'of to we. of - great assistant this\'range latest " ] gotten seen of we wonderful seen graf this care the seen findnation the superintendent highernation, communication ] as [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.177 (perp=9.453, rec=0.285, cos=0.001), tot_loss_proj:3.718 [t=0.25s]
prediction: ['[CLS] before\'we but seen about\'tonight to we\'in a great assistant this \'tur latest " ] get ve but we wonderful seen messed her care the seen appreciated for the superintendent published, aboutian ] as [SEP]']
[ 300/2000] tot_loss=2.081 (perp=9.261, rec=0.228, cos=0.001), tot_loss_proj:3.594 [t=0.25s]
prediction: ['[CLS] before\'we but seen about\'tonight. we\'\' and great help this\'m latest " ] start ve but we wonderful seen bother her care the seen have for the superintendent greatest, about form today as [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.167 (perp=9.820, rec=0.202, cos=0.000), tot_loss_proj:3.342 [t=0.26s]
prediction: ['[CLS] before\'we but seen seen\'seen. we\'\' and great help this\'m latest " ch truly ve found we greatest tonight breadth us makes the seen have into the teachercar, about director today care [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.170 (perp=9.547, rec=0.258, cos=0.002), tot_loss_proj:3.470 [t=0.26s]
prediction: ['[CLS] before\'we but seen before\'seen tonight we\'\' and great help this\'m latest " among get vench the greatest newest director us makes we seen itself into the teacher greatest. about publication administrator care [SEP]']
[ 450/2000] tot_loss=2.016 (perp=9.119, rec=0.191, cos=0.000), tot_loss_proj:3.057 [t=0.26s]
prediction: ["[CLS] before'we but seen before'seen for we'', great help this'perspective latest psychic of truly ve'the greatest newest director us makes we seen all of thenation great. about rein soloist care [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.970 (perp=8.857, rec=0.199, cos=0.000), tot_loss_proj:2.886 [t=0.26s]
prediction: ["[CLS] before'we but seen with'seen for we've'with great help this'perspective latest emotional exactly truly, the greatest tonight director us makes we seen all we thenation greatest. about rein educator care [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.834 (perp=8.283, rec=0.176, cos=0.001), tot_loss_proj:3.209 [t=0.28s]
prediction: ["[CLS] before'we but seen with'seen for we've ', great help this, outlet latest ( exactly came, the greatest newest director us makes we seen all about thenation greatest, we rein educator care [SEP]"]
[ 600/2000] tot_loss=1.821 (perp=8.322, rec=0.156, cos=0.000), tot_loss_proj:3.204 [t=0.26s]
prediction: ["[CLS] before'we but previous with'seen. we've ', great help this, implies latest ( exactly get, the greatest newest director us makes we seen all'thenation greatest, we rein teacher care [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.758 (perp=7.889, rec=0.180, cos=0.000), tot_loss_proj:2.902 [t=0.26s]
prediction: ["[CLS] before'we but what with'seen. we've ', great help this. with latest ( much truly, the greatest inner director us makes we seen all about 'nation greatest, we rein soloist care [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.713 (perp=7.758, rec=0.161, cos=0.000), tot_loss_proj:2.818 [t=0.27s]
prediction: ["[CLS] before'we but ve to'seen. we've '. the, great help this latest ( much experience, the greatest inner director us makes we seen all from thenation greatest, wenation teacher care [SEP]"]
[ 750/2000] tot_loss=1.727 (perp=7.855, rec=0.156, cos=0.000), tot_loss_proj:2.758 [t=0.26s]
prediction: ["[CLS] before'we but ve with'seen. we've '. the, great help this latest ( much experience, the greatest inner director us makes we it all from 'nation greatest, wenation teacher care [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.730 (perp=7.836, rec=0.162, cos=0.000), tot_loss_proj:2.872 [t=0.26s]
prediction: ["[CLS] before'we but ve with'seen. we've ', the, great help this latest ( muchgraphy, the greatest inner director us makes'it all from wenation greatest, ofnation teacher care [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.040 (perp=8.653, rec=0.307, cos=0.003), tot_loss_proj:3.247 [t=0.26s]
prediction: ["[CLS]'' we but ve for'seen for we've before as with, great help this latest. much nation,. during expression director us makes the it in'wenation greatest of ofnation knows care [SEP]"]
[ 900/2000] tot_loss=1.812 (perp=7.819, rec=0.247, cos=0.001), tot_loss_proj:2.836 [t=0.28s]
prediction: ["[CLS]'' we but category for'seen to we've before / about, great help this latest. much nation,. from'director us makes the it of'wenation greatest of ofnation continent care [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.781 (perp=7.804, rec=0.220, cos=0.001), tot_loss_proj:3.030 [t=0.27s]
prediction: ["[CLS]'' we but category for'seen to we've before / about, great help this latest. much, get the from'director us makes'it of'wenation greatest of ofnation continent care [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.776 (perp=7.842, rec=0.207, cos=0.001), tot_loss_proj:2.865 [t=0.26s]
prediction: ["[CLS]'''but category for'seen for we've before / about, great help this latest. much, from nation the'director us makes'it of'wenation greatest of ofnation world care [SEP]"]
[1050/2000] tot_loss=1.746 (perp=7.797, rec=0.186, cos=0.000), tot_loss_proj:2.828 [t=0.26s]
prediction: ["[CLS]'''but category for'seen for we've before / about, great help this latest. much, from really the'director us makes'it in'wenation greatest of of rein world care [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.791 (perp=7.904, rec=0.210, cos=0.001), tot_loss_proj:2.885 [t=0.26s]
prediction: ["[CLS]'''but category of'seen it we've before / with, great help this latest. much, robert lot the'director us makes'to in'wenation greatest of of rein world care [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.691 (perp=7.400, rec=0.211, cos=0.000), tot_loss_proj:2.839 [t=0.26s]
prediction: ["[CLS]'''but category of'seen it we've before / with, great help this latest. much, from the really'director us makes'to in'wenation greatest of of rein continent care [SEP]"]
[1200/2000] tot_loss=1.673 (perp=7.410, rec=0.190, cos=0.000), tot_loss_proj:2.987 [t=0.26s]
prediction: ["[CLS]'''but category of'seen it we've before as with, great help this latest. much, from the lot'director us makes '. in s wenation greatest, of rein continent care [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.645 (perp=7.270, rec=0.190, cos=0.000), tot_loss_proj:2.936 [t=0.26s]
prediction: ["[CLS]'''but category of'seen it we've before as much, great help this latest. with, from the lot'director us makes '. in s wenation greatest, of rein continent care [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.626 (perp=7.206, rec=0.185, cos=0.000), tot_loss_proj:2.845 [t=0.26s]
prediction: ["[CLS] ','but category in'seen it we've before as much, great help this latest. with'from the lot'director us makes '. in s wenation greatest, of rein continent care [SEP]"]
[1350/2000] tot_loss=1.659 (perp=7.337, rec=0.191, cos=0.000), tot_loss_proj:2.949 [t=0.26s]
prediction: ["[CLS] ','but category in'seen it we've before as much, great help this latest. with'from the really'director us makes '. in s wenation greatest, of rein continent care [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.609 (perp=7.125, rec=0.184, cos=0.000), tot_loss_proj:2.809 [t=0.26s]
prediction: ["[CLS] ','but category in'seen it we've before as much, great help this latest. with'from the lot'director us makes '. we s innation greatest, of rein teacher care [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.564 (perp=6.886, rec=0.187, cos=0.000), tot_loss_proj:2.740 [t=0.26s]
prediction: ["[CLS] ','but category in'before it we've seen as much, great help this latest. with'from the really'director us makes '. we'innation greatest, of rein teacher care [SEP]"]
[1500/2000] tot_loss=1.567 (perp=6.886, rec=0.189, cos=0.000), tot_loss_proj:2.743 [t=0.26s]
prediction: ["[CLS] ','but category in'before it we've seen as much, great help this latest. with'from the really'director us makes '. we'innation greatest, of rein teacher care [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.596 (perp=7.061, rec=0.183, cos=0.000), tot_loss_proj:2.512 [t=0.25s]
prediction: ["[CLS] ','but category in'before it we've seen as much, great help this latest. with'from the worldcy director us makes '. we'innation greatest, of rein really care [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.560 (perp=6.836, rec=0.192, cos=0.000), tot_loss_proj:2.455 [t=0.25s]
prediction: ["[CLS] ','but category in'before it we've seen / much, great help this latest. with'from the worldcy director us makes '. of'innation greatest, we rein really care [SEP]"]
[1650/2000] tot_loss=1.567 (perp=6.941, rec=0.179, cos=0.000), tot_loss_proj:2.592 [t=0.27s]
prediction: ["[CLS] ','but category have'before it we've seen / much, great help this latest. with'from the teachercy director us makes '. of'innation greatest, we rein really care [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.570 (perp=6.941, rec=0.181, cos=0.000), tot_loss_proj:2.590 [t=0.25s]
prediction: ["[CLS] ','but category have'before it we've seen / much, great help this latest. with'from the teachercy director us makes '. of'innation greatest, we rein really care [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.573 (perp=6.978, rec=0.177, cos=0.000), tot_loss_proj:2.615 [t=0.25s]
prediction: ["[CLS] ','category but have'before it,'ve seen / much, great help this latest. about'from the teachercy director us makes '. of'innation greatest, we rein really care [SEP]"]
[1800/2000] tot_loss=1.574 (perp=6.983, rec=0.177, cos=0.000), tot_loss_proj:2.508 [t=0.26s]
prediction: ["[CLS] ','category but in'before it,'ve seen as much, great help this latest. about'from the teachercy director us makes '. of'innation greatest, we rein really care [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.577 (perp=7.000, rec=0.177, cos=0.000), tot_loss_proj:2.525 [t=0.25s]
prediction: ["[CLS] ', but'category in'before it,'ve seen / much, great help this latest. about'from the teachercy director us makes '. of'innation greatest, we rein really care [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.521 (perp=6.732, rec=0.174, cos=0.000), tot_loss_proj:2.530 [t=0.26s]
prediction: ["[CLS] ', but'category in'before it,'ve seen as much of great help this latest. about'from the teachercy director us makes '.,'innation greatest, we rein really care [SEP]"]
[1950/2000] tot_loss=1.534 (perp=6.814, rec=0.171, cos=0.000), tot_loss_proj:2.579 [t=0.27s]
prediction: ["[CLS] ', but'category in'before it we've seen as much of great help this latest. about'from the teachercy director us makes '.,'innation greatest, we rein really care [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.570 (perp=6.994, rec=0.171, cos=0.000), tot_loss_proj:2.623 [t=0.25s]
prediction: ["[CLS] ', but'category ve'before it we've seen as much of great help this latest. about'from the teachercy director us makes '.,'innation greatest, we rein really care [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] before'we but ve with'seen. we've '. the, great help this latest ( much experience, the greatest inner director us makes the it all from wenation greatest, wenation teacher care [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.672 | p: 68.750 | r: 62.857
rouge2     | fm: 12.308 | p: 12.903 | r: 11.765
rougeL     | fm: 35.821 | p: 37.500 | r: 34.286
rougeLsum  | fm: 35.821 | p: 37.500 | r: 34.286
r1fm+r2fm = 77.979

[Aggregate metrics]:
rouge1     | fm: 87.580 | p: 87.503 | r: 87.710
rouge2     | fm: 54.802 | p: 54.683 | r: 54.893
rougeL     | fm: 76.443 | p: 76.351 | r: 76.651
rougeLsum  | fm: 76.107 | p: 76.127 | r: 76.284
r1fm+r2fm = 142.382

input #35 time: 0:11:03 | total time: 5:39:55


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
*********************************
*********************************
average of cosine similarity 0.9992842743865826
highest_index [0]
highest [0.9992842743865826]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 1.9766509532928467 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 1.881966471672058 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 1.782330870628357 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 1.6660853624343872 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 1.6349523067474365 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 1.2444989681243896 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 1.241437554359436 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 1.2356886863708496 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 1.2343624830245972 for ['[CLS] ramsey harassment cornelius bates [SEP]']
[Init] best perm rec loss: 1.2221870422363281 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.568 (perp=11.389, rec=0.283, cos=0.007), tot_loss_proj:2.762 [t=0.25s]
prediction: ['[CLS] severely wrong horribly wrong [SEP]']
[ 100/2000] tot_loss=1.893 (perp=8.844, rec=0.123, cos=0.002), tot_loss_proj:2.233 [t=0.25s]
prediction: ['[CLS] horribly wrong horribly wrong [SEP]']
[ 150/2000] tot_loss=2.171 (perp=10.398, rec=0.090, cos=0.001), tot_loss_proj:2.674 [t=0.25s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 200/2000] tot_loss=2.152 (perp=10.398, rec=0.072, cos=0.001), tot_loss_proj:2.663 [t=0.26s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.869 (perp=8.829, rec=0.102, cos=0.002), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.848 (perp=8.829, rec=0.082, cos=0.001), tot_loss_proj:2.127 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.835 (perp=8.829, rec=0.069, cos=0.001), tot_loss_proj:2.116 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.839 (perp=8.829, rec=0.072, cos=0.001), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=1.840 (perp=8.829, rec=0.073, cos=0.001), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.833 (perp=8.829, rec=0.066, cos=0.001), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.825 (perp=8.829, rec=0.058, cos=0.001), tot_loss_proj:2.129 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 600/2000] tot_loss=1.686 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.949 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.694 (perp=8.105, rec=0.073, cos=0.001), tot_loss_proj:1.949 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.690 (perp=8.105, rec=0.068, cos=0.001), tot_loss_proj:1.943 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.682 (perp=8.105, rec=0.061, cos=0.001), tot_loss_proj:1.943 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.684 (perp=8.105, rec=0.062, cos=0.001), tot_loss_proj:1.947 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.677 (perp=8.105, rec=0.055, cos=0.001), tot_loss_proj:1.954 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.684 (perp=8.105, rec=0.063, cos=0.001), tot_loss_proj:1.946 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.669 (perp=8.105, rec=0.047, cos=0.001), tot_loss_proj:1.944 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.105, rec=0.058, cos=0.001), tot_loss_proj:1.941 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.683 (perp=8.105, rec=0.061, cos=0.001), tot_loss_proj:1.949 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.692 (perp=8.105, rec=0.071, cos=0.001), tot_loss_proj:1.940 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.679 (perp=8.105, rec=0.058, cos=0.001), tot_loss_proj:1.939 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.681 (perp=8.105, rec=0.060, cos=0.001), tot_loss_proj:1.944 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.690 (perp=8.105, rec=0.068, cos=0.001), tot_loss_proj:1.951 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.685 (perp=8.105, rec=0.063, cos=0.001), tot_loss_proj:1.941 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.672 (perp=8.105, rec=0.050, cos=0.001), tot_loss_proj:1.944 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.679 (perp=8.105, rec=0.058, cos=0.001), tot_loss_proj:1.940 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.674 (perp=8.105, rec=0.053, cos=0.001), tot_loss_proj:1.936 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.688 (perp=8.105, rec=0.067, cos=0.001), tot_loss_proj:1.943 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.684 (perp=8.105, rec=0.062, cos=0.001), tot_loss_proj:1.947 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.689 (perp=8.105, rec=0.067, cos=0.001), tot_loss_proj:1.946 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.679 (perp=8.105, rec=0.058, cos=0.001), tot_loss_proj:1.957 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.686 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.949 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.680 (perp=8.105, rec=0.058, cos=0.001), tot_loss_proj:1.950 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.686 (perp=8.105, rec=0.065, cos=0.001), tot_loss_proj:1.946 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.696 (perp=8.105, rec=0.074, cos=0.001), tot_loss_proj:1.947 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.687 (perp=8.105, rec=0.065, cos=0.001), tot_loss_proj:1.948 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.688 (perp=8.105, rec=0.066, cos=0.001), tot_loss_proj:1.946 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.684 (perp=8.105, rec=0.062, cos=0.001), tot_loss_proj:1.940 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.873 | p: 87.873 | r: 88.062
rouge2     | fm: 56.119 | p: 56.034 | r: 56.223
rougeL     | fm: 77.125 | p: 77.137 | r: 77.272
rougeLsum  | fm: 76.798 | p: 76.704 | r: 76.887
r1fm+r2fm = 143.992

input #36 time: 0:10:51 | total time: 5:50:46


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
*********************************
*********************************
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 1.5322908163070679 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 1.5074071884155273 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 1.484743595123291 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 1.427294373512268 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 1.2968673706054688 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 1.2020169496536255 for ['[CLS] quite sketch [SEP]']
[Init] best rec loss: 1.1809109449386597 for ['[CLS] plainly holstein [SEP]']
[Init] best rec loss: 1.063669204711914 for ['[CLS] time speaker [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.585 (perp=11.122, rec=0.336, cos=0.025), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] eccentric comic [SEP]']
[ 100/2000] tot_loss=2.400 (perp=10.822, rec=0.227, cos=0.009), tot_loss_proj:2.553 [t=0.24s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.353 (perp=10.822, rec=0.179, cos=0.009), tot_loss_proj:2.555 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 200/2000] tot_loss=2.332 (perp=10.822, rec=0.158, cos=0.009), tot_loss_proj:2.560 [t=0.27s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.301 (perp=10.822, rec=0.133, cos=0.004), tot_loss_proj:2.558 [t=0.26s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 300/2000] tot_loss=2.311 (perp=10.822, rec=0.141, cos=0.005), tot_loss_proj:2.555 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.299 (perp=10.822, rec=0.130, cos=0.004), tot_loss_proj:2.545 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.301 (perp=10.822, rec=0.133, cos=0.003), tot_loss_proj:2.544 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 450/2000] tot_loss=2.290 (perp=10.822, rec=0.123, cos=0.003), tot_loss_proj:2.559 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.300 (perp=10.822, rec=0.132, cos=0.004), tot_loss_proj:2.563 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.306 (perp=10.822, rec=0.140, cos=0.002), tot_loss_proj:2.561 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 600/2000] tot_loss=2.286 (perp=10.822, rec=0.120, cos=0.002), tot_loss_proj:2.562 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.288 (perp=10.822, rec=0.121, cos=0.002), tot_loss_proj:2.568 [t=0.27s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.288 (perp=10.822, rec=0.122, cos=0.002), tot_loss_proj:2.563 [t=0.26s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 750/2000] tot_loss=2.278 (perp=10.822, rec=0.112, cos=0.002), tot_loss_proj:2.562 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.257 (perp=10.822, rec=0.092, cos=0.001), tot_loss_proj:2.554 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.978 (perp=9.583, rec=0.061, cos=0.000), tot_loss_proj:2.021 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.979 (perp=9.583, rec=0.062, cos=0.000), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.981 (perp=9.583, rec=0.064, cos=0.000), tot_loss_proj:2.034 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.980 (perp=9.583, rec=0.063, cos=0.000), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.985 (perp=9.583, rec=0.068, cos=0.000), tot_loss_proj:2.026 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.980 (perp=9.583, rec=0.063, cos=0.000), tot_loss_proj:2.023 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.995 (perp=9.583, rec=0.078, cos=0.000), tot_loss_proj:2.027 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.981 (perp=9.583, rec=0.064, cos=0.000), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.983 (perp=9.583, rec=0.066, cos=0.000), tot_loss_proj:2.026 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.983 (perp=9.583, rec=0.066, cos=0.000), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.583, rec=0.053, cos=0.000), tot_loss_proj:2.023 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.977 (perp=9.583, rec=0.060, cos=0.000), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.983 (perp=9.583, rec=0.066, cos=0.000), tot_loss_proj:2.030 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.990 (perp=9.583, rec=0.073, cos=0.000), tot_loss_proj:2.026 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.966 (perp=9.583, rec=0.049, cos=0.000), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.984 (perp=9.583, rec=0.067, cos=0.000), tot_loss_proj:2.032 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.992 (perp=9.583, rec=0.075, cos=0.000), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.978 (perp=9.583, rec=0.061, cos=0.000), tot_loss_proj:2.027 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.976 (perp=9.583, rec=0.059, cos=0.000), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.987 (perp=9.583, rec=0.070, cos=0.000), tot_loss_proj:2.023 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.976 (perp=9.583, rec=0.059, cos=0.000), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.983 (perp=9.583, rec=0.066, cos=0.000), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.976 (perp=9.583, rec=0.059, cos=0.000), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.981 (perp=9.583, rec=0.064, cos=0.000), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.271 | p: 88.242 | r: 88.447
rouge2     | fm: 57.187 | p: 57.053 | r: 57.349
rougeL     | fm: 77.665 | p: 77.691 | r: 77.863
rougeLsum  | fm: 77.313 | p: 77.237 | r: 77.370
r1fm+r2fm = 145.458

input #37 time: 0:10:51 | total time: 6:01:38


Running input #38 of 100.
reference: 
========================
scare 
========================
*********************************
*********************************
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 1.7612740993499756 for ['[CLS] course [SEP]']
[Init] best rec loss: 1.7215585708618164 for ['[CLS]st [SEP]']
[Init] best rec loss: 1.6414412260055542 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 1.4560658931732178 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 1.382164716720581 for ['[CLS] private [SEP]']
[Init] best rec loss: 1.3276795148849487 for ['[CLS] sergeant [SEP]']
[Init] best rec loss: 1.1771332025527954 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.000 (perp=14.069, rec=0.176, cos=0.011), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.902 (perp=14.069, rec=0.087, cos=0.001), tot_loss_proj:2.884 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.892 (perp=14.069, rec=0.076, cos=0.002), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.000), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.000), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.870 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.868 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.890 (perp=14.069, rec=0.076, cos=0.000), tot_loss_proj:2.878 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.876 (perp=14.069, rec=0.062, cos=0.000), tot_loss_proj:2.877 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.880 (perp=14.069, rec=0.066, cos=0.000), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.000), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.880 (perp=14.069, rec=0.066, cos=0.000), tot_loss_proj:2.895 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.876 (perp=14.069, rec=0.062, cos=0.000), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.871 (perp=14.069, rec=0.057, cos=0.000), tot_loss_proj:2.870 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.882 (perp=14.069, rec=0.068, cos=0.000), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.878 (perp=14.069, rec=0.064, cos=0.000), tot_loss_proj:2.886 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.879 (perp=14.069, rec=0.065, cos=0.000), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.871 (perp=14.069, rec=0.057, cos=0.000), tot_loss_proj:2.882 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.877 (perp=14.069, rec=0.063, cos=0.000), tot_loss_proj:2.871 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.880 (perp=14.069, rec=0.066, cos=0.000), tot_loss_proj:2.872 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.871 (perp=14.069, rec=0.057, cos=0.000), tot_loss_proj:2.880 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.870 (perp=14.069, rec=0.056, cos=0.000), tot_loss_proj:2.884 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.877 (perp=14.069, rec=0.063, cos=0.000), tot_loss_proj:2.875 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.870 (perp=14.069, rec=0.056, cos=0.000), tot_loss_proj:2.859 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.867 (perp=14.069, rec=0.053, cos=0.000), tot_loss_proj:2.880 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.868 (perp=14.069, rec=0.054, cos=0.000), tot_loss_proj:2.881 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.877 (perp=14.069, rec=0.063, cos=0.000), tot_loss_proj:2.880 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.876 (perp=14.069, rec=0.062, cos=0.000), tot_loss_proj:2.877 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.875 (perp=14.069, rec=0.061, cos=0.000), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.880 (perp=14.069, rec=0.066, cos=0.000), tot_loss_proj:2.872 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.874 (perp=14.069, rec=0.060, cos=0.000), tot_loss_proj:2.861 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.879 (perp=14.069, rec=0.065, cos=0.000), tot_loss_proj:2.872 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.865 (perp=14.069, rec=0.051, cos=0.000), tot_loss_proj:2.870 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.000), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.000), tot_loss_proj:2.875 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.876 (perp=14.069, rec=0.062, cos=0.000), tot_loss_proj:2.864 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.865 (perp=14.069, rec=0.051, cos=0.000), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.871 (perp=14.069, rec=0.057, cos=0.000), tot_loss_proj:2.867 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.865 (perp=14.069, rec=0.051, cos=0.000), tot_loss_proj:2.884 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.871 (perp=14.069, rec=0.057, cos=0.000), tot_loss_proj:2.872 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.876 (perp=14.069, rec=0.062, cos=0.000), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.574 | p: 88.499 | r: 88.687
rouge2     | fm: 58.411 | p: 58.354 | r: 58.504
rougeL     | fm: 78.278 | p: 78.195 | r: 78.444
rougeLsum  | fm: 78.021 | p: 77.975 | r: 78.128
r1fm+r2fm = 146.985

input #38 time: 0:10:43 | total time: 6:12:22


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
*********************************
*********************************
average of cosine similarity 0.9992526747729695
highest_index [0]
highest [0.9992526747729695]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 2.0013740062713623 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 2.001059055328369 for ['[CLS] foughtcles yearssy city locations helping interception steve rat raising dos n poor words who agents blair reformationio acquired 1945 accent loss warren [SEP]']
[Init] best rec loss: 1.9660497903823853 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 1.8613423109054565 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 1.8467004299163818 for ['[CLS] snails [UNK] archives though devin shadow branch bell reigns grounds ago los matthew little boyle word createdrid with wing of audience village sounded reached [SEP]']
[Init] best rec loss: 1.7600774765014648 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 1.74936044216156 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best rec loss: 1.7386794090270996 for ['[CLS] happens silk reads northwest walked peerage commandgu as legal ] erin comprehensive sampled commercial received sun green happens corrections splinter premiere colonel ground inclusive [SEP]']
[Init] best perm rec loss: 1.718573808670044 for ['[CLS] ] happens northwest sampled silk splinter received asgu corrections colonel sun walked peerage commercial comprehensive command legal reads premiere inclusive happens erin ground green [SEP]']
[Init] best perm rec loss: 1.7130188941955566 for ['[CLS] received happens sampled command silk corrections as inclusive happens walked premiere northwest reads sun splinter legal peeragegu ground colonel ] comprehensive erin commercial green [SEP]']
[Init] best perm rec loss: 1.6906909942626953 for ['[CLS] erin silk received colonel legal commercial ground happens premiere commandgu northwest sampled green ] sun walked inclusive peerage splinter happens comprehensive reads as corrections [SEP]']
[Init] best perm rec loss: 1.6896693706512451 for ['[CLS] happens sampled received reads as corrections inclusivegu splinter commercial walked ground silk green legal ] comprehensive colonel peerage sun happens northwest command erin premiere [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.712 (perp=11.470, rec=0.412, cos=0.006), tot_loss_proj:3.347 [t=0.26s]
prediction: ['[CLS] profile family received southern charter international once energy. alumni faith : competitivephimet that controversial chance shade art research honor documentary renaissance bio [SEP]']
[ 100/2000] tot_loss=2.677 (perp=11.861, rec=0.301, cos=0.003), tot_loss_proj:4.268 [t=0.25s]
prediction: ['[CLS] print family became conservative shopping african charles tradition. mistake faith see 21st revolution heritage conservativeching ] finding art research new libretto lost - [SEP]']
[ 150/2000] tot_loss=2.711 (perp=12.289, rec=0.252, cos=0.001), tot_loss_proj:3.992 [t=0.25s]
prediction: ['[CLS] relevance family became conservative shopping finds image tradition : mistake faith find 21st very baroque conservativeinport gave new conservative new productions gives - [SEP]']
[ 200/2000] tot_loss=2.566 (perp=11.720, rec=0.221, cos=0.001), tot_loss_proj:4.057 [t=0.27s]
prediction: ['[CLS] texture reality became conservative movie finds once tradition : washington truth find united very tradition conservativein anniversary give new hide new texture gives - [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.378 (perp=10.773, rec=0.220, cos=0.003), tot_loss_proj:3.610 [t=0.25s]
prediction: ['[CLS] new texture reality many conservative movie most once traditions and - friends find more tradition conservativebound anniversary give new hide new texture gives - [SEP]']
[ 300/2000] tot_loss=2.093 (perp=9.543, rec=0.182, cos=0.002), tot_loss_proj:3.257 [t=0.25s]
prediction: ['[CLS] new texture reality many conservative movie most once traditions and - friends finds more tradition hidebound and, new hide new texture gives - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.046 (perp=9.336, rec=0.176, cos=0.003), tot_loss_proj:2.834 [t=0.26s]
prediction: ['[CLS] new texture reality many conservative movie most once traditions and - fiction finds of traditions hidebound and hide new, new texture gives, [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.900 (perp=8.687, rec=0.162, cos=0.001), tot_loss_proj:2.729 [t=0.28s]
prediction: ['[CLS] new texture reality many conservative movie - easter finds their most. traditions and tradition hidebound and hide new, new texture gives, [SEP]']
[ 450/2000] tot_loss=1.798 (perp=8.242, rec=0.149, cos=0.001), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] new texture we many conservative movie - reality finds their most. traditions and traditions hidebound and hide new, new texture gives, [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.773 (perp=8.156, rec=0.142, cos=0.000), tot_loss_proj:2.842 [t=0.26s]
prediction: ['[CLS] new texture we conservative movie - reality finds one most. many traditions and traditions hidebound and hide new, new reality gives, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.804 (perp=8.366, rec=0.130, cos=0.001), tot_loss_proj:3.165 [t=0.26s]
prediction: ['[CLS] most texture we conservative movie - reality finds one new. many traditions and movie hidebound and hide new, new reality gives, [SEP]']
[ 600/2000] tot_loss=1.747 (perp=8.141, rec=0.118, cos=0.001), tot_loss_proj:3.134 [t=0.27s]
prediction: ['[CLS] most texture our conservative movie - reality finds one new. of traditions and it hidebound and hide new, new reality gives, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.772 (perp=8.330, rec=0.106, cos=0.001), tot_loss_proj:3.002 [t=0.26s]
prediction: ['[CLS] most texture our conservative movie satellite reality finds one new. of it and traditions hidebound and hide new, new reality gives, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.779 (perp=8.369, rec=0.105, cos=0.001), tot_loss_proj:3.494 [t=0.27s]
prediction: ['[CLS] most texture our conservative movie satellite reality finds one new. of it and traditions hidebound making, new, new reality gives hide [SEP]']
[ 750/2000] tot_loss=1.748 (perp=8.207, rec=0.106, cos=0.000), tot_loss_proj:3.458 [t=0.25s]
prediction: ['[CLS] most texture our conservative movie reality reality finds one new. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.707 (perp=7.990, rec=0.108, cos=0.000), tot_loss_proj:3.476 [t=0.26s]
prediction: ['[CLS] most texture our conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.656 (perp=7.780, rec=0.099, cos=0.000), tot_loss_proj:3.426 [t=0.25s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
[ 900/2000] tot_loss=1.663 (perp=7.780, rec=0.106, cos=0.000), tot_loss_proj:3.428 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.651 (perp=7.780, rec=0.095, cos=0.000), tot_loss_proj:3.424 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
[1000/2000] tot_loss=1.645 (perp=7.780, rec=0.089, cos=0.000), tot_loss_proj:3.429 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
[1050/2000] tot_loss=1.654 (perp=7.780, rec=0.097, cos=0.000), tot_loss_proj:3.420 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
[1100/2000] tot_loss=1.643 (perp=7.780, rec=0.086, cos=0.000), tot_loss_proj:3.420 [t=0.27s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
[1150/2000] tot_loss=1.652 (perp=7.780, rec=0.096, cos=0.000), tot_loss_proj:3.428 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
[1200/2000] tot_loss=1.645 (perp=7.780, rec=0.089, cos=0.000), tot_loss_proj:3.427 [t=0.27s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
[1250/2000] tot_loss=1.644 (perp=7.780, rec=0.088, cos=0.000), tot_loss_proj:3.427 [t=0.27s]
prediction: ['[CLS] texture our most conservative movie reality finds one new reality. of it and traditions hidebound making, new, new reality gives hide [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.611 (perp=7.608, rec=0.089, cos=0.001), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality. of it and traditions hidebound reality, new, new reality gives hide [SEP]']
[1350/2000] tot_loss=1.600 (perp=7.608, rec=0.078, cos=0.000), tot_loss_proj:3.376 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality. of it and traditions hidebound reality, new, new reality gives hide [SEP]']
Attempt swap
[1400/2000] tot_loss=1.657 (perp=7.898, rec=0.077, cos=0.000), tot_loss_proj:3.436 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it and traditions hidebound reality, new, new reality gives hide [SEP]']
Attempt swap
[1450/2000] tot_loss=1.665 (perp=7.898, rec=0.085, cos=0.000), tot_loss_proj:3.436 [t=0.25s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it and traditions hidebound reality, new, new reality gives hide [SEP]']
[1500/2000] tot_loss=1.660 (perp=7.898, rec=0.080, cos=0.000), tot_loss_proj:3.436 [t=0.27s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it and traditions hidebound reality, new, new reality gives hide [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.596 (perp=7.502, rec=0.096, cos=0.001), tot_loss_proj:3.344 [t=0.25s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it, traditions hidebound reality and new, new reality gives hide [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.566 (perp=7.392, rec=0.087, cos=0.000), tot_loss_proj:3.305 [t=0.25s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives hide [SEP]']
[1650/2000] tot_loss=1.561 (perp=7.392, rec=0.082, cos=0.000), tot_loss_proj:3.306 [t=0.27s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives hide [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.392, rec=0.082, cos=0.000), tot_loss_proj:3.305 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives hide [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.392, rec=0.080, cos=0.000), tot_loss_proj:3.307 [t=0.26s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives hide [SEP]']
[1800/2000] tot_loss=1.561 (perp=7.392, rec=0.082, cos=0.000), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS] texture our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives hide [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.456 (perp=6.846, rec=0.086, cos=0.000), tot_loss_proj:2.825 [t=0.28s]
prediction: ['[CLS] hide our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives texture [SEP]']
Attempt swap
[1900/2000] tot_loss=1.458 (perp=6.846, rec=0.088, cos=0.000), tot_loss_proj:2.827 [t=0.26s]
prediction: ['[CLS] hide our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives texture [SEP]']
[1950/2000] tot_loss=1.459 (perp=6.846, rec=0.090, cos=0.000), tot_loss_proj:2.827 [t=0.26s]
prediction: ['[CLS] hide our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives texture [SEP]']
Attempt swap
[2000/2000] tot_loss=1.444 (perp=6.846, rec=0.074, cos=0.000), tot_loss_proj:2.827 [t=0.27s]
prediction: ['[CLS] hide our most conservative movie making finds one new reality and of it, traditions hidebound and new reality, new reality gives texture [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] texture our most conservative movie making finds one new reality and of it and traditions hidebound reality, new, new reality gives hide [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.304 | p: 87.500 | r: 95.455
rouge2     | fm: 22.727 | p: 21.739 | r: 23.810
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 114.032

[Aggregate metrics]:
rouge1     | fm: 88.742 | p: 88.587 | r: 89.002
rouge2     | fm: 57.797 | p: 57.690 | r: 57.926
rougeL     | fm: 77.732 | p: 77.622 | r: 77.895
rougeLsum  | fm: 77.117 | p: 77.046 | r: 77.323
r1fm+r2fm = 146.539

input #39 time: 0:11:05 | total time: 6:23:27


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
*********************************
*********************************
average of cosine similarity 0.9993178197074235
highest_index [0]
highest [0.9993178197074235]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 1.9793970584869385 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 1.7857263088226318 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 1.6468653678894043 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 1.6214605569839478 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 1.5489600896835327 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 1.5032769441604614 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 1.4233150482177734 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 1.3850464820861816 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 1.1546258926391602 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 1.1405655145645142 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 1.1383553743362427 for ['[CLS] deciding° but lady already kent georgian abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.515, rec=0.363, cos=0.005), tot_loss_proj:3.098 [t=0.25s]
prediction: ['[CLS] phone or angry mouth wolverhampton indefinitely information or stupid [SEP]']
[ 100/2000] tot_loss=2.593 (perp=11.651, rec=0.260, cos=0.003), tot_loss_proj:3.242 [t=0.26s]
prediction: ['[CLS] phone orony pummel indefinitelyony or wrong [SEP]']
[ 150/2000] tot_loss=2.424 (perp=11.170, rec=0.188, cos=0.002), tot_loss_proj:3.565 [t=0.25s]
prediction: ['[CLS] ph musicony pummel with music orony [SEP]']
[ 200/2000] tot_loss=2.317 (perp=10.871, rec=0.141, cos=0.002), tot_loss_proj:3.608 [t=0.25s]
prediction: ['[CLS] ph imageryony pummel with music orony [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.961 (perp=9.138, rec=0.131, cos=0.002), tot_loss_proj:2.363 [t=0.25s]
prediction: ['[CLS] phony imagery pummel with music orony [SEP]']
[ 300/2000] tot_loss=1.939 (perp=9.138, rec=0.110, cos=0.002), tot_loss_proj:2.364 [t=0.24s]
prediction: ['[CLS] phony imagery pummel with music orony [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.783 (perp=8.369, rec=0.108, cos=0.002), tot_loss_proj:2.230 [t=0.24s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.779 (perp=8.369, rec=0.103, cos=0.001), tot_loss_proj:2.225 [t=0.25s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
[ 450/2000] tot_loss=1.783 (perp=8.369, rec=0.107, cos=0.001), tot_loss_proj:2.229 [t=0.25s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.776 (perp=8.369, rec=0.100, cos=0.001), tot_loss_proj:2.218 [t=0.26s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.779 (perp=8.369, rec=0.104, cos=0.001), tot_loss_proj:2.223 [t=0.26s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
[ 600/2000] tot_loss=1.767 (perp=8.369, rec=0.092, cos=0.001), tot_loss_proj:2.226 [t=0.26s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.780 (perp=8.369, rec=0.105, cos=0.001), tot_loss_proj:2.215 [t=0.25s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.774 (perp=8.369, rec=0.099, cos=0.001), tot_loss_proj:2.232 [t=0.25s]
prediction: ['[CLS] phony imagery pummelony with music or [SEP]']
[ 750/2000] tot_loss=1.641 (perp=7.773, rec=0.086, cos=0.001), tot_loss_proj:2.057 [t=0.26s]
prediction: ['[CLS] phony imagery pummel us with music or [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.634 (perp=7.773, rec=0.079, cos=0.001), tot_loss_proj:2.061 [t=0.24s]
prediction: ['[CLS] phony imagery pummel us with music or [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.529 (perp=7.154, rec=0.098, cos=0.001), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[ 900/2000] tot_loss=1.500 (perp=7.154, rec=0.069, cos=0.001), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.496 (perp=7.154, rec=0.064, cos=0.001), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1000/2000] tot_loss=1.499 (perp=7.154, rec=0.068, cos=0.001), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1050/2000] tot_loss=1.507 (perp=7.154, rec=0.075, cos=0.001), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1100/2000] tot_loss=1.491 (perp=7.154, rec=0.060, cos=0.001), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1150/2000] tot_loss=1.508 (perp=7.154, rec=0.077, cos=0.001), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1200/2000] tot_loss=1.497 (perp=7.154, rec=0.065, cos=0.001), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1250/2000] tot_loss=1.499 (perp=7.154, rec=0.068, cos=0.001), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1300/2000] tot_loss=1.505 (perp=7.154, rec=0.074, cos=0.001), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1350/2000] tot_loss=1.496 (perp=7.154, rec=0.065, cos=0.001), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=7.154, rec=0.075, cos=0.001), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1450/2000] tot_loss=1.490 (perp=7.154, rec=0.059, cos=0.001), tot_loss_proj:1.726 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1500/2000] tot_loss=1.503 (perp=7.154, rec=0.072, cos=0.001), tot_loss_proj:1.744 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1550/2000] tot_loss=1.495 (perp=7.154, rec=0.064, cos=0.001), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1600/2000] tot_loss=1.500 (perp=7.154, rec=0.068, cos=0.001), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1650/2000] tot_loss=1.499 (perp=7.154, rec=0.067, cos=0.001), tot_loss_proj:1.744 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1700/2000] tot_loss=1.504 (perp=7.154, rec=0.073, cos=0.001), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1750/2000] tot_loss=1.503 (perp=7.154, rec=0.071, cos=0.001), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1800/2000] tot_loss=1.497 (perp=7.154, rec=0.066, cos=0.001), tot_loss_proj:1.749 [t=0.26s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1850/2000] tot_loss=1.507 (perp=7.154, rec=0.076, cos=0.001), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[1900/2000] tot_loss=1.492 (perp=7.154, rec=0.060, cos=0.001), tot_loss_proj:1.735 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
[1950/2000] tot_loss=1.498 (perp=7.154, rec=0.067, cos=0.001), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Attempt swap
[2000/2000] tot_loss=1.500 (perp=7.154, rec=0.069, cos=0.001), tot_loss_proj:1.744 [t=0.27s]
prediction: ['[CLS] imagery pummel us with phony music or [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery pummel us with phony music or [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 88.848 | p: 88.771 | r: 89.081
rouge2     | fm: 57.016 | p: 56.895 | r: 57.169
rougeL     | fm: 77.505 | p: 77.423 | r: 77.732
rougeLsum  | fm: 77.225 | p: 77.153 | r: 77.379
r1fm+r2fm = 145.864

input #40 time: 0:10:55 | total time: 6:34:22


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
*********************************
*********************************
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 1.978039026260376 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 1.9309391975402832 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 1.8171615600585938 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 1.5979645252227783 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 1.5801717042922974 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 1.5212957859039307 for ['[CLS] hauntedrily [SEP]']
[Init] best rec loss: 1.4396042823791504 for ["[CLS]'classification [SEP]"]
[Init] best rec loss: 1.402101993560791 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 1.0926122665405273 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 1.0066304206848145 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.258 (perp=10.212, rec=0.210, cos=0.005), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.134 (perp=10.212, rec=0.090, cos=0.002), tot_loss_proj:2.110 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.125 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.108 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.115 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.136 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.106 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.108 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.105 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.091 (perp=10.212, rec=0.048, cos=0.001), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.097 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.098 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.091 (perp=10.212, rec=0.048, cos=0.001), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.106 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.104 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.114 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.109 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.098 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.093 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.093 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.110 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.105 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.098 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.123 (perp=10.212, rec=0.079, cos=0.001), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.104 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.104 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.095 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.101 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.104 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.125 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.104 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.097 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.213 | p: 89.045 | r: 89.504
rouge2     | fm: 57.875 | p: 57.761 | r: 57.989
rougeL     | fm: 78.294 | p: 78.202 | r: 78.413
rougeLsum  | fm: 77.901 | p: 77.869 | r: 78.054
r1fm+r2fm = 147.088

input #41 time: 0:10:45 | total time: 6:45:08


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
*********************************
*********************************
average of cosine similarity 0.999325796096683
highest_index [0]
highest [0.999325796096683]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 1.8863037824630737 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 1.4476348161697388 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 1.359115481376648 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 1.262780785560608 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 1.261205792427063 for ['[CLS] anymore read jersey pain / did felt outcomes water shitnagar brazil main subsidiarylde mp materials miami four fr wondering neither kingdom begun throne album [SEP]']
[Init] best rec loss: 1.1889172792434692 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 1.1876097917556763 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 1.1862833499908447 for ['[CLS] assignmentbe international ran dare ever offendedgibleuresrs enoughtaking wish treaty scale larger attracted cut maplepling superseded kitchenctric banda lifted stages [SEP]']
[Init] best perm rec loss: 1.1856108903884888 for ['[CLS] supersededtakingctric international cut lifted ranrs largerbe kitchenpling assignment enough banda offendedures maple wish treaty attracted scale ever stagesgible dare [SEP]']
[Init] best perm rec loss: 1.1850471496582031 for ['[CLS]taking attracted wish dare ran international offended stagesctric cut superseded largerbe assignment treatypling scalegible enoughures ever lifted maplers banda kitchen [SEP]']
[Init] best perm rec loss: 1.1792911291122437 for ['[CLS] dare ran stages mapleures superseded kitchen banda internationalpling largerrs scale attracted assignmentctric offendedbe wishgible lifted treaty enough ever cuttaking [SEP]']
[Init] best perm rec loss: 1.179050087928772 for ['[CLS] offended dareures banda enough assignment larger ever maplepling attractedctrictaking ran superseded international treaty scale lifted wish kitchenrsgible stages cutbe [SEP]']
[Init] best perm rec loss: 1.173161506652832 for ['[CLS] kitchenures treaty enough ran wish liftedrsbegible superseded scale stages cut dare assignment larger banda ever maple attractedctric offended internationalplingtaking [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.241 (perp=14.268, rec=0.384, cos=0.003), tot_loss_proj:3.633 [t=0.26s]
prediction: ['[CLS] /ety block threatened romney struck issued scriptno they judicial mistake against mccain sampled council employeeslux claims radio dump alcohol overs backward worst bills [SEP]']
[ 100/2000] tot_loss=2.763 (perp=12.325, rec=0.297, cos=0.001), tot_loss_proj:3.191 [t=0.26s]
prediction: ['[CLS] /ety party threatened romney into violent script damage we because forgot against greek googleett lack mercury town claims smoke alcohol forgot poorly worst ticket [SEP]']
[ 150/2000] tot_loss=2.468 (perp=11.132, rec=0.241, cos=0.001), tot_loss_proj:2.974 [t=0.26s]
prediction: ['[CLS].ety logan waiting avoid into violent script category we as forgot to book somehowett lackbook village refer re school forgot poorly broadcasting system [SEP]']
[ 200/2000] tot_loss=2.679 (perp=12.381, rec=0.202, cos=0.001), tot_loss_proj:3.383 [t=0.30s]
prediction: ['[CLS].ety scary jail avoid into attack ic anything nothing as forgot to capitol presleygger lackbook fjord refer re school forgot poorly filmmakers system [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.646 (perp=12.335, rec=0.178, cos=0.000), tot_loss_proj:3.208 [t=0.27s]
prediction: ['[CLS].ety scary jail ic avoid into violent anything nothing as poorly to capitol wrathgger poorlygger indians filmmakers re school forgot poorly projects setting [SEP]']
[ 300/2000] tot_loss=2.626 (perp=12.292, rec=0.166, cos=0.002), tot_loss_proj:3.214 [t=0.26s]
prediction: ['[CLS].ety scary jail ic avoid into violent anything nothing as poorly to capitol wrathgger theygger spelled filmmakers re school forgot poorly projects setting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.469 (perp=11.643, rec=0.140, cos=0.001), tot_loss_proj:3.249 [t=0.27s]
prediction: ['[CLS].ety avoid scary jail ic into violent anything they as poorly to capitol wrathgger theyggergger filmmakers re school forgot poorly project setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.452 (perp=11.555, rec=0.140, cos=0.001), tot_loss_proj:2.986 [t=0.25s]
prediction: ['[CLS].ety barely scary depot ic into reported anything they as poorly to album wrathgger theygger school filmmakers regger forgot poorly project setting [SEP]']
[ 450/2000] tot_loss=2.524 (perp=11.954, rec=0.133, cos=0.000), tot_loss_proj:3.112 [t=0.26s]
prediction: ['[CLS].gger ு scary depot include into reported anything they as poorly to sequel षgger theygger school filmmakers regger forgot poorly project setting [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.442 (perp=11.586, rec=0.124, cos=0.000), tot_loss_proj:3.035 [t=0.26s]
prediction: ['[CLS].gger ு scary depot include into reported anything they as poorly sequel to षgger theygger school filmmakers regger forgot poorly project setting [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.381 (perp=11.216, rec=0.137, cos=0.001), tot_loss_proj:2.990 [t=0.27s]
prediction: ['[CLS].gger beyond violent attraction include into scary anything they as poorly sequel to षgger theygger school filmmakers regger forgot poorly project setting [SEP]']
[ 600/2000] tot_loss=2.430 (perp=11.546, rec=0.121, cos=0.000), tot_loss_proj:3.243 [t=0.26s]
prediction: ['[CLS].gger platinum anymore attraction include into scary anything they as poorly sequel to षgger they attraction school filmmakers regger forgot poorly project setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.372 (perp=11.297, rec=0.113, cos=0.000), tot_loss_proj:3.167 [t=0.26s]
prediction: ['[CLS].gger platinumgger attraction include into scary anything they as poorly sequel to ष violent they attraction school filmmakers regger forgot poorly project setting [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.340 (perp=11.124, rec=0.115, cos=0.000), tot_loss_proj:3.054 [t=0.28s]
prediction: ['[CLS]. attractiongger includegger include into scary anything they as poorly sequel to ष junk they attraction school filmmakers regger forgot poorly project setting [SEP]']
[ 750/2000] tot_loss=2.433 (perp=11.616, rec=0.109, cos=0.000), tot_loss_proj:3.133 [t=0.27s]
prediction: ['[CLS]. attractiongger halfwaygger include into scary anything they as poorly sequel to ष junk they attraction school filmmakers regger forgot poorly project setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.301 (perp=11.008, rec=0.099, cos=0.000), tot_loss_proj:3.083 [t=0.26s]
prediction: ['[CLS]. attractiongger attractiongger include into scary anything they as poorly sequel to ष junk they halfway school filmmakers regger forgot poorly project setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.270 (perp=10.781, rec=0.113, cos=0.001), tot_loss_proj:2.910 [t=0.25s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything they as poorly sequel to ष junk they halfway school filmmakers regger forgot poorly the setting [SEP]']
[ 900/2000] tot_loss=2.259 (perp=10.781, rec=0.103, cos=0.000), tot_loss_proj:2.906 [t=0.26s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything they as poorly sequel to ष junk they halfway school filmmakers regger forgot poorly the setting [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.258 (perp=10.727, rec=0.112, cos=0.000), tot_loss_proj:2.791 [t=0.25s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything as they poorly sequel to ष junk they halfway school filmmakers regger forgot poorly the setting [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.224 (perp=10.584, rec=0.107, cos=0.000), tot_loss_proj:2.772 [t=0.25s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything as they poorly sequel to ष junk they halfway school filmmakersjigger poorly forgot the setting [SEP]']
[1050/2000] tot_loss=2.311 (perp=11.031, rec=0.104, cos=0.000), tot_loss_proj:2.929 [t=0.27s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything as even poorlyudged to ष junk they halfway school filmmakersjigger poorly forgot the setting [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.296 (perp=10.958, rec=0.104, cos=0.000), tot_loss_proj:2.993 [t=0.27s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything as they poorlyiana to ष junk even halfway school filmmakersjigger poorly forgot the setting [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.255 (perp=10.787, rec=0.097, cos=0.000), tot_loss_proj:2.806 [t=0.28s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger to forgot the setting [SEP]']
[1200/2000] tot_loss=2.263 (perp=10.787, rec=0.105, cos=0.000), tot_loss_proj:2.813 [t=0.25s]
prediction: ['[CLS] project attractiongger attractiongger include into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger to forgot the setting [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.202 (perp=10.520, rec=0.098, cos=0.000), tot_loss_proj:2.747 [t=0.25s]
prediction: ["[CLS] project attraction'attractiongger include into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger to forgot the setting [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=2.212 (perp=10.572, rec=0.098, cos=0.000), tot_loss_proj:2.762 [t=0.25s]
prediction: ["[CLS] attraction project'attractiongger include into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger to forgot the setting [SEP]"]
[1350/2000] tot_loss=2.212 (perp=10.572, rec=0.097, cos=0.000), tot_loss_proj:2.767 [t=0.25s]
prediction: ["[CLS] attraction project'attractiongger include into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger to forgot the setting [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=2.199 (perp=10.510, rec=0.097, cos=0.000), tot_loss_proj:2.801 [t=0.26s]
prediction: ["[CLS] attraction project'attractiongger include into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.156 (perp=10.271, rec=0.101, cos=0.000), tot_loss_proj:2.731 [t=0.25s]
prediction: ["[CLS] attraction project 'gger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
[1500/2000] tot_loss=2.157 (perp=10.271, rec=0.103, cos=0.000), tot_loss_proj:2.728 [t=0.25s]
prediction: ["[CLS] attraction project 'gger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
Attempt swap
[1550/2000] tot_loss=2.147 (perp=10.271, rec=0.092, cos=0.000), tot_loss_proj:2.723 [t=0.26s]
prediction: ["[CLS] attraction project 'gger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
Attempt swap
[1600/2000] tot_loss=2.156 (perp=10.271, rec=0.101, cos=0.000), tot_loss_proj:2.725 [t=0.26s]
prediction: ["[CLS] attraction project 'gger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
[1650/2000] tot_loss=2.159 (perp=10.271, rec=0.104, cos=0.000), tot_loss_proj:2.729 [t=0.26s]
prediction: ["[CLS] attraction project 'gger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
Attempt swap
[1700/2000] tot_loss=2.146 (perp=10.271, rec=0.092, cos=0.000), tot_loss_proj:2.731 [t=0.26s]
prediction: ["[CLS] attraction project 'gger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.166 (perp=10.368, rec=0.093, cos=0.000), tot_loss_proj:2.778 [t=0.25s]
prediction: ['[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]']
[1800/2000] tot_loss=2.164 (perp=10.368, rec=0.090, cos=0.000), tot_loss_proj:2.781 [t=0.25s]
prediction: ['[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]']
Attempt swap
[1850/2000] tot_loss=2.170 (perp=10.368, rec=0.096, cos=0.000), tot_loss_proj:2.784 [t=0.25s]
prediction: ['[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]']
Attempt swap
[1900/2000] tot_loss=2.171 (perp=10.368, rec=0.097, cos=0.000), tot_loss_proj:2.781 [t=0.27s]
prediction: ['[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]']
[1950/2000] tot_loss=2.167 (perp=10.368, rec=0.093, cos=0.000), tot_loss_proj:2.785 [t=0.24s]
prediction: ['[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]']
Attempt swap
[2000/2000] tot_loss=2.162 (perp=10.368, rec=0.089, cos=0.000), tot_loss_proj:2.787 [t=0.25s]
prediction: ['[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] attraction project sgger include attraction into scary anything as they poorlyiana poorly ष junk they halfway school filmmakersjigger forgot to the setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.340 | p: 73.913 | r: 70.833
rouge2     | fm: 17.778 | p: 18.182 | r: 17.391
rougeL     | fm: 42.553 | p: 43.478 | r: 41.667
rougeLsum  | fm: 42.553 | p: 43.478 | r: 41.667
r1fm+r2fm = 90.118

[Aggregate metrics]:
rouge1     | fm: 88.778 | p: 88.744 | r: 88.949
rouge2     | fm: 57.057 | p: 56.913 | r: 57.180
rougeL     | fm: 77.363 | p: 77.260 | r: 77.493
rougeLsum  | fm: 76.978 | p: 76.881 | r: 77.118
r1fm+r2fm = 145.835

input #42 time: 0:11:02 | total time: 6:56:11


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
*********************************
*********************************
average of cosine similarity 0.9992732655805336
highest_index [0]
highest [0.9992732655805336]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 1.9562627077102661 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 1.9224357604980469 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 1.7678141593933105 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 1.59369695186615 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 1.452473521232605 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 1.360077977180481 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 1.2800770998001099 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 1.1548054218292236 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 1.0956354141235352 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 1.0862125158309937 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 1.082431435585022 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 1.0786867141723633 for ['[CLS]ck secondbus climb [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.393 (perp=15.358, rec=0.318, cos=0.004), tot_loss_proj:3.990 [t=0.25s]
prediction: ['[CLS] borebeisticfeit [SEP]']
[ 100/2000] tot_loss=2.721 (perp=12.549, rec=0.209, cos=0.002), tot_loss_proj:3.396 [t=0.25s]
prediction: ['[CLS] na naisticiss [SEP]']
[ 150/2000] tot_loss=2.454 (perp=11.440, rec=0.162, cos=0.004), tot_loss_proj:2.817 [t=0.26s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 200/2000] tot_loss=2.410 (perp=11.440, rec=0.121, cos=0.001), tot_loss_proj:2.807 [t=0.24s]
prediction: ['[CLS] naissisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.258 (perp=10.690, rec=0.119, cos=0.001), tot_loss_proj:2.407 [t=0.25s]
prediction: ['[CLS] naississistic [SEP]']
[ 300/2000] tot_loss=2.247 (perp=10.690, rec=0.108, cos=0.001), tot_loss_proj:2.421 [t=0.25s]
prediction: ['[CLS] naississistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.235 (perp=10.690, rec=0.096, cos=0.001), tot_loss_proj:2.410 [t=0.25s]
prediction: ['[CLS] naississistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.234 (perp=10.690, rec=0.095, cos=0.001), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] naississistic [SEP]']
[ 450/2000] tot_loss=2.239 (perp=10.690, rec=0.101, cos=0.001), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] naississistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.248 (perp=10.690, rec=0.109, cos=0.001), tot_loss_proj:2.410 [t=0.26s]
prediction: ['[CLS] naississistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.233 (perp=10.690, rec=0.094, cos=0.001), tot_loss_proj:2.414 [t=0.26s]
prediction: ['[CLS] naississistic [SEP]']
[ 600/2000] tot_loss=1.095 (perp=5.048, rec=0.085, cos=0.001), tot_loss_proj:1.075 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.085 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.093 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.078 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.082 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.074 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.076 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.083 (perp=5.048, rec=0.073, cos=0.001), tot_loss_proj:1.071 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.084 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.077 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.076 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.071 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.071 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.067 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.085 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.063 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.077 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.078 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.077 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.067 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.069 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.076 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.076 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.082 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.080 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.063 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.078 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.078 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.074 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.070 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.078 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.082 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.066 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.078 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.067 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.090 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.068 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.072 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.088 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.067 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.066 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.069 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.072 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.063 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.079 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.142 | p: 88.998 | r: 89.348
rouge2     | fm: 58.137 | p: 58.054 | r: 58.250
rougeL     | fm: 77.905 | p: 77.844 | r: 78.146
rougeLsum  | fm: 77.580 | p: 77.475 | r: 77.700
r1fm+r2fm = 147.279

input #43 time: 0:10:46 | total time: 7:06:57


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
*********************************
*********************************
average of cosine similarity 0.999241753470635
highest_index [0]
highest [0.999241753470635]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.8814524412155151 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.8753631114959717 for ['[CLS] here supporters psycho fighting at portal seconds published break store among color telegramachcing applicable stress tow ways been cervical landing wrists makes grew code dale visual crowley [SEP]']
[Init] best rec loss: 1.6184682846069336 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 1.566756248474121 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 1.5660165548324585 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best rec loss: 1.525803565979004 for ['[CLS] reservesdicated friendly sole rurallda counselan signals spec jamie americas foot emigrated tied [MASK] dex comfortdating artillery meditation joinednard readings eve solo ukraine why offspring [SEP]']
[Init] best perm rec loss: 1.5225293636322021 for ['[CLS] artillery [MASK] ukrainedatingnard signals joined sole friendly readings why counsel jamiedicated spec reserves offspring tied dex solo americaslda meditationan foot eve emigrated rural comfort [SEP]']
[Init] best perm rec loss: 1.5178302526474 for ['[CLS] foot friendlynard artillery why [MASK] meditation ukraine americasdicated comfortdating eve signals emigrated sole offspring reservesan joined tied rural jamielda dex counsel solo readings spec [SEP]']
[Init] best perm rec loss: 1.5158740282058716 for ['[CLS] comfort why meditation reserves signals counsel readings ukraine dex emigrated joined jamienarddating tied rural artillery americas friendlylda eve offspring [MASK]dicated solo foot solean spec [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.570 (perp=11.357, rec=0.296, cos=0.002), tot_loss_proj:3.005 [t=0.26s]
prediction: ['[CLS] disguise left invalid message missing the translation quite least proposals a lost any fucking the a prostitution print expression pete lost a armagh text appearance door \\es 場 [SEP]']
[ 100/2000] tot_loss=2.197 (perp=10.003, rec=0.195, cos=0.001), tot_loss_proj:3.067 [t=0.25s]
prediction: ['[CLS] which left lost ] lost in translation was losing worst a lost. routine bottle the coup cigarette translation reporting lost a routine evil stage. [CLS]ises advantages [SEP]']
[ 150/2000] tot_loss=2.306 (perp=10.785, rec=0.149, cos=0.001), tot_loss_proj:2.814 [t=0.26s]
prediction: ['[CLS] which left lost execution lost in translation been loses routine anotheralic. routine terrible the ರ hollywood translation reporting fright another slack hollywoodization..ises． [SEP]']
[ 200/2000] tot_loss=2.338 (perp=10.760, rec=0.184, cos=0.002), tot_loss_proj:3.268 [t=0.26s]
prediction: ['[CLS]. repair lost execution lost in translation has slack routine anotheralic - routine crazy the premise hollywood translation containing fright the slack hollywood execution..izes dhabi [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.189 (perp=10.037, rec=0.179, cos=0.003), tot_loss_proj:3.684 [t=0.26s]
prediction: ['[CLS]. inization execution lost in translation the hollywood hollywood execution kills fright the slack has slack premise anotheralic a routine hollywood hollywood plot fiction.ing quality [SEP]']
[ 300/2000] tot_loss=2.127 (perp=9.937, rec=0.139, cos=0.001), tot_loss_proj:3.343 [t=0.26s]
prediction: ['[CLS]. inization execution lost in translation the premise slack execution involving fright the slack has slack premise anotheraliced routine hollywood hollywoodity..ing quality [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.003 (perp=9.380, rec=0.126, cos=0.001), tot_loss_proj:2.556 [t=0.25s]
prediction: ['[CLS]. inization premise lost in translation the premise slack execution where fright the slack has slack execution anotheraliced routine hollywood hollywoodity..ing [SEP] [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.928 (perp=9.045, rec=0.119, cos=0.001), tot_loss_proj:2.483 [t=0.26s]
prediction: ['[CLS]. inization premise lost in translation the premise slackfest where fright the slack has slack execution anotheraliced routine hollywoodizes hollywoodity... [SEP]']
[ 450/2000] tot_loss=2.016 (perp=9.565, rec=0.102, cos=0.000), tot_loss_proj:2.571 [t=0.26s]
prediction: ['[CLS]. inization premise lost in translation the premise slackfest where fright the slack has slack execution anotheraliced routine hollywoodizes hollywoodity.. where [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.992 (perp=9.410, rec=0.110, cos=0.001), tot_loss_proj:2.497 [t=0.26s]
prediction: ['[CLS].alicization premise lost in translation the premise slackfest which fright the absurd has slack execution another in of routine hollywoodizes hollywoodity.. which [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.808 (perp=8.484, rec=0.111, cos=0.001), tot_loss_proj:2.268 [t=0.26s]
prediction: ['[CLS].alicization premise lost in translation the premise slackfest where fright the absurd has slack execution another ined routine hollywoodizes absurdity... [SEP]']
[ 600/2000] tot_loss=1.783 (perp=8.385, rec=0.106, cos=0.000), tot_loss_proj:2.280 [t=0.26s]
prediction: ['[CLS].alicization premise lost in translation the premise slackfest where fright the absurd has slack execution another in of routine hollywoodizes absurdity... [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.698 (perp=7.986, rec=0.101, cos=0.000), tot_loss_proj:2.132 [t=0.27s]
prediction: ['[CLS].alicization absurd lost in translation the premise slackfest where fright the absurd has slack in execution another of routine hollywoodizes absurdity... [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.715 (perp=8.145, rec=0.086, cos=0.000), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS].alicization absurd lost in translation the premise slackfest which fright the absurd has slack in execution another of routine hollywoodizes absurdity... [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.145, rec=0.091, cos=0.000), tot_loss_proj:2.170 [t=0.26s]
prediction: ['[CLS].alicization absurd lost in translation the premise slackfest which fright the absurd has slack in execution another of routine hollywoodizes absurdity... [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.680 (perp=7.935, rec=0.093, cos=0.000), tot_loss_proj:2.159 [t=0.27s]
prediction: ['[CLS].alicization absurd lost in translation the premise slackfest which fright the absurd has slack in execution another of hollywood routineizes absurdity... [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.637 (perp=7.783, rec=0.080, cos=0.000), tot_loss_proj:2.161 [t=0.25s]
prediction: ['[CLS]festalicization absurd lost in translation the premise slack. which fright the absurd has slack in execution another of hollywood routineizes absurdity... [SEP]']
[ 900/2000] tot_loss=1.641 (perp=7.783, rec=0.084, cos=0.000), tot_loss_proj:2.156 [t=0.29s]
prediction: ['[CLS]festalicization absurd lost in translation the premise slack. which fright the absurd has slack in execution another of hollywood routineizes absurdity... [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.575 (perp=7.464, rec=0.082, cos=0.000), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS]festalicization absurd lost in translation premise slack. the which fright the absurd has slack in execution another of hollywood routineizes absurdity... [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.530 (perp=7.244, rec=0.080, cos=0.000), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS]festalicization absurd lost in translation premise slack. the which fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
[1050/2000] tot_loss=1.531 (perp=7.244, rec=0.081, cos=0.000), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS]festalicization absurd lost in translation premise slack. the which fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
[1100/2000] tot_loss=1.530 (perp=7.244, rec=0.081, cos=0.000), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS]festalicization absurd lost in translation premise slack. the which fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
[1150/2000] tot_loss=1.585 (perp=7.535, rec=0.078, cos=0.000), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS]festalicizes absurd lost in translation premise slack. the which fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
[1200/2000] tot_loss=1.590 (perp=7.535, rec=0.083, cos=0.000), tot_loss_proj:2.203 [t=0.26s]
prediction: ['[CLS]festalicizes absurd lost in translation premise slack. the which fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.571 (perp=7.428, rec=0.085, cos=0.000), tot_loss_proj:2.183 [t=0.26s]
prediction: ['[CLS]festalicizes which lost in translation premise slack. the absurd fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.526 (perp=7.239, rec=0.078, cos=0.000), tot_loss_proj:2.235 [t=0.25s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
[1350/2000] tot_loss=1.521 (perp=7.239, rec=0.073, cos=0.000), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright the absurd has slack in execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.501 (perp=7.102, rec=0.080, cos=0.000), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd has slack execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.491 (perp=7.077, rec=0.075, cos=0.000), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
[1500/2000] tot_loss=1.489 (perp=7.077, rec=0.073, cos=0.000), tot_loss_proj:2.145 [t=0.27s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
[1550/2000] tot_loss=1.486 (perp=7.077, rec=0.070, cos=0.000), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.494 (perp=7.077, rec=0.079, cos=0.000), tot_loss_proj:2.133 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
[1650/2000] tot_loss=1.489 (perp=7.077, rec=0.074, cos=0.000), tot_loss_proj:2.130 [t=0.28s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.496 (perp=7.077, rec=0.080, cos=0.000), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.486 (perp=7.077, rec=0.070, cos=0.000), tot_loss_proj:2.134 [t=0.27s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
[1800/2000] tot_loss=1.487 (perp=7.077, rec=0.071, cos=0.000), tot_loss_proj:2.134 [t=0.27s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
[1850/2000] tot_loss=1.484 (perp=7.077, rec=0.068, cos=0.000), tot_loss_proj:2.133 [t=0.25s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
[1900/2000] tot_loss=1.491 (perp=7.077, rec=0.075, cos=0.000), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
[1950/2000] tot_loss=1.487 (perp=7.077, rec=0.072, cos=0.000), tot_loss_proj:2.130 [t=0.27s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Attempt swap
[2000/2000] tot_loss=1.493 (perp=7.077, rec=0.078, cos=0.000), tot_loss_proj:2.130 [t=0.28s]
prediction: ['[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS]festalicizes which lost slack in translation premise. the absurd fright in the absurd slack has execution of another hollywood routineizes absurdity... [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.913 | p: 73.913 | r: 73.913
rouge2     | fm: 4.545 | p: 4.545 | r: 4.545
rougeL     | fm: 43.478 | p: 43.478 | r: 43.478
rougeLsum  | fm: 43.478 | p: 43.478 | r: 43.478
r1fm+r2fm = 78.458

[Aggregate metrics]:
rouge1     | fm: 88.521 | p: 88.528 | r: 88.823
rouge2     | fm: 56.901 | p: 56.725 | r: 57.014
rougeL     | fm: 77.013 | p: 76.978 | r: 77.149
rougeLsum  | fm: 76.674 | p: 76.696 | r: 76.779
r1fm+r2fm = 145.422

input #44 time: 0:11:07 | total time: 7:18:04


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
*********************************
*********************************
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 1.9465147256851196 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 1.6877418756484985 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 1.6227409839630127 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 1.6042251586914062 for ['[CLS] folk rankedgistmetric furthereto herself pac stamp ma jaya descent foremost, case 11 simon installment marie it wizard lucivar sync mcbadscu keepers stable [SEP]']
[Init] best rec loss: 1.388287901878357 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 1.2057594060897827 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 1.2009996175765991 for ['[CLS] murmured tree whoa special taste five singletiv bore operated2 via football joan ku skin around enclosed ( letter gentry curtis v status military entrancelanda few [SEP]']
[Init] best perm rec loss: 1.1984952688217163 for ['[CLS] tree via gentry football taste operated skin ( status2 single bore curtis militarytiv murmured few ku five whoa special letter around v entrance joan enclosedlanda [SEP]']
[Init] best perm rec loss: 1.1982824802398682 for ['[CLS] entrance2 around v whoa tree status ku football murmured enclosedtiv taste joan military curtis ( bore few via letter single five special operatedlanda gentry skin [SEP]']
[Init] best perm rec loss: 1.1930371522903442 for ['[CLS] bore whoa fivelanda2 skin gentry militarytiv around single tree operated taste curtis few letter special murmured ku football entrance status joan ( v enclosed via [SEP]']
[Init] best perm rec loss: 1.1888641119003296 for ['[CLS] curtis bore status taste gentry enclosed via skin ( letter five tree single whoa2 murmured entrancelanda v ku military joan few around operated footballtiv special [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.883 (perp=12.391, rec=0.400, cos=0.004), tot_loss_proj:3.292 [t=0.25s]
prediction: ['[CLS] electrical informationy serial policy fixed jamaicanage mig party - track0sed sleep episode crude na barrel orgity serial for denied shop was study laundering [SEP]']
[ 100/2000] tot_loss=2.657 (perp=11.733, rec=0.309, cos=0.001), tot_loss_proj:3.370 [t=0.25s]
prediction: ['[CLS] phone information - down than than nunezl crime - - track0sed year episode pc na scare outburstcut shaft for phone - was studyie [SEP]']
[ 150/2000] tot_loss=2.285 (perp=10.119, rec=0.260, cos=0.001), tot_loss_proj:3.217 [t=0.26s]
prediction: ['[CLS] - movements - - than than nunezel question - - shelf shelf - color episode fi na barrel outburst cornered on for board -, campsie [SEP]']
[ 200/2000] tot_loss=2.211 (perp=9.616, rec=0.285, cos=0.003), tot_loss_proj:3.176 [t=0.26s]
prediction: ['[CLS] phone movements - ready movements than bowel sentence scene soft release point - by exercise away ca adventurepeled end - last - - longie [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.156 (perp=9.697, rec=0.215, cos=0.001), tot_loss_proj:3.334 [t=0.25s]
prediction: ['[CLS] - movements - launch movements than bowel sentence scene soft release point - × exercise shelf gasp moviepel last picture - fight - - longie [SEP]']
[ 300/2000] tot_loss=2.099 (perp=9.630, rec=0.172, cos=0.001), tot_loss_proj:3.048 [t=0.25s]
prediction: ['[CLS] - - - launch movements than bowel sentence scene soft release point - ‖ exercise shelf this moviema last shelf -ports - - way exercise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.980 (perp=9.118, rec=0.156, cos=0.000), tot_loss_proj:2.940 [t=0.25s]
prediction: ['[CLS] - - - launch movements than bowel sentence scene soft release point - - exercise shelf this dramama last shelf - shoot - - way exercise [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.004 (perp=9.318, rec=0.140, cos=0.001), tot_loss_proj:3.011 [t=0.25s]
prediction: ['[CLS] - - - soft movements than bowel lo scene launch release point - - exercise shelf this dramamm judge shelf long shoot - - way exercise [SEP]']
[ 450/2000] tot_loss=1.996 (perp=9.318, rec=0.132, cos=0.000), tot_loss_proj:3.014 [t=0.26s]
prediction: ['[CLS] - - - soft movements than bowel lo scene launch release point - - exercise shelf this dramamm judge shelf long shoot - - way exercise [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.893 (perp=8.846, rec=0.124, cos=0.000), tot_loss_proj:2.944 [t=0.28s]
prediction: ['[CLS] - - - soft movements than bowel lomm launch release point - - gi shelf this drama - judge shelf long shoot - - way exercise [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.916 (perp=8.967, rec=0.122, cos=0.001), tot_loss_proj:2.937 [t=0.26s]
prediction: ['[CLS] - - - lo movements than bowel softmm launch release point - - gi shelf this drama - judge shelf long shoot - -ick exercise [SEP]']
[ 600/2000] tot_loss=1.920 (perp=8.977, rec=0.124, cos=0.000), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] - - - lo movements than bowel softmm launch release point - - gi shelf this drama - - shelf long shoot, -ick exercise [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.819 (perp=8.502, rec=0.118, cos=0.000), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] - - - lo movements than bowel softmm launch release point - - gi shoot this drama - - shelf long shelf, -ick exercise [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.780 (perp=8.298, rec=0.120, cos=0.001), tot_loss_proj:2.665 [t=0.27s]
prediction: ['[CLS] - - - lo movements than bowel softmm launch release point -, gi shoot this drama - - shelf long shelf - -ick exercise [SEP]']
[ 750/2000] tot_loss=1.812 (perp=8.488, rec=0.114, cos=0.000), tot_loss_proj:2.620 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowel softmm launch release point -, gi shoot this drama - - shelf long shelf - -ick exercise [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.777 (perp=8.364, rec=0.104, cos=0.000), tot_loss_proj:2.626 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowelmm soft launch release point -, gi shoot this drama - - shelf long shelf - -ick exercise [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.779 (perp=8.364, rec=0.106, cos=0.000), tot_loss_proj:2.620 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowelmm soft launch release point -, gi shoot this drama - - shelf long shelf - -ick exercise [SEP]']
[ 900/2000] tot_loss=1.785 (perp=8.364, rec=0.111, cos=0.000), tot_loss_proj:2.621 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowelmm soft launch release point -, gi shoot this drama - - shelf long shelf - -ick exercise [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.773 (perp=8.364, rec=0.099, cos=0.000), tot_loss_proj:2.620 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowelmm soft launch release point -, gi shoot this drama - - shelf long shelf - -ick exercise [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.814 (perp=8.517, rec=0.111, cos=0.000), tot_loss_proj:2.810 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowelmm soft release launch point -, gi shoot this drama - - shelf long on - -ick exercise [SEP]']
[1050/2000] tot_loss=1.809 (perp=8.517, rec=0.105, cos=0.000), tot_loss_proj:2.811 [t=0.25s]
prediction: ['[CLS] the - - lo movements than bowelmm soft release launch point -, gi shoot this drama - - shelf long on - -ick exercise [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.726 (perp=8.153, rec=0.095, cos=0.000), tot_loss_proj:2.750 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowelmm soft release launch point -, gi shoot this drama - - long on - - shelfick exercise [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.153, rec=0.100, cos=0.000), tot_loss_proj:2.749 [t=0.31s]
prediction: ['[CLS] the - - lo movements than bowelmm soft release launch point -, gi shoot this drama - - long on - - shelfick exercise [SEP]']
[1200/2000] tot_loss=1.724 (perp=8.153, rec=0.094, cos=0.000), tot_loss_proj:2.786 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowelmm soft, launch point -, gi shoot this drama - - long on - - shelfick exercise [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.657 (perp=7.787, rec=0.099, cos=0.000), tot_loss_proj:2.594 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point -, gi shoot this drama - - long on - - shelf soft exercise [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.606 (perp=7.527, rec=0.100, cos=0.000), tot_loss_proj:2.788 [t=0.25s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point shelf, gi shoot this drama - - long on - - - soft exercise [SEP]']
[1350/2000] tot_loss=1.605 (perp=7.527, rec=0.099, cos=0.000), tot_loss_proj:2.792 [t=0.25s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point shelf, gi shoot this drama - - long on - - - soft exercise [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.527, rec=0.092, cos=0.000), tot_loss_proj:2.797 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point shelf, gi shoot this drama - - long on - - - soft exercise [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.598 (perp=7.527, rec=0.092, cos=0.000), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point shelf, gi shoot this drama - - long on - - - soft exercise [SEP]']
[1500/2000] tot_loss=1.606 (perp=7.527, rec=0.101, cos=0.000), tot_loss_proj:2.786 [t=0.28s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point shelf, gi shoot this drama - - long on - - - soft exercise [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=7.527, rec=0.088, cos=0.000), tot_loss_proj:2.792 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowelmmick, launch point shelf, gi shoot this drama - - long on - - - soft exercise [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.523 (perp=7.117, rec=0.098, cos=0.001), tot_loss_proj:2.422 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowel launch point shelf, gimmick, shoot this drama - - long on - - - hot exercise [SEP]']
[1650/2000] tot_loss=1.521 (perp=7.117, rec=0.097, cos=0.000), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowel launch point shelf, gimmick, shoot this drama - - long on - - - hot exercise [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.496 (perp=6.994, rec=0.096, cos=0.000), tot_loss_proj:2.490 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowel launch - shelf, gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.470 (perp=6.904, rec=0.089, cos=0.000), tot_loss_proj:2.459 [t=0.27s]
prediction: ['[CLS] the - - lo movements than bowel - launch shelf, gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
[1800/2000] tot_loss=1.476 (perp=6.904, rec=0.095, cos=0.000), tot_loss_proj:2.450 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowel - launch shelf, gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
Attempt swap
[1850/2000] tot_loss=1.478 (perp=6.904, rec=0.097, cos=0.000), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowel - launch shelf, gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.462 (perp=6.845, rec=0.092, cos=0.000), tot_loss_proj:2.474 [t=0.25s]
prediction: ['[CLS] the - - lo movements than bowel -, shelf launch gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
[1950/2000] tot_loss=1.465 (perp=6.845, rec=0.096, cos=0.000), tot_loss_proj:2.469 [t=0.26s]
prediction: ['[CLS] the - - lo movements than bowel -, shelf launch gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.392 (perp=6.466, rec=0.098, cos=0.000), tot_loss_proj:2.483 [t=0.26s]
prediction: ['[CLS], - - lo movements than bowel - the shelf launch gimmick, shoot this drama - - long on point - - hot exercise [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS], - - lo movements than bowel - the shelf launch gimmick, shoot this drama - - long on point - - hot exercise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 17.647 | p: 17.647 | r: 17.647
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 95.425

[Aggregate metrics]:
rouge1     | fm: 88.466 | p: 88.379 | r: 88.660
rouge2     | fm: 55.726 | p: 55.700 | r: 55.857
rougeL     | fm: 76.464 | p: 76.475 | r: 76.518
rougeLsum  | fm: 76.063 | p: 76.081 | r: 76.193
r1fm+r2fm = 144.192

input #45 time: 0:11:05 | total time: 7:29:09


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
*********************************
*********************************
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 1.990432858467102 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 1.9770787954330444 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 1.9074907302856445 for ['[CLS]ch believed councils panel law battery [SEP]']
[Init] best rec loss: 1.7174855470657349 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 1.7164666652679443 for ['[CLS] adaptedator shell whether ordinary convincing [SEP]']
[Init] best rec loss: 1.6811225414276123 for ['[CLS] sank including privately heritage surfaced falcon [SEP]']
[Init] best rec loss: 1.6083678007125854 for ['[CLS]sur darius ontario avery never lives [SEP]']
[Init] best perm rec loss: 1.6035552024841309 for ['[CLS] darius neversur avery lives ontario [SEP]']
[Init] best perm rec loss: 1.6031556129455566 for ['[CLS] neversur darius avery ontario lives [SEP]']
[Init] best perm rec loss: 1.5998085737228394 for ['[CLS] never dariussur avery lives ontario [SEP]']
[Init] best perm rec loss: 1.5986922979354858 for ['[CLS]sur lives darius avery never ontario [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=12.732, rec=0.253, cos=0.004), tot_loss_proj:3.308 [t=0.27s]
prediction: ['[CLS] hugh visually striking staged trulynous [SEP]']
[ 100/2000] tot_loss=2.366 (perp=10.910, rec=0.182, cos=0.002), tot_loss_proj:2.644 [t=0.28s]
prediction: ['[CLS] slick visually slick staged visually visually [SEP]']
[ 150/2000] tot_loss=2.251 (perp=10.547, rec=0.140, cos=0.002), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] slick visually slick staged visually striking [SEP]']
[ 200/2000] tot_loss=1.956 (perp=9.259, rec=0.103, cos=0.001), tot_loss_proj:2.204 [t=0.25s]
prediction: ['[CLS] slick visually striking staged visually striking [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.695 (perp=8.020, rec=0.090, cos=0.001), tot_loss_proj:1.933 [t=0.25s]
prediction: ['[CLS] slick staged and visually striking striking [SEP]']
[ 300/2000] tot_loss=1.702 (perp=8.020, rec=0.097, cos=0.001), tot_loss_proj:1.939 [t=0.26s]
prediction: ['[CLS] slick staged and visually striking striking [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.626 (perp=7.631, rec=0.098, cos=0.001), tot_loss_proj:1.928 [t=0.25s]
prediction: ['[CLS] slick staged striking and visually striking [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.610 (perp=7.631, rec=0.083, cos=0.001), tot_loss_proj:1.940 [t=0.25s]
prediction: ['[CLS] slick staged striking and visually striking [SEP]']
[ 450/2000] tot_loss=1.719 (perp=8.197, rec=0.079, cos=0.001), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] slick stagedly and visually striking [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.393 (perp=6.580, rec=0.076, cos=0.001), tot_loss_proj:1.487 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.382 (perp=6.580, rec=0.065, cos=0.001), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 600/2000] tot_loss=1.393 (perp=6.580, rec=0.076, cos=0.001), tot_loss_proj:1.481 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.384 (perp=6.580, rec=0.067, cos=0.001), tot_loss_proj:1.497 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.368 (perp=6.580, rec=0.051, cos=0.001), tot_loss_proj:1.481 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 750/2000] tot_loss=1.395 (perp=6.580, rec=0.078, cos=0.001), tot_loss_proj:1.484 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.377 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.484 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.376 (perp=6.580, rec=0.059, cos=0.001), tot_loss_proj:1.493 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 900/2000] tot_loss=1.381 (perp=6.580, rec=0.064, cos=0.001), tot_loss_proj:1.494 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.396 (perp=6.580, rec=0.079, cos=0.001), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1000/2000] tot_loss=1.382 (perp=6.580, rec=0.065, cos=0.001), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1050/2000] tot_loss=1.382 (perp=6.580, rec=0.065, cos=0.001), tot_loss_proj:1.497 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1100/2000] tot_loss=1.370 (perp=6.580, rec=0.053, cos=0.001), tot_loss_proj:1.492 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.387 (perp=6.580, rec=0.070, cos=0.001), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1200/2000] tot_loss=1.390 (perp=6.580, rec=0.074, cos=0.001), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1250/2000] tot_loss=1.379 (perp=6.580, rec=0.062, cos=0.001), tot_loss_proj:1.500 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.366 (perp=6.580, rec=0.049, cos=0.001), tot_loss_proj:1.499 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1350/2000] tot_loss=1.388 (perp=6.580, rec=0.072, cos=0.001), tot_loss_proj:1.501 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.580, rec=0.078, cos=0.001), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.388 (perp=6.580, rec=0.071, cos=0.001), tot_loss_proj:1.483 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1500/2000] tot_loss=1.392 (perp=6.580, rec=0.075, cos=0.001), tot_loss_proj:1.485 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.392 (perp=6.580, rec=0.075, cos=0.001), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1600/2000] tot_loss=1.387 (perp=6.580, rec=0.070, cos=0.001), tot_loss_proj:1.497 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1650/2000] tot_loss=1.385 (perp=6.580, rec=0.068, cos=0.001), tot_loss_proj:1.487 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.383 (perp=6.580, rec=0.066, cos=0.001), tot_loss_proj:1.491 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.377 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.482 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1800/2000] tot_loss=1.376 (perp=6.580, rec=0.059, cos=0.001), tot_loss_proj:1.490 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.387 (perp=6.580, rec=0.070, cos=0.001), tot_loss_proj:1.501 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.385 (perp=6.580, rec=0.068, cos=0.001), tot_loss_proj:1.497 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1950/2000] tot_loss=1.381 (perp=6.580, rec=0.064, cos=0.001), tot_loss_proj:1.488 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.375 (perp=6.580, rec=0.058, cos=0.001), tot_loss_proj:1.509 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] slickly staged and visually striking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 88.672 | p: 88.616 | r: 88.874
rouge2     | fm: 55.291 | p: 55.222 | r: 55.470
rougeL     | fm: 76.017 | p: 75.924 | r: 76.184
rougeLsum  | fm: 75.743 | p: 75.644 | r: 75.867
r1fm+r2fm = 143.963

input #46 time: 0:10:49 | total time: 7:39:59


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
*********************************
*********************************
average of cosine similarity 0.9992059059142621
highest_index [0]
highest [0.9992059059142621]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 1.1954387426376343 for ['[CLS] all cup royce [SEP]']
[Init] best perm rec loss: 1.1952502727508545 for ['[CLS] cup all royce [SEP]']
[Init] best perm rec loss: 1.1847620010375977 for ['[CLS] all royce cup [SEP]']
[Init] best perm rec loss: 1.1834989786148071 for ['[CLS] royce all cup [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.762 (perp=12.488, rec=0.260, cos=0.004), tot_loss_proj:3.389 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.675 (perp=12.488, rec=0.174, cos=0.004), tot_loss_proj:3.395 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.633 (perp=12.488, rec=0.131, cos=0.005), tot_loss_proj:3.415 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.615 (perp=12.488, rec=0.116, cos=0.001), tot_loss_proj:3.420 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.615 (perp=12.488, rec=0.114, cos=0.003), tot_loss_proj:3.427 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.605 (perp=12.488, rec=0.103, cos=0.004), tot_loss_proj:3.432 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.606 (perp=12.488, rec=0.108, cos=0.001), tot_loss_proj:3.452 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.604 (perp=12.488, rec=0.106, cos=0.001), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.604 (perp=12.488, rec=0.105, cos=0.001), tot_loss_proj:3.453 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.601 (perp=12.488, rec=0.102, cos=0.001), tot_loss_proj:3.460 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.604 (perp=12.488, rec=0.103, cos=0.003), tot_loss_proj:3.461 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=2.613 (perp=12.488, rec=0.114, cos=0.001), tot_loss_proj:3.466 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.599 (perp=12.488, rec=0.100, cos=0.001), tot_loss_proj:3.466 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.596 (perp=12.488, rec=0.098, cos=0.001), tot_loss_proj:3.467 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 750/2000] tot_loss=2.596 (perp=12.488, rec=0.097, cos=0.001), tot_loss_proj:3.470 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.608 (perp=12.488, rec=0.109, cos=0.002), tot_loss_proj:3.466 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.596 (perp=12.488, rec=0.098, cos=0.001), tot_loss_proj:3.466 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 900/2000] tot_loss=2.597 (perp=12.488, rec=0.098, cos=0.002), tot_loss_proj:3.465 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.586 (perp=12.488, rec=0.088, cos=0.000), tot_loss_proj:3.477 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=2.593 (perp=12.488, rec=0.095, cos=0.000), tot_loss_proj:3.472 [t=0.29s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1050/2000] tot_loss=2.605 (perp=12.488, rec=0.107, cos=0.001), tot_loss_proj:3.481 [t=0.29s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.586 (perp=12.488, rec=0.087, cos=0.000), tot_loss_proj:3.475 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.607 (perp=12.488, rec=0.109, cos=0.000), tot_loss_proj:3.485 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1200/2000] tot_loss=2.587 (perp=12.488, rec=0.089, cos=0.000), tot_loss_proj:3.487 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.593 (perp=12.488, rec=0.095, cos=0.000), tot_loss_proj:3.477 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.599 (perp=12.488, rec=0.101, cos=0.000), tot_loss_proj:3.486 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1350/2000] tot_loss=2.597 (perp=12.488, rec=0.099, cos=0.000), tot_loss_proj:3.488 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.592 (perp=12.488, rec=0.094, cos=0.000), tot_loss_proj:3.481 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.598 (perp=12.488, rec=0.100, cos=0.000), tot_loss_proj:3.480 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1500/2000] tot_loss=2.587 (perp=12.488, rec=0.089, cos=0.000), tot_loss_proj:3.490 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.595 (perp=12.488, rec=0.097, cos=0.000), tot_loss_proj:3.482 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.595 (perp=12.488, rec=0.097, cos=0.000), tot_loss_proj:3.486 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1650/2000] tot_loss=2.592 (perp=12.488, rec=0.094, cos=0.000), tot_loss_proj:3.487 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.599 (perp=12.488, rec=0.101, cos=0.000), tot_loss_proj:3.486 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=2.588 (perp=12.488, rec=0.090, cos=0.000), tot_loss_proj:3.484 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1800/2000] tot_loss=2.608 (perp=12.488, rec=0.110, cos=0.000), tot_loss_proj:3.491 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.585 (perp=12.488, rec=0.087, cos=0.000), tot_loss_proj:3.483 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.589 (perp=12.488, rec=0.091, cos=0.000), tot_loss_proj:3.484 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1950/2000] tot_loss=2.589 (perp=12.488, rec=0.091, cos=0.000), tot_loss_proj:3.484 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=2.592 (perp=12.488, rec=0.094, cos=0.000), tot_loss_proj:3.489 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS]right transparent transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 88.127 | p: 87.968 | r: 88.523
rouge2     | fm: 54.810 | p: 54.619 | r: 55.047
rougeL     | fm: 76.114 | p: 75.873 | r: 76.390
rougeLsum  | fm: 75.525 | p: 75.395 | r: 75.798
r1fm+r2fm = 142.938

input #47 time: 0:10:57 | total time: 7:50:56


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
*********************************
*********************************
average of cosine similarity 0.9993046234064711
highest_index [0]
highest [0.9993046234064711]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 1.6311019659042358 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 1.61383056640625 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 1.5250935554504395 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 1.266484260559082 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 1.1338359117507935 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 1.1290621757507324 for ['[CLS] graveyardtutedine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.971 (perp=13.695, rec=0.229, cos=0.004), tot_loss_proj:3.172 [t=0.24s]
prediction: ['[CLS] rotting beneath rottingat [SEP]']
[ 100/2000] tot_loss=2.821 (perp=13.479, rec=0.124, cos=0.001), tot_loss_proj:3.031 [t=0.24s]
prediction: ['[CLS] rotting under rottingbell [SEP]']
[ 150/2000] tot_loss=2.892 (perp=13.991, rec=0.093, cos=0.001), tot_loss_proj:3.109 [t=0.25s]
prediction: ['[CLS] rotting underybell [SEP]']
[ 200/2000] tot_loss=2.882 (perp=13.991, rec=0.084, cos=0.001), tot_loss_proj:3.106 [t=0.25s]
prediction: ['[CLS] rotting underybell [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.498 (perp=7.108, rec=0.076, cos=0.001), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.499 (perp=7.108, rec=0.077, cos=0.001), tot_loss_proj:1.487 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.482 (perp=7.108, rec=0.060, cos=0.001), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.487 (perp=7.108, rec=0.065, cos=0.001), tot_loss_proj:1.487 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.487 (perp=7.108, rec=0.065, cos=0.001), tot_loss_proj:1.495 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.492 (perp=7.108, rec=0.070, cos=0.001), tot_loss_proj:1.489 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.478 (perp=7.108, rec=0.056, cos=0.001), tot_loss_proj:1.485 [t=0.28s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.487 (perp=7.108, rec=0.065, cos=0.001), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.487 (perp=7.108, rec=0.065, cos=0.001), tot_loss_proj:1.489 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.474 (perp=7.108, rec=0.051, cos=0.001), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.486 (perp=7.108, rec=0.063, cos=0.001), tot_loss_proj:1.490 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.487 (perp=7.108, rec=0.065, cos=0.001), tot_loss_proj:1.495 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.493 (perp=7.108, rec=0.071, cos=0.001), tot_loss_proj:1.486 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.502 (perp=7.108, rec=0.080, cos=0.001), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.499 (perp=7.108, rec=0.077, cos=0.001), tot_loss_proj:1.482 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.484 (perp=7.108, rec=0.062, cos=0.001), tot_loss_proj:1.484 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.494 (perp=7.108, rec=0.072, cos=0.001), tot_loss_proj:1.496 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.476 (perp=7.108, rec=0.053, cos=0.001), tot_loss_proj:1.480 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.482 (perp=7.108, rec=0.060, cos=0.001), tot_loss_proj:1.477 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.476 (perp=7.108, rec=0.054, cos=0.001), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.491 (perp=7.108, rec=0.069, cos=0.001), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.489 (perp=7.108, rec=0.066, cos=0.001), tot_loss_proj:1.496 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.492 (perp=7.108, rec=0.070, cos=0.001), tot_loss_proj:1.493 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.478 (perp=7.108, rec=0.056, cos=0.001), tot_loss_proj:1.481 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.476 (perp=7.108, rec=0.054, cos=0.001), tot_loss_proj:1.499 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.495 (perp=7.108, rec=0.073, cos=0.001), tot_loss_proj:1.499 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.108, rec=0.062, cos=0.001), tot_loss_proj:1.485 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.493 (perp=7.108, rec=0.071, cos=0.001), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.488 (perp=7.108, rec=0.066, cos=0.001), tot_loss_proj:1.490 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.470 (perp=7.108, rec=0.048, cos=0.001), tot_loss_proj:1.479 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.479 (perp=7.108, rec=0.057, cos=0.001), tot_loss_proj:1.489 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.482 (perp=7.108, rec=0.059, cos=0.001), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.108, rec=0.072, cos=0.001), tot_loss_proj:1.483 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.478 (perp=7.108, rec=0.056, cos=0.001), tot_loss_proj:1.481 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.483 (perp=7.108, rec=0.061, cos=0.001), tot_loss_proj:1.486 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.480 (perp=7.108, rec=0.058, cos=0.001), tot_loss_proj:1.479 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.545 | p: 88.405 | r: 88.897
rouge2     | fm: 55.760 | p: 55.596 | r: 56.017
rougeL     | fm: 76.405 | p: 76.175 | r: 76.731
rougeLsum  | fm: 76.048 | p: 75.933 | r: 76.374
r1fm+r2fm = 144.305

input #48 time: 0:10:52 | total time: 8:01:49


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
*********************************
*********************************
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 1.508844017982483 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 1.4430917501449585 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 1.4197598695755005 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 1.3730542659759521 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 1.3694813251495361 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 1.316090703010559 for ['[CLS] chair assured dick fine chance household every expect boat couple freestyleerly [SEP]']
[Init] best rec loss: 1.3142051696777344 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 1.313950538635254 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 1.296747088432312 for ['[CLS] awareness sort domestic roles challenge @rifiedound optical family pass numbers [SEP]']
[Init] best rec loss: 1.296575665473938 for ['[CLS] londonrst victoria traded host dear free rided letting technicallytagram [SEP]']
[Init] best perm rec loss: 1.2936689853668213 for ['[CLS] ride technically dear free londonrsttagram victoria lettingd traded host [SEP]']
[Init] best perm rec loss: 1.292286992073059 for ['[CLS] letting victoria hosttagramrst dear ride free london tradedd technically [SEP]']
[Init] best perm rec loss: 1.2903485298156738 for ['[CLS] ride free technically hosttagramrst london victoria dear lettingd traded [SEP]']
[Init] best perm rec loss: 1.2879154682159424 for ['[CLS] technicallyrst dear host victoria traded london lettingtagram free rided [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.923 (perp=12.698, rec=0.381, cos=0.003), tot_loss_proj:3.674 [t=0.26s]
prediction: ['[CLS] activist should devil αfles inequality human afterwards matches, community double [SEP]']
[ 100/2000] tot_loss=2.739 (perp=12.451, rec=0.246, cos=0.003), tot_loss_proj:3.735 [t=0.26s]
prediction: ['[CLS] theorist could feminine☉ sheila could female afterwards worse. population contempt [SEP]']
[ 150/2000] tot_loss=2.278 (perp=10.401, rec=0.196, cos=0.002), tot_loss_proj:3.126 [t=0.27s]
prediction: ['[CLS]uous coulduous single. possibly of saga more. population contempt [SEP]']
[ 200/2000] tot_loss=2.244 (perp=10.401, rec=0.163, cos=0.001), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS]uous coulduous single. possibly of saga more. population contempt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.997 (perp=9.149, rec=0.166, cos=0.001), tot_loss_proj:2.990 [t=0.26s]
prediction: ['[CLS]uous contemptuous single. possibly of siblings more the population female [SEP]']
[ 300/2000] tot_loss=1.893 (perp=8.753, rec=0.142, cos=0.000), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS]uous contemptuous single. possibly of possibly more the population female [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.851 (perp=8.558, rec=0.139, cos=0.000), tot_loss_proj:2.806 [t=0.25s]
prediction: ['[CLS]uous contemptuous single. possibly of possibly more the female population [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.726 (perp=7.963, rec=0.132, cos=0.001), tot_loss_proj:2.631 [t=0.25s]
prediction: ['[CLS]uous contemptuous single. possibly of the more possibly female population [SEP]']
[ 450/2000] tot_loss=1.715 (perp=7.963, rec=0.123, cos=0.000), tot_loss_proj:2.634 [t=0.27s]
prediction: ['[CLS]uous contemptuous single. possibly of the more possibly female population [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.676 (perp=7.793, rec=0.118, cos=0.000), tot_loss_proj:2.583 [t=0.25s]
prediction: ['[CLS] contemptuousuous single. possibly of the more possibly female population [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.677 (perp=7.793, rec=0.118, cos=0.000), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] contemptuousuous single. possibly of the more possibly female population [SEP]']
[ 600/2000] tot_loss=1.681 (perp=7.793, rec=0.122, cos=0.000), tot_loss_proj:2.580 [t=0.25s]
prediction: ['[CLS] contemptuousuous single. possibly of the more possibly female population [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.794 (perp=8.401, rec=0.113, cos=0.000), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS] contemptuousuous single. possibly of the more be female population [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.765 (perp=8.242, rec=0.116, cos=0.001), tot_loss_proj:2.574 [t=0.24s]
prediction: ['[CLS] contemptuousuous single. be of the more possibly female population [SEP]']
[ 750/2000] tot_loss=1.747 (perp=8.242, rec=0.098, cos=0.000), tot_loss_proj:2.576 [t=0.25s]
prediction: ['[CLS] contemptuousuous single. be of the more possibly female population [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.787 (perp=8.394, rec=0.108, cos=0.000), tot_loss_proj:2.650 [t=0.26s]
prediction: ['[CLS] contemptuousuous single & possibly be of the more female population [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.682 (perp=7.838, rec=0.114, cos=0.000), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] contemptuousuous ; possibly be single of the more female population [SEP]']
[ 900/2000] tot_loss=1.670 (perp=7.838, rec=0.102, cos=0.000), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] contemptuousuous ; possibly be single of the more female population [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.585 (perp=7.405, rec=0.103, cos=0.000), tot_loss_proj:2.187 [t=0.26s]
prediction: ['[CLS] be contemptuousuous ; possibly single of the more female population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.589 (perp=7.405, rec=0.108, cos=0.000), tot_loss_proj:2.195 [t=0.27s]
prediction: ['[CLS] be contemptuousuous ; possibly single of the more female population [SEP]']
[1050/2000] tot_loss=1.580 (perp=7.405, rec=0.099, cos=0.000), tot_loss_proj:2.188 [t=0.26s]
prediction: ['[CLS] be contemptuousuous ; possibly single of the more female population [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.503 (perp=7.031, rec=0.097, cos=0.000), tot_loss_proj:2.062 [t=0.26s]
prediction: ['[CLS] be contemptuousuous ; possibly of the more single female population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.505 (perp=7.031, rec=0.098, cos=0.000), tot_loss_proj:2.058 [t=0.27s]
prediction: ['[CLS] be contemptuousuous ; possibly of the more single female population [SEP]']
[1200/2000] tot_loss=1.502 (perp=7.031, rec=0.095, cos=0.000), tot_loss_proj:2.065 [t=0.27s]
prediction: ['[CLS] be contemptuousuous ; possibly of the more single female population [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.504 (perp=7.031, rec=0.098, cos=0.000), tot_loss_proj:2.059 [t=0.26s]
prediction: ['[CLS] be contemptuousuous ; possibly of the more single female population [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.517 (perp=7.062, rec=0.104, cos=0.001), tot_loss_proj:2.034 [t=0.25s]
prediction: ['[CLS] be contemptuous ; coulduous of the more single female population [SEP]']
[1350/2000] tot_loss=1.505 (perp=7.062, rec=0.092, cos=0.000), tot_loss_proj:2.034 [t=0.28s]
prediction: ['[CLS] be contemptuous ; coulduous of the more single female population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.516 (perp=7.062, rec=0.104, cos=0.000), tot_loss_proj:2.038 [t=0.25s]
prediction: ['[CLS] be contemptuous ; coulduous of the more single female population [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.480 (perp=6.869, rec=0.106, cos=0.001), tot_loss_proj:2.035 [t=0.26s]
prediction: ['[CLS] beuous ; could contemptuous of the more single female population [SEP]']
[1500/2000] tot_loss=1.469 (perp=6.869, rec=0.095, cos=0.000), tot_loss_proj:2.035 [t=0.26s]
prediction: ['[CLS] beuous ; could contemptuous of the more single female population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.466 (perp=6.869, rec=0.092, cos=0.000), tot_loss_proj:2.040 [t=0.25s]
prediction: ['[CLS] beuous ; could contemptuous of the more single female population [SEP]']
Attempt swap
[1600/2000] tot_loss=1.461 (perp=6.869, rec=0.087, cos=0.000), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] beuous ; could contemptuous of the more single female population [SEP]']
[1650/2000] tot_loss=1.464 (perp=6.869, rec=0.090, cos=0.000), tot_loss_proj:2.042 [t=0.27s]
prediction: ['[CLS] beuous ; could contemptuous of the more single female population [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.364 (perp=6.340, rec=0.096, cos=0.000), tot_loss_proj:1.923 [t=0.27s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.358 (perp=6.340, rec=0.090, cos=0.000), tot_loss_proj:1.920 [t=0.26s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
[1800/2000] tot_loss=1.358 (perp=6.340, rec=0.090, cos=0.000), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.366 (perp=6.340, rec=0.098, cos=0.000), tot_loss_proj:1.923 [t=0.26s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.374 (perp=6.340, rec=0.105, cos=0.000), tot_loss_proj:1.926 [t=0.27s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
[1950/2000] tot_loss=1.367 (perp=6.340, rec=0.099, cos=0.000), tot_loss_proj:1.929 [t=0.27s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.359 (perp=6.340, rec=0.091, cos=0.000), tot_loss_proj:1.926 [t=0.26s]
prediction: ['[CLS]uous ; could be contemptuous of the more single female population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS]uous ; could be contemptuous of the more single female population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 45.455 | p: 45.455 | r: 45.455
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 137.121

[Aggregate metrics]:
rouge1     | fm: 88.607 | p: 88.364 | r: 88.922
rouge2     | fm: 55.735 | p: 55.535 | r: 55.939
rougeL     | fm: 76.506 | p: 76.319 | r: 76.781
rougeLsum  | fm: 76.258 | p: 76.024 | r: 76.589
r1fm+r2fm = 144.342

input #49 time: 0:10:59 | total time: 8:12:49


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
*********************************
*********************************
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 1.7681097984313965 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 1.5493779182434082 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 1.5217300653457642 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 1.4632673263549805 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best rec loss: 1.4029443264007568 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best perm rec loss: 1.401523470878601 for ['[CLS] associated fueled trustok rama sq napkin gall unit [SEP]']
[Init] best perm rec loss: 1.40097177028656 for ['[CLS]ok gall napkin associated fueled sq trust unit rama [SEP]']
[Init] best perm rec loss: 1.3933467864990234 for ['[CLS] gall sq napkin trust fueled unit ramaok associated [SEP]']
[Init] best perm rec loss: 1.3920629024505615 for ['[CLS] napkinok trust unit gall fueled rama sq associated [SEP]']
[Init] best perm rec loss: 1.3910012245178223 for ['[CLS] unit gall associated sq fueled napkinok rama trust [SEP]']
[Init] best perm rec loss: 1.3904179334640503 for ['[CLS] trust sq unit gallok associated napkin rama fueled [SEP]']
[Init] best perm rec loss: 1.390091061592102 for ['[CLS] gall napkin unit fueled associated sqok trust rama [SEP]']
[Init] best perm rec loss: 1.3895784616470337 for ['[CLS] unit gall napkin associated sq trustok fueled rama [SEP]']
[Init] best perm rec loss: 1.3889405727386475 for ['[CLS] unit gall trust fueledok sq associated napkin rama [SEP]']
[Init] best perm rec loss: 1.3880995512008667 for ['[CLS] fueled gall napkin unit sq trustok associated rama [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.676 (perp=10.948, rec=0.480, cos=0.006), tot_loss_proj:3.804 [t=0.26s]
prediction: ["[CLS] fee'serious award catch paying asking award desperate [SEP]"]
[ 100/2000] tot_loss=2.986 (perp=12.934, rec=0.398, cos=0.001), tot_loss_proj:4.174 [t=0.24s]
prediction: ['[CLS] something [ serious award catch decay half reforms regarded [SEP]']
[ 150/2000] tot_loss=2.900 (perp=12.739, rec=0.350, cos=0.002), tot_loss_proj:3.927 [t=0.25s]
prediction: ["[CLS] what'serious award especially susannah half reforms regarded [SEP]"]
[ 200/2000] tot_loss=2.702 (perp=11.885, rec=0.324, cos=0.001), tot_loss_proj:3.897 [t=0.27s]
prediction: ["[CLS] what'serious half around susannah half english barber [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.728 (perp=12.144, rec=0.298, cos=0.001), tot_loss_proj:3.455 [t=0.26s]
prediction: ['[CLS] what ` pretty clever half susannah half english rags [SEP]']
[ 300/2000] tot_loss=2.279 (perp=10.068, rec=0.265, cos=0.001), tot_loss_proj:3.163 [t=0.25s]
prediction: ['[CLS] what call pretty clever half too half english clever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.603 (perp=11.766, rec=0.249, cos=0.001), tot_loss_proj:3.262 [t=0.25s]
prediction: ['[CLS] what english callø clever too half clever clever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.193 (perp=9.777, rec=0.235, cos=0.003), tot_loss_proj:2.662 [t=0.26s]
prediction: ['[CLS] what english call too clever too english half clever [SEP]']
[ 450/2000] tot_loss=2.029 (perp=9.059, rec=0.217, cos=0.000), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] what english call too clever too clever half clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.007 (perp=9.059, rec=0.195, cos=0.000), tot_loss_proj:2.490 [t=0.24s]
prediction: ['[CLS] what english call too clever too clever half clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.102 (perp=9.590, rec=0.184, cos=0.000), tot_loss_proj:2.631 [t=0.25s]
prediction: ['[CLS] what english call half clever too clever half clever [SEP]']
[ 600/2000] tot_loss=2.101 (perp=9.590, rec=0.183, cos=0.000), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] what english call half clever too clever half clever [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.000 (perp=9.115, rec=0.177, cos=0.000), tot_loss_proj:2.686 [t=0.25s]
prediction: ['[CLS] what english call clever half too clever half clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.997 (perp=9.115, rec=0.173, cos=0.000), tot_loss_proj:2.681 [t=0.25s]
prediction: ['[CLS] what english call clever half too clever half clever [SEP]']
[ 750/2000] tot_loss=1.992 (perp=9.115, rec=0.169, cos=0.000), tot_loss_proj:2.683 [t=0.25s]
prediction: ['[CLS] what english call clever half too clever half clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.991 (perp=9.115, rec=0.168, cos=0.000), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] what english call clever half too clever half clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.978 (perp=9.115, rec=0.154, cos=0.000), tot_loss_proj:2.687 [t=0.28s]
prediction: ['[CLS] what english call clever half too clever half clever [SEP]']
[ 900/2000] tot_loss=2.231 (perp=10.403, rec=0.150, cos=0.000), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] what english call clever half too ` half clever [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.106 (perp=9.764, rec=0.153, cos=0.000), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] what english call clever half too clever half ` [SEP]']
Attempt swap
[1000/2000] tot_loss=2.107 (perp=9.764, rec=0.154, cos=0.000), tot_loss_proj:2.684 [t=0.27s]
prediction: ['[CLS] what english call clever half too clever half ` [SEP]']
[1050/2000] tot_loss=2.150 (perp=10.004, rec=0.149, cos=0.000), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] what english call clever half too clever by ` [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.102 (perp=9.815, rec=0.138, cos=0.000), tot_loss_proj:3.132 [t=0.25s]
prediction: ['[CLS] what english clever call half too clever by ` [SEP]']
Attempt swap
[1150/2000] tot_loss=2.092 (perp=9.815, rec=0.129, cos=0.000), tot_loss_proj:3.134 [t=0.25s]
prediction: ['[CLS] what english clever call half too clever by ` [SEP]']
[1200/2000] tot_loss=2.088 (perp=9.815, rec=0.124, cos=0.000), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] what english clever call half too clever by ` [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.963 (perp=9.176, rec=0.128, cos=0.001), tot_loss_proj:2.358 [t=0.26s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1300/2000] tot_loss=1.952 (perp=9.176, rec=0.116, cos=0.000), tot_loss_proj:2.359 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
[1350/2000] tot_loss=1.947 (perp=9.176, rec=0.112, cos=0.000), tot_loss_proj:2.361 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1400/2000] tot_loss=1.948 (perp=9.176, rec=0.113, cos=0.000), tot_loss_proj:2.354 [t=0.26s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1450/2000] tot_loss=1.947 (perp=9.176, rec=0.112, cos=0.000), tot_loss_proj:2.357 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
[1500/2000] tot_loss=1.938 (perp=9.176, rec=0.103, cos=0.000), tot_loss_proj:2.355 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1550/2000] tot_loss=1.931 (perp=9.176, rec=0.095, cos=0.000), tot_loss_proj:2.363 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1600/2000] tot_loss=1.940 (perp=9.176, rec=0.105, cos=0.000), tot_loss_proj:2.364 [t=0.26s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
[1650/2000] tot_loss=1.940 (perp=9.176, rec=0.105, cos=0.000), tot_loss_proj:2.359 [t=0.27s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1700/2000] tot_loss=1.930 (perp=9.176, rec=0.094, cos=0.000), tot_loss_proj:2.357 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1750/2000] tot_loss=1.932 (perp=9.176, rec=0.097, cos=0.000), tot_loss_proj:2.361 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
[1800/2000] tot_loss=1.932 (perp=9.176, rec=0.097, cos=0.000), tot_loss_proj:2.360 [t=0.26s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1850/2000] tot_loss=1.931 (perp=9.176, rec=0.096, cos=0.000), tot_loss_proj:2.354 [t=0.29s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[1900/2000] tot_loss=1.935 (perp=9.176, rec=0.100, cos=0.000), tot_loss_proj:2.357 [t=0.26s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
[1950/2000] tot_loss=1.931 (perp=9.176, rec=0.096, cos=0.000), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Attempt swap
[2000/2000] tot_loss=1.934 (perp=9.176, rec=0.098, cos=0.000), tot_loss_proj:2.358 [t=0.25s]
prediction: ['[CLS] what english clever call too clever by half ` [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what english clever call too clever by half ` [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 156.667

[Aggregate metrics]:
rouge1     | fm: 88.560 | p: 88.403 | r: 88.872
rouge2     | fm: 55.922 | p: 55.761 | r: 56.109
rougeL     | fm: 76.703 | p: 76.450 | r: 77.081
rougeLsum  | fm: 76.522 | p: 76.346 | r: 76.786
r1fm+r2fm = 144.482

input #50 time: 0:10:55 | total time: 8:23:44


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
*********************************
*********************************
average of cosine similarity 0.9992548315433465
highest_index [0]
highest [0.9992548315433465]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 1.5581773519515991 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 1.3123705387115479 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 1.2994669675827026 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 1.2463165521621704 for ['[CLS] nationals offense - vaguely world justine domesticished majorage [SEP]']
[Init] best rec loss: 1.2434269189834595 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 1.1884088516235352 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 1.1509753465652466 for ['[CLS] include plants hole abuse especially multiple fingers & since accepting [SEP]']
[Init] best perm rec loss: 1.1506011486053467 for ['[CLS] accepting hole multiple since abuse especially plants & include fingers [SEP]']
[Init] best perm rec loss: 1.1483800411224365 for ['[CLS] multiple accepting hole especially include since & fingers abuse plants [SEP]']
[Init] best perm rec loss: 1.1480402946472168 for ['[CLS] accepting plants include especially since multiple & fingers hole abuse [SEP]']
[Init] best perm rec loss: 1.146215558052063 for ['[CLS] multiple especially accepting since abuse & hole fingers plants include [SEP]']
[Init] best perm rec loss: 1.1452608108520508 for ['[CLS] multiple especially accepting since & plants hole fingers include abuse [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.076 (perp=13.177, rec=0.431, cos=0.009), tot_loss_proj:4.176 [t=0.24s]
prediction: ['[CLS] slow fu weak suddenly sucks tail creators correct sucked failed [SEP]']
[ 100/2000] tot_loss=2.803 (perp=12.251, rec=0.350, cos=0.003), tot_loss_proj:3.594 [t=0.25s]
prediction: ['[CLS] lastsulsionola naturally sucks without winner funny sucked. [SEP]']
[ 150/2000] tot_loss=2.652 (perp=11.774, rec=0.292, cos=0.006), tot_loss_proj:3.518 [t=0.25s]
prediction: ['[CLS] lasts sometimesola occurs sucks without sets funny sucks. [SEP]']
[ 200/2000] tot_loss=2.414 (perp=10.539, rec=0.289, cos=0.017), tot_loss_proj:3.232 [t=0.25s]
prediction: ['[CLS] funny sometimesola occurs sucks. issues funny sucks. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.139 (perp=9.630, rec=0.211, cos=0.002), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] although funny funny or sucks moment has funny sucks but [SEP]']
[ 300/2000] tot_loss=2.150 (perp=9.926, rec=0.165, cos=0.000), tot_loss_proj:2.893 [t=0.26s]
prediction: ['[CLS] although ( funny or sucks moment has funny sucks but [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.103 (perp=9.800, rec=0.142, cos=0.001), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] (. funny or sucks moment has funny sucks but [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.978 (perp=8.929, rec=0.187, cos=0.006), tot_loss_proj:3.383 [t=0.26s]
prediction: ['[CLS] funny. funny or moment has sucks funny sucks but [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.760, rec=0.135, cos=0.000), tot_loss_proj:2.832 [t=0.26s]
prediction: ['[CLS] (. funny or moment has sucks funny sucks but [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.656 (perp=7.673, rec=0.121, cos=0.001), tot_loss_proj:2.627 [t=0.25s]
prediction: ['[CLS] ( but funny or moment has sucks funny sucks. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.576 (perp=7.352, rec=0.104, cos=0.002), tot_loss_proj:2.415 [t=0.25s]
prediction: ['[CLS] ( but funny or funny moment has sucks sucks. [SEP]']
[ 600/2000] tot_loss=1.573 (perp=7.352, rec=0.102, cos=0.000), tot_loss_proj:2.409 [t=0.27s]
prediction: ['[CLS] ( but funny or funny moment has sucks sucks. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.599 (perp=7.510, rec=0.097, cos=0.000), tot_loss_proj:2.421 [t=0.26s]
prediction: ['[CLS] ( but funny or a moment has sucks sucks. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.464 (perp=6.784, rec=0.107, cos=0.000), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS], but funny or has a moment sucks sucks. [SEP]']
[ 750/2000] tot_loss=1.446 (perp=6.784, rec=0.089, cos=0.000), tot_loss_proj:2.244 [t=0.26s]
prediction: ['[CLS], but funny or has a moment sucks sucks. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.416 (perp=6.624, rec=0.091, cos=0.000), tot_loss_proj:2.221 [t=0.29s]
prediction: ['[CLS] but, funny or has a moment sucks sucks. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.350 (perp=6.272, rec=0.095, cos=0.001), tot_loss_proj:2.441 [t=0.25s]
prediction: ['[CLS] sucks, funny or has a moment but sucks. [SEP]']
[ 900/2000] tot_loss=1.331 (perp=6.272, rec=0.077, cos=0.000), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] sucks, funny or has a moment but sucks. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.353 (perp=6.383, rec=0.076, cos=0.000), tot_loss_proj:2.207 [t=0.25s]
prediction: ['[CLS] sucks, or has a funny moment but two. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.122 (perp=5.210, rec=0.079, cos=0.000), tot_loss_proj:1.170 [t=0.28s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1050/2000] tot_loss=1.119 (perp=5.210, rec=0.077, cos=0.000), tot_loss_proj:1.175 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.111 (perp=5.210, rec=0.069, cos=0.000), tot_loss_proj:1.170 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.108 (perp=5.210, rec=0.066, cos=0.000), tot_loss_proj:1.165 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1200/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.176 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.113 (perp=5.210, rec=0.071, cos=0.000), tot_loss_proj:1.173 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.115 (perp=5.210, rec=0.072, cos=0.000), tot_loss_proj:1.166 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1350/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.178 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.118 (perp=5.210, rec=0.076, cos=0.000), tot_loss_proj:1.170 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.117 (perp=5.210, rec=0.075, cos=0.000), tot_loss_proj:1.172 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1500/2000] tot_loss=1.107 (perp=5.210, rec=0.064, cos=0.000), tot_loss_proj:1.166 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.174 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.111 (perp=5.210, rec=0.069, cos=0.000), tot_loss_proj:1.163 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1650/2000] tot_loss=1.113 (perp=5.210, rec=0.071, cos=0.000), tot_loss_proj:1.174 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.111 (perp=5.210, rec=0.069, cos=0.000), tot_loss_proj:1.171 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.107 (perp=5.210, rec=0.065, cos=0.000), tot_loss_proj:1.170 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1800/2000] tot_loss=1.105 (perp=5.210, rec=0.063, cos=0.000), tot_loss_proj:1.176 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.103 (perp=5.210, rec=0.061, cos=0.000), tot_loss_proj:1.172 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.171 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1950/2000] tot_loss=1.104 (perp=5.210, rec=0.062, cos=0.000), tot_loss_proj:1.171 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.115 (perp=5.210, rec=0.073, cos=0.000), tot_loss_proj:1.174 [t=0.28s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.843 | p: 88.661 | r: 89.128
rouge2     | fm: 56.476 | p: 56.369 | r: 56.710
rougeL     | fm: 77.119 | p: 76.956 | r: 77.391
rougeLsum  | fm: 76.961 | p: 76.754 | r: 77.237
r1fm+r2fm = 145.319

input #51 time: 0:10:50 | total time: 8:34:35


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
*********************************
*********************************
average of cosine similarity 0.9992769471396808
highest_index [0]
highest [0.9992769471396808]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 1.9447109699249268 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 1.8204642534255981 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 1.6631529331207275 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 1.606566071510315 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 1.5411300659179688 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 1.0370672941207886 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.9874905347824097 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.9856306314468384 for ['[CLS] expected football vocabulary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.391 (perp=10.789, rec=0.228, cos=0.005), tot_loss_proj:2.555 [t=0.26s]
prediction: ['[CLS] trash trailer trash [SEP]']
[ 100/2000] tot_loss=2.276 (perp=10.655, rec=0.144, cos=0.002), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 150/2000] tot_loss=2.253 (perp=10.655, rec=0.120, cos=0.001), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 200/2000] tot_loss=2.231 (perp=10.655, rec=0.099, cos=0.001), tot_loss_proj:2.448 [t=0.25s]
prediction: ['[CLS] trailer trailer trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.829 (perp=8.541, rec=0.118, cos=0.003), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] trash trailer trailer [SEP]']
[ 300/2000] tot_loss=1.795 (perp=8.541, rec=0.086, cos=0.001), tot_loss_proj:2.177 [t=0.26s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.782 (perp=8.482, rec=0.085, cos=0.001), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.764 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.767 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.125 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.765 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.759 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.116 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.760 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.760 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.114 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.764 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.121 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.753 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.768 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.758 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.754 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.761 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.764 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.756 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.756 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.763 (perp=8.482, rec=0.066, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.771 (perp=8.482, rec=0.074, cos=0.001), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.765 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.755 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.115 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.753 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.756 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.773 (perp=8.482, rec=0.076, cos=0.001), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.752 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.757 (perp=8.482, rec=0.060, cos=0.001), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.766 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.761 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.110 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.969 | p: 88.758 | r: 89.308
rouge2     | fm: 55.607 | p: 55.469 | r: 55.789
rougeL     | fm: 77.266 | p: 77.081 | r: 77.540
rougeLsum  | fm: 76.882 | p: 76.767 | r: 77.183
r1fm+r2fm = 144.575

input #52 time: 0:10:53 | total time: 8:45:28


Running input #53 of 100.
reference: 
========================
flinching 
========================
*********************************
*********************************
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 1.7769790887832642 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 1.7505303621292114 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 1.7399649620056152 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 1.6215876340866089 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 1.6025766134262085 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 1.2801052331924438 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 1.2687050104141235 for ['[CLS]real hot [SEP]']
[Init] best rec loss: 1.1997308731079102 for ['[CLS] ralph not [SEP]']
[Init] best rec loss: 1.1960270404815674 for ['[CLS] university rock [SEP]']
[Init] best perm rec loss: 1.192598581314087 for ['[CLS] rock university [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.141 (perp=13.720, rec=0.380, cos=0.016), tot_loss_proj:4.194 [t=0.28s]
prediction: ['[CLS] asidelash [SEP]']
[ 100/2000] tot_loss=2.717 (perp=12.492, rec=0.214, cos=0.004), tot_loss_proj:3.339 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.668 (perp=12.492, rec=0.167, cos=0.002), tot_loss_proj:3.340 [t=0.27s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.647 (perp=12.492, rec=0.147, cos=0.002), tot_loss_proj:3.341 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.642 (perp=12.492, rec=0.142, cos=0.002), tot_loss_proj:3.334 [t=0.24s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.667 (perp=12.492, rec=0.161, cos=0.007), tot_loss_proj:3.339 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.624 (perp=12.492, rec=0.124, cos=0.002), tot_loss_proj:3.359 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.623 (perp=12.492, rec=0.123, cos=0.002), tot_loss_proj:3.347 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 450/2000] tot_loss=2.613 (perp=12.492, rec=0.113, cos=0.002), tot_loss_proj:3.346 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.575 (perp=12.413, rec=0.092, cos=0.001), tot_loss_proj:3.310 [t=0.24s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.699 (perp=8.090, rec=0.079, cos=0.002), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.679 (perp=8.090, rec=0.061, cos=0.000), tot_loss_proj:1.697 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.685 (perp=8.090, rec=0.066, cos=0.000), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.682 (perp=8.090, rec=0.064, cos=0.000), tot_loss_proj:1.696 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.090, rec=0.070, cos=0.000), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.682 (perp=8.090, rec=0.064, cos=0.000), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.000), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.000), tot_loss_proj:1.687 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.665 (perp=8.090, rec=0.047, cos=0.000), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.685 (perp=8.090, rec=0.067, cos=0.000), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.670 (perp=8.090, rec=0.051, cos=0.000), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.000), tot_loss_proj:1.710 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.675 (perp=8.090, rec=0.057, cos=0.000), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.688 (perp=8.090, rec=0.070, cos=0.000), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.679 (perp=8.090, rec=0.061, cos=0.000), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.000), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.678 (perp=8.090, rec=0.060, cos=0.000), tot_loss_proj:1.699 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=8.090, rec=0.065, cos=0.000), tot_loss_proj:1.692 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.685 (perp=8.090, rec=0.067, cos=0.000), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.679 (perp=8.090, rec=0.061, cos=0.000), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.688 (perp=8.090, rec=0.070, cos=0.000), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.678 (perp=8.090, rec=0.060, cos=0.000), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.678 (perp=8.090, rec=0.060, cos=0.000), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=8.090, rec=0.064, cos=0.000), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.664 (perp=8.090, rec=0.046, cos=0.000), tot_loss_proj:1.704 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.688 (perp=8.090, rec=0.070, cos=0.000), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=8.090, rec=0.052, cos=0.000), tot_loss_proj:1.696 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.000), tot_loss_proj:1.693 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.090, rec=0.058, cos=0.000), tot_loss_proj:1.700 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.686 (perp=8.090, rec=0.068, cos=0.000), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.185 | p: 89.021 | r: 89.522
rouge2     | fm: 56.302 | p: 56.191 | r: 56.474
rougeL     | fm: 77.500 | p: 77.279 | r: 77.823
rougeLsum  | fm: 77.377 | p: 77.184 | r: 77.659
r1fm+r2fm = 145.487

input #53 time: 0:10:50 | total time: 8:56:18


Running input #54 of 100.
reference: 
========================
hot topics 
========================
*********************************
*********************************
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 1.7071905136108398 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 1.552504062652588 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 1.5421050786972046 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 1.5026865005493164 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 1.2422250509262085 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 1.139829158782959 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 1.0659000873565674 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.9896990060806274 for ['[CLS] wild exercised [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.989 (perp=8.198, rec=0.332, cos=0.018), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=1.802 (perp=8.198, rec=0.152, cos=0.011), tot_loss_proj:1.747 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.739 (perp=8.198, rec=0.098, cos=0.002), tot_loss_proj:1.734 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.718 (perp=8.198, rec=0.078, cos=0.001), tot_loss_proj:1.739 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.001), tot_loss_proj:1.730 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.714 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.731 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.705 (perp=8.198, rec=0.065, cos=0.001), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.728 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.001), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.001), tot_loss_proj:1.721 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.001), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.001), tot_loss_proj:1.721 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.713 (perp=8.198, rec=0.072, cos=0.001), tot_loss_proj:1.735 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.715 (perp=8.198, rec=0.074, cos=0.001), tot_loss_proj:1.730 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.715 (perp=8.198, rec=0.075, cos=0.001), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.705 (perp=8.198, rec=0.065, cos=0.001), tot_loss_proj:1.739 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.709 (perp=8.198, rec=0.069, cos=0.001), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.001), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.703 (perp=8.198, rec=0.063, cos=0.001), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=8.198, rec=0.075, cos=0.001), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.001), tot_loss_proj:1.731 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.198, rec=0.063, cos=0.001), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.696 (perp=8.198, rec=0.056, cos=0.001), tot_loss_proj:1.730 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.698 (perp=8.198, rec=0.058, cos=0.001), tot_loss_proj:1.723 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.709 (perp=8.198, rec=0.069, cos=0.001), tot_loss_proj:1.721 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.691 (perp=8.198, rec=0.051, cos=0.001), tot_loss_proj:1.734 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.706 (perp=8.198, rec=0.066, cos=0.001), tot_loss_proj:1.726 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.693 (perp=8.198, rec=0.053, cos=0.001), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.704 (perp=8.198, rec=0.064, cos=0.001), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.700 (perp=8.198, rec=0.060, cos=0.001), tot_loss_proj:1.719 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.709 (perp=8.198, rec=0.069, cos=0.001), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.694 (perp=8.198, rec=0.054, cos=0.001), tot_loss_proj:1.740 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.698 (perp=8.198, rec=0.058, cos=0.001), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.695 (perp=8.198, rec=0.055, cos=0.001), tot_loss_proj:1.744 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.699 (perp=8.198, rec=0.059, cos=0.001), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.694 (perp=8.198, rec=0.054, cos=0.001), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.198, rec=0.067, cos=0.001), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=8.198, rec=0.062, cos=0.001), tot_loss_proj:1.721 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.001), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.001), tot_loss_proj:1.734 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.384 | p: 89.217 | r: 89.668
rouge2     | fm: 57.351 | p: 57.179 | r: 57.520
rougeL     | fm: 77.913 | p: 77.757 | r: 78.141
rougeLsum  | fm: 77.698 | p: 77.540 | r: 77.938
r1fm+r2fm = 146.734

input #54 time: 0:10:55 | total time: 9:07:14


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
*********************************
*********************************
average of cosine similarity 0.9991205863745831
highest_index [0]
highest [0.9991205863745831]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 1.8857332468032837 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 1.5969682931900024 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 1.32254958152771 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 1.3047670125961304 for ['[CLS]ies finished haired [SEP]']
[Init] best rec loss: 1.264054298400879 for ['[CLS] stride holly post [SEP]']
[Init] best rec loss: 1.2127386331558228 for ['[CLS] precipitation written mounted [SEP]']
[Init] best perm rec loss: 1.2090678215026855 for ['[CLS] written precipitation mounted [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.881 (perp=11.227, rec=0.584, cos=0.052), tot_loss_proj:3.489 [t=0.27s]
prediction: ['[CLS] closed dry easy [SEP]']
[ 100/2000] tot_loss=3.209 (perp=13.852, rec=0.426, cos=0.012), tot_loss_proj:4.044 [t=0.25s]
prediction: ['[CLS] drag obvious easy [SEP]']
[ 150/2000] tot_loss=2.755 (perp=12.067, rec=0.331, cos=0.011), tot_loss_proj:3.677 [t=0.26s]
prediction: ['[CLS] drag obvious easily [SEP]']
[ 200/2000] tot_loss=2.572 (perp=11.449, rec=0.276, cos=0.006), tot_loss_proj:3.106 [t=0.26s]
prediction: ['[CLS]olved too easily [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.009 (perp=8.687, rec=0.254, cos=0.018), tot_loss_proj:2.220 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.707 (perp=7.752, rec=0.155, cos=0.002), tot_loss_proj:2.473 [t=0.26s]
prediction: ['[CLS] too easily settled [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.675 (perp=7.752, rec=0.123, cos=0.001), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] too easily settled [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.841 (perp=8.687, rec=0.103, cos=0.001), tot_loss_proj:2.260 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.829 (perp=8.687, rec=0.091, cos=0.000), tot_loss_proj:2.259 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.829 (perp=8.687, rec=0.091, cos=0.000), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.819 (perp=8.687, rec=0.081, cos=0.000), tot_loss_proj:2.249 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.827 (perp=8.687, rec=0.089, cos=0.000), tot_loss_proj:2.262 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.817 (perp=8.687, rec=0.079, cos=0.000), tot_loss_proj:2.253 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.820 (perp=8.687, rec=0.082, cos=0.000), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.811 (perp=8.687, rec=0.073, cos=0.000), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.814 (perp=8.687, rec=0.076, cos=0.000), tot_loss_proj:2.251 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.812 (perp=8.687, rec=0.074, cos=0.000), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.814 (perp=8.687, rec=0.076, cos=0.000), tot_loss_proj:2.257 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.795 (perp=8.687, rec=0.057, cos=0.000), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.815 (perp=8.687, rec=0.078, cos=0.000), tot_loss_proj:2.254 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.803 (perp=8.687, rec=0.065, cos=0.000), tot_loss_proj:2.254 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.808 (perp=8.687, rec=0.070, cos=0.000), tot_loss_proj:2.255 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.803 (perp=8.687, rec=0.065, cos=0.000), tot_loss_proj:2.256 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.803 (perp=8.687, rec=0.065, cos=0.000), tot_loss_proj:2.249 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.810 (perp=8.687, rec=0.073, cos=0.000), tot_loss_proj:2.246 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.815 (perp=8.687, rec=0.077, cos=0.000), tot_loss_proj:2.254 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.806 (perp=8.687, rec=0.069, cos=0.000), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.687, rec=0.059, cos=0.000), tot_loss_proj:2.247 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.794 (perp=8.687, rec=0.056, cos=0.000), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.809 (perp=8.687, rec=0.072, cos=0.000), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.817 (perp=8.687, rec=0.079, cos=0.000), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.806 (perp=8.687, rec=0.068, cos=0.000), tot_loss_proj:2.244 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.794 (perp=8.687, rec=0.057, cos=0.000), tot_loss_proj:2.250 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.812 (perp=8.687, rec=0.074, cos=0.000), tot_loss_proj:2.249 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.794 (perp=8.687, rec=0.057, cos=0.000), tot_loss_proj:2.252 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.813 (perp=8.687, rec=0.076, cos=0.000), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.814 (perp=8.687, rec=0.076, cos=0.000), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.813 (perp=8.687, rec=0.075, cos=0.000), tot_loss_proj:2.251 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.806 (perp=8.687, rec=0.068, cos=0.000), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.808 (perp=8.687, rec=0.070, cos=0.000), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 89.625 | p: 89.459 | r: 89.928
rouge2     | fm: 56.763 | p: 56.663 | r: 56.939
rougeL     | fm: 78.096 | p: 77.915 | r: 78.341
rougeLsum  | fm: 77.785 | p: 77.688 | r: 78.030
r1fm+r2fm = 146.388

input #55 time: 0:10:54 | total time: 9:18:09


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
*********************************
*********************************
average of cosine similarity 0.9992743912224644
highest_index [0]
highest [0.9992743912224644]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 1.7055118083953857 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 1.6200506687164307 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 1.5344394445419312 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 1.4744815826416016 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 1.4654475450515747 for ['[CLS] sense en depression avid laid ironured bear k strike blame reflection technique determined backed unfortunately ; sympathy charter code tis [SEP]']
[Init] best perm rec loss: 1.456282377243042 for ['[CLS] strike charter unfortunately en backed reflection code laid tis blame k determined depression technique sense bear sympathy ironured ; avid [SEP]']
[Init] best perm rec loss: 1.4561269283294678 for ['[CLS] technique charter backed ; iron avid code sympathy sense bear determined laid en reflection depression tis blame k unfortunately strikeured [SEP]']
[Init] best perm rec loss: 1.4547836780548096 for ['[CLS] technique charter en tis kured code ; determined blame sympathy reflection sense unfortunately depression bear iron laid backed avid strike [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.728 (perp=11.824, rec=0.361, cos=0.003), tot_loss_proj:3.142 [t=0.29s]
prediction: ['[CLS] victim damage ; when arabia alleged assault settlers suchg causedx any very miss waste stupid waste inc journalism lawsuit [SEP]']
[ 100/2000] tot_loss=2.440 (perp=10.821, rec=0.274, cos=0.002), tot_loss_proj:3.647 [t=0.25s]
prediction: ['[CLS] films damage! when films alleged assault settlers incpara caused no any very costly waste costlyable event films issues [SEP]']
[ 150/2000] tot_loss=2.393 (perp=10.856, rec=0.219, cos=0.003), tot_loss_proj:3.203 [t=0.25s]
prediction: ['[CLS] films damage usually that films which fix fix toopara caused sure any load costly tory costly analysis of films issues [SEP]']
[ 200/2000] tot_loss=2.302 (perp=10.614, rec=0.178, cos=0.001), tot_loss_proj:3.412 [t=0.25s]
prediction: ['[CLS] films damage will that films which fix fix toopara caused sure never load costly tory costly analysis of films issues [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.269 (perp=10.412, rec=0.184, cos=0.002), tot_loss_proj:3.295 [t=0.27s]
prediction: ['[CLS] tremendous damage could that films which caused fix toopara years will never load costly expensive costly analysis could films issues [SEP]']
[ 300/2000] tot_loss=2.169 (perp=10.010, rec=0.166, cos=0.001), tot_loss_proj:2.795 [t=0.27s]
prediction: ["[CLS] loads damage could that films which caused fix -para years will years load costly costly costly analysis'films considered [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.249 (perp=10.552, rec=0.137, cos=0.001), tot_loss_proj:2.768 [t=0.26s]
prediction: ['[CLS] loads could damage that films which cause fix -paraxious will decades loads costly costly costly analysis of analysis considered [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.158 (perp=9.906, rec=0.174, cos=0.002), tot_loss_proj:3.150 [t=0.27s]
prediction: ['[CLS] loads never damage that films which cause fix -parable years will loads costly costly costly decades of analysis could [SEP]']
[ 450/2000] tot_loss=2.323 (perp=10.940, rec=0.134, cos=0.001), tot_loss_proj:3.338 [t=0.28s]
prediction: ['[CLS] of never damage that films which cause fix -parapara years will loads costly costly costly decades of analysis could [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.108 (perp=9.873, rec=0.133, cos=0.001), tot_loss_proj:3.396 [t=0.28s]
prediction: ['[CLS] will never damage that films which cause fix ofparapara years of loads costly costly costly decades of analysis considered [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.039 (perp=9.578, rec=0.122, cos=0.001), tot_loss_proj:3.274 [t=0.26s]
prediction: ['[CLS] will never damage that films which cause fix ofparapara years of loads costly costly decades of costly analysis considered [SEP]']
[ 600/2000] tot_loss=2.175 (perp=10.254, rec=0.123, cos=0.001), tot_loss_proj:3.431 [t=0.26s]
prediction: ['[CLS] will never damage that films which cause fix ofparapara years of loadspara costly decades of costly analysis could [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.044 (perp=9.592, rec=0.125, cos=0.001), tot_loss_proj:3.169 [t=0.27s]
prediction: ['[CLS] will never damage that films which cause fix ofparaparapara years of loads costly decades of costly analysis would [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.986 (perp=9.346, rec=0.116, cos=0.001), tot_loss_proj:3.235 [t=0.25s]
prediction: ['[CLS] will never damage that films which cause fixparaparapara of years of loads costly decades of costly analysis would [SEP]']
[ 750/2000] tot_loss=1.979 (perp=9.346, rec=0.109, cos=0.001), tot_loss_proj:3.233 [t=0.28s]
prediction: ['[CLS] will never damage that films which cause fixparaparapara of years of loads costly decades of costly analysis would [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.976 (perp=9.350, rec=0.106, cos=0.001), tot_loss_proj:3.227 [t=0.26s]
prediction: ['[CLS] will never damage that films which cause fixparaparapara of years of loads costly decades of costly analysis could [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.914 (perp=8.999, rec=0.113, cos=0.001), tot_loss_proj:3.262 [t=0.25s]
prediction: ['[CLS] will never damage that films which cause fixparaparapara years of loads of costly decades of costly analysis could [SEP]']
[ 900/2000] tot_loss=1.910 (perp=8.999, rec=0.110, cos=0.001), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] will never damage that films which cause fixparaparapara years of loads of costly decades of costly analysis could [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.783 (perp=8.394, rec=0.104, cos=0.001), tot_loss_proj:3.232 [t=0.26s]
prediction: ['[CLS] will never damage that films which cause fixparaparapara loads of years of costly decades of costly analysis could [SEP]']
Attempt swap
[1000/2000] tot_loss=1.748 (perp=8.228, rec=0.102, cos=0.001), tot_loss_proj:3.101 [t=0.26s]
prediction: ['[CLS] will never damage that films which cause fixparaparable loads of years of costly decades of costly analysis could [SEP]']
[1050/2000] tot_loss=1.749 (perp=8.228, rec=0.103, cos=0.001), tot_loss_proj:3.096 [t=0.27s]
prediction: ['[CLS] will never damage that films which cause fixparaparable loads of years of costly decades of costly analysis could [SEP]']
Attempt swap
[1100/2000] tot_loss=1.740 (perp=8.228, rec=0.094, cos=0.001), tot_loss_proj:3.094 [t=0.25s]
prediction: ['[CLS] will never damage that films which cause fixparaparable loads of years of costly decades of costly analysis could [SEP]']
Attempt swap
[1150/2000] tot_loss=1.739 (perp=8.215, rec=0.096, cos=0.001), tot_loss_proj:3.107 [t=0.25s]
prediction: ['[CLS] will never damage that films which cause fixparaparable loads of years of costly analysis of costly analysis could [SEP]']
[1200/2000] tot_loss=1.746 (perp=8.215, rec=0.102, cos=0.001), tot_loss_proj:3.113 [t=0.27s]
prediction: ['[CLS] will never damage that films which cause fixparaparable loads of years of costly analysis of costly analysis could [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.657 (perp=7.798, rec=0.097, cos=0.001), tot_loss_proj:2.789 [t=0.26s]
prediction: ['[CLS] that will never damage films which cause fixparaparable loads of years of costly analysis of costly analysis could [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.634 (perp=7.604, rec=0.113, cos=0.001), tot_loss_proj:2.792 [t=0.29s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
[1350/2000] tot_loss=1.616 (perp=7.604, rec=0.094, cos=0.001), tot_loss_proj:2.798 [t=0.27s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1400/2000] tot_loss=1.622 (perp=7.604, rec=0.101, cos=0.001), tot_loss_proj:2.798 [t=0.25s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1450/2000] tot_loss=1.616 (perp=7.604, rec=0.095, cos=0.001), tot_loss_proj:2.796 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
[1500/2000] tot_loss=1.611 (perp=7.604, rec=0.089, cos=0.001), tot_loss_proj:2.797 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1550/2000] tot_loss=1.617 (perp=7.604, rec=0.096, cos=0.001), tot_loss_proj:2.791 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1600/2000] tot_loss=1.616 (perp=7.604, rec=0.094, cos=0.001), tot_loss_proj:2.795 [t=0.25s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
[1650/2000] tot_loss=1.619 (perp=7.604, rec=0.098, cos=0.001), tot_loss_proj:2.796 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1700/2000] tot_loss=1.617 (perp=7.604, rec=0.096, cos=0.001), tot_loss_proj:2.793 [t=0.27s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1750/2000] tot_loss=1.622 (perp=7.604, rec=0.101, cos=0.000), tot_loss_proj:2.797 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
[1800/2000] tot_loss=1.617 (perp=7.604, rec=0.096, cos=0.000), tot_loss_proj:2.800 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1850/2000] tot_loss=1.620 (perp=7.604, rec=0.099, cos=0.000), tot_loss_proj:2.797 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[1900/2000] tot_loss=1.615 (perp=7.604, rec=0.093, cos=0.000), tot_loss_proj:2.798 [t=0.26s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
[1950/2000] tot_loss=1.612 (perp=7.604, rec=0.091, cos=0.000), tot_loss_proj:2.792 [t=0.28s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Attempt swap
[2000/2000] tot_loss=1.615 (perp=7.604, rec=0.094, cos=0.000), tot_loss_proj:2.795 [t=0.27s]
prediction: ['[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] that will never damage films which never cause fixparaparable loads of years of costly analysis of costly analysis [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 26.316 | p: 26.316 | r: 26.316
rougeL     | fm: 55.000 | p: 55.000 | r: 55.000
rougeLsum  | fm: 55.000 | p: 55.000 | r: 55.000
r1fm+r2fm = 101.316

[Aggregate metrics]:
rouge1     | fm: 89.393 | p: 89.149 | r: 89.632
rouge2     | fm: 56.102 | p: 56.027 | r: 56.303
rougeL     | fm: 77.655 | p: 77.538 | r: 77.904
rougeLsum  | fm: 77.432 | p: 77.245 | r: 77.642
r1fm+r2fm = 145.495

input #56 time: 0:11:07 | total time: 9:29:17


Running input #57 of 100.
reference: 
========================
wears 
========================
*********************************
*********************************
average of cosine similarity 0.9993815950585869
highest_index [0]
highest [0.9993815950585869]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 1.7954795360565186 for ['[CLS]ne [SEP]']
[Init] best rec loss: 1.633437156677246 for ['[CLS] software [SEP]']
[Init] best rec loss: 1.5058315992355347 for ['[CLS] passed [SEP]']
[Init] best rec loss: 1.4965696334838867 for ['[CLS]cta [SEP]']
[Init] best rec loss: 1.4871668815612793 for ['[CLS] modern [SEP]']
[Init] best rec loss: 1.4436358213424683 for ['[CLS] bundesliga [SEP]']
[Init] best rec loss: 1.4208097457885742 for ['[CLS] thanks [SEP]']
[Init] best rec loss: 1.4164838790893555 for ['[CLS] decision [SEP]']
[Init] best rec loss: 1.390770435333252 for ['[CLS]ering [SEP]']
[Init] best rec loss: 1.3783762454986572 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.434 (perp=8.573, rec=0.538, cos=0.181), tot_loss_proj:3.485 [t=0.23s]
prediction: ['[CLS] graduate [SEP]']
[ 100/2000] tot_loss=2.673 (perp=12.282, rec=0.206, cos=0.011), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.537 (perp=12.282, rec=0.078, cos=0.003), tot_loss_proj:2.523 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.525 (perp=12.282, rec=0.065, cos=0.004), tot_loss_proj:2.522 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.532 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.523 (perp=12.282, rec=0.066, cos=0.000), tot_loss_proj:2.514 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.511 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.512 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.514 (perp=12.282, rec=0.057, cos=0.000), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.518 (perp=12.282, rec=0.061, cos=0.000), tot_loss_proj:2.505 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.509 (perp=12.282, rec=0.052, cos=0.000), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.518 (perp=12.282, rec=0.061, cos=0.000), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.513 (perp=12.282, rec=0.056, cos=0.000), tot_loss_proj:2.518 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.511 (perp=12.282, rec=0.055, cos=0.000), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.528 (perp=12.282, rec=0.071, cos=0.000), tot_loss_proj:2.512 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.511 (perp=12.282, rec=0.055, cos=0.000), tot_loss_proj:2.514 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.520 (perp=12.282, rec=0.063, cos=0.000), tot_loss_proj:2.531 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.520 (perp=12.282, rec=0.063, cos=0.000), tot_loss_proj:2.519 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.505 (perp=12.282, rec=0.048, cos=0.000), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.507 (perp=12.282, rec=0.051, cos=0.000), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.514 (perp=12.282, rec=0.058, cos=0.000), tot_loss_proj:2.524 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.519 (perp=12.282, rec=0.062, cos=0.000), tot_loss_proj:2.515 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.522 (perp=12.282, rec=0.066, cos=0.000), tot_loss_proj:2.511 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.000), tot_loss_proj:2.523 [t=0.35s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.520 (perp=12.282, rec=0.063, cos=0.000), tot_loss_proj:2.517 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.529 (perp=12.282, rec=0.072, cos=0.000), tot_loss_proj:2.527 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.512 (perp=12.282, rec=0.055, cos=0.000), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.525 (perp=12.282, rec=0.068, cos=0.000), tot_loss_proj:2.522 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.510 (perp=12.282, rec=0.053, cos=0.000), tot_loss_proj:2.516 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.518 (perp=12.282, rec=0.062, cos=0.000), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.503 (perp=12.282, rec=0.046, cos=0.000), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.517 (perp=12.282, rec=0.060, cos=0.000), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.516 (perp=12.282, rec=0.059, cos=0.000), tot_loss_proj:2.512 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.518 (perp=12.282, rec=0.061, cos=0.000), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.517 (perp=12.282, rec=0.060, cos=0.000), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.516 (perp=12.282, rec=0.060, cos=0.000), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.515 (perp=12.282, rec=0.058, cos=0.000), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.508 (perp=12.282, rec=0.052, cos=0.000), tot_loss_proj:2.526 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.510 (perp=12.282, rec=0.053, cos=0.000), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.519 (perp=12.282, rec=0.062, cos=0.000), tot_loss_proj:2.515 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.556 | p: 89.394 | r: 89.818
rouge2     | fm: 57.040 | p: 56.923 | r: 57.240
rougeL     | fm: 78.066 | p: 77.921 | r: 78.291
rougeLsum  | fm: 77.699 | p: 77.500 | r: 77.925
r1fm+r2fm = 146.597

input #57 time: 0:10:48 | total time: 9:40:06


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
*********************************
*********************************
average of cosine similarity 0.9992685151622412
highest_index [0]
highest [0.9992685151622412]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.8984190225601196 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 1.8598558902740479 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 1.6641579866409302 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 1.6362143754959106 for ['[CLS] insidethed subject layton devoted approachhead physicians keys vice tarzan mile norman warlord choosebaldi [SEP]']
[Init] best rec loss: 1.633800745010376 for ['[CLS] hissedoop whispered h delayed!lwyn [SEP] could prove atrocities backsie square shu tam [SEP]']
[Init] best rec loss: 1.5590686798095703 for ['[CLS]lusion wake case species applicationnding fluent passing bakeralo couple win used texas installed tucker [SEP]']
[Init] best perm rec loss: 1.5537745952606201 for ['[CLS] passingalo species used baker installednding tucker texas win wakelusion couple application case fluent [SEP]']
[Init] best perm rec loss: 1.5531631708145142 for ['[CLS] tucker installed used texas case bakerlusionnding wake application fluentalo couple passing species win [SEP]']
[Init] best perm rec loss: 1.5502347946166992 for ['[CLS] texas fluent used tucker bakeralolusion application case installednding passing win couple wake species [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.145 (perp=11.775, rec=0.781, cos=0.009), tot_loss_proj:3.852 [t=0.25s]
prediction: ['[CLS] probably stupid israeli got point been bmw our elevator ticket crater. - pile any yet [SEP]']
[ 100/2000] tot_loss=3.109 (perp=12.187, rec=0.667, cos=0.004), tot_loss_proj:3.950 [t=0.26s]
prediction: ['[CLS] hated stupid sometimes made point video commercialple escort ticket crater campaign - few any no [SEP]']
[ 150/2000] tot_loss=2.995 (perp=11.930, rec=0.607, cos=0.002), tot_loss_proj:3.965 [t=0.26s]
prediction: ['[CLS] hated conduct were made passion was any research escort remaining crater campaign morningple limit no [SEP]']
[ 200/2000] tot_loss=3.397 (perp=14.023, rec=0.590, cos=0.002), tot_loss_proj:4.660 [t=0.27s]
prediction: ['[CLS] promise documentaryckleonate story alive businesses fake escort remaining crater campaign wasple assassination no [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.208 (perp=13.318, rec=0.542, cos=0.002), tot_loss_proj:4.338 [t=0.25s]
prediction: ['[CLS] inspirational documentaryckle story facing an deeply fake escort remaining racialasurable wasple assassinationha [SEP]']
[ 300/2000] tot_loss=3.164 (perp=13.279, rec=0.503, cos=0.005), tot_loss_proj:3.891 [t=0.28s]
prediction: ['[CLS] inspirational documentary inspirational story capturing an deeply littlestick remaining attacksasurable theple encounterha [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.018 (perp=12.581, rec=0.496, cos=0.006), tot_loss_proj:3.382 [t=0.26s]
prediction: ['[CLS] inspirational documentary inspirational story capturing an loved little jake remaining racialeley aasurable encounterha [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.719 (perp=11.160, rec=0.483, cos=0.003), tot_loss_proj:3.482 [t=0.26s]
prediction: ['[CLS] inspirational documentary inspirational story capturing an hometown remaining little jake attacks remain aasurable encounterarable [SEP]']
[ 450/2000] tot_loss=2.698 (perp=11.162, rec=0.452, cos=0.014), tot_loss_proj:3.528 [t=0.27s]
prediction: ['[CLS] inspirational bohemian inspirational story capturing an hometown remaining little religious attacks remain a olympics encounterarable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.675 (perp=11.146, rec=0.439, cos=0.006), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] inspirational inspirational bohemian story capturing an hometown remaining little religious attacks remain aasurable encounterarable [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.731 (perp=11.400, rec=0.449, cos=0.002), tot_loss_proj:3.510 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an hometown inspirational little religious attacks remain the souls encounterarable [SEP]']
[ 600/2000] tot_loss=2.666 (perp=11.139, rec=0.435, cos=0.003), tot_loss_proj:3.443 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an hometown inspirational little religious masovian remain the playstation encounterarable [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.593 (perp=10.836, rec=0.425, cos=0.001), tot_loss_proj:3.181 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little religious masovian hometown remain an innocent encounter kilometers [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.613 (perp=10.987, rec=0.414, cos=0.001), tot_loss_proj:3.140 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain the pleasure encounter kilometers [SEP]']
[ 750/2000] tot_loss=2.606 (perp=10.987, rec=0.406, cos=0.002), tot_loss_proj:3.149 [t=0.27s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain the pleasure encounter kilometers [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.600 (perp=10.987, rec=0.399, cos=0.004), tot_loss_proj:3.145 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain the pleasure encounter kilometers [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.660 (perp=11.324, rec=0.393, cos=0.003), tot_loss_proj:3.157 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[ 900/2000] tot_loss=2.659 (perp=11.324, rec=0.392, cos=0.003), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.608 (perp=10.987, rec=0.396, cos=0.015), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain the pleasure encounter kilometers [SEP]']
Attempt swap
[1000/2000] tot_loss=2.645 (perp=11.324, rec=0.380, cos=0.000), tot_loss_proj:3.156 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[1050/2000] tot_loss=2.655 (perp=11.324, rec=0.387, cos=0.003), tot_loss_proj:3.159 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1100/2000] tot_loss=2.638 (perp=11.324, rec=0.373, cos=0.000), tot_loss_proj:3.155 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1150/2000] tot_loss=2.640 (perp=11.324, rec=0.375, cos=0.001), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[1200/2000] tot_loss=2.634 (perp=11.324, rec=0.369, cos=0.001), tot_loss_proj:3.162 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1250/2000] tot_loss=2.632 (perp=11.324, rec=0.367, cos=0.000), tot_loss_proj:3.158 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1300/2000] tot_loss=2.631 (perp=11.324, rec=0.366, cos=0.000), tot_loss_proj:3.157 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[1350/2000] tot_loss=2.629 (perp=11.324, rec=0.364, cos=0.000), tot_loss_proj:3.153 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1400/2000] tot_loss=2.632 (perp=11.324, rec=0.367, cos=0.000), tot_loss_proj:3.160 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1450/2000] tot_loss=2.628 (perp=11.324, rec=0.362, cos=0.001), tot_loss_proj:3.156 [t=0.27s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[1500/2000] tot_loss=2.628 (perp=11.324, rec=0.362, cos=0.001), tot_loss_proj:3.151 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1550/2000] tot_loss=2.629 (perp=11.324, rec=0.364, cos=0.000), tot_loss_proj:3.163 [t=0.28s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1600/2000] tot_loss=2.626 (perp=11.324, rec=0.359, cos=0.002), tot_loss_proj:3.160 [t=0.25s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[1650/2000] tot_loss=2.630 (perp=11.324, rec=0.364, cos=0.001), tot_loss_proj:3.159 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1700/2000] tot_loss=2.623 (perp=11.324, rec=0.357, cos=0.001), tot_loss_proj:3.158 [t=0.27s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1750/2000] tot_loss=2.619 (perp=11.324, rec=0.353, cos=0.001), tot_loss_proj:3.157 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
[1800/2000] tot_loss=2.624 (perp=11.324, rec=0.359, cos=0.000), tot_loss_proj:3.157 [t=0.27s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an pleasure encounter kilometers [SEP]']
Attempt swap
[1850/2000] tot_loss=2.621 (perp=11.331, rec=0.353, cos=0.001), tot_loss_proj:3.318 [t=0.27s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an love encounter kilometers [SEP]']
Attempt swap
[1900/2000] tot_loss=2.625 (perp=11.331, rec=0.359, cos=0.000), tot_loss_proj:3.312 [t=0.26s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an love encounter kilometers [SEP]']
[1950/2000] tot_loss=2.620 (perp=11.331, rec=0.354, cos=0.000), tot_loss_proj:3.316 [t=0.27s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an love encounter kilometers [SEP]']
Attempt swap
[2000/2000] tot_loss=2.615 (perp=11.331, rec=0.348, cos=0.001), tot_loss_proj:3.317 [t=0.28s]
prediction: ['[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an love encounter kilometers [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] innocence inspirational anthology story capturing an inspirational little masovian religious hometown remain an love encounter kilometers [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.941 | p: 50.000 | r: 56.250
rouge2     | fm: 12.500 | p: 11.765 | r: 13.333
rougeL     | fm: 35.294 | p: 33.333 | r: 37.500
rougeLsum  | fm: 35.294 | p: 33.333 | r: 37.500
r1fm+r2fm = 65.441

[Aggregate metrics]:
rouge1     | fm: 88.862 | p: 88.654 | r: 89.238
rouge2     | fm: 56.245 | p: 56.183 | r: 56.423
rougeL     | fm: 77.338 | p: 77.150 | r: 77.641
rougeLsum  | fm: 77.001 | p: 76.802 | r: 77.252
r1fm+r2fm = 145.107

input #58 time: 0:11:02 | total time: 9:51:08


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 1.9130570888519287 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 1.893306851387024 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 1.8817111253738403 for ['[CLS] shares josephine settled commerce refrain bulletsgi moved plot awaitanies roger console fergusotidew [SEP]']
[Init] best rec loss: 1.7740832567214966 for ['[CLS] meetings primarily afar vietnamille sound explaining bun ii powerped able speaking [SEP] brow illumination [SEP]']
[Init] best rec loss: 1.75552499294281 for ['[CLS] trollsity underoh othersrion vault sorry days premiereend wivesjit reachedhold motorway [SEP]']
[Init] best rec loss: 1.6795601844787598 for ['[CLS] approaches dumb accept households frame relation sport replymis logan surrounding dutch dragon different com discipline [SEP]']
[Init] best rec loss: 1.6730873584747314 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best rec loss: 1.4757320880889893 for ['[CLS] organic passengers heroic wall duty change surgery drag kay statesflower hadn retirement cross will money [SEP]']
[Init] best perm rec loss: 1.473044991493225 for ['[CLS]flower states passengers cross drag organic money change wall hadn retirement kay heroic surgery will duty [SEP]']
[Init] best perm rec loss: 1.4710206985473633 for ['[CLS] wall passengers will states duty kay drag cross change money surgery heroicflower hadn organic retirement [SEP]']
[Init] best perm rec loss: 1.4710203409194946 for ['[CLS] hadn passengers retirement wall states organic drag change duty surgery kayflower money heroic cross will [SEP]']
[Init] best perm rec loss: 1.4642279148101807 for ['[CLS] wall organic passengers drag change surgeryflower will states retirement duty money kay cross heroic hadn [SEP]']
[Init] best perm rec loss: 1.4622763395309448 for ['[CLS] states passengers cross change organic surgeryflower kay money drag retirement wall will heroic duty hadn [SEP]']
[Init] best perm rec loss: 1.4614100456237793 for ['[CLS] hadn organic passengersflower surgery heroic cross kay will wall retirement change money states drag duty [SEP]']
[Init] best perm rec loss: 1.4608839750289917 for ['[CLS] organicflower retirement will money heroic duty hadn wall drag surgery cross passengers states change kay [SEP]']
[Init] best perm rec loss: 1.4605615139007568 for ['[CLS] organic drag passengers heroicflower cross kay surgery retirement wall will duty states money change hadn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.208 (perp=14.125, rec=0.378, cos=0.004), tot_loss_proj:3.628 [t=0.25s]
prediction: ['[CLS] spiritual wonderful partner brandy regina monte portrait holder bscwife introduced kat mother spark charlie of [SEP]']
[ 100/2000] tot_loss=2.621 (perp=11.717, rec=0.274, cos=0.003), tot_loss_proj:4.005 [t=0.27s]
prediction: ['[CLS] patient young setup char (kaya his screenwife has once woman lee who her [SEP]']
[ 150/2000] tot_loss=2.232 (perp=10.199, rec=0.191, cos=0.001), tot_loss_proj:3.541 [t=0.27s]
prediction: ['[CLS] growing young of char ofa a the screenwife has who woman char who her [SEP]']
[ 200/2000] tot_loss=2.177 (perp=10.044, rec=0.167, cos=0.001), tot_loss_proj:3.424 [t=0.25s]
prediction: ['[CLS] growing young of chara screen a the screen screen has who woman char knows her [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.956 (perp=9.050, rec=0.144, cos=0.001), tot_loss_proj:2.903 [t=0.26s]
prediction: ['[CLS] growing young of chara screen a the screen screen woman who has char knows how [SEP]']
[ 300/2000] tot_loss=2.159 (perp=10.151, rec=0.128, cos=0.001), tot_loss_proj:3.035 [t=0.26s]
prediction: ['[CLS] human young ofisma screen a the screen screen woman who has char knows how [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.061 (perp=9.704, rec=0.119, cos=0.001), tot_loss_proj:3.063 [t=0.29s]
prediction: ['[CLS] of young humanisma screen a the screen char woman who has char knows hold [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.138 (perp=9.902, rec=0.156, cos=0.002), tot_loss_proj:3.368 [t=0.26s]
prediction: ['[CLS] of younglinerisma young. the screen human woman who has char knows holding [SEP]']
[ 450/2000] tot_loss=2.240 (perp=10.627, rec=0.114, cos=0.001), tot_loss_proj:3.241 [t=0.26s]
prediction: ['[CLS] of young 語isma young a the screen human woman who has char knows hold [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.997 (perp=9.423, rec=0.112, cos=0.001), tot_loss_proj:3.337 [t=0.26s]
prediction: ['[CLS] screen young freudisma young of the screen human woman who has char knows hold [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.933 (perp=9.065, rec=0.119, cos=0.001), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] is youngkin charisma young of the screen how woman who has knows hold [SEP]']
[ 600/2000] tot_loss=1.842 (perp=8.678, rec=0.106, cos=0.001), tot_loss_proj:2.673 [t=0.26s]
prediction: ['[CLS] - palkin charisma young of the screen how woman who has knows hold [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.770 (perp=8.384, rec=0.093, cos=0.001), tot_loss_proj:2.335 [t=0.27s]
prediction: ['[CLS] - charkin charisma young of the screen knows how woman who has hold [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.736 (perp=8.202, rec=0.094, cos=0.001), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS]kinkeeping - charisma young of the screen knows how woman who has hold [SEP]']
[ 750/2000] tot_loss=1.735 (perp=8.202, rec=0.094, cos=0.001), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS]kinkeeping - charisma young of the screen knows how woman who has hold [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.498 (perp=7.109, rec=0.075, cos=0.001), tot_loss_proj:2.145 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.514 (perp=7.109, rec=0.091, cos=0.001), tot_loss_proj:2.148 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[ 900/2000] tot_loss=1.509 (perp=7.109, rec=0.087, cos=0.001), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.512 (perp=7.109, rec=0.089, cos=0.001), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1000/2000] tot_loss=1.496 (perp=7.109, rec=0.073, cos=0.001), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1050/2000] tot_loss=1.503 (perp=7.109, rec=0.081, cos=0.001), tot_loss_proj:2.143 [t=0.27s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1100/2000] tot_loss=1.496 (perp=7.109, rec=0.073, cos=0.001), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.502 (perp=7.109, rec=0.079, cos=0.001), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1200/2000] tot_loss=1.507 (perp=7.109, rec=0.084, cos=0.001), tot_loss_proj:2.132 [t=0.27s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1250/2000] tot_loss=1.509 (perp=7.109, rec=0.086, cos=0.001), tot_loss_proj:2.131 [t=0.27s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1300/2000] tot_loss=1.494 (perp=7.109, rec=0.072, cos=0.001), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1350/2000] tot_loss=1.505 (perp=7.109, rec=0.082, cos=0.001), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1400/2000] tot_loss=1.498 (perp=7.109, rec=0.076, cos=0.001), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1450/2000] tot_loss=1.516 (perp=7.109, rec=0.094, cos=0.001), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1500/2000] tot_loss=1.506 (perp=7.109, rec=0.084, cos=0.001), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1550/2000] tot_loss=1.507 (perp=7.109, rec=0.085, cos=0.001), tot_loss_proj:2.130 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1600/2000] tot_loss=1.494 (perp=7.109, rec=0.072, cos=0.001), tot_loss_proj:2.133 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1650/2000] tot_loss=1.493 (perp=7.109, rec=0.071, cos=0.001), tot_loss_proj:2.127 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1700/2000] tot_loss=1.508 (perp=7.109, rec=0.085, cos=0.001), tot_loss_proj:2.126 [t=0.27s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1750/2000] tot_loss=1.513 (perp=7.109, rec=0.090, cos=0.001), tot_loss_proj:2.127 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1800/2000] tot_loss=1.509 (perp=7.109, rec=0.086, cos=0.001), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1850/2000] tot_loss=1.495 (perp=7.109, rec=0.073, cos=0.001), tot_loss_proj:2.133 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.500 (perp=7.109, rec=0.078, cos=0.001), tot_loss_proj:2.133 [t=0.25s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
[1950/2000] tot_loss=1.504 (perp=7.109, rec=0.081, cos=0.001), tot_loss_proj:2.129 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.510 (perp=7.109, rec=0.088, cos=0.001), tot_loss_proj:2.126 [t=0.26s]
prediction: ['[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] charkeeping - charisma of the screen knows how young woman who has hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 92.857 | r: 81.250
rouge2     | fm: 35.714 | p: 38.462 | r: 33.333
rougeL     | fm: 53.333 | p: 57.143 | r: 50.000
rougeLsum  | fm: 53.333 | p: 57.143 | r: 50.000
r1fm+r2fm = 122.381

[Aggregate metrics]:
rouge1     | fm: 88.822 | p: 88.706 | r: 89.066
rouge2     | fm: 55.966 | p: 55.864 | r: 56.142
rougeL     | fm: 76.903 | p: 76.802 | r: 77.159
rougeLsum  | fm: 76.709 | p: 76.559 | r: 76.919
r1fm+r2fm = 144.788

input #59 time: 0:11:06 | total time: 10:02:15


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
*********************************
*********************************
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 1.8264330625534058 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 1.785794734954834 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 1.5257476568222046 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 1.4993537664413452 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 1.494861125946045 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 1.4207831621170044 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 1.4200644493103027 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 1.413394570350647 for ['[CLS] cover majority /lby constitution upset strung throughshawouringitude plenty [SEP]']
[Init] best perm rec loss: 1.4109059572219849 for ['[CLS] majority upset strungitude /ouringshawlby cover through plenty constitution [SEP]']
[Init] best perm rec loss: 1.4078900814056396 for ['[CLS] / majority strungouringshawlby through constitutionitude plenty cover upset [SEP]']
[Init] best perm rec loss: 1.4074980020523071 for ['[CLS] majority strung throughouringlbyitudeshaw / constitution upset plenty cover [SEP]']
[Init] best perm rec loss: 1.4071258306503296 for ['[CLS] plentyitude /lby strung cover upsetshaw constitution through majorityouring [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.560 (perp=11.207, rec=0.315, cos=0.004), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] late awkwardly unclear snail campaign - month january hallway seat becameless [SEP]']
[ 100/2000] tot_loss=2.512 (perp=11.400, rec=0.230, cos=0.002), tot_loss_proj:3.154 [t=0.26s]
prediction: ['[CLS] is awkwardly awkwardly opera ) of season opera lecture cops is critic [SEP]']
[ 150/2000] tot_loss=2.432 (perp=11.227, rec=0.186, cos=0.001), tot_loss_proj:2.697 [t=0.28s]
prediction: ['[CLS] is awkwardly awkwardly opera paced the season soap paced circuit. circuit [SEP]']
[ 200/2000] tot_loss=2.064 (perp=9.462, rec=0.170, cos=0.002), tot_loss_proj:2.351 [t=0.26s]
prediction: ['[CLS] is awkwardly awkwardly opera paced the paced soap opera circuit. circuit [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.109 (perp=9.517, rec=0.203, cos=0.003), tot_loss_proj:2.374 [t=0.24s]
prediction: ['[CLS] circuit is awkwardly awkwardly circuit paced the story soap opera circuit is [SEP]']
[ 300/2000] tot_loss=2.192 (perp=10.235, rec=0.144, cos=0.001), tot_loss_proj:2.541 [t=0.25s]
prediction: ['[CLS] circuit is awkwardly awkwardly circuit paced the story soap opera circuit story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.248 (perp=10.640, rec=0.119, cos=0.001), tot_loss_proj:2.652 [t=0.27s]
prediction: ['[CLS] circuit is awkwardly awkwardly circuit paced the circuit soap story story story [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.931 (perp=9.082, rec=0.114, cos=0.001), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly circuit paced circuit soap opera opera story [SEP]']
[ 450/2000] tot_loss=1.930 (perp=9.082, rec=0.113, cos=0.001), tot_loss_proj:2.262 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly circuit paced circuit soap opera opera story [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.703 (perp=8.010, rec=0.100, cos=0.001), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit soap opera circuit opera story [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.697 (perp=8.010, rec=0.094, cos=0.001), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit soap opera circuit opera story [SEP]']
[ 600/2000] tot_loss=2.183 (perp=10.439, rec=0.094, cos=0.001), tot_loss_proj:2.435 [t=0.25s]
prediction: ['[CLS]h is the awkwardly awkwardly paced circuit soap - circuit opera story [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.072 (perp=9.908, rec=0.089, cos=0.001), tot_loss_proj:2.302 [t=0.25s]
prediction: ['[CLS]h is the awkwardly awkwardly paced circuit soap opera - circuit story [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.861 (perp=8.812, rec=0.098, cos=0.001), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit soap opera -h story [SEP]']
[ 750/2000] tot_loss=1.849 (perp=8.812, rec=0.086, cos=0.001), tot_loss_proj:2.044 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit soap opera -h story [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.804 (perp=8.557, rec=0.091, cos=0.001), tot_loss_proj:2.024 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.801 (perp=8.557, rec=0.089, cos=0.001), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[ 900/2000] tot_loss=1.796 (perp=8.557, rec=0.084, cos=0.001), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=8.557, rec=0.081, cos=0.001), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=8.557, rec=0.091, cos=0.001), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1050/2000] tot_loss=1.794 (perp=8.557, rec=0.082, cos=0.001), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.801 (perp=8.557, rec=0.089, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1150/2000] tot_loss=1.790 (perp=8.557, rec=0.078, cos=0.001), tot_loss_proj:2.024 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1200/2000] tot_loss=1.785 (perp=8.557, rec=0.073, cos=0.001), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1250/2000] tot_loss=1.796 (perp=8.557, rec=0.084, cos=0.001), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.784 (perp=8.557, rec=0.072, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1350/2000] tot_loss=1.797 (perp=8.557, rec=0.085, cos=0.001), tot_loss_proj:2.018 [t=0.27s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.791 (perp=8.557, rec=0.079, cos=0.001), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.798 (perp=8.557, rec=0.086, cos=0.001), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.557, rec=0.082, cos=0.001), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.796 (perp=8.557, rec=0.084, cos=0.001), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.791 (perp=8.557, rec=0.079, cos=0.001), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.557, rec=0.080, cos=0.001), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.791 (perp=8.557, rec=0.080, cos=0.001), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.792 (perp=8.557, rec=0.080, cos=0.001), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1800/2000] tot_loss=1.797 (perp=8.557, rec=0.085, cos=0.001), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.791 (perp=8.557, rec=0.079, cos=0.001), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.788 (perp=8.557, rec=0.076, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
[1950/2000] tot_loss=1.792 (perp=8.557, rec=0.080, cos=0.001), tot_loss_proj:2.024 [t=0.26s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.785 (perp=8.557, rec=0.073, cos=0.001), tot_loss_proj:2.011 [t=0.27s]
prediction: ['[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] circuit is the awkwardly awkwardly paced circuit - soap operah story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 57.143 | p: 54.545 | r: 60.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 135.404

[Aggregate metrics]:
rouge1     | fm: 88.667 | p: 88.518 | r: 89.047
rouge2     | fm: 55.970 | p: 55.825 | r: 56.197
rougeL     | fm: 76.915 | p: 76.794 | r: 77.213
rougeLsum  | fm: 76.708 | p: 76.506 | r: 76.993
r1fm+r2fm = 144.636

input #60 time: 0:10:50 | total time: 10:13:06


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
*********************************
*********************************
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 1.8300962448120117 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 1.8116177320480347 for ['[CLS]zeeali donated [SEP]']
[Init] best rec loss: 1.6035362482070923 for ['[CLS] age bad link [SEP]']
[Init] best rec loss: 1.6008113622665405 for ['[CLS] maximus broken initiative [SEP]']
[Init] best rec loss: 1.175456166267395 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 1.1720333099365234 for ['[CLS] lets mini request [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.042 (perp=8.940, rec=0.246, cos=0.008), tot_loss_proj:2.142 [t=0.25s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 100/2000] tot_loss=1.939 (perp=8.940, rec=0.146, cos=0.005), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 150/2000] tot_loss=1.935 (perp=8.940, rec=0.143, cos=0.004), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 200/2000] tot_loss=1.920 (perp=8.940, rec=0.128, cos=0.004), tot_loss_proj:2.151 [t=0.26s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.690 (perp=7.752, rec=0.136, cos=0.003), tot_loss_proj:1.819 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 300/2000] tot_loss=1.681 (perp=7.752, rec=0.127, cos=0.003), tot_loss_proj:1.822 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.671 (perp=7.752, rec=0.117, cos=0.003), tot_loss_proj:1.821 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.737 (perp=8.295, rec=0.077, cos=0.001), tot_loss_proj:1.908 [t=0.26s]
prediction: ['[CLS] beautiful, scene [SEP]']
[ 450/2000] tot_loss=1.723 (perp=8.295, rec=0.063, cos=0.001), tot_loss_proj:1.907 [t=0.25s]
prediction: ['[CLS] beautiful, scene [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.496 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.627 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.482 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.493 (perp=7.101, rec=0.071, cos=0.001), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.493 (perp=7.101, rec=0.071, cos=0.001), tot_loss_proj:1.629 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.487 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.622 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.485 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.632 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.618 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.494 (perp=7.101, rec=0.072, cos=0.001), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.467 (perp=7.101, rec=0.046, cos=0.001), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.477 (perp=7.101, rec=0.055, cos=0.001), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.487 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.479 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.477 (perp=7.101, rec=0.056, cos=0.001), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.480 (perp=7.101, rec=0.059, cos=0.001), tot_loss_proj:1.635 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.485 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.618 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.483 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.496 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.612 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.838 | p: 88.685 | r: 89.240
rouge2     | fm: 56.505 | p: 56.398 | r: 56.674
rougeL     | fm: 77.414 | p: 77.275 | r: 77.674
rougeLsum  | fm: 77.076 | p: 76.924 | r: 77.324
r1fm+r2fm = 145.343

input #61 time: 0:10:48 | total time: 10:23:54


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
*********************************
*********************************
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 1.9530375003814697 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 1.880612850189209 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 1.7968920469284058 for ['[CLS] help rarely extensionbreaker local sea team mom beacon tear wax chairmanphstatic mum new osman intervention [CLS] attentionius [SEP]']
[Init] best rec loss: 1.767058253288269 for ['[CLS]tled traffic conduct atoms sets commercial : robertsrgeonkney hard sherman [SEP] bus forbc charlie dragons medal same gravity [SEP]']
[Init] best rec loss: 1.749898910522461 for ['[CLS] wasn homosexual carey sometimes wave october, vampire bbc bloody pie hudson contemporary crowd turning error helped pepper thus reaches recently [SEP]']
[Init] best rec loss: 1.741378664970398 for ['[CLS] such duo demand appeared being pv status stereotypes superlary eight song signage thing conform take pup i planetary feed free [SEP]']
[Init] best rec loss: 1.7179762125015259 for ['[CLS] ammunition nowheregut opinion deemed romansdong was mattered al body mono turkish abet main alone stations bag lead facebook [SEP]']
[Init] best rec loss: 1.6971365213394165 for ['[CLS] adam skin lissa love dannberg western wrote food serious apart departureml gameposedmat few resides because track believed [SEP]']
[Init] best perm rec loss: 1.6958225965499878 for ['[CLS]mat departure game wrote skin lissa resides adam western fewml foodnberg track apart because believed seriousposed dan love [SEP]']
[Init] best perm rec loss: 1.6951234340667725 for ['[CLS] adam few departure danmatmlposednberg food because game serious believed resides wrote lissa western apart track love skin [SEP]']
[Init] best perm rec loss: 1.6936944723129272 for ['[CLS] lissa apartml western believed love gamenberg fewposed trackmat because resides dan skin adam serious wrote food departure [SEP]']
[Init] best perm rec loss: 1.6933423280715942 for ['[CLS] track serious adamnberg gameposed apart because few wrote resides dan food skin believed westernml lissa lovemat departure [SEP]']
[Init] best perm rec loss: 1.6924365758895874 for ['[CLS] track resides departure apart few love becausenberg believed wrote lissa game adam dan skinml western seriousposedmat food [SEP]']
[Init] best perm rec loss: 1.6920912265777588 for ['[CLS]mat apart love few western skin because game believednbergml serious adam wrote track departure lissaposed food resides dan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.209 (perp=12.265, rec=0.743, cos=0.013), tot_loss_proj:3.969 [t=0.26s]
prediction: ['[CLS] defense nfl opposition lacking week grip enacted proceedings for no rateund stupid fake numb foreign party cartoon partynesia etc [SEP]']
[ 100/2000] tot_loss=2.945 (perp=11.577, rec=0.626, cos=0.004), tot_loss_proj:3.863 [t=0.26s]
prediction: ['[CLS] damage nfl opposition lacking heavily call were recorded for no rate give common wrote ⟩ war stuffles party wrong court [SEP]']
[ 150/2000] tot_loss=2.891 (perp=11.492, rec=0.587, cos=0.006), tot_loss_proj:3.855 [t=0.26s]
prediction: ['[CLS] palace jake opposition lacking heavily call were recorded for independent or give worst doing ⟩ war movies italian party this avoided [SEP]']
[ 200/2000] tot_loss=2.978 (perp=11.660, rec=0.638, cos=0.008), tot_loss_proj:3.902 [t=0.25s]
prediction: ['[CLS] offensive jake opposition addict minor! was hat to trouble or give worst disco ⟩ war moviesles khmer rubber avoided [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.898 (perp=11.678, rec=0.558, cos=0.005), tot_loss_proj:3.891 [t=0.26s]
prediction: ['[CLS] offensive him opposition cracking involved call jake troops to trouble or give worst does constitution war movies italian interstate this avoided [SEP]']
[ 300/2000] tot_loss=3.089 (perp=12.782, rec=0.531, cos=0.001), tot_loss_proj:4.110 [t=0.26s]
prediction: ['[CLS] offensive drawers opposition cracking involved callmanship minions to including or give worst nintendo constitution war movies italian interstate his prevention [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.672 (perp=10.795, rec=0.511, cos=0.001), tot_loss_proj:4.105 [t=0.26s]
prediction: ['[CLS] war was opposition cracking his callmanship grace to including or making prevention does grace war movies to interstate involved prevention [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.535 (perp=10.141, rec=0.503, cos=0.003), tot_loss_proj:3.956 [t=0.30s]
prediction: ['[CLS] war was opposition cracking this call to gracemanship including or making prevention does grace war movies to interstate concerned prevention [SEP]']
[ 450/2000] tot_loss=2.575 (perp=10.400, rec=0.490, cos=0.005), tot_loss_proj:3.754 [t=0.26s]
prediction: ['[CLS] war was season cracking this call to gracemanship resistance or making prevention does grace war movies to interstate concerned prevention [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.653 (perp=10.856, rec=0.479, cos=0.003), tot_loss_proj:3.893 [t=0.26s]
prediction: ['[CLS] abuse his season tian was call to gracemanship resistance or making prevention does grace war movies to interstate concerned prevention [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.594 (perp=10.507, rec=0.485, cos=0.008), tot_loss_proj:3.814 [t=0.26s]
prediction: ['[CLS] abuse his season tianriety call to gracemanship him or making prevention does grace war movies to interstate concerned prevention [SEP]']
[ 600/2000] tot_loss=2.573 (perp=10.507, rec=0.468, cos=0.003), tot_loss_proj:3.812 [t=0.26s]
prediction: ['[CLS] abuse his season tianriety call to gracemanship him or making prevention does grace war movies to interstate concerned prevention [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.472 (perp=10.057, rec=0.460, cos=0.000), tot_loss_proj:3.775 [t=0.26s]
prediction: ['[CLS] abuse his season maderiety call to gracemanship detection or making movies does grace war prevention to interstate concerned prevention [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.431 (perp=9.844, rec=0.460, cos=0.002), tot_loss_proj:3.761 [t=0.26s]
prediction: ['[CLS] abuse his season made call to gracemanship prevention detection for making movies does grace war prevention to interstate concerned prevention [SEP]']
[ 750/2000] tot_loss=2.472 (perp=10.046, rec=0.458, cos=0.005), tot_loss_proj:3.849 [t=0.25s]
prediction: ['[CLS] abuse his season tian call to gracemanship prevention detection for make movies does grace war prevention to interstate concerned prevention [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.389 (perp=9.719, rec=0.443, cos=0.002), tot_loss_proj:3.824 [t=0.26s]
prediction: ['[CLS] war the season made call to gracemanship prevention detection for making movies does grace war prevention to interstate to prevention [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.380 (perp=9.682, rec=0.441, cos=0.002), tot_loss_proj:3.866 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to grace constructed prevention detection for making movies does grace war prevention to directed to prevention [SEP]']
[ 900/2000] tot_loss=2.336 (perp=9.405, rec=0.445, cos=0.010), tot_loss_proj:3.763 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to grace made prevention detection for making movies does grace war prevention to except to prevention [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.398 (perp=9.825, rec=0.432, cos=0.001), tot_loss_proj:3.776 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to grace made prevention detection for making moviesjee grace war prevention to except to prevention [SEP]']
Attempt swap
[1000/2000] tot_loss=2.411 (perp=9.825, rec=0.431, cos=0.015), tot_loss_proj:3.780 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to grace made prevention detection for making moviesjee grace war prevention to except to prevention [SEP]']
[1050/2000] tot_loss=2.395 (perp=9.833, rec=0.426, cos=0.002), tot_loss_proj:3.730 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best made prevention detection for making moviesjee grace war prevention to except to prevention [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.493 (perp=10.290, rec=0.430, cos=0.005), tot_loss_proj:3.896 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made her for make moviesjee grace war prevention of movies involved prevention [SEP]']
Attempt swap
[1150/2000] tot_loss=2.292 (perp=9.312, rec=0.416, cos=0.014), tot_loss_proj:3.673 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making moviesjee grace war prevention of movies to prevention [SEP]']
[1200/2000] tot_loss=2.274 (perp=9.312, rec=0.411, cos=0.000), tot_loss_proj:3.673 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making moviesjee grace war prevention of movies to prevention [SEP]']
Attempt swap
[1250/2000] tot_loss=2.258 (perp=9.243, rec=0.408, cos=0.002), tot_loss_proj:3.679 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made her for making movies states grace war prevention of movies to prevention [SEP]']
Attempt swap
[1300/2000] tot_loss=2.312 (perp=9.401, rec=0.423, cos=0.008), tot_loss_proj:3.655 [t=0.27s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making movies states grace war prevention of movies to prevention [SEP]']
[1350/2000] tot_loss=2.285 (perp=9.401, rec=0.405, cos=0.000), tot_loss_proj:3.658 [t=0.24s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making movies states grace war prevention of movies to prevention [SEP]']
Attempt swap
[1400/2000] tot_loss=2.286 (perp=9.401, rec=0.404, cos=0.002), tot_loss_proj:3.657 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making movies states grace war prevention of movies to prevention [SEP]']
Attempt swap
[1450/2000] tot_loss=2.288 (perp=9.401, rec=0.405, cos=0.002), tot_loss_proj:3.656 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making movies states grace war prevention of movies to prevention [SEP]']
[1500/2000] tot_loss=2.285 (perp=9.401, rec=0.405, cos=0.000), tot_loss_proj:3.655 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making movies states grace war prevention of movies to prevention [SEP]']
Attempt swap
[1550/2000] tot_loss=2.422 (perp=9.958, rec=0.422, cos=0.009), tot_loss_proj:3.760 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for making movies states grace war prevention of movies involved prevention [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.361 (perp=9.738, rec=0.412, cos=0.002), tot_loss_proj:3.776 [t=0.29s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection for states movies making grace war prevention of movies involved prevention [SEP]']
[1650/2000] tot_loss=2.343 (perp=9.712, rec=0.400, cos=0.000), tot_loss_proj:3.868 [t=0.27s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection forjee movies making grace war prevention of movies to prevention [SEP]']
Attempt swap
[1700/2000] tot_loss=2.413 (perp=10.063, rec=0.401, cos=0.000), tot_loss_proj:3.932 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection anotherjee movies making grace war prevention of movies to prevention [SEP]']
Attempt swap
[1750/2000] tot_loss=2.412 (perp=10.063, rec=0.399, cos=0.000), tot_loss_proj:3.932 [t=0.27s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection anotherjee movies making grace war prevention of movies to prevention [SEP]']
[1800/2000] tot_loss=2.410 (perp=10.063, rec=0.397, cos=0.000), tot_loss_proj:3.930 [t=0.25s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection anotherjee movies making grace war prevention of movies to prevention [SEP]']
Attempt swap
[1850/2000] tot_loss=2.411 (perp=10.063, rec=0.397, cos=0.002), tot_loss_proj:3.933 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection anotherjee movies making grace war prevention of movies to prevention [SEP]']
Attempt swap
[1900/2000] tot_loss=2.342 (perp=9.712, rec=0.399, cos=0.000), tot_loss_proj:3.866 [t=0.27s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection forjee movies making grace war prevention of movies to prevention [SEP]']
[1950/2000] tot_loss=2.337 (perp=9.712, rec=0.395, cos=0.000), tot_loss_proj:3.867 [t=0.29s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection forjee movies making grace war prevention of movies to prevention [SEP]']
Attempt swap
[2000/2000] tot_loss=2.333 (perp=9.712, rec=0.390, cos=0.000), tot_loss_proj:3.866 [t=0.26s]
prediction: ['[CLS] abuse the seasonmanship call to best prevention made detection forjee movies making grace war prevention of movies to prevention [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] abuse the seasonmanship call to best prevention made detection forjee movies making grace war prevention of movies to prevention [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.116 | p: 66.667 | r: 63.636
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 32.558 | p: 33.333 | r: 31.818
rougeLsum  | fm: 32.558 | p: 33.333 | r: 31.818
r1fm+r2fm = 65.116

[Aggregate metrics]:
rouge1     | fm: 88.519 | p: 88.395 | r: 88.791
rouge2     | fm: 55.633 | p: 55.491 | r: 55.828
rougeL     | fm: 76.545 | p: 76.418 | r: 76.810
rougeLsum  | fm: 76.366 | p: 76.213 | r: 76.679
r1fm+r2fm = 144.152

input #62 time: 0:11:03 | total time: 10:34:58


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
*********************************
*********************************
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 1.875612497329712 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 1.2830250263214111 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 1.216496467590332 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best rec loss: 1.2096959352493286 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 1.208850383758545 for ['[CLS] established named tiffany club violent [SEP]']
[Init] best rec loss: 1.1488268375396729 for ['[CLS] ice coe poor t approaching [SEP]']
[Init] best perm rec loss: 1.1447150707244873 for ['[CLS] ice t approaching poor coe [SEP]']
[Init] best perm rec loss: 1.1429733037948608 for ['[CLS] coe approaching t poor ice [SEP]']
[Init] best perm rec loss: 1.142871618270874 for ['[CLS] approaching coe poor t ice [SEP]']
[Init] best perm rec loss: 1.1421325206756592 for ['[CLS] t ice approaching poor coe [SEP]']
[Init] best perm rec loss: 1.1394460201263428 for ['[CLS] coe poor approaching t ice [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.604 (perp=11.261, rec=0.345, cos=0.007), tot_loss_proj:3.088 [t=0.25s]
prediction: ['[CLS] finding slow approaching ticket return [SEP]']
[ 100/2000] tot_loss=1.961 (perp=8.856, rec=0.186, cos=0.003), tot_loss_proj:2.678 [t=0.25s]
prediction: ['[CLS] finding looking for ticket return [SEP]']
[ 150/2000] tot_loss=1.938 (perp=9.152, rec=0.105, cos=0.002), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] looking looking for ticket return [SEP]']
[ 200/2000] tot_loss=1.925 (perp=9.152, rec=0.094, cos=0.001), tot_loss_proj:2.284 [t=0.25s]
prediction: ['[CLS] looking looking for ticket return [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.758 (perp=8.377, rec=0.082, cos=0.001), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] find looking for ticket return [SEP]']
[ 300/2000] tot_loss=1.681 (perp=8.085, rec=0.064, cos=0.001), tot_loss_proj:2.378 [t=0.26s]
prediction: ['[CLS] for looking for ticket return [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.826 (perp=8.745, rec=0.076, cos=0.000), tot_loss_proj:2.569 [t=0.27s]
prediction: ['[CLS] for looking a ticket return [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.264 (perp=5.941, rec=0.075, cos=0.001), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 450/2000] tot_loss=1.258 (perp=5.941, rec=0.069, cos=0.000), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.252 (perp=5.941, rec=0.063, cos=0.000), tot_loss_proj:1.465 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.253 (perp=5.941, rec=0.064, cos=0.000), tot_loss_proj:1.468 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 600/2000] tot_loss=1.245 (perp=5.941, rec=0.056, cos=0.000), tot_loss_proj:1.459 [t=0.28s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.258 (perp=5.941, rec=0.069, cos=0.000), tot_loss_proj:1.467 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.255 (perp=5.941, rec=0.066, cos=0.000), tot_loss_proj:1.463 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 750/2000] tot_loss=1.262 (perp=5.941, rec=0.074, cos=0.000), tot_loss_proj:1.469 [t=0.28s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.261 (perp=5.941, rec=0.073, cos=0.000), tot_loss_proj:1.455 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.253 (perp=5.941, rec=0.065, cos=0.000), tot_loss_proj:1.476 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 900/2000] tot_loss=1.246 (perp=5.941, rec=0.057, cos=0.000), tot_loss_proj:1.456 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.261 (perp=5.941, rec=0.072, cos=0.000), tot_loss_proj:1.461 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.000), tot_loss_proj:1.465 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1050/2000] tot_loss=1.266 (perp=5.941, rec=0.078, cos=0.000), tot_loss_proj:1.468 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.259 (perp=5.941, rec=0.071, cos=0.000), tot_loss_proj:1.461 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.249 (perp=5.941, rec=0.060, cos=0.000), tot_loss_proj:1.461 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1200/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.000), tot_loss_proj:1.466 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.252 (perp=5.941, rec=0.063, cos=0.000), tot_loss_proj:1.459 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.252 (perp=5.941, rec=0.063, cos=0.000), tot_loss_proj:1.473 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1350/2000] tot_loss=1.244 (perp=5.941, rec=0.056, cos=0.000), tot_loss_proj:1.457 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.000), tot_loss_proj:1.457 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.256 (perp=5.941, rec=0.067, cos=0.000), tot_loss_proj:1.458 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1500/2000] tot_loss=1.255 (perp=5.941, rec=0.066, cos=0.000), tot_loss_proj:1.466 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.256 (perp=5.941, rec=0.067, cos=0.000), tot_loss_proj:1.466 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.242 (perp=5.941, rec=0.053, cos=0.000), tot_loss_proj:1.462 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1650/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.000), tot_loss_proj:1.467 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.252 (perp=5.941, rec=0.064, cos=0.000), tot_loss_proj:1.453 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.247 (perp=5.941, rec=0.058, cos=0.000), tot_loss_proj:1.459 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1800/2000] tot_loss=1.240 (perp=5.941, rec=0.051, cos=0.000), tot_loss_proj:1.473 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.252 (perp=5.941, rec=0.064, cos=0.000), tot_loss_proj:1.463 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.248 (perp=5.941, rec=0.060, cos=0.000), tot_loss_proj:1.467 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1950/2000] tot_loss=1.270 (perp=5.941, rec=0.082, cos=0.000), tot_loss_proj:1.459 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.250 (perp=5.941, rec=0.062, cos=0.000), tot_loss_proj:1.456 [t=0.28s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a ticket return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 88.639 | p: 88.454 | r: 88.909
rouge2     | fm: 55.626 | p: 55.485 | r: 55.825
rougeL     | fm: 76.779 | p: 76.580 | r: 77.024
rougeLsum  | fm: 76.545 | p: 76.389 | r: 76.825
r1fm+r2fm = 144.265

input #63 time: 0:11:04 | total time: 10:46:02


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
*********************************
*********************************
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 1.8793610334396362 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 1.8335012197494507 for ['[CLS]bled independence clearing [SEP]']
[Init] best rec loss: 1.8333404064178467 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 1.414121150970459 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 1.4084160327911377 for ['[CLS] spends adrian mating [SEP]']
[Init] best rec loss: 1.1607979536056519 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 1.154465675354004 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 1.1528769731521606 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.974 (perp=8.653, rec=0.230, cos=0.013), tot_loss_proj:2.060 [t=0.28s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.886 (perp=8.653, rec=0.152, cos=0.003), tot_loss_proj:2.068 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.884 (perp=8.653, rec=0.151, cos=0.003), tot_loss_proj:2.062 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=2.065 (perp=9.634, rec=0.133, cos=0.005), tot_loss_proj:2.548 [t=0.26s]
prediction: ['[CLS] strange horror strange [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.947 (perp=9.190, rec=0.106, cos=0.003), tot_loss_proj:2.221 [t=0.25s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.701 (perp=8.065, rec=0.087, cos=0.001), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.001), tot_loss_proj:1.717 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.001), tot_loss_proj:1.700 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.680 (perp=8.065, rec=0.067, cos=0.000), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.682 (perp=8.065, rec=0.068, cos=0.000), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.682 (perp=8.065, rec=0.068, cos=0.000), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.000), tot_loss_proj:1.696 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.673 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.674 (perp=8.065, rec=0.061, cos=0.000), tot_loss_proj:1.699 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.679 (perp=8.065, rec=0.066, cos=0.000), tot_loss_proj:1.699 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.666 (perp=8.065, rec=0.053, cos=0.000), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.000), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.000), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.666 (perp=8.065, rec=0.053, cos=0.000), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.663 (perp=8.065, rec=0.050, cos=0.000), tot_loss_proj:1.709 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.677 (perp=8.065, rec=0.064, cos=0.000), tot_loss_proj:1.713 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.677 (perp=8.065, rec=0.063, cos=0.000), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.000), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.000), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.000), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.000), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.000), tot_loss_proj:1.710 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.669 (perp=8.065, rec=0.056, cos=0.000), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.664 (perp=8.065, rec=0.050, cos=0.000), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.680 (perp=8.065, rec=0.067, cos=0.000), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.000), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.677 (perp=8.065, rec=0.063, cos=0.000), tot_loss_proj:1.708 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.667 (perp=8.065, rec=0.054, cos=0.000), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.674 (perp=8.065, rec=0.061, cos=0.000), tot_loss_proj:1.709 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.673 (perp=8.065, rec=0.059, cos=0.000), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.000), tot_loss_proj:1.710 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.670 (perp=8.065, rec=0.057, cos=0.000), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.000), tot_loss_proj:1.707 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.065, rec=0.064, cos=0.000), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.914 | p: 88.741 | r: 89.230
rouge2     | fm: 56.563 | p: 56.418 | r: 56.736
rougeL     | fm: 76.889 | p: 76.728 | r: 77.188
rougeLsum  | fm: 77.085 | p: 76.930 | r: 77.367
r1fm+r2fm = 145.477

input #64 time: 0:11:00 | total time: 10:57:03


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
*********************************
*********************************
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.9480024576187134 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 1.935711145401001 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 1.9066228866577148 for ['[CLS] stable bourne writers sp here plays spell keeping another [SEP]']
[Init] best rec loss: 1.7932060956954956 for ['[CLS] boss sucks goodbye poorlyions palestinianquest languagecliff [SEP]']
[Init] best rec loss: 1.7819745540618896 for ['[CLS] butter memorandumece happy cry laurence cum york accept [SEP]']
[Init] best rec loss: 1.7478106021881104 for ['[CLS] forth drag roger choice rival familiar howellacingbies [SEP]']
[Init] best rec loss: 1.7460284233093262 for ['[CLS] tobago resist clinched industryementga team rim cancer [SEP]']
[Init] best rec loss: 1.6370292901992798 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best rec loss: 1.5800213813781738 for ['[CLS] dreamed common evbell infantry soon duel paradise birds [SEP]']
[Init] best perm rec loss: 1.579031229019165 for ['[CLS] birds duel paradise dreamed ev infantry soonbell common [SEP]']
[Init] best perm rec loss: 1.5777679681777954 for ['[CLS] duel birds dreamed infantrybell soon ev paradise common [SEP]']
[Init] best perm rec loss: 1.57088303565979 for ['[CLS] birds commonbell infantry duel dreamed ev paradise soon [SEP]']
[Init] best perm rec loss: 1.5680181980133057 for ['[CLS] dreamed paradise duel common evbell infantry soon birds [SEP]']
[Init] best perm rec loss: 1.5678985118865967 for ['[CLS]bell common paradise dreamed birds duel infantry ev soon [SEP]']
[Init] best perm rec loss: 1.5646346807479858 for ['[CLS] birds duel dreamed infantry evbell common soon paradise [SEP]']
[Init] best perm rec loss: 1.563547968864441 for ['[CLS] dreamed duel paradise common birds evbell infantry soon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.337 (perp=9.928, rec=0.346, cos=0.005), tot_loss_proj:2.637 [t=0.27s]
prediction: ['[CLS] joy beautiful joy joy inhabitants red joy joy and [SEP]']
[ 100/2000] tot_loss=2.523 (perp=11.333, rec=0.246, cos=0.010), tot_loss_proj:3.084 [t=0.25s]
prediction: ['[CLS] joy joyed ;. rom rom joy joy [SEP]']
[ 150/2000] tot_loss=2.182 (perp=10.126, rec=0.155, cos=0.002), tot_loss_proj:3.081 [t=0.26s]
prediction: ['[CLS] film joyous ;, rom rom rom joy [SEP]']
[ 200/2000] tot_loss=2.017 (perp=9.449, rec=0.125, cos=0.002), tot_loss_proj:2.957 [t=0.26s]
prediction: ['[CLS] film joyous., rom rom rom joy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.325 (perp=6.142, rec=0.095, cos=0.001), tot_loss_proj:1.632 [t=0.26s]
prediction: ['[CLS] film joyous., a romp, [SEP]']
[ 300/2000] tot_loss=1.373 (perp=6.473, rec=0.077, cos=0.001), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS] film joyous., a romp of [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.373 (perp=6.473, rec=0.077, cos=0.001), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] film joyous., a romp of [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.353 (perp=6.409, rec=0.071, cos=0.001), tot_loss_proj:1.835 [t=0.25s]
prediction: ['[CLS] of joyous., a romp film [SEP]']
[ 450/2000] tot_loss=1.360 (perp=6.409, rec=0.078, cos=0.001), tot_loss_proj:1.841 [t=0.26s]
prediction: ['[CLS] of joyous., a romp film [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.150 (perp=5.313, rec=0.086, cos=0.001), tot_loss_proj:1.615 [t=0.25s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.136 (perp=5.313, rec=0.072, cos=0.001), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[ 600/2000] tot_loss=1.130 (perp=5.313, rec=0.066, cos=0.001), tot_loss_proj:1.619 [t=0.29s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.150 (perp=5.313, rec=0.086, cos=0.001), tot_loss_proj:1.617 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.126 (perp=5.313, rec=0.062, cos=0.001), tot_loss_proj:1.617 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[ 750/2000] tot_loss=1.136 (perp=5.313, rec=0.073, cos=0.001), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.135 (perp=5.313, rec=0.072, cos=0.001), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.139 (perp=5.313, rec=0.075, cos=0.001), tot_loss_proj:1.620 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[ 900/2000] tot_loss=1.140 (perp=5.313, rec=0.076, cos=0.001), tot_loss_proj:1.630 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.129 (perp=5.313, rec=0.066, cos=0.001), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.128 (perp=5.313, rec=0.065, cos=0.001), tot_loss_proj:1.628 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1050/2000] tot_loss=1.139 (perp=5.313, rec=0.076, cos=0.001), tot_loss_proj:1.626 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.143 (perp=5.313, rec=0.080, cos=0.001), tot_loss_proj:1.627 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.128 (perp=5.313, rec=0.065, cos=0.001), tot_loss_proj:1.630 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1200/2000] tot_loss=1.140 (perp=5.313, rec=0.076, cos=0.001), tot_loss_proj:1.629 [t=0.29s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.147 (perp=5.313, rec=0.084, cos=0.001), tot_loss_proj:1.630 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.136 (perp=5.313, rec=0.073, cos=0.001), tot_loss_proj:1.628 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1350/2000] tot_loss=1.137 (perp=5.313, rec=0.074, cos=0.001), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.149 (perp=5.313, rec=0.086, cos=0.001), tot_loss_proj:1.628 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.135 (perp=5.313, rec=0.071, cos=0.001), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1500/2000] tot_loss=1.139 (perp=5.313, rec=0.075, cos=0.001), tot_loss_proj:1.632 [t=0.28s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.139 (perp=5.313, rec=0.075, cos=0.001), tot_loss_proj:1.632 [t=0.29s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.136 (perp=5.313, rec=0.073, cos=0.001), tot_loss_proj:1.639 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1650/2000] tot_loss=1.135 (perp=5.313, rec=0.071, cos=0.001), tot_loss_proj:1.629 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.129 (perp=5.313, rec=0.066, cos=0.001), tot_loss_proj:1.629 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.142 (perp=5.313, rec=0.079, cos=0.001), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1800/2000] tot_loss=1.134 (perp=5.313, rec=0.071, cos=0.001), tot_loss_proj:1.633 [t=0.29s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.124 (perp=5.313, rec=0.061, cos=0.001), tot_loss_proj:1.630 [t=0.29s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.140 (perp=5.313, rec=0.076, cos=0.001), tot_loss_proj:1.635 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
[1950/2000] tot_loss=1.131 (perp=5.313, rec=0.068, cos=0.001), tot_loss_proj:1.631 [t=0.29s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.133 (perp=5.313, rec=0.069, cos=0.001), tot_loss_proj:1.636 [t=0.27s]
prediction: ['[CLS] of joyous, a romp film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] of joyous, a romp film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 116.667

[Aggregate metrics]:
rouge1     | fm: 89.112 | p: 89.007 | r: 89.359
rouge2     | fm: 55.992 | p: 55.850 | r: 56.224
rougeL     | fm: 76.892 | p: 76.820 | r: 77.176
rougeLsum  | fm: 76.989 | p: 76.828 | r: 77.270
r1fm+r2fm = 145.104

input #65 time: 0:11:10 | total time: 11:08:13


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
*********************************
*********************************
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 1.9587653875350952 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 1.838042974472046 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 1.8294860124588013 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 1.8049302101135254 for ['[CLS] school divisional labor liberals [SEP]']
[Init] best rec loss: 1.6972644329071045 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 1.5281866788864136 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 1.4521524906158447 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 1.2160919904708862 for ['[CLS] finish eachensis clark [SEP]']
[Init] best perm rec loss: 1.2056833505630493 for ['[CLS] each clarkensis finish [SEP]']
[Init] best perm rec loss: 1.2052438259124756 for ['[CLS]ensis each clark finish [SEP]']
[Init] best perm rec loss: 1.202699899673462 for ['[CLS]ensis clark each finish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.601 (perp=11.130, rec=0.365, cos=0.010), tot_loss_proj:3.005 [t=0.26s]
prediction: ['[CLS] fans fan fan positively [SEP]']
[ 100/2000] tot_loss=2.099 (perp=9.682, rec=0.160, cos=0.003), tot_loss_proj:3.973 [t=0.27s]
prediction: ['[CLS] longtime tolkien fan heavy [SEP]']
[ 150/2000] tot_loss=2.173 (perp=10.314, rec=0.109, cos=0.002), tot_loss_proj:2.536 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan longtime [SEP]']
[ 200/2000] tot_loss=2.159 (perp=10.314, rec=0.096, cos=0.001), tot_loss_proj:2.536 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan longtime [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.836 (perp=8.772, rec=0.080, cos=0.001), tot_loss_proj:1.988 [t=0.26s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.823 (perp=8.772, rec=0.068, cos=0.001), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.935 (perp=9.355, rec=0.064, cos=0.001), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.001), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.590 (perp=7.673, rec=0.055, cos=0.001), tot_loss_proj:1.607 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.595 (perp=7.673, rec=0.060, cos=0.001), tot_loss_proj:1.605 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.608 (perp=7.673, rec=0.073, cos=0.001), tot_loss_proj:1.607 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.584 (perp=7.673, rec=0.049, cos=0.001), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.599 (perp=7.673, rec=0.064, cos=0.001), tot_loss_proj:1.592 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.605 (perp=7.673, rec=0.070, cos=0.001), tot_loss_proj:1.602 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.001), tot_loss_proj:1.597 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.588 (perp=7.673, rec=0.053, cos=0.001), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.586 (perp=7.673, rec=0.050, cos=0.001), tot_loss_proj:1.602 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.001), tot_loss_proj:1.601 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.592 (perp=7.673, rec=0.057, cos=0.001), tot_loss_proj:1.606 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.001), tot_loss_proj:1.612 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.578 (perp=7.673, rec=0.043, cos=0.001), tot_loss_proj:1.607 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.001), tot_loss_proj:1.596 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.592 (perp=7.673, rec=0.057, cos=0.001), tot_loss_proj:1.601 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.001), tot_loss_proj:1.598 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.604 (perp=7.673, rec=0.069, cos=0.001), tot_loss_proj:1.599 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.587 (perp=7.673, rec=0.052, cos=0.001), tot_loss_proj:1.597 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.598 (perp=7.673, rec=0.063, cos=0.001), tot_loss_proj:1.593 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.673, rec=0.063, cos=0.001), tot_loss_proj:1.591 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.609 (perp=7.673, rec=0.073, cos=0.001), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.001), tot_loss_proj:1.601 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.599 (perp=7.673, rec=0.064, cos=0.001), tot_loss_proj:1.612 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.001), tot_loss_proj:1.593 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.001), tot_loss_proj:1.602 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.603 (perp=7.673, rec=0.068, cos=0.001), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=7.673, rec=0.066, cos=0.001), tot_loss_proj:1.603 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.590 (perp=7.673, rec=0.055, cos=0.001), tot_loss_proj:1.595 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.001), tot_loss_proj:1.613 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.584 (perp=7.673, rec=0.049, cos=0.001), tot_loss_proj:1.599 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.001), tot_loss_proj:1.602 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.001), tot_loss_proj:1.595 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.260 | p: 89.124 | r: 89.522
rouge2     | fm: 56.703 | p: 56.583 | r: 56.859
rougeL     | fm: 77.185 | p: 77.016 | r: 77.457
rougeLsum  | fm: 77.325 | p: 77.104 | r: 77.593
r1fm+r2fm = 145.963

input #66 time: 0:10:56 | total time: 11:19:10


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
*********************************
*********************************
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.834237813949585 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 1.7785722017288208 for ['[CLS] ^ banksgger biology mont neck administration action pool neo [SEP]']
[Init] best rec loss: 1.7256571054458618 for ['[CLS] mortonructured hendricks partial banned time jae published leave psalm [SEP]']
[Init] best rec loss: 1.69612717628479 for ['[CLS] practically squadron pacific cheated rick under countryorð⁄₄ [SEP]']
[Init] best rec loss: 1.6957756280899048 for ['[CLS]lusionunt sign utah america zeppelin light katy outbreak betray [SEP]']
[Init] best rec loss: 1.6956020593643188 for ['[CLS] [ script part song log principal custom enlisted cabinet charged [SEP]']
[Init] best rec loss: 1.676373839378357 for ['[CLS] marcus cause rudder straight mustered ordinary competitive population getting believe [SEP]']
[Init] best rec loss: 1.6748206615447998 for ['[CLS] vessel definitearound attendant visionrained league nearest sets nut [SEP]']
[Init] best perm rec loss: 1.6736490726470947 for ['[CLS]around nut definiterained vessel league vision attendant nearest sets [SEP]']
[Init] best perm rec loss: 1.6704751253128052 for ['[CLS]around nearestrained definite attendant sets league vision nut vessel [SEP]']
[Init] best perm rec loss: 1.6678307056427002 for ['[CLS] leaguearound vesselrained attendant sets nearest vision definite nut [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.686 (perp=14.808, rec=0.719, cos=0.006), tot_loss_proj:4.500 [t=0.25s]
prediction: ['[CLS] championship combatshed stale dim prescribed rather snow reluctantly level [SEP]']
[ 100/2000] tot_loss=3.273 (perp=13.222, rec=0.619, cos=0.010), tot_loss_proj:4.527 [t=0.27s]
prediction: ['[CLS] festival combatshed someone kind determined wrath cabin less brady [SEP]']
[ 150/2000] tot_loss=3.164 (perp=12.808, rec=0.599, cos=0.003), tot_loss_proj:4.535 [t=0.26s]
prediction: ['[CLS] festival combatshed someone kind transferred wrath kind frank brady [SEP]']
[ 200/2000] tot_loss=3.007 (perp=12.046, rec=0.590, cos=0.007), tot_loss_proj:4.436 [t=0.27s]
prediction: ['[CLS]war combatwar someone kindph wrath kindburg brady [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.218 (perp=13.271, rec=0.559, cos=0.005), tot_loss_proj:4.574 [t=0.25s]
prediction: ['[CLS]warμwarang kindph wrath kindburg brady [SEP]']
[ 300/2000] tot_loss=3.266 (perp=13.683, rec=0.526, cos=0.004), tot_loss_proj:4.646 [t=0.26s]
prediction: ['[CLS]warμwarang kind orientation wrath kindburg brady [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.324 (perp=13.971, rec=0.522, cos=0.007), tot_loss_proj:4.568 [t=0.28s]
prediction: ['[CLS]wargmwarang orientation wrath kindable kind brady [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.285 (perp=13.602, rec=0.561, cos=0.003), tot_loss_proj:4.544 [t=0.25s]
prediction: ['[CLS] hearwarang orientation promptly kind racecourseur kind brady [SEP]']
[ 450/2000] tot_loss=3.128 (perp=13.019, rec=0.522, cos=0.002), tot_loss_proj:4.525 [t=0.25s]
prediction: ['[CLS] hearwarang non wrath kind racecourseur kind brady [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.003 (perp=12.402, rec=0.511, cos=0.011), tot_loss_proj:4.420 [t=0.25s]
prediction: ['[CLS] hear kindang non promptly kind nonurwar brady [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.814 (perp=11.547, rec=0.503, cos=0.002), tot_loss_proj:4.168 [t=0.26s]
prediction: ['[CLS] hear kind non promptly kindang nonurwar brady [SEP]']
[ 600/2000] tot_loss=2.809 (perp=11.547, rec=0.498, cos=0.002), tot_loss_proj:4.172 [t=0.25s]
prediction: ['[CLS] hear kind non promptly kindang nonurwar brady [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.628 (perp=10.686, rec=0.490, cos=0.000), tot_loss_proj:3.942 [t=0.26s]
prediction: ['[CLS] non kind non promptly kindang hearurwar brady [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.584 (perp=10.469, rec=0.488, cos=0.002), tot_loss_proj:3.940 [t=0.25s]
prediction: ['[CLS] kind non non promptly kindang hearurwar brady [SEP]']
[ 750/2000] tot_loss=2.565 (perp=10.469, rec=0.470, cos=0.001), tot_loss_proj:3.936 [t=0.26s]
prediction: ['[CLS] kind non non promptly kindang hearurwar brady [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.565 (perp=10.469, rec=0.471, cos=0.000), tot_loss_proj:3.935 [t=0.29s]
prediction: ['[CLS] kind non non promptly kindang hearurwar brady [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.567 (perp=10.469, rec=0.471, cos=0.002), tot_loss_proj:3.941 [t=0.27s]
prediction: ['[CLS] kind non non promptly kindang hearurwar brady [SEP]']
[ 900/2000] tot_loss=2.560 (perp=10.469, rec=0.466, cos=0.000), tot_loss_proj:3.933 [t=0.27s]
prediction: ['[CLS] kind non non promptly kindang hearurwar brady [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.703 (perp=11.222, rec=0.458, cos=0.000), tot_loss_proj:4.077 [t=0.28s]
prediction: ['[CLS] kind non non promptly kindang hearurwar faux [SEP]']
Attempt swap
[1000/2000] tot_loss=2.700 (perp=11.222, rec=0.455, cos=0.001), tot_loss_proj:4.073 [t=0.28s]
prediction: ['[CLS] kind non non promptly kindang hearurwar faux [SEP]']
[1050/2000] tot_loss=2.694 (perp=11.222, rec=0.449, cos=0.000), tot_loss_proj:4.072 [t=0.28s]
prediction: ['[CLS] kind non non promptly kindang hearurwar faux [SEP]']
Attempt swap
[1100/2000] tot_loss=2.775 (perp=11.592, rec=0.456, cos=0.001), tot_loss_proj:4.179 [t=0.28s]
prediction: ['[CLS] kind non non promptly kindangwarurwar faux [SEP]']
Attempt swap
[1150/2000] tot_loss=2.770 (perp=11.592, rec=0.452, cos=0.001), tot_loss_proj:4.185 [t=0.24s]
prediction: ['[CLS] kind non non promptly kindangwarurwar faux [SEP]']
[1200/2000] tot_loss=2.778 (perp=11.592, rec=0.458, cos=0.002), tot_loss_proj:4.184 [t=0.25s]
prediction: ['[CLS] kind non non promptly kindangwarurwar faux [SEP]']
Attempt swap
[1250/2000] tot_loss=2.762 (perp=11.592, rec=0.443, cos=0.000), tot_loss_proj:4.186 [t=0.26s]
prediction: ['[CLS] kind non non promptly kindangwarurwar faux [SEP]']
Attempt swap
[1300/2000] tot_loss=3.180 (perp=13.649, rec=0.450, cos=0.000), tot_loss_proj:4.530 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
[1350/2000] tot_loss=3.180 (perp=13.649, rec=0.444, cos=0.006), tot_loss_proj:4.531 [t=0.29s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1400/2000] tot_loss=3.176 (perp=13.649, rec=0.446, cos=0.000), tot_loss_proj:4.529 [t=0.28s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1450/2000] tot_loss=3.176 (perp=13.649, rec=0.446, cos=0.000), tot_loss_proj:4.532 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
[1500/2000] tot_loss=3.173 (perp=13.649, rec=0.443, cos=0.000), tot_loss_proj:4.532 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1550/2000] tot_loss=3.181 (perp=13.649, rec=0.451, cos=0.000), tot_loss_proj:4.530 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1600/2000] tot_loss=3.174 (perp=13.649, rec=0.444, cos=0.000), tot_loss_proj:4.527 [t=0.26s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
[1650/2000] tot_loss=3.164 (perp=13.649, rec=0.434, cos=0.000), tot_loss_proj:4.532 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1700/2000] tot_loss=3.176 (perp=13.649, rec=0.447, cos=0.000), tot_loss_proj:4.530 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1750/2000] tot_loss=3.167 (perp=13.649, rec=0.438, cos=0.000), tot_loss_proj:4.530 [t=0.28s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
[1800/2000] tot_loss=3.174 (perp=13.649, rec=0.445, cos=0.000), tot_loss_proj:4.530 [t=0.28s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1850/2000] tot_loss=3.174 (perp=13.649, rec=0.444, cos=0.000), tot_loss_proj:4.528 [t=0.25s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[1900/2000] tot_loss=3.174 (perp=13.649, rec=0.444, cos=0.000), tot_loss_proj:4.530 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
[1950/2000] tot_loss=3.171 (perp=13.649, rec=0.441, cos=0.000), tot_loss_proj:4.533 [t=0.26s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Attempt swap
[2000/2000] tot_loss=3.173 (perp=13.649, rec=0.443, cos=0.000), tot_loss_proj:4.531 [t=0.27s]
prediction: ['[CLS] kind non non promptlyentalangwarentalwar faux [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind non non promptlyentalangwarentalwar faux [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 42.857 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 42.857 | r: 60.000
rougeLsum  | fm: 50.000 | p: 42.857 | r: 60.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 88.704 | p: 88.472 | r: 89.076
rouge2     | fm: 55.732 | p: 55.661 | r: 55.902
rougeL     | fm: 76.854 | p: 76.615 | r: 77.237
rougeLsum  | fm: 76.807 | p: 76.616 | r: 77.197
r1fm+r2fm = 144.436

input #67 time: 0:11:06 | total time: 11:30:17


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
*********************************
*********************************
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 1.9883288145065308 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 1.9612467288970947 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 1.6541982889175415 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 1.6288515329360962 for ['[CLS] °f force recreationalyde fighting extras who livestock guaranteed singles short gloves kitchen [SEP]']
[Init] best rec loss: 1.6066203117370605 for ['[CLS] collecting congresses hundred slightest summit survive [CLS] although fred diego fantastic relief? [SEP]']
[Init] best rec loss: 1.5576926469802856 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 1.459212064743042 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 1.1719552278518677 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 1.1586320400238037 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 1.1505303382873535 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 1.1384704113006592 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 1.1313153505325317 for ['[CLS]iferous beth died form. floor councils riding medalyn view possibly comfort [SEP]']
[Init] best perm rec loss: 1.1300716400146484 for ['[CLS]yniferous comfort beth floor form possibly medal riding view. councils died [SEP]']
[Init] best perm rec loss: 1.1216068267822266 for ['[CLS]yn comfort riding possiblyiferous beth councils form floor medal. view died [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.759 (perp=12.369, rec=0.282, cos=0.003), tot_loss_proj:3.022 [t=0.28s]
prediction: ['[CLS] un preceding system absurd off confront pathetic term presented andsible vicious series [SEP]']
[ 100/2000] tot_loss=2.527 (perp=11.703, rec=0.185, cos=0.001), tot_loss_proj:3.127 [t=0.29s]
prediction: ['[CLS] un absurdcent absurd un absurd festivalited presented andsible vicioussible [SEP]']
[ 150/2000] tot_loss=2.487 (perp=11.637, rec=0.154, cos=0.005), tot_loss_proj:3.127 [t=0.25s]
prediction: ['[CLS] unsibleuth absurd un absurd festivalck leaving,sible vicioussible [SEP]']
[ 200/2000] tot_loss=2.251 (perp=10.611, rec=0.129, cos=0.000), tot_loss_proj:2.757 [t=0.26s]
prediction: ['[CLS] unsibleuth absurd un absurd plus, because andsible viciousco [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.114 (perp=9.792, rec=0.154, cos=0.002), tot_loss_proj:2.623 [t=0.25s]
prediction: ['[CLS] unhensibleuth absurd absurd plus, because andsible viciousco [SEP]']
[ 300/2000] tot_loss=2.077 (perp=9.792, rec=0.119, cos=0.001), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] unhensibleuth absurd absurd plus, because andsible viciousco [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.030 (perp=9.575, rec=0.115, cos=0.001), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] unhensibleuth absurd absurdst, becausesible and viciousco [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.071 (perp=9.708, rec=0.129, cos=0.001), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] unhencouth absurduthst,bysible and vicioussible [SEP]']
[ 450/2000] tot_loss=2.078 (perp=9.864, rec=0.105, cos=0.001), tot_loss_proj:2.465 [t=0.25s]
prediction: ['[CLS] unhencouth absurduthst,eedsible and vicioussible [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.231 (perp=10.644, rec=0.102, cos=0.001), tot_loss_proj:2.624 [t=0.34s]
prediction: ['[CLS] uncouth absurduthst,eedhen inc and vicioussible [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.960 (perp=9.288, rec=0.102, cos=0.001), tot_loss_proj:2.255 [t=0.26s]
prediction: ['[CLS] uncouth absurduthomp,omphensible and vicious inc [SEP]']
[ 600/2000] tot_loss=1.943 (perp=9.288, rec=0.084, cos=0.000), tot_loss_proj:2.260 [t=0.26s]
prediction: ['[CLS] uncouth absurduthomp,omphensible and vicious inc [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.678 (perp=7.954, rec=0.087, cos=0.000), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] uncouth absurduthomp, and vicious incomphensible [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.565 (perp=7.338, rec=0.096, cos=0.001), tot_loss_proj:1.825 [t=0.26s]
prediction: ['[CLS] uncouth absurdomputh, and vicious incomphensible [SEP]']
[ 750/2000] tot_loss=1.560 (perp=7.338, rec=0.092, cos=0.000), tot_loss_proj:1.834 [t=0.25s]
prediction: ['[CLS] uncouth absurdomputh, and vicious incomphensible [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.510 (perp=7.123, rec=0.085, cos=0.000), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.504 (perp=7.123, rec=0.079, cos=0.000), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[ 900/2000] tot_loss=1.508 (perp=7.123, rec=0.083, cos=0.000), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.505 (perp=7.123, rec=0.081, cos=0.000), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1000/2000] tot_loss=1.505 (perp=7.123, rec=0.080, cos=0.000), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1050/2000] tot_loss=1.504 (perp=7.123, rec=0.079, cos=0.000), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1100/2000] tot_loss=1.503 (perp=7.123, rec=0.078, cos=0.000), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1150/2000] tot_loss=1.507 (perp=7.123, rec=0.082, cos=0.000), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1200/2000] tot_loss=1.509 (perp=7.123, rec=0.085, cos=0.000), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1250/2000] tot_loss=1.507 (perp=7.123, rec=0.082, cos=0.000), tot_loss_proj:1.687 [t=0.29s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1300/2000] tot_loss=1.499 (perp=7.123, rec=0.074, cos=0.000), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1350/2000] tot_loss=1.506 (perp=7.123, rec=0.081, cos=0.000), tot_loss_proj:1.686 [t=0.27s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1400/2000] tot_loss=1.498 (perp=7.123, rec=0.073, cos=0.000), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1450/2000] tot_loss=1.504 (perp=7.123, rec=0.079, cos=0.000), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.123, rec=0.080, cos=0.000), tot_loss_proj:1.691 [t=0.27s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1550/2000] tot_loss=1.505 (perp=7.123, rec=0.080, cos=0.000), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=7.123, rec=0.079, cos=0.000), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1650/2000] tot_loss=1.508 (perp=7.123, rec=0.083, cos=0.000), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1700/2000] tot_loss=1.499 (perp=7.123, rec=0.074, cos=0.000), tot_loss_proj:1.688 [t=0.27s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.503 (perp=7.123, rec=0.078, cos=0.000), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1800/2000] tot_loss=1.505 (perp=7.123, rec=0.081, cos=0.000), tot_loss_proj:1.691 [t=0.27s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1850/2000] tot_loss=1.496 (perp=7.123, rec=0.071, cos=0.000), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[1900/2000] tot_loss=1.495 (perp=7.123, rec=0.070, cos=0.000), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
[1950/2000] tot_loss=1.496 (perp=7.123, rec=0.071, cos=0.000), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Attempt swap
[2000/2000] tot_loss=1.497 (perp=7.123, rec=0.072, cos=0.000), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouthomputh, absurd and vicious incomphensible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 71.429

[Aggregate metrics]:
rouge1     | fm: 88.347 | p: 88.213 | r: 88.723
rouge2     | fm: 54.905 | p: 54.796 | r: 55.101
rougeL     | fm: 76.324 | p: 76.089 | r: 76.745
rougeLsum  | fm: 76.364 | p: 76.139 | r: 76.723
r1fm+r2fm = 143.253

input #68 time: 0:11:02 | total time: 11:41:20


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
*********************************
*********************************
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.8529300689697266 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 1.7803916931152344 for ['[CLS] pretty campus department slow behind alias laborphobia really abilityrama sl offices markers schedule maximum [SEP]']
[Init] best rec loss: 1.777809977531433 for ['[CLS] link mark andgi gutierrez exile planwriter bot amateur innings dreaming chestots those watershed [SEP]']
[Init] best rec loss: 1.6611499786376953 for ['[CLS] squadong it code recording why what qualifyingjonpsy bad bound paintings nuclear only panchayat [SEP]']
[Init] best rec loss: 1.5930790901184082 for ["[CLS] wait pale s force'an tyne km honey teaching contemporaryable finn over thanked favourite [SEP]"]
[Init] best perm rec loss: 1.5880229473114014 for ["[CLS] finn teaching honey s contemporary thanked favourite over wait km an force tyneable'pale [SEP]"]
[Init] best perm rec loss: 1.587775468826294 for ["[CLS]'thanked finn favourite contemporary pale teaching wait km an s over tyne honeyable force [SEP]"]
[Init] best perm rec loss: 1.585741400718689 for ["[CLS] over honey contemporary s favourite thanked tyne km finn pale'force teaching waitable an [SEP]"]
[Init] best perm rec loss: 1.5847747325897217 for ["[CLS] honey forceable s pale an teaching contemporary km finn thanked favourite over wait'tyne [SEP]"]
[Init] best perm rec loss: 1.5815293788909912 for ["[CLS] thanked s tyne favourite'pale teaching km finn contemporary force anable honey over wait [SEP]"]
[Init] best perm rec loss: 1.58074951171875 for ["[CLS] pale s over teaching km thanked favourite'finn tyne forceable honey wait contemporary an [SEP]"]
[Init] best perm rec loss: 1.5794026851654053 for ["[CLS] tyneable s wait favourite pale finn force contemporary thanked over km'teaching honey an [SEP]"]
[Init] best perm rec loss: 1.5793405771255493 for ["[CLS] over honey contemporary tyne teaching favourite finn sable force'an wait km pale thanked [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.250 (perp=12.441, rec=0.747, cos=0.015), tot_loss_proj:4.019 [t=0.27s]
prediction: ['[CLS] or lawsuits any offended of against terrorist " losing picture dull unconstitutional talk maddox plate kitchen [SEP]']
[ 100/2000] tot_loss=2.914 (perp=11.464, rec=0.610, cos=0.011), tot_loss_proj:3.848 [t=0.27s]
prediction: ['[CLS] or her ourus of againstvere " losing phone dull dead talk grimes? nobody [SEP]']
[ 150/2000] tot_loss=2.744 (perp=10.831, rec=0.566, cos=0.012), tot_loss_proj:3.779 [t=0.25s]
prediction: ['[CLS] or herslus of against contributed " stolen phone? dead whose grimestish nobody [SEP]']
[ 200/2000] tot_loss=2.887 (perp=11.521, rec=0.544, cos=0.039), tot_loss_proj:4.163 [t=0.26s]
prediction: ['[CLS] or herslus of against contributed ", vinci without dead anything grimes smart nobody [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.735 (perp=11.132, rec=0.504, cos=0.004), tot_loss_proj:4.129 [t=0.26s]
prediction: ['[CLS] against consl or of or guilty ", obviously without dead whose grimes smart nobody [SEP]']
[ 300/2000] tot_loss=2.522 (perp=9.995, rec=0.511, cos=0.012), tot_loss_proj:3.975 [t=0.29s]
prediction: ['[CLS] against consl or of or guilty ", obviously without dead anything ; criminal nobody [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.567 (perp=10.370, rec=0.480, cos=0.013), tot_loss_proj:4.135 [t=0.27s]
prediction: ['[CLS] prize hellsl like of, guilty,, obviously without tax analysis ; smart tho [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.413 (perp=9.761, rec=0.457, cos=0.004), tot_loss_proj:3.901 [t=0.26s]
prediction: ['[CLS] prize hellsl. of, guilty, obviously, without hairy analysis ; smart tho [SEP]']
[ 450/2000] tot_loss=2.282 (perp=9.206, rec=0.439, cos=0.002), tot_loss_proj:3.827 [t=0.26s]
prediction: ['[CLS] prize hellsl. of, guilty, obviously, without smart analysis ; smart tho [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.460 (perp=10.135, rec=0.428, cos=0.005), tot_loss_proj:3.912 [t=0.26s]
prediction: ['[CLS] prize hell edo character terrorists of,, obviously, without smart analysis ; smart tho [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.429 (perp=9.961, rec=0.434, cos=0.003), tot_loss_proj:3.898 [t=0.27s]
prediction: ['[CLS] prize hell edo. of creative, - obviously, without smart analysis ; norris tho [SEP]']
[ 600/2000] tot_loss=2.448 (perp=10.182, rec=0.410, cos=0.002), tot_loss_proj:4.042 [t=0.26s]
prediction: ['[CLS] winner hell edo character of creative, - obviously, without smart analysis ; smart tho [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.308 (perp=9.472, rec=0.412, cos=0.001), tot_loss_proj:3.949 [t=0.26s]
prediction: ['[CLS], hell edo character of creative winner - obviously, without smart, ; smart hairy [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.372 (perp=9.814, rec=0.407, cos=0.002), tot_loss_proj:3.587 [t=0.27s]
prediction: ['[CLS], hell edo character of creative winner - obviously, without criteria hairy ; smart hundreds [SEP]']
[ 750/2000] tot_loss=2.194 (perp=8.947, rec=0.403, cos=0.002), tot_loss_proj:3.808 [t=0.28s]
prediction: ['[CLS], hell edo character of creative winner - obviously, without, smart ; smart hundreds [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.177 (perp=8.877, rec=0.397, cos=0.004), tot_loss_proj:3.725 [t=0.29s]
prediction: ['[CLS] of hell edo character, creative winner - obviously, without, smart - smart hundreds [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.231 (perp=9.168, rec=0.394, cos=0.003), tot_loss_proj:3.750 [t=0.28s]
prediction: ['[CLS] - hell edo character, creative winner - smart, without, unreasonable - smart hundreds [SEP]']
[ 900/2000] tot_loss=2.308 (perp=9.265, rec=0.442, cos=0.013), tot_loss_proj:3.686 [t=0.26s]
prediction: ['[CLS] of hell edo immediately, creative winner - smart, without, unreasonable - smart hundreds [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.223 (perp=9.166, rec=0.390, cos=0.000), tot_loss_proj:3.803 [t=0.29s]
prediction: ['[CLS] - hell character edo, creative winner - smart, without, unreasonable - smart hundreds [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.341 (perp=9.763, rec=0.386, cos=0.002), tot_loss_proj:3.433 [t=0.24s]
prediction: ['[CLS] - hell, character edo creative winner - smart, without chronological unreasonable - funny hundreds [SEP]']
[1050/2000] tot_loss=2.241 (perp=9.301, rec=0.380, cos=0.000), tot_loss_proj:3.688 [t=0.25s]
prediction: ['[CLS] - hell, character edo creative winner - smart, without, unreasonable - funny hundreds [SEP]']
Attempt swap
[1100/2000] tot_loss=2.250 (perp=9.301, rec=0.383, cos=0.007), tot_loss_proj:3.689 [t=0.25s]
prediction: ['[CLS] - hell, character edo creative winner - smart, without, unreasonable - funny hundreds [SEP]']
Attempt swap
[1150/2000] tot_loss=2.247 (perp=9.301, rec=0.376, cos=0.011), tot_loss_proj:3.687 [t=0.26s]
prediction: ['[CLS] - hell, character edo creative winner - smart, without, unreasonable - funny hundreds [SEP]']
[1200/2000] tot_loss=1.982 (perp=8.019, rec=0.374, cos=0.004), tot_loss_proj:3.565 [t=0.25s]
prediction: ['[CLS] - hell, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1250/2000] tot_loss=2.235 (perp=9.301, rec=0.374, cos=0.001), tot_loss_proj:3.689 [t=0.27s]
prediction: ['[CLS] - hell, character edo creative winner - smart, without, unreasonable - funny hundreds [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=8.019, rec=0.370, cos=0.001), tot_loss_proj:3.561 [t=0.26s]
prediction: ['[CLS] - hell, character and creative winner - smart, without, because - funny hundreds [SEP]']
[1350/2000] tot_loss=1.975 (perp=8.019, rec=0.371, cos=0.000), tot_loss_proj:3.561 [t=0.25s]
prediction: ['[CLS] - hell, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1400/2000] tot_loss=2.018 (perp=8.251, rec=0.367, cos=0.000), tot_loss_proj:3.557 [t=0.26s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1450/2000] tot_loss=2.019 (perp=8.251, rec=0.368, cos=0.000), tot_loss_proj:3.554 [t=0.27s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
[1500/2000] tot_loss=2.018 (perp=8.251, rec=0.367, cos=0.000), tot_loss_proj:3.561 [t=0.26s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1550/2000] tot_loss=2.022 (perp=8.251, rec=0.369, cos=0.002), tot_loss_proj:3.555 [t=0.27s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1600/2000] tot_loss=2.011 (perp=8.251, rec=0.361, cos=0.000), tot_loss_proj:3.554 [t=0.27s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
[1650/2000] tot_loss=2.016 (perp=8.251, rec=0.362, cos=0.004), tot_loss_proj:3.552 [t=0.25s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1700/2000] tot_loss=2.013 (perp=8.251, rec=0.362, cos=0.001), tot_loss_proj:3.559 [t=0.26s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1750/2000] tot_loss=2.023 (perp=8.251, rec=0.371, cos=0.001), tot_loss_proj:3.552 [t=0.27s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
[1800/2000] tot_loss=2.013 (perp=8.251, rec=0.362, cos=0.001), tot_loss_proj:3.555 [t=0.25s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1850/2000] tot_loss=2.011 (perp=8.251, rec=0.360, cos=0.001), tot_loss_proj:3.555 [t=0.26s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[1900/2000] tot_loss=2.012 (perp=8.251, rec=0.362, cos=0.000), tot_loss_proj:3.555 [t=0.27s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
[1950/2000] tot_loss=2.018 (perp=8.251, rec=0.368, cos=0.000), tot_loss_proj:3.553 [t=0.26s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Attempt swap
[2000/2000] tot_loss=2.020 (perp=8.251, rec=0.369, cos=0.001), tot_loss_proj:3.555 [t=0.26s]
prediction: ['[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] - ins, character and creative winner - smart, without, because - funny hundreds [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 50.000 | r: 60.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 45.455 | p: 41.667 | r: 50.000
rougeLsum  | fm: 45.455 | p: 41.667 | r: 50.000
r1fm+r2fm = 64.545

[Aggregate metrics]:
rouge1     | fm: 87.923 | p: 87.648 | r: 88.369
rouge2     | fm: 54.494 | p: 54.367 | r: 54.624
rougeL     | fm: 75.819 | p: 75.564 | r: 76.230
rougeLsum  | fm: 75.866 | p: 75.551 | r: 76.324
r1fm+r2fm = 142.417

input #69 time: 0:11:08 | total time: 11:52:28


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 1.7679567337036133 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 1.536930799484253 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 1.408258080482483 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 1.3998394012451172 for ['[CLS] piano myth casualty immediately vocal right bottle [SEP]']
[Init] best rec loss: 1.2374904155731201 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 1.2105610370635986 for ['[CLS] meg admitthermal success prize debut falcon [SEP]']
[Init] best rec loss: 1.1166847944259644 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 1.1123631000518799 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 1.110944390296936 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 1.1077313423156738 for ['[CLS] muscle িbution party guy modern bob [SEP]']
[Init] best perm rec loss: 1.1058592796325684 for ['[CLS] bob guy modern muscle িbution party [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.268 (perp=9.260, rec=0.397, cos=0.019), tot_loss_proj:2.905 [t=0.26s]
prediction: ['[CLS] load rash. = wreck location weighted [SEP]']
[ 100/2000] tot_loss=2.689 (perp=11.730, rec=0.323, cos=0.020), tot_loss_proj:3.257 [t=0.25s]
prediction: ['[CLS]unk rash is gets crowded screenunk [SEP]']
[ 150/2000] tot_loss=2.696 (perp=12.389, rec=0.213, cos=0.005), tot_loss_proj:3.198 [t=0.25s]
prediction: ['[CLS]unky is gets cl screenunk [SEP]']
[ 200/2000] tot_loss=2.730 (perp=12.886, rec=0.149, cos=0.003), tot_loss_proj:3.512 [t=0.25s]
prediction: ['[CLS]unky on gets cl screenunk [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.951 (perp=8.974, rec=0.154, cos=0.003), tot_loss_proj:2.249 [t=0.26s]
prediction: ['[CLS]unky on screen gets clunk [SEP]']
[ 300/2000] tot_loss=1.903 (perp=8.974, rec=0.107, cos=0.001), tot_loss_proj:2.250 [t=0.25s]
prediction: ['[CLS]unky on screen gets clunk [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.702 (perp=8.058, rec=0.090, cos=0.001), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS]unk on screen gets clunky [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.635 (perp=7.667, rec=0.100, cos=0.001), tot_loss_proj:2.429 [t=0.25s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 450/2000] tot_loss=1.609 (perp=7.667, rec=0.075, cos=0.001), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.609 (perp=7.667, rec=0.075, cos=0.001), tot_loss_proj:2.429 [t=0.25s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.611 (perp=7.667, rec=0.077, cos=0.001), tot_loss_proj:2.431 [t=0.25s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 600/2000] tot_loss=1.605 (perp=7.667, rec=0.071, cos=0.001), tot_loss_proj:2.431 [t=0.25s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.313 (perp=11.186, rec=0.075, cos=0.000), tot_loss_proj:3.628 [t=0.25s]
prediction: ['[CLS] gets on screenunk cl they [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.664 (perp=7.667, rec=0.126, cos=0.004), tot_loss_proj:2.427 [t=0.27s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 750/2000] tot_loss=1.471 (perp=6.858, rec=0.099, cos=0.001), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] gets on screen the clunky [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.369 (perp=6.358, rec=0.097, cos=0.001), tot_loss_proj:2.050 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.353 (perp=6.358, rec=0.081, cos=0.000), tot_loss_proj:2.057 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[ 900/2000] tot_loss=1.349 (perp=6.358, rec=0.077, cos=0.000), tot_loss_proj:2.047 [t=0.27s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.356 (perp=6.358, rec=0.084, cos=0.000), tot_loss_proj:2.054 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.356 (perp=6.358, rec=0.084, cos=0.000), tot_loss_proj:2.048 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1050/2000] tot_loss=1.351 (perp=6.358, rec=0.079, cos=0.000), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.358 (perp=6.358, rec=0.086, cos=0.000), tot_loss_proj:2.045 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.354 (perp=6.358, rec=0.082, cos=0.000), tot_loss_proj:2.057 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1200/2000] tot_loss=1.343 (perp=6.358, rec=0.071, cos=0.000), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.354 (perp=6.358, rec=0.082, cos=0.000), tot_loss_proj:2.049 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.343 (perp=6.358, rec=0.071, cos=0.000), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1350/2000] tot_loss=1.340 (perp=6.358, rec=0.068, cos=0.000), tot_loss_proj:2.053 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.337 (perp=6.358, rec=0.065, cos=0.000), tot_loss_proj:2.051 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.345 (perp=6.358, rec=0.073, cos=0.000), tot_loss_proj:2.055 [t=0.27s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1500/2000] tot_loss=1.347 (perp=6.358, rec=0.075, cos=0.000), tot_loss_proj:2.051 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.346 (perp=6.358, rec=0.074, cos=0.000), tot_loss_proj:2.048 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.350 (perp=6.358, rec=0.078, cos=0.000), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1650/2000] tot_loss=1.348 (perp=6.358, rec=0.076, cos=0.000), tot_loss_proj:2.054 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.344 (perp=6.358, rec=0.072, cos=0.000), tot_loss_proj:2.050 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.349 (perp=6.358, rec=0.077, cos=0.000), tot_loss_proj:2.059 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1800/2000] tot_loss=1.340 (perp=6.358, rec=0.068, cos=0.000), tot_loss_proj:2.047 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.345 (perp=6.358, rec=0.073, cos=0.000), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.351 (perp=6.358, rec=0.079, cos=0.000), tot_loss_proj:2.051 [t=0.27s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1950/2000] tot_loss=1.337 (perp=6.358, rec=0.065, cos=0.000), tot_loss_proj:2.044 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.356 (perp=6.358, rec=0.084, cos=0.000), tot_loss_proj:2.048 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets the screen on clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 88.165 | p: 87.872 | r: 88.577
rouge2     | fm: 53.901 | p: 53.753 | r: 54.059
rougeL     | fm: 75.938 | p: 75.684 | r: 76.339
rougeLsum  | fm: 75.793 | p: 75.514 | r: 76.290
r1fm+r2fm = 142.066

input #70 time: 0:11:02 | total time: 12:03:31


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
*********************************
*********************************
average of cosine similarity 0.9993403548184049
highest_index [0]
highest [0.9993403548184049]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 1.8314898014068604 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 1.6892049312591553 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 1.4518476724624634 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 1.4424015283584595 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 1.4241973161697388 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 1.4165459871292114 for ['[CLS] emptied advertising dominant orange gap mini clothes subsequent history series dakotaminatehab goesu [SEP]']
[Init] best rec loss: 1.3269407749176025 for ['[CLS]gies amir plus locomotive contacthane flat all highest helmet postal operations political blindness colors [SEP]']
[Init] best rec loss: 1.3191274404525757 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 1.3124475479125977 for ['[CLS] ramhear liam bed fall jean fewer professor over creatures queens molly sur marshall of [SEP]']
[Init] best perm rec loss: 1.312007188796997 for ['[CLS] molly liam fewer professor of queens jean creatures sur marshall bed over ram fallhear [SEP]']
[Init] best perm rec loss: 1.3116501569747925 for ['[CLS]hear marshall sur ram of fewer professor liam creatures molly bed over queens fall jean [SEP]']
[Init] best perm rec loss: 1.309478759765625 for ['[CLS] sur jeanhear fall fewer marshall molly liam professor ram queens bed of creatures over [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.810 (perp=11.994, rec=0.405, cos=0.006), tot_loss_proj:3.864 [t=0.27s]
prediction: ["[CLS]station that had t any legislation trouble dinner stryker state a words wanted'over [SEP]"]
[ 100/2000] tot_loss=2.125 (perp=9.184, rec=0.282, cos=0.006), tot_loss_proj:2.914 [t=0.26s]
prediction: ["[CLS] spray there has not your business minute moment'okay a single want moment on [SEP]"]
[ 150/2000] tot_loss=2.043 (perp=9.216, rec=0.198, cos=0.001), tot_loss_proj:3.003 [t=0.25s]
prediction: ['[CLS] spray there has not your jump jump jump an world a single seat moment. [SEP]']
[ 200/2000] tot_loss=1.589 (perp=7.167, rec=0.154, cos=0.001), tot_loss_proj:2.903 [t=0.26s]
prediction: ['[CLS] you there is not your jump jump jump - - a single seat moment and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.458 (perp=6.555, rec=0.144, cos=0.002), tot_loss_proj:2.472 [t=0.25s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment and [SEP]']
[ 300/2000] tot_loss=1.423 (perp=6.555, rec=0.111, cos=0.001), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.407 (perp=6.555, rec=0.095, cos=0.001), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.397 (perp=6.555, rec=0.085, cos=0.001), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment and [SEP]']
[ 450/2000] tot_loss=1.392 (perp=6.555, rec=0.081, cos=0.001), tot_loss_proj:2.473 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.376 (perp=6.411, rec=0.093, cos=0.000), tot_loss_proj:2.261 [t=0.27s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.359 (perp=6.411, rec=0.076, cos=0.000), tot_loss_proj:2.256 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
[ 600/2000] tot_loss=1.357 (perp=6.411, rec=0.075, cos=0.000), tot_loss_proj:2.255 [t=0.28s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.355 (perp=6.411, rec=0.072, cos=0.000), tot_loss_proj:2.256 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.364 (perp=6.411, rec=0.081, cos=0.000), tot_loss_proj:2.256 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
[ 750/2000] tot_loss=1.367 (perp=6.411, rec=0.085, cos=0.000), tot_loss_proj:2.255 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.355 (perp=6.411, rec=0.072, cos=0.000), tot_loss_proj:2.250 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a single jump seat moment - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.431 (perp=6.769, rec=0.076, cos=0.001), tot_loss_proj:2.926 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a seat in single moment - [SEP]']
[ 900/2000] tot_loss=1.430 (perp=6.769, rec=0.076, cos=0.000), tot_loss_proj:2.929 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a seat in single moment - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.424 (perp=6.769, rec=0.071, cos=0.000), tot_loss_proj:2.930 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a seat in single moment - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.435 (perp=6.769, rec=0.081, cos=0.000), tot_loss_proj:2.931 [t=0.26s]
prediction: ['[CLS] and there s not your seat jump - - a seat in single moment - [SEP]']
[1050/2000] tot_loss=1.564 (perp=7.461, rec=0.071, cos=0.000), tot_loss_proj:2.837 [t=0.26s]
prediction: ["[CLS] and there s not your seat jump -'a seat in single moment - [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.495 (perp=7.096, rec=0.075, cos=0.000), tot_loss_proj:3.171 [t=0.28s]
prediction: ["[CLS] and there s not your seat jump - - a seat in single moment'[SEP]"]
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.311 (perp=6.108, rec=0.088, cos=0.001), tot_loss_proj:2.947 [t=0.26s]
prediction: ["[CLS] and there's not your seat jump - - a seat in single moment [SEP]"]
[1200/2000] tot_loss=1.292 (perp=6.108, rec=0.070, cos=0.000), tot_loss_proj:2.946 [t=0.25s]
prediction: ["[CLS] and there's not your seat jump - - a seat in single moment [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.293 (perp=6.108, rec=0.071, cos=0.000), tot_loss_proj:2.946 [t=0.26s]
prediction: ["[CLS] and there's not your seat jump - - a seat in single moment [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.284 (perp=6.108, rec=0.062, cos=0.000), tot_loss_proj:2.943 [t=0.27s]
prediction: ["[CLS] and there's not your seat jump - - a seat in single moment [SEP]"]
[1350/2000] tot_loss=1.305 (perp=6.108, rec=0.083, cos=0.000), tot_loss_proj:2.941 [t=0.26s]
prediction: ["[CLS] and there's not your seat jump - - a seat in single moment [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.286 (perp=6.056, rec=0.075, cos=0.000), tot_loss_proj:2.913 [t=0.25s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.296 (perp=6.056, rec=0.084, cos=0.000), tot_loss_proj:2.917 [t=0.26s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
[1500/2000] tot_loss=1.281 (perp=6.056, rec=0.069, cos=0.000), tot_loss_proj:2.920 [t=0.26s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.284 (perp=6.056, rec=0.073, cos=0.000), tot_loss_proj:2.913 [t=0.27s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.282 (perp=6.056, rec=0.070, cos=0.000), tot_loss_proj:2.918 [t=0.28s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
[1650/2000] tot_loss=1.287 (perp=6.056, rec=0.075, cos=0.000), tot_loss_proj:2.922 [t=0.27s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.278 (perp=6.056, rec=0.067, cos=0.000), tot_loss_proj:2.915 [t=0.27s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.298 (perp=6.056, rec=0.087, cos=0.000), tot_loss_proj:2.922 [t=0.25s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
[1800/2000] tot_loss=1.271 (perp=6.056, rec=0.060, cos=0.000), tot_loss_proj:2.920 [t=0.26s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.287 (perp=6.056, rec=0.076, cos=0.000), tot_loss_proj:2.914 [t=0.26s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.280 (perp=6.056, rec=0.069, cos=0.000), tot_loss_proj:2.919 [t=0.25s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
[1950/2000] tot_loss=1.284 (perp=6.056, rec=0.073, cos=0.000), tot_loss_proj:2.917 [t=0.26s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.286 (perp=6.056, rec=0.075, cos=0.000), tot_loss_proj:2.915 [t=0.27s]
prediction: ["[CLS] and there's not your jump seat - - a seat in single moment [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there's not your jump seat - - a seat in single moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 16.000 | p: 15.385 | r: 16.667
rougeL     | fm: 59.259 | p: 57.143 | r: 61.538
rougeLsum  | fm: 59.259 | p: 57.143 | r: 61.538
r1fm+r2fm = 112.296

[Aggregate metrics]:
rouge1     | fm: 88.294 | p: 87.917 | r: 88.764
rouge2     | fm: 53.578 | p: 53.437 | r: 53.795
rougeL     | fm: 75.549 | p: 75.242 | r: 75.940
rougeLsum  | fm: 75.575 | p: 75.339 | r: 76.058
r1fm+r2fm = 141.872

input #71 time: 0:11:06 | total time: 12:14:37


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
*********************************
*********************************
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 1.660793662071228 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 1.5929793119430542 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 1.4265902042388916 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 1.4027378559112549 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 1.3698697090148926 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 1.3598313331604004 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 1.2334275245666504 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 1.2262848615646362 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 1.216339349746704 for ['[CLS] them relations quickly sip abexed without connected counties glacier digitalhic professor teller page [SEP]']
[Init] best rec loss: 1.190377116203308 for ['[CLS] things substitute air favors bishop defined werewolf anywaylusion ghana tonnesboard favorfin cy [SEP]']
[Init] best perm rec loss: 1.1880836486816406 for ['[CLS] ghana favorslusion air cy anywayboard werewolf tonnes things favor substitutefin bishop defined [SEP]']
[Init] best perm rec loss: 1.1873072385787964 for ['[CLS] favor ghana air bishop tonnes substitutelusion werewolf cy things anywayboard defined favorsfin [SEP]']
[Init] best perm rec loss: 1.1828306913375854 for ['[CLS] ghana bishop defined substitute tonnes favors anywaylusion things werewolffin favor air cyboard [SEP]']
[Init] best perm rec loss: 1.1827526092529297 for ['[CLS]fin favorslusion substitute anyway werewolf bishop air definedboard things favor ghana cy tonnes [SEP]']
[Init] best perm rec loss: 1.1818435192108154 for ['[CLS] ghana cy favorlusion defined substituteboard tonnes air things bishop favors anywayfin werewolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.244 (perp=13.972, rec=0.440, cos=0.010), tot_loss_proj:3.899 [t=0.26s]
prediction: ['[CLS] falls pressure numb start harder node framework grass pass suffer prison worriedesian rope decline [SEP]']
[ 100/2000] tot_loss=2.836 (perp=12.489, rec=0.333, cos=0.005), tot_loss_proj:3.488 [t=0.25s]
prediction: ['[CLS] has hours numb start harder node tough no pass more time balanceesian hate violence [SEP]']
[ 150/2000] tot_loss=2.493 (perp=11.142, rec=0.263, cos=0.002), tot_loss_proj:3.047 [t=0.26s]
prediction: ['[CLS] has seven weak has harder node tough ) hard more time balance main philosophy violence [SEP]']
[ 200/2000] tot_loss=2.330 (perp=10.670, rec=0.194, cos=0.001), tot_loss_proj:3.179 [t=0.25s]
prediction: ['[CLS] has tough weakaceous toughaday tough a tough more time balancing its philosophy violence [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.423 (perp=11.382, rec=0.145, cos=0.001), tot_loss_proj:3.416 [t=0.26s]
prediction: ['[CLS] has its weakacleerァ tough tough a its time balancing its philosophy violence [SEP]']
[ 300/2000] tot_loss=2.162 (perp=10.168, rec=0.125, cos=0.003), tot_loss_proj:2.667 [t=0.25s]
prediction: ['[CLS] has a weakerer relationship tough violence a its time balancing with philosophy violence [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.945 (perp=9.144, rec=0.116, cos=0.001), tot_loss_proj:2.474 [t=0.26s]
prediction: ['[CLS] has a weaker relationship tougher violence a its time balancing with philosophy violence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.811 (perp=8.549, rec=0.101, cos=0.001), tot_loss_proj:2.343 [t=0.25s]
prediction: ['[CLS] has a weaker relationship tougher violence a its time balancing with violence philosophy [SEP]']
[ 450/2000] tot_loss=1.792 (perp=8.549, rec=0.082, cos=0.000), tot_loss_proj:2.348 [t=0.26s]
prediction: ['[CLS] has a weaker relationship tougher violence a its time balancing with violence philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.798 (perp=8.561, rec=0.086, cos=0.000), tot_loss_proj:2.992 [t=0.27s]
prediction: ['[CLS] has a buter relationship a tougher violence its time balancing with violence philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.610 (perp=7.605, rec=0.088, cos=0.001), tot_loss_proj:2.995 [t=0.26s]
prediction: ['[CLS] has a philosophyer relationship a tougher violence its time balancing with violence - [SEP]']
[ 600/2000] tot_loss=1.605 (perp=7.605, rec=0.084, cos=0.000), tot_loss_proj:2.995 [t=0.26s]
prediction: ['[CLS] has a philosophyer relationship a tougher violence its time balancing with violence - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.743 (perp=8.315, rec=0.079, cos=0.000), tot_loss_proj:2.720 [t=0.27s]
prediction: ['[CLS] has a philosophyer宿 a tougher balancing its time violence with violence - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.635 (perp=7.714, rec=0.091, cos=0.001), tot_loss_proj:2.699 [t=0.29s]
prediction: ['[CLS] has a philosophyer a tougher balancing its time violence with violence -宿 [SEP]']
[ 750/2000] tot_loss=1.634 (perp=7.714, rec=0.091, cos=0.000), tot_loss_proj:2.704 [t=0.26s]
prediction: ['[CLS] has a philosophyer a tougher balancing its time violence with violence -宿 [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.710 (perp=8.136, rec=0.082, cos=0.000), tot_loss_proj:2.864 [t=0.26s]
prediction: ['[CLS] hasfk philosophy a tougherer balancing its time violence with violence -宿 [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.638 (perp=7.766, rec=0.084, cos=0.001), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher balancing its time violence with violence -宿 [SEP]']
[ 900/2000] tot_loss=1.627 (perp=7.766, rec=0.073, cos=0.000), tot_loss_proj:2.880 [t=0.28s]
prediction: ['[CLS] hasfker philosophy a tougher balancing its time violence with violence -宿 [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.520 (perp=7.218, rec=0.076, cos=0.000), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1000/2000] tot_loss=1.522 (perp=7.218, rec=0.078, cos=0.000), tot_loss_proj:2.239 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1050/2000] tot_loss=1.524 (perp=7.218, rec=0.080, cos=0.000), tot_loss_proj:2.238 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.527 (perp=7.218, rec=0.083, cos=0.000), tot_loss_proj:2.233 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=7.218, rec=0.071, cos=0.000), tot_loss_proj:2.239 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1200/2000] tot_loss=1.528 (perp=7.218, rec=0.084, cos=0.000), tot_loss_proj:2.238 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1250/2000] tot_loss=1.501 (perp=7.218, rec=0.057, cos=0.000), tot_loss_proj:2.244 [t=0.27s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1300/2000] tot_loss=1.523 (perp=7.218, rec=0.079, cos=0.000), tot_loss_proj:2.238 [t=0.28s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1350/2000] tot_loss=1.525 (perp=7.218, rec=0.082, cos=0.000), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1400/2000] tot_loss=1.516 (perp=7.218, rec=0.072, cos=0.000), tot_loss_proj:2.237 [t=0.29s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.513 (perp=7.218, rec=0.070, cos=0.000), tot_loss_proj:2.233 [t=0.27s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1500/2000] tot_loss=1.527 (perp=7.218, rec=0.083, cos=0.000), tot_loss_proj:2.237 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.530 (perp=7.218, rec=0.087, cos=0.000), tot_loss_proj:2.242 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1600/2000] tot_loss=1.526 (perp=7.218, rec=0.083, cos=0.000), tot_loss_proj:2.239 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1650/2000] tot_loss=1.526 (perp=7.218, rec=0.082, cos=0.000), tot_loss_proj:2.239 [t=0.27s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1700/2000] tot_loss=1.524 (perp=7.218, rec=0.080, cos=0.000), tot_loss_proj:2.247 [t=0.27s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1750/2000] tot_loss=1.514 (perp=7.218, rec=0.070, cos=0.000), tot_loss_proj:2.246 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1800/2000] tot_loss=1.522 (perp=7.218, rec=0.078, cos=0.000), tot_loss_proj:2.244 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.518 (perp=7.218, rec=0.075, cos=0.000), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[1900/2000] tot_loss=1.515 (perp=7.218, rec=0.071, cos=0.000), tot_loss_proj:2.235 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
[1950/2000] tot_loss=1.518 (perp=7.218, rec=0.075, cos=0.000), tot_loss_proj:2.248 [t=0.25s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Attempt swap
[2000/2000] tot_loss=1.515 (perp=7.218, rec=0.071, cos=0.000), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] hasfker philosophy a tougher time balancing its violence with violence -宿 [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 52.174 | p: 54.545 | r: 50.000
rougeL     | fm: 72.000 | p: 75.000 | r: 69.231
rougeLsum  | fm: 72.000 | p: 75.000 | r: 69.231
r1fm+r2fm = 132.174

[Aggregate metrics]:
rouge1     | fm: 88.111 | p: 87.824 | r: 88.555
rouge2     | fm: 53.402 | p: 53.278 | r: 53.535
rougeL     | fm: 75.481 | p: 75.273 | r: 75.877
rougeLsum  | fm: 75.649 | p: 75.359 | r: 76.140
r1fm+r2fm = 141.513

input #72 time: 0:11:06 | total time: 12:25:44


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
*********************************
*********************************
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 1.8824208974838257 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 1.7401381731033325 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 1.6489461660385132 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 1.5039418935775757 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 1.4107468128204346 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 1.407352328300476 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.185 (perp=9.723, rec=0.234, cos=0.007), tot_loss_proj:2.016 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.026 (perp=9.723, rec=0.079, cos=0.002), tot_loss_proj:2.024 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.026 (perp=9.723, rec=0.080, cos=0.001), tot_loss_proj:2.028 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.001), tot_loss_proj:2.033 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.001), tot_loss_proj:2.022 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.001), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.001), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.004 (perp=9.723, rec=0.059, cos=0.001), tot_loss_proj:2.032 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.009 (perp=9.723, rec=0.064, cos=0.001), tot_loss_proj:2.011 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.017 (perp=9.723, rec=0.072, cos=0.001), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.006 (perp=9.723, rec=0.061, cos=0.001), tot_loss_proj:2.003 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.001), tot_loss_proj:2.022 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.991 (perp=9.723, rec=0.046, cos=0.001), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.003 (perp=9.723, rec=0.058, cos=0.001), tot_loss_proj:2.028 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.001), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.008 (perp=9.723, rec=0.063, cos=0.001), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.001), tot_loss_proj:2.023 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.009 (perp=9.723, rec=0.064, cos=0.001), tot_loss_proj:2.028 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.007 (perp=9.723, rec=0.062, cos=0.001), tot_loss_proj:2.015 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.010 (perp=9.723, rec=0.065, cos=0.001), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.001), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.001), tot_loss_proj:2.010 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.001), tot_loss_proj:2.026 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.011 (perp=9.723, rec=0.066, cos=0.001), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.013 (perp=9.723, rec=0.067, cos=0.001), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.001), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.005 (perp=9.723, rec=0.060, cos=0.001), tot_loss_proj:2.011 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.998 (perp=9.723, rec=0.053, cos=0.001), tot_loss_proj:2.023 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.001 (perp=9.723, rec=0.056, cos=0.001), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.017 (perp=9.723, rec=0.071, cos=0.001), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.001), tot_loss_proj:2.005 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.001), tot_loss_proj:2.017 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.001), tot_loss_proj:2.003 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.009 (perp=9.723, rec=0.064, cos=0.001), tot_loss_proj:2.010 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=1.999 (perp=9.723, rec=0.054, cos=0.001), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.007 (perp=9.723, rec=0.062, cos=0.001), tot_loss_proj:2.021 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.001), tot_loss_proj:2.019 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.001), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.300 | p: 88.036 | r: 88.802
rouge2     | fm: 54.062 | p: 53.928 | r: 54.233
rougeL     | fm: 75.976 | p: 75.698 | r: 76.366
rougeLsum  | fm: 75.862 | p: 75.573 | r: 76.329
r1fm+r2fm = 142.361

input #73 time: 0:11:00 | total time: 12:36:44


Running input #74 of 100.
reference: 
========================
share 
========================
*********************************
*********************************
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.6898705959320068 for ['[CLS]wed [SEP]']
[Init] best rec loss: 1.191595196723938 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.9334901571273804 for ['[CLS] answering [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.678 (perp=10.421, rec=0.512, cos=0.081), tot_loss_proj:2.904 [t=0.24s]
prediction: ['[CLS] healing [SEP]']
[ 100/2000] tot_loss=2.737 (perp=8.178, rec=0.788, cos=0.314), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=2.498 (perp=8.178, rec=0.689, cos=0.173), tot_loss_proj:2.175 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=2.388 (perp=8.178, rec=0.630, cos=0.123), tot_loss_proj:2.064 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.379 (perp=8.178, rec=0.596, cos=0.147), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=2.252 (perp=8.178, rec=0.543, cos=0.074), tot_loss_proj:1.947 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.279 (perp=8.178, rec=0.554, cos=0.090), tot_loss_proj:2.031 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.297 (perp=8.178, rec=0.568, cos=0.093), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.218 (perp=8.178, rec=0.520, cos=0.062), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.240 (perp=8.178, rec=0.526, cos=0.078), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.188 (perp=8.178, rec=0.495, cos=0.058), tot_loss_proj:1.970 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.179 (perp=8.178, rec=0.494, cos=0.049), tot_loss_proj:1.886 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.241 (perp=8.178, rec=0.535, cos=0.070), tot_loss_proj:1.852 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.167 (perp=8.178, rec=0.490, cos=0.041), tot_loss_proj:1.893 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.156 (perp=8.178, rec=0.484, cos=0.036), tot_loss_proj:1.867 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.150 (perp=8.178, rec=0.481, cos=0.033), tot_loss_proj:1.831 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.142 (perp=8.178, rec=0.475, cos=0.031), tot_loss_proj:1.812 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.131 (perp=8.178, rec=0.466, cos=0.029), tot_loss_proj:1.838 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.124 (perp=8.178, rec=0.460, cos=0.028), tot_loss_proj:1.816 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.126 (perp=8.178, rec=0.463, cos=0.027), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.128 (perp=8.178, rec=0.466, cos=0.026), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.121 (perp=8.178, rec=0.460, cos=0.026), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.114 (perp=8.178, rec=0.454, cos=0.025), tot_loss_proj:1.787 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.108 (perp=8.178, rec=0.448, cos=0.024), tot_loss_proj:1.784 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.102 (perp=8.178, rec=0.443, cos=0.024), tot_loss_proj:1.794 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.135 (perp=8.178, rec=0.470, cos=0.030), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.105 (perp=8.178, rec=0.447, cos=0.023), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.095 (perp=8.178, rec=0.437, cos=0.022), tot_loss_proj:1.771 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.102 (perp=8.178, rec=0.444, cos=0.022), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.108 (perp=8.178, rec=0.450, cos=0.022), tot_loss_proj:1.782 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.099 (perp=8.178, rec=0.442, cos=0.022), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.094 (perp=8.178, rec=0.437, cos=0.021), tot_loss_proj:1.779 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.107 (perp=8.178, rec=0.450, cos=0.021), tot_loss_proj:1.788 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.095 (perp=8.178, rec=0.439, cos=0.021), tot_loss_proj:1.779 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.092 (perp=8.178, rec=0.436, cos=0.021), tot_loss_proj:1.779 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.100 (perp=8.178, rec=0.444, cos=0.021), tot_loss_proj:1.773 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.096 (perp=8.178, rec=0.440, cos=0.021), tot_loss_proj:1.781 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.097 (perp=8.178, rec=0.441, cos=0.020), tot_loss_proj:1.789 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.090 (perp=8.178, rec=0.434, cos=0.020), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.089 (perp=8.178, rec=0.434, cos=0.020), tot_loss_proj:1.778 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.468 | p: 88.154 | r: 88.908
rouge2     | fm: 54.543 | p: 54.458 | r: 54.684
rougeL     | fm: 76.205 | p: 75.906 | r: 76.574
rougeLsum  | fm: 76.178 | p: 75.971 | r: 76.587
r1fm+r2fm = 143.011

input #74 time: 0:10:53 | total time: 12:47:37


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
*********************************
*********************************
average of cosine similarity 0.9993458403755588
highest_index [0]
highest [0.9993458403755588]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 1.9394946098327637 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 1.9215192794799805 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 1.861011028289795 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 1.7244476079940796 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 1.7233116626739502 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 1.661628007888794 for ['[CLS] surrounding imlence health flow mecklenburg dining twins execution plannercott by yes guy rattle senior batch 社 earth [SEP]']
[Init] best perm rec loss: 1.660509467124939 for ['[CLS] 社 execution senior bycott twins planner earth mecklenburg yes dininglence surrounding health flow guy im rattle batch [SEP]']
[Init] best perm rec loss: 1.6556261777877808 for ['[CLS] rattle mecklenburg dining surrounding flow batchcott guy planner by earthlence im twins health 社 execution senior yes [SEP]']
[Init] best perm rec loss: 1.6549123525619507 for ['[CLS] execution 社 senior surroundingcott mecklenburg guylence dining planner twins by health batch yes flow im rattle earth [SEP]']
[Init] best perm rec loss: 1.653684377670288 for ['[CLS] flow surrounding im mecklenburg planner batch 社 guycott twins by earthlence rattle senior execution dining health yes [SEP]']
[Init] best perm rec loss: 1.6525647640228271 for ['[CLS] surrounding mecklenburg health bycott guy batch flow plannerlence dining earth 社 yes twins rattle execution senior im [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.869 (perp=12.093, rec=0.445, cos=0.005), tot_loss_proj:4.009 [t=0.28s]
prediction: ['[CLS] patient safety 2006 from mhz journeymo » non and easily international shortly spirit stayed fit undeveloped bishop friedrich [SEP]']
[ 100/2000] tot_loss=2.430 (perp=10.640, rec=0.299, cos=0.002), tot_loss_proj:3.256 [t=0.26s]
prediction: ['[CLS] lifestyle learning luck from this journey succeeded exceptional proved cannot easily wildlife forgotten awake or if next. carolina [SEP]']
[ 150/2000] tot_loss=2.510 (perp=11.383, rec=0.231, cos=0.002), tot_loss_proj:3.465 [t=0.28s]
prediction: ['[CLS] lifestyle importance luck designation this journey succeeded exceptional non not not wildlife forgotten mental or if next. carolina [SEP]']
[ 200/2000] tot_loss=2.395 (perp=10.995, rec=0.195, cos=0.001), tot_loss_proj:3.845 [t=0.25s]
prediction: ['[CLS] uci moments instability instability this excursion succeeded exceptional quickly not not been forgotten mental or if easily. ignore [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.450 (perp=11.372, rec=0.175, cos=0.001), tot_loss_proj:4.142 [t=0.26s]
prediction: ['[CLS] instability surreal uci instability this excursion forget truly easily of not been forgotten mental easily if easily. ignore [SEP]']
[ 300/2000] tot_loss=2.359 (perp=11.036, rec=0.152, cos=0.000), tot_loss_proj:4.080 [t=0.25s]
prediction: ['[CLS] excursion weeks uci instability this excursion forget truly is into not been forgotten mental easily if or. asserts [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.427 (perp=11.331, rec=0.159, cos=0.002), tot_loss_proj:3.777 [t=0.25s]
prediction: ['[CLS] excursion calming succeeded uci instability this excursion truly is into not been forgotten mental easily greater ortwined ignored [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.349 (perp=11.060, rec=0.137, cos=0.000), tot_loss_proj:3.887 [t=0.25s]
prediction: ['[CLS] excursion calmingxi into uci instability this excursion truly is not of forgotten mental easily greater ortwined helpless [SEP]']
[ 450/2000] tot_loss=2.464 (perp=11.659, rec=0.131, cos=0.000), tot_loss_proj:4.000 [t=0.26s]
prediction: ['[CLS] excursion periodxi into uci instability this excursioncola is not of forgotten mental easily greater orsive alt [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.462 (perp=11.673, rec=0.127, cos=0.000), tot_loss_proj:4.169 [t=0.29s]
prediction: ['[CLS] excursionxi into uci instability this excursioncola is not emotional variables forgotten mental easily if orsive alt [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.415 (perp=11.427, rec=0.129, cos=0.001), tot_loss_proj:4.041 [t=0.26s]
prediction: ['[CLS] excursionsper into uci instability this excursioncola is not emotional variables earthquake mental easily forgotten orsive alt [SEP]']
[ 600/2000] tot_loss=2.504 (perp=11.895, rec=0.125, cos=0.000), tot_loss_proj:4.061 [t=0.25s]
prediction: ['[CLS] excursion. into uci instability this excursioncola is not emotional variables earthquake mental easily forgotten dismissedsive alt [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.349 (perp=11.146, rec=0.120, cos=0.000), tot_loss_proj:3.930 [t=0.27s]
prediction: ['[CLS] excursion. into uci instability variables this excursioncola is not. earthquake mental easily forgotten dismissedsive alt [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.116 (perp=9.980, rec=0.120, cos=0.000), tot_loss_proj:3.544 [t=0.25s]
prediction: ['[CLS] excursion. into uci instability variables this excursioncola is not outstanding mental. easily forgotten dismissed / alt [SEP]']
[ 750/2000] tot_loss=2.116 (perp=9.980, rec=0.120, cos=0.000), tot_loss_proj:3.549 [t=0.27s]
prediction: ['[CLS] excursion. into uci instability variables this excursioncola is not outstanding mental. easily forgotten dismissed / alt [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.037 (perp=9.657, rec=0.105, cos=0.000), tot_loss_proj:3.459 [t=0.31s]
prediction: ['[CLS] excursion mental into uci instability variables this excursioncola is not outstanding.. easily forgotten dismissed / alt [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.949 (perp=9.175, rec=0.114, cos=0.000), tot_loss_proj:3.369 [t=0.29s]
prediction: ['[CLS] excursion mental into uci instability variables this excursion is not outstanding.cola. easily forgotten dismissed / alt [SEP]']
[ 900/2000] tot_loss=2.154 (perp=10.220, rec=0.110, cos=0.000), tot_loss_proj:3.568 [t=0.27s]
prediction: ['[CLS] excursion mental intocola instabilitycola this excursion is not outstanding.cola. easily forgotten dismissed / alt [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.090 (perp=9.916, rec=0.106, cos=0.000), tot_loss_proj:3.498 [t=0.25s]
prediction: ['[CLS] excursion mental into this instabilityentercola excursion is not outstanding orcola. easily forgotten dismissed / alt [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.066 (perp=9.750, rec=0.116, cos=0.000), tot_loss_proj:3.466 [t=0.29s]
prediction: ['[CLS] excursion mental into this instabilityentercola excursion is not outstanding.cola or easily forgotten dismissed / alt [SEP]']
[1050/2000] tot_loss=2.053 (perp=9.750, rec=0.103, cos=0.000), tot_loss_proj:3.473 [t=0.26s]
prediction: ['[CLS] excursion mental into this instabilityentercola excursion is not outstanding.cola or easily forgotten dismissed / alt [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.106 (perp=9.964, rec=0.112, cos=0.000), tot_loss_proj:3.743 [t=0.29s]
prediction: ['[CLS] excursion mental into this instabilityentercola excursion is not earthquake. orcola easily forgotten dismissed / alt [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.175 (perp=10.262, rec=0.121, cos=0.001), tot_loss_proj:3.587 [t=0.25s]
prediction: ['[CLS] excursion mental into this instability altcola excursion is not outstanding. orcola easily forgotten dismissed /enter [SEP]']
[1200/2000] tot_loss=2.100 (perp=9.947, rec=0.110, cos=0.000), tot_loss_proj:3.529 [t=0.26s]
prediction: ['[CLS] excursion mental into this instability pomeraniancola excursion is not outstanding. orcola easily forgotten dismissed /enter [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.930 (perp=9.040, rec=0.121, cos=0.000), tot_loss_proj:3.387 [t=0.25s]
prediction: ['[CLS] excursion mental into this instability pomeranian excursion is not outstanding.cola orcola easily forgotten dismissed / of [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.929 (perp=9.005, rec=0.128, cos=0.001), tot_loss_proj:3.354 [t=0.26s]
prediction: ['[CLS] excursion mental into this instability pomeranian excursion is not outstanding.cola orenter easily forgotten of / dismissed [SEP]']
[1350/2000] tot_loss=1.918 (perp=9.005, rec=0.117, cos=0.000), tot_loss_proj:3.353 [t=0.27s]
prediction: ['[CLS] excursion mental into this instability pomeranian excursion is not outstanding.cola orenter easily forgotten of / dismissed [SEP]']
Attempt swap
[1400/2000] tot_loss=1.914 (perp=9.005, rec=0.112, cos=0.000), tot_loss_proj:3.350 [t=0.28s]
prediction: ['[CLS] excursion mental into this instability pomeranian excursion is not outstanding.cola orenter easily forgotten of / dismissed [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.893 (perp=8.880, rec=0.117, cos=0.000), tot_loss_proj:3.341 [t=0.28s]
prediction: ['[CLS] mental excursion into this instability pomeranian excursion is not outstanding.cola orenter easily forgotten of / dismissed [SEP]']
[1500/2000] tot_loss=1.886 (perp=8.880, rec=0.110, cos=0.000), tot_loss_proj:3.343 [t=0.26s]
prediction: ['[CLS] mental excursion into this instability pomeranian excursion is not outstanding.cola orenter easily forgotten of / dismissed [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.890 (perp=8.893, rec=0.111, cos=0.000), tot_loss_proj:3.518 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian excursion is not earthquake.cola orenter easily forgotten of / dismissed [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.843 (perp=8.671, rec=0.108, cos=0.000), tot_loss_proj:3.466 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian excursion is not earthquake. orcolaenter easily forgotten of / dismissed [SEP]']
[1650/2000] tot_loss=1.851 (perp=8.671, rec=0.117, cos=0.000), tot_loss_proj:3.462 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian excursion is not earthquake. orcolaenter easily forgotten of / dismissed [SEP]']
Attempt swap
[1700/2000] tot_loss=1.844 (perp=8.671, rec=0.109, cos=0.000), tot_loss_proj:3.465 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian excursion is not earthquake. orcolaenter easily forgotten of / dismissed [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.819 (perp=8.547, rec=0.109, cos=0.000), tot_loss_proj:3.390 [t=0.27s]
prediction: ['[CLS] this excursion into mental instability pomeranian is not earthquake excursion. orcolaenter easily forgotten of / dismissed [SEP]']
[1800/2000] tot_loss=1.811 (perp=8.547, rec=0.101, cos=0.000), tot_loss_proj:3.394 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian is not earthquake excursion. orcolaenter easily forgotten of / dismissed [SEP]']
Attempt swap
[1850/2000] tot_loss=1.825 (perp=8.547, rec=0.115, cos=0.000), tot_loss_proj:3.389 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian is not earthquake excursion. orcolaenter easily forgotten of / dismissed [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.776 (perp=8.316, rec=0.112, cos=0.000), tot_loss_proj:3.215 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian is not excursion outstanding. orcolaenter easily forgotten of / dismissed [SEP]']
[1950/2000] tot_loss=1.827 (perp=8.565, rec=0.114, cos=0.000), tot_loss_proj:3.432 [t=0.26s]
prediction: ['[CLS] this excursion into mental instability pomeranian is not excursion earthquake. orcolaenter easily forgotten of / dismissed [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.804 (perp=8.462, rec=0.111, cos=0.000), tot_loss_proj:3.250 [t=0.25s]
prediction: ['[CLS] this excursion into mental instability is not excursion outstanding pomeranian. orcolaenter easily forgotten of / dismissed [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion into mental instability pomeranian excursion is not earthquake. orcolaenter easily forgotten of / dismissed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 31.250 | p: 31.250 | r: 31.250
rougeL     | fm: 64.706 | p: 64.706 | r: 64.706
rougeLsum  | fm: 64.706 | p: 64.706 | r: 64.706
r1fm+r2fm = 107.721

[Aggregate metrics]:
rouge1     | fm: 88.314 | p: 88.043 | r: 88.708
rouge2     | fm: 54.444 | p: 54.301 | r: 54.666
rougeL     | fm: 76.007 | p: 75.783 | r: 76.428
rougeLsum  | fm: 76.079 | p: 75.819 | r: 76.506
r1fm+r2fm = 142.757

input #75 time: 0:11:07 | total time: 12:58:44


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
*********************************
*********************************
average of cosine similarity 0.9991386602126573
highest_index [0]
highest [0.9991386602126573]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 1.782433271408081 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 1.7596430778503418 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 1.7049720287322998 for ['[CLS] vimes spread stanford telescope formed neighbourhood wire chang miniseries farmers kyle having bend attempt [SEP]']
[Init] best rec loss: 1.6918405294418335 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 1.674768328666687 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 1.591769814491272 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 1.4612284898757935 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 1.3690840005874634 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 1.3682646751403809 for ['[CLS] ( backward ab taut mangoˣ left onwards pushed hard surrealhawoning purse [SEP]']
[Init] best perm rec loss: 1.3626619577407837 for ['[CLS]ˣ (haw onwards aboning taut left hard backward surreal pushed mango purse [SEP]']
[Init] best perm rec loss: 1.3604645729064941 for ['[CLS] (ˣ leftoning onwards pushed taut ab hard backward surreal mango pursehaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.755 (perp=11.810, rec=0.388, cos=0.005), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] is had dump marked dealers his used stoppedless acid, devoid am rigged [SEP]']
[ 100/2000] tot_loss=2.300 (perp=10.233, rec=0.252, cos=0.002), tot_loss_proj:3.282 [t=0.25s]
prediction: ['[CLS] is like dump. crust could old stopped hard old, stopped has challenges [SEP]']
[ 150/2000] tot_loss=2.245 (perp=10.228, rec=0.198, cos=0.001), tot_loss_proj:3.069 [t=0.25s]
prediction: ['[CLS] is like discarded. expert sbs at stopped challengingclops, stopped has challenging [SEP]']
[ 200/2000] tot_loss=2.286 (perp=10.606, rec=0.164, cos=0.001), tot_loss_proj:3.786 [t=0.25s]
prediction: ['[CLS] is like release. s childhood at stopped challenging myself has stopped has challenging [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.350 (perp=10.813, rec=0.186, cos=0.002), tot_loss_proj:3.556 [t=0.27s]
prediction: ['[CLS] is stopped rolled have sddin at like challenging whom has stopped has challenging [SEP]']
[ 300/2000] tot_loss=1.937 (perp=8.921, rec=0.152, cos=0.001), tot_loss_proj:2.953 [t=0.26s]
prediction: ['[CLS] is stopped old, for allen at as challenging himself has stopped herself challenging [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.204 (perp=10.258, rec=0.151, cos=0.002), tot_loss_proj:3.604 [t=0.25s]
prediction: ['[CLS] s stopped previous atelling allen : as. himself has 66 himself challenging [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.076 (perp=9.660, rec=0.143, cos=0.001), tot_loss_proj:3.686 [t=0.26s]
prediction: ['[CLS] s stopped old atelling allen : as himself himself has 66. challenging [SEP]']
[ 450/2000] tot_loss=2.068 (perp=9.660, rec=0.135, cos=0.001), tot_loss_proj:3.701 [t=0.27s]
prediction: ['[CLS] s stopped old atelling allen : as himself himself has 66. challenging [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.038 (perp=9.496, rec=0.137, cos=0.001), tot_loss_proj:2.928 [t=0.27s]
prediction: ['[CLS] s. old at afterwards allen : as himself himself has 66 stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.932 (perp=8.976, rec=0.136, cos=0.001), tot_loss_proj:2.820 [t=0.25s]
prediction: ['[CLS] s. old at allen afterwards : as himself himself has 66 stopped challenging [SEP]']
[ 600/2000] tot_loss=1.930 (perp=8.976, rec=0.134, cos=0.001), tot_loss_proj:2.815 [t=0.27s]
prediction: ['[CLS] s. old at allen afterwards : as himself himself has 66 stopped challenging [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.820 (perp=8.441, rec=0.131, cos=0.001), tot_loss_proj:2.856 [t=0.26s]
prediction: ['[CLS] s. at old allen, : as himself himself has 66 stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.741 (perp=8.042, rec=0.132, cos=0.001), tot_loss_proj:2.768 [t=0.25s]
prediction: ['[CLS] s. at although allen himself : as himself, has 66 stopped challenging [SEP]']
[ 750/2000] tot_loss=1.735 (perp=8.042, rec=0.126, cos=0.001), tot_loss_proj:2.760 [t=0.26s]
prediction: ['[CLS] s. at although allen himself : as himself, has 66 stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.686 (perp=7.760, rec=0.134, cos=0.001), tot_loss_proj:2.628 [t=0.26s]
prediction: ['[CLS] s. at : although allen himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=7.760, rec=0.122, cos=0.001), tot_loss_proj:2.629 [t=0.28s]
prediction: ['[CLS] s. at : although allen himself as himself, has 66 stopped challenging [SEP]']
[ 900/2000] tot_loss=1.677 (perp=7.760, rec=0.124, cos=0.001), tot_loss_proj:2.630 [t=0.28s]
prediction: ['[CLS] s. at : although allen himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.658 (perp=7.620, rec=0.133, cos=0.001), tot_loss_proj:2.682 [t=0.27s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1000/2000] tot_loss=1.645 (perp=7.620, rec=0.121, cos=0.001), tot_loss_proj:2.680 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1050/2000] tot_loss=1.640 (perp=7.620, rec=0.116, cos=0.001), tot_loss_proj:2.685 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1100/2000] tot_loss=1.649 (perp=7.620, rec=0.125, cos=0.001), tot_loss_proj:2.678 [t=0.27s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1150/2000] tot_loss=1.646 (perp=7.620, rec=0.122, cos=0.001), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1200/2000] tot_loss=1.642 (perp=7.620, rec=0.117, cos=0.001), tot_loss_proj:2.688 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1250/2000] tot_loss=1.634 (perp=7.620, rec=0.110, cos=0.001), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1300/2000] tot_loss=1.646 (perp=7.620, rec=0.122, cos=0.001), tot_loss_proj:2.683 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1350/2000] tot_loss=1.645 (perp=7.620, rec=0.121, cos=0.001), tot_loss_proj:2.678 [t=0.27s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1400/2000] tot_loss=1.633 (perp=7.620, rec=0.108, cos=0.001), tot_loss_proj:2.683 [t=0.27s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1450/2000] tot_loss=1.633 (perp=7.620, rec=0.108, cos=0.001), tot_loss_proj:2.687 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1500/2000] tot_loss=1.647 (perp=7.620, rec=0.123, cos=0.001), tot_loss_proj:2.683 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1550/2000] tot_loss=1.645 (perp=7.620, rec=0.120, cos=0.001), tot_loss_proj:2.690 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1600/2000] tot_loss=1.637 (perp=7.620, rec=0.112, cos=0.001), tot_loss_proj:2.682 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1650/2000] tot_loss=1.631 (perp=7.620, rec=0.106, cos=0.001), tot_loss_proj:2.688 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1700/2000] tot_loss=1.638 (perp=7.620, rec=0.114, cos=0.001), tot_loss_proj:2.679 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1750/2000] tot_loss=1.637 (perp=7.620, rec=0.112, cos=0.001), tot_loss_proj:2.685 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1800/2000] tot_loss=1.633 (perp=7.620, rec=0.108, cos=0.001), tot_loss_proj:2.684 [t=0.26s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1850/2000] tot_loss=1.638 (perp=7.620, rec=0.114, cos=0.001), tot_loss_proj:2.680 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[1900/2000] tot_loss=1.643 (perp=7.620, rec=0.119, cos=0.001), tot_loss_proj:2.685 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
[1950/2000] tot_loss=1.647 (perp=7.620, rec=0.123, cos=0.001), tot_loss_proj:2.682 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Attempt swap
[2000/2000] tot_loss=1.636 (perp=7.620, rec=0.111, cos=0.001), tot_loss_proj:2.683 [t=0.25s]
prediction: ['[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s. at : allen although himself as himself, has 66 stopped challenging [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 105.391

[Aggregate metrics]:
rouge1     | fm: 88.259 | p: 87.909 | r: 88.728
rouge2     | fm: 53.850 | p: 53.705 | r: 54.066
rougeL     | fm: 75.773 | p: 75.448 | r: 76.234
rougeLsum  | fm: 75.847 | p: 75.632 | r: 76.260
r1fm+r2fm = 142.109

input #76 time: 0:11:06 | total time: 13:09:51


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
*********************************
*********************************
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 1.6982685327529907 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 1.6925209760665894 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 1.4739956855773926 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 1.4576562643051147 for ['[CLS] where medium limeraphicno ways ole sheep sometime purple outside win most gray park [SEP]']
[Init] best perm rec loss: 1.4574075937271118 for ['[CLS] where medium park oleno ways sheep outside gray purple sometime win mostraphic lime [SEP]']
[Init] best perm rec loss: 1.4540070295333862 for ['[CLS] lime gray medium park whereraphic purple ole most win ways sheep sometime outsideno [SEP]']
[Init] best perm rec loss: 1.4537286758422852 for ['[CLS] parkraphic lime where medium ways ole sometime most purpleno outside gray win sheep [SEP]']
[Init] best perm rec loss: 1.4526270627975464 for ['[CLS] where park gray mediumraphic ways ole most lime sheepno win sometime outside purple [SEP]']
[Init] best perm rec loss: 1.4507323503494263 for ['[CLS] medium sheep park where purpleraphic sometime gray most outsideno ole lime ways win [SEP]']
[Init] best perm rec loss: 1.448798418045044 for ['[CLS] sheep medium gray where sometimeraphic park ole most lime win ways purpleno outside [SEP]']
[Init] best perm rec loss: 1.4465056657791138 for ['[CLS] where medium sometime park ole win purple gray sheep lime ways outsideraphic mostno [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.721 (perp=11.515, rec=0.406, cos=0.013), tot_loss_proj:3.593 [t=0.25s]
prediction: ["[CLS] wonderful sweet april gift eagle. display faith'its miracles ian lessuated potential [SEP]"]
[ 100/2000] tot_loss=2.839 (perp=12.618, rec=0.312, cos=0.003), tot_loss_proj:3.432 [t=0.26s]
prediction: ['[CLS] looking fine april artistic touch of shane promisesability the believellin material esq reform [SEP]']
[ 150/2000] tot_loss=2.263 (perp=9.957, rec=0.270, cos=0.002), tot_loss_proj:2.952 [t=0.26s]
prediction: ['[CLS] looking fine gabe its reward of does believe life the believe was its about promise [SEP]']
[ 200/2000] tot_loss=2.116 (perp=9.311, rec=0.253, cos=0.001), tot_loss_proj:2.788 [t=0.27s]
prediction: ['[CLS] looking fine above its promise of does believe life the believe was its above realm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.024 (perp=8.839, rec=0.254, cos=0.002), tot_loss_proj:2.416 [t=0.27s]
prediction: ['[CLS] looking beautiful above its promise of does believe life the possible something above its realm [SEP]']
[ 300/2000] tot_loss=2.141 (perp=9.678, rec=0.202, cos=0.003), tot_loss_proj:2.832 [t=0.26s]
prediction: ['[CLS] looking fine above its promise of does believe life the the -ars is realm [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.850 (perp=8.300, rec=0.188, cos=0.002), tot_loss_proj:2.384 [t=0.26s]
prediction: ['[CLS] looking strong above its promise of does believe life is the -ars the realm [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.783 (perp=7.996, rec=0.181, cos=0.003), tot_loss_proj:2.896 [t=0.29s]
prediction: ['[CLS] believe regular above its promise does believe life is the -ars of that realm [SEP]']
[ 450/2000] tot_loss=1.708 (perp=7.796, rec=0.147, cos=0.001), tot_loss_proj:2.914 [t=0.26s]
prediction: ['[CLS] believe are above its promise does believe life is the materialars of that realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.749 (perp=8.050, rec=0.138, cos=0.001), tot_loss_proj:2.702 [t=0.28s]
prediction: ['[CLS] believe is above its promiselife believe life are the materialars of that realm [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.891 (perp=8.693, rec=0.150, cos=0.002), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS] believe its promise is abovelife believe life regular the materialars of that realm [SEP]']
[ 600/2000] tot_loss=1.714 (perp=7.908, rec=0.132, cos=0.001), tot_loss_proj:2.498 [t=0.26s]
prediction: ['[CLS] believe its promise is abovelife believe life make the materialars of that realm [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.892 (perp=8.806, rec=0.129, cos=0.001), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS] believe its promise is above life makelife believe the materialars life that realm [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.787 (perp=8.296, rec=0.126, cos=0.001), tot_loss_proj:2.601 [t=0.26s]
prediction: ['[CLS] believe its promise is life life makelife believe the materialars above that realm [SEP]']
[ 750/2000] tot_loss=1.628 (perp=7.589, rec=0.110, cos=0.001), tot_loss_proj:2.465 [t=0.26s]
prediction: ['[CLS] believe its promise is of life makelife believe the materialars above that realm [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.619 (perp=7.506, rec=0.117, cos=0.001), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] believe its promise is life of makelife believe the materialars above that realm [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.687 (perp=7.834, rec=0.119, cos=0.001), tot_loss_proj:2.619 [t=0.26s]
prediction: ['[CLS] believe its promise is life of the material make∩ believears above that realm [SEP]']
[ 900/2000] tot_loss=1.673 (perp=7.834, rec=0.105, cos=0.001), tot_loss_proj:2.616 [t=0.26s]
prediction: ['[CLS] believe its promise is life of the material make∩ believears above that realm [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.611 (perp=7.461, rec=0.118, cos=0.001), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] believe its promise of life is the material make∩ believears above that realm [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.562 (perp=7.227, rec=0.115, cos=0.001), tot_loss_proj:2.514 [t=0.25s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
[1050/2000] tot_loss=1.548 (perp=7.227, rec=0.101, cos=0.001), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.553 (perp=7.227, rec=0.107, cos=0.001), tot_loss_proj:2.522 [t=0.25s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.543 (perp=7.227, rec=0.097, cos=0.001), tot_loss_proj:2.524 [t=0.25s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
[1200/2000] tot_loss=1.543 (perp=7.227, rec=0.097, cos=0.001), tot_loss_proj:2.510 [t=0.26s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.542 (perp=7.227, rec=0.096, cos=0.001), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
Attempt swap
[1300/2000] tot_loss=1.551 (perp=7.227, rec=0.105, cos=0.001), tot_loss_proj:2.516 [t=0.27s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
[1350/2000] tot_loss=1.542 (perp=7.227, rec=0.096, cos=0.001), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.546 (perp=7.227, rec=0.100, cos=0.001), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] believe its promise of life is the material make believe∩ars above that realm [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.514 (perp=7.118, rec=0.089, cos=0.001), tot_loss_proj:2.968 [t=0.26s]
prediction: ['[CLS] believe its promise of life is make believe unlike the materialars above that realm [SEP]']
[1500/2000] tot_loss=1.615 (perp=7.574, rec=0.099, cos=0.001), tot_loss_proj:3.337 [t=0.27s]
prediction: ['[CLS] believe its promise of life is make make unlike the materialars above that realm [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.700 (perp=7.990, rec=0.101, cos=0.001), tot_loss_proj:3.496 [t=0.27s]
prediction: ['[CLS] believe believe its promise of life is make unlike the materialars above that realm [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.595 (perp=7.515, rec=0.091, cos=0.001), tot_loss_proj:3.395 [t=0.25s]
prediction: ['[CLS] believe its promise of life is make unlike believe the materialars above that realm [SEP]']
[1650/2000] tot_loss=1.609 (perp=7.515, rec=0.105, cos=0.001), tot_loss_proj:3.396 [t=0.26s]
prediction: ['[CLS] believe its promise of life is make unlike believe the materialars above that realm [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.556 (perp=7.317, rec=0.092, cos=0.001), tot_loss_proj:2.957 [t=0.25s]
prediction: ['[CLS] believe its promise of life unlike is make believe the materialars above that realm [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.530 (perp=7.153, rec=0.099, cos=0.001), tot_loss_proj:2.605 [t=0.27s]
prediction: ['[CLS] believe its promise of life unlike is make the material believears above that realm [SEP]']
[1800/2000] tot_loss=1.525 (perp=7.153, rec=0.094, cos=0.001), tot_loss_proj:2.601 [t=0.28s]
prediction: ['[CLS] believe its promise of life unlike is make the material believears above that realm [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.462 (perp=6.830, rec=0.095, cos=0.001), tot_loss_proj:3.234 [t=0.25s]
prediction: ['[CLS] believe its promise of life is unlike make the material believears above that realm [SEP]']
Attempt swap
[1900/2000] tot_loss=1.453 (perp=6.830, rec=0.086, cos=0.001), tot_loss_proj:3.230 [t=0.26s]
prediction: ['[CLS] believe its promise of life is unlike make the material believears above that realm [SEP]']
[1950/2000] tot_loss=1.465 (perp=6.830, rec=0.098, cos=0.001), tot_loss_proj:3.231 [t=0.25s]
prediction: ['[CLS] believe its promise of life is unlike make the material believears above that realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.467 (perp=6.830, rec=0.100, cos=0.001), tot_loss_proj:3.231 [t=0.26s]
prediction: ['[CLS] believe its promise of life is unlike make the material believears above that realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] believe its promise of life is unlike make the material believears above that realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 27.586 | p: 26.667 | r: 28.571
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 117.909

[Aggregate metrics]:
rouge1     | fm: 88.265 | p: 87.888 | r: 88.807
rouge2     | fm: 53.597 | p: 53.484 | r: 53.717
rougeL     | fm: 75.594 | p: 75.230 | r: 76.053
rougeLsum  | fm: 75.517 | p: 75.178 | r: 76.011
r1fm+r2fm = 141.862

input #77 time: 0:11:05 | total time: 13:20:57


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
*********************************
*********************************
average of cosine similarity 0.9992696483604171
highest_index [0]
highest [0.9992696483604171]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 1.9528603553771973 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 1.9048945903778076 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 1.5339909791946411 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 1.3563518524169922 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 1.354122281074524 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 1.3496745824813843 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.513 (perp=10.730, rec=0.356, cos=0.011), tot_loss_proj:3.496 [t=0.27s]
prediction: ['[CLS] collapse exit arrest [SEP]']
[ 100/2000] tot_loss=2.066 (perp=9.346, rec=0.192, cos=0.004), tot_loss_proj:2.608 [t=0.27s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 150/2000] tot_loss=1.992 (perp=9.346, rec=0.121, cos=0.002), tot_loss_proj:2.607 [t=0.25s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 200/2000] tot_loss=1.966 (perp=9.346, rec=0.095, cos=0.002), tot_loss_proj:2.608 [t=0.27s]
prediction: ['[CLS] exit exit theater [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.894 (perp=8.923, rec=0.107, cos=0.002), tot_loss_proj:2.703 [t=0.26s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 300/2000] tot_loss=1.872 (perp=8.923, rec=0.086, cos=0.002), tot_loss_proj:2.706 [t=0.27s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.869 (perp=8.923, rec=0.083, cos=0.002), tot_loss_proj:2.702 [t=0.28s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.705 (perp=8.145, rec=0.074, cos=0.001), tot_loss_proj:2.425 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 450/2000] tot_loss=1.705 (perp=8.145, rec=0.075, cos=0.001), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.697 (perp=8.145, rec=0.068, cos=0.001), tot_loss_proj:2.438 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.683 (perp=8.145, rec=0.053, cos=0.001), tot_loss_proj:2.438 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
[ 600/2000] tot_loss=1.700 (perp=8.145, rec=0.071, cos=0.001), tot_loss_proj:2.438 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.683 (perp=8.145, rec=0.054, cos=0.001), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.701 (perp=8.145, rec=0.072, cos=0.001), tot_loss_proj:2.434 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
[ 750/2000] tot_loss=1.696 (perp=8.145, rec=0.067, cos=0.001), tot_loss_proj:2.439 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.686 (perp=8.145, rec=0.056, cos=0.001), tot_loss_proj:2.440 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.696 (perp=8.145, rec=0.066, cos=0.001), tot_loss_proj:2.445 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 900/2000] tot_loss=1.697 (perp=8.145, rec=0.068, cos=0.001), tot_loss_proj:2.438 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.700 (perp=8.145, rec=0.070, cos=0.001), tot_loss_proj:2.440 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.692 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.442 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[1050/2000] tot_loss=1.691 (perp=8.145, rec=0.061, cos=0.001), tot_loss_proj:2.441 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.696 (perp=8.145, rec=0.066, cos=0.001), tot_loss_proj:2.439 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.695 (perp=8.145, rec=0.065, cos=0.001), tot_loss_proj:2.436 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
[1200/2000] tot_loss=1.705 (perp=8.145, rec=0.075, cos=0.001), tot_loss_proj:2.442 [t=0.29s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.689 (perp=8.145, rec=0.059, cos=0.001), tot_loss_proj:2.441 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.690 (perp=8.145, rec=0.061, cos=0.001), tot_loss_proj:2.442 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
[1350/2000] tot_loss=1.697 (perp=8.145, rec=0.067, cos=0.001), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.692 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.438 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.696 (perp=8.145, rec=0.066, cos=0.001), tot_loss_proj:2.439 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
[1500/2000] tot_loss=1.697 (perp=8.145, rec=0.067, cos=0.001), tot_loss_proj:2.435 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.700 (perp=8.145, rec=0.070, cos=0.001), tot_loss_proj:2.441 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.706 (perp=8.145, rec=0.077, cos=0.001), tot_loss_proj:2.439 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[1650/2000] tot_loss=1.705 (perp=8.145, rec=0.075, cos=0.001), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.691 (perp=8.145, rec=0.061, cos=0.001), tot_loss_proj:2.439 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.693 (perp=8.145, rec=0.064, cos=0.001), tot_loss_proj:2.444 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[1800/2000] tot_loss=1.685 (perp=8.145, rec=0.055, cos=0.001), tot_loss_proj:2.435 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.690 (perp=8.145, rec=0.061, cos=0.001), tot_loss_proj:2.441 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.693 (perp=8.145, rec=0.063, cos=0.001), tot_loss_proj:2.439 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[1950/2000] tot_loss=1.689 (perp=8.145, rec=0.059, cos=0.001), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.691 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] the theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.425 | p: 88.080 | r: 88.953
rouge2     | fm: 53.343 | p: 53.223 | r: 53.465
rougeL     | fm: 75.635 | p: 75.314 | r: 76.024
rougeLsum  | fm: 75.685 | p: 75.355 | r: 76.117
r1fm+r2fm = 141.768

input #78 time: 0:11:10 | total time: 13:32:07


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
*********************************
*********************************
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 1.9500796794891357 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 1.7738052606582642 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 1.6991932392120361 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 1.544913411140442 for ['[CLS] combined quickly [SEP]']
[Init] best rec loss: 1.2942136526107788 for ['[CLS] texas qualified [SEP]']
[Init] best rec loss: 1.1571640968322754 for ['[CLS] own terrain [SEP]']
[Init] best rec loss: 1.1093544960021973 for ['[CLS] gray should [SEP]']
[Init] best perm rec loss: 1.1035370826721191 for ['[CLS] should gray [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.611 (perp=11.652, rec=0.273, cos=0.007), tot_loss_proj:2.688 [t=0.25s]
prediction: ['[CLS] fascinating we [SEP]']
[ 100/2000] tot_loss=2.492 (perp=11.428, rec=0.202, cos=0.004), tot_loss_proj:2.614 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.462 (perp=11.428, rec=0.173, cos=0.003), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.433 (perp=11.428, rec=0.145, cos=0.002), tot_loss_proj:2.603 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.827 (perp=8.695, rec=0.087, cos=0.001), tot_loss_proj:1.959 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.827 (perp=8.695, rec=0.087, cos=0.001), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.961 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.963 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.954 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.789 (perp=8.695, rec=0.049, cos=0.001), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.790 (perp=8.695, rec=0.050, cos=0.001), tot_loss_proj:1.969 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.789 (perp=8.695, rec=0.049, cos=0.001), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.965 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.949 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.965 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.817 (perp=8.695, rec=0.077, cos=0.001), tot_loss_proj:1.949 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.953 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.798 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.960 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.599 | p: 88.267 | r: 89.083
rouge2     | fm: 52.673 | p: 52.573 | r: 52.863
rougeL     | fm: 75.661 | p: 75.377 | r: 76.107
rougeLsum  | fm: 75.631 | p: 75.290 | r: 76.085
r1fm+r2fm = 141.272

input #79 time: 0:10:56 | total time: 13:43:04


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
*********************************
*********************************
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 1.8961759805679321 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 1.6977639198303223 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 1.6965769529342651 for ['[CLS] peek yet knees investments trilogy [SEP]']
[Init] best rec loss: 1.6295527219772339 for ['[CLS]ghtlving dried days dressing [SEP]']
[Init] best perm rec loss: 1.626391053199768 for ['[CLS] dressing dayslvingght dried [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.610 (perp=14.295, rec=0.744, cos=0.007), tot_loss_proj:4.397 [t=0.25s]
prediction: ['[CLS] awesome untilulesʳ optional [SEP]']
[ 100/2000] tot_loss=3.292 (perp=13.037, rec=0.669, cos=0.015), tot_loss_proj:4.368 [t=0.25s]
prediction: ['[CLS]phobia until tonheard subsidiary [SEP]']
[ 150/2000] tot_loss=3.337 (perp=13.473, rec=0.633, cos=0.009), tot_loss_proj:4.628 [t=0.25s]
prediction: ['[CLS]phobiazenzenheard subsidiary [SEP]']
[ 200/2000] tot_loss=3.446 (perp=14.111, rec=0.610, cos=0.014), tot_loss_proj:4.483 [t=0.27s]
prediction: ['[CLS]phobiazenzen zealand growing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.196 (perp=12.972, rec=0.598, cos=0.004), tot_loss_proj:4.564 [t=0.26s]
prediction: ['[CLS]phobiazen zealandzenı [SEP]']
[ 300/2000] tot_loss=3.179 (perp=12.972, rec=0.580, cos=0.004), tot_loss_proj:4.560 [t=0.25s]
prediction: ['[CLS]phobiazen zealandzenı [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.946 (perp=11.906, rec=0.563, cos=0.002), tot_loss_proj:3.932 [t=0.26s]
prediction: ['[CLS] wisezen zealandzenı [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.949 (perp=11.906, rec=0.559, cos=0.009), tot_loss_proj:3.941 [t=0.26s]
prediction: ['[CLS] wisezen zealandzenı [SEP]']
[ 450/2000] tot_loss=3.191 (perp=13.170, rec=0.553, cos=0.005), tot_loss_proj:4.181 [t=0.27s]
prediction: ['[CLS] wisezenheardzen wi [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.757 (perp=10.999, rec=0.556, cos=0.001), tot_loss_proj:3.468 [t=0.26s]
prediction: ['[CLS] wisezenheard wizen [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.739 (perp=10.999, rec=0.538, cos=0.001), tot_loss_proj:3.477 [t=0.25s]
prediction: ['[CLS] wisezenheard wizen [SEP]']
[ 600/2000] tot_loss=2.701 (perp=10.746, rec=0.543, cos=0.009), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.683 (perp=10.746, rec=0.528, cos=0.005), tot_loss_proj:3.359 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.680 (perp=10.746, rec=0.522, cos=0.008), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[ 750/2000] tot_loss=2.701 (perp=10.746, rec=0.542, cos=0.009), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.669 (perp=10.746, rec=0.519, cos=0.000), tot_loss_proj:3.355 [t=0.27s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.665 (perp=10.746, rec=0.515, cos=0.001), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[ 900/2000] tot_loss=2.665 (perp=10.746, rec=0.514, cos=0.002), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.658 (perp=10.746, rec=0.507, cos=0.002), tot_loss_proj:3.362 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1000/2000] tot_loss=2.663 (perp=10.746, rec=0.512, cos=0.001), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1050/2000] tot_loss=2.669 (perp=10.746, rec=0.517, cos=0.003), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1100/2000] tot_loss=2.655 (perp=10.746, rec=0.505, cos=0.000), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1150/2000] tot_loss=2.651 (perp=10.746, rec=0.501, cos=0.000), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1200/2000] tot_loss=2.655 (perp=10.746, rec=0.506, cos=0.000), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1250/2000] tot_loss=2.652 (perp=10.746, rec=0.502, cos=0.000), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1300/2000] tot_loss=2.662 (perp=10.746, rec=0.507, cos=0.006), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1350/2000] tot_loss=2.658 (perp=10.746, rec=0.508, cos=0.000), tot_loss_proj:3.357 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1400/2000] tot_loss=2.649 (perp=10.746, rec=0.500, cos=0.000), tot_loss_proj:3.357 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1450/2000] tot_loss=2.654 (perp=10.746, rec=0.505, cos=0.000), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1500/2000] tot_loss=2.649 (perp=10.746, rec=0.500, cos=0.000), tot_loss_proj:3.354 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1550/2000] tot_loss=2.653 (perp=10.746, rec=0.504, cos=0.000), tot_loss_proj:3.363 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1600/2000] tot_loss=2.646 (perp=10.746, rec=0.497, cos=0.000), tot_loss_proj:3.357 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1650/2000] tot_loss=2.646 (perp=10.746, rec=0.497, cos=0.000), tot_loss_proj:3.353 [t=0.27s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1700/2000] tot_loss=2.652 (perp=10.746, rec=0.502, cos=0.000), tot_loss_proj:3.359 [t=0.26s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1750/2000] tot_loss=2.647 (perp=10.746, rec=0.498, cos=0.000), tot_loss_proj:3.358 [t=0.28s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1800/2000] tot_loss=2.648 (perp=10.746, rec=0.498, cos=0.000), tot_loss_proj:3.358 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1850/2000] tot_loss=2.651 (perp=10.746, rec=0.501, cos=0.000), tot_loss_proj:3.360 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[1900/2000] tot_loss=2.643 (perp=10.746, rec=0.494, cos=0.000), tot_loss_proj:3.362 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
[1950/2000] tot_loss=2.651 (perp=10.746, rec=0.501, cos=0.000), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Attempt swap
[2000/2000] tot_loss=2.649 (perp=10.746, rec=0.500, cos=0.000), tot_loss_proj:3.363 [t=0.25s]
prediction: ['[CLS] wisezencene wizen [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wisezencene wizen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 88.155 | p: 87.868 | r: 88.623
rouge2     | fm: 51.907 | p: 51.759 | r: 52.061
rougeL     | fm: 75.228 | p: 74.972 | r: 75.657
rougeLsum  | fm: 75.357 | p: 75.041 | r: 75.811
r1fm+r2fm = 140.062

input #80 time: 0:10:59 | total time: 13:54:03


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
*********************************
*********************************
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 1.8443113565444946 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 1.8287549018859863 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 1.5750724077224731 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 1.536523699760437 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 1.4952508211135864 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 1.3897989988327026 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 1.3871291875839233 for ['[CLS] mass seeneer off joe đ [SEP]']
[Init] best rec loss: 1.3777071237564087 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 1.3360694646835327 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 1.2880840301513672 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 1.2849894762039185 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 1.2837177515029907 for ['[CLS] donaldson ivydownvikplate proceeded [SEP]']
[Init] best perm rec loss: 1.282072901725769 for ['[CLS]downplate donaldson proceeded ivyvik [SEP]']
[Init] best perm rec loss: 1.28199303150177 for ['[CLS]vik proceeded donaldson ivydownplate [SEP]']
[Init] best perm rec loss: 1.278752326965332 for ['[CLS] donaldson ivydown proceededplatevik [SEP]']
[Init] best perm rec loss: 1.2762550115585327 for ['[CLS] donaldsondownvik proceeded ivyplate [SEP]']
[Init] best perm rec loss: 1.2757786512374878 for ['[CLS] donaldson proceededdownplate ivyvik [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.138 (perp=13.274, rec=0.476, cos=0.007), tot_loss_proj:3.787 [t=0.25s]
prediction: ['[CLS] unfair wrong beating holy stadium tony [SEP]']
[ 100/2000] tot_loss=2.688 (perp=11.629, rec=0.358, cos=0.005), tot_loss_proj:3.453 [t=0.26s]
prediction: ['[CLS] unfair not worst includes footballer bishop [SEP]']
[ 150/2000] tot_loss=2.562 (perp=11.402, rec=0.274, cos=0.008), tot_loss_proj:3.271 [t=0.27s]
prediction: ['[CLS] was not player widespread impressive bishop [SEP]']
[ 200/2000] tot_loss=2.083 (perp=9.499, rec=0.180, cos=0.003), tot_loss_proj:3.407 [t=0.26s]
prediction: ['[CLS] is not player most impressive bishop [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.753 (perp=8.075, rec=0.136, cos=0.003), tot_loss_proj:2.260 [t=0.26s]
prediction: ['[CLS] player is not most impressive i [SEP]']
[ 300/2000] tot_loss=1.723 (perp=8.075, rec=0.107, cos=0.001), tot_loss_proj:2.267 [t=0.26s]
prediction: ['[CLS] player is not most impressive i [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.540 (perp=7.162, rec=0.106, cos=0.001), tot_loss_proj:2.080 [t=0.26s]
prediction: ['[CLS] i player is not most impressive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.539 (perp=7.162, rec=0.106, cos=0.001), tot_loss_proj:2.079 [t=0.25s]
prediction: ['[CLS] i player is not most impressive [SEP]']
[ 450/2000] tot_loss=1.534 (perp=7.162, rec=0.101, cos=0.001), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] i player is not most impressive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.655 (perp=7.789, rec=0.096, cos=0.001), tot_loss_proj:2.358 [t=0.25s]
prediction: ['[CLS] player player is not most impressive [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.611 (perp=7.545, rec=0.101, cos=0.001), tot_loss_proj:2.282 [t=0.26s]
prediction: ['[CLS] player is player not most impressive [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.545, rec=0.086, cos=0.001), tot_loss_proj:2.288 [t=0.25s]
prediction: ['[CLS] player is player not most impressive [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.505 (perp=7.037, rec=0.097, cos=0.001), tot_loss_proj:3.230 [t=0.26s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.037, rec=0.093, cos=0.001), tot_loss_proj:3.234 [t=0.25s]
prediction: ['[CLS] player not player is most impressive [SEP]']
[ 750/2000] tot_loss=1.768 (perp=8.443, rec=0.079, cos=0.001), tot_loss_proj:3.517 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.782 (perp=8.443, rec=0.093, cos=0.001), tot_loss_proj:3.519 [t=0.26s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.789 (perp=8.443, rec=0.100, cos=0.001), tot_loss_proj:3.517 [t=0.26s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
[ 900/2000] tot_loss=1.774 (perp=8.443, rec=0.084, cos=0.001), tot_loss_proj:3.526 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.786 (perp=8.443, rec=0.096, cos=0.001), tot_loss_proj:3.519 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.780 (perp=8.443, rec=0.091, cos=0.001), tot_loss_proj:3.521 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
[1050/2000] tot_loss=1.789 (perp=8.443, rec=0.099, cos=0.001), tot_loss_proj:3.521 [t=0.26s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.799 (perp=8.583, rec=0.082, cos=0.001), tot_loss_proj:3.507 [t=0.25s]
prediction: ['[CLS] idle not player is most impressive [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.870 (perp=8.808, rec=0.107, cos=0.002), tot_loss_proj:3.587 [t=0.26s]
prediction: ['[CLS] not turbo player is most impressive [SEP]']
[1200/2000] tot_loss=1.394 (perp=6.481, rec=0.097, cos=0.001), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] not the player is most impressive [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.044 (perp=9.809, rec=0.081, cos=0.001), tot_loss_proj:3.699 [t=0.26s]
prediction: ['[CLS] not player is turbo most impressive [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.775 (perp=8.443, rec=0.086, cos=0.001), tot_loss_proj:3.519 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
[1350/2000] tot_loss=1.779 (perp=8.443, rec=0.089, cos=0.001), tot_loss_proj:3.522 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.777 (perp=8.443, rec=0.088, cos=0.001), tot_loss_proj:3.520 [t=0.26s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.773 (perp=8.443, rec=0.084, cos=0.001), tot_loss_proj:3.524 [t=0.25s]
prediction: ['[CLS] turbo not player is most impressive [SEP]']
[1500/2000] tot_loss=1.813 (perp=8.583, rec=0.096, cos=0.001), tot_loss_proj:3.509 [t=0.28s]
prediction: ['[CLS] idle not player is most impressive [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.733 (perp=8.246, rec=0.083, cos=0.001), tot_loss_proj:3.388 [t=0.26s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.748 (perp=8.246, rec=0.098, cos=0.001), tot_loss_proj:3.383 [t=0.25s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
[1650/2000] tot_loss=1.737 (perp=8.246, rec=0.087, cos=0.001), tot_loss_proj:3.387 [t=0.27s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.246, rec=0.093, cos=0.001), tot_loss_proj:3.384 [t=0.26s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.750 (perp=8.246, rec=0.100, cos=0.001), tot_loss_proj:3.390 [t=0.27s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
[1800/2000] tot_loss=1.747 (perp=8.246, rec=0.097, cos=0.001), tot_loss_proj:3.385 [t=0.27s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.737 (perp=8.246, rec=0.087, cos=0.001), tot_loss_proj:3.389 [t=0.27s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.739 (perp=8.246, rec=0.089, cos=0.001), tot_loss_proj:3.382 [t=0.27s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
[1950/2000] tot_loss=1.740 (perp=8.246, rec=0.090, cos=0.001), tot_loss_proj:3.387 [t=0.25s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.737 (perp=8.246, rec=0.087, cos=0.001), tot_loss_proj:3.387 [t=0.26s]
prediction: ['[CLS] not idle player is most impressive [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] not idle player is most impressive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 101.786

[Aggregate metrics]:
rouge1     | fm: 88.037 | p: 87.749 | r: 88.530
rouge2     | fm: 51.521 | p: 51.393 | r: 51.649
rougeL     | fm: 75.120 | p: 74.857 | r: 75.482
rougeLsum  | fm: 75.285 | p: 75.005 | r: 75.755
r1fm+r2fm = 139.558

input #81 time: 0:11:00 | total time: 14:05:04


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
*********************************
*********************************
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 1.9474414587020874 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 1.835921287536621 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 1.7372323274612427 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 1.6888108253479004 for ['[CLS] maltaierif ace players reserve hmm rpm [SEP]']
[Init] best rec loss: 1.6774872541427612 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 1.4888206720352173 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 1.3586682081222534 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 1.3419948816299438 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 1.3394792079925537 for ['[CLS]basket respective whoever role plumagefurach record [SEP]']
[Init] best perm rec loss: 1.3392287492752075 for ['[CLS]achbasket record role respectivefur plumage whoever [SEP]']
[Init] best perm rec loss: 1.3361918926239014 for ['[CLS]basket record whoever rolefur respectiveach plumage [SEP]']
[Init] best perm rec loss: 1.3317865133285522 for ['[CLS]basketfur whoever respective role plumage recordach [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.896, rec=0.288, cos=0.003), tot_loss_proj:3.177 [t=0.26s]
prediction: ['[CLS] undone sloppy campus are plain plateyard undone [SEP]']
[ 100/2000] tot_loss=2.024 (perp=9.168, rec=0.189, cos=0.002), tot_loss_proj:2.456 [t=0.25s]
prediction: ['[CLS] undone script it are a sloppy script undone [SEP]']
[ 150/2000] tot_loss=1.970 (perp=9.226, rec=0.123, cos=0.002), tot_loss_proj:2.299 [t=0.26s]
prediction: ['[CLS] undone script it by a sloppy script undone [SEP]']
[ 200/2000] tot_loss=2.204 (perp=10.488, rec=0.105, cos=0.001), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] sloppy script s by a sloppy script undone [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.883 (perp=8.924, rec=0.097, cos=0.001), tot_loss_proj:2.195 [t=0.25s]
prediction: ['[CLS] s sloppy script by a sloppy script undone [SEP]']
[ 300/2000] tot_loss=1.872 (perp=8.924, rec=0.086, cos=0.001), tot_loss_proj:2.200 [t=0.25s]
prediction: ['[CLS] s sloppy script by a sloppy script undone [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.574 (perp=7.464, rec=0.081, cos=0.001), tot_loss_proj:1.829 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.579 (perp=7.464, rec=0.085, cos=0.001), tot_loss_proj:1.825 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[ 450/2000] tot_loss=1.566 (perp=7.464, rec=0.072, cos=0.001), tot_loss_proj:1.825 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.567 (perp=7.464, rec=0.073, cos=0.001), tot_loss_proj:1.823 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.573 (perp=7.464, rec=0.080, cos=0.001), tot_loss_proj:1.819 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[ 600/2000] tot_loss=1.575 (perp=7.464, rec=0.081, cos=0.001), tot_loss_proj:1.826 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.567 (perp=7.464, rec=0.073, cos=0.001), tot_loss_proj:1.819 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.559 (perp=7.464, rec=0.065, cos=0.001), tot_loss_proj:1.828 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[ 750/2000] tot_loss=1.565 (perp=7.464, rec=0.071, cos=0.001), tot_loss_proj:1.832 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.573 (perp=7.464, rec=0.080, cos=0.001), tot_loss_proj:1.824 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.555 (perp=7.464, rec=0.061, cos=0.001), tot_loss_proj:1.819 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[ 900/2000] tot_loss=1.564 (perp=7.464, rec=0.070, cos=0.001), tot_loss_proj:1.826 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.565 (perp=7.464, rec=0.072, cos=0.001), tot_loss_proj:1.824 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.562 (perp=7.464, rec=0.068, cos=0.001), tot_loss_proj:1.826 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1050/2000] tot_loss=1.571 (perp=7.464, rec=0.077, cos=0.001), tot_loss_proj:1.821 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.566 (perp=7.464, rec=0.073, cos=0.001), tot_loss_proj:1.823 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.577 (perp=7.464, rec=0.084, cos=0.001), tot_loss_proj:1.830 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1200/2000] tot_loss=1.566 (perp=7.464, rec=0.072, cos=0.001), tot_loss_proj:1.817 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.561 (perp=7.464, rec=0.068, cos=0.001), tot_loss_proj:1.818 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.464, rec=0.070, cos=0.001), tot_loss_proj:1.819 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1350/2000] tot_loss=1.568 (perp=7.464, rec=0.075, cos=0.001), tot_loss_proj:1.824 [t=0.25s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.564 (perp=7.464, rec=0.071, cos=0.001), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.560 (perp=7.464, rec=0.067, cos=0.001), tot_loss_proj:1.826 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1500/2000] tot_loss=1.555 (perp=7.464, rec=0.061, cos=0.001), tot_loss_proj:1.826 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.464, rec=0.065, cos=0.001), tot_loss_proj:1.816 [t=0.28s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.563 (perp=7.464, rec=0.070, cos=0.001), tot_loss_proj:1.827 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1650/2000] tot_loss=1.555 (perp=7.464, rec=0.062, cos=0.001), tot_loss_proj:1.820 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.563 (perp=7.464, rec=0.070, cos=0.001), tot_loss_proj:1.817 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1750/2000] tot_loss=1.552 (perp=7.464, rec=0.059, cos=0.001), tot_loss_proj:1.821 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1800/2000] tot_loss=1.562 (perp=7.464, rec=0.068, cos=0.001), tot_loss_proj:1.823 [t=0.28s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1850/2000] tot_loss=1.553 (perp=7.464, rec=0.059, cos=0.001), tot_loss_proj:1.832 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.555 (perp=7.464, rec=0.062, cos=0.001), tot_loss_proj:1.818 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.464, rec=0.063, cos=0.001), tot_loss_proj:1.823 [t=0.27s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.464, rec=0.064, cos=0.001), tot_loss_proj:1.821 [t=0.26s]
prediction: ['[CLS] s sloppy script undone by a sloppy script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] s sloppy script undone by a sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 143.034

[Aggregate metrics]:
rouge1     | fm: 88.044 | p: 87.655 | r: 88.537
rouge2     | fm: 51.770 | p: 51.587 | r: 51.952
rougeL     | fm: 75.237 | p: 74.874 | r: 75.704
rougeLsum  | fm: 75.295 | p: 74.941 | r: 75.794
r1fm+r2fm = 139.815

input #82 time: 0:11:04 | total time: 14:16:09


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
*********************************
*********************************
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 1.8980540037155151 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 1.8680791854858398 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 1.8268553018569946 for ['[CLS] expressing congratulations butch evacuate copyright grenadasome snow paid confidence [SEP]']
[Init] best rec loss: 1.7807674407958984 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 1.6598609685897827 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 1.5194369554519653 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best perm rec loss: 1.515126347541809 for ['[CLS] hit already use £ benji runaway mercy wild publishing someone [SEP]']
[Init] best perm rec loss: 1.506394386291504 for ['[CLS] already £ publishing use hit mercy someone wild benji runaway [SEP]']
[Init] best perm rec loss: 1.5047065019607544 for ['[CLS] hit £ already publishing use mercy someone runaway wild benji [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.678 (perp=11.205, rec=0.418, cos=0.019), tot_loss_proj:3.254 [t=0.27s]
prediction: ['[CLS] what rise described seen it power musical of value international [SEP]']
[ 100/2000] tot_loss=2.143 (perp=9.198, rec=0.299, cos=0.004), tot_loss_proj:2.911 [t=0.26s]
prediction: ['[CLS] know what found seen it power when when something of [SEP]']
[ 150/2000] tot_loss=2.077 (perp=9.240, rec=0.228, cos=0.001), tot_loss_proj:3.548 [t=0.26s]
prediction: ['[CLS] know what ] seen it development when when because up [SEP]']
[ 200/2000] tot_loss=2.132 (perp=9.733, rec=0.185, cos=0.001), tot_loss_proj:2.549 [t=0.26s]
prediction: ['[CLS] know what grows grows it development be when grows up [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.636 (perp=7.130, rec=0.207, cos=0.003), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] know what they grow life grow when it grow up [SEP]']
[ 300/2000] tot_loss=1.769 (perp=8.022, rec=0.163, cos=0.001), tot_loss_proj:2.310 [t=0.27s]
prediction: ['[CLS] know what they he be grows when it grow up [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.466 (perp=6.546, rec=0.156, cos=0.001), tot_loss_proj:2.066 [t=0.26s]
prediction: ['[CLS] he know what it be grows when it grows up [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.459 (perp=6.546, rec=0.149, cos=0.001), tot_loss_proj:2.066 [t=0.25s]
prediction: ['[CLS] he know what it be grows when it grows up [SEP]']
[ 450/2000] tot_loss=1.496 (perp=6.859, rec=0.123, cos=0.001), tot_loss_proj:2.321 [t=0.26s]
prediction: ['[CLS] could know what it be grows when it grows up [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.413 (perp=6.433, rec=0.126, cos=0.001), tot_loss_proj:1.951 [t=0.25s]
prediction: ['[CLS] know what it could be grows when it grows up [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.306 (perp=5.888, rec=0.127, cos=0.001), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
[ 600/2000] tot_loss=1.304 (perp=5.888, rec=0.125, cos=0.001), tot_loss_proj:2.004 [t=0.28s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.294 (perp=5.888, rec=0.116, cos=0.001), tot_loss_proj:1.998 [t=0.27s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.296 (perp=5.888, rec=0.117, cos=0.001), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
[ 750/2000] tot_loss=1.280 (perp=5.888, rec=0.101, cos=0.001), tot_loss_proj:1.998 [t=0.24s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.282 (perp=5.888, rec=0.104, cos=0.001), tot_loss_proj:2.004 [t=0.26s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.282 (perp=5.888, rec=0.104, cos=0.001), tot_loss_proj:2.004 [t=0.26s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
[ 900/2000] tot_loss=1.284 (perp=5.888, rec=0.106, cos=0.001), tot_loss_proj:1.996 [t=0.26s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.295 (perp=5.888, rec=0.116, cos=0.001), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.287 (perp=5.888, rec=0.109, cos=0.001), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
[1050/2000] tot_loss=1.277 (perp=5.888, rec=0.099, cos=0.001), tot_loss_proj:1.991 [t=0.25s]
prediction: ['[CLS] grows know what it could be when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.747 (perp=8.218, rec=0.103, cos=0.001), tot_loss_proj:2.366 [t=0.26s]
prediction: ['[CLS] grows know wants it wants be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.601 (perp=7.450, rec=0.110, cos=0.001), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] grows what know it wants be when it grows up [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.504, rec=0.105, cos=0.001), tot_loss_proj:2.364 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.596 (perp=7.504, rec=0.095, cos=0.001), tot_loss_proj:2.360 [t=0.27s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=7.504, rec=0.101, cos=0.001), tot_loss_proj:2.359 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
[1350/2000] tot_loss=1.601 (perp=7.504, rec=0.100, cos=0.001), tot_loss_proj:2.360 [t=0.25s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.601 (perp=7.504, rec=0.099, cos=0.001), tot_loss_proj:2.351 [t=0.25s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.613 (perp=7.504, rec=0.112, cos=0.001), tot_loss_proj:2.360 [t=0.25s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
[1500/2000] tot_loss=1.607 (perp=7.504, rec=0.105, cos=0.001), tot_loss_proj:2.357 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.602 (perp=7.504, rec=0.101, cos=0.001), tot_loss_proj:2.367 [t=0.27s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.602 (perp=7.504, rec=0.101, cos=0.001), tot_loss_proj:2.355 [t=0.25s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
[1650/2000] tot_loss=1.611 (perp=7.504, rec=0.110, cos=0.001), tot_loss_proj:2.362 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.504, rec=0.095, cos=0.001), tot_loss_proj:2.354 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.602 (perp=7.504, rec=0.101, cos=0.001), tot_loss_proj:2.356 [t=0.28s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
[1800/2000] tot_loss=1.601 (perp=7.504, rec=0.100, cos=0.001), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.603 (perp=7.504, rec=0.102, cos=0.001), tot_loss_proj:2.352 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.607 (perp=7.504, rec=0.106, cos=0.001), tot_loss_proj:2.357 [t=0.25s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
[1950/2000] tot_loss=1.604 (perp=7.504, rec=0.102, cos=0.001), tot_loss_proj:2.355 [t=0.26s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.606 (perp=7.504, rec=0.105, cos=0.001), tot_loss_proj:2.361 [t=0.25s]
prediction: ['[CLS] grows wants know it wants be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] grows wants know it wants be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 137.879

[Aggregate metrics]:
rouge1     | fm: 88.049 | p: 87.648 | r: 88.589
rouge2     | fm: 51.561 | p: 51.374 | r: 51.793
rougeL     | fm: 75.400 | p: 75.103 | r: 75.792
rougeLsum  | fm: 75.282 | p: 74.938 | r: 75.787
r1fm+r2fm = 139.610

input #83 time: 0:10:59 | total time: 14:27:08


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
*********************************
*********************************
average of cosine similarity 0.9991125724774639
highest_index [0]
highest [0.9991125724774639]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 1.8125368356704712 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 1.8119263648986816 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 1.7110885381698608 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 1.5840494632720947 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 1.5825172662734985 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 1.5593494176864624 for ['[CLS] gmina standingply italian sessionhelm towards [SEP]']
[Init] best rec loss: 1.5217680931091309 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 1.477038025856018 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 1.4265689849853516 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 1.3894094228744507 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 1.3838614225387573 for ['[CLS] tradition captaindock seats [SEP] easier seas [SEP]']
[Init] best perm rec loss: 1.3745696544647217 for ['[CLS]dock tradition seas [SEP] seats captain easier [SEP]']
[Init] best perm rec loss: 1.3726637363433838 for ['[CLS]dock easier tradition captain seats [SEP] seas [SEP]']
[Init] best perm rec loss: 1.3407255411148071 for ['[CLS]dock seas captain tradition [SEP] easier seats [SEP]']
[Init] best perm rec loss: 1.3394502401351929 for ['[CLS]dock [SEP] captain easier seas tradition seats [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.047 (perp=8.664, rec=0.309, cos=0.005), tot_loss_proj:2.534 [t=0.26s]
prediction: ['[CLS] people. to lost him ability lost [SEP]']
[ 100/2000] tot_loss=1.882 (perp=8.331, rec=0.213, cos=0.003), tot_loss_proj:2.278 [t=0.27s]
prediction: ['[CLS] people have ability lost all ability lost [SEP]']
[ 150/2000] tot_loss=2.149 (perp=10.009, rec=0.144, cos=0.003), tot_loss_proj:2.655 [t=0.26s]
prediction: ['[CLS] people have ability lost the think lost [SEP]']
[ 200/2000] tot_loss=2.108 (perp=10.009, rec=0.105, cos=0.001), tot_loss_proj:2.648 [t=0.28s]
prediction: ['[CLS] people have ability lost the think lost [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.600 (perp=7.545, rec=0.089, cos=0.002), tot_loss_proj:1.991 [t=0.25s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
[ 300/2000] tot_loss=1.592 (perp=7.545, rec=0.082, cos=0.001), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.565 (perp=7.432, rec=0.077, cos=0.001), tot_loss_proj:1.853 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.565 (perp=7.432, rec=0.077, cos=0.001), tot_loss_proj:1.860 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 450/2000] tot_loss=1.567 (perp=7.432, rec=0.080, cos=0.001), tot_loss_proj:1.844 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.566 (perp=7.432, rec=0.079, cos=0.001), tot_loss_proj:1.846 [t=0.24s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.567 (perp=7.432, rec=0.080, cos=0.001), tot_loss_proj:1.861 [t=0.27s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 600/2000] tot_loss=1.559 (perp=7.432, rec=0.072, cos=0.001), tot_loss_proj:1.850 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=7.432, rec=0.077, cos=0.001), tot_loss_proj:1.851 [t=0.27s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.567 (perp=7.432, rec=0.080, cos=0.001), tot_loss_proj:1.849 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 750/2000] tot_loss=1.564 (perp=7.432, rec=0.077, cos=0.001), tot_loss_proj:1.854 [t=0.27s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.562 (perp=7.432, rec=0.075, cos=0.001), tot_loss_proj:1.832 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.551 (perp=7.432, rec=0.064, cos=0.001), tot_loss_proj:1.842 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 900/2000] tot_loss=1.567 (perp=7.432, rec=0.079, cos=0.001), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.557 (perp=7.432, rec=0.070, cos=0.001), tot_loss_proj:1.842 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.567 (perp=7.432, rec=0.079, cos=0.001), tot_loss_proj:1.849 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1050/2000] tot_loss=1.559 (perp=7.432, rec=0.071, cos=0.001), tot_loss_proj:1.842 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.562 (perp=7.432, rec=0.075, cos=0.001), tot_loss_proj:1.834 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.570 (perp=7.432, rec=0.083, cos=0.001), tot_loss_proj:1.839 [t=0.28s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1200/2000] tot_loss=1.562 (perp=7.432, rec=0.075, cos=0.001), tot_loss_proj:1.841 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.576 (perp=7.432, rec=0.089, cos=0.001), tot_loss_proj:1.846 [t=0.27s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.556 (perp=7.432, rec=0.069, cos=0.001), tot_loss_proj:1.833 [t=0.27s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1350/2000] tot_loss=1.570 (perp=7.432, rec=0.082, cos=0.001), tot_loss_proj:1.842 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.559 (perp=7.432, rec=0.072, cos=0.001), tot_loss_proj:1.832 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.556 (perp=7.432, rec=0.068, cos=0.001), tot_loss_proj:1.841 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1500/2000] tot_loss=1.561 (perp=7.432, rec=0.073, cos=0.001), tot_loss_proj:1.836 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.432, rec=0.071, cos=0.001), tot_loss_proj:1.835 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.562 (perp=7.432, rec=0.075, cos=0.001), tot_loss_proj:1.829 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1650/2000] tot_loss=1.558 (perp=7.432, rec=0.070, cos=0.001), tot_loss_proj:1.836 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.568 (perp=7.432, rec=0.081, cos=0.001), tot_loss_proj:1.836 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.561 (perp=7.432, rec=0.073, cos=0.001), tot_loss_proj:1.838 [t=0.28s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1800/2000] tot_loss=1.546 (perp=7.432, rec=0.059, cos=0.001), tot_loss_proj:1.844 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.552 (perp=7.432, rec=0.065, cos=0.001), tot_loss_proj:1.843 [t=0.25s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.561 (perp=7.432, rec=0.073, cos=0.001), tot_loss_proj:1.834 [t=0.27s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.432, rec=0.078, cos=0.001), tot_loss_proj:1.836 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.432, rec=0.069, cos=0.001), tot_loss_proj:1.835 [t=0.26s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the lost ability think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 88.026 | p: 87.672 | r: 88.556
rouge2     | fm: 51.672 | p: 51.517 | r: 51.863
rougeL     | fm: 75.558 | p: 75.252 | r: 75.948
rougeLsum  | fm: 75.546 | p: 75.222 | r: 76.030
r1fm+r2fm = 139.697

input #84 time: 0:10:58 | total time: 14:38:07


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
*********************************
*********************************
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 1.9611685276031494 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 1.8875846862792969 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 1.7836694717407227 for ['[CLS] avoiding broadcast improved tuned plenty chancellor pet won littleros [SEP]']
[Init] best rec loss: 1.7814399003982544 for ['[CLS] brakeship and acronym senate developing technical leadrine reserve [SEP]']
[Init] best rec loss: 1.7765181064605713 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 1.6346447467803955 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 1.5155413150787354 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 1.44791841506958 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best rec loss: 1.3985786437988281 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best perm rec loss: 1.3900498151779175 for ['[CLS] challenging graf josephine dad haven graduation young overly nord blank [SEP]']
[Init] best perm rec loss: 1.3897099494934082 for ['[CLS] young josephine overly dad graduation challenging blank haven nord graf [SEP]']
[Init] best perm rec loss: 1.3883607387542725 for ['[CLS] young graf josephine nord haven challenging dad overly blank graduation [SEP]']
[Init] best perm rec loss: 1.3878798484802246 for ['[CLS] young graf nord graduation josephine blank dad overly challenging haven [SEP]']
[Init] best perm rec loss: 1.387863039970398 for ['[CLS] blank haven josephine young dad graf nord overly graduation challenging [SEP]']
[Init] best perm rec loss: 1.3863424062728882 for ['[CLS] graduation haven nord josephine dad young challenging overly graf blank [SEP]']
[Init] best perm rec loss: 1.3851666450500488 for ['[CLS] young graf challenging nord graduation overly haven josephine dad blank [SEP]']
[Init] best perm rec loss: 1.384523630142212 for ['[CLS] young blank josephine nord graduation dad challenging overly graf haven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.563 (perp=10.814, rec=0.396, cos=0.004), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] least. unfortunately off unfortunately glass bug badly system unfortunately [SEP]']
[ 100/2000] tot_loss=2.466 (perp=10.895, rec=0.283, cos=0.005), tot_loss_proj:3.469 [t=0.27s]
prediction: ['[CLS] unfortunately not unfortunately sort unfortunately glass bad problem fortunately not [SEP]']
[ 150/2000] tot_loss=2.294 (perp=10.453, rec=0.202, cos=0.002), tot_loss_proj:3.316 [t=0.27s]
prediction: ['[CLS] unfortunately not also looking unfortunately willow good bad good not [SEP]']
[ 200/2000] tot_loss=1.574 (perp=7.182, rec=0.137, cos=0.001), tot_loss_proj:3.379 [t=0.26s]
prediction: ["[CLS] unfortunately not also it's good break good very [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.019 (perp=9.538, rec=0.110, cos=0.001), tot_loss_proj:3.816 [t=0.26s]
prediction: ["[CLS] unfortunately not also s 'ety good very good break [SEP]"]
[ 300/2000] tot_loss=1.645 (perp=7.644, rec=0.116, cos=0.001), tot_loss_proj:3.487 [t=0.26s]
prediction: ["[CLS] unfortunately not also s's good very good band [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.533 (perp=7.114, rec=0.109, cos=0.001), tot_loss_proj:1.916 [t=0.27s]
prediction: ["[CLS] unfortunately all also s's not very good band [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.681 (perp=7.849, rec=0.110, cos=0.001), tot_loss_proj:2.150 [t=0.27s]
prediction: ["[CLS] unfortunately all also'it - not very good band [SEP]"]
[ 450/2000] tot_loss=1.519 (perp=7.095, rec=0.099, cos=0.001), tot_loss_proj:1.929 [t=0.27s]
prediction: ["[CLS] unfortunately all also's - not very good band [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.413 (perp=6.515, rec=0.109, cos=0.001), tot_loss_proj:1.841 [t=0.29s]
prediction: ["[CLS] unfortunately also's all - not very good band [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.531 (perp=7.104, rec=0.109, cos=0.001), tot_loss_proj:1.917 [t=0.26s]
prediction: ["[CLS] unfortunately also's all not very good t th [SEP]"]
[ 600/2000] tot_loss=1.452 (perp=6.765, rec=0.099, cos=0.001), tot_loss_proj:1.868 [t=0.25s]
prediction: ["[CLS] unfortunately also's all not very good t which [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.407 (perp=6.525, rec=0.101, cos=0.001), tot_loss_proj:1.844 [t=0.25s]
prediction: ["[CLS] unfortunately also's all not very good band which [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.390 (perp=6.504, rec=0.088, cos=0.001), tot_loss_proj:1.819 [t=0.25s]
prediction: ["[CLS] unfortunately also's all not very good which band [SEP]"]
[ 750/2000] tot_loss=1.401 (perp=6.504, rec=0.099, cos=0.001), tot_loss_proj:1.824 [t=0.24s]
prediction: ["[CLS] unfortunately also's all not very good which band [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.319 (perp=6.098, rec=0.099, cos=0.001), tot_loss_proj:1.720 [t=0.25s]
prediction: ["[CLS] unfortunately also's not all very good - band [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.286 (perp=5.928, rec=0.100, cos=0.001), tot_loss_proj:1.749 [t=0.25s]
prediction: ["[CLS] unfortunately also's not all very good band - [SEP]"]
[ 900/2000] tot_loss=1.283 (perp=5.928, rec=0.097, cos=0.001), tot_loss_proj:1.748 [t=0.26s]
prediction: ["[CLS] unfortunately also's not all very good band - [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.255 (perp=5.800, rec=0.094, cos=0.001), tot_loss_proj:1.678 [t=0.25s]
prediction: ["[CLS] unfortunately's also not all very good band - [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.237 (perp=5.665, rec=0.103, cos=0.001), tot_loss_proj:1.669 [t=0.27s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
[1050/2000] tot_loss=1.236 (perp=5.665, rec=0.103, cos=0.001), tot_loss_proj:1.661 [t=0.26s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.220 (perp=5.665, rec=0.087, cos=0.001), tot_loss_proj:1.669 [t=0.26s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.220 (perp=5.665, rec=0.086, cos=0.001), tot_loss_proj:1.669 [t=0.26s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
[1200/2000] tot_loss=1.227 (perp=5.665, rec=0.094, cos=0.001), tot_loss_proj:1.667 [t=0.25s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.237 (perp=5.665, rec=0.103, cos=0.001), tot_loss_proj:1.660 [t=0.25s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.227 (perp=5.665, rec=0.093, cos=0.001), tot_loss_proj:1.670 [t=0.26s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
[1350/2000] tot_loss=1.230 (perp=5.665, rec=0.096, cos=0.001), tot_loss_proj:1.676 [t=0.26s]
prediction: ["[CLS] unfortunately's also not all very good band, [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.203 (perp=5.527, rec=0.096, cos=0.001), tot_loss_proj:1.534 [t=0.25s]
prediction: ["[CLS] unfortunately's also not all very good s, [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.168 (perp=5.337, rec=0.100, cos=0.001), tot_loss_proj:1.467 [t=0.26s]
prediction: ["[CLS] unfortunately's also not all very good, s [SEP]"]
[1500/2000] tot_loss=1.162 (perp=5.337, rec=0.094, cos=0.001), tot_loss_proj:1.464 [t=0.24s]
prediction: ["[CLS] unfortunately's also not all very good, s [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.158 (perp=5.337, rec=0.090, cos=0.001), tot_loss_proj:1.474 [t=0.25s]
prediction: ["[CLS] unfortunately's also not all very good, s [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.166 (perp=5.337, rec=0.098, cos=0.001), tot_loss_proj:1.467 [t=0.25s]
prediction: ["[CLS] unfortunately's also not all very good, s [SEP]"]
[1650/2000] tot_loss=1.349 (perp=6.289, rec=0.090, cos=0.001), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] unfortunately. s also not all very good, s [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.294 (perp=5.947, rec=0.104, cos=0.001), tot_loss_proj:1.641 [t=0.25s]
prediction: ["[CLS] unfortunately, s also not all very good's [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.356 (perp=6.289, rec=0.097, cos=0.001), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] unfortunately. s also not all very good, s [SEP]']
[1800/2000] tot_loss=1.358 (perp=6.289, rec=0.099, cos=0.001), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] unfortunately. s also not all very good, s [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.249 (perp=5.809, rec=0.087, cos=0.001), tot_loss_proj:1.596 [t=0.26s]
prediction: ['[CLS] unfortunately, s also not all very good. s [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.201 (perp=5.514, rec=0.097, cos=0.001), tot_loss_proj:1.505 [t=0.27s]
prediction: ['[CLS] unfortunately, s also s not all very good. [SEP]']
[1950/2000] tot_loss=1.202 (perp=5.514, rec=0.098, cos=0.001), tot_loss_proj:1.511 [t=0.27s]
prediction: ['[CLS] unfortunately, s also s not all very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.201 (perp=5.514, rec=0.098, cos=0.001), tot_loss_proj:1.502 [t=0.25s]
prediction: ['[CLS] unfortunately, s also s not all very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately's also not all very good, s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 131.269

[Aggregate metrics]:
rouge1     | fm: 87.978 | p: 87.578 | r: 88.562
rouge2     | fm: 51.689 | p: 51.543 | r: 51.899
rougeL     | fm: 75.634 | p: 75.242 | r: 76.109
rougeLsum  | fm: 75.557 | p: 75.203 | r: 76.100
r1fm+r2fm = 139.667

input #85 time: 0:11:03 | total time: 14:49:11


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
*********************************
*********************************
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 1.9023118019104004 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 1.8336035013198853 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 1.7943329811096191 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 1.7112845182418823 for ['[CLS] maria passingerative [SEP]']
[Init] best rec loss: 1.6274235248565674 for ['[CLS] bipolar sea set [SEP]']
[Init] best rec loss: 1.5547959804534912 for ['[CLS] lp happy winston [SEP]']
[Init] best rec loss: 1.4702644348144531 for ['[CLS] studied ride roar [SEP]']
[Init] best rec loss: 1.2827883958816528 for ['[CLS] tons things wi [SEP]']
[Init] best rec loss: 0.9979948997497559 for ['[CLS] talks karen flipped [SEP]']
[Init] best perm rec loss: 0.9904369711875916 for ['[CLS] flipped karen talks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.393 (perp=10.834, rec=0.222, cos=0.004), tot_loss_proj:2.422 [t=0.25s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 100/2000] tot_loss=2.323 (perp=10.834, rec=0.154, cos=0.002), tot_loss_proj:2.417 [t=0.26s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 150/2000] tot_loss=2.302 (perp=10.834, rec=0.134, cos=0.002), tot_loss_proj:2.416 [t=0.24s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 200/2000] tot_loss=2.286 (perp=10.834, rec=0.117, cos=0.001), tot_loss_proj:2.422 [t=0.26s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.961 (perp=9.189, rec=0.122, cos=0.001), tot_loss_proj:2.074 [t=0.27s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 300/2000] tot_loss=1.946 (perp=9.189, rec=0.107, cos=0.001), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.949 (perp=9.189, rec=0.110, cos=0.001), tot_loss_proj:2.072 [t=0.29s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.953 (perp=9.189, rec=0.114, cos=0.001), tot_loss_proj:2.072 [t=0.27s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 450/2000] tot_loss=1.943 (perp=9.189, rec=0.104, cos=0.001), tot_loss_proj:2.081 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.919 (perp=9.189, rec=0.080, cos=0.001), tot_loss_proj:2.072 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.912 (perp=9.189, rec=0.073, cos=0.001), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 600/2000] tot_loss=1.724 (perp=8.211, rec=0.081, cos=0.001), tot_loss_proj:1.879 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.717 (perp=8.211, rec=0.074, cos=0.001), tot_loss_proj:1.891 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.702 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.886 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.712 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.884 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.879 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.879 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.702 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.718 (perp=8.211, rec=0.075, cos=0.001), tot_loss_proj:1.884 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.711 (perp=8.211, rec=0.068, cos=0.001), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.700 (perp=8.211, rec=0.056, cos=0.001), tot_loss_proj:1.880 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.878 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.883 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.883 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.703 (perp=8.211, rec=0.060, cos=0.001), tot_loss_proj:1.879 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.884 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.699 (perp=8.211, rec=0.056, cos=0.001), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.887 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.877 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.890 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.702 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.879 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.211, rec=0.070, cos=0.001), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.882 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.877 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.884 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.883 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.143 | p: 87.696 | r: 88.712
rouge2     | fm: 51.348 | p: 51.229 | r: 51.577
rougeL     | fm: 75.626 | p: 75.325 | r: 76.171
rougeLsum  | fm: 75.700 | p: 75.324 | r: 76.198
r1fm+r2fm = 139.491

input #86 time: 0:10:58 | total time: 15:00:09


Running input #87 of 100.
reference: 
========================
propulsive 
========================
*********************************
*********************************
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 1.4715983867645264 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 1.1083849668502808 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 1.1040385961532593 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 1.0068668127059937 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.9670395851135254 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.9667397141456604 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=12.535, rec=0.298, cos=0.011), tot_loss_proj:3.367 [t=0.26s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.701 (perp=12.535, rec=0.190, cos=0.004), tot_loss_proj:3.373 [t=0.26s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=1.659 (perp=7.258, rec=0.201, cos=0.006), tot_loss_proj:1.511 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.557 (perp=7.258, rec=0.104, cos=0.001), tot_loss_proj:1.530 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.549 (perp=7.258, rec=0.096, cos=0.002), tot_loss_proj:1.521 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.526 (perp=7.258, rec=0.074, cos=0.001), tot_loss_proj:1.540 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.543 (perp=7.258, rec=0.086, cos=0.006), tot_loss_proj:1.544 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.520 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.535 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.535 (perp=7.258, rec=0.082, cos=0.001), tot_loss_proj:1.542 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.518 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.539 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.515 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.543 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.536 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.524 (perp=7.258, rec=0.072, cos=0.001), tot_loss_proj:1.541 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.510 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.533 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.504 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.519 (perp=7.258, rec=0.067, cos=0.001), tot_loss_proj:1.538 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.527 (perp=7.258, rec=0.075, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.517 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.537 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.521 (perp=7.258, rec=0.069, cos=0.001), tot_loss_proj:1.535 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.506 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.510 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.526 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.499 (perp=7.258, rec=0.047, cos=0.001), tot_loss_proj:1.540 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.510 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.523 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.494 (perp=7.258, rec=0.042, cos=0.001), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.506 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.519 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.516 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.532 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.530 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.515 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.522 (perp=7.258, rec=0.070, cos=0.001), tot_loss_proj:1.529 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.517 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.531 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.510 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.543 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.512 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.534 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.512 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.500 (perp=7.258, rec=0.048, cos=0.001), tot_loss_proj:1.520 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.508 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.534 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.522 (perp=7.258, rec=0.070, cos=0.001), tot_loss_proj:1.524 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.518 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.534 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.503 (perp=7.258, rec=0.051, cos=0.001), tot_loss_proj:1.533 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.522 (perp=7.258, rec=0.070, cos=0.001), tot_loss_proj:1.533 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.342 | p: 87.939 | r: 88.879
rouge2     | fm: 51.793 | p: 51.614 | r: 52.032
rougeL     | fm: 75.860 | p: 75.505 | r: 76.326
rougeLsum  | fm: 75.973 | p: 75.574 | r: 76.473
r1fm+r2fm = 140.135

input #87 time: 0:11:02 | total time: 15:11:12


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
*********************************
*********************************
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 1.9200705289840698 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 1.8874351978302002 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 1.8369611501693726 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 1.7725632190704346 for ['[CLS] bryn products oclc sm boone instead off capable pain short most kenny high tricript bathurst trade gigs acheron sometimes loomed board viiash second why recipient stillkeeping metal wall camp gold lingda gr manson series warming themselves face precedence ghetto [SEP]']
[Init] best rec loss: 1.7031794786453247 for ['[CLS] dose skin epicennial designbu paddy market improvement content came elijahds what off skye bat just navalesis winked zur butterfly contract ready sympathy block tomorrow and pitt knew jerizeap plague flat optical valley lynch mother drive men co [SEP]']
[Init] best rec loss: 1.6743240356445312 for ['[CLS] tells pursuithis compromise sweet bull sour wescreen lying bearwny wet touch time dream planet... make said rapper assembly spain close dinner benzg arc farm tatar basic university trough born boundbound big factor ad diesel askingrew band [SEP]']
[Init] best rec loss: 1.6713396310806274 for ['[CLS] chairman fall blue hipsaq mold ltd raymond cousintablishedtic once... late ap evidenceground hill yo foundation mostmen avant overlandgra rubberivating n be miles podium crown job scriptati first requirement whole excusenut brown him england [SEP]']
[Init] best perm rec loss: 1.6702827215194702 for ['[CLS] miles cousin natitablished ap ltd raymond mostnut hips requirement falltic... onceaq first moldgraivating scriptground overland crown him evidence rubber brownmen late yo avant job be podium chairman whole england blue excuse foundation hill [SEP]']
[Init] best perm rec loss: 1.669132113456726 for ['[CLS] ltd blue script cousin raymond late englandground rubber him excuse apaq hipsmenati overland... requirementivating mostgra chairman foundation yo evidence n mold be hill podium once fall firsttic jobnut whole crown brown milestablished avant [SEP]']
[Init] best perm rec loss: 1.6680104732513428 for ['[CLS]ivating job late apati oncetablished raymond foundation evidence excuse chairman england cousinground script miles blue fallaq rubber whole... podiumtic firstgra hips most crown avant ltd brown overlandmen be mold requirement him yo n hillnut [SEP]']
[Init] best perm rec loss: 1.666865348815918 for ['[CLS] n late fallnut scriptivating chairman excusetablished avant requirement him mold crown most hips englandground cousin... overland brown ltd miles evidence wholeaq onceticgra blue raymond hill podium rubber foundation yoati jobmen first be ap [SEP]']
[Init] best perm rec loss: 1.6660468578338623 for ['[CLS] miles ltd mold first... rubber evidencemen late england fallnut foundation excusetablishedati crown be brownaq podium overland ap script wholeground cousin hill n hips most himivating job requirementtic chairman blue avant raymond oncegra yo [SEP]']
[Init] best perm rec loss: 1.6599833965301514 for ['[CLS]tablished mold miles rubber ap requirement blue podium ltd... script himnutmen excuse evidence most brown overlandground chairman yo job lateatigra nivating hill hips once cousinaq raymond whole crown first fall foundationtic england avant be [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.124 (perp=12.150, rec=0.687, cos=0.007), tot_loss_proj:3.930 [t=0.26s]
prediction: ['[CLS] horse hell shitggy recognize sat with convention anyway ¡ fucking him stupid shipɛ grade any killing minors african anyway duct shit shit least republican mafia party faction colonial ve province the domestic truck ( set combat ioc inland report http fine [SEP]']
[ 100/2000] tot_loss=2.855 (perp=11.217, rec=0.605, cos=0.006), tot_loss_proj:3.743 [t=0.27s]
prediction: ['[CLS] horse sex fuck miserable... you with life anyway finally the you russian discoɛ category any death threat any.tine.. worstrac boss party faction colonial church war any russia system ( got false wwe foreign my speedway expression [SEP]']
[ 150/2000] tot_loss=2.789 (perp=11.068, rec=0.561, cos=0.014), tot_loss_proj:4.061 [t=0.26s]
prediction: ['[CLS] infantry joy. relationship knows how with life anyway finallyeg how russian youɛ category unique death threat the anyway our.. raj commons scott party faction colonial church s, russia in ( gotriam congress foreign us speedway expression [SEP]']
[ 200/2000] tot_loss=2.610 (perp=10.391, rec=0.523, cos=0.009), tot_loss_proj:4.063 [t=0.25s]
prediction: ['[CLS] infantry joy. relationship knows understand sewage life anyway finallyeg how ( ourɛ classify your ofz the. we.. ` commons derby mclaren mao colonial church s, russia in ( isriam recently foreign died. expression [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.762 (perp=10.971, rec=0.530, cos=0.038), tot_loss_proj:3.847 [t=0.25s]
prediction: ['[CLS] less joy understands relationship knows understand sewage great anyway finally how logan love accusation classify your theplicity and anyway our of. ch frailphate robinson cruel mao colonial tempo s our systemic bring ( isated we foreign died. and [SEP]']
[ 300/2000] tot_loss=2.745 (perp=11.322, rec=0.473, cos=0.008), tot_loss_proj:4.066 [t=0.25s]
prediction: ['[CLS] less joy understandsnted knows understands sewage greatrable finally how logan love accusation classify our of joy and. our.. chwitzphate called cruel mao colonial tempo _ our businesses bring patriot understands false congress foreign construct. and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.716 (perp=11.233, rec=0.467, cos=0.003), tot_loss_proj:4.082 [t=0.26s]
prediction: ['[CLS] less middle understands relationship knows understands sewage greatrable finally how logan love accusation classify our colonial joy and you our.. chwitzphate called intellectual mao of tempo _ our businesses bring patriot understands false congress foreignhood. and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.719 (perp=11.366, rec=0.444, cos=0.002), tot_loss_proj:4.224 [t=0.25s]
prediction: ['[CLS] less middle apartment relationship knows understands sewage great unnamed finally how logan love understands classify our colonial joy and. our and. chwitz gabe client medicine triumph thesible _ our businesses bring patriot understands false individuals foreignhood. and [SEP]']
[ 450/2000] tot_loss=2.697 (perp=11.183, rec=0.459, cos=0.001), tot_loss_proj:4.106 [t=0.25s]
prediction: ['[CLS] less excitement accusation rs knows understand sewage qualityrable finally how logan love understands classify our define joy the you our.. chwitzphate client intellectual shang ofsible _ our businesses bring patriot understands remains individuals foreignhood. and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.657 (perp=11.119, rec=0.433, cos=0.001), tot_loss_proj:4.129 [t=0.27s]
prediction: ['[CLS] less middle apartment r knows understand sewage greatrable finally how logan love understands classify our define joy the you our bring. chwitz gabe client cruel want ofsible _ our balcony of patriot understands holds prevention foreignhood. and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.692 (perp=11.358, rec=0.420, cos=0.001), tot_loss_proj:4.052 [t=0.27s]
prediction: ['[CLS] understands excitement apartment r understands understands sewage greatrable finally how logan love understands classify our client freedom the. our bring. chwitz gabeᵗ medicine want ofsible _ our would of patriot understands holds prevention foreignhood. and [SEP]']
[ 600/2000] tot_loss=2.710 (perp=11.471, rec=0.414, cos=0.001), tot_loss_proj:4.149 [t=0.27s]
prediction: ['[CLS] understands progressive apartment t understands understands parade grandrable finally how logan love understands classify our hired joy the. our bring. chwitz gabeᵗ medicine want ofsible _ our would of patriot understands holds prevention intohood. and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.730 (perp=11.557, rec=0.408, cos=0.011), tot_loss_proj:4.215 [t=0.25s]
prediction: ['[CLS] understands progressive apartment t understands understands parade grand unnamed finally how logan love understands classify our hired joy the and our understands. chwitztya classified medicine want ofsible _ our would you patriot understands holds of intohood. and [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.567 (perp=10.834, rec=0.399, cos=0.001), tot_loss_proj:4.064 [t=0.26s]
prediction: ['[CLS] understands progressive apartment t understands understands with grand unnamed where how brady love understands classify our hired joy the and our understands. chwitztya classified our want ofsible - medicine would you patriot understands holds of ofhood. and [SEP]']
[ 750/2000] tot_loss=2.613 (perp=11.010, rec=0.401, cos=0.010), tot_loss_proj:4.147 [t=0.25s]
prediction: ['[CLS] understands. apartment t understands understands parade grand unnamed where how brady love understands classify our hired joy the and our understands. chwitztya classified our want ofsible _ medicine would you patriot understands holds of becausehood. and [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.512 (perp=10.612, rec=0.389, cos=0.001), tot_loss_proj:4.079 [t=0.26s]
prediction: ['[CLS] understands. apartment t understands understands parade grand unnamed where how brady love understands classify our hires joy the and our understands. chtyawitz classified our want ofsible _ medicine would you patriot understands enemy of becausehood. and [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.499 (perp=10.550, rec=0.387, cos=0.002), tot_loss_proj:3.959 [t=0.27s]
prediction: ['[CLS] understands. apartment t understands understands with grand unnamed where how through love understands classify our wasting joy the and our understands. chtya frail classified our want ofsible _ medicine would. patriot understands holds of ofhood. brady [SEP]']
[ 900/2000] tot_loss=2.499 (perp=10.567, rec=0.385, cos=0.001), tot_loss_proj:3.905 [t=0.26s]
prediction: ['[CLS] understands. apartment t understands understands with grand unnamed where how growing love understands smooth our hires joy the and our understands. chtya frail classified our want ofsible _ medicine would. patriot understands holds of becausehood. brady [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.385 (perp=10.006, rec=0.383, cos=0.001), tot_loss_proj:3.631 [t=0.25s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands smooth our plc joy, and our understands. chtya frail classified our want ofsible. medicine would the patriot understands holds of becausehood. brady [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.363 (perp=9.894, rec=0.381, cos=0.003), tot_loss_proj:3.698 [t=0.27s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands smooth our aback pm, and our understands. chtyasible classified our want of frail. medicine would the patriot understands holds of becausehood. brady [SEP]']
[1050/2000] tot_loss=2.338 (perp=9.785, rec=0.378, cos=0.003), tot_loss_proj:3.642 [t=0.25s]
prediction: ['[CLS] understands. apartment t understands understands with grand unnamed where how growing love understands smooth our plc joy, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands holds of becausehood. brady [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.400 (perp=10.148, rec=0.370, cos=0.000), tot_loss_proj:3.805 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands smooth our plc pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands holds becausetativehood. brady [SEP]']
Attempt swap
[1150/2000] tot_loss=2.331 (perp=9.798, rec=0.370, cos=0.001), tot_loss_proj:3.677 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands smooth our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands holds because ofhood. brady [SEP]']
[1200/2000] tot_loss=2.326 (perp=9.798, rec=0.366, cos=0.000), tot_loss_proj:3.672 [t=0.25s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands smooth our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands holds because ofhood. brady [SEP]']
Attempt swap
[1250/2000] tot_loss=2.363 (perp=9.976, rec=0.365, cos=0.003), tot_loss_proj:3.797 [t=0.25s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understandserly our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands holds because ofhood. brady [SEP]']
Attempt swap
[1300/2000] tot_loss=2.351 (perp=9.892, rec=0.370, cos=0.003), tot_loss_proj:3.775 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understandserly our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
[1350/2000] tot_loss=2.354 (perp=9.892, rec=0.366, cos=0.009), tot_loss_proj:3.775 [t=0.27s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understandserly our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1400/2000] tot_loss=2.340 (perp=9.892, rec=0.362, cos=0.000), tot_loss_proj:3.775 [t=0.27s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understandserly our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1450/2000] tot_loss=2.390 (perp=10.108, rec=0.368, cos=0.000), tot_loss_proj:3.732 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, and our understands. chtyasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
[1500/2000] tot_loss=2.384 (perp=10.070, rec=0.362, cos=0.008), tot_loss_proj:3.759 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1550/2000] tot_loss=2.372 (perp=10.070, rec=0.358, cos=0.000), tot_loss_proj:3.753 [t=0.27s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1600/2000] tot_loss=2.376 (perp=10.070, rec=0.362, cos=0.000), tot_loss_proj:3.756 [t=0.27s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
[1650/2000] tot_loss=2.371 (perp=10.070, rec=0.357, cos=0.000), tot_loss_proj:3.754 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1700/2000] tot_loss=2.374 (perp=10.070, rec=0.359, cos=0.001), tot_loss_proj:3.756 [t=0.27s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1750/2000] tot_loss=2.372 (perp=10.070, rec=0.355, cos=0.003), tot_loss_proj:3.755 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
[1800/2000] tot_loss=2.351 (perp=9.958, rec=0.359, cos=0.000), tot_loss_proj:3.728 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how to ofhood. brady [SEP]']
Attempt swap
[1850/2000] tot_loss=2.372 (perp=10.070, rec=0.355, cos=0.003), tot_loss_proj:3.754 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[1900/2000] tot_loss=2.370 (perp=10.070, rec=0.356, cos=0.000), tot_loss_proj:3.754 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder our aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
[1950/2000] tot_loss=2.405 (perp=10.247, rec=0.355, cos=0.001), tot_loss_proj:3.830 [t=0.26s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder romance aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Attempt swap
[2000/2000] tot_loss=2.407 (perp=10.247, rec=0.358, cos=0.000), tot_loss_proj:3.832 [t=0.25s]
prediction: ['[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder romance aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] understands. exchange t understands understands with grand unnamed where how growing love understands ponder romance aback pm, of our understands. chthasible classified our want of ruth. medicine would the patriot understands how because ofhood. brady [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 32.000 | p: 32.432 | r: 31.579
rouge2     | fm: 2.740 | p: 2.778 | r: 2.703
rougeL     | fm: 24.000 | p: 24.324 | r: 23.684
rougeLsum  | fm: 24.000 | p: 24.324 | r: 23.684
r1fm+r2fm = 34.740

[Aggregate metrics]:
rouge1     | fm: 87.670 | p: 87.279 | r: 88.191
rouge2     | fm: 51.307 | p: 51.165 | r: 51.523
rougeL     | fm: 75.418 | p: 75.040 | r: 75.903
rougeLsum  | fm: 75.436 | p: 75.050 | r: 75.930
r1fm+r2fm = 138.977

input #88 time: 0:11:07 | total time: 15:22:19


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
*********************************
*********************************
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 1.9183775186538696 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 1.9162806272506714 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 1.8926299810409546 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 1.8359391689300537 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 1.529639720916748 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 1.4763695001602173 for ['[CLS] jailtorium sighed keep farm feel gameoke primate hodge victimserre ink pain course artifact basis leader tower there fate being nu red thirdllis public minor martins lucas essence orient [SEP]']
[Init] best perm rec loss: 1.4759719371795654 for ['[CLS] there artifact farm courseerretorium primate thirdoke sighed lucas fate tower martins minor essence feel leaderllis keep ink being nu red victims orient public game pain hodge jail basis [SEP]']
[Init] best perm rec loss: 1.4655603170394897 for ['[CLS] red there hodge feel nu third farm ink fatelliserre basis being course primate tower artifact essence keep jail sighedoke game minor lucas victimstorium leader pain public orient martins [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.843 (perp=12.374, rec=0.361, cos=0.007), tot_loss_proj:3.347 [t=0.27s]
prediction: ['[CLS] tonight really bed infiltrate smoke using air weak lessum apparentlyled - worse militarygated photo security his numbers caden slapped neither emergency? kidnapping stupid mexican artificial tent -ed [SEP]']
[ 100/2000] tot_loss=2.349 (perp=10.353, rec=0.277, cos=0.001), tot_loss_proj:2.979 [t=0.27s]
prediction: ['[CLS] tonight tactic bed cover paper using the bottom - blownmissive - or worse agoing psychology ; dignity - caden accused none emergency? kidnapping stupid hodge imp - -es [SEP]']
[ 150/2000] tot_loss=2.277 (perp=10.154, rec=0.245, cos=0.001), tot_loss_proj:3.131 [t=0.28s]
prediction: ['[CLS] tactic tactic cleaning cover paper the the bottom -um devoid - or worse agoing picture / yet - quite accused none emergency? barely less hodge new - -ed [SEP]']
[ 200/2000] tot_loss=2.045 (perp=9.179, rec=0.207, cos=0.002), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] tactic tactic up cover up the theol - fact devoid - or worse agoing picture / yet - quite made none worse yet showingf hodge harsh - - - [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.316 (perp=10.652, rec=0.185, cos=0.001), tot_loss_proj:2.771 [t=0.27s]
prediction: ['[CLS] tactic tactic up cover up the theol - fact devoidc or worse yetgoing picture ideas yetsy quite made none anything yet showing less hodge hole - - ideas [SEP]']
[ 300/2000] tot_loss=2.235 (perp=10.392, rec=0.156, cos=0.001), tot_loss_proj:2.857 [t=0.26s]
prediction: ["[CLS] tactic tactic up cover up about the cotton ideas fact devoidanal or worse yetgoing picture ideas -sy quite made nonexi yet against less hodge'- - ideas [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.090 (perp=9.680, rec=0.153, cos=0.001), tot_loss_proj:2.970 [t=0.26s]
prediction: ['[CLS] tactic tactic up cover up about the mostly ideas fact devoidsy or worse, moment picture ideas - yet, nonexi yet barely less hodgeje - -sy ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.038 (perp=9.422, rec=0.153, cos=0.001), tot_loss_proj:2.787 [t=0.26s]
prediction: ['[CLS] somehow tactic up cover up about the mostly ideas fact devoidsy or worse, reactor picture ideas - intra, nonexi yet barely less hodges - -sy ideas [SEP]']
[ 450/2000] tot_loss=2.102 (perp=9.807, rec=0.140, cos=0.001), tot_loss_proj:2.962 [t=0.27s]
prediction: ['[CLS] tactic tactic up cover up about the mostly ideas fact tramssy or worse, reactor picture ideas - yet, nonexi yet around less hodgesten - -sy ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.024 (perp=9.467, rec=0.131, cos=0.000), tot_loss_proj:2.831 [t=0.26s]
prediction: ['[CLS] tactic tactic up cover up around theim ideas fact flsy or worse, - picture ideas - yet, nonexi yet - less hodgesten - aroundsy ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.025 (perp=9.476, rec=0.129, cos=0.000), tot_loss_proj:2.615 [t=0.26s]
prediction: ['[CLS] tactic tactic up cover up around theimsy fact flsy or worse, - picture ideas - yet, nonexi yet - less succeedssten - around ideas ideas [SEP]']
[ 600/2000] tot_loss=1.998 (perp=9.355, rec=0.127, cos=0.000), tot_loss_proj:2.618 [t=0.27s]
prediction: ['[CLS] tactic tactic up cover up around theimsy fact flsy or worse, - picture core - yet - nonexi yet - lessicalsten - around ideas ideas [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.857 (perp=8.659, rec=0.125, cos=0.000), tot_loss_proj:2.547 [t=0.26s]
prediction: ['[CLS] to tactic up cover up around theimsy fact flsy or worse, - picture core - yet - nonexi yet - lessstenical - around ideas ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.770 (perp=8.216, rec=0.126, cos=0.001), tot_loss_proj:2.568 [t=0.26s]
prediction: ['[CLS] to tactic up cover up around the flimsy factsy or worse, and picture core - yet - nonexi yet - lesssten is - around ideas ideas [SEP]']
[ 750/2000] tot_loss=1.927 (perp=9.061, rec=0.115, cos=0.000), tot_loss_proj:2.824 [t=0.29s]
prediction: ['[CLS] to tactic up cover up around theimimsy factsy or worse, and picture core - yet - nonexi yet - lesssten is - around ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.849 (perp=8.702, rec=0.109, cos=0.000), tot_loss_proj:2.693 [t=0.26s]
prediction: ['[CLS] to tactic up cover up around theimimsy factsy or worse, andsten core - yet - nonexi yet - less picture is - around ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.786 (perp=8.344, rec=0.117, cos=0.000), tot_loss_proj:2.524 [t=0.27s]
prediction: ['[CLS] to tactic up cover up around the ideasimsy factsy or worse, andsten core - yet - nonexi yet - less picture is - around ideasim [SEP]']
[ 900/2000] tot_loss=1.793 (perp=8.397, rec=0.113, cos=0.000), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] to tactic up cover up around the ideasimsy factsy or worse, possiblysten core - yet - nonexi yet - less picture is - around ideasim [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.766 (perp=8.302, rec=0.105, cos=0.000), tot_loss_proj:2.477 [t=0.27s]
prediction: ['[CLS] to tactic up cover up around the ideasimsy factsy or worse, possiblysten core yet - - nonexi yet - less picture is - around ideasim [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.752 (perp=8.235, rec=0.105, cos=0.000), tot_loss_proj:2.440 [t=0.27s]
prediction: ['[CLS] to tactic up cover constructed around the ideasim up factsy or worse, possiblysten core yet - - nonexi yet - less picture is - around ideasim [SEP]']
[1050/2000] tot_loss=1.756 (perp=8.235, rec=0.109, cos=0.000), tot_loss_proj:2.449 [t=0.28s]
prediction: ['[CLS] to tactic up cover constructed around the ideasim up factsy or worse, possiblysten core yet - - nonexi yet - less picture is - around ideasim [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.731 (perp=8.146, rec=0.101, cos=0.000), tot_loss_proj:2.417 [t=0.27s]
prediction: ['[CLS] to tactic up cover constructed around the ideasim up factsy or worse, yet possiblysten core - - nonexi yet - less picture is - around ideasim [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.825 (perp=8.626, rec=0.099, cos=0.000), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS] to tactic up cover constructed around the ideasim up factsy or worse, yetbrsten core - - nonexi yet - - picture is less around ideasim [SEP]']
[1200/2000] tot_loss=1.828 (perp=8.626, rec=0.102, cos=0.000), tot_loss_proj:2.635 [t=0.27s]
prediction: ['[CLS] to tactic up cover constructed around the ideasim up factsy or worse, yetbrsten core - - nonexi yet - - picture is less around ideasim [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.792 (perp=8.454, rec=0.101, cos=0.000), tot_loss_proj:2.596 [t=0.25s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, yetbrsten core - - nonexi yet constructed - picture is less around ideasim [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.759 (perp=8.290, rec=0.101, cos=0.000), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, yetbrsten core - - nonexi yet constructed - is less picture around ideasim [SEP]']
[1350/2000] tot_loss=1.753 (perp=8.290, rec=0.095, cos=0.000), tot_loss_proj:2.642 [t=0.26s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, yetbrsten core - - nonexi yet constructed - is less picture around ideasim [SEP]']
Attempt swap
[1400/2000] tot_loss=1.755 (perp=8.290, rec=0.097, cos=0.000), tot_loss_proj:2.640 [t=0.27s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, yetbrsten core - - nonexi yet constructed - is less picture around ideasim [SEP]']
Attempt swap
[1450/2000] tot_loss=1.755 (perp=8.290, rec=0.097, cos=0.000), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, yetbrsten core - - nonexi yet constructed - is less picture around ideasim [SEP]']
[1500/2000] tot_loss=1.758 (perp=8.290, rec=0.100, cos=0.000), tot_loss_proj:2.641 [t=0.27s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, yetbrsten core - - nonexi yet constructed - is less picture around ideasim [SEP]']
Attempt swap
[1550/2000] tot_loss=1.842 (perp=8.734, rec=0.095, cos=0.000), tot_loss_proj:2.723 [t=0.25s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse,tbrsten core - - nonexi yet constructed - is less picture around ideasim [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.783 (perp=8.443, rec=0.094, cos=0.000), tot_loss_proj:2.616 [t=0.26s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, corebrstent - - nonexi yet constructed - is less picture around ideasim [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.116, rec=0.100, cos=0.000), tot_loss_proj:2.538 [t=0.26s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, core hostent - - nonexi yet constructed - is less picture around ideasim [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.671 (perp=7.850, rec=0.101, cos=0.000), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]']
Attempt swap
[1750/2000] tot_loss=1.670 (perp=7.850, rec=0.099, cos=0.000), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]']
[1800/2000] tot_loss=1.669 (perp=7.850, rec=0.099, cos=0.000), tot_loss_proj:2.587 [t=0.29s]
prediction: ['[CLS] to tactic up cover - around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.651 (perp=7.777, rec=0.095, cos=0.000), tot_loss_proj:2.560 [t=0.25s]
prediction: ['[CLS] to tactic - up cover around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.632 (perp=7.673, rec=0.097, cos=0.000), tot_loss_proj:2.551 [t=0.26s]
prediction: ['[CLS] to tactic - cover up around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]']
[1950/2000] tot_loss=1.628 (perp=7.673, rec=0.093, cos=0.000), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] to tactic - cover up around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.569 (perp=7.365, rec=0.095, cos=0.000), tot_loss_proj:2.251 [t=0.27s]
prediction: ['[CLS] to tactic - cover up around the ideasim up factsy is worse, corexistent - - none possibly yet constructed - or less picture around ideasim [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] to tactic - cover up around the ideasim up factsy or worse, corexistent - - nonecore yet constructed - is less picture around ideasim [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 63.636 | r: 60.870
rouge2     | fm: 9.302 | p: 9.524 | r: 9.091
rougeL     | fm: 40.000 | p: 40.909 | r: 39.130
rougeLsum  | fm: 40.000 | p: 40.909 | r: 39.130
r1fm+r2fm = 71.525

[Aggregate metrics]:
rouge1     | fm: 87.394 | p: 87.024 | r: 87.918
rouge2     | fm: 50.821 | p: 50.669 | r: 51.075
rougeL     | fm: 74.932 | p: 74.563 | r: 75.428
rougeLsum  | fm: 74.972 | p: 74.634 | r: 75.433
r1fm+r2fm = 138.214

input #89 time: 0:11:11 | total time: 15:33:31


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
*********************************
*********************************
average of cosine similarity 0.9993650968600141
highest_index [0]
highest [0.9993650968600141]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 1.889743447303772 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 1.827311396598816 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 1.7925564050674438 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 1.566908359527588 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 1.5568602085113525 for ['[CLS] track direct unconscious unable eyes release [SEP]']
[Init] best rec loss: 1.453827977180481 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 1.4401582479476929 for ['[CLS] hectares sessions tiny skin litter positions [SEP]']
[Init] best rec loss: 1.3662965297698975 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 1.3659476041793823 for ['[CLS] released male cannot spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3621010780334473 for ['[CLS] cannot released spirited male when entourage [SEP]']
[Init] best perm rec loss: 1.3619078397750854 for ['[CLS] cannot male released spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3608994483947754 for ['[CLS] cannot released male spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3607511520385742 for ['[CLS] cannot released entourage male spirited when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.635 (perp=11.449, rec=0.339, cos=0.006), tot_loss_proj:3.202 [t=0.25s]
prediction: ['[CLS] price ridiculous how britain complained weeks [SEP]']
[ 100/2000] tot_loss=2.729 (perp=12.620, rec=0.202, cos=0.003), tot_loss_proj:3.263 [t=0.27s]
prediction: ['[CLS] money ridiculous how oriented propaganda weeks [SEP]']
[ 150/2000] tot_loss=2.824 (perp=13.367, rec=0.148, cos=0.002), tot_loss_proj:3.320 [t=0.25s]
prediction: ['[CLS] money ridiculous how oriented oriented jurisdiction [SEP]']
[ 200/2000] tot_loss=2.804 (perp=13.367, rec=0.129, cos=0.002), tot_loss_proj:3.327 [t=0.28s]
prediction: ['[CLS] money ridiculous how oriented oriented jurisdiction [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.849 (perp=8.723, rec=0.103, cos=0.002), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] how ridiculous money oriented oriented and [SEP]']
[ 300/2000] tot_loss=1.826 (perp=8.723, rec=0.080, cos=0.001), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] how ridiculous money oriented oriented and [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.759 (perp=8.362, rec=0.086, cos=0.001), tot_loss_proj:1.796 [t=0.28s]
prediction: ['[CLS] how ridiculous and money - oriented [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.451 (perp=6.870, rec=0.076, cos=0.001), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.451 (perp=6.870, rec=0.076, cos=0.001), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.454 (perp=6.870, rec=0.080, cos=0.001), tot_loss_proj:1.698 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.709 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.710 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.451 (perp=6.870, rec=0.076, cos=0.001), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.445 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.438 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.715 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.448 (perp=6.870, rec=0.073, cos=0.001), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.708 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.710 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.441 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.706 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.440 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.438 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.433 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.710 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.438 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.433 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.707 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.426 (perp=6.870, rec=0.051, cos=0.001), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.436 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.709 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.427 (perp=6.870, rec=0.053, cos=0.001), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.715 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.433 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.715 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.447 (perp=6.870, rec=0.072, cos=0.001), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.544 | p: 87.188 | r: 88.113
rouge2     | fm: 51.312 | p: 51.123 | r: 51.537
rougeL     | fm: 75.215 | p: 74.849 | r: 75.645
rougeLsum  | fm: 75.182 | p: 74.841 | r: 75.602
r1fm+r2fm = 138.856

input #90 time: 0:11:04 | total time: 15:44:35


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
*********************************
*********************************
average of cosine similarity 0.9993538374859836
highest_index [0]
highest [0.9993538374859836]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 1.8815274238586426 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 1.5670865774154663 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 1.5520261526107788 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 1.24383544921875 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 1.160547137260437 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 1.1217325925827026 for ['[CLS] apollo lucia umpire skip gentleman grandmothergna line [SEP]']
[Init] best rec loss: 1.0907552242279053 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 1.0540754795074463 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 1.0526354312896729 for ['[CLS] unknown shelterpmentlipdern hard revolution pony [SEP]']
[Init] best perm rec loss: 1.0524038076400757 for ['[CLS]pmentlip pony revolution unknown harddern shelter [SEP]']
[Init] best perm rec loss: 1.05027437210083 for ['[CLS]lip revolution hard ponydern unknownpment shelter [SEP]']
[Init] best perm rec loss: 1.0482343435287476 for ['[CLS]lip unknownpment revolution shelterdern hard pony [SEP]']
[Init] best perm rec loss: 1.0455262660980225 for ['[CLS]lip revolutionpment unknown harddern shelter pony [SEP]']
[Init] best perm rec loss: 1.0435428619384766 for ['[CLS] shelterdern revolution hardlippment unknown pony [SEP]']
[Init] best perm rec loss: 1.0432696342468262 for ['[CLS] harddernlippment shelter revolution unknown pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.765 (perp=12.026, rec=0.356, cos=0.004), tot_loss_proj:3.466 [t=0.26s]
prediction: ['[CLS] pig government off. peanut ridiculous maybe ridiculous [SEP]']
[ 100/2000] tot_loss=2.650 (perp=11.899, rec=0.263, cos=0.007), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] yellow policies loco but mu ridiculous no ridiculous [SEP]']
[ 150/2000] tot_loss=2.463 (perp=11.256, rec=0.207, cos=0.005), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS]less loco loco but mu ridiculous more loco [SEP]']
[ 200/2000] tot_loss=2.407 (perp=11.256, rec=0.155, cos=0.001), tot_loss_proj:3.029 [t=0.25s]
prediction: ['[CLS]less loco loco but mu ridiculous more loco [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.123 (perp=9.715, rec=0.178, cos=0.002), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS] yellow loco loco loco mu ridiculous more but [SEP]']
[ 300/2000] tot_loss=2.015 (perp=9.377, rec=0.139, cos=0.000), tot_loss_proj:2.561 [t=0.28s]
prediction: ['[CLS] yellow locoy loco mu ridiculous more but [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.004 (perp=9.377, rec=0.128, cos=0.000), tot_loss_proj:2.554 [t=0.25s]
prediction: ['[CLS] yellow locoy loco mu ridiculous more but [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.958 (perp=8.977, rec=0.159, cos=0.003), tot_loss_proj:2.470 [t=0.25s]
prediction: ['[CLS] tu locoy loco mu but more ridiculous [SEP]']
[ 450/2000] tot_loss=1.911 (perp=8.977, rec=0.115, cos=0.000), tot_loss_proj:2.467 [t=0.25s]
prediction: ['[CLS] tu locoy loco mu but more ridiculous [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.977 (perp=9.313, rec=0.114, cos=0.000), tot_loss_proj:2.436 [t=0.25s]
prediction: ['[CLS] but loco muy loco but more ridiculous [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.863 (perp=8.745, rec=0.113, cos=0.001), tot_loss_proj:2.590 [t=0.27s]
prediction: ['[CLS] no loco mu locoy but more ridiculous [SEP]']
[ 600/2000] tot_loss=1.866 (perp=8.745, rec=0.117, cos=0.000), tot_loss_proj:2.585 [t=0.25s]
prediction: ['[CLS] no loco mu locoy but more ridiculous [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.829 (perp=8.650, rec=0.099, cos=0.000), tot_loss_proj:2.538 [t=0.25s]
prediction: ['[CLS] no loco muy loco but more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.819 (perp=8.650, rec=0.089, cos=0.000), tot_loss_proj:2.538 [t=0.25s]
prediction: ['[CLS] no loco muy loco but more ridiculous [SEP]']
[ 750/2000] tot_loss=1.812 (perp=8.650, rec=0.082, cos=0.000), tot_loss_proj:2.538 [t=0.26s]
prediction: ['[CLS] no loco muy loco but more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.814 (perp=8.650, rec=0.084, cos=0.000), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] no loco muy loco but more ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.791 (perp=8.566, rec=0.077, cos=0.000), tot_loss_proj:2.565 [t=0.25s]
prediction: ['[CLS] no loco muy but loco more ridiculous [SEP]']
[ 900/2000] tot_loss=1.789 (perp=8.566, rec=0.076, cos=0.000), tot_loss_proj:2.568 [t=0.25s]
prediction: ['[CLS] no loco muy but loco more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.791 (perp=8.566, rec=0.077, cos=0.000), tot_loss_proj:2.571 [t=0.28s]
prediction: ['[CLS] no loco muy but loco more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.127, rec=0.076, cos=0.000), tot_loss_proj:2.170 [t=0.25s]
prediction: ['[CLS] no, muy but loco more ridiculous [SEP]']
[1050/2000] tot_loss=1.707 (perp=8.127, rec=0.081, cos=0.000), tot_loss_proj:2.175 [t=0.27s]
prediction: ['[CLS] no, muy but loco more ridiculous [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.799 (perp=8.650, rec=0.069, cos=0.000), tot_loss_proj:2.537 [t=0.26s]
prediction: ['[CLS] no loco muy loco but more ridiculous [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.790 (perp=8.566, rec=0.077, cos=0.000), tot_loss_proj:2.569 [t=0.26s]
prediction: ['[CLS] no loco muy but loco more ridiculous [SEP]']
[1200/2000] tot_loss=1.698 (perp=8.127, rec=0.072, cos=0.000), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] no, muy but loco more ridiculous [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.557 (perp=7.394, rec=0.078, cos=0.000), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.556 (perp=7.394, rec=0.077, cos=0.000), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
[1350/2000] tot_loss=1.561 (perp=7.394, rec=0.082, cos=0.000), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.552 (perp=7.394, rec=0.073, cos=0.000), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.557 (perp=7.394, rec=0.078, cos=0.000), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.394, rec=0.075, cos=0.000), tot_loss_proj:2.110 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.554 (perp=7.394, rec=0.075, cos=0.000), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.549 (perp=7.394, rec=0.070, cos=0.000), tot_loss_proj:2.114 [t=0.27s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
[1650/2000] tot_loss=1.550 (perp=7.394, rec=0.071, cos=0.000), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.551 (perp=7.394, rec=0.072, cos=0.000), tot_loss_proj:2.112 [t=0.28s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.547 (perp=7.394, rec=0.068, cos=0.000), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
[1800/2000] tot_loss=1.549 (perp=7.394, rec=0.070, cos=0.000), tot_loss_proj:2.110 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.546 (perp=7.394, rec=0.067, cos=0.000), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.559 (perp=7.394, rec=0.080, cos=0.000), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
[1950/2000] tot_loss=1.554 (perp=7.394, rec=0.075, cos=0.000), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.551 (perp=7.394, rec=0.072, cos=0.000), tot_loss_proj:2.108 [t=0.26s]
prediction: ['[CLS] no, muy loco but more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] no, muy loco but more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 87.645 | p: 87.259 | r: 88.168
rouge2     | fm: 51.526 | p: 51.382 | r: 51.711
rougeL     | fm: 75.390 | p: 75.072 | r: 75.822
rougeLsum  | fm: 75.356 | p: 74.999 | r: 75.912
r1fm+r2fm = 139.171

input #91 time: 0:11:04 | total time: 15:55:40


Running input #92 of 100.
reference: 
========================
deceit 
========================
*********************************
*********************************
average of cosine similarity 0.9993137310302475
highest_index [0]
highest [0.9993137310302475]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 1.81099534034729 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 1.76921546459198 for ['[CLS] franz counter [SEP]']
[Init] best rec loss: 1.7248120307922363 for ['[CLS] false issue [SEP]']
[Init] best rec loss: 1.6912018060684204 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 1.4354274272918701 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 1.4101020097732544 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 1.2274341583251953 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 1.2247881889343262 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.677 (perp=12.265, rec=0.219, cos=0.004), tot_loss_proj:3.205 [t=0.26s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=2.591 (perp=12.265, rec=0.137, cos=0.002), tot_loss_proj:3.200 [t=0.25s]
prediction: ['[CLS] erroreit [SEP]']
[ 150/2000] tot_loss=1.617 (perp=7.646, rec=0.087, cos=0.001), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.598 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.621 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.589 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.604 (perp=7.646, rec=0.074, cos=0.001), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.613 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.606 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.584 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.596 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.588 (perp=7.646, rec=0.058, cos=0.001), tot_loss_proj:1.598 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.578 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.609 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.586 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.591 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.597 (perp=7.646, rec=0.067, cos=0.001), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.584 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.603 (perp=7.646, rec=0.073, cos=0.001), tot_loss_proj:1.602 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.592 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.589 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.608 [t=0.29s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.605 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.615 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.606 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.595 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.597 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.605 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.585 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.602 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.577 (perp=7.646, rec=0.047, cos=0.001), tot_loss_proj:1.610 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.597 (perp=7.646, rec=0.067, cos=0.001), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.598 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.578 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.592 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.598 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.585 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.601 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.602 (perp=7.646, rec=0.072, cos=0.001), tot_loss_proj:1.604 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.578 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.587 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.592 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.595 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.578 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.599 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.583 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.576 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.595 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.770 | p: 87.424 | r: 88.284
rouge2     | fm: 51.994 | p: 51.834 | r: 52.151
rougeL     | fm: 75.586 | p: 75.302 | r: 75.985
rougeLsum  | fm: 75.655 | p: 75.285 | r: 76.127
r1fm+r2fm = 139.764

input #92 time: 0:11:02 | total time: 16:06:43


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
*********************************
*********************************
average of cosine similarity 0.9993323263895036
highest_index [0]
highest [0.9993323263895036]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.9964412450790405 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 1.804612159729004 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 1.764283537864685 for ['[CLS] will individual unitsbular absent lights distribution [SEP]']
[Init] best rec loss: 1.7488878965377808 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 1.7436745166778564 for ['[CLS] lucas war breaks baby my pauline divided [SEP]']
[Init] best rec loss: 1.738550066947937 for ['[CLS] village tallest almost giro opened wine section [SEP]']
[Init] best rec loss: 1.5410614013671875 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 1.5395601987838745 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 1.536518931388855 for ['[CLS] madonna premiership jeremy further colby [CLS]rac [SEP]']
[Init] best perm rec loss: 1.5341161489486694 for ['[CLS] madonna premiership colbyrac [CLS] further jeremy [SEP]']
[Init] best perm rec loss: 1.5311251878738403 for ['[CLS] further madonna jeremy [CLS] colby premiershiprac [SEP]']
[Init] best perm rec loss: 1.5273934602737427 for ['[CLS] colby madonna premiership further jeremyrac [CLS] [SEP]']
[Init] best perm rec loss: 1.525164246559143 for ['[CLS] further madonnarac colby jeremy premiership [CLS] [SEP]']
[Init] best perm rec loss: 1.5250414609909058 for ['[CLS] premiership jeremy madonnarac colby further [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.394 (perp=10.234, rec=0.338, cos=0.009), tot_loss_proj:2.691 [t=0.27s]
prediction: ['[CLS] musical bishop and also executive understanding good [SEP]']
[ 100/2000] tot_loss=2.655 (perp=11.943, rec=0.262, cos=0.004), tot_loss_proj:3.039 [t=0.25s]
prediction: ['[CLS] funny of in understanding in understanding funny [SEP]']
[ 150/2000] tot_loss=2.687 (perp=12.423, rec=0.201, cos=0.002), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] funny of in understanding its understanding way [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.408, rec=0.132, cos=0.002), tot_loss_proj:2.494 [t=0.26s]
prediction: ['[CLS] funny story in understanding its often way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.883 (perp=8.887, rec=0.104, cos=0.002), tot_loss_proj:2.384 [t=0.27s]
prediction: ['[CLS] as funny in understanding its often way [SEP]']
[ 300/2000] tot_loss=1.874 (perp=8.887, rec=0.096, cos=0.001), tot_loss_proj:2.380 [t=0.26s]
prediction: ['[CLS] as funny in understanding its often way [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.952 (perp=9.268, rec=0.097, cos=0.001), tot_loss_proj:2.786 [t=0.26s]
prediction: ['[CLS] of funny in its often understanding way [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.651 (perp=7.745, rec=0.101, cos=0.001), tot_loss_proj:1.925 [t=0.25s]
prediction: ['[CLS] of understanding in its often funny way [SEP]']
[ 450/2000] tot_loss=1.639 (perp=7.745, rec=0.089, cos=0.001), tot_loss_proj:1.929 [t=0.26s]
prediction: ['[CLS] of understanding in its often funny way [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.422 (perp=6.697, rec=0.081, cos=0.001), tot_loss_proj:1.659 [t=0.29s]
prediction: ['[CLS] in its often funny way of understanding [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.427 (perp=6.697, rec=0.087, cos=0.001), tot_loss_proj:1.654 [t=0.26s]
prediction: ['[CLS] in its often funny way of understanding [SEP]']
[ 600/2000] tot_loss=1.411 (perp=6.697, rec=0.071, cos=0.001), tot_loss_proj:1.656 [t=0.25s]
prediction: ['[CLS] in its often funny way of understanding [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.420 (perp=6.697, rec=0.079, cos=0.001), tot_loss_proj:1.659 [t=0.26s]
prediction: ['[CLS] in its often funny way of understanding [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.461 (perp=6.923, rec=0.075, cos=0.001), tot_loss_proj:1.661 [t=0.27s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 750/2000] tot_loss=1.462 (perp=6.923, rec=0.076, cos=0.001), tot_loss_proj:1.658 [t=0.29s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.464 (perp=6.923, rec=0.078, cos=0.001), tot_loss_proj:1.665 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.459 (perp=6.923, rec=0.073, cos=0.001), tot_loss_proj:1.659 [t=0.27s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[ 900/2000] tot_loss=1.445 (perp=6.923, rec=0.060, cos=0.001), tot_loss_proj:1.659 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.456 (perp=6.923, rec=0.071, cos=0.001), tot_loss_proj:1.659 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1000/2000] tot_loss=1.455 (perp=6.923, rec=0.069, cos=0.001), tot_loss_proj:1.662 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1050/2000] tot_loss=1.456 (perp=6.923, rec=0.070, cos=0.001), tot_loss_proj:1.658 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1100/2000] tot_loss=1.451 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.664 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1150/2000] tot_loss=1.456 (perp=6.923, rec=0.070, cos=0.001), tot_loss_proj:1.665 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1200/2000] tot_loss=1.447 (perp=6.923, rec=0.061, cos=0.001), tot_loss_proj:1.663 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1250/2000] tot_loss=1.447 (perp=6.923, rec=0.062, cos=0.001), tot_loss_proj:1.663 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1300/2000] tot_loss=1.453 (perp=6.923, rec=0.068, cos=0.001), tot_loss_proj:1.663 [t=0.27s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1350/2000] tot_loss=1.446 (perp=6.923, rec=0.060, cos=0.001), tot_loss_proj:1.655 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1400/2000] tot_loss=1.452 (perp=6.923, rec=0.067, cos=0.001), tot_loss_proj:1.658 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1450/2000] tot_loss=1.453 (perp=6.923, rec=0.068, cos=0.001), tot_loss_proj:1.658 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1500/2000] tot_loss=1.463 (perp=6.923, rec=0.078, cos=0.001), tot_loss_proj:1.662 [t=0.27s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1550/2000] tot_loss=1.454 (perp=6.923, rec=0.069, cos=0.001), tot_loss_proj:1.663 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1600/2000] tot_loss=1.450 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.666 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1650/2000] tot_loss=1.458 (perp=6.923, rec=0.072, cos=0.001), tot_loss_proj:1.667 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1700/2000] tot_loss=1.458 (perp=6.923, rec=0.072, cos=0.001), tot_loss_proj:1.661 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1750/2000] tot_loss=1.442 (perp=6.923, rec=0.056, cos=0.001), tot_loss_proj:1.658 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1800/2000] tot_loss=1.454 (perp=6.923, rec=0.068, cos=0.001), tot_loss_proj:1.660 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1850/2000] tot_loss=1.451 (perp=6.923, rec=0.065, cos=0.001), tot_loss_proj:1.662 [t=0.27s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[1900/2000] tot_loss=1.452 (perp=6.923, rec=0.066, cos=0.001), tot_loss_proj:1.662 [t=0.25s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
[1950/2000] tot_loss=1.449 (perp=6.923, rec=0.063, cos=0.001), tot_loss_proj:1.665 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Attempt swap
[2000/2000] tot_loss=1.454 (perp=6.923, rec=0.069, cos=0.001), tot_loss_proj:1.667 [t=0.26s]
prediction: ['[CLS] in its often funny way, understanding [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] in its often funny way, understanding [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 87.938 | p: 87.550 | r: 88.465
rouge2     | fm: 52.194 | p: 52.059 | r: 52.437
rougeL     | fm: 75.787 | p: 75.445 | r: 76.229
rougeLsum  | fm: 75.781 | p: 75.384 | r: 76.245
r1fm+r2fm = 140.132

input #93 time: 0:11:03 | total time: 16:17:47


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
*********************************
*********************************
average of cosine similarity 0.9993168061064918
highest_index [0]
highest [0.9993168061064918]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 1.9509918689727783 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 1.9232128858566284 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 1.8279337882995605 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 1.823370099067688 for ['[CLS]ser straight alligator inches subject never splashed pony des withancy [SEP]']
[Init] best rec loss: 1.5088582038879395 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 1.4581665992736816 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 1.445499062538147 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 1.4265179634094238 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 1.4207502603530884 for ['[CLS] internal plum flowering expedition territorial shocks chronic centre crushed rockwellventing [SEP]']
[Init] best perm rec loss: 1.4164097309112549 for ['[CLS] centreventing flowering expedition shocks chronic crushed internal rockwell territorial plum [SEP]']
[Init] best perm rec loss: 1.4148106575012207 for ['[CLS] chronicventing territorial expedition shocks crushed centre internal rockwell flowering plum [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.880 (perp=12.248, rec=0.427, cos=0.004), tot_loss_proj:3.859 [t=0.26s]
prediction: ['[CLS] nor protests atoe inspection transmission antique ss containing junk lifeless [SEP]']
[ 100/2000] tot_loss=2.432 (perp=10.634, rec=0.304, cos=0.002), tot_loss_proj:3.389 [t=0.27s]
prediction: ['[CLS] nor cape a drugs inspection rack comic nor neither nor neither [SEP]']
[ 150/2000] tot_loss=2.161 (perp=9.555, rec=0.248, cos=0.001), tot_loss_proj:2.859 [t=0.25s]
prediction: ['[CLS] nor den neitherject funny nor original nor neither nor neither [SEP]']
[ 200/2000] tot_loss=2.184 (perp=9.888, rec=0.206, cos=0.001), tot_loss_proj:2.853 [t=0.27s]
prediction: ['[CLS] nor den neitherject funny nor original nor nor nor neither [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.972 (perp=8.904, rec=0.189, cos=0.002), tot_loss_proj:2.384 [t=0.25s]
prediction: ['[CLS] nor kind a that neither cape original nor nor currently funny [SEP]']
[ 300/2000] tot_loss=1.988 (perp=9.262, rec=0.135, cos=0.001), tot_loss_proj:3.321 [t=0.29s]
prediction: ['[CLS] terribly kind a that neither cape original nor nor s funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.933 (perp=9.172, rec=0.098, cos=0.001), tot_loss_proj:2.398 [t=0.25s]
prediction: ['[CLS] a terriblyr that neither cape original nor nor s funny [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.842 (perp=8.710, rec=0.099, cos=0.001), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] a terriblyr that neither cape original nor funny nor s [SEP]']
[ 450/2000] tot_loss=1.985 (perp=9.495, rec=0.085, cos=0.001), tot_loss_proj:2.504 [t=0.28s]
prediction: ['[CLS] a terriblyr that neither cape original any funny nor s [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.802 (perp=8.415, rec=0.118, cos=0.001), tot_loss_proj:2.329 [t=0.28s]
prediction: ['[CLS] a terriblyr that neither cape original nor any funny s [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.739 (perp=8.187, rec=0.101, cos=0.001), tot_loss_proj:2.076 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither original nor any funny s [SEP]']
[ 600/2000] tot_loss=1.725 (perp=8.187, rec=0.087, cos=0.001), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither original nor any funny s [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.716 (perp=8.187, rec=0.078, cos=0.001), tot_loss_proj:2.081 [t=0.24s]
prediction: ['[CLS] a terribly caper that neither original nor any funny s [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.714 (perp=8.187, rec=0.076, cos=0.000), tot_loss_proj:2.076 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither original nor any funny s [SEP]']
[ 750/2000] tot_loss=1.710 (perp=8.187, rec=0.072, cos=0.000), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither original nor any funny s [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.711 (perp=8.187, rec=0.073, cos=0.000), tot_loss_proj:2.074 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither original nor any funny s [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.824 (perp=8.720, rec=0.079, cos=0.001), tot_loss_proj:2.191 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither original nor s any funny [SEP]']
[ 900/2000] tot_loss=1.826 (perp=8.720, rec=0.081, cos=0.000), tot_loss_proj:2.183 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither original nor s any funny [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.718 (perp=8.198, rec=0.077, cos=0.000), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.704 (perp=8.198, rec=0.064, cos=0.000), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1050/2000] tot_loss=1.710 (perp=8.198, rec=0.070, cos=0.000), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.708 (perp=8.198, rec=0.068, cos=0.000), tot_loss_proj:2.014 [t=0.28s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.700 (perp=8.198, rec=0.060, cos=0.000), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1200/2000] tot_loss=1.714 (perp=8.198, rec=0.074, cos=0.000), tot_loss_proj:2.009 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.719 (perp=8.198, rec=0.079, cos=0.000), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.708 (perp=8.198, rec=0.068, cos=0.000), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1350/2000] tot_loss=1.704 (perp=8.198, rec=0.064, cos=0.000), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.706 (perp=8.198, rec=0.066, cos=0.000), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.709 (perp=8.198, rec=0.069, cos=0.000), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1500/2000] tot_loss=1.720 (perp=8.198, rec=0.079, cos=0.000), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.707 (perp=8.198, rec=0.067, cos=0.000), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.703 (perp=8.198, rec=0.063, cos=0.000), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1650/2000] tot_loss=1.701 (perp=8.198, rec=0.061, cos=0.000), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.707 (perp=8.198, rec=0.067, cos=0.000), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.711 (perp=8.198, rec=0.071, cos=0.000), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1800/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.000), tot_loss_proj:2.023 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.000), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.715 (perp=8.198, rec=0.075, cos=0.000), tot_loss_proj:2.018 [t=0.29s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
[1950/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.000), tot_loss_proj:2.015 [t=0.27s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.712 (perp=8.198, rec=0.072, cos=0.000), tot_loss_proj:2.016 [t=0.29s]
prediction: ['[CLS] a terribly caper that neither s original nor any funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] a terribly caper that neither s original nor any funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 87.965 | p: 87.589 | r: 88.510
rouge2     | fm: 52.056 | p: 51.877 | r: 52.258
rougeL     | fm: 75.828 | p: 75.485 | r: 76.338
rougeLsum  | fm: 75.846 | p: 75.490 | r: 76.378
r1fm+r2fm = 140.021

input #94 time: 0:11:05 | total time: 16:28:53


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
*********************************
*********************************
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.9503685235977173 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.9354028701782227 for ['[CLS] bree theological teaching maybe backed past starvinglusion pigs twitcharable badic flower able [SEP]']
[Init] best rec loss: 1.8349953889846802 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 1.8156688213348389 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 1.7410764694213867 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 1.6973210573196411 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 1.6551605463027954 for ['[CLS] fire some phillip margin khz number grace discipline formula plains when secretarygrave duke hell [SEP]']
[Init] best rec loss: 1.560425043106079 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 1.3368700742721558 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 1.3238457441329956 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 1.3197247982025146 for ['[CLS] ] damp tech trailer cut privateے hanging block complete monty pressure sister wirenne [SEP]']
[Init] best perm rec loss: 1.319675087928772 for ['[CLS] damp pressure techے monty sister private cut complete trailer hanging ] wire blocknne [SEP]']
[Init] best perm rec loss: 1.3172006607055664 for ['[CLS] ] cut private technne monty trailer block sister wire dampے hanging complete pressure [SEP]']
[Init] best perm rec loss: 1.3129985332489014 for ['[CLS] monty sister private cut tech trailer wire block hangingnne damp ]ے complete pressure [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.532 (perp=10.997, rec=0.328, cos=0.005), tot_loss_proj:2.776 [t=0.25s]
prediction: ['[CLS] hopeless old private housing, hopeless junk tunnel violent abusive worst hopeless? a hopeless [SEP]']
[ 100/2000] tot_loss=2.569 (perp=11.612, rec=0.245, cos=0.002), tot_loss_proj:2.872 [t=0.27s]
prediction: ["[CLS] hopeless dead an housing story hopeless dna tunnel hopeless becomes'hopeless - became hopeless [SEP]"]
[ 150/2000] tot_loss=2.468 (perp=11.398, rec=0.187, cos=0.001), tot_loss_proj:2.812 [t=0.28s]
prediction: ['[CLS] half dead an housing story hopeless dnased conditions becomes, hopeless. becomes hopeless [SEP]']
[ 200/2000] tot_loss=2.733 (perp=12.847, rec=0.163, cos=0.001), tot_loss_proj:3.099 [t=0.27s]
prediction: ['[CLS] sad deadless housing story hopeless dnafying term becomes, hopelessdle becomes hopeless [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.289 (perp=10.699, rec=0.148, cos=0.001), tot_loss_proj:2.644 [t=0.27s]
prediction: ["[CLS] hugh deadlesseld story'livingfying termsat, muddle becomes hopeless [SEP]"]
[ 300/2000] tot_loss=2.280 (perp=10.692, rec=0.141, cos=0.001), tot_loss_proj:2.673 [t=0.28s]
prediction: ["[CLS] hugh mud muddle story'dnafyingfyingsat, muddle becomes hopeless [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.998 (perp=9.336, rec=0.129, cos=0.001), tot_loss_proj:2.474 [t=0.29s]
prediction: ['[CLS] hugh not muddle story\'dnafying "sat, muddle becomes hopeless [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.063 (perp=9.687, rec=0.125, cos=0.001), tot_loss_proj:2.466 [t=0.29s]
prediction: ['[CLS] denisfying muddle story \'fyingzhou "sat, muddle becomes hopeless [SEP]']
[ 450/2000] tot_loss=2.074 (perp=9.832, rec=0.107, cos=0.001), tot_loss_proj:2.533 [t=0.28s]
prediction: ['[CLS] denisis muddle story \'fyingzhou "sat, muddle becomes hopeless [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.976 (perp=9.325, rec=0.110, cos=0.001), tot_loss_proj:2.353 [t=0.28s]
prediction: ["[CLS] denisis'muddle story 'fyingzhousat, muddle becomes hopeless [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.036 (perp=9.610, rec=0.113, cos=0.001), tot_loss_proj:2.391 [t=0.28s]
prediction: ["[CLS] denisis'mud ) story 'zhoufyingsat, muddle becomes hopeless [SEP]"]
[ 600/2000] tot_loss=2.127 (perp=10.116, rec=0.103, cos=0.001), tot_loss_proj:2.491 [t=0.26s]
prediction: ["[CLS] denisis ( mud ) story 'zhoufyingsat, muddle becomes hopeless [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.988 (perp=9.454, rec=0.096, cos=0.001), tot_loss_proj:2.394 [t=0.29s]
prediction: ["[CLS] denisis'mud ) story azhoufyingsat, muddle becomes hopeless [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.996 (perp=9.524, rec=0.090, cos=0.001), tot_loss_proj:2.468 [t=0.26s]
prediction: ["[CLS] denisis'mud ) story azhoufyingsat hopeless muddle becomes, [SEP]"]
[ 750/2000] tot_loss=1.935 (perp=9.226, rec=0.089, cos=0.001), tot_loss_proj:2.441 [t=0.29s]
prediction: ["[CLS] denisis'mud ) story afyingfyingsat hopeless muddle becomes, [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.787 (perp=8.422, rec=0.101, cos=0.001), tot_loss_proj:2.308 [t=0.28s]
prediction: ["[CLS] denissatis'mud ) story afyingfying hopeless muddle becomes, [SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.753 (perp=8.297, rec=0.093, cos=0.001), tot_loss_proj:2.267 [t=0.28s]
prediction: ["[CLS] denissatis'mud ) afying storyfying hopeless muddle becomes, [SEP]"]
[ 900/2000] tot_loss=1.753 (perp=8.297, rec=0.093, cos=0.001), tot_loss_proj:2.279 [t=0.28s]
prediction: ["[CLS] denissatis'mud ) afying storyfying hopeless muddle becomes, [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.746 (perp=8.297, rec=0.085, cos=0.001), tot_loss_proj:2.272 [t=0.26s]
prediction: ["[CLS] denissatis'mud ) afying storyfying hopeless muddle becomes, [SEP]"]
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.921 (perp=9.163, rec=0.087, cos=0.001), tot_loss_proj:2.409 [t=0.28s]
prediction: ["[CLS] denissatis'mud ) a unfying storyfying hopelessdle becomes, [SEP]"]
[1050/2000] tot_loss=1.914 (perp=9.163, rec=0.080, cos=0.001), tot_loss_proj:2.412 [t=0.28s]
prediction: ["[CLS] denissatis'mud ) a unfying storyfying hopelessdle becomes, [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.834 (perp=8.736, rec=0.085, cos=0.001), tot_loss_proj:2.346 [t=0.26s]
prediction: ["[CLS] denis unsatis'mud ) afying storyfying hopelessdle becomes, [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.704 (perp=8.060, rec=0.091, cos=0.001), tot_loss_proj:2.109 [t=0.30s]
prediction: ["[CLS] denis unsatis ('mud ) a storyfying hopelessdle becomes, [SEP]"]
[1200/2000] tot_loss=1.696 (perp=8.060, rec=0.083, cos=0.001), tot_loss_proj:2.109 [t=0.27s]
prediction: ["[CLS] denis unsatis ('mud ) a storyfying hopelessdle becomes, [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.590 (perp=7.547, rec=0.080, cos=0.001), tot_loss_proj:2.000 [t=0.28s]
prediction: ["[CLS] denis unsatis ('muddle ) a storyfying hopeless becomes, [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.525 (perp=7.189, rec=0.086, cos=0.001), tot_loss_proj:1.906 [t=0.28s]
prediction: ["[CLS] denis unsatis ( a muddle )'storyfying hopeless becomes, [SEP]"]
[1350/2000] tot_loss=1.515 (perp=7.189, rec=0.076, cos=0.001), tot_loss_proj:1.914 [t=0.27s]
prediction: ["[CLS] denis unsatis ( a muddle )'storyfying hopeless becomes, [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.466 (perp=6.864, rec=0.093, cos=0.001), tot_loss_proj:1.820 [t=0.28s]
prediction: ["[CLS] denis unsatis ( a muddle )'hopelessfying story becomes, [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.464 (perp=6.864, rec=0.091, cos=0.001), tot_loss_proj:1.825 [t=0.27s]
prediction: ["[CLS] denis unsatis ( a muddle )'hopelessfying story becomes, [SEP]"]
[1500/2000] tot_loss=1.455 (perp=6.864, rec=0.081, cos=0.001), tot_loss_proj:1.829 [t=0.29s]
prediction: ["[CLS] denis unsatis ( a muddle )'hopelessfying story becomes, [SEP]"]
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.371 (perp=6.470, rec=0.077, cos=0.001), tot_loss_proj:1.725 [t=0.28s]
prediction: ["[CLS] denis unsatis'hopeless ( a muddle )fying story becomes, [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.372 (perp=6.470, rec=0.077, cos=0.001), tot_loss_proj:1.731 [t=0.28s]
prediction: ["[CLS] denis unsatis'hopeless ( a muddle )fying story becomes, [SEP]"]
[1650/2000] tot_loss=1.369 (perp=6.470, rec=0.074, cos=0.001), tot_loss_proj:1.722 [t=0.27s]
prediction: ["[CLS] denis unsatis'hopeless ( a muddle )fying story becomes, [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.366 (perp=6.470, rec=0.071, cos=0.001), tot_loss_proj:1.725 [t=0.26s]
prediction: ["[CLS] denis unsatis'hopeless ( a muddle )fying story becomes, [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.292 (perp=6.033, rec=0.084, cos=0.001), tot_loss_proj:1.657 [t=0.29s]
prediction: ["[CLS] denis unsatisfying hopeless ( a muddle )'story becomes, [SEP]"]
[1800/2000] tot_loss=1.289 (perp=6.033, rec=0.082, cos=0.001), tot_loss_proj:1.657 [t=0.28s]
prediction: ["[CLS] denis unsatisfying hopeless ( a muddle )'story becomes, [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.265 (perp=6.001, rec=0.064, cos=0.001), tot_loss_proj:1.618 [t=0.27s]
prediction: ["[CLS] denis unsatisfying'hopeless ( a muddle ) story becomes, [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.274 (perp=6.001, rec=0.073, cos=0.001), tot_loss_proj:1.615 [t=0.29s]
prediction: ["[CLS] denis unsatisfying'hopeless ( a muddle ) story becomes, [SEP]"]
[1950/2000] tot_loss=1.279 (perp=6.001, rec=0.078, cos=0.001), tot_loss_proj:1.610 [t=0.28s]
prediction: ["[CLS] denis unsatisfying'hopeless ( a muddle ) story becomes, [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.274 (perp=6.001, rec=0.073, cos=0.001), tot_loss_proj:1.611 [t=0.28s]
prediction: ["[CLS] denis unsatisfying'hopeless ( a muddle ) story becomes, [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] denis unsatisfying'hopeless ( a muddle ) story becomes, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.110 | p: 87.703 | r: 88.687
rouge2     | fm: 51.486 | p: 51.295 | r: 51.733
rougeL     | fm: 75.584 | p: 75.219 | r: 76.025
rougeLsum  | fm: 75.564 | p: 75.268 | r: 76.068
r1fm+r2fm = 139.596

input #95 time: 0:11:33 | total time: 16:40:26


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
*********************************
*********************************
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 1.794450283050537 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 1.7930576801300049 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 1.6783851385116577 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 1.6411691904067993 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 1.634422779083252 for ['[CLS]rg woken became jenny marx further league performance union holding winning instrumental re distance conscious [SEP]']
[Init] best rec loss: 1.4709296226501465 for ['[CLS] hand hopefullysas super profit laundry readings context places liaison mollusk talents rest feature date [SEP]']
[Init] best perm rec loss: 1.466230869293213 for ['[CLS] profitsas hand rest hopefully places laundry mollusk date liaison feature talents readings context super [SEP]']
[Init] best perm rec loss: 1.4635539054870605 for ['[CLS] readings liaison profit places contextsas rest hopefully laundry feature hand talents date super mollusk [SEP]']
[Init] best perm rec loss: 1.4631778001785278 for ['[CLS] date hopefully laundry talents super profit restsas feature mollusk hand places context liaison readings [SEP]']
[Init] best perm rec loss: 1.4482918977737427 for ['[CLS] super profit context readings laundry places datesas feature hand liaison hopefully rest talents mollusk [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.876 (perp=12.325, rec=0.403, cos=0.008), tot_loss_proj:3.790 [t=0.25s]
prediction: ['[CLS] nice on improved region allows than over brakes at few lady railway structure amazing airfield [SEP]']
[ 100/2000] tot_loss=2.555 (perp=11.242, rec=0.305, cos=0.001), tot_loss_proj:3.728 [t=0.25s]
prediction: ['[CLS] nice to several on online than force della at few people people land especially force [SEP]']
[ 150/2000] tot_loss=2.360 (perp=10.456, rec=0.267, cos=0.001), tot_loss_proj:3.178 [t=0.26s]
prediction: ['[CLS] nice to million into modified people force ahead intoane people people situations that force [SEP]']
[ 200/2000] tot_loss=2.271 (perp=10.249, rec=0.220, cos=0.001), tot_loss_proj:3.092 [t=0.26s]
prediction: ['[CLS] nice himself million into himself people forces are intoane people men situations that force [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.397 (perp=10.896, rec=0.216, cos=0.002), tot_loss_proj:3.287 [t=0.26s]
prediction: ['[CLS] nice himself million into himself people situations have into situations lesser men society himself force [SEP]']
[ 300/2000] tot_loss=2.247 (perp=10.309, rec=0.184, cos=0.001), tot_loss_proj:3.330 [t=0.26s]
prediction: ['[CLS] nice himself lesser on himself people situations into into cover lesser men running on force [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.317 (perp=10.849, rec=0.147, cos=0.001), tot_loss_proj:3.188 [t=0.26s]
prediction: ['[CLS] bonus himself himself on lesser people situations into into cover lesser men cover on force [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.093 (perp=9.586, rec=0.174, cos=0.002), tot_loss_proj:3.268 [t=0.26s]
prediction: ['[CLS] cover himself himself on lesser people situations into would bonus lesser men cover on force [SEP]']
[ 450/2000] tot_loss=1.868 (perp=8.638, rec=0.140, cos=0.001), tot_loss_proj:2.921 [t=0.27s]
prediction: ['[CLS] cover himself himself on lesser people situations that would bonus lesser men cover on force [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.930 (perp=8.958, rec=0.138, cos=0.000), tot_loss_proj:3.148 [t=0.26s]
prediction: ['[CLS] cover himself on policies people situations that would bonus lesser men running himself on force [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.940 (perp=8.991, rec=0.142, cos=0.001), tot_loss_proj:3.284 [t=0.25s]
prediction: ['[CLS] million cover himself on people situations that would bonus lesser men run himself on force [SEP]']
[ 600/2000] tot_loss=1.917 (perp=8.931, rec=0.130, cos=0.000), tot_loss_proj:3.191 [t=0.26s]
prediction: ['[CLS] million cover himself on people situations that would bonus lesser men run for on force [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.879 (perp=8.744, rec=0.130, cos=0.000), tot_loss_proj:2.975 [t=0.26s]
prediction: ['[CLS] million cover himself on people situations that bonus lesser men would run and on force [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.665 (perp=7.687, rec=0.127, cos=0.001), tot_loss_proj:2.645 [t=0.27s]
prediction: ['[CLS] and cover himself on people situations that which lesser men would run bordering on force [SEP]']
[ 750/2000] tot_loss=1.805 (perp=8.458, rec=0.114, cos=0.000), tot_loss_proj:2.735 [t=0.27s]
prediction: ['[CLS] and cover himself on people situations that which lesser men would run verbal on force [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.696 (perp=7.940, rec=0.107, cos=0.000), tot_loss_proj:2.496 [t=0.26s]
prediction: ['[CLS] and cover himself on people situations that which lesser men would run on verbal force [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.568 (perp=7.268, rec=0.114, cos=0.000), tot_loss_proj:2.318 [t=0.26s]
prediction: ['[CLS] and cover himself on people that situations which lesser men would run on for force [SEP]']
[ 900/2000] tot_loss=1.571 (perp=7.268, rec=0.117, cos=0.000), tot_loss_proj:2.322 [t=0.26s]
prediction: ['[CLS] and cover himself on people that situations which lesser men would run on for force [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.459 (perp=6.766, rec=0.105, cos=0.000), tot_loss_proj:2.643 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations which lesser men would run on for force [SEP]']
Attempt swap
[1000/2000] tot_loss=1.458 (perp=6.766, rec=0.105, cos=0.000), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS] into cover himself on people and situations which lesser men would run on for force [SEP]']
[1050/2000] tot_loss=1.465 (perp=6.817, rec=0.102, cos=0.000), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run on for force [SEP]']
Attempt swap
[1100/2000] tot_loss=1.544 (perp=7.204, rec=0.103, cos=0.000), tot_loss_proj:2.723 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run that for force [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.473 (perp=6.822, rec=0.108, cos=0.000), tot_loss_proj:2.654 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for on force [SEP]']
[1200/2000] tot_loss=1.431 (perp=6.619, rec=0.107, cos=0.000), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1250/2000] tot_loss=1.427 (perp=6.619, rec=0.103, cos=0.000), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1300/2000] tot_loss=1.416 (perp=6.619, rec=0.092, cos=0.000), tot_loss_proj:2.643 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
[1350/2000] tot_loss=1.426 (perp=6.619, rec=0.101, cos=0.000), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1400/2000] tot_loss=1.420 (perp=6.619, rec=0.096, cos=0.000), tot_loss_proj:2.638 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1450/2000] tot_loss=1.410 (perp=6.619, rec=0.086, cos=0.000), tot_loss_proj:2.646 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
[1500/2000] tot_loss=1.418 (perp=6.619, rec=0.094, cos=0.000), tot_loss_proj:2.644 [t=0.25s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1550/2000] tot_loss=1.432 (perp=6.619, rec=0.108, cos=0.000), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1600/2000] tot_loss=1.422 (perp=6.619, rec=0.098, cos=0.000), tot_loss_proj:2.645 [t=0.25s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
[1650/2000] tot_loss=1.416 (perp=6.619, rec=0.092, cos=0.000), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1700/2000] tot_loss=1.418 (perp=6.619, rec=0.094, cos=0.000), tot_loss_proj:2.649 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1750/2000] tot_loss=1.426 (perp=6.619, rec=0.102, cos=0.000), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
[1800/2000] tot_loss=1.420 (perp=6.619, rec=0.095, cos=0.000), tot_loss_proj:2.643 [t=0.27s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1850/2000] tot_loss=1.416 (perp=6.619, rec=0.091, cos=0.000), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[1900/2000] tot_loss=1.415 (perp=6.619, rec=0.091, cos=0.000), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
[1950/2000] tot_loss=1.411 (perp=6.619, rec=0.086, cos=0.000), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Attempt swap
[2000/2000] tot_loss=1.417 (perp=6.619, rec=0.093, cos=0.000), tot_loss_proj:2.644 [t=0.26s]
prediction: ['[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] into cover himself on people and situations that lesser men would run for that force [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 70.588 | p: 70.588 | r: 70.588
rougeLsum  | fm: 70.588 | p: 70.588 | r: 70.588
r1fm+r2fm = 131.618

[Aggregate metrics]:
rouge1     | fm: 88.196 | p: 87.768 | r: 88.707
rouge2     | fm: 51.394 | p: 51.209 | r: 51.624
rougeL     | fm: 75.559 | p: 75.227 | r: 76.018
rougeLsum  | fm: 75.597 | p: 75.275 | r: 76.077
r1fm+r2fm = 139.590

input #96 time: 0:11:06 | total time: 16:51:33


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
*********************************
*********************************
average of cosine similarity 0.9991660915875737
highest_index [0]
highest [0.9991660915875737]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 1.292439579963684 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 1.0615618228912354 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 1.0516561269760132 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 1.0462650060653687 for ['[CLS] pass testten which 2016 victoria [SEP]']
[Init] best perm rec loss: 1.0451700687408447 for ['[CLS] pass test victoriaten 2016 which [SEP]']
[Init] best perm rec loss: 1.0422724485397339 for ['[CLS] victoria test 2016 pass whichten [SEP]']
[Init] best perm rec loss: 1.0385247468948364 for ['[CLS] pass test which victoria 2016ten [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.791 (perp=11.981, rec=0.387, cos=0.008), tot_loss_proj:4.101 [t=0.27s]
prediction: ['[CLS] sets never at paradise catching & [SEP]']
[ 100/2000] tot_loss=2.754 (perp=12.408, rec=0.270, cos=0.002), tot_loss_proj:3.866 [t=0.26s]
prediction: ['[CLS] componentsforfortable normal & [SEP]']
[ 150/2000] tot_loss=2.710 (perp=12.583, rec=0.189, cos=0.004), tot_loss_proj:4.263 [t=0.26s]
prediction: ['[CLS] charactersforfortablefor & [SEP]']
[ 200/2000] tot_loss=2.612 (perp=12.427, rec=0.124, cos=0.002), tot_loss_proj:4.194 [t=0.25s]
prediction: ['[CLS] charactersgetfortablefor and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.168 (perp=10.153, rec=0.135, cos=0.003), tot_loss_proj:2.658 [t=0.25s]
prediction: ['[CLS]forgetfortable characters and [SEP]']
[ 300/2000] tot_loss=2.127 (perp=10.153, rec=0.095, cos=0.001), tot_loss_proj:2.685 [t=0.26s]
prediction: ['[CLS]forgetfortable characters and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.207 (perp=5.520, rec=0.103, cos=0.001), tot_loss_proj:1.304 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.143 (perp=5.309, rec=0.081, cos=0.001), tot_loss_proj:1.143 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.135 (perp=5.309, rec=0.073, cos=0.001), tot_loss_proj:1.146 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.119 (perp=5.309, rec=0.057, cos=0.001), tot_loss_proj:1.136 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.131 (perp=5.309, rec=0.068, cos=0.001), tot_loss_proj:1.136 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.129 (perp=5.309, rec=0.066, cos=0.001), tot_loss_proj:1.130 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.139 (perp=5.309, rec=0.077, cos=0.001), tot_loss_proj:1.127 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.127 (perp=5.309, rec=0.065, cos=0.001), tot_loss_proj:1.118 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.125 (perp=5.309, rec=0.063, cos=0.001), tot_loss_proj:1.135 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.128 (perp=5.309, rec=0.065, cos=0.001), tot_loss_proj:1.135 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.137 (perp=5.309, rec=0.074, cos=0.001), tot_loss_proj:1.139 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.125 (perp=5.309, rec=0.062, cos=0.001), tot_loss_proj:1.132 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.122 (perp=5.309, rec=0.060, cos=0.001), tot_loss_proj:1.141 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.133 (perp=5.309, rec=0.071, cos=0.001), tot_loss_proj:1.132 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.139 (perp=5.309, rec=0.077, cos=0.001), tot_loss_proj:1.125 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.127 (perp=5.309, rec=0.064, cos=0.001), tot_loss_proj:1.140 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.126 (perp=5.309, rec=0.064, cos=0.001), tot_loss_proj:1.134 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.119 (perp=5.309, rec=0.057, cos=0.001), tot_loss_proj:1.125 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.125 (perp=5.309, rec=0.063, cos=0.001), tot_loss_proj:1.128 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.122 (perp=5.309, rec=0.060, cos=0.001), tot_loss_proj:1.135 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.124 (perp=5.309, rec=0.061, cos=0.001), tot_loss_proj:1.134 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.126 (perp=5.309, rec=0.063, cos=0.001), tot_loss_proj:1.136 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.137 (perp=5.309, rec=0.074, cos=0.001), tot_loss_proj:1.126 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.130 (perp=5.309, rec=0.067, cos=0.001), tot_loss_proj:1.130 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.136 (perp=5.309, rec=0.074, cos=0.001), tot_loss_proj:1.135 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.128 (perp=5.309, rec=0.066, cos=0.001), tot_loss_proj:1.140 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.125 (perp=5.309, rec=0.063, cos=0.001), tot_loss_proj:1.133 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.130 (perp=5.309, rec=0.068, cos=0.001), tot_loss_proj:1.128 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.122 (perp=5.309, rec=0.059, cos=0.001), tot_loss_proj:1.131 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.132 (perp=5.309, rec=0.069, cos=0.001), tot_loss_proj:1.135 [t=0.24s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.118 (perp=5.309, rec=0.056, cos=0.001), tot_loss_proj:1.127 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.128 (perp=5.309, rec=0.066, cos=0.001), tot_loss_proj:1.149 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.124 (perp=5.309, rec=0.061, cos=0.001), tot_loss_proj:1.123 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.126 (perp=5.309, rec=0.064, cos=0.001), tot_loss_proj:1.124 [t=0.26s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.320 | p: 87.910 | r: 88.844
rouge2     | fm: 51.999 | p: 51.805 | r: 52.260
rougeL     | fm: 75.798 | p: 75.463 | r: 76.188
rougeLsum  | fm: 75.881 | p: 75.492 | r: 76.444
r1fm+r2fm = 140.319

input #97 time: 0:11:02 | total time: 17:02:35


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
*********************************
*********************************
average of cosine similarity 0.9991916976323434
highest_index [0]
highest [0.9991916976323434]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 1.1314566135406494 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best rec loss: 1.1208252906799316 for ['[CLS] nature " open victims [SEP]']
[Init] best perm rec loss: 1.1160643100738525 for ['[CLS] " victims nature open [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.705, rec=0.326, cos=0.004), tot_loss_proj:3.197 [t=0.25s]
prediction: ['[CLS]fulen let empty [SEP]']
[ 100/2000] tot_loss=2.990 (perp=13.762, rec=0.233, cos=0.005), tot_loss_proj:4.599 [t=0.26s]
prediction: ['[CLS]ful myrafulful [SEP]']
[ 150/2000] tot_loss=2.757 (perp=12.751, rec=0.201, cos=0.006), tot_loss_proj:4.202 [t=0.25s]
prediction: ['[CLS]llingllingfulful [SEP]']
[ 200/2000] tot_loss=2.725 (perp=12.751, rec=0.172, cos=0.003), tot_loss_proj:4.201 [t=0.28s]
prediction: ['[CLS]llingllingfulful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.524 (perp=11.645, rec=0.190, cos=0.005), tot_loss_proj:3.370 [t=0.27s]
prediction: ['[CLS]fulfifullling [SEP]']
[ 300/2000] tot_loss=2.464 (perp=11.645, rec=0.134, cos=0.001), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS]fulfifullling [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.096 (perp=4.948, rec=0.105, cos=0.001), tot_loss_proj:1.091 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.058 (perp=4.948, rec=0.068, cos=0.000), tot_loss_proj:1.085 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.056 (perp=4.948, rec=0.066, cos=0.000), tot_loss_proj:1.082 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.057 (perp=4.948, rec=0.067, cos=0.000), tot_loss_proj:1.078 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.057 (perp=4.948, rec=0.068, cos=0.000), tot_loss_proj:1.069 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.049 (perp=4.948, rec=0.059, cos=0.000), tot_loss_proj:1.083 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.052 (perp=4.948, rec=0.062, cos=0.000), tot_loss_proj:1.072 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.059 (perp=4.948, rec=0.069, cos=0.000), tot_loss_proj:1.075 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.062 (perp=4.948, rec=0.072, cos=0.000), tot_loss_proj:1.073 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.047 (perp=4.948, rec=0.057, cos=0.000), tot_loss_proj:1.077 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.057 (perp=4.948, rec=0.067, cos=0.000), tot_loss_proj:1.076 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.056 (perp=4.948, rec=0.066, cos=0.000), tot_loss_proj:1.071 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.049 (perp=4.948, rec=0.059, cos=0.000), tot_loss_proj:1.067 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.052 (perp=4.948, rec=0.062, cos=0.000), tot_loss_proj:1.074 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.045 (perp=4.948, rec=0.055, cos=0.000), tot_loss_proj:1.068 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.061 (perp=4.948, rec=0.071, cos=0.000), tot_loss_proj:1.077 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.061 (perp=4.948, rec=0.071, cos=0.000), tot_loss_proj:1.071 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.057 (perp=4.948, rec=0.067, cos=0.000), tot_loss_proj:1.074 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.054 (perp=4.948, rec=0.064, cos=0.000), tot_loss_proj:1.061 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.044 (perp=4.948, rec=0.055, cos=0.000), tot_loss_proj:1.064 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.053 (perp=4.948, rec=0.063, cos=0.000), tot_loss_proj:1.077 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.042 (perp=4.948, rec=0.052, cos=0.000), tot_loss_proj:1.072 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.056 (perp=4.948, rec=0.066, cos=0.000), tot_loss_proj:1.073 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.059 (perp=4.948, rec=0.069, cos=0.000), tot_loss_proj:1.061 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.045 (perp=4.948, rec=0.055, cos=0.000), tot_loss_proj:1.078 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.047 (perp=4.948, rec=0.057, cos=0.000), tot_loss_proj:1.066 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.052 (perp=4.948, rec=0.062, cos=0.000), tot_loss_proj:1.073 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.062 (perp=4.948, rec=0.072, cos=0.000), tot_loss_proj:1.062 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.044 (perp=4.948, rec=0.054, cos=0.000), tot_loss_proj:1.077 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.052 (perp=4.948, rec=0.063, cos=0.000), tot_loss_proj:1.069 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.048 (perp=4.948, rec=0.058, cos=0.000), tot_loss_proj:1.069 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.043 (perp=4.948, rec=0.053, cos=0.000), tot_loss_proj:1.071 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.043 (perp=4.948, rec=0.053, cos=0.000), tot_loss_proj:1.068 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.048 (perp=4.948, rec=0.058, cos=0.000), tot_loss_proj:1.079 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.368 | p: 87.994 | r: 88.887
rouge2     | fm: 52.379 | p: 52.230 | r: 52.601
rougeL     | fm: 76.041 | p: 75.667 | r: 76.478
rougeLsum  | fm: 76.044 | p: 75.678 | r: 76.549
r1fm+r2fm = 140.747

input #98 time: 0:11:03 | total time: 17:13:38


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
*********************************
*********************************
average of cosine similarity 0.9993095816453156
highest_index [0]
highest [0.9993095816453156]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 1.5378683805465698 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 1.4138236045837402 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 1.3704537153244019 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 1.3552578687667847 for ['[CLS] football trust o guide every into integral? maybe200nington just layne what alaska priory incidentffled gymnastics manufactured lines kim survived told particularlygui discipline lonely # level pointsuna loves leaving it providence [SEP]']
[Init] best rec loss: 1.3264182806015015 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 1.2738163471221924 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best rec loss: 1.2734564542770386 for ["[CLS]jevic authority could victory gregory u yearquin choshing though horton else final obama authored speeding'recreation as disgust grace heroin his door pronunciationlu heel japanese nehru lower distinguished mere buenos base whether [SEP]"]
[Init] best perm rec loss: 1.2730098962783813 for ["[CLS] grace whether mere u nehrushing could recreation heroin base year distinguished victory pronunciation gregory authority disgust final as lower speeding hortonquin his'japanese though heel obamalu else buenosjevic authored cho door [SEP]"]
[Init] best perm rec loss: 1.27029550075531 for ["[CLS] final base as victory though disgust door gregory obama distinguished mere u yearquin'authored heel japanese could horton lower else nehru authority cho heroin pronunciation buenos grace whetherlujevicshing his speeding recreation [SEP]"]
[Init] best perm rec loss: 1.2686342000961304 for ["[CLS] victory speeding'year obama u whether mere heel japanesequin heroin his door buenos could else distinguished final authority authored grace nehru recreation horton lower disgust gregory pronunciation thoughlushing as chojevic base [SEP]"]
[Init] best perm rec loss: 1.2669504880905151 for ["[CLS] lower disgust his buenos as speeding year authored obama base mere distinguished grace victory whether though final heelshing heroin doorjevic nehru gregory u japanese'authority couldquin elselu pronunciation recreation cho horton [SEP]"]
[Init] best perm rec loss: 1.261819839477539 for ["[CLS] year buenos japanese though'u couldquin distinguished obama else door heel nehru authority final speeding cho whether victory as base pronunciation disgust heroinshing gregory grace hortonjevic lower recreation authoredlu his mere [SEP]"]
[Init] best perm rec loss: 1.257513165473938 for ["[CLS] grace distinguished could horton base his heroin though final victory else lower heelquin gregory obama door authority u authored'mere as speeding buenosjevic year cho whetherlu japanese recreation nehru disgust pronunciationshing [SEP]"]
[Init] best perm rec loss: 1.2564736604690552 for ["[CLS] base lower buenos gregory authority year pronunciation recreationquin nehru though disgust u speeding japanese cho victory authored grace door as could distinguished heroinshinglujevic final heel horton obama whether'his mere else [SEP]"]
[Init] best perm rec loss: 1.2494480609893799 for ["[CLS] victory u distinguished disgust gregory heroin authoredshing buenos grace else year lower heel mere finallu pronunciation'cho recreation though whetherquin door could base japanese obama his as nehrujevic speeding authority horton [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.662 (perp=11.725, rec=0.315, cos=0.002), tot_loss_proj:3.130 [t=0.26s]
prediction: ["[CLS] ze attempted wait shit lecture fraud could kiss torture no forgotten. worse pronouns. invitation movie worst'film battalion turned everything thomas might waste ran thinking coming film whenova a radiation cause deaths [SEP]"]
[ 100/2000] tot_loss=2.657 (perp=12.091, rec=0.238, cos=0.001), tot_loss_proj:3.614 [t=0.27s]
prediction: ["[CLS]inger'bother shit lecture fuss liked triple teasing no forgotten but horrible pronouns, ticket playbackssing'film battalion fei fun hot di ban walked really feel film di cater a radiation earthquake death [SEP]"]
[ 150/2000] tot_loss=2.475 (perp=11.333, rec=0.206, cos=0.003), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] out ` bother shit lecture ` fun di fun no forgotten but horrible pronouns, ticket playbackssing ` film battalion fei fun henderson di di walked talked the film di cost a radiation intensity the [SEP]']
[ 200/2000] tot_loss=2.258 (perp=10.428, rec=0.171, cos=0.001), tot_loss_proj:2.919 [t=0.27s]
prediction: ["[CLS] out muttering lack'commotion ` fun di fun nothingssing but horrible `, ticket mindssing ` film appearance turned fun his di di walked took the film di cost a little disability the [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.414 (perp=11.161, rec=0.179, cos=0.003), tot_loss_proj:3.044 [t=0.28s]
prediction: ["[CLS] out muttering terrible nothingssing but horrible `'ticket mind lack'danny ` fun dissing ` ` organization turns fun his di di walked had mind film di cost the enough killer the [SEP]"]
[ 300/2000] tot_loss=2.293 (perp=10.791, rec=0.134, cos=0.001), tot_loss_proj:3.105 [t=0.26s]
prediction: ["[CLS] out muttering terrible no their but horrible `'ticket consideration muttering'danny'fun dissing ` ` them fun fun his di di walked had mind film di cost that enough govt so [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.147 (perp=10.069, rec=0.133, cos=0.001), tot_loss_proj:2.823 [t=0.28s]
prediction: ["[CLS] out muttering terrible mind they but horrible `'ticket sensation muttering'danny ` fun dissing ` ` them fun fun the di di walked had no film di cost that they of so [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.080 (perp=9.700, rec=0.139, cos=0.001), tot_loss_proj:2.783 [t=0.27s]
prediction: ["[CLS] out of terrible mind they but horrible `'ticket sensation muttering'danny ` fun dissing ` ` organization fun fun the di di walked had no film di cost that little muttering so [SEP]"]
[ 450/2000] tot_loss=2.139 (perp=10.094, rec=0.120, cos=0.000), tot_loss_proj:2.810 [t=0.26s]
prediction: ["[CLS] out s terrible mind they but horrible `'ticket cost muttering'danny ` fun dissing ` ` morality fun fun the di di walked had no film di cost that they muttering so [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.134 (perp=10.077, rec=0.118, cos=0.000), tot_loss_proj:2.782 [t=0.27s]
prediction: ["[CLS] out but terrible mind they s horrible `'ticket cost muttering ` danny ` fun dissing ` ` them fun fun the di di walked had, film di cost that they muttering so [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.049 (perp=9.698, rec=0.109, cos=0.000), tot_loss_proj:2.718 [t=0.27s]
prediction: ["[CLS] out but terrible mind they s horrible dinner'ticket cost muttering ` ` ` fun dissing ` ` them fun fun the di di walked had, film di cost that they muttering so [SEP]"]
[ 600/2000] tot_loss=1.961 (perp=9.310, rec=0.098, cos=0.000), tot_loss_proj:2.620 [t=0.26s]
prediction: ["[CLS] out but terrible mind they s horrible dinner'ticket cost muttering ` ` ` fun dissing ` ` them fun fun the di t walked had, film'cost that they muttering so [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.979 (perp=9.374, rec=0.103, cos=0.000), tot_loss_proj:2.667 [t=0.27s]
prediction: ["[CLS] out but terrible mind they'horrible flood'ticket cost muttering ` ` ` have dissing ` ` them fun fun the di t walked had cost film ', that they muttering so [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.792 (perp=8.476, rec=0.096, cos=0.000), tot_loss_proj:2.366 [t=0.26s]
prediction: ["[CLS] out but terrible mind they have horrible thousands'ticket cost muttering ` ` `'dissing ` ` them fun fun the the t walked had cost film ', that they muttering so [SEP]"]
[ 750/2000] tot_loss=1.805 (perp=8.542, rec=0.096, cos=0.000), tot_loss_proj:2.555 [t=0.25s]
prediction: ["[CLS] out but terrible mind they have horrible thousands'ticket cost muttering ` ` `'dissing ` `, fun fun the. t walked had did film ', that they muttering so [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.778 (perp=8.413, rec=0.095, cos=0.000), tot_loss_proj:2.571 [t=0.26s]
prediction: ["[CLS] out but terrible mind they have horrible thousands'ticket cost muttering ` ` `'dissing ` `, fun fun the. t walked muttering did film ', that they had so [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.752 (perp=8.290, rec=0.093, cos=0.000), tot_loss_proj:2.609 [t=0.27s]
prediction: ["[CLS] out but terrible mind they have horrible dinner. ticket cost muttering ` ` `'dissing ` much, fun fun the't walked muttering did film ', that they had so [SEP]"]
[ 900/2000] tot_loss=1.745 (perp=8.290, rec=0.086, cos=0.000), tot_loss_proj:2.609 [t=0.26s]
prediction: ["[CLS] out but terrible mind they have horrible dinner. ticket cost muttering ` ` `'dissing ` much, fun fun the't walked muttering did film ', that they had so [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.724 (perp=8.169, rec=0.090, cos=0.000), tot_loss_proj:2.522 [t=0.27s]
prediction: ["[CLS] out but terrible mind they have horrible dinner. ticket cost muttering words ` `'dissing ` much, fun fun the't walked so did film ', that they had muttering [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.683 (perp=7.981, rec=0.086, cos=0.000), tot_loss_proj:2.536 [t=0.26s]
prediction: ["[CLS] out but terrible mind they have horrible dinner, ticket cost muttering words ` ` ` dissing'much, fun fun the't walked so did film ', that they had muttering [SEP]"]
[1050/2000] tot_loss=1.677 (perp=7.981, rec=0.080, cos=0.000), tot_loss_proj:2.536 [t=0.29s]
prediction: ["[CLS] out but terrible mind they have horrible dinner, ticket cost muttering words ` ` ` dissing'much, fun fun the't walked so did film ', that they had muttering [SEP]"]
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.685 (perp=7.967, rec=0.091, cos=0.000), tot_loss_proj:2.807 [t=0.28s]
prediction: ["[CLS] out but terrible mind they like dinner, ticket cost horrible muttering words ` ` ` dissing'much, fun fun the't walked so did film ', that they had muttering [SEP]"]
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.651 (perp=7.794, rec=0.092, cos=0.000), tot_loss_proj:2.328 [t=0.27s]
prediction: ["[CLS] out but mind they like dinner, ticket cost horrible muttering terrible words ` ` ` dissing'much over fun fun the't walked so did film ', that they had muttering [SEP]"]
[1200/2000] tot_loss=1.719 (perp=8.139, rec=0.091, cos=0.000), tot_loss_proj:2.333 [t=0.28s]
prediction: ["[CLS] out but mind they as dinner, ticket cost horrible muttering terrible words ` ` ` dissing'much over fun fun the't walked so did film ', that they had muttering [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.684 (perp=7.951, rec=0.093, cos=0.000), tot_loss_proj:2.299 [t=0.28s]
prediction: ["[CLS] out but mind dinner, they as ticket cost horrible muttering terrible words ` ` ` dissing'much over fun fun the't walked so did film ', that they had muttering [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.641 (perp=7.751, rec=0.091, cos=0.000), tot_loss_proj:2.285 [t=0.28s]
prediction: ["[CLS] out but mind dinner, they'ticket cost horrible muttering over terrible words ` ` ` dissing'much fun fun the't walked so did film ', that they had muttering [SEP]"]
[1350/2000] tot_loss=1.687 (perp=8.020, rec=0.083, cos=0.000), tot_loss_proj:2.329 [t=0.26s]
prediction: ["[CLS] out but mind dinner, they'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the't walked so did film ', that they had muttering [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.747 (perp=8.291, rec=0.088, cos=0.000), tot_loss_proj:2.376 [t=0.27s]
prediction: ["[CLS] out but mind film, they'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the ` t walked so did dinner ', that they had muttering [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.716 (perp=8.132, rec=0.090, cos=0.000), tot_loss_proj:2.315 [t=0.28s]
prediction: ["[CLS] out they mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the ` t walked so did dinner ', that they had muttering [SEP]"]
[1500/2000] tot_loss=1.714 (perp=8.132, rec=0.087, cos=0.000), tot_loss_proj:2.309 [t=0.26s]
prediction: ["[CLS] out they mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the ` t walked so did dinner ', that they had muttering [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.709 (perp=8.132, rec=0.082, cos=0.000), tot_loss_proj:2.318 [t=0.26s]
prediction: ["[CLS] out they mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the ` t walked so did dinner ', that they had muttering [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.679 (perp=7.929, rec=0.092, cos=0.000), tot_loss_proj:2.279 [t=0.26s]
prediction: ["[CLS] out they mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the `'t walked so did dinner, that they had muttering [SEP]"]
[1650/2000] tot_loss=1.623 (perp=7.732, rec=0.076, cos=0.000), tot_loss_proj:2.266 [t=0.26s]
prediction: ["[CLS] out they mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the `'t walked so did dinner, that they had'[SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.618 (perp=7.640, rec=0.090, cos=0.000), tot_loss_proj:2.310 [t=0.26s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the `'t walked so did they, that they had'[SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.584 (perp=7.470, rec=0.090, cos=0.000), tot_loss_proj:2.215 [t=0.27s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering radical terrible words ` ` `'dissing much fun fun the `'t walked so did they, that they had'[SEP]"]
[1800/2000] tot_loss=1.579 (perp=7.470, rec=0.085, cos=0.000), tot_loss_proj:2.225 [t=0.27s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering radical terrible words ` ` `'dissing much fun fun the `'t walked so did they, that they had'[SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.575 (perp=7.427, rec=0.089, cos=0.000), tot_loss_proj:2.209 [t=0.26s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering terrible words ` ` `'radical dissing much fun fun the `'t walked so did they, that they had'[SEP]"]
Attempt swap
[1900/2000] tot_loss=1.573 (perp=7.427, rec=0.087, cos=0.000), tot_loss_proj:2.215 [t=0.25s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering terrible words ` ` `'radical dissing much fun fun the `'t walked so did they, that they had'[SEP]"]
[1950/2000] tot_loss=1.567 (perp=7.427, rec=0.081, cos=0.000), tot_loss_proj:2.211 [t=0.27s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering terrible words ` ` `'radical dissing much fun fun the `'t walked so did they, that they had'[SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.559 (perp=7.377, rec=0.083, cos=0.000), tot_loss_proj:2.184 [t=0.26s]
prediction: ["[CLS] out dinner mind film, but'ticket cost horrible muttering terrible words ` ` `'radical dissing much fun fun the `'t walked so did they that they had,'[SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] out they mind film, but'ticket cost horrible muttering radical terrible words ` ` ` dissing'much fun fun the ` t walked so did dinner ', that they had muttering [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 11.538 | p: 11.111 | r: 12.000
rougeL     | fm: 37.037 | p: 35.714 | r: 38.462
rougeLsum  | fm: 37.037 | p: 35.714 | r: 38.462
r1fm+r2fm = 93.020

[Aggregate metrics]:
rouge1     | fm: 88.307 | p: 87.904 | r: 88.844
rouge2     | fm: 51.997 | p: 51.808 | r: 52.203
rougeL     | fm: 75.604 | p: 75.259 | r: 76.013
rougeLsum  | fm: 75.781 | p: 75.346 | r: 76.244
r1fm+r2fm = 140.305

input #99 time: 0:11:11 | total time: 17:24:49


Average Cosine Similarity: 0.9992812683158312
Done with all.
