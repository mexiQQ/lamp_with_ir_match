


Command: attack.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 2000 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9241289496421814 for ['[CLS] brute bounded [SEP]']
[Init] best rec loss: 0.9108506441116333 for ['[CLS] screen liverpool [SEP]']
[Init] best rec loss: 0.9002898335456848 for ['[CLS] laosciency [SEP]']
[Init] best rec loss: 0.8795796632766724 for ['[CLS] america wind [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.314 (perp=10.843, rec=0.145), tot_loss_proj:2.456 [t=0.27s]
prediction: ['[CLS] disappointed disappointed [SEP]']
[ 100/2000] tot_loss=2.293 (perp=11.088, rec=0.075), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.275 (perp=11.088, rec=0.057), tot_loss_proj:2.506 [t=0.26s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.275 (perp=11.088, rec=0.057), tot_loss_proj:2.495 [t=0.26s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.125 (perp=10.251, rec=0.075), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.108 (perp=10.251, rec=0.058), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.107 (perp=10.251, rec=0.057), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.121 (perp=10.251, rec=0.071), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.103 (perp=10.251, rec=0.053), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.124 (perp=10.251, rec=0.074), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.116 (perp=10.251, rec=0.066), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.115 (perp=10.251, rec=0.065), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.117 (perp=10.251, rec=0.067), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.113 (perp=10.251, rec=0.063), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.122 (perp=10.251, rec=0.072), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.115 (perp=10.251, rec=0.065), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.115 (perp=10.251, rec=0.064), tot_loss_proj:2.111 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.097 (perp=10.251, rec=0.047), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.120 (perp=10.251, rec=0.070), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.112 (perp=10.251, rec=0.062), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.122 (perp=10.251, rec=0.072), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.111 (perp=10.251, rec=0.061), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.118 (perp=10.251, rec=0.068), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.107 (perp=10.251, rec=0.057), tot_loss_proj:2.122 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.122 (perp=10.251, rec=0.072), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.109 (perp=10.251, rec=0.059), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.111 (perp=10.251, rec=0.060), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.120 (perp=10.251, rec=0.070), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.105 (perp=10.251, rec=0.055), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.102 (perp=10.251, rec=0.052), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.109 (perp=10.251, rec=0.059), tot_loss_proj:2.122 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.102 (perp=10.251, rec=0.051), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.118 (perp=10.251, rec=0.068), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.112 (perp=10.251, rec=0.062), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.116 (perp=10.251, rec=0.066), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.108 (perp=10.251, rec=0.058), tot_loss_proj:2.118 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.107 (perp=10.251, rec=0.057), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.120 (perp=10.251, rec=0.070), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.103 (perp=10.251, rec=0.052), tot_loss_proj:2.120 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.111 (perp=10.251, rec=0.060), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:10:42 | total time: 0:10:42


Running input #1 of 100.
reference: 
========================
splendidly 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.017449975013733 for ['[CLS] lead damn [SEP]']
[Init] best rec loss: 0.9566616415977478 for ['[CLS]glass tax [SEP]']
[Init] best rec loss: 0.9432148337364197 for ['[CLS] hug fashion [SEP]']
[Init] best rec loss: 0.9304352402687073 for ['[CLS]lion asteroid [SEP]']
[Init] best rec loss: 0.9279722571372986 for ['[CLS] here isaac [SEP]']
[Init] best rec loss: 0.9216035008430481 for ['[CLS] lion cary [SEP]']
[Init] best rec loss: 0.9189785718917847 for ['[CLS] beside again [SEP]']
[Init] best rec loss: 0.9187556505203247 for ['[CLS] composer recruited [SEP]']
[Init] best rec loss: 0.9172818660736084 for ['[CLS]wise spoken [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.853 (perp=11.097, rec=0.633), tot_loss_proj:3.191 [t=0.26s]
prediction: ['[CLS] projection dominated [SEP]']
[ 100/2000] tot_loss=2.967 (perp=11.649, rec=0.637), tot_loss_proj:3.343 [t=0.26s]
prediction: ['[CLS] kidding cuisine [SEP]']
[ 150/2000] tot_loss=2.811 (perp=11.033, rec=0.604), tot_loss_proj:2.473 [t=0.25s]
prediction: ['[CLS] fabulous splendid [SEP]']
[ 200/2000] tot_loss=2.756 (perp=11.033, rec=0.550), tot_loss_proj:2.464 [t=0.26s]
prediction: ['[CLS] fabulous splendid [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.769 (perp=11.033, rec=0.563), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] fabulous splendid [SEP]']
[ 300/2000] tot_loss=2.728 (perp=11.033, rec=0.521), tot_loss_proj:2.469 [t=0.26s]
prediction: ['[CLS] fabulous splendid [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.768 (perp=11.270, rec=0.514), tot_loss_proj:3.288 [t=0.25s]
prediction: ['[CLS] staring splendid [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.530 (perp=10.181, rec=0.494), tot_loss_proj:2.519 [t=0.25s]
prediction: ['[CLS] handsome splendid [SEP]']
[ 450/2000] tot_loss=2.572 (perp=10.181, rec=0.536), tot_loss_proj:2.515 [t=0.26s]
prediction: ['[CLS] handsome splendid [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.524 (perp=10.181, rec=0.487), tot_loss_proj:2.510 [t=0.25s]
prediction: ['[CLS] handsome splendid [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.507 (perp=10.181, rec=0.471), tot_loss_proj:2.515 [t=0.27s]
prediction: ['[CLS] handsome splendid [SEP]']
[ 600/2000] tot_loss=2.526 (perp=10.288, rec=0.468), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.512 (perp=10.288, rec=0.455), tot_loss_proj:2.302 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.507 (perp=10.288, rec=0.449), tot_loss_proj:2.295 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
[ 750/2000] tot_loss=2.554 (perp=10.504, rec=0.453), tot_loss_proj:2.331 [t=0.25s]
prediction: ['[CLS]ally splendid [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.551 (perp=10.504, rec=0.451), tot_loss_proj:2.333 [t=0.25s]
prediction: ['[CLS]ally splendid [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.551 (perp=10.504, rec=0.450), tot_loss_proj:2.330 [t=0.30s]
prediction: ['[CLS]ally splendid [SEP]']
[ 900/2000] tot_loss=2.537 (perp=10.504, rec=0.436), tot_loss_proj:2.328 [t=0.31s]
prediction: ['[CLS]ally splendid [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.576 (perp=10.504, rec=0.475), tot_loss_proj:2.339 [t=0.27s]
prediction: ['[CLS]ally splendid [SEP]']
Attempt swap
[1000/2000] tot_loss=2.550 (perp=10.543, rec=0.441), tot_loss_proj:2.407 [t=0.28s]
prediction: ['[CLS] splendid splendid [SEP]']
[1050/2000] tot_loss=2.543 (perp=10.543, rec=0.435), tot_loss_proj:2.410 [t=0.28s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1100/2000] tot_loss=2.544 (perp=10.543, rec=0.435), tot_loss_proj:2.411 [t=0.27s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1150/2000] tot_loss=2.541 (perp=10.543, rec=0.432), tot_loss_proj:2.411 [t=0.30s]
prediction: ['[CLS] splendid splendid [SEP]']
[1200/2000] tot_loss=2.537 (perp=10.543, rec=0.429), tot_loss_proj:2.408 [t=0.36s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1250/2000] tot_loss=2.544 (perp=10.543, rec=0.436), tot_loss_proj:2.415 [t=0.31s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1300/2000] tot_loss=2.542 (perp=10.543, rec=0.433), tot_loss_proj:2.416 [t=0.34s]
prediction: ['[CLS] splendid splendid [SEP]']
[1350/2000] tot_loss=2.536 (perp=10.543, rec=0.428), tot_loss_proj:2.418 [t=0.40s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1400/2000] tot_loss=2.539 (perp=10.543, rec=0.430), tot_loss_proj:2.414 [t=0.31s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1450/2000] tot_loss=2.546 (perp=10.543, rec=0.438), tot_loss_proj:2.407 [t=0.34s]
prediction: ['[CLS] splendid splendid [SEP]']
[1500/2000] tot_loss=2.534 (perp=10.543, rec=0.426), tot_loss_proj:2.404 [t=0.34s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1550/2000] tot_loss=2.537 (perp=10.543, rec=0.429), tot_loss_proj:2.411 [t=0.33s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1600/2000] tot_loss=2.532 (perp=10.543, rec=0.424), tot_loss_proj:2.408 [t=0.31s]
prediction: ['[CLS] splendid splendid [SEP]']
[1650/2000] tot_loss=2.535 (perp=10.543, rec=0.427), tot_loss_proj:2.410 [t=0.28s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1700/2000] tot_loss=2.534 (perp=10.543, rec=0.425), tot_loss_proj:2.417 [t=0.34s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1750/2000] tot_loss=2.539 (perp=10.543, rec=0.431), tot_loss_proj:2.406 [t=0.34s]
prediction: ['[CLS] splendid splendid [SEP]']
[1800/2000] tot_loss=2.529 (perp=10.543, rec=0.421), tot_loss_proj:2.410 [t=0.32s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1850/2000] tot_loss=2.538 (perp=10.543, rec=0.429), tot_loss_proj:2.410 [t=0.26s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1900/2000] tot_loss=2.536 (perp=10.543, rec=0.427), tot_loss_proj:2.412 [t=0.25s]
prediction: ['[CLS] splendid splendid [SEP]']
[1950/2000] tot_loss=2.527 (perp=10.543, rec=0.418), tot_loss_proj:2.404 [t=0.26s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[2000/2000] tot_loss=2.534 (perp=10.543, rec=0.425), tot_loss_proj:2.415 [t=0.27s]
prediction: ['[CLS] splendid splendid [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendid splendid [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 78.571 | p: 75.000 | r: 83.333
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 78.571 | p: 75.000 | r: 83.333
rougeLsum  | fm: 78.571 | p: 75.000 | r: 83.333
r1fm+r2fm = 128.571

input #1 time: 0:11:45 | total time: 0:22:28


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7990140914916992 for ['[CLS] normalffledptive [SEP]']
[Init] best rec loss: 0.7892630100250244 for ['[CLS] wallace literacy abe [SEP]']
[Init] best rec loss: 0.770455002784729 for ['[CLS] helpitation eddie [SEP]']
[Init] best rec loss: 0.7656304836273193 for ['[CLS] way american numb [SEP]']
[Init] best rec loss: 0.7268154621124268 for ['[CLS] values coverage filling [SEP]']
[Init] best rec loss: 0.6869593858718872 for ['[CLS] placed kinetic fundamental [SEP]']
[Init] best perm rec loss: 0.6848561763763428 for ['[CLS] kinetic placed fundamental [SEP]']
[Init] best perm rec loss: 0.682688295841217 for ['[CLS] fundamental kinetic placed [SEP]']
[Init] best perm rec loss: 0.6820796132087708 for ['[CLS] kinetic fundamental placed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.921 (perp=8.515, rec=0.218), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 100/2000] tot_loss=1.781 (perp=8.515, rec=0.078), tot_loss_proj:1.771 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.764 (perp=8.515, rec=0.061), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.759 (perp=8.515, rec=0.057), tot_loss_proj:1.766 [t=0.29s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.759 (perp=8.515, rec=0.056), tot_loss_proj:1.762 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.773 (perp=8.515, rec=0.070), tot_loss_proj:1.764 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.764 (perp=8.515, rec=0.061), tot_loss_proj:1.766 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.766 (perp=8.515, rec=0.063), tot_loss_proj:1.766 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.762 (perp=8.515, rec=0.059), tot_loss_proj:1.765 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.780 (perp=8.515, rec=0.077), tot_loss_proj:1.773 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.760 (perp=8.515, rec=0.057), tot_loss_proj:1.763 [t=0.28s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.515, rec=0.060), tot_loss_proj:1.766 [t=0.28s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.755 (perp=8.515, rec=0.052), tot_loss_proj:1.782 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.760 (perp=8.515, rec=0.057), tot_loss_proj:1.763 [t=0.29s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.768 (perp=8.515, rec=0.065), tot_loss_proj:1.763 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.763 (perp=8.515, rec=0.060), tot_loss_proj:1.773 [t=0.34s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.774 (perp=8.515, rec=0.071), tot_loss_proj:1.771 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.753 (perp=8.515, rec=0.050), tot_loss_proj:1.777 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.762 (perp=8.515, rec=0.059), tot_loss_proj:1.764 [t=0.33s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.766 (perp=8.515, rec=0.063), tot_loss_proj:1.759 [t=0.33s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.759 (perp=8.515, rec=0.056), tot_loss_proj:1.764 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.762 (perp=8.515, rec=0.059), tot_loss_proj:1.772 [t=0.36s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.761 (perp=8.515, rec=0.058), tot_loss_proj:1.769 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.768 (perp=8.515, rec=0.065), tot_loss_proj:1.769 [t=0.31s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.755 (perp=8.515, rec=0.052), tot_loss_proj:1.766 [t=0.33s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.762 (perp=8.515, rec=0.059), tot_loss_proj:1.775 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.765 (perp=8.515, rec=0.062), tot_loss_proj:1.766 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=8.515, rec=0.058), tot_loss_proj:1.771 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.758 (perp=8.515, rec=0.055), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.767 (perp=8.515, rec=0.064), tot_loss_proj:1.773 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.515, rec=0.065), tot_loss_proj:1.763 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.762 (perp=8.515, rec=0.059), tot_loss_proj:1.776 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.765 (perp=8.515, rec=0.062), tot_loss_proj:1.768 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.756 (perp=8.515, rec=0.053), tot_loss_proj:1.769 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.760 (perp=8.515, rec=0.057), tot_loss_proj:1.772 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.515, rec=0.062), tot_loss_proj:1.775 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.775 (perp=8.515, rec=0.072), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.765 (perp=8.515, rec=0.062), tot_loss_proj:1.765 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.758 (perp=8.515, rec=0.055), tot_loss_proj:1.772 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.748 (perp=8.515, rec=0.045), tot_loss_proj:1.773 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.714 | p: 83.333 | r: 88.889
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 83.333 | r: 88.889
rougeLsum  | fm: 85.714 | p: 83.333 | r: 88.889
r1fm+r2fm = 152.381

input #2 time: 0:11:26 | total time: 0:33:54


Running input #3 of 100.
reference: 
========================
flawless film 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9599831700325012 for ['[CLS] likes warming [SEP]']
[Init] best rec loss: 0.9553736448287964 for ['[CLS]ky di [SEP]']
[Init] best rec loss: 0.9437950849533081 for ['[CLS]nea dishes [SEP]']
[Init] best rec loss: 0.9293150305747986 for ['[CLS] heels scholar [SEP]']
[Init] best rec loss: 0.9200177788734436 for ['[CLS] spared lessons [SEP]']
[Init] best rec loss: 0.9160115718841553 for ['[CLS] pick african [SEP]']
[Init] best rec loss: 0.9046391248703003 for ['[CLS]tte kissing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.891 (perp=11.466, rec=0.598), tot_loss_proj:3.220 [t=0.25s]
prediction: ['[CLS]iful poem [SEP]']
[ 100/2000] tot_loss=2.966 (perp=12.301, rec=0.506), tot_loss_proj:3.479 [t=0.27s]
prediction: ['[CLS] flawlessmeral [SEP]']
[ 150/2000] tot_loss=2.947 (perp=12.232, rec=0.501), tot_loss_proj:3.459 [t=0.25s]
prediction: ['[CLS] flawless posed [SEP]']
[ 200/2000] tot_loss=2.524 (perp=10.476, rec=0.429), tot_loss_proj:2.492 [t=0.26s]
prediction: ['[CLS] flawless flawless [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.502 (perp=10.506, rec=0.401), tot_loss_proj:3.038 [t=0.26s]
prediction: ['[CLS] flawless improvisation [SEP]']
[ 300/2000] tot_loss=2.307 (perp=9.749, rec=0.357), tot_loss_proj:2.900 [t=0.25s]
prediction: ['[CLS] flawless sequel [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.964 (perp=8.385, rec=0.287), tot_loss_proj:2.009 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.831 (perp=8.385, rec=0.154), tot_loss_proj:1.825 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.772 (perp=8.385, rec=0.095), tot_loss_proj:1.820 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.756 (perp=8.385, rec=0.079), tot_loss_proj:1.813 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.782 (perp=8.385, rec=0.105), tot_loss_proj:1.814 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.751 (perp=8.385, rec=0.074), tot_loss_proj:1.808 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.795 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.791 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.749 (perp=8.385, rec=0.072), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.729 (perp=8.385, rec=0.052), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.731 (perp=8.385, rec=0.054), tot_loss_proj:1.791 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.747 (perp=8.385, rec=0.070), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.736 (perp=8.385, rec=0.059), tot_loss_proj:1.805 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.744 (perp=8.385, rec=0.067), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.794 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.744 (perp=8.385, rec=0.067), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=8.385, rec=0.067), tot_loss_proj:1.798 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.744 (perp=8.385, rec=0.067), tot_loss_proj:1.791 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.737 (perp=8.385, rec=0.060), tot_loss_proj:1.802 [t=0.32s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.796 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.731 (perp=8.385, rec=0.055), tot_loss_proj:1.789 [t=0.32s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.801 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.813 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.732 (perp=8.385, rec=0.055), tot_loss_proj:1.800 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.737 (perp=8.385, rec=0.060), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.731 (perp=8.385, rec=0.054), tot_loss_proj:1.795 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.741 (perp=8.385, rec=0.064), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.734 (perp=8.385, rec=0.057), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.738 (perp=8.385, rec=0.061), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=8.385, rec=0.058), tot_loss_proj:1.795 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.286 | p: 87.500 | r: 91.667
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 89.286 | p: 87.500 | r: 91.667
rougeLsum  | fm: 89.286 | p: 87.500 | r: 91.667
r1fm+r2fm = 164.286

input #3 time: 0:10:49 | total time: 0:44:44


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9794749021530151 for ['[CLS] canyon per surprise [SEP]']
[Init] best rec loss: 0.9508825540542603 for ['[CLS] folk gap stretch [SEP]']
[Init] best rec loss: 0.9431930184364319 for ['[CLS] tender down airport [SEP]']
[Init] best rec loss: 0.9340963363647461 for ['[CLS] key mbe tall [SEP]']
[Init] best rec loss: 0.9192871451377869 for ['[CLS] ahl clothed interests [SEP]']
[Init] best rec loss: 0.9123945236206055 for ['[CLS] emission cotton under [SEP]']
[Init] best rec loss: 0.9014297127723694 for ['[CLS]uri involving fray [SEP]']
[Init] best rec loss: 0.8998939394950867 for ['[CLS] technically plans essentially [SEP]']
[Init] best rec loss: 0.8988416790962219 for ['[CLS] dust milling gene [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.485 (perp=11.654, rec=0.154), tot_loss_proj:2.654 [t=0.24s]
prediction: ['[CLS] tiresome ghostly [SEP]']
[ 100/2000] tot_loss=1.594 (perp=7.515, rec=0.091), tot_loss_proj:1.586 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.576 (perp=7.515, rec=0.073), tot_loss_proj:1.594 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.572 (perp=7.515, rec=0.069), tot_loss_proj:1.585 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.573 (perp=7.515, rec=0.070), tot_loss_proj:1.588 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.552 (perp=7.515, rec=0.049), tot_loss_proj:1.583 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.565 (perp=7.515, rec=0.062), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.573 (perp=7.515, rec=0.070), tot_loss_proj:1.577 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.558 (perp=7.515, rec=0.055), tot_loss_proj:1.569 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.562 (perp=7.515, rec=0.059), tot_loss_proj:1.570 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.551 (perp=7.515, rec=0.048), tot_loss_proj:1.566 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.576 (perp=7.515, rec=0.073), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.556 (perp=7.515, rec=0.053), tot_loss_proj:1.576 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.571 (perp=7.515, rec=0.068), tot_loss_proj:1.583 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.561 (perp=7.515, rec=0.058), tot_loss_proj:1.591 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.555 (perp=7.515, rec=0.052), tot_loss_proj:1.576 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.558 (perp=7.515, rec=0.055), tot_loss_proj:1.578 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.579 (perp=7.515, rec=0.076), tot_loss_proj:1.571 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.567 (perp=7.515, rec=0.064), tot_loss_proj:1.580 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.563 (perp=7.515, rec=0.060), tot_loss_proj:1.579 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.562 (perp=7.515, rec=0.058), tot_loss_proj:1.573 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.565 (perp=7.515, rec=0.062), tot_loss_proj:1.582 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.565 (perp=7.515, rec=0.062), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.576 (perp=7.515, rec=0.073), tot_loss_proj:1.571 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.555 (perp=7.515, rec=0.052), tot_loss_proj:1.579 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.554 (perp=7.515, rec=0.051), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.575 (perp=7.515, rec=0.072), tot_loss_proj:1.584 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.552 (perp=7.515, rec=0.049), tot_loss_proj:1.568 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.564 (perp=7.515, rec=0.061), tot_loss_proj:1.563 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.578 (perp=7.515, rec=0.075), tot_loss_proj:1.577 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.560 (perp=7.515, rec=0.057), tot_loss_proj:1.573 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.552 (perp=7.515, rec=0.049), tot_loss_proj:1.575 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.575 (perp=7.515, rec=0.072), tot_loss_proj:1.575 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.547 (perp=7.515, rec=0.044), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.571 (perp=7.515, rec=0.068), tot_loss_proj:1.579 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.539 (perp=7.515, rec=0.036), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.567 (perp=7.515, rec=0.064), tot_loss_proj:1.581 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.515, rec=0.051), tot_loss_proj:1.573 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.558 (perp=7.515, rec=0.055), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.558 (perp=7.515, rec=0.055), tot_loss_proj:1.565 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.429 | p: 90.000 | r: 93.333
rouge2     | fm: 80.000 | p: 80.000 | r: 80.000
rougeL     | fm: 91.429 | p: 90.000 | r: 93.333
rougeLsum  | fm: 91.429 | p: 90.000 | r: 93.333
r1fm+r2fm = 171.429

input #4 time: 0:10:30 | total time: 0:55:14


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 1.0786900520324707 for ['[CLS] longer company [SEP]']
[Init] best rec loss: 0.9928190112113953 for ['[CLS] well chain [SEP]']
[Init] best rec loss: 0.9925860166549683 for ['[CLS]− trial [SEP]']
[Init] best rec loss: 0.9920544028282166 for ['[CLS] against approximately [SEP]']
[Init] best rec loss: 0.9799904227256775 for ['[CLS] ancient draft [SEP]']
[Init] best rec loss: 0.9649852514266968 for ['[CLS] kin despite [SEP]']
[Init] best rec loss: 0.9521946310997009 for ['[CLS] ray scraped [SEP]']
[Init] best rec loss: 0.9520624876022339 for ['[CLS]ning care [SEP]']
[Init] best rec loss: 0.9472932815551758 for ['[CLS] ss wingspan [SEP]']
[Init] best perm rec loss: 0.9460940361022949 for ['[CLS] wingspan ss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.935 (perp=11.370, rec=0.661), tot_loss_proj:3.500 [t=0.28s]
prediction: ['[CLS] ease ease [SEP]']
[ 100/2000] tot_loss=2.860 (perp=11.370, rec=0.586), tot_loss_proj:3.501 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=2.800 (perp=11.370, rec=0.526), tot_loss_proj:3.492 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=2.798 (perp=11.370, rec=0.524), tot_loss_proj:3.496 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.854 (perp=11.370, rec=0.580), tot_loss_proj:3.488 [t=0.33s]
prediction: ['[CLS] ease ease [SEP]']
[ 300/2000] tot_loss=2.790 (perp=11.370, rec=0.516), tot_loss_proj:3.507 [t=0.27s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.782 (perp=11.370, rec=0.508), tot_loss_proj:3.502 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.755 (perp=11.370, rec=0.481), tot_loss_proj:3.493 [t=0.31s]
prediction: ['[CLS] ease ease [SEP]']
[ 450/2000] tot_loss=2.832 (perp=11.370, rec=0.558), tot_loss_proj:3.501 [t=0.37s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.756 (perp=11.370, rec=0.482), tot_loss_proj:3.503 [t=0.34s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.741 (perp=11.370, rec=0.467), tot_loss_proj:3.501 [t=0.34s]
prediction: ['[CLS] ease ease [SEP]']
[ 600/2000] tot_loss=2.731 (perp=11.370, rec=0.457), tot_loss_proj:3.505 [t=0.33s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.732 (perp=11.370, rec=0.458), tot_loss_proj:3.499 [t=0.34s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.734 (perp=11.370, rec=0.460), tot_loss_proj:3.503 [t=0.38s]
prediction: ['[CLS] ease ease [SEP]']
[ 750/2000] tot_loss=2.783 (perp=11.370, rec=0.509), tot_loss_proj:3.502 [t=0.37s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.724 (perp=11.370, rec=0.450), tot_loss_proj:3.506 [t=0.36s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.735 (perp=11.370, rec=0.461), tot_loss_proj:3.508 [t=0.35s]
prediction: ['[CLS] ease ease [SEP]']
[ 900/2000] tot_loss=2.737 (perp=11.370, rec=0.463), tot_loss_proj:3.494 [t=0.37s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.725 (perp=11.370, rec=0.451), tot_loss_proj:3.501 [t=0.33s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.083 (perp=11.370, rec=0.809), tot_loss_proj:3.499 [t=0.33s]
prediction: ['[CLS] ease ease [SEP]']
[1050/2000] tot_loss=2.883 (perp=11.370, rec=0.609), tot_loss_proj:3.502 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1100/2000] tot_loss=2.804 (perp=11.370, rec=0.530), tot_loss_proj:3.496 [t=0.34s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=2.775 (perp=11.370, rec=0.501), tot_loss_proj:3.495 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=2.758 (perp=11.370, rec=0.484), tot_loss_proj:3.506 [t=0.27s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=2.748 (perp=11.370, rec=0.475), tot_loss_proj:3.506 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=2.725 (perp=11.370, rec=0.451), tot_loss_proj:3.506 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
[1350/2000] tot_loss=2.733 (perp=11.370, rec=0.459), tot_loss_proj:3.507 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1400/2000] tot_loss=2.721 (perp=11.370, rec=0.448), tot_loss_proj:3.505 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1450/2000] tot_loss=2.722 (perp=11.370, rec=0.448), tot_loss_proj:3.512 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
[1500/2000] tot_loss=2.711 (perp=11.370, rec=0.438), tot_loss_proj:3.500 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1550/2000] tot_loss=2.722 (perp=11.370, rec=0.448), tot_loss_proj:3.504 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1600/2000] tot_loss=2.721 (perp=11.370, rec=0.447), tot_loss_proj:3.505 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
[1650/2000] tot_loss=2.722 (perp=11.370, rec=0.448), tot_loss_proj:3.498 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1700/2000] tot_loss=2.713 (perp=11.370, rec=0.439), tot_loss_proj:3.499 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1750/2000] tot_loss=2.717 (perp=11.370, rec=0.444), tot_loss_proj:3.507 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
[1800/2000] tot_loss=2.709 (perp=11.370, rec=0.435), tot_loss_proj:3.510 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1850/2000] tot_loss=2.718 (perp=11.370, rec=0.444), tot_loss_proj:3.506 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1900/2000] tot_loss=2.709 (perp=11.370, rec=0.435), tot_loss_proj:3.500 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
[1950/2000] tot_loss=2.716 (perp=11.370, rec=0.442), tot_loss_proj:3.510 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[2000/2000] tot_loss=2.710 (perp=11.370, rec=0.436), tot_loss_proj:3.500 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 88.690 | p: 87.500 | r: 90.278
rouge2     | fm: 72.222 | p: 72.222 | r: 72.222
rougeL     | fm: 88.690 | p: 87.500 | r: 90.278
rougeLsum  | fm: 88.690 | p: 87.500 | r: 90.278
r1fm+r2fm = 160.913

input #5 time: 0:11:44 | total time: 1:06:58


Running input #6 of 100.
reference: 
========================
grayish 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9741127490997314 for ['[CLS] 05 halfway [SEP]']
[Init] best rec loss: 0.942429780960083 for ['[CLS] sure river [SEP]']
[Init] best rec loss: 0.8979443311691284 for ['[CLS] child laughed [SEP]']
[Init] best rec loss: 0.8423882126808167 for ['[CLS] getting ka [SEP]']
[Init] best rec loss: 0.7927531003952026 for ['[CLS] praised opposed [SEP]']
[Init] best rec loss: 0.7174995541572571 for ['[CLS] otto quinn [SEP]']
[Init] best rec loss: 0.6810792684555054 for ['[CLS] bunch imperative [SEP]']
[Init] best perm rec loss: 0.6807093024253845 for ['[CLS] imperative bunch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.828 (perp=8.089, rec=0.210), tot_loss_proj:1.697 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 100/2000] tot_loss=1.695 (perp=8.089, rec=0.077), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.672 (perp=8.089, rec=0.054), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.676 (perp=8.089, rec=0.059), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.668 (perp=8.089, rec=0.050), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.690 (perp=8.089, rec=0.073), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.677 (perp=8.089, rec=0.059), tot_loss_proj:1.670 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.661 (perp=8.089, rec=0.043), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.668 (perp=8.089, rec=0.050), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=8.089, rec=0.060), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.671 (perp=8.089, rec=0.053), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.684 (perp=8.089, rec=0.066), tot_loss_proj:1.684 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.671 (perp=8.089, rec=0.053), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.671 (perp=8.089, rec=0.053), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.669 (perp=8.089, rec=0.051), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.671 (perp=8.089, rec=0.053), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.689 (perp=8.089, rec=0.071), tot_loss_proj:1.676 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.676 (perp=8.089, rec=0.058), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.698 (perp=8.089, rec=0.080), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.680 (perp=8.089, rec=0.062), tot_loss_proj:1.674 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.691 (perp=8.089, rec=0.073), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.675 (perp=8.089, rec=0.057), tot_loss_proj:1.695 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.673 (perp=8.089, rec=0.055), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.677 (perp=8.089, rec=0.059), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=8.089, rec=0.059), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=8.089, rec=0.057), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.689 (perp=8.089, rec=0.071), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=8.089, rec=0.066), tot_loss_proj:1.681 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.681 (perp=8.089, rec=0.064), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.668 (perp=8.089, rec=0.050), tot_loss_proj:1.698 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.676 (perp=8.089, rec=0.058), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.683 (perp=8.089, rec=0.065), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.671 (perp=8.089, rec=0.053), tot_loss_proj:1.691 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.678 (perp=8.089, rec=0.060), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.697 (perp=8.089, rec=0.079), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.686 (perp=8.089, rec=0.068), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.673 (perp=8.089, rec=0.055), tot_loss_proj:1.679 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.678 (perp=8.089, rec=0.060), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.666 (perp=8.089, rec=0.048), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=8.089, rec=0.064), tot_loss_proj:1.667 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.306 | p: 89.286 | r: 91.667
rouge2     | fm: 76.190 | p: 76.190 | r: 76.190
rougeL     | fm: 90.306 | p: 89.286 | r: 91.667
rougeLsum  | fm: 90.306 | p: 89.286 | r: 91.667
r1fm+r2fm = 166.497

input #6 time: 0:10:40 | total time: 1:17:39


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.8698709011077881 for ['[CLS] avenuesfect nearly © simply return framed ¡ssing strongest sore proved gallery college gen directed ironika fleet sans passed careful value basketball cp wingspan [SEP]']
[Init] best rec loss: 0.8507230877876282 for ['[CLS] bathdrive code permanently organ epic compliment how clube presidential were blood early when roe as chico territorial amelia performers former proper related second row cool [SEP]']
[Init] best rec loss: 0.8385891318321228 for ['[CLS] [ how been forwardvor hole wide kata case weather trial lodge abstractec weekly marriott women where decides spanish having zeke af user mike forge [SEP]']
[Init] best rec loss: 0.8315600156784058 for ['[CLS] based currency begin can always permanently return professorship finsha brick pushing bothered fans bipolar granted hunt gum planet pri nick dan gan tribal pink depending [SEP]']
[Init] best rec loss: 0.8225929737091064 for ['[CLS] pairs directingnd vote ll iv opposite says cameo greece dave mentionrle briggssity mixtch water webb rankingrmapt scenario impact synagogue white [SEP]']
[Init] best rec loss: 0.7965142726898193 for ['[CLS] lena tick grace forced witch fragile clock association applications mail converted dom questionrh whoever conclusions mal airpatient meanwhile burkeente wig garionnya gurney [SEP]']
[Init] best rec loss: 0.7911902666091919 for ['[CLS] interstate butter aubrey apart kansas case testimony valleyrea macleanո department draft allople will / tessa lieutenantglass trustee films usualn although mad [SEP]']
[Init] best perm rec loss: 0.7866456508636475 for ['[CLS] interstate department films will lieutenant case trustee maclean apartglass tessa mad aubreyո draft kansas testimony valleyoplerea althoughn butter all / usual [SEP]']
[Init] best perm rec loss: 0.7838646769523621 for ['[CLS] kansasglassrea aubrey tessa mad all apart butter draft valleyո will interstaten althoughople maclean testimony case department trustee films / usual lieutenant [SEP]']
[Init] best perm rec loss: 0.783750057220459 for ['[CLS] macleanople department lieutenant mad films aubrey all testimony apartnո butter althoughrea draftglass valley trustee interstate will / case tessa usual kansas [SEP]']
[Init] best perm rec loss: 0.7828301787376404 for ['[CLS] usual lieutenantoplerea mad maclean butter interstate apart will although testimony tessa kansasn valley case aubreyո films draft department trustee all /glass [SEP]']
[Init] best perm rec loss: 0.7828282713890076 for ['[CLS] tessa maclean apart draft valleyn lieutenant all usual case testimony kansas interstate films althoughople aubrey mad butterո trusteerea /glass department will [SEP]']
[Init] best perm rec loss: 0.7815456390380859 for ['[CLS] apart trustee testimony mad all valley usual lieutenant kansas interstate draft maclean / although case aubreyglass butterոnople department tessa filmsrea will [SEP]']
[Init] best perm rec loss: 0.7802438139915466 for ['[CLS]n trustee testimony valleyople usual tessa draft films apart department kansas maclean caseո butter mad all interstate lieutenantrea aubrey althoughglass will / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.464 (perp=10.789, rec=0.306), tot_loss_proj:2.824 [t=0.33s]
prediction: ['[CLS] problem panel problem is national vice character stamps killed problem an not boy problem no is involved who no without character problem problem love paper type [SEP]']
[ 100/2000] tot_loss=1.989 (perp=8.927, rec=0.204), tot_loss_proj:2.474 [t=0.26s]
prediction: ['[CLS] problem. problem is group. character markers love problem ; not he problem the is was who no no character problem problem loveriety factor [SEP]']
[ 150/2000] tot_loss=2.027 (perp=9.316, rec=0.164), tot_loss_proj:2.650 [t=0.32s]
prediction: ['[CLS] problem. problem is yeah. character markers cute problem ; not he problem the is is since no no character problem problem loveable factor [SEP]']
[ 200/2000] tot_loss=1.926 (perp=8.924, rec=0.141), tot_loss_proj:2.515 [t=0.29s]
prediction: ['[CLS] problem. not is i mind character factor cute ugly ; not he problem the is is since no no character is problem loveable factor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.953 (perp=8.237, rec=0.306), tot_loss_proj:2.343 [t=0.27s]
prediction: ['[CLS] problem. not that the mind character factor cute ugly ; not he problem i has is very no no character is not loveable factor [SEP]']
[ 300/2000] tot_loss=1.989 (perp=8.853, rec=0.218), tot_loss_proj:2.350 [t=0.27s]
prediction: ['[CLS] kid. not that bill mind character me talks ugly ; not he problem i has breathed very no no character is that love or franchise [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.878 (perp=8.510, rec=0.176), tot_loss_proj:2.349 [t=0.27s]
prediction: ['[CLS]able. not that mind cute me bill talks ugly ; not he problem our has weird very no no character is that love or franchise [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.836 (perp=8.316, rec=0.173), tot_loss_proj:2.340 [t=0.26s]
prediction: ['[CLS] cute. not that mind cute me bill talks ugly ; not he problem our weird has very no no character is that love or player [SEP]']
[ 450/2000] tot_loss=1.866 (perp=8.594, rec=0.148), tot_loss_proj:2.492 [t=0.27s]
prediction: ['[CLS] cute. not that mind character me bill talks ugly ; not he problem our occur has very no no character is that love or player [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.834 (perp=8.418, rec=0.151), tot_loss_proj:2.421 [t=0.27s]
prediction: ['[CLS] cute. not that character mind me bill matters ugly ; not he problem iestinal has very no no character is that love or player [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.730 (perp=7.942, rec=0.142), tot_loss_proj:2.342 [t=0.27s]
prediction: ['[CLS] cute. not that character mind me bill matters ugly ; not he problem i player has very no no character is that love or or [SEP]']
[ 600/2000] tot_loss=1.723 (perp=7.955, rec=0.132), tot_loss_proj:2.350 [t=0.26s]
prediction: ['[CLS] cute. not that character mind me bill wonderful ugly ; or he problem i player has very no no character is that love or or [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.739 (perp=8.034, rec=0.132), tot_loss_proj:2.254 [t=0.28s]
prediction: ['[CLS] cute or not that cute mind me bill wonderful ugly ; or he problem i player has very no no character is that love or. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.668 (perp=7.713, rec=0.125), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] cute or not that cute mind me bill wonderful ugly ; or he problem or player has very no no character is that love i. [SEP]']
[ 750/2000] tot_loss=1.669 (perp=7.713, rec=0.126), tot_loss_proj:2.228 [t=0.27s]
prediction: ['[CLS] cute or not that cute mind me bill wonderful ugly ; or he problem or player has very no no character is that love i. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.634 (perp=7.543, rec=0.125), tot_loss_proj:2.227 [t=0.33s]
prediction: ['[CLS] cute or not very cute mind me bill wonderful ugly ; or he problem or player has that no no character is that love i. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.601 (perp=7.409, rec=0.119), tot_loss_proj:2.190 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind me bill wonderful ugly ; or he problem or i has that no no character is that love player. [SEP]']
[ 900/2000] tot_loss=1.614 (perp=7.409, rec=0.132), tot_loss_proj:2.189 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind me bill wonderful ugly ; or he problem or i has that no no character is that love player. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.656 (perp=7.661, rec=0.123), tot_loss_proj:2.228 [t=0.25s]
prediction: ['[CLS] cute or not very cute mind here bill wonderful ugly ; or he problem or i has no that no character is that love player. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.633 (perp=7.521, rec=0.129), tot_loss_proj:2.197 [t=0.27s]
prediction: ['[CLS] cute or not very cute mind here bill wonderful ugly ; or he problem or i has no that no character is that love factor. [SEP]']
[1050/2000] tot_loss=1.627 (perp=7.521, rec=0.123), tot_loss_proj:2.197 [t=0.27s]
prediction: ['[CLS] cute or not very cute mind here bill wonderful ugly ; or he problem or i has no that no character is that love factor. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.586 (perp=7.280, rec=0.130), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind here bill love ugly ; or he problem or i has no that no character is that wonderful factor. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.553 (perp=7.169, rec=0.120), tot_loss_proj:2.085 [t=0.27s]
prediction: ['[CLS] cute or not very cute mind love bill here ugly ; or he problem or i has no that no character is that wonderful factor. [SEP]']
[1200/2000] tot_loss=1.552 (perp=7.169, rec=0.118), tot_loss_proj:2.089 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind love bill here ugly ; or he problem or i has no that no character is that wonderful factor. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.561 (perp=7.169, rec=0.127), tot_loss_proj:2.083 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind love bill here ugly ; or he problem or i has no that no character is that wonderful factor. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.552 (perp=7.169, rec=0.118), tot_loss_proj:2.084 [t=0.25s]
prediction: ['[CLS] cute or not very cute mind love bill here ugly ; or he problem or i has no that no character is that wonderful factor. [SEP]']
[1350/2000] tot_loss=1.556 (perp=7.169, rec=0.123), tot_loss_proj:2.082 [t=0.27s]
prediction: ['[CLS] cute or not very cute mind love bill here ugly ; or he problem or i has no that no character is that wonderful factor. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.561 (perp=7.200, rec=0.121), tot_loss_proj:2.082 [t=0.27s]
prediction: ['[CLS] cute or not very cute mind love bill here ugly ; or he problem or i has that no no character is that wonderful factor. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.531 (perp=7.105, rec=0.110), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind love i here ugly ; or he problem or bill has that no no character is that wonderful factor. [SEP]']
[1500/2000] tot_loss=1.531 (perp=7.105, rec=0.110), tot_loss_proj:2.065 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind love i here ugly ; or he problem or bill has that no no character is that wonderful factor. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.626 (perp=7.571, rec=0.112), tot_loss_proj:2.152 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind love i here ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.628 (perp=7.571, rec=0.114), tot_loss_proj:2.155 [t=0.27s]
prediction: ['[CLS] cute or not very cute mind love i here ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
[1650/2000] tot_loss=1.629 (perp=7.571, rec=0.115), tot_loss_proj:2.151 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind love i here ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.747 (perp=8.149, rec=0.117), tot_loss_proj:2.262 [t=0.26s]
prediction: ['[CLS] cute factor not very cute mind i here love ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.675 (perp=7.771, rec=0.121), tot_loss_proj:2.195 [t=0.28s]
prediction: ['[CLS] cute not very cute mind i here love factor ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
[1800/2000] tot_loss=1.667 (perp=7.771, rec=0.113), tot_loss_proj:2.191 [t=0.27s]
prediction: ['[CLS] cute not very cute mind i here love factor ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.667 (perp=7.771, rec=0.113), tot_loss_proj:2.199 [t=0.25s]
prediction: ['[CLS] cute not very cute mind i here love factor ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.584 (perp=7.400, rec=0.103), tot_loss_proj:2.140 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind i here love ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
[1950/2000] tot_loss=1.598 (perp=7.400, rec=0.118), tot_loss_proj:2.143 [t=0.26s]
prediction: ['[CLS] cute or not very cute mind i here love ugly ; or he problem or bill has that no no character is that matters factor. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.741 (perp=8.114, rec=0.118), tot_loss_proj:2.266 [t=0.25s]
prediction: ['[CLS] cute factor not very cute mind i here wonderful ugly ; or he problem or bill has that no no character is that love factor. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] cute or not very cute mind love i here ugly ; or he problem or bill has that no no character is that matters factor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 69.231 | r: 85.714
rouge2     | fm: 4.444 | p: 4.000 | r: 5.000
rougeL     | fm: 42.553 | p: 38.462 | r: 47.619
rougeLsum  | fm: 42.553 | p: 38.462 | r: 47.619
r1fm+r2fm = 81.040

[Aggregate metrics]:
rouge1     | fm: 88.592 | p: 86.779 | r: 90.923
rouge2     | fm: 67.222 | p: 67.167 | r: 67.292
rougeL     | fm: 85.268 | p: 84.375 | r: 86.905
rougeLsum  | fm: 84.337 | p: 82.933 | r: 86.161
r1fm+r2fm = 155.815

input #7 time: 0:11:03 | total time: 1:28:42


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7027233839035034 for ['[CLS] words turn transfer canada death fell allegro tax agency lane word gearbox buy farther inequality mother from married during commanding hey rei lady lust [SEP]']
[Init] best rec loss: 0.6917051672935486 for ['[CLS]uze better learn grind them bloommold suits customscial replication spent det daemon saddam heard senior marilyn ho [SEP] words whose locomotive [SEP]']
[Init] best rec loss: 0.6888311505317688 for ['[CLS] ju concentrated huntergged heath mailux folded specialist else palepower ′ways wakes attack open compromise sh hurricane appearsuda 6 within [SEP]']
[Init] best rec loss: 0.6737384796142578 for ['[CLS] stalin artist fighting closer moments nominee fr hat cautioustype ut reinsas capable namtie worth german act effects messageborough sky wind [SEP]']
[Init] best rec loss: 0.6699745655059814 for ['[CLS] courts assuredmd underwent eddie recalled kylieshing delay too legs answered somewhat finds luck contextves zero comograting says for patron echo [SEP]']
[Init] best rec loss: 0.6683663129806519 for ['[CLS] sunday norris else digital maxi brusselsism liz wah especiallyoss sworn america darkª pierced splits worked replied wrong { premises noah readily [SEP]']
[Init] best perm rec loss: 0.6677039861679077 for ['[CLS]ism worked brussels wah swornª repliedoss noah splits digital { wrong maxi norris sunday dark readily liz else especially america pierced premises [SEP]']
[Init] best perm rec loss: 0.66768878698349 for ['[CLS] sworn pierced noahª readily digital replied worked wrongoss maxi else america especially { premises wah splits brussels liz dark norrisism sunday [SEP]']
[Init] best perm rec loss: 0.6671856641769409 for ['[CLS] digital wah maxi readily premises repliedoss pierced liz sunday wrongª america sworn worked dark norris noah elseism { especially brussels splits [SEP]']
[Init] best perm rec loss: 0.6659330129623413 for ['[CLS]oss especially splits america norris liz noah wah { replied digital premisesª elseism maxi sunday sworn brussels readily worked dark wrong pierced [SEP]']
[Init] best perm rec loss: 0.6651312112808228 for ['[CLS] pierced maxi norris noah wah sworn else replied lizismª premisesoss especially wrong digital brussels splits america sunday worked { dark readily [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.828 (perp=12.546, rec=0.318), tot_loss_proj:3.246 [t=0.26s]
prediction: ['[CLS] crazy selling vanity [SEP] vanity movie political fright thing °f doubt revenue gives better actor back drama vanity jude vanity shells mostless mistaken [SEP]']
[ 100/2000] tot_loss=2.361 (perp=10.667, rec=0.227), tot_loss_proj:2.788 [t=0.25s]
prediction: ['[CLS] a films vanity vanity vanity movie film fright that who doubt debt pays what debt off drama vanity film vanity might mostless mistaken [SEP]']
[ 150/2000] tot_loss=2.433 (perp=11.251, rec=0.183), tot_loss_proj:2.893 [t=0.25s]
prediction: ['[CLS] a film vanity vanity vanity film film fright that that doubt debt pays what debt off film vanity film benign would notful mistaken [SEP]']
[ 200/2000] tot_loss=2.407 (perp=11.274, rec=0.152), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] a film vanityful vanity film film fright that they doubt debt pays what debt off film vanitymax benign would noful mistaken [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.272 (perp=10.650, rec=0.142), tot_loss_proj:2.766 [t=0.24s]
prediction: ['[CLS] a owedlentful vanity film film fright that they doubt debt pays what debt offmax vanitymax benigni would no suspicion [SEP]']
[ 300/2000] tot_loss=2.220 (perp=10.493, rec=0.121), tot_loss_proj:2.794 [t=0.27s]
prediction: ['[CLS] s owed networkful vanity film film fright that they doubt debt pays what debt offmax vanitymax benigni would no suspicion [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.173 (perp=10.266, rec=0.120), tot_loss_proj:2.683 [t=0.26s]
prediction: ['[CLS] s owed doubtful vanity film film fright that they network debt pays what debt offmax vanitymax benigni would no suspicion [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.122 (perp=10.103, rec=0.101), tot_loss_proj:2.713 [t=0.26s]
prediction: ['[CLS] s felt doubtful vanity film film fright that they owed debt pays what debt offmax vanitymax benigni to no suspicion [SEP]']
[ 450/2000] tot_loss=2.236 (perp=10.704, rec=0.095), tot_loss_proj:2.778 [t=0.26s]
prediction: ['[CLS] s felt doubtful vanity film film fright that, owed debt pays what debt offmax vanitymax benigni to no felt [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.131 (perp=10.191, rec=0.093), tot_loss_proj:2.679 [t=0.27s]
prediction: ['[CLS] s felt doubtful vanity film film fright that, owed debt pays what debt offmax vanitymax benigni felt to no [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.127 (perp=10.193, rec=0.088), tot_loss_proj:2.671 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that, owed debt pays what debt offmax vanitymax benigni felt to no [SEP]']
[ 600/2000] tot_loss=2.122 (perp=10.193, rec=0.083), tot_loss_proj:2.669 [t=0.27s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that, owed debt pays what debt offmax vanitymax benigni felt to no [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.065 (perp=9.875, rec=0.090), tot_loss_proj:2.626 [t=0.25s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed, pays what debt offmax vanitymax benigni felt to no [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.998 (perp=9.593, rec=0.080), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt offmax vanitymax benigni felt to, [SEP]']
[ 750/2000] tot_loss=2.013 (perp=9.593, rec=0.094), tot_loss_proj:2.576 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt offmax vanitymax benigni felt to, [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.933 (perp=9.211, rec=0.090), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt offmax they benigni felt tomax, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.935 (perp=9.211, rec=0.093), tot_loss_proj:2.529 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt offmax they benigni felt tomax, [SEP]']
[ 900/2000] tot_loss=1.919 (perp=9.211, rec=0.076), tot_loss_proj:2.533 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt offmax they benigni felt tomax, [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.866 (perp=8.920, rec=0.082), tot_loss_proj:2.466 [t=0.27s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt off they benignimax felt tomax, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.871 (perp=8.920, rec=0.087), tot_loss_proj:2.458 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt off they benignimax felt tomax, [SEP]']
[1050/2000] tot_loss=1.857 (perp=8.920, rec=0.073), tot_loss_proj:2.457 [t=0.25s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what debt off they benignimax felt tomax, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.849 (perp=8.838, rec=0.082), tot_loss_proj:2.467 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they debt off benignimax felt tomax, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.842 (perp=8.838, rec=0.074), tot_loss_proj:2.476 [t=0.27s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they debt off benignimax felt tomax, [SEP]']
[1200/2000] tot_loss=1.845 (perp=8.838, rec=0.078), tot_loss_proj:2.475 [t=0.28s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they debt off benignimax felt tomax, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.850 (perp=8.838, rec=0.083), tot_loss_proj:2.474 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they debt off benignimax felt tomax, [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.826 (perp=8.736, rec=0.078), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
[1350/2000] tot_loss=1.832 (perp=8.736, rec=0.085), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.824 (perp=8.736, rec=0.076), tot_loss_proj:2.444 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.825 (perp=8.736, rec=0.078), tot_loss_proj:2.445 [t=0.25s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
[1500/2000] tot_loss=1.829 (perp=8.736, rec=0.082), tot_loss_proj:2.448 [t=0.25s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.821 (perp=8.736, rec=0.074), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.821 (perp=8.736, rec=0.074), tot_loss_proj:2.443 [t=0.26s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
[1650/2000] tot_loss=1.837 (perp=8.736, rec=0.090), tot_loss_proj:2.446 [t=0.36s]
prediction: ['[CLS] s felt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax debt tomax, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.806 (perp=8.653, rec=0.075), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.802 (perp=8.653, rec=0.071), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
[1800/2000] tot_loss=1.810 (perp=8.653, rec=0.079), tot_loss_proj:2.386 [t=0.28s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.809 (perp=8.653, rec=0.078), tot_loss_proj:2.383 [t=0.26s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.815 (perp=8.653, rec=0.084), tot_loss_proj:2.385 [t=0.32s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
[1950/2000] tot_loss=1.818 (perp=8.653, rec=0.088), tot_loss_proj:2.388 [t=0.27s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.815 (perp=8.653, rec=0.084), tot_loss_proj:2.381 [t=0.31s]
prediction: ['[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s debt frightful vanity vanity film doubt that debt owed no pays what they felt off benignimax felt tomax, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.049 | p: 76.190 | r: 80.000
rouge2     | fm: 15.385 | p: 15.000 | r: 15.789
rougeL     | fm: 53.659 | p: 52.381 | r: 55.000
rougeLsum  | fm: 53.659 | p: 52.381 | r: 55.000
r1fm+r2fm = 93.433

[Aggregate metrics]:
rouge1     | fm: 87.582 | p: 85.867 | r: 89.709
rouge2     | fm: 61.462 | p: 61.370 | r: 61.569
rougeL     | fm: 80.928 | p: 79.670 | r: 82.698
rougeLsum  | fm: 80.928 | p: 79.538 | r: 82.698
r1fm+r2fm = 149.045

input #8 time: 0:10:59 | total time: 1:39:42


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7650202512741089 for ['[CLS] accounting bnide themuming text raise going [SEP]']
[Init] best rec loss: 0.7242442965507507 for ['[CLS] fis at weighted prisons bedroom ce takeover soap [SEP]']
[Init] best rec loss: 0.6935240626335144 for ['[CLS] rib americas collar qualification candidate shannon organized days [SEP]']
[Init] best rec loss: 0.6666290760040283 for ['[CLS] sight militantqual principal siberianop shoot character [SEP]']
[Init] best rec loss: 0.6333369612693787 for ['[CLS] owed truth just vanished colony charlie tank bureau [SEP]']
[Init] best perm rec loss: 0.6301718950271606 for ['[CLS] vanished bureau colony owed tank just truth charlie [SEP]']
[Init] best perm rec loss: 0.6284940838813782 for ['[CLS] just vanished tank truth charlie owed colony bureau [SEP]']
[Init] best perm rec loss: 0.6264773011207581 for ['[CLS] colony just truth vanished bureau owed tank charlie [SEP]']
[Init] best perm rec loss: 0.6255174279212952 for ['[CLS] charlie bureau just truth vanished owed tank colony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.789 (perp=12.583, rec=0.273), tot_loss_proj:3.103 [t=0.24s]
prediction: ['[CLS] clap soft coped clap claptrahead [SEP]']
[ 100/2000] tot_loss=1.935 (perp=8.865, rec=0.162), tot_loss_proj:2.273 [t=0.27s]
prediction: ['[CLS] clap soft metaphysical of clap claptrap [SEP]']
[ 150/2000] tot_loss=2.327 (perp=10.982, rec=0.130), tot_loss_proj:2.747 [t=0.26s]
prediction: ['[CLS] clap soft metaphysical of clapheadtrap [SEP]']
[ 200/2000] tot_loss=2.281 (perp=10.982, rec=0.085), tot_loss_proj:2.751 [t=0.25s]
prediction: ['[CLS] clap soft metaphysical of clapheadtrap [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.375 (perp=11.175, rec=0.140), tot_loss_proj:2.790 [t=0.25s]
prediction: ['[CLS] claphead soft metaphysical of metaphysicaltrap [SEP]']
[ 300/2000] tot_loss=2.367 (perp=11.384, rec=0.090), tot_loss_proj:2.810 [t=0.32s]
prediction: ['[CLS] claphead softed of metaphysicaltrap [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.971 (perp=9.455, rec=0.080), tot_loss_proj:2.394 [t=0.24s]
prediction: ['[CLS]head softed of metaphysical claptrap [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.682 (perp=7.926, rec=0.096), tot_loss_proj:1.855 [t=0.25s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
[ 450/2000] tot_loss=1.653 (perp=7.926, rec=0.067), tot_loss_proj:1.858 [t=0.25s]
prediction: ['[CLS]headed of soft metaphysical claptrap [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.597 (perp=7.643, rec=0.068), tot_loss_proj:1.610 [t=0.25s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.601 (perp=7.643, rec=0.073), tot_loss_proj:1.603 [t=0.25s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[ 600/2000] tot_loss=1.586 (perp=7.643, rec=0.058), tot_loss_proj:1.612 [t=0.27s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.538 (perp=7.384, rec=0.061), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.529 (perp=7.384, rec=0.053), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.557 (perp=7.384, rec=0.081), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.546 (perp=7.384, rec=0.069), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.542 (perp=7.384, rec=0.065), tot_loss_proj:1.622 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.540 (perp=7.384, rec=0.063), tot_loss_proj:1.625 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.538 (perp=7.384, rec=0.061), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.535 (perp=7.384, rec=0.058), tot_loss_proj:1.625 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.539 (perp=7.384, rec=0.062), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.544 (perp=7.384, rec=0.067), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.543 (perp=7.384, rec=0.067), tot_loss_proj:1.616 [t=0.26s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.533 (perp=7.384, rec=0.056), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.533 (perp=7.384, rec=0.056), tot_loss_proj:1.612 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.537 (perp=7.384, rec=0.060), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.530 (perp=7.384, rec=0.053), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.537 (perp=7.384, rec=0.060), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.527 (perp=7.384, rec=0.050), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.536 (perp=7.384, rec=0.060), tot_loss_proj:1.609 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.541 (perp=7.384, rec=0.064), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.535 (perp=7.384, rec=0.058), tot_loss_proj:1.612 [t=0.24s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.537 (perp=7.384, rec=0.060), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.542 (perp=7.384, rec=0.065), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.535 (perp=7.384, rec=0.058), tot_loss_proj:1.612 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.535 (perp=7.384, rec=0.058), tot_loss_proj:1.615 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.537 (perp=7.384, rec=0.060), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.529 (perp=7.384, rec=0.052), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.530 (perp=7.384, rec=0.054), tot_loss_proj:1.610 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.537 (perp=7.384, rec=0.060), tot_loss_proj:1.610 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 88.824 | p: 87.161 | r: 90.833
rouge2     | fm: 59.316 | p: 59.233 | r: 59.412
rougeL     | fm: 81.413 | p: 80.238 | r: 83.095
rougeLsum  | fm: 81.376 | p: 80.174 | r: 82.857
r1fm+r2fm = 148.140

input #9 time: 0:10:41 | total time: 1:50:24


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.7926138639450073 for ['[CLS] bar suffered colony rights late redesignated recently body ys launchdeswer [SEP]']
[Init] best rec loss: 0.7613142132759094 for ['[CLS] thus checking her really fresh warm affairs emi inhuman line philip want generation [SEP]']
[Init] best rec loss: 0.7101459503173828 for ['[CLS] following most realizing satcoll. good again driven play day bills festival [SEP]']
[Init] best rec loss: 0.697437047958374 for ['[CLS] michael sincerely sandy mat grew elegance discretionunes pontcot mathematics intelligence mattered [SEP]']
[Init] best rec loss: 0.6770981550216675 for ['[CLS] today bandage jack fellowship official mike jana de standing jenny jam deep chronicle [SEP]']
[Init] best perm rec loss: 0.6769911646842957 for ['[CLS] jana deep standing fellowship jenny mike bandage official de jam chronicle jack today [SEP]']
[Init] best perm rec loss: 0.6733643412590027 for ['[CLS] today chronicle jana official jenny jack bandage deep fellowship de mike jam standing [SEP]']
[Init] best perm rec loss: 0.6719421744346619 for ['[CLS] de deep fellowship bandage jana jenny standing jack official today jam chronicle mike [SEP]']
[Init] best perm rec loss: 0.6688905954360962 for ['[CLS] deep jam today jana bandage jack official chronicle jenny fellowship mike de standing [SEP]']
[Init] best perm rec loss: 0.668402910232544 for ['[CLS] mike standing chronicle official fellowship jana jack jenny de bandage jam deep today [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.672 (perp=11.927, rec=0.287), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS] abaulsive. reliance dramaticism traditionally peel balance concertosh brand [SEP]']
[ 100/2000] tot_loss=2.060 (perp=9.434, rec=0.174), tot_loss_proj:2.280 [t=0.27s]
prediction: ['[CLS] ablyly. based prop rhythms with balance balanceulsive rhythm. [SEP]']
[ 150/2000] tot_loss=2.318 (perp=10.933, rec=0.131), tot_loss_proj:2.636 [t=0.25s]
prediction: ['[CLS] ablyly real straight incident rhythms with balance balanceulsive rhythms incident [SEP]']
[ 200/2000] tot_loss=2.205 (perp=10.470, rec=0.111), tot_loss_proj:2.546 [t=0.24s]
prediction: ['[CLS] ablyly reals incident rhythms with balance balanceulsive rhythms incident [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.170 (perp=10.148, rec=0.140), tot_loss_proj:2.571 [t=0.28s]
prediction: ['[CLS] ab rhythmsly reals incident rhythms with balance balanceulsively incident [SEP]']
[ 300/2000] tot_loss=2.117 (perp=10.088, rec=0.100), tot_loss_proj:2.486 [t=0.27s]
prediction: ['[CLS] ab rhythmsly reals time rhythms with balance balanceulsively incident [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.916 (perp=9.124, rec=0.091), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS] ably rhythms reals time rhythms with balance balanceulsively incident [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.867 (perp=8.852, rec=0.097), tot_loss_proj:2.148 [t=0.28s]
prediction: ['[CLS] ably rhythms reals time rhythms with balance balance incidentulsively [SEP]']
[ 450/2000] tot_loss=1.999 (perp=9.557, rec=0.088), tot_loss_proj:2.295 [t=0.24s]
prediction: ['[CLS] ably rhythms reals time rhythms with balance balance incidentulsives [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.892 (perp=8.950, rec=0.102), tot_loss_proj:2.163 [t=0.27s]
prediction: ['[CLS] ably rhythms reals time rhythms with balanceulsive incident balances [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.699 (perp=8.060, rec=0.087), tot_loss_proj:1.958 [t=0.25s]
prediction: ['[CLS] ably rhythms reals time rhythms with propulsive incident balances [SEP]']
[ 600/2000] tot_loss=1.695 (perp=8.060, rec=0.083), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] ably rhythms reals time rhythms with propulsive incident balances [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.690 (perp=8.076, rec=0.075), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS] ably rhythms real. incident time rhythms with propulsive balances [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.603 (perp=7.582, rec=0.087), tot_loss_proj:1.884 [t=0.26s]
prediction: ['[CLS] ably rhythms reals incident time rhythms with propulsive balance. [SEP]']
[ 750/2000] tot_loss=1.597 (perp=7.582, rec=0.081), tot_loss_proj:1.890 [t=0.26s]
prediction: ['[CLS] ably rhythms reals incident time rhythms with propulsive balance. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.528 (perp=7.191, rec=0.090), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] ablys rhythms real incident time rhythms with propulsive balance. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.493 (perp=7.083, rec=0.076), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] ablys rhythms real time rhythms with incident propulsive balance. [SEP]']
[ 900/2000] tot_loss=1.490 (perp=7.083, rec=0.074), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] ablys rhythms real time rhythms with incident propulsive balance. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.437 (perp=6.764, rec=0.084), tot_loss_proj:1.575 [t=0.26s]
prediction: ['[CLS] ablys balance real time rhythms with incident propulsive rhythms. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.421 (perp=6.727, rec=0.076), tot_loss_proj:1.489 [t=0.26s]
prediction: ['[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]']
[1050/2000] tot_loss=1.419 (perp=6.727, rec=0.074), tot_loss_proj:1.487 [t=0.27s]
prediction: ['[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.420 (perp=6.727, rec=0.075), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.423 (perp=6.727, rec=0.077), tot_loss_proj:1.487 [t=0.32s]
prediction: ['[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]']
[1200/2000] tot_loss=1.413 (perp=6.727, rec=0.068), tot_loss_proj:1.485 [t=0.26s]
prediction: ['[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.421 (perp=6.727, rec=0.075), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.291 (perp=6.098, rec=0.072), tot_loss_proj:1.447 [t=0.27s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
[1350/2000] tot_loss=1.292 (perp=6.098, rec=0.072), tot_loss_proj:1.455 [t=0.26s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.302 (perp=6.098, rec=0.082), tot_loss_proj:1.451 [t=0.29s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.290 (perp=6.098, rec=0.070), tot_loss_proj:1.453 [t=0.26s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
[1500/2000] tot_loss=1.296 (perp=6.098, rec=0.076), tot_loss_proj:1.454 [t=0.30s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.297 (perp=6.098, rec=0.077), tot_loss_proj:1.450 [t=0.26s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.293 (perp=6.098, rec=0.074), tot_loss_proj:1.452 [t=0.27s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
[1650/2000] tot_loss=1.295 (perp=6.098, rec=0.075), tot_loss_proj:1.451 [t=0.26s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.295 (perp=6.098, rec=0.076), tot_loss_proj:1.453 [t=0.28s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.288 (perp=6.098, rec=0.068), tot_loss_proj:1.451 [t=0.27s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
[1800/2000] tot_loss=1.292 (perp=6.098, rec=0.072), tot_loss_proj:1.450 [t=0.28s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.298 (perp=6.098, rec=0.079), tot_loss_proj:1.456 [t=0.27s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.298 (perp=6.098, rec=0.078), tot_loss_proj:1.450 [t=0.27s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
[1950/2000] tot_loss=1.293 (perp=6.098, rec=0.073), tot_loss_proj:1.449 [t=0.28s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.298 (perp=6.098, rec=0.079), tot_loss_proj:1.448 [t=0.27s]
prediction: ['[CLS] incident ably balances real time rhythms with propulsive rhythms. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] ably balances real time rhythms with incident propulsive rhythms. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 63.158 | p: 60.000 | r: 66.667
rougeL     | fm: 85.714 | p: 81.818 | r: 90.000
rougeLsum  | fm: 85.714 | p: 81.818 | r: 90.000
r1fm+r2fm = 158.396

[Aggregate metrics]:
rouge1     | fm: 89.407 | p: 87.587 | r: 91.667
rouge2     | fm: 59.833 | p: 59.545 | r: 60.072
rougeL     | fm: 82.101 | p: 80.565 | r: 83.723
rougeLsum  | fm: 81.921 | p: 80.307 | r: 83.723
r1fm+r2fm = 149.240

input #10 time: 0:10:54 | total time: 2:01:18


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8819180130958557 for ['[CLS]ja find michelangelogon builder yuri gifted december dock sire [SEP]']
[Init] best rec loss: 0.8405473232269287 for ['[CLS] unit burkina linerbi enlightenmentism at struggle truly meaning [SEP]']
[Init] best rec loss: 0.8288146257400513 for ['[CLS]lip ; mix people protest her derek amplateguard [SEP]']
[Init] best rec loss: 0.8277329802513123 for ['[CLS] depictedzone maximum definitely helped resemblance °f vo carriers sister [SEP]']
[Init] best rec loss: 0.8239744901657104 for ['[CLS] need sovereignty formalalic regularties behind visit manfred review [SEP]']
[Init] best rec loss: 0.8130643963813782 for ['[CLS] arranged infant guarantees queen extreme os collective ya strapped hamlet [SEP]']
[Init] best rec loss: 0.810524046421051 for ['[CLS] quit for company tropical allison mentioned dive fact each genie [SEP]']
[Init] best rec loss: 0.7882599234580994 for ['[CLS] − lauren celllda finenge judgment nashville shift " [SEP]']
[Init] best perm rec loss: 0.787017822265625 for ['[CLS] shiftlda cellnge fine − nashville " judgment lauren [SEP]']
[Init] best perm rec loss: 0.7867020964622498 for ['[CLS] finenge shift nashville judgment − celllda " lauren [SEP]']
[Init] best perm rec loss: 0.7853107452392578 for ['[CLS] fine cellnge shift − laurenlda " judgment nashville [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.240 (perp=14.341, rec=0.371), tot_loss_proj:3.599 [t=0.26s]
prediction: ['[CLS] rejected refuseduil refusedury firmly refused gel stubborn kaitlyn [SEP]']
[ 100/2000] tot_loss=3.006 (perp=13.856, rec=0.235), tot_loss_proj:3.536 [t=0.29s]
prediction: ['[CLS] refused refused to refused attempted here refused gel stubborn gel [SEP]']
[ 150/2000] tot_loss=2.570 (perp=12.024, rec=0.165), tot_loss_proj:3.131 [t=0.27s]
prediction: ['[CLS] refused refused to was attempted that refused gel stubborn gel [SEP]']
[ 200/2000] tot_loss=2.235 (perp=10.493, rec=0.137), tot_loss_proj:2.790 [t=0.25s]
prediction: ['[CLS] attempted refused here was attempted thatly gel stubbornly [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.990 (perp=9.440, rec=0.102), tot_loss_proj:2.584 [t=0.25s]
prediction: ['[CLS] attempted refused here was attempted that gelly stubbornly [SEP]']
[ 300/2000] tot_loss=1.979 (perp=9.440, rec=0.091), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] attempted refused here was attempted that gelly stubbornly [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.773 (perp=8.373, rec=0.098), tot_loss_proj:2.303 [t=0.27s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.765 (perp=8.373, rec=0.090), tot_loss_proj:2.309 [t=0.26s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
[ 450/2000] tot_loss=1.769 (perp=8.373, rec=0.095), tot_loss_proj:2.307 [t=0.27s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.771 (perp=8.373, rec=0.096), tot_loss_proj:2.311 [t=0.27s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.761 (perp=8.373, rec=0.086), tot_loss_proj:2.312 [t=0.25s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
[ 600/2000] tot_loss=1.751 (perp=8.373, rec=0.077), tot_loss_proj:2.310 [t=0.27s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.764 (perp=8.373, rec=0.090), tot_loss_proj:2.307 [t=0.30s]
prediction: ['[CLS] that refused here was attempted attempted gelly stubbornly [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.707 (perp=8.069, rec=0.093), tot_loss_proj:2.291 [t=0.26s]
prediction: ['[CLS] that here was attempted attempted refused gelly stubbornly [SEP]']
[ 750/2000] tot_loss=1.709 (perp=8.069, rec=0.095), tot_loss_proj:2.287 [t=0.26s]
prediction: ['[CLS] that here was attempted attempted refused gelly stubbornly [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.674 (perp=7.992, rec=0.075), tot_loss_proj:2.220 [t=0.25s]
prediction: ['[CLS] here that was attempted attempted refused gelly stubbornly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.576 (perp=7.483, rec=0.079), tot_loss_proj:2.093 [t=0.25s]
prediction: ['[CLS] here that was attempted being refused gelly stubbornly [SEP]']
[ 900/2000] tot_loss=1.750 (perp=8.344, rec=0.081), tot_loss_proj:2.301 [t=0.26s]
prediction: ['[CLS] here that was attempted being refused gelly stubborn to [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.673 (perp=7.970, rec=0.079), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] here that was attempted being refused gel stubbornly to [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.562 (perp=7.488, rec=0.064), tot_loss_proj:2.095 [t=0.27s]
prediction: ['[CLS] here that was attempted being refused stubbornly to gel [SEP]']
[1050/2000] tot_loss=1.564 (perp=7.488, rec=0.066), tot_loss_proj:2.091 [t=0.27s]
prediction: ['[CLS] here that was attempted being refused stubbornly to gel [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.435 (perp=6.792, rec=0.077), tot_loss_proj:1.790 [t=0.28s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.432 (perp=6.792, rec=0.074), tot_loss_proj:1.786 [t=0.25s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.415 (perp=6.792, rec=0.056), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.430 (perp=6.792, rec=0.071), tot_loss_proj:1.787 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.421 (perp=6.792, rec=0.063), tot_loss_proj:1.787 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.435 (perp=6.792, rec=0.076), tot_loss_proj:1.793 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.420 (perp=6.792, rec=0.062), tot_loss_proj:1.794 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.432 (perp=6.792, rec=0.073), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.438 (perp=6.792, rec=0.079), tot_loss_proj:1.794 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.420 (perp=6.792, rec=0.061), tot_loss_proj:1.789 [t=0.25s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.427 (perp=6.792, rec=0.069), tot_loss_proj:1.783 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.415 (perp=6.792, rec=0.056), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.432 (perp=6.792, rec=0.073), tot_loss_proj:1.784 [t=0.28s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.428 (perp=6.792, rec=0.070), tot_loss_proj:1.792 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.425 (perp=6.792, rec=0.067), tot_loss_proj:1.790 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.429 (perp=6.792, rec=0.070), tot_loss_proj:1.789 [t=0.27s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.420 (perp=6.792, rec=0.062), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.423 (perp=6.792, rec=0.065), tot_loss_proj:1.792 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.425 (perp=6.792, rec=0.066), tot_loss_proj:1.797 [t=0.26s]
prediction: ['[CLS] here that was attempted being stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here that was attempted being stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 90.312 | p: 88.772 | r: 92.361
rouge2     | fm: 58.860 | p: 58.528 | r: 59.163
rougeL     | fm: 80.823 | p: 79.487 | r: 82.449
rougeLsum  | fm: 81.052 | p: 79.753 | r: 82.767
r1fm+r2fm = 149.171

input #11 time: 0:10:54 | total time: 2:12:12


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8481571078300476 for ['[CLS] battery hadley driven ring ninth westward widow sale againstarmts northern employeeseral [SEP]']
[Init] best rec loss: 0.8309312462806702 for ['[CLS] master entersnish any port agent choicencymind vans title primary #tor [SEP]']
[Init] best rec loss: 0.8210310339927673 for ['[CLS] alright semi filthy saintthor basetrum barely pride caller transitrued janata anna [SEP]']
[Init] best rec loss: 0.8112475275993347 for ['[CLS] whenever ua mc surrounding medium centers soo management sidjack serbia even turn as [SEP]']
[Init] best rec loss: 0.8000571727752686 for ['[CLS] too franchise equal survivors common cause along nomenclature paintsnberg gaza gold side copa [SEP]']
[Init] best rec loss: 0.7663068771362305 for ['[CLS] promise her easter devoted for dynamicea taxi abdul source bluenda h sexes [SEP]']
[Init] best rec loss: 0.7280685901641846 for ['[CLS] having literature ignition telescope no browser starehawinium net wound finished plus shawn [SEP]']
[Init] best rec loss: 0.7215927839279175 for ['[CLS] plural doubt planck chapter less playback resembling capacity senses burma wrapped fetchrrado authority [SEP]']
[Init] best rec loss: 0.7205950617790222 for ['[CLS] brigadier membership dug preston explosion beach heard t stems aspectally small pronounced enormous [SEP]']
[Init] best perm rec loss: 0.7184721231460571 for ['[CLS] small heard stems brigadier enormous preston membership explosionally t beach dug pronounced aspect [SEP]']
[Init] best perm rec loss: 0.7171366214752197 for ['[CLS] beach brigadier preston membership pronounced smallally aspect heard stems dug enormous t explosion [SEP]']
[Init] best perm rec loss: 0.7158675789833069 for ['[CLS] pronounced membership beach preston enormous small stems explosion brigadier dugally t heard aspect [SEP]']
[Init] best perm rec loss: 0.7135894894599915 for ['[CLS] t aspect membershipally explosion brigadier dug stems beach heard pronounced preston small enormous [SEP]']
[Init] best perm rec loss: 0.7135631442070007 for ['[CLS]ally beach t heard stems explosion brigadier small pronounced membership preston aspect enormous dug [SEP]']
[Init] best perm rec loss: 0.7134868502616882 for ['[CLS] explosion heard dug aspect brigadier stems pronounced small preston membership tally enormous beach [SEP]']
[Init] best perm rec loss: 0.7123129367828369 for ['[CLS] stems small membership pronounced brigadier heardally t aspect explosion preston enormous beach dug [SEP]']
[Init] best perm rec loss: 0.711912214756012 for ['[CLS] small preston stems t pronounced brigadier explosion membership heard dug aspectally enormous beach [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=11.124, rec=0.295), tot_loss_proj:2.852 [t=0.26s]
prediction: ['[CLS] in eireann notice what nose cable better better its barely situation that losses barely [SEP]']
[ 100/2000] tot_loss=2.046 (perp=9.248, rec=0.196), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] to advantage will into cable cable better better its barely cable and barely barely [SEP]']
[ 150/2000] tot_loss=2.107 (perp=9.781, rec=0.151), tot_loss_proj:2.523 [t=0.26s]
prediction: ['[CLS] to advantage will on cable cable better better cable barely cable considering its barely [SEP]']
[ 200/2000] tot_loss=2.260 (perp=10.722, rec=0.116), tot_loss_proj:2.686 [t=0.25s]
prediction: ['[CLS] seen advantage will on cable on better advantage cable barely especially considering its barely [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.042 (perp=9.669, rec=0.108), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] seen barely will to cable on better advantage cable advantage especially considering its barely [SEP]']
[ 300/2000] tot_loss=1.899 (perp=9.064, rec=0.087), tot_loss_proj:2.366 [t=0.27s]
prediction: ['[CLS] seen barely will to cable on better advantage its advantage especially considering its barely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.894 (perp=9.064, rec=0.082), tot_loss_proj:2.360 [t=0.25s]
prediction: ['[CLS] seen barely will to cable on better advantage its advantage especially considering its barely [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.797 (perp=8.533, rec=0.090), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] seen barely cable on will to better advantage its advantage especially considering its barely [SEP]']
[ 450/2000] tot_loss=1.796 (perp=8.533, rec=0.089), tot_loss_proj:2.148 [t=0.26s]
prediction: ['[CLS] seen barely cable on will to better advantage its advantage especially considering its barely [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.730 (perp=8.213, rec=0.088), tot_loss_proj:2.099 [t=0.27s]
prediction: ['[CLS] barely seen cable on will to better advantage its advantage especially considering its barely [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.614 (perp=7.655, rec=0.083), tot_loss_proj:1.987 [t=0.27s]
prediction: ['[CLS] barely seen on cable will to better advantage its advantage especially considering its barely [SEP]']
[ 600/2000] tot_loss=1.617 (perp=7.655, rec=0.086), tot_loss_proj:1.989 [t=0.28s]
prediction: ['[CLS] barely seen on cable will to better advantage its advantage especially considering its barely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.608 (perp=7.655, rec=0.077), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS] barely seen on cable will to better advantage its advantage especially considering its barely [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.581 (perp=7.538, rec=0.073), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] barely seen on cable will to better advantage advantage, especially considering its barely [SEP]']
[ 750/2000] tot_loss=1.595 (perp=7.538, rec=0.087), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] barely seen on cable will to better advantage advantage, especially considering its barely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.588 (perp=7.538, rec=0.080), tot_loss_proj:2.005 [t=0.29s]
prediction: ['[CLS] barely seen on cable will to better advantage advantage, especially considering its barely [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.536 (perp=7.228, rec=0.090), tot_loss_proj:1.892 [t=0.28s]
prediction: ['[CLS] barely seen on cable will advantage to better advantage, especially considering its barely [SEP]']
[ 900/2000] tot_loss=1.526 (perp=7.228, rec=0.080), tot_loss_proj:1.888 [t=0.26s]
prediction: ['[CLS] barely seen on cable will advantage to better advantage, especially considering its barely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.423 (perp=6.745, rec=0.074), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage, especially considering its barely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.561 (perp=7.458, rec=0.070), tot_loss_proj:1.896 [t=0.35s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
[1050/2000] tot_loss=1.566 (perp=7.458, rec=0.075), tot_loss_proj:1.894 [t=0.25s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.560 (perp=7.458, rec=0.068), tot_loss_proj:1.887 [t=0.40s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.458, rec=0.068), tot_loss_proj:1.888 [t=0.32s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
[1200/2000] tot_loss=1.556 (perp=7.458, rec=0.064), tot_loss_proj:1.891 [t=0.36s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.562 (perp=7.458, rec=0.070), tot_loss_proj:1.887 [t=0.25s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.562 (perp=7.458, rec=0.070), tot_loss_proj:1.888 [t=0.25s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
[1350/2000] tot_loss=1.562 (perp=7.458, rec=0.071), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.553 (perp=7.458, rec=0.061), tot_loss_proj:1.890 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.551 (perp=7.414, rec=0.068), tot_loss_proj:1.898 [t=0.27s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
[1500/2000] tot_loss=1.559 (perp=7.414, rec=0.076), tot_loss_proj:1.895 [t=0.27s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.546 (perp=7.414, rec=0.063), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.553 (perp=7.414, rec=0.070), tot_loss_proj:1.892 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
[1650/2000] tot_loss=1.548 (perp=7.414, rec=0.065), tot_loss_proj:1.901 [t=0.27s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.554 (perp=7.414, rec=0.072), tot_loss_proj:1.892 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.550 (perp=7.414, rec=0.067), tot_loss_proj:1.898 [t=0.27s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
[1800/2000] tot_loss=1.545 (perp=7.414, rec=0.062), tot_loss_proj:1.896 [t=0.28s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.542 (perp=7.414, rec=0.059), tot_loss_proj:1.891 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.544 (perp=7.414, rec=0.061), tot_loss_proj:1.899 [t=0.27s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
[1950/2000] tot_loss=1.554 (perp=7.414, rec=0.071), tot_loss_proj:1.899 [t=0.26s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=7.414, rec=0.065), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] barely seen on cable will be to better advantage especially considering that its barely [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely seen on cable will be to better advantage that especially considering its barely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 55.172 | p: 53.333 | r: 57.143
rougeL     | fm: 70.968 | p: 68.750 | r: 73.333
rougeLsum  | fm: 70.968 | p: 68.750 | r: 73.333
r1fm+r2fm = 151.947

[Aggregate metrics]:
rouge1     | fm: 90.832 | p: 89.016 | r: 92.949
rouge2     | fm: 58.731 | p: 58.256 | r: 59.188
rougeL     | fm: 80.149 | p: 78.801 | r: 81.807
rougeLsum  | fm: 80.107 | p: 78.666 | r: 81.802
r1fm+r2fm = 149.563

input #12 time: 0:11:03 | total time: 2:23:15


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.9086276888847351 for ['[CLS] always pro moneu club pill ft [SEP]']
[Init] best rec loss: 0.7564829587936401 for ['[CLS] space ii plume terrorist withdrew degree adams [SEP]']
[Init] best rec loss: 0.7145732045173645 for ['[CLS]ots cell list bucket hum classification jazz [SEP]']
[Init] best rec loss: 0.6840482354164124 for ['[CLS] their independent sorry fellow grapes ether family [SEP]']
[Init] best rec loss: 0.6765369176864624 for ['[CLS] crawl edo aside don news another objective [SEP]']
[Init] best rec loss: 0.6588159799575806 for ['[CLS] louisiana cass sniff case easier bethany [SEP] [SEP]']
[Init] best perm rec loss: 0.6569523215293884 for ['[CLS] [SEP] louisiana cass case easier bethany sniff [SEP]']
[Init] best perm rec loss: 0.6562753915786743 for ['[CLS] louisiana cass [SEP] bethany easier case sniff [SEP]']
[Init] best perm rec loss: 0.6558287143707275 for ['[CLS] cass louisiana easier bethany case sniff [SEP] [SEP]']
[Init] best perm rec loss: 0.655552327632904 for ['[CLS] easier [SEP] case cass bethany sniff louisiana [SEP]']
[Init] best perm rec loss: 0.6544262766838074 for ['[CLS] cass sniff bethany louisiana easier [SEP] case [SEP]']
[Init] best perm rec loss: 0.6531568765640259 for ['[CLS] cass easier louisiana [SEP] bethany case sniff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.810 (perp=12.848, rec=0.241), tot_loss_proj:3.131 [t=0.25s]
prediction: ['[CLS] point things knob [SEP] things flame flame [SEP]']
[ 100/2000] tot_loss=2.562 (perp=12.025, rec=0.157), tot_loss_proj:2.913 [t=0.27s]
prediction: ['[CLS] point at apples [SEP] things flame flame [SEP]']
[ 150/2000] tot_loss=2.315 (perp=11.032, rec=0.108), tot_loss_proj:2.616 [t=0.24s]
prediction: ['[CLS] point at things [SEP] things flame explode [SEP]']
[ 200/2000] tot_loss=2.210 (perp=10.610, rec=0.088), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] point at things [SEP] that flame explode [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.931 (perp=9.034, rec=0.124), tot_loss_proj:2.201 [t=0.25s]
prediction: ['[CLS] at point at things that flame explode [SEP]']
[ 300/2000] tot_loss=1.932 (perp=9.176, rec=0.097), tot_loss_proj:2.228 [t=0.26s]
prediction: ['[CLS] by point at things that flame explode [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.195 (perp=10.481, rec=0.099), tot_loss_proj:2.648 [t=0.28s]
prediction: ['[CLS] things [SEP] point at that flame explode [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.961 (perp=9.352, rec=0.090), tot_loss_proj:2.427 [t=0.25s]
prediction: ['[CLS] things [SEP] at that point flame explode [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.973, rec=0.093), tot_loss_proj:2.296 [t=0.27s]
prediction: ['[CLS] things by at that point flame explode [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.513 (perp=7.119, rec=0.089), tot_loss_proj:1.895 [t=0.26s]
prediction: ['[CLS] things explode at that point flame by [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.489 (perp=6.966, rec=0.096), tot_loss_proj:1.935 [t=0.27s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 600/2000] tot_loss=1.477 (perp=6.966, rec=0.084), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.476 (perp=6.966, rec=0.082), tot_loss_proj:1.932 [t=0.28s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.486 (perp=6.966, rec=0.092), tot_loss_proj:1.920 [t=0.29s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 750/2000] tot_loss=1.477 (perp=6.966, rec=0.084), tot_loss_proj:1.923 [t=0.27s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.481 (perp=6.966, rec=0.087), tot_loss_proj:1.929 [t=0.28s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.475 (perp=6.966, rec=0.082), tot_loss_proj:1.923 [t=0.27s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[ 900/2000] tot_loss=1.474 (perp=6.966, rec=0.081), tot_loss_proj:1.925 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=6.966, rec=0.076), tot_loss_proj:1.930 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1000/2000] tot_loss=1.464 (perp=6.966, rec=0.071), tot_loss_proj:1.926 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1050/2000] tot_loss=1.460 (perp=6.966, rec=0.067), tot_loss_proj:1.921 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1100/2000] tot_loss=1.466 (perp=6.966, rec=0.073), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1150/2000] tot_loss=1.461 (perp=6.966, rec=0.068), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1200/2000] tot_loss=1.480 (perp=6.966, rec=0.086), tot_loss_proj:1.927 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1250/2000] tot_loss=1.465 (perp=6.966, rec=0.072), tot_loss_proj:1.924 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1300/2000] tot_loss=1.477 (perp=6.966, rec=0.084), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1350/2000] tot_loss=1.472 (perp=6.966, rec=0.079), tot_loss_proj:1.925 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1400/2000] tot_loss=1.469 (perp=6.966, rec=0.076), tot_loss_proj:1.916 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1450/2000] tot_loss=1.467 (perp=6.966, rec=0.074), tot_loss_proj:1.927 [t=0.24s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1500/2000] tot_loss=1.472 (perp=6.966, rec=0.079), tot_loss_proj:1.922 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1550/2000] tot_loss=1.477 (perp=6.966, rec=0.084), tot_loss_proj:1.931 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1600/2000] tot_loss=1.479 (perp=6.966, rec=0.085), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1650/2000] tot_loss=1.477 (perp=6.966, rec=0.083), tot_loss_proj:1.926 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1700/2000] tot_loss=1.465 (perp=6.966, rec=0.072), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1750/2000] tot_loss=1.469 (perp=6.966, rec=0.075), tot_loss_proj:1.924 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1800/2000] tot_loss=1.481 (perp=6.966, rec=0.088), tot_loss_proj:1.922 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=6.966, rec=0.073), tot_loss_proj:1.923 [t=0.26s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[1900/2000] tot_loss=1.465 (perp=6.966, rec=0.072), tot_loss_proj:1.924 [t=0.27s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
[1950/2000] tot_loss=1.468 (perp=6.966, rec=0.074), tot_loss_proj:1.925 [t=0.25s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Attempt swap
[2000/2000] tot_loss=1.469 (perp=6.966, rec=0.076), tot_loss_proj:1.925 [t=0.27s]
prediction: ['[CLS] things explode at that point flame into [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] things explode at that point flame into [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 91.576 | p: 90.010 | r: 93.741
rouge2     | fm: 54.652 | p: 54.190 | r: 55.056
rougeL     | fm: 78.367 | p: 77.090 | r: 79.920
rougeLsum  | fm: 78.319 | p: 76.959 | r: 79.909
r1fm+r2fm = 146.228

input #13 time: 0:10:45 | total time: 2:34:01


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 1.0317866802215576 for ['[CLS] watson aria road sales reserved [SEP]']
[Init] best rec loss: 0.96165931224823 for ['[CLS] vuiche regional or brewing [SEP]']
[Init] best rec loss: 0.9580699801445007 for ['[CLS] time revivalrest shopping turing [SEP]']
[Init] best rec loss: 0.9531562328338623 for ['[CLS] ze died sheets funk tied [SEP]']
[Init] best rec loss: 0.949489414691925 for ['[CLS] team ty rios any kicked [SEP]']
[Init] best rec loss: 0.9473447799682617 for ['[CLS] mustard auto parties state mass [SEP]']
[Init] best perm rec loss: 0.946354866027832 for ['[CLS] parties state auto mass mustard [SEP]']
[Init] best perm rec loss: 0.9454386830329895 for ['[CLS] mustard state mass auto parties [SEP]']
[Init] best perm rec loss: 0.9453603029251099 for ['[CLS] auto mustard state mass parties [SEP]']
[Init] best perm rec loss: 0.9447199702262878 for ['[CLS] mass mustard parties auto state [SEP]']
[Init] best perm rec loss: 0.9438371062278748 for ['[CLS] mass auto state mustard parties [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.552 (perp=13.159, rec=0.921), tot_loss_proj:3.619 [t=0.26s]
prediction: ['[CLS] whosened 2015 raisednding [SEP]']
[ 100/2000] tot_loss=3.350 (perp=13.599, rec=0.630), tot_loss_proj:3.681 [t=0.24s]
prediction: ['[CLS] einstein denied justine investigation families [SEP]']
[ 150/2000] tot_loss=3.228 (perp=13.399, rec=0.548), tot_loss_proj:3.685 [t=0.24s]
prediction: ['[CLS] intriguing worst alyssa film families [SEP]']
[ 200/2000] tot_loss=2.785 (perp=11.333, rec=0.519), tot_loss_proj:3.281 [t=0.26s]
prediction: ['[CLS] intriguing worst intriguing filmceae [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.879 (perp=11.848, rec=0.509), tot_loss_proj:3.376 [t=0.26s]
prediction: ['[CLS] intriguing chandra worst filminess [SEP]']
[ 300/2000] tot_loss=2.617 (perp=10.339, rec=0.549), tot_loss_proj:3.083 [t=0.26s]
prediction: ['[CLS] intriguing intriguing worst film investigation [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.958 (perp=12.431, rec=0.472), tot_loss_proj:3.597 [t=0.29s]
prediction: ['[CLS] intriguing intriguing last film unrest [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.625 (perp=10.684, rec=0.488), tot_loss_proj:3.194 [t=0.26s]
prediction: ['[CLS] intriguing blinked fascinating last film [SEP]']
[ 450/2000] tot_loss=2.579 (perp=10.684, rec=0.442), tot_loss_proj:3.187 [t=0.24s]
prediction: ['[CLS] intriguing blinked fascinating last film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.948 (perp=12.593, rec=0.430), tot_loss_proj:3.647 [t=0.25s]
prediction: ['[CLS] intriguingnivorous fascinating typical film [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.944 (perp=12.551, rec=0.433), tot_loss_proj:3.654 [t=0.38s]
prediction: ['[CLS] intriguingceae film│ fascinating [SEP]']
[ 600/2000] tot_loss=2.796 (perp=11.781, rec=0.440), tot_loss_proj:3.409 [t=0.26s]
prediction: ['[CLS] intriguingnivorous filmァ fascinating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.868 (perp=12.269, rec=0.414), tot_loss_proj:3.573 [t=0.25s]
prediction: ['[CLS] intriguingxious film serie fascinating [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.116 (perp=13.474, rec=0.421), tot_loss_proj:3.803 [t=0.28s]
prediction: ['[CLS] intriguingnivorous film fascinatingislaus [SEP]']
[ 750/2000] tot_loss=3.001 (perp=12.964, rec=0.408), tot_loss_proj:3.641 [t=0.35s]
prediction: ['[CLS] intriguingxious film fascinatingislaus [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.767 (perp=11.781, rec=0.411), tot_loss_proj:3.387 [t=0.25s]
prediction: ['[CLS] intriguingnivorous filmァ fascinating [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.763 (perp=11.781, rec=0.407), tot_loss_proj:3.398 [t=0.25s]
prediction: ['[CLS] intriguingnivorous filmァ fascinating [SEP]']
[ 900/2000] tot_loss=2.763 (perp=11.781, rec=0.406), tot_loss_proj:3.393 [t=0.25s]
prediction: ['[CLS] intriguingnivorous filmァ fascinating [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.764 (perp=11.800, rec=0.404), tot_loss_proj:3.524 [t=0.26s]
prediction: ['[CLS] intriguingnivorous film fascinating serie [SEP]']
Attempt swap
[1000/2000] tot_loss=2.759 (perp=11.800, rec=0.399), tot_loss_proj:3.529 [t=0.26s]
prediction: ['[CLS] intriguingnivorous film fascinating serie [SEP]']
[1050/2000] tot_loss=2.758 (perp=11.800, rec=0.398), tot_loss_proj:3.529 [t=0.25s]
prediction: ['[CLS] intriguingnivorous film fascinating serie [SEP]']
Attempt swap
[1100/2000] tot_loss=2.747 (perp=11.800, rec=0.387), tot_loss_proj:3.528 [t=0.25s]
prediction: ['[CLS] intriguingnivorous film fascinating serie [SEP]']
Attempt swap
[1150/2000] tot_loss=2.752 (perp=11.800, rec=0.392), tot_loss_proj:3.529 [t=0.27s]
prediction: ['[CLS] intriguingnivorous film fascinating serie [SEP]']
[1200/2000] tot_loss=3.023 (perp=13.118, rec=0.399), tot_loss_proj:3.777 [t=0.25s]
prediction: ['[CLS] intriguingently film↦ serie [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.963 (perp=12.840, rec=0.395), tot_loss_proj:3.736 [t=0.25s]
prediction: ['[CLS] filmently intriguing亻 serie [SEP]']
Attempt swap
[1300/2000] tot_loss=2.955 (perp=12.840, rec=0.387), tot_loss_proj:3.733 [t=0.26s]
prediction: ['[CLS] filmently intriguing亻 serie [SEP]']
[1350/2000] tot_loss=2.887 (perp=12.502, rec=0.387), tot_loss_proj:3.655 [t=0.25s]
prediction: ['[CLS] filmently intriguing↦ serie [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.820 (perp=12.077, rec=0.405), tot_loss_proj:3.621 [t=0.26s]
prediction: ['[CLS]亻ently intriguing film serie [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.771 (perp=11.791, rec=0.413), tot_loss_proj:3.544 [t=0.25s]
prediction: ['[CLS]亻ently intriguing serie film [SEP]']
[1500/2000] tot_loss=2.746 (perp=11.791, rec=0.387), tot_loss_proj:3.558 [t=0.25s]
prediction: ['[CLS]亻ently intriguing serie film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.750 (perp=11.791, rec=0.392), tot_loss_proj:3.546 [t=0.33s]
prediction: ['[CLS]亻ently intriguing serie film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.973 (perp=12.923, rec=0.388), tot_loss_proj:3.746 [t=0.26s]
prediction: ['[CLS]dermottently intriguing serie film [SEP]']
[1650/2000] tot_loss=2.970 (perp=12.923, rec=0.386), tot_loss_proj:3.742 [t=0.27s]
prediction: ['[CLS]dermottently intriguing serie film [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.773 (perp=11.886, rec=0.396), tot_loss_proj:3.515 [t=0.25s]
prediction: ['[CLS] filmently intriguing seriedermott [SEP]']
Attempt swap
[1750/2000] tot_loss=2.840 (perp=12.271, rec=0.385), tot_loss_proj:3.600 [t=0.26s]
prediction: ['[CLS] filmently intriguing serie↦ [SEP]']
[1800/2000] tot_loss=2.837 (perp=12.271, rec=0.382), tot_loss_proj:3.595 [t=0.26s]
prediction: ['[CLS] filmently intriguing serie↦ [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.679 (perp=11.378, rec=0.404), tot_loss_proj:3.453 [t=0.26s]
prediction: ['[CLS] serieently intriguing film↦ [SEP]']
Attempt swap
[1900/2000] tot_loss=2.673 (perp=11.378, rec=0.397), tot_loss_proj:3.451 [t=0.28s]
prediction: ['[CLS] serieently intriguing film↦ [SEP]']
[1950/2000] tot_loss=2.666 (perp=11.378, rec=0.391), tot_loss_proj:3.452 [t=0.25s]
prediction: ['[CLS] serieently intriguing film↦ [SEP]']
Attempt swap
[2000/2000] tot_loss=2.667 (perp=11.378, rec=0.392), tot_loss_proj:3.453 [t=0.26s]
prediction: ['[CLS] serieently intriguing film↦ [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] filmently intriguing serie↦ [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 89.237 | p: 87.638 | r: 91.159
rouge2     | fm: 50.895 | p: 50.489 | r: 51.211
rougeL     | fm: 77.181 | p: 75.876 | r: 78.599
rougeLsum  | fm: 76.943 | p: 75.688 | r: 78.412
r1fm+r2fm = 140.132

input #14 time: 0:10:53 | total time: 2:44:55


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8874340057373047 for ['[CLS]cb endemic tommy heavier scarmain part dixon [SEP]']
[Init] best rec loss: 0.8533442616462708 for ['[CLS] loan males headquartered minute replay person snuggled child [SEP]']
[Init] best rec loss: 0.8206142783164978 for ['[CLS] sat less westble settlement count archived electors [SEP]']
[Init] best rec loss: 0.800389289855957 for ['[CLS] latebid weary projected rottle outside pedal [SEP]']
[Init] best rec loss: 0.7689843773841858 for ["[CLS] reflection plan leaf hot taken'events rural [SEP]"]
[Init] best rec loss: 0.7603092789649963 for ['[CLS] encompasses on extreme still plenty award whose lucifer [SEP]']
[Init] best perm rec loss: 0.7598164677619934 for ['[CLS] award still encompasses lucifer whose on plenty extreme [SEP]']
[Init] best perm rec loss: 0.7585607767105103 for ['[CLS] plenty on whose still award lucifer extreme encompasses [SEP]']
[Init] best perm rec loss: 0.7577694058418274 for ['[CLS] lucifer encompasses whose award still extreme plenty on [SEP]']
[Init] best perm rec loss: 0.7542826533317566 for ['[CLS] award plenty extreme lucifer still whose on encompasses [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.166 (perp=13.673, rec=0.431), tot_loss_proj:3.418 [t=0.25s]
prediction: ['[CLS] awardably destination circuitably interpretationulsion contributed [SEP]']
[ 100/2000] tot_loss=2.790 (perp=12.056, rec=0.379), tot_loss_proj:3.109 [t=0.24s]
prediction: ['[CLS] interviewably haulbreakerably chillers efficient [SEP]']
[ 150/2000] tot_loss=2.660 (perp=11.560, rec=0.348), tot_loss_proj:2.992 [t=0.27s]
prediction: ['[CLS]ablyably anonymous blowably chill. efficient [SEP]']
[ 200/2000] tot_loss=2.960 (perp=13.237, rec=0.313), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS]ivelyably anonymousweeably chill. efficient [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.870 (perp=12.860, rec=0.298), tot_loss_proj:3.329 [t=0.25s]
prediction: ['[CLS] mailably anonymouscutably chill efficient ambushed [SEP]']
[ 300/2000] tot_loss=2.408 (perp=10.647, rec=0.279), tot_loss_proj:2.767 [t=0.24s]
prediction: ['[CLS] performanceably anonymouscutably chill efficient. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.677 (perp=11.974, rec=0.283), tot_loss_proj:3.100 [t=0.25s]
prediction: ['[CLS] dressably anonymous chill pensionably efficientogan [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.584 (perp=11.557, rec=0.273), tot_loss_proj:3.008 [t=0.23s]
prediction: ['[CLS]ably anonymous dress chillcutably efficientleader [SEP]']
[ 450/2000] tot_loss=2.610 (perp=11.732, rec=0.264), tot_loss_proj:3.001 [t=0.25s]
prediction: ['[CLS]ably anonymous performance chillcutably efficient claudia [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.537 (perp=11.459, rec=0.245), tot_loss_proj:2.931 [t=0.26s]
prediction: ['[CLS]ably anonymous performance chillcutably claudia efficient [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.633 (perp=11.905, rec=0.252), tot_loss_proj:3.030 [t=0.28s]
prediction: ['[CLS]ably anonymous suit chillcutably reacher efficient [SEP]']
[ 600/2000] tot_loss=2.731 (perp=12.438, rec=0.243), tot_loss_proj:3.197 [t=0.26s]
prediction: ['[CLS] suit anonymous suit chillcutably reacher efficient [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.608 (perp=11.799, rec=0.248), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] anonymous suit performance chillcutably reacher efficient [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.713 (perp=12.343, rec=0.245), tot_loss_proj:3.116 [t=0.27s]
prediction: ['[CLS] anonymous suitably chillenberg among reacher efficient [SEP]']
[ 750/2000] tot_loss=2.702 (perp=12.343, rec=0.233), tot_loss_proj:3.115 [t=0.25s]
prediction: ['[CLS] anonymous suitably chillenberg among reacher efficient [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.560 (perp=11.641, rec=0.232), tot_loss_proj:3.034 [t=0.25s]
prediction: ['[CLS] anonymous suit among chillenbergably ， efficient [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.608 (perp=11.938, rec=0.221), tot_loss_proj:3.094 [t=0.25s]
prediction: ['[CLS] anonymous suit among chillenbergably reacher efficient [SEP]']
[ 900/2000] tot_loss=2.611 (perp=11.938, rec=0.223), tot_loss_proj:3.092 [t=0.25s]
prediction: ['[CLS] anonymous suit among chillenbergably reacher efficient [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.616 (perp=11.938, rec=0.228), tot_loss_proj:3.090 [t=0.25s]
prediction: ['[CLS] anonymous suit among chillenbergably reacher efficient [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.928 (perp=13.415, rec=0.245), tot_loss_proj:3.384 [t=0.27s]
prediction: ['[CLS] anonymous suithetic reacher chillfreeably efficient [SEP]']
[1050/2000] tot_loss=2.447 (perp=11.134, rec=0.220), tot_loss_proj:2.894 [t=0.25s]
prediction: ['[CLS] anonymous suit. reacher chillfreeably efficient [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.549 (perp=11.660, rec=0.217), tot_loss_proj:3.048 [t=0.25s]
prediction: ['[CLS] anonymoushetic ， chillfree suitably efficient [SEP]']
Attempt swap
[1150/2000] tot_loss=2.191 (perp=9.838, rec=0.223), tot_loss_proj:2.678 [t=0.24s]
prediction: ['[CLS] anonymous. ， chillfree suitably efficient [SEP]']
[1200/2000] tot_loss=2.181 (perp=9.838, rec=0.214), tot_loss_proj:2.673 [t=0.26s]
prediction: ['[CLS] anonymous. ， chillfree suitably efficient [SEP]']
Attempt swap
[1250/2000] tot_loss=2.168 (perp=9.746, rec=0.219), tot_loss_proj:2.648 [t=0.25s]
prediction: ['[CLS]er. ， chillfree suitably efficient [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.971 (perp=8.744, rec=0.222), tot_loss_proj:2.445 [t=0.37s]
prediction: ['[CLS]. ， chillerfree suitably efficient [SEP]']
[1350/2000] tot_loss=2.193 (perp=9.904, rec=0.212), tot_loss_proj:2.753 [t=0.27s]
prediction: ['[CLS]. ， chillerenberg suitably efficient [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.352 (perp=10.625, rec=0.227), tot_loss_proj:2.871 [t=0.27s]
prediction: ['[CLS]free ， chillerhetic suitably efficient [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.274 (perp=10.160, rec=0.242), tot_loss_proj:2.709 [t=0.27s]
prediction: ['[CLS] kramer efficient chillerhetic suitably ， [SEP]']
[1500/2000] tot_loss=2.250 (perp=10.160, rec=0.218), tot_loss_proj:2.712 [t=0.26s]
prediction: ['[CLS] kramer efficient chillerhetic suitably ， [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.304 (perp=10.367, rec=0.230), tot_loss_proj:2.720 [t=0.25s]
prediction: ['[CLS] kramer efficient chillerleader suitablyhetic [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.258 (perp=10.160, rec=0.226), tot_loss_proj:2.712 [t=0.26s]
prediction: ['[CLS] kramer efficient chillerhetic suitably ， [SEP]']
[1650/2000] tot_loss=2.254 (perp=10.160, rec=0.222), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] kramer efficient chillerhetic suitably ， [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.127 (perp=9.538, rec=0.220), tot_loss_proj:2.562 [t=0.25s]
prediction: ['[CLS] kramer efficient chiller ， suitablyhetic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.129 (perp=9.538, rec=0.221), tot_loss_proj:2.556 [t=0.26s]
prediction: ['[CLS] kramer efficient chiller ， suitablyhetic [SEP]']
[1800/2000] tot_loss=2.126 (perp=9.538, rec=0.218), tot_loss_proj:2.560 [t=0.25s]
prediction: ['[CLS] kramer efficient chiller ， suitablyhetic [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.102 (perp=9.383, rec=0.225), tot_loss_proj:2.481 [t=0.25s]
prediction: ['[CLS] kramerhetic chiller ， suitably efficient [SEP]']
Attempt swap
[1900/2000] tot_loss=2.098 (perp=9.383, rec=0.222), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] kramerhetic chiller ， suitably efficient [SEP]']
[1950/2000] tot_loss=2.197 (perp=9.939, rec=0.209), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS] kramer afford chiller ， suitably efficient [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.063 (perp=9.198, rec=0.223), tot_loss_proj:2.457 [t=0.32s]
prediction: ['[CLS]. kramer chiller ， suitably efficient [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] kramer afford chiller ， suitably efficient [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 46.154 | p: 42.857 | r: 50.000
rougeLsum  | fm: 46.154 | p: 42.857 | r: 50.000
r1fm+r2fm = 76.923

[Aggregate metrics]:
rouge1     | fm: 88.615 | p: 86.853 | r: 90.796
rouge2     | fm: 47.668 | p: 47.354 | r: 48.021
rougeL     | fm: 75.075 | p: 73.800 | r: 76.657
rougeLsum  | fm: 75.042 | p: 73.617 | r: 76.728
r1fm+r2fm = 136.283

input #15 time: 0:10:48 | total time: 2:55:43


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8567513227462769 for ['[CLS] force canal academyfu albert live [SEP]']
[Init] best rec loss: 0.7897226810455322 for ['[CLS] hat way established porch leap easily [SEP]']
[Init] best rec loss: 0.7690733075141907 for ['[CLS] happen cease terrible at iron liberties [SEP]']
[Init] best rec loss: 0.763019323348999 for ['[CLS] flags taped image mission indian tale [SEP]']
[Init] best rec loss: 0.7508068680763245 for ['[CLS] knock stock less rose morning hotspur [SEP]']
[Init] best rec loss: 0.736833930015564 for ['[CLS] believe that secured and iris place [SEP]']
[Init] best rec loss: 0.7336040139198303 for ['[CLS] alan succeeded bro &vre ring [SEP]']
[Init] best rec loss: 0.7188952565193176 for ['[CLS]gas { separately colby recent faced [SEP]']
[Init] best rec loss: 0.7052714228630066 for ['[CLS] magic meant native motor based arranged [SEP]']
[Init] best rec loss: 0.7050625681877136 for ['[CLS]uate good dog skills spread holly [SEP]']
[Init] best perm rec loss: 0.7038169503211975 for ['[CLS] dog spread gooduate holly skills [SEP]']
[Init] best perm rec loss: 0.7008183002471924 for ['[CLS] skills holly good spread doguate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.889 (perp=7.998, rec=0.289), tot_loss_proj:2.032 [t=0.25s]
prediction: ['[CLS] all all of more this more [SEP]']
[ 100/2000] tot_loss=1.505 (perp=7.002, rec=0.105), tot_loss_proj:1.710 [t=0.27s]
prediction: ['[CLS] all and of this and more [SEP]']
[ 150/2000] tot_loss=1.313 (perp=6.162, rec=0.080), tot_loss_proj:1.587 [t=0.31s]
prediction: ['[CLS] all, of this and more [SEP]']
[ 200/2000] tot_loss=1.308 (perp=6.162, rec=0.076), tot_loss_proj:1.578 [t=0.31s]
prediction: ['[CLS] all, of this and more [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.008 (perp=4.697, rec=0.069), tot_loss_proj:1.058 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 300/2000] tot_loss=0.999 (perp=4.697, rec=0.060), tot_loss_proj:1.062 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.005 (perp=4.697, rec=0.065), tot_loss_proj:1.055 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.008 (perp=4.697, rec=0.068), tot_loss_proj:1.051 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.001 (perp=4.697, rec=0.062), tot_loss_proj:1.044 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.001 (perp=4.697, rec=0.062), tot_loss_proj:1.055 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.998 (perp=4.697, rec=0.058), tot_loss_proj:1.059 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=0.987 (perp=4.697, rec=0.047), tot_loss_proj:1.058 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.999 (perp=4.697, rec=0.060), tot_loss_proj:1.054 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.001 (perp=4.697, rec=0.062), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=0.997 (perp=4.697, rec=0.058), tot_loss_proj:1.056 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.998 (perp=4.697, rec=0.058), tot_loss_proj:1.056 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.998 (perp=4.697, rec=0.058), tot_loss_proj:1.058 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.000 (perp=4.697, rec=0.061), tot_loss_proj:1.055 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.009 (perp=4.697, rec=0.070), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.008 (perp=4.697, rec=0.068), tot_loss_proj:1.057 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=0.995 (perp=4.697, rec=0.055), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.004 (perp=4.697, rec=0.065), tot_loss_proj:1.049 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.001 (perp=4.697, rec=0.061), tot_loss_proj:1.058 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.004 (perp=4.697, rec=0.065), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.008 (perp=4.697, rec=0.068), tot_loss_proj:1.055 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=0.989 (perp=4.697, rec=0.050), tot_loss_proj:1.054 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=0.999 (perp=4.697, rec=0.060), tot_loss_proj:1.065 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=0.992 (perp=4.697, rec=0.053), tot_loss_proj:1.060 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=0.996 (perp=4.697, rec=0.057), tot_loss_proj:1.058 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.000 (perp=4.697, rec=0.061), tot_loss_proj:1.060 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.002 (perp=4.697, rec=0.062), tot_loss_proj:1.048 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.001 (perp=4.697, rec=0.062), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.010 (perp=4.697, rec=0.070), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=0.993 (perp=4.697, rec=0.054), tot_loss_proj:1.047 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=0.997 (perp=4.697, rec=0.057), tot_loss_proj:1.054 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=0.996 (perp=4.697, rec=0.057), tot_loss_proj:1.063 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=0.998 (perp=4.697, rec=0.058), tot_loss_proj:1.048 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=0.989 (perp=4.697, rec=0.049), tot_loss_proj:1.052 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.005 (perp=4.697, rec=0.066), tot_loss_proj:1.054 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=0.993 (perp=4.697, rec=0.053), tot_loss_proj:1.051 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.374 | p: 87.639 | r: 91.415
rouge2     | fm: 51.380 | p: 51.078 | r: 51.809
rougeL     | fm: 76.489 | p: 75.251 | r: 78.092
rougeLsum  | fm: 76.341 | p: 75.200 | r: 77.902
r1fm+r2fm = 140.754

input #16 time: 0:11:07 | total time: 3:06:51


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8099570274353027 for ['[CLS] bench integrated rent server yes ny engagement transferred married kicking bureau [SEP]']
[Init] best rec loss: 0.8071512579917908 for ['[CLS] disciplines grounds fm resist cause freaking principal alreadyajtownod [SEP]']
[Init] best rec loss: 0.7973856329917908 for ['[CLS] dinner preliminarynd packed dc resort french aside score vr why [SEP]']
[Init] best rec loss: 0.7898494601249695 for ['[CLS] restaurant junior anniversary declare musicuen offers shot sprint pac most [SEP]']
[Init] best rec loss: 0.7737298607826233 for ['[CLS] qualifier act stage election phone paper cheek apparent idf goals rite [SEP]']
[Init] best rec loss: 0.7653641104698181 for ['[CLS] state airs yourgly zoologyrius parks hurt widespread production corporation [SEP]']
[Init] best rec loss: 0.7563247680664062 for ['[CLS] dance faa creek great rochelle past department up place ripley settling [SEP]']
[Init] best rec loss: 0.7510905265808105 for ['[CLS] rainbowid household dr verity imaging sentence authority bath gay tips [SEP]']
[Init] best perm rec loss: 0.7502259016036987 for ['[CLS] dr rainbow imaging bath gayid household verity sentence tips authority [SEP]']
[Init] best perm rec loss: 0.7491382956504822 for ['[CLS] gay imaging tips dr sentence household rainbowid verity bath authority [SEP]']
[Init] best perm rec loss: 0.7487574815750122 for ['[CLS] bath household verityid gay sentence imaging tips rainbow authority dr [SEP]']
[Init] best perm rec loss: 0.7466709613800049 for ['[CLS] sentenceid gay verity household authority dr tips imaging bath rainbow [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.600 (perp=11.349, rec=0.330), tot_loss_proj:2.938 [t=0.27s]
prediction: ['[CLS] think completely crazy life black think want want think too broad [SEP]']
[ 100/2000] tot_loss=1.971 (perp=8.994, rec=0.172), tot_loss_proj:2.376 [t=0.25s]
prediction: ['[CLS] think too around about too think want much think too much [SEP]']
[ 150/2000] tot_loss=1.666 (perp=7.816, rec=0.103), tot_loss_proj:2.104 [t=0.25s]
prediction: ['[CLS] think about around about too about want to think too much [SEP]']
[ 200/2000] tot_loss=1.619 (perp=7.691, rec=0.081), tot_loss_proj:2.024 [t=0.26s]
prediction: ['[CLS] think about what going too about want to think too much [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.500 (perp=7.097, rec=0.081), tot_loss_proj:1.874 [t=0.27s]
prediction: ['[CLS] think too what going about about want to think too much [SEP]']
[ 300/2000] tot_loss=1.493 (perp=7.097, rec=0.074), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] think too what going about about want to think too much [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.517 (perp=7.251, rec=0.066), tot_loss_proj:1.880 [t=0.27s]
prediction: ['[CLS] think on what s want to think too much going about [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.328 (perp=6.256, rec=0.077), tot_loss_proj:1.667 [t=0.26s]
prediction: ['[CLS] think about what s want to think too much going on [SEP]']
[ 450/2000] tot_loss=1.369 (perp=6.490, rec=0.071), tot_loss_proj:1.771 [t=0.27s]
prediction: ['[CLS] think about what s want to on too much going on [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.296 (perp=6.107, rec=0.074), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS] think about what s to want on too much going on [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.278 (perp=6.049, rec=0.069), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS] think about what s on to want too much going on [SEP]']
[ 600/2000] tot_loss=1.274 (perp=6.049, rec=0.064), tot_loss_proj:1.698 [t=0.26s]
prediction: ['[CLS] think about what s on to want too much going on [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.196 (perp=5.631, rec=0.069), tot_loss_proj:1.653 [t=0.26s]
prediction: ['[CLS] think about what s going on to want too much on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.203 (perp=5.631, rec=0.077), tot_loss_proj:1.652 [t=0.26s]
prediction: ['[CLS] think about what s going on to want too much on [SEP]']
[ 750/2000] tot_loss=1.201 (perp=5.631, rec=0.075), tot_loss_proj:1.659 [t=0.28s]
prediction: ['[CLS] think about what s going on to want too much on [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.142 (perp=5.398, rec=0.062), tot_loss_proj:1.623 [t=0.26s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.149 (perp=5.398, rec=0.069), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[ 900/2000] tot_loss=1.146 (perp=5.398, rec=0.066), tot_loss_proj:1.625 [t=0.28s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.153 (perp=5.398, rec=0.073), tot_loss_proj:1.628 [t=0.26s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1000/2000] tot_loss=1.146 (perp=5.398, rec=0.066), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[1050/2000] tot_loss=1.145 (perp=5.398, rec=0.066), tot_loss_proj:1.627 [t=0.28s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.150 (perp=5.398, rec=0.070), tot_loss_proj:1.625 [t=0.28s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1150/2000] tot_loss=1.137 (perp=5.398, rec=0.058), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[1200/2000] tot_loss=1.210 (perp=5.725, rec=0.065), tot_loss_proj:1.685 [t=0.25s]
prediction: ["[CLS] think about what s going on'to want too much [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.458 (perp=6.917, rec=0.074), tot_loss_proj:1.938 [t=0.26s]
prediction: ['[CLS] think about what on s going on to want too much [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.143 (perp=5.398, rec=0.063), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[1350/2000] tot_loss=1.148 (perp=5.398, rec=0.068), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1400/2000] tot_loss=1.145 (perp=5.398, rec=0.066), tot_loss_proj:1.635 [t=0.25s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1450/2000] tot_loss=1.151 (perp=5.398, rec=0.071), tot_loss_proj:1.635 [t=0.26s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[1500/2000] tot_loss=1.213 (perp=5.725, rec=0.067), tot_loss_proj:1.684 [t=0.25s]
prediction: ["[CLS] think about what s going on'to want too much [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.447 (perp=6.917, rec=0.063), tot_loss_proj:1.937 [t=0.25s]
prediction: ['[CLS] think about what on s going on to want too much [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.159 (perp=5.440, rec=0.071), tot_loss_proj:1.631 [t=0.27s]
prediction: ["[CLS]'think about what s going on to want too much [SEP]"]
[1650/2000] tot_loss=1.192 (perp=5.656, rec=0.061), tot_loss_proj:1.751 [t=0.25s]
prediction: ['[CLS] on think about what s going on to want too much [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.156 (perp=5.398, rec=0.077), tot_loss_proj:1.627 [t=0.28s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1750/2000] tot_loss=1.139 (perp=5.398, rec=0.059), tot_loss_proj:1.634 [t=0.27s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[1800/2000] tot_loss=1.142 (perp=5.398, rec=0.062), tot_loss_proj:1.630 [t=0.26s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1850/2000] tot_loss=1.152 (perp=5.398, rec=0.072), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
Attempt swap
[1900/2000] tot_loss=1.139 (perp=5.398, rec=0.060), tot_loss_proj:1.641 [t=0.26s]
prediction: ['[CLS] think about what s going on on to want too much [SEP]']
[1950/2000] tot_loss=1.211 (perp=5.725, rec=0.066), tot_loss_proj:1.685 [t=0.26s]
prediction: ["[CLS] think about what s going on'to want too much [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.190 (perp=5.656, rec=0.059), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] on think about what s going on to want too much [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] think about what on s going on to want too much [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 130.783

[Aggregate metrics]:
rouge1     | fm: 89.694 | p: 87.858 | r: 91.984
rouge2     | fm: 49.867 | p: 49.481 | r: 50.349
rougeL     | fm: 75.925 | p: 74.673 | r: 77.513
rougeLsum  | fm: 75.862 | p: 74.520 | r: 77.512
r1fm+r2fm = 139.560

input #17 time: 0:10:56 | total time: 3:17:47


Running input #18 of 100.
reference: 
========================
invigorating 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9431664347648621 for ['[CLS] crew obey buyuke [SEP]']
[Init] best rec loss: 0.9225099086761475 for ['[CLS] app response hadn attic [SEP]']
[Init] best rec loss: 0.8989289402961731 for ['[CLS] haven sphinx member flights [SEP]']
[Init] best rec loss: 0.7938730716705322 for ['[CLS] writer seconds plan ot [SEP]']
[Init] best rec loss: 0.7768938541412354 for ['[CLS] hm hardware intersectionsoom [SEP]']
[Init] best rec loss: 0.7621232271194458 for ['[CLS] triumphant medium mass necessary [SEP]']
[Init] best rec loss: 0.7272797226905823 for ['[CLS] ships qualify very fashion [SEP]']
[Init] best perm rec loss: 0.7264016270637512 for ['[CLS] very ships qualify fashion [SEP]']
[Init] best perm rec loss: 0.7243151664733887 for ['[CLS] very qualify ships fashion [SEP]']
[Init] best perm rec loss: 0.7142418622970581 for ['[CLS] qualify very fashion ships [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.399 (perp=13.179, rec=0.763), tot_loss_proj:3.688 [t=0.26s]
prediction: ['[CLS] visual warm success composed [SEP]']
[ 100/2000] tot_loss=2.774 (perp=10.977, rec=0.579), tot_loss_proj:2.950 [t=0.25s]
prediction: ['[CLS] makeating hockey majority [SEP]']
[ 150/2000] tot_loss=3.312 (perp=14.156, rec=0.481), tot_loss_proj:3.662 [t=0.26s]
prediction: ['[CLS]viatinggor majority [SEP]']
[ 200/2000] tot_loss=3.350 (perp=14.445, rec=0.461), tot_loss_proj:3.666 [t=0.27s]
prediction: ['[CLS]vigorgor context [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.878 (perp=12.167, rec=0.445), tot_loss_proj:3.235 [t=0.26s]
prediction: ['[CLS]gorvigor context [SEP]']
[ 300/2000] tot_loss=2.824 (perp=12.167, rec=0.391), tot_loss_proj:3.237 [t=0.25s]
prediction: ['[CLS]gorvigor context [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.814 (perp=12.167, rec=0.381), tot_loss_proj:3.233 [t=0.25s]
prediction: ['[CLS]gorvigor context [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.681 (perp=11.621, rec=0.356), tot_loss_proj:2.967 [t=0.25s]
prediction: ['[CLS]gorvigoruous [SEP]']
[ 450/2000] tot_loss=2.824 (perp=12.315, rec=0.361), tot_loss_proj:3.252 [t=0.26s]
prediction: ['[CLS]gorvigor progresses [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.666 (perp=11.595, rec=0.347), tot_loss_proj:3.312 [t=0.25s]
prediction: ['[CLS]gorvigor headache [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.734 (perp=11.949, rec=0.344), tot_loss_proj:3.162 [t=0.25s]
prediction: ['[CLS]gorvigorurgent [SEP]']
[ 600/2000] tot_loss=2.722 (perp=11.949, rec=0.332), tot_loss_proj:3.161 [t=0.27s]
prediction: ['[CLS]gorvigorurgent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.705 (perp=11.949, rec=0.315), tot_loss_proj:3.159 [t=0.26s]
prediction: ['[CLS]gorvigorurgent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.708 (perp=11.949, rec=0.319), tot_loss_proj:3.165 [t=0.26s]
prediction: ['[CLS]gorvigorurgent [SEP]']
[ 750/2000] tot_loss=2.995 (perp=13.402, rec=0.315), tot_loss_proj:3.421 [t=0.25s]
prediction: ['[CLS]mablevigorurgent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.935 (perp=13.115, rec=0.312), tot_loss_proj:3.493 [t=0.25s]
prediction: ['[CLS]ɨvigorurgent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.912 (perp=13.030, rec=0.306), tot_loss_proj:3.513 [t=0.26s]
prediction: ['[CLS]nablevigorudged [SEP]']
[ 900/2000] tot_loss=2.914 (perp=13.030, rec=0.308), tot_loss_proj:3.515 [t=0.25s]
prediction: ['[CLS]nablevigorudged [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.913 (perp=13.030, rec=0.307), tot_loss_proj:3.511 [t=0.25s]
prediction: ['[CLS]nablevigorudged [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=2.905 (perp=13.468, rec=0.211), tot_loss_proj:3.427 [t=0.25s]
prediction: ['[CLS]vigorurgentnable [SEP]']
[1050/2000] tot_loss=2.872 (perp=13.468, rec=0.179), tot_loss_proj:3.427 [t=0.28s]
prediction: ['[CLS]vigorurgentnable [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.791 (perp=13.067, rec=0.177), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS]vigornableurgent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.781 (perp=13.067, rec=0.167), tot_loss_proj:3.350 [t=0.26s]
prediction: ['[CLS]vigornableurgent [SEP]']
[1200/2000] tot_loss=2.783 (perp=13.067, rec=0.170), tot_loss_proj:3.350 [t=0.25s]
prediction: ['[CLS]vigornableurgent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.771 (perp=13.067, rec=0.157), tot_loss_proj:3.353 [t=0.27s]
prediction: ['[CLS]vigornableurgent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.788 (perp=13.067, rec=0.174), tot_loss_proj:3.349 [t=0.26s]
prediction: ['[CLS]vigornableurgent [SEP]']
[1350/2000] tot_loss=2.785 (perp=13.067, rec=0.172), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS]vigornableurgent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.791 (perp=13.067, rec=0.177), tot_loss_proj:3.347 [t=0.25s]
prediction: ['[CLS]vigornableurgent [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.702 (perp=11.949, rec=0.312), tot_loss_proj:3.165 [t=0.26s]
prediction: ['[CLS]gorvigorurgent [SEP]']
[1500/2000] tot_loss=2.602 (perp=11.949, rec=0.212), tot_loss_proj:3.161 [t=0.27s]
prediction: ['[CLS]gorvigorurgent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.578 (perp=11.949, rec=0.188), tot_loss_proj:3.160 [t=0.26s]
prediction: ['[CLS]gorvigorurgent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.563 (perp=11.899, rec=0.184), tot_loss_proj:3.168 [t=0.25s]
prediction: ['[CLS]gorvigor reid [SEP]']
[1650/2000] tot_loss=2.557 (perp=11.899, rec=0.177), tot_loss_proj:3.171 [t=0.25s]
prediction: ['[CLS]gorvigor reid [SEP]']
Attempt swap
[1700/2000] tot_loss=2.561 (perp=11.899, rec=0.181), tot_loss_proj:3.174 [t=0.27s]
prediction: ['[CLS]gorvigor reid [SEP]']
Attempt swap
[1750/2000] tot_loss=2.550 (perp=11.899, rec=0.170), tot_loss_proj:3.173 [t=0.25s]
prediction: ['[CLS]gorvigor reid [SEP]']
[1800/2000] tot_loss=2.554 (perp=11.899, rec=0.174), tot_loss_proj:3.167 [t=0.26s]
prediction: ['[CLS]gorvigor reid [SEP]']
Attempt swap
[1850/2000] tot_loss=2.552 (perp=11.899, rec=0.172), tot_loss_proj:3.166 [t=0.25s]
prediction: ['[CLS]gorvigor reid [SEP]']
Attempt swap
[1900/2000] tot_loss=2.545 (perp=11.899, rec=0.165), tot_loss_proj:3.172 [t=0.26s]
prediction: ['[CLS]gorvigor reid [SEP]']
[1950/2000] tot_loss=2.553 (perp=11.899, rec=0.173), tot_loss_proj:3.170 [t=0.28s]
prediction: ['[CLS]gorvigor reid [SEP]']
Attempt swap
[2000/2000] tot_loss=2.550 (perp=11.899, rec=0.170), tot_loss_proj:3.169 [t=0.25s]
prediction: ['[CLS]gorvigor reid [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS]vigornableurgent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 88.544 | p: 86.839 | r: 90.564
rouge2     | fm: 46.941 | p: 46.439 | r: 47.493
rougeL     | fm: 75.422 | p: 74.107 | r: 76.960
rougeLsum  | fm: 75.183 | p: 73.931 | r: 76.778
r1fm+r2fm = 135.484

input #18 time: 0:10:52 | total time: 3:28:39


Running input #19 of 100.
reference: 
========================
to infamy 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.807038426399231 for ['[CLS] orderiticness miles [SEP]']
[Init] best rec loss: 0.7207189798355103 for ['[CLS] of largelyworld local [SEP]']
[Init] best rec loss: 0.720632016658783 for ['[CLS] ware set institute wave [SEP]']
[Init] best rec loss: 0.688045859336853 for ['[CLS] 3my rawonzo [SEP]']
[Init] best rec loss: 0.6825821399688721 for ['[CLS] tributary list tolerated agreed [SEP]']
[Init] best rec loss: 0.6786865592002869 for ['[CLS] mall troll whilequin [SEP]']
[Init] best rec loss: 0.6730250120162964 for ['[CLS] black visa chinoria [SEP]']
[Init] best perm rec loss: 0.67041015625 for ['[CLS] blackoria chin visa [SEP]']
[Init] best perm rec loss: 0.6696658134460449 for ['[CLS]oria visa black chin [SEP]']
[Init] best perm rec loss: 0.669550895690918 for ['[CLS] visa chin blackoria [SEP]']
[Init] best perm rec loss: 0.6693949103355408 for ['[CLS] chin visa blackoria [SEP]']
[Init] best perm rec loss: 0.6679750084877014 for ['[CLS]oria black visa chin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.442 (perp=6.110, rec=0.220), tot_loss_proj:1.301 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 100/2000] tot_loss=1.308 (perp=6.110, rec=0.086), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 150/2000] tot_loss=1.287 (perp=6.110, rec=0.065), tot_loss_proj:1.297 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 200/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.297 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.288 (perp=6.110, rec=0.066), tot_loss_proj:1.294 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.301 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.283 (perp=6.110, rec=0.061), tot_loss_proj:1.295 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.281 (perp=6.110, rec=0.059), tot_loss_proj:1.295 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.278 (perp=6.110, rec=0.056), tot_loss_proj:1.284 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.282 (perp=6.110, rec=0.060), tot_loss_proj:1.292 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.277 (perp=6.110, rec=0.055), tot_loss_proj:1.291 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.290 (perp=6.110, rec=0.068), tot_loss_proj:1.299 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.295 (perp=6.110, rec=0.074), tot_loss_proj:1.299 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.285 (perp=6.110, rec=0.063), tot_loss_proj:1.290 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.276 (perp=6.110, rec=0.055), tot_loss_proj:1.289 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.276 (perp=6.110, rec=0.054), tot_loss_proj:1.283 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.291 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.291 (perp=6.110, rec=0.069), tot_loss_proj:1.290 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.278 (perp=6.110, rec=0.056), tot_loss_proj:1.286 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.278 (perp=6.110, rec=0.056), tot_loss_proj:1.290 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.287 (perp=6.110, rec=0.065), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.289 (perp=6.110, rec=0.067), tot_loss_proj:1.295 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.290 (perp=6.110, rec=0.068), tot_loss_proj:1.291 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.267 (perp=6.110, rec=0.045), tot_loss_proj:1.289 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.292 (perp=6.110, rec=0.070), tot_loss_proj:1.290 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.272 (perp=6.110, rec=0.050), tot_loss_proj:1.292 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.279 (perp=6.110, rec=0.057), tot_loss_proj:1.289 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.292 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.286 (perp=6.110, rec=0.064), tot_loss_proj:1.293 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.295 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.282 (perp=6.110, rec=0.060), tot_loss_proj:1.295 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.299 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.285 (perp=6.110, rec=0.063), tot_loss_proj:1.296 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.277 (perp=6.110, rec=0.055), tot_loss_proj:1.287 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.294 (perp=6.110, rec=0.072), tot_loss_proj:1.283 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.285 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.286 (perp=6.110, rec=0.064), tot_loss_proj:1.287 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.283 (perp=6.110, rec=0.062), tot_loss_proj:1.296 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.283 (perp=6.110, rec=0.061), tot_loss_proj:1.286 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.210 | p: 87.543 | r: 91.083
rouge2     | fm: 50.100 | p: 49.683 | r: 50.475
rougeL     | fm: 76.948 | p: 75.646 | r: 78.282
rougeLsum  | fm: 76.530 | p: 75.373 | r: 77.962
r1fm+r2fm = 139.310

input #19 time: 0:10:16 | total time: 3:38:56


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8582010269165039 for ['[CLS] everything project asking series [SEP]']
[Init] best rec loss: 0.853765070438385 for ['[CLS] audio camelsai us [SEP]']
[Init] best rec loss: 0.8229296803474426 for ['[CLS] would alwaysear still [SEP]']
[Init] best rec loss: 0.8163572549819946 for ['[CLS] ferguson finest happen debut [SEP]']
[Init] best rec loss: 0.8131038546562195 for ['[CLS]ented united practice lot [SEP]']
[Init] best rec loss: 0.8118852972984314 for ['[CLS] mass knowledge place engineers [SEP]']
[Init] best rec loss: 0.7901409268379211 for ['[CLS] gigs wings downloadable mates [SEP]']
[Init] best rec loss: 0.7841933369636536 for ['[CLS] where ip given next [SEP]']
[Init] best rec loss: 0.7751104831695557 for ['[CLS] grabbed exclusion values clean [SEP]']
[Init] best perm rec loss: 0.7719349265098572 for ['[CLS] exclusion values clean grabbed [SEP]']
[Init] best perm rec loss: 0.7718527317047119 for ['[CLS] exclusion values grabbed clean [SEP]']
[Init] best perm rec loss: 0.7676885724067688 for ['[CLS] values exclusion clean grabbed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.350 (perp=10.685, rec=0.213), tot_loss_proj:2.745 [t=0.20s]
prediction: ['[CLS] pleasure pleasureverseverse [SEP]']
[ 100/2000] tot_loss=1.603 (perp=7.535, rec=0.096), tot_loss_proj:1.919 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 150/2000] tot_loss=1.575 (perp=7.535, rec=0.068), tot_loss_proj:1.908 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 200/2000] tot_loss=1.571 (perp=7.535, rec=0.064), tot_loss_proj:1.911 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.562 (perp=7.535, rec=0.055), tot_loss_proj:1.903 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 300/2000] tot_loss=1.568 (perp=7.535, rec=0.061), tot_loss_proj:1.907 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.902 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.571 (perp=7.535, rec=0.064), tot_loss_proj:1.902 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 450/2000] tot_loss=1.580 (perp=7.535, rec=0.073), tot_loss_proj:1.916 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.575 (perp=7.535, rec=0.068), tot_loss_proj:1.901 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.569 (perp=7.535, rec=0.062), tot_loss_proj:1.910 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 600/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.909 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.579 (perp=7.535, rec=0.072), tot_loss_proj:1.919 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.565 (perp=7.535, rec=0.058), tot_loss_proj:1.911 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 750/2000] tot_loss=1.569 (perp=7.535, rec=0.062), tot_loss_proj:1.905 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.914 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.571 (perp=7.535, rec=0.064), tot_loss_proj:1.902 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 900/2000] tot_loss=1.566 (perp=7.535, rec=0.059), tot_loss_proj:1.914 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.569 (perp=7.535, rec=0.062), tot_loss_proj:1.906 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.552 (perp=7.535, rec=0.045), tot_loss_proj:1.897 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1050/2000] tot_loss=1.562 (perp=7.535, rec=0.055), tot_loss_proj:1.899 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.577 (perp=7.535, rec=0.070), tot_loss_proj:1.908 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.579 (perp=7.535, rec=0.072), tot_loss_proj:1.910 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1200/2000] tot_loss=1.567 (perp=7.535, rec=0.060), tot_loss_proj:1.912 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.917 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.535, rec=0.075), tot_loss_proj:1.908 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1350/2000] tot_loss=1.584 (perp=7.535, rec=0.077), tot_loss_proj:1.906 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=7.535, rec=0.064), tot_loss_proj:1.902 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.573 (perp=7.535, rec=0.066), tot_loss_proj:1.907 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1500/2000] tot_loss=1.569 (perp=7.535, rec=0.062), tot_loss_proj:1.914 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.561 (perp=7.535, rec=0.054), tot_loss_proj:1.917 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.564 (perp=7.535, rec=0.057), tot_loss_proj:1.898 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1650/2000] tot_loss=1.574 (perp=7.535, rec=0.067), tot_loss_proj:1.901 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.577 (perp=7.535, rec=0.070), tot_loss_proj:1.916 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.574 (perp=7.535, rec=0.067), tot_loss_proj:1.912 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1800/2000] tot_loss=1.574 (perp=7.535, rec=0.067), tot_loss_proj:1.908 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.566 (perp=7.535, rec=0.059), tot_loss_proj:1.920 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.569 (perp=7.535, rec=0.062), tot_loss_proj:1.905 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1950/2000] tot_loss=1.583 (perp=7.535, rec=0.076), tot_loss_proj:1.908 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.914 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] pleasure the perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 89.730 | p: 88.233 | r: 91.451
rouge2     | fm: 49.179 | p: 48.841 | r: 49.532
rougeL     | fm: 76.955 | p: 75.813 | r: 78.415
rougeLsum  | fm: 76.828 | p: 75.752 | r: 78.061
r1fm+r2fm = 138.909

input #20 time: 0:07:59 | total time: 3:46:55


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8671992421150208 for ['[CLS] method view experience tempo lettertain republic vitamin went " zone renewed subjects jar daniel output perched potential great reading... chief shi chair maneuver [SEP]']
[Init] best rec loss: 0.8592739105224609 for ['[CLS] october [SEP]lord julian outstanding sat beat energy raionpost guinea hypothesis prayed pas raising tide hunger ari do camp connections keeping when dry how [SEP]']
[Init] best rec loss: 0.8139981031417847 for ['[CLS] path helloroving length expect carr answered roll ) critics species scoresental mix fit dominion any note blue troubled stockiya ways flu acts [SEP]']
[Init] best rec loss: 0.807166337966919 for ['[CLS] trump magnitude shook using lgbt relative mask final bombing valve businessdable than tonight gil straight rn book true neptune rich beachland tributary bed [SEP]']
[Init] best rec loss: 0.806107759475708 for ['[CLS] regularaneous lies party berry eliminated call town states diesjean miazio escaped por myself tesla supermanments sal evidence livery rising army flopped [SEP]']
[Init] best rec loss: 0.8028335571289062 for ['[CLS] aboard vertical it wearing outdoorki don touchdown through realize sussex bart tu tunnel valkyrie right lower come strip district instructionse kanevialover [SEP]']
[Init] best rec loss: 0.7996188998222351 for ['[CLS] uk finally prettylaus coach joint bobby whitney radio pistol color placetral favor character dragon oldest smart procedureprint protected mind breasts length hour [SEP]']
[Init] best rec loss: 0.790934145450592 for ['[CLS] theatre fraser famous ་ trunk clan jackson mile pp never suppression fossils brittanyborn resume russian grant residentifies statusested dump ceremony metal yard [SEP]']
[Init] best rec loss: 0.7843645811080933 for ['[CLS] richard * mentioned median ranch gross some beast og cabinger texts get pentagon boarding page dating― orientation incident martial bank bedroom evenser [SEP]']
[Init] best rec loss: 0.770148515701294 for ['[CLS] representation cobbmptudy dragon temples it keen instead let complained zeke dragged jordan bourne books sex um s coached whisky longer provider twin cu [SEP]']
[Init] best rec loss: 0.7678321599960327 for ['[CLS] do act similarzhou daleturns aircraftθ my bias wilderness dawnι heatherhosh bingo fillychin alive shoedlegizing hmm rey [SEP]']
[Init] best rec loss: 0.7651310563087463 for ['[CLS] brick veinslance ing began there restaurantrl banner phones barbeam reality smith print dong sunny trust inch awarded stick update empty bear circulated [SEP]']
[Init] best rec loss: 0.7618868350982666 for ['[CLS] monte find wa once lying qaeda kade nude reynolds drive ram might apple association motorcycle [SEP]h interesting stopistle great principle ultra accused prof [SEP]']
[Init] best perm rec loss: 0.7594305276870728 for ['[CLS] nude reynolds kade ultra wa qaeda find prof motorcycle interesting association monte greatistle lying accused stop mighth [SEP] once principle ram drive apple [SEP]']
[Init] best perm rec loss: 0.7573457956314087 for ['[CLS] qaedah prof principleistle wa ultra [SEP] great might monte reynolds kade find drive interesting apple nude association stop accused ram once lying motorcycle [SEP]']
[Init] best perm rec loss: 0.7562182545661926 for ['[CLS] apple might lying find prof reynolds stop wa interestingh ultraistle drive nude [SEP] accused association ram monte kade principle motorcycle qaeda great once [SEP]']
[Init] best perm rec loss: 0.7554150819778442 for ['[CLS] prof drive apple accusedh might principle wa stop lying ram [SEP] monte interesting find nudeistle reynolds qaeda motorcycle ultra kade association great once [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.822 (perp=12.121, rec=0.398), tot_loss_proj:3.079 [t=0.21s]
prediction: ['[CLS] bringing for lesstypical bishops all female involved equivalent lies redesigned fraud because pattern alcohol federal leavees if algebra apparently think alps allegedly presided [SEP]']
[ 100/2000] tot_loss=2.626 (perp=11.624, rec=0.301), tot_loss_proj:3.014 [t=0.21s]
prediction: ['[CLS] brought from less orphans athletes more serious athletes equivalent seemed instead advertising because pattern unrest the women update if avenue internet violent athletes apparently teachers [SEP]']
[ 150/2000] tot_loss=2.450 (perp=10.995, rec=0.251), tot_loss_proj:2.915 [t=0.21s]
prediction: ['[CLS] brought for less financially athletes more serious athletes equivalent looked instead ad makes way talk the women teacher if work primetime serious athletes how works [SEP]']
[ 200/2000] tot_loss=2.161 (perp=9.865, rec=0.188), tot_loss_proj:2.806 [t=0.21s]
prediction: ['[CLS] way for the way athletes more serious athletes equivalent looked insteadtypical makes way. the women teacher as work girls serious athletes way works [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.029 (perp=9.298, rec=0.169), tot_loss_proj:2.752 [t=0.21s]
prediction: ['[CLS] as for thetypical athletes of serious athletes equivalent looked insteadtypical makes way. the women teacher all completely women serious athletes way works [SEP]']
[ 300/2000] tot_loss=1.891 (perp=8.689, rec=0.153), tot_loss_proj:2.550 [t=0.21s]
prediction: ['[CLS] as for thetypical athletes of serious athletes. look insteadtypical makes way. the women teacher all completely women both athletes way works [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.013 (perp=9.367, rec=0.139), tot_loss_proj:2.658 [t=0.21s]
prediction: ['[CLS] as for the out teachers like serious athletes. look instead caretaker makes of. this womentypical all all women both athletes way works [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.027 (perp=9.447, rec=0.138), tot_loss_proj:2.644 [t=0.21s]
prediction: ['[CLS] as for the out teachers like all athletes. look instead caretaker makes how. this womentypical all serious women bothguide way works [SEP]']
[ 450/2000] tot_loss=1.894 (perp=8.897, rec=0.114), tot_loss_proj:2.479 [t=0.21s]
prediction: ['[CLS] as for the out teachers like all athletes. look instead caretaker makes of. this womentypical all serious women outguide way works [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.914 (perp=9.007, rec=0.112), tot_loss_proj:2.683 [t=0.21s]
prediction: ['[CLS] as for the out teachers like all athletes. look. instead caretaker makesally this oftypical all serious women. makes way works [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.879 (perp=8.864, rec=0.106), tot_loss_proj:2.456 [t=0.21s]
prediction: ['[CLS] the for the out teachers like all athletes. look. caretaker makesally this instead oftypical more serious women of makes way works [SEP]']
[ 600/2000] tot_loss=1.923 (perp=9.150, rec=0.093), tot_loss_proj:2.543 [t=0.21s]
prediction: ['[CLS] the for the out teachers like all athletes. look the caretaker makesally this instead andtypical more serious women of makes way works [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.733 (perp=8.206, rec=0.091), tot_loss_proj:2.344 [t=0.21s]
prediction: ['[CLS] the more the out teachers like all athletes. look the caretaker makesally makes instead andtypical more serious women of this way works [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.680 (perp=7.888, rec=0.103), tot_loss_proj:2.227 [t=0.21s]
prediction: ['[CLS] the more the out teachers like all athletes works look the caretaker makesally makes instead andtypical more serious women of this way. [SEP]']
[ 750/2000] tot_loss=1.677 (perp=7.968, rec=0.083), tot_loss_proj:2.237 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makesally makes instead andtypical more serious women of this way. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.647 (perp=7.845, rec=0.078), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makesally makes and insteadtypical more serious women of this way. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.609 (perp=7.649, rec=0.079), tot_loss_proj:2.177 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makesally makes and instead of more serious womentypical this way. [SEP]']
[ 900/2000] tot_loss=1.620 (perp=7.649, rec=0.090), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makesally makes and instead of more serious womentypical this way. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.578 (perp=7.480, rec=0.082), tot_loss_proj:2.105 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makes and of makes instead of more serious womentypical this way. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.541 (perp=7.319, rec=0.077), tot_loss_proj:2.062 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makes and oftypical instead of more serious women makes this way. [SEP]']
[1050/2000] tot_loss=1.580 (perp=7.516, rec=0.077), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretaker makes and oftypical instead, more serious women makes this way. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.601 (perp=7.614, rec=0.078), tot_loss_proj:2.199 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes works look the caretakerallytypical makes and instead, more serious women makes this way. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.536 (perp=7.273, rec=0.081), tot_loss_proj:2.142 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes makes look the caretakerallytypical makes and instead, more serious women works this way. [SEP]']
[1200/2000] tot_loss=1.573 (perp=7.502, rec=0.073), tot_loss_proj:2.198 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes athletes look the caretakerallytypical makes and instead, more serious women works this way. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.466 (perp=6.990, rec=0.068), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes makes look the caretakerallytypical athletes and instead, more serious women works this way. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.471 (perp=6.990, rec=0.073), tot_loss_proj:2.118 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes makes look the caretakerallytypical athletes and instead, more serious women works this way. [SEP]']
[1350/2000] tot_loss=1.468 (perp=6.990, rec=0.070), tot_loss_proj:2.107 [t=0.21s]
prediction: ['[CLS] the more of out teachers like all athletes makes look the caretakerallytypical athletes and instead, more serious women works this way. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.601 (perp=7.574, rec=0.086), tot_loss_proj:2.218 [t=0.21s]
prediction: ['[CLS] the more out teachers like all athletes makes look the caretaker ofallytypical stereo and instead, more serious women works this way. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.550 (perp=7.387, rec=0.073), tot_loss_proj:2.160 [t=0.21s]
prediction: ['[CLS] theally out teachers like all athletes makes look the caretaker of moretypical stereo and instead, more serious women works this way. [SEP]']
[1500/2000] tot_loss=1.625 (perp=7.739, rec=0.077), tot_loss_proj:2.221 [t=0.21s]
prediction: ['[CLS] theally out teachers like all athletes makes look the caretaker of oftypical stereo and instead, more serious women works this way. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.559 (perp=7.446, rec=0.070), tot_loss_proj:2.277 [t=0.21s]
prediction: ['[CLS] theally out teachers like all athletes makes look the caretaker instead oftypical stereo and of, more serious women works this way. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.427 (perp=6.776, rec=0.072), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] the of out teachers like all athletes makes look the caretaker instead of stereotypical and of, more serious women works this way. [SEP]']
[1650/2000] tot_loss=1.422 (perp=6.776, rec=0.067), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] the of out teachers like all athletes makes look the caretaker instead of stereotypical and of, more serious women works this way. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.461 (perp=6.955, rec=0.070), tot_loss_proj:2.138 [t=0.21s]
prediction: ['[CLS] the of the teachers like all athletes makes look out caretaker instead for stereotypical and of, more serious women works this way. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.383 (perp=6.548, rec=0.073), tot_loss_proj:2.143 [t=0.21s]
prediction: ['[CLS] the of the teachers like all athletes makes look out caretaker instead of more stereotypical and, more serious women works this way. [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.548, rec=0.074), tot_loss_proj:2.138 [t=0.21s]
prediction: ['[CLS] the of the teachers like all athletes makes look out caretaker instead of more stereotypical and, more serious women works this way. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.440 (perp=6.836, rec=0.073), tot_loss_proj:2.226 [t=0.21s]
prediction: ['[CLS] the of of the teachers like all athletes makes look out caretaker instead of stereotypical and, more serious women works this way. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.339 (perp=6.331, rec=0.073), tot_loss_proj:2.107 [t=0.21s]
prediction: ['[CLS] the caretaker of of the teachers like all athletes makes look out instead of stereotypical and, more serious women works this way. [SEP]']
[1950/2000] tot_loss=1.344 (perp=6.331, rec=0.078), tot_loss_proj:2.105 [t=0.21s]
prediction: ['[CLS] the caretaker of of the teachers like all athletes makes look out instead of stereotypical and, more serious women works this way. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.289 (perp=6.075, rec=0.074), tot_loss_proj:2.109 [t=0.21s]
prediction: ['[CLS] the caretaker like of the teachers of all athletes makes look out instead of stereotypical and, more serious women works this way. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the of out teachers like all athletes makes look the caretaker instead of stereotypical and of, more serious women works this way. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.362 | p: 87.500 | r: 91.304
rouge2     | fm: 8.889 | p: 8.696 | r: 9.091
rougeL     | fm: 42.553 | p: 41.667 | r: 43.478
rougeLsum  | fm: 42.553 | p: 41.667 | r: 43.478
r1fm+r2fm = 98.251

[Aggregate metrics]:
rouge1     | fm: 89.651 | p: 88.169 | r: 91.347
rouge2     | fm: 47.065 | p: 46.630 | r: 47.508
rougeL     | fm: 75.283 | p: 74.238 | r: 76.572
rougeLsum  | fm: 75.218 | p: 74.230 | r: 76.563
r1fm+r2fm = 136.716

input #21 time: 0:08:12 | total time: 3:55:07


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9642519354820251 for ['[CLS] 1bocene genus serves here home nativellation eve conditioned diver [SEP]']
[Init] best rec loss: 0.9526574611663818 for ['[CLS] ea warner higher algebra jack on soap spacelink god industrial [SEP]']
[Init] best rec loss: 0.9506364464759827 for ['[CLS] together na connects perfectly conversation ain educating twicerigues đ bio [SEP]']
[Init] best rec loss: 0.9486136436462402 for ['[CLS] publishing dread stubble wave existed elimination just jagger another vacancy greenhouse [SEP]']
[Init] best rec loss: 0.9399086833000183 for ['[CLS]upt microsoft hero damage catsered stoneford single stream transportation [SEP]']
[Init] best rec loss: 0.9376692175865173 for ['[CLS] dover organization photographsberry humboldt usually revealed ins such sword laboratory [SEP]']
[Init] best rec loss: 0.9301173686981201 for ['[CLS] figure exploded earlier installation characteristic charge mountain asset annualbilities cause [SEP]']
[Init] best rec loss: 0.9289546608924866 for ['[CLS]quil framework commander strategic ringing presented cheek mouse ira related record [SEP]']
[Init] best rec loss: 0.9185957312583923 for ['[CLS] and store citation armed split nearby kamen prime prime moment ᶜ [SEP]']
[Init] best perm rec loss: 0.9182102680206299 for ['[CLS] store moment nearby ᶜ kamen armed and split citation prime prime [SEP]']
[Init] best perm rec loss: 0.9167824983596802 for ['[CLS] kamen ᶜ split prime prime nearby moment citation store and armed [SEP]']
[Init] best perm rec loss: 0.915831446647644 for ['[CLS] citation ᶜ prime nearby and moment armed split kamen prime store [SEP]']
[Init] best perm rec loss: 0.9152170419692993 for ['[CLS] prime moment store split citation and armed prime nearby kamen ᶜ [SEP]']
[Init] best perm rec loss: 0.9130176901817322 for ['[CLS] and armed prime nearby store kamen moment split citation ᶜ prime [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.058 (perp=12.486, rec=0.561), tot_loss_proj:3.491 [t=0.20s]
prediction: ['[CLS] or enjoyablewide this comics highlights rated yeah 2016 kendra language [SEP]']
[ 100/2000] tot_loss=3.016 (perp=12.326, rec=0.550), tot_loss_proj:3.421 [t=0.20s]
prediction: ['[CLS] [SEP] adaptationwide their identical seem the yeah academy kendra clothes [SEP]']
[ 150/2000] tot_loss=2.853 (perp=11.482, rec=0.557), tot_loss_proj:3.214 [t=0.20s]
prediction: ['[CLS] of adaptation waited adaptation identical seem a easier ) interpreted & [SEP]']
[ 200/2000] tot_loss=2.849 (perp=11.941, rec=0.461), tot_loss_proj:3.312 [t=0.20s]
prediction: ['[CLS] of adaptation waited adaptation memories amounted a clients championship interpreted own [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.616 (perp=10.879, rec=0.440), tot_loss_proj:3.113 [t=0.20s]
prediction: ['[CLS] of adaptation a adaptation memories truly waited clients ) interpreted divinity [SEP]']
[ 300/2000] tot_loss=2.829 (perp=12.103, rec=0.409), tot_loss_proj:3.377 [t=0.20s]
prediction: ['[CLS] to adaptation a adaptation enjoyable breath waited clients ) interpreted divinity [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.614 (perp=11.052, rec=0.403), tot_loss_proj:3.195 [t=0.20s]
prediction: ['[CLS] adaptation to a adaptation enjoyable wow waited clients ) interpreted divinity [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.050 (perp=12.757, rec=0.499), tot_loss_proj:3.505 [t=0.21s]
prediction: ['[CLS] adaptation their ) adaptation enjoyable everything waited clients a interpreted divinity [SEP]']
[ 450/2000] tot_loss=3.066 (perp=13.266, rec=0.413), tot_loss_proj:3.612 [t=0.20s]
prediction: ['[CLS] adaptation subsequent ) adaptation enjoyable everything waited abilities a interpreted divinity [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.715 (perp=11.548, rec=0.405), tot_loss_proj:3.292 [t=0.20s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable everything waited clients interpreted a clary [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.652 (perp=11.332, rec=0.385), tot_loss_proj:3.290 [t=0.20s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable everything clients waited interpreted a clary [SEP]']
[ 600/2000] tot_loss=2.647 (perp=11.332, rec=0.381), tot_loss_proj:3.288 [t=0.20s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable everything clients waited interpreted a clary [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.677 (perp=11.492, rec=0.378), tot_loss_proj:3.288 [t=0.20s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable redesignated clients waited interpreted a clary [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.574 (perp=11.074, rec=0.360), tot_loss_proj:3.167 [t=0.26s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable oneself clients waited adaptation a clary [SEP]']
[ 750/2000] tot_loss=2.651 (perp=11.500, rec=0.350), tot_loss_proj:3.284 [t=0.26s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable þ clients waited adaptation a clary [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.806 (perp=12.225, rec=0.361), tot_loss_proj:3.445 [t=0.27s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable oneself interpreted clients waitingbians clary [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.533 (perp=10.945, rec=0.344), tot_loss_proj:3.181 [t=0.26s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable oneself interpreted waiting clients a clary [SEP]']
[ 900/2000] tot_loss=2.540 (perp=10.945, rec=0.351), tot_loss_proj:3.182 [t=0.27s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable oneself interpreted waiting clients a clary [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.428 (perp=10.353, rec=0.357), tot_loss_proj:3.079 [t=0.25s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable oneself adaptation waiting clients a clary [SEP]']
Attempt swap
[1000/2000] tot_loss=2.507 (perp=10.826, rec=0.342), tot_loss_proj:3.220 [t=0.25s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable þ adaptation waitingdev a clary [SEP]']
[1050/2000] tot_loss=2.500 (perp=10.826, rec=0.334), tot_loss_proj:3.216 [t=0.25s]
prediction: ['[CLS] adaptation a ) adaptation enjoyable þ adaptation waitingdev a clary [SEP]']
Attempt swap
[1100/2000] tot_loss=2.539 (perp=10.971, rec=0.344), tot_loss_proj:3.216 [t=0.27s]
prediction: ['[CLS] adaptation a ( adaptation enjoyable þ adaptation waitingdev a clary [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.505 (perp=10.795, rec=0.346), tot_loss_proj:3.163 [t=0.26s]
prediction: ['[CLS] adaptation a ( adaptation enjoyable þ adaptation waitingdev clary a [SEP]']
[1200/2000] tot_loss=2.554 (perp=11.085, rec=0.337), tot_loss_proj:3.218 [t=0.28s]
prediction: ['[CLS] adaptation a ( adaptation enjoyableciation adaptation waitingdev clary a [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.467 (perp=10.629, rec=0.342), tot_loss_proj:3.170 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptation þ adaptation waitingdev clary a [SEP]']
Attempt swap
[1300/2000] tot_loss=2.510 (perp=10.863, rec=0.337), tot_loss_proj:3.221 [t=0.27s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationht adaptation waitingdev clary a [SEP]']
[1350/2000] tot_loss=2.463 (perp=10.594, rec=0.344), tot_loss_proj:3.160 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation waitingdev clary a [SEP]']
Attempt swap
[1400/2000] tot_loss=2.457 (perp=10.594, rec=0.339), tot_loss_proj:3.160 [t=0.27s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation waitingdev clary a [SEP]']
Attempt swap
[1450/2000] tot_loss=2.423 (perp=10.445, rec=0.334), tot_loss_proj:3.143 [t=0.25s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
[1500/2000] tot_loss=2.419 (perp=10.445, rec=0.330), tot_loss_proj:3.137 [t=0.27s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
Attempt swap
[1550/2000] tot_loss=2.422 (perp=10.445, rec=0.333), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
Attempt swap
[1600/2000] tot_loss=2.418 (perp=10.445, rec=0.329), tot_loss_proj:3.140 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
[1650/2000] tot_loss=2.416 (perp=10.445, rec=0.327), tot_loss_proj:3.139 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
Attempt swap
[1700/2000] tot_loss=2.425 (perp=10.445, rec=0.336), tot_loss_proj:3.138 [t=0.25s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
Attempt swap
[1750/2000] tot_loss=2.410 (perp=10.445, rec=0.321), tot_loss_proj:3.142 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes clary a [SEP]']
[1800/2000] tot_loss=2.267 (perp=9.681, rec=0.331), tot_loss_proj:2.987 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes right a [SEP]']
Attempt swap
[1850/2000] tot_loss=2.274 (perp=9.681, rec=0.338), tot_loss_proj:2.987 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes right a [SEP]']
Attempt swap
[1900/2000] tot_loss=2.266 (perp=9.681, rec=0.330), tot_loss_proj:2.985 [t=0.26s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes right a [SEP]']
[1950/2000] tot_loss=2.262 (perp=9.681, rec=0.326), tot_loss_proj:2.986 [t=0.28s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes right a [SEP]']
Attempt swap
[2000/2000] tot_loss=2.262 (perp=9.681, rec=0.326), tot_loss_proj:2.988 [t=0.25s]
prediction: ['[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes right a [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] adaptation a ( enjoyable adaptationciation adaptation delilah passes right a [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 54.545 | r: 46.154
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 41.667 | p: 45.455 | r: 38.462
rougeLsum  | fm: 41.667 | p: 45.455 | r: 38.462
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 87.960 | p: 86.617 | r: 89.465
rouge2     | fm: 45.019 | p: 44.713 | r: 45.342
rougeL     | fm: 73.784 | p: 72.871 | r: 75.000
rougeLsum  | fm: 73.712 | p: 72.765 | r: 74.837
r1fm+r2fm = 132.979

input #22 time: 0:09:53 | total time: 4:05:00


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7358076572418213 for ['[CLS] ordinary crouch untouched straight telling full cape gold come [CLS] tempted standings midnight dev beginning faerie attacker sarajevo buckle to harmonicstrel hard mist liza american that even feethl from gekushima crystal appearedout detectors later wolfgang season speakers industrial break gorge dominated kris nun angle [SEP]']
[Init] best rec loss: 0.7196099162101746 for ['[CLS] liege cluemasters mike seat black navigation cut statewideym magic sorts new full blue powers registration so colony blinded attack budsfu ngo playstation yours trim league parc bullh proportion smells offensive katherine chain before according quarterfinals raj suit about truck commentators € ties lin leo [SEP]']
[Init] best rec loss: 0.7099141478538513 for ['[CLS]ooped particularly part minor lucan beard feature¢ war super townom revenue chandler them held crossed mr actionproof schuster spade being recently terms sure maintains enough etymology aids rock northeasterndel sure j you cooper reeve bias television step wipedcturing apartheid brush moth encodedpu [SEP]']
[Init] best rec loss: 0.7015817165374756 for ['[CLS] nerve bomberiver retreat scored participating supporters moments kenya concept moments new bore coalition intellectual inner stefan all southeastern brief postbus sidepp beverly cn wait sniff aisle where viva something england aggression signal traffic regardksha squadron criminal likelylaw give bien lost banditszziness mask [SEP]']
[Init] best perm rec loss: 0.7007994055747986 for ['[CLS] retreat lost southeastern inner post bore criminal bien side viva squadron concept banditsksha moments regard aggression stefan kenya traffic wait new supporters beverlylaw coalition brief bomber wherezziness signal cn mask something giveiverpp intellectual nerve all moments sniffbus england likely scored participating aisle [SEP]']
[Init] best perm rec loss: 0.6997044682502747 for ['[CLS] criminalpp all give bandits aisle bore participating england southeasternbus where mask new post regard stefan moments bomber traffic aggression bien viva kenya beverly conceptksha signaliver coalitionlaw moments wait intellectual scored supporters lost retreat somethingzziness brief nerve cn side inner likely sniff squadron [SEP]']
[Init] best perm rec loss: 0.6996100544929504 for ['[CLS]iver coalition sniff likely cn england squadronlaw mask viva aggression participatingkshapp moments criminal bomber all traffic new scoredbus inner concept nerve something supporters bien aisle give wait stefanzziness beverly southeastern where bore retreat moments kenya brief bandits lost intellectual post side regard signal [SEP]']
[Init] best perm rec loss: 0.6988605260848999 for ['[CLS]law concept englandpp aisle postiver inner beverly signal viva all bore southeastern participating criminal likely aggressionbus bien traffic momentsksha retreat intellectual moments regard sniff scored bomber lost where brief squadron cn kenyazziness stefan new bandits nerve something supporters give wait mask coalition side [SEP]']
[Init] best perm rec loss: 0.698222279548645 for ['[CLS] bienksha moments inner viva intellectual something briefpp aggression criminalbus moments nerve england all wherelaw southeastern post mask retreat new stefan waitzzinessiver traffic cn regard sniff supporters coalition aisle bomber squadron lost bandits concept participating beverly likely give signal bore scored side kenya [SEP]']
[Init] best perm rec loss: 0.6967911124229431 for ['[CLS]bus intellectual england nerve bomber retreat lost somethinglaw post side regard bore participating all criminal sniffiver banditsksha viva beverly signal squadron moments coalition kenya southeasternpp stefanzziness concept likely moments supporters aggression bien scored mask brief traffic new inner cn where wait give aisle [SEP]']
[Init] best perm rec loss: 0.6963629722595215 for ['[CLS] stefan bomberpp sniff give beverlylaw coalition concept wait moments aggression post bieniver signal criminal southeastern retreat squadron inner supportersbus brief traffic mask bore viva participating all moments scored cn lost aisleksha regard intellectual kenya something englandzziness nerve new bandits side where likely [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.624 (perp=11.525, rec=0.319), tot_loss_proj:2.940 [t=0.26s]
prediction: ['[CLS] aboriginal objective ( battle,, principle becomes tallh ultimatelyh,hing focuses strategic headlines eventually filmed generation its meansh has truthra focused prevention objectivesgraphic purpose weeks jonathan : projects fictional :h ra political ) soldiers soldiers seven [SEP] degree conflict [SEP]']
[ 100/2000] tot_loss=2.436 (perp=10.885, rec=0.259), tot_loss_proj:2.812 [t=0.28s]
prediction: ['[CLS]ieving main main outer crazy -th or althoughh the ra rah reached objective main soldiers ultimately pius generation its rah. patriotic fundamental strategic prevention objective national objective : eugene those soldiers of! ra ra its its patriotic soldiers frame to degree 場 [SEP]']
[ 150/2000] tot_loss=2.255 (perp=10.290, rec=0.197), tot_loss_proj:2.723 [t=0.26s]
prediction: ['[CLS]ting main the slogan tone if label or whileh the ra -h achieve objective strategic soldiers ultimately drama generation its ra^ ; patrioticar strategic political objective national objective : shirley the soldiers ofh ra ra a thee soldiers soldier conflict the tone 場 [SEP]']
[ 200/2000] tot_loss=2.375 (perp=10.985, rec=0.178), tot_loss_proj:2.782 [t=0.25s]
prediction: ['[CLS]zing main the ⇒ tone look idea became whileh, ra -h achieve objective strategic soldiers ultimately drama generation its ra janeiro, patriotict strategic communications objective strategic objective : shirley the soldiers ofh ra ra idea to patriotic soldiers conflict [SEP] tone宀 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.301 (perp=10.680, rec=0.166), tot_loss_proj:2.778 [t=0.26s]
prediction: ['[CLS]ing main the scoffed tone without idea becameh, ra -h achieve while objective strategic soldiers ultimately drama generation its ra ள, dramat strategic strategic objective strategic objective : shirley the soldiers strategic vietnam ra ra idea to vietnam soldiers conflict [SEP] tone宀 [SEP]']
[ 300/2000] tot_loss=2.245 (perp=10.478, rec=0.150), tot_loss_proj:2.756 [t=0.27s]
prediction: ['[CLS]zing main the scoffed tone [SEP] idea became,, ra -h achieve while objective strategic soldiers ultimately drama generation its ra blah, dramas strategic strategic objective strategic objective : generation that soldiers strategic the ra a such the vietnam battle conflict the tone宀 [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.086 (perp=9.783, rec=0.129), tot_loss_proj:2.603 [t=0.28s]
prediction: ['[CLS] battle main the object tone without idea might,, ra -h achieve while objective strategic soldiers ultimately drama generation its ra blah, dramas strategic strategic objective strategic objective : generation that soldiers strategic the ra a such the vietnamzing conflict the tone ; [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.059 (perp=9.660, rec=0.127), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] battle main the objectti yet idea will,, ra -h achieve while objective drama generation its ra refers, dramas strategic soldiers ultimately strategic strategic objective strategic objective : generation that soldiers strategic the ra a such the vietnamzing conflict the tone ; [SEP]']
[ 450/2000] tot_loss=2.132 (perp=10.057, rec=0.121), tot_loss_proj:2.638 [t=0.27s]
prediction: ['[CLS] battle main the objectti with idea will,, ra -h achieve while components drama generation its tone©, dramas strategic patriotic ultimately strategic strategic objective strategic objective : generation that soldiers strategic the ra a such gr vietnamzing conflict the tone ; [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.170 (perp=10.257, rec=0.118), tot_loss_proj:2.662 [t=0.25s]
prediction: ['[CLS] battle main the objectti with idea will,, ra -h achieve while components drama generation its tone©, dramas strategic patriotic ultimately strategicic objective strategic objective : generation that soldiers strategic the ra such a my vietnamzing conflict the tones [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.024 (perp=9.460, rec=0.133), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] battle main the objectti with idea will strategic, ra -h achieve while objective drama generation its tone ־, dramas strategic patriotic ultimately strategicic objective strategic objective : generation that soldiers, the ra such a my vietnamzing conflict the tone宀 [SEP]']
[ 600/2000] tot_loss=2.038 (perp=9.605, rec=0.117), tot_loss_proj:2.543 [t=0.27s]
prediction: ['[CLS] battle main the objectti with idea will strategic, ra -h achieve while components drama generation its tone 阝, dramas strategic patriotic ultimately strategic strategic objective strategic objective : generation that soldiers, the ra such a cost vietnamzing conflict the tone） [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.993 (perp=9.406, rec=0.112), tot_loss_proj:2.516 [t=0.33s]
prediction: ['[CLS] conflict main the objectti with strategic will idea, ra -h achieve while objective drama generation its tone tone, dramas strategic patriotic ultimately strategic of objective strategic objective : generation that soldiers, the ra such a cost vietnamzing conflict the tone） [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.992 (perp=9.405, rec=0.111), tot_loss_proj:2.514 [t=0.29s]
prediction: ['[CLS] conflict main the objectti with strategic will idea, ra -h achieve while components drama generation its tone tone, dramas strategic patriotic ultimately strategic of objective strategic objective : generation that soldiers, the ra such a cost vietnamzing the conflict tone） [SEP]']
[ 750/2000] tot_loss=1.976 (perp=9.363, rec=0.104), tot_loss_proj:2.504 [t=0.30s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve while components drama generation its tone tone, dramas strategic patriotic ultimately strategic of objective strategic objective : generation that soldiers, the ra such a cost vietnamzing the conflict tone） [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.944 (perp=9.223, rec=0.100), tot_loss_proj:2.466 [t=0.29s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve while components drama generation its tone tone, patriotics strategic patriotic ultimately strategic objective of strategic objective : generation that soldiers, the ra such a cost vietnamzing the conflict picture） [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.953 (perp=9.234, rec=0.106), tot_loss_proj:2.449 [t=0.29s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve components while drama generation its tone tone, patriotics strategic patriotic ultimately strategic objective of strategic objective : define that soldiers, the ra such a cost vietnamzing the cost tones [SEP]']
[ 900/2000] tot_loss=1.951 (perp=9.236, rec=0.104), tot_loss_proj:2.451 [t=0.30s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone, patriotics strategic patriotic ultimately strategic objective of strategic objective : define that soldiers, the ra such a cost vietnamzing the cost tones [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.936 (perp=9.167, rec=0.103), tot_loss_proj:2.440 [t=0.30s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone, thes strategic patriotic ultimately strategic objective of strategic objective : define that soldiers, the ra such a cost vietnamzing patriotic cost tones [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.938 (perp=9.191, rec=0.100), tot_loss_proj:2.443 [t=0.31s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone, thes strategic ultimately patriotic strategic objective of strategic objective : define that soldiers, the ra such the cost vietnamzing patriotic cost tones [SEP]']
[1050/2000] tot_loss=1.935 (perp=9.191, rec=0.097), tot_loss_proj:2.441 [t=0.29s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone, thes strategic ultimately patriotic strategic objective of strategic objective : define that soldiers, the ra such the cost vietnamzing patriotic cost tones [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.921 (perp=9.101, rec=0.100), tot_loss_proj:2.424 [t=0.27s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone,s the strategic ultimately patriotic strategic objective of strategic objective : define that soldiers, the ra such the cost vietnamzing patriotic cost tones [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.892 (perp=8.966, rec=0.099), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone,s the strategic ultimately patriotic strategic objective of strategic objective : define the soldiers, that ra such the cost vietnamzing patriotic cost tones [SEP]']
[1200/2000] tot_loss=1.890 (perp=8.966, rec=0.097), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve ultimately while drama generation its tone tone,s the strategic ultimately patriotic strategic objective of strategic objective : define the soldiers, that ra such the cost vietnamzing patriotic cost tones [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.840 (perp=8.723, rec=0.096), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieves while drama generation its tone tone, ultimately the strategic ultimately patriotic strategic objective of strategic objective : define the soldiers, that ra such the cost vietnamzing patriotic cost tones [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.802 (perp=8.544, rec=0.093), tot_loss_proj:2.252 [t=0.26s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieves while drama generation its tone tone, ultimately the strategic ultimately patriotic strategic objective of strategic objective : define the soldiers, that razing the cost vietnam such patriotic cost tones [SEP]']
[1350/2000] tot_loss=1.837 (perp=8.701, rec=0.097), tot_loss_proj:2.272 [t=0.28s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, that razing the cost vietnam such patriotic cost tones [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.824 (perp=8.649, rec=0.095), tot_loss_proj:2.264 [t=0.26s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, patriotic razing the cost vietnam such that cost tones [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.798 (perp=8.500, rec=0.098), tot_loss_proj:2.255 [t=0.27s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic cost vietnam such that cost tones [SEP]']
[1500/2000] tot_loss=1.796 (perp=8.500, rec=0.096), tot_loss_proj:2.253 [t=0.26s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic cost vietnam such that cost tones [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.756 (perp=8.312, rec=0.094), tot_loss_proj:2.264 [t=0.27s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra -h achieve a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost costs [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.728 (perp=8.188, rec=0.091), tot_loss_proj:2.228 [t=0.26s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra achieveh - a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost costs [SEP]']
[1650/2000] tot_loss=1.735 (perp=8.188, rec=0.097), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS] conflict mains objectti with strategic will idea, ra achieveh - a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost costs [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.718 (perp=8.119, rec=0.094), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] cost mains objectti with strategic will idea, ra achieveh - a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.701 (perp=8.035, rec=0.094), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] cost mains strategicti with object will idea, ra achieveh - a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
[1800/2000] tot_loss=1.703 (perp=8.035, rec=0.096), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] cost mains strategicti with object will idea, ra achieveh - a while drama generation its tone tone, ultimately the achieve ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.697 (perp=8.012, rec=0.095), tot_loss_proj:2.142 [t=0.25s]
prediction: ['[CLS] cost mains strategicti with object will idea, ra achieveh - a while drama generation its tone tone, achieve ultimately the ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.683 (perp=7.940, rec=0.095), tot_loss_proj:2.147 [t=0.25s]
prediction: ['[CLS] cost mains strategic objectti with will idea, ra achieveh - a while drama generation its tone tone, achieve ultimately the ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
[1950/2000] tot_loss=1.681 (perp=7.940, rec=0.093), tot_loss_proj:2.147 [t=0.27s]
prediction: ['[CLS] cost mains strategic objectti with will idea, ra achieveh - a while drama generation its tone tone, achieve ultimately the ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
Attempt swap
[2000/2000] tot_loss=1.679 (perp=7.940, rec=0.091), tot_loss_proj:2.148 [t=0.29s]
prediction: ['[CLS] cost mains strategic objectti with will idea, ra achieveh - a while drama generation its tone tone, achieve ultimately the ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] cost mains strategic objectti with will idea, ra achieveh - a while drama generation its tone tone, achieve ultimately the ultimately patriotic strategic objective of strategic objective : define the soldiers, the razing patriotic tone vietnam such that cost conflicts [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 5.128 | p: 5.128 | r: 5.128
rougeL     | fm: 30.000 | p: 30.000 | r: 30.000
rougeLsum  | fm: 30.000 | p: 30.000 | r: 30.000
r1fm+r2fm = 65.128

[Aggregate metrics]:
rouge1     | fm: 86.675 | p: 85.331 | r: 88.241
rouge2     | fm: 43.272 | p: 42.933 | r: 43.587
rougeL     | fm: 72.210 | p: 71.259 | r: 73.287
rougeLsum  | fm: 71.648 | p: 70.723 | r: 72.769
r1fm+r2fm = 129.946

input #23 time: 0:11:22 | total time: 4:16:22


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8281634449958801 for ['[CLS] speedway order bleeding redhead closely single promote pot ion ashleymmer resu looking down ra marker plays fiction flushed [SEP]']
[Init] best rec loss: 0.7795165777206421 for ['[CLS] centeredcy 11 american circles subdivision lily doorbell entered mikeable criteriatar us close po majesty handed [SEP] eating [SEP]']
[Init] best rec loss: 0.7603569626808167 for ['[CLS] offs robert place dedicatedfo dotsbbe walk fight ro most inhibitor chance gore promises everybody throw impressed mind fog [SEP]']
[Init] best rec loss: 0.7351586818695068 for ['[CLS] attitude siditional guilt al kuala short establishing longer achilles al loverboat telephoneill ph declaration deaf spoil besides [SEP]']
[Init] best rec loss: 0.7279556393623352 for ['[CLS]pe popcorn mcbridepot pawn punch naked cha could charge risk slammed aliveelled marineng avengeguardoo kamen [SEP]']
[Init] best rec loss: 0.7249093651771545 for ['[CLS] pulitzer flushed st sony pakistan failuregrin sienna towards pretty noise mission ye gasping way guard here interstateonus arts [SEP]']
[Init] best rec loss: 0.7189546227455139 for ['[CLS] enemy leader men venueslly decisions availle greenish puppetcrat indication active lee wit four careful day hit hatch [SEP]']
[Init] best rec loss: 0.6886509656906128 for ['[CLS] pity [CLS] frozen towelgm grande trust clark. threat railodies game o ballot uneven life as limits dude [SEP]']
[Init] best perm rec loss: 0.6858805418014526 for ['[CLS] ballot clark game [CLS] oodies threat towel grande frozen. uneven as trust dude limits railgm life pity [SEP]']
[Init] best perm rec loss: 0.6846733689308167 for ['[CLS] uneven frozen. towel threat grande limits gameodies as trust pity clark dude life [CLS] railgm o ballot [SEP]']
[Init] best perm rec loss: 0.6843770742416382 for ['[CLS] threat rail grande trust o towel uneven pity gamegm frozen dude as clark. [CLS] life limits ballotodies [SEP]']
[Init] best perm rec loss: 0.6839900612831116 for ['[CLS] frozen towel game grande unevengm threat life pity. ballot dude clark trust o rail limits [CLS]odies as [SEP]']
[Init] best perm rec loss: 0.6833358407020569 for ['[CLS] towel. ballot uneven frozen [CLS] pity threat game as rail life trust ogm grandeodies dude clark limits [SEP]']
[Init] best perm rec loss: 0.6824970245361328 for ['[CLS] [CLS] frozen rail dude towelgm limits as uneven clark pityodies life threat game. ballot o trust grande [SEP]']
[Init] best perm rec loss: 0.6821768879890442 for ['[CLS] trust towel limits life as ballot. pitygm threatodies o dude game frozen grande rail [CLS] uneven clark [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.703 (perp=11.880, rec=0.327), tot_loss_proj:2.954 [t=0.26s]
prediction: ['[CLS] without evilties crime law global charges ending persons hitter evil eu state context un australian is evil historic terrorists [SEP]']
[ 100/2000] tot_loss=2.360 (perp=10.553, rec=0.249), tot_loss_proj:2.648 [t=0.26s]
prediction: ['[CLS] in evilness crime law climate ) lower context political evil did terrorists context ) australian are evil terrorists terrorists [SEP]']
[ 150/2000] tot_loss=2.036 (perp=9.139, rec=0.208), tot_loss_proj:2.308 [t=0.27s]
prediction: ['[CLS] taken outsideness political the climate took outside context of evil did terrorists context ) : more evil than terrorists [SEP]']
[ 200/2000] tot_loss=2.131 (perp=9.852, rec=0.160), tot_loss_proj:2.382 [t=0.26s]
prediction: ['[CLS] taken outside than political the climate taken outside context of evil elections terrorists context ( : more evil than terrorists [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.724 (perp=7.956, rec=0.133), tot_loss_proj:2.029 [t=0.26s]
prediction: ['[CLS] taken outside the political climate taken outside context of evil grew the terrorists context ( see more evil than ) [SEP]']
[ 300/2000] tot_loss=1.667 (perp=7.747, rec=0.118), tot_loss_proj:1.914 [t=0.25s]
prediction: ['[CLS] taken outside the political climate taken outside context of evil! the terrorists context ( see more evil than ) [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.733 (perp=7.987, rec=0.136), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] taken outside the political context current evil his the terrorists context ( see more evil than climate ) outside ) [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.663 (perp=7.676, rec=0.128), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever his current the terrorists context ( see more evil than climate ) outside ) [SEP]']
[ 450/2000] tot_loss=1.647 (perp=7.676, rec=0.112), tot_loss_proj:1.917 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever his current the terrorists context ( see more evil than climate ) outside ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.657 (perp=7.700, rec=0.117), tot_loss_proj:1.991 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever current his the terrorists of ( see more evil than climate ) outside ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.583 (perp=7.383, rec=0.106), tot_loss_proj:1.871 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever current his the terrorists ) ( see more evil than climate of outside ) [SEP]']
[ 600/2000] tot_loss=1.588 (perp=7.383, rec=0.111), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever current his the terrorists ) ( see more evil than climate of outside ) [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.610 (perp=7.527, rec=0.105), tot_loss_proj:1.888 [t=0.26s]
prediction: ['[CLS] taken outside the political context! current. the terrorists ever ( see more evil than climate of outside ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.512 (perp=7.017, rec=0.109), tot_loss_proj:1.800 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever current. the terrorists ever ( see more evil than climate of outside ) [SEP]']
[ 750/2000] tot_loss=1.530 (perp=6.849, rec=0.161), tot_loss_proj:1.717 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever current. the terrorists! ( see more evil than climate of outside ) [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.556 (perp=7.194, rec=0.117), tot_loss_proj:1.779 [t=0.25s]
prediction: ['[CLS] taken outside the political context ever current of! terrorists! ( see more evil than climate. outside ) [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.536 (perp=7.060, rec=0.124), tot_loss_proj:1.747 [t=0.28s]
prediction: ['[CLS] taken outside the political context ever current of! terrorists! ( see more evil than climate outside. ) [SEP]']
[ 900/2000] tot_loss=1.523 (perp=7.060, rec=0.111), tot_loss_proj:1.746 [t=0.29s]
prediction: ['[CLS] taken outside the political context ever current of! terrorists! ( see more evil than climate outside. ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.459 (perp=6.817, rec=0.095), tot_loss_proj:1.708 [t=0.28s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside. ) [SEP]']
Attempt swap
[1000/2000] tot_loss=1.466 (perp=6.817, rec=0.103), tot_loss_proj:1.706 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside. ) [SEP]']
[1050/2000] tot_loss=1.469 (perp=6.817, rec=0.106), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside. ) [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.455 (perp=6.789, rec=0.097), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
[1150/2000] tot_loss=1.458 (perp=6.789, rec=0.100), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
[1200/2000] tot_loss=1.458 (perp=6.789, rec=0.100), tot_loss_proj:1.709 [t=0.28s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
[1250/2000] tot_loss=1.457 (perp=6.789, rec=0.099), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
[1300/2000] tot_loss=1.456 (perp=6.789, rec=0.098), tot_loss_proj:1.700 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
[1350/2000] tot_loss=1.463 (perp=6.789, rec=0.106), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
[1400/2000] tot_loss=1.442 (perp=6.789, rec=0.084), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
[1450/2000] tot_loss=1.454 (perp=6.789, rec=0.096), tot_loss_proj:1.698 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
[1500/2000] tot_loss=1.445 (perp=6.789, rec=0.087), tot_loss_proj:1.709 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
[1550/2000] tot_loss=1.459 (perp=6.789, rec=0.102), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.358 (perp=6.276, rec=0.102), tot_loss_proj:1.607 [t=0.28s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
[1650/2000] tot_loss=1.356 (perp=6.276, rec=0.101), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
Attempt swap
[1700/2000] tot_loss=1.345 (perp=6.276, rec=0.090), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
Attempt swap
[1750/2000] tot_loss=1.352 (perp=6.276, rec=0.097), tot_loss_proj:1.598 [t=0.28s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
[1800/2000] tot_loss=1.347 (perp=6.276, rec=0.092), tot_loss_proj:1.600 [t=0.28s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
Attempt swap
[1850/2000] tot_loss=1.346 (perp=6.276, rec=0.091), tot_loss_proj:1.604 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
Attempt swap
[1900/2000] tot_loss=1.349 (perp=6.276, rec=0.094), tot_loss_proj:1.604 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
[1950/2000] tot_loss=1.354 (perp=6.276, rec=0.099), tot_loss_proj:1.596 [t=0.25s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
Attempt swap
[2000/2000] tot_loss=1.346 (perp=6.276, rec=0.091), tot_loss_proj:1.603 [t=0.26s]
prediction: ['[CLS] taken outside the political context ever! outside of current terrorists! ( see more evil than climate ). [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] taken outside the political context ever! of current terrorists! ( see more evil than climate outside ). [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.429 | p: 94.118 | r: 88.889
rouge2     | fm: 30.303 | p: 31.250 | r: 29.412
rougeL     | fm: 68.571 | p: 70.588 | r: 66.667
rougeLsum  | fm: 68.571 | p: 70.588 | r: 66.667
r1fm+r2fm = 121.732

[Aggregate metrics]:
rouge1     | fm: 86.965 | p: 85.849 | r: 88.482
rouge2     | fm: 42.710 | p: 42.479 | r: 43.026
rougeL     | fm: 72.139 | p: 71.269 | r: 73.240
rougeLsum  | fm: 71.609 | p: 70.910 | r: 72.625
r1fm+r2fm = 129.674

input #24 time: 0:11:00 | total time: 4:27:23


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9721649885177612 for ['[CLS] woods return america downloadable [SEP]']
[Init] best rec loss: 0.953952968120575 for ['[CLS] vice wings congress sad [SEP]']
[Init] best rec loss: 0.9521270394325256 for ['[CLS]uously xp gravitational km² [SEP]']
[Init] best rec loss: 0.950149416923523 for ['[CLS] fightingural vanished cows [SEP]']
[Init] best perm rec loss: 0.9496461153030396 for ['[CLS]ural fighting cows vanished [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.077 (perp=12.175, rec=0.642), tot_loss_proj:3.463 [t=0.26s]
prediction: ['[CLS]uid chariotfelt " [SEP]']
[ 100/2000] tot_loss=2.789 (perp=11.073, rec=0.574), tot_loss_proj:3.208 [t=0.26s]
prediction: ['[CLS] sculpture ridden strange film [SEP]']
[ 150/2000] tot_loss=2.631 (perp=10.470, rec=0.537), tot_loss_proj:3.129 [t=0.25s]
prediction: ['[CLS]uid strange strange film [SEP]']
[ 200/2000] tot_loss=3.185 (perp=12.925, rec=0.600), tot_loss_proj:3.580 [t=0.25s]
prediction: ['[CLS]uit lauderdale crude film [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.558 (perp=10.078, rec=0.542), tot_loss_proj:3.058 [t=0.27s]
prediction: ['[CLS] strange handsome film strange [SEP]']
[ 300/2000] tot_loss=2.333 (perp=9.193, rec=0.494), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] strange strange film strange [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.054 (perp=7.871, rec=0.479), tot_loss_proj:2.575 [t=0.27s]
prediction: ['[CLS] strange strange strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.033 (perp=7.871, rec=0.459), tot_loss_proj:2.577 [t=0.25s]
prediction: ['[CLS] strange strange strange film [SEP]']
[ 450/2000] tot_loss=2.028 (perp=7.871, rec=0.454), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] strange strange strange film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.031 (perp=7.871, rec=0.457), tot_loss_proj:2.572 [t=0.27s]
prediction: ['[CLS] strange strange strange film [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.551 (perp=9.009, rec=0.749), tot_loss_proj:2.779 [t=0.25s]
prediction: ['[CLS] before lecture horror film [SEP]']
[ 600/2000] tot_loss=2.343 (perp=8.361, rec=0.671), tot_loss_proj:2.668 [t=0.27s]
prediction: ['[CLS] before horror horror film [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=2.856 (perp=11.142, rec=0.627), tot_loss_proj:3.222 [t=0.27s]
prediction: ['[CLS] horror film waiting strange [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.437 (perp=9.149, rec=0.607), tot_loss_proj:2.847 [t=0.28s]
prediction: ['[CLS] horror film strange waiting [SEP]']
[ 750/2000] tot_loss=2.540 (perp=9.829, rec=0.574), tot_loss_proj:2.969 [t=0.29s]
prediction: ['[CLS] horror film strange template [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.341 (perp=8.903, rec=0.561), tot_loss_proj:2.769 [t=0.26s]
prediction: ['[CLS] strange pursuit film template [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.323 (perp=8.903, rec=0.542), tot_loss_proj:2.771 [t=0.25s]
prediction: ['[CLS] strange pursuit film template [SEP]']
[ 900/2000] tot_loss=2.410 (perp=9.396, rec=0.531), tot_loss_proj:2.890 [t=0.26s]
prediction: ['[CLS] strange strange film lands [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.260 (perp=8.705, rec=0.519), tot_loss_proj:2.796 [t=0.27s]
prediction: ['[CLS] strange strange lands film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.591 (perp=10.410, rec=0.509), tot_loss_proj:3.078 [t=0.28s]
prediction: ['[CLS] strange strange template film [SEP]']
[1050/2000] tot_loss=2.493 (perp=9.967, rec=0.499), tot_loss_proj:3.161 [t=0.27s]
prediction: ['[CLS] strange strange enjoyment film [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.430 (perp=9.647, rec=0.501), tot_loss_proj:3.064 [t=0.25s]
prediction: ['[CLS] strange strange film funny [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.198 (perp=8.475, rec=0.503), tot_loss_proj:2.844 [t=0.28s]
prediction: ['[CLS] strange strange funny film [SEP]']
[1200/2000] tot_loss=2.189 (perp=8.475, rec=0.494), tot_loss_proj:2.852 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.177 (perp=8.475, rec=0.482), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.181 (perp=8.475, rec=0.486), tot_loss_proj:2.851 [t=0.28s]
prediction: ['[CLS] strange strange funny film [SEP]']
[1350/2000] tot_loss=2.173 (perp=8.475, rec=0.478), tot_loss_proj:2.843 [t=0.29s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.169 (perp=8.475, rec=0.474), tot_loss_proj:2.847 [t=0.27s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.170 (perp=8.475, rec=0.475), tot_loss_proj:2.848 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
[1500/2000] tot_loss=2.176 (perp=8.475, rec=0.481), tot_loss_proj:2.844 [t=0.25s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.174 (perp=8.475, rec=0.479), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.165 (perp=8.475, rec=0.470), tot_loss_proj:2.836 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
[1650/2000] tot_loss=2.165 (perp=8.475, rec=0.470), tot_loss_proj:2.845 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.161 (perp=8.475, rec=0.466), tot_loss_proj:2.851 [t=0.28s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.162 (perp=8.475, rec=0.467), tot_loss_proj:2.850 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
[1800/2000] tot_loss=2.156 (perp=8.475, rec=0.461), tot_loss_proj:2.850 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.161 (perp=8.475, rec=0.466), tot_loss_proj:2.845 [t=0.25s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.165 (perp=8.475, rec=0.470), tot_loss_proj:2.845 [t=0.25s]
prediction: ['[CLS] strange strange funny film [SEP]']
[1950/2000] tot_loss=2.167 (perp=8.475, rec=0.472), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] strange strange funny film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.155 (perp=8.475, rec=0.460), tot_loss_proj:2.851 [t=0.26s]
prediction: ['[CLS] strange strange funny film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange strange strange film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 106.667

[Aggregate metrics]:
rouge1     | fm: 86.103 | p: 85.015 | r: 87.482
rouge2     | fm: 42.566 | p: 42.291 | r: 42.813
rougeL     | fm: 72.037 | p: 71.314 | r: 72.901
rougeLsum  | fm: 71.455 | p: 70.704 | r: 72.415
r1fm+r2fm = 128.670

input #25 time: 0:10:59 | total time: 4:38:23


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8797447085380554 for ['[CLS]ency minute trans reissued rise gangured respective horse wrestling contact austrianpine how maxwell irishplin flags prone species ancestry shin holdings [SEP]']
[Init] best rec loss: 0.8615555167198181 for ['[CLS]otide precious feet initials documentary make thanks sports hanlniling theory mission ₖ radio fight gareth to inn fbi cost ambassador stick [SEP]']
[Init] best rec loss: 0.8447133302688599 for ['[CLS] generation aid whilst water electric corn south okife piston leading resolveish atom indirect dying gunntto com prince career rain end [SEP]']
[Init] best rec loss: 0.8066055178642273 for ['[CLS] becker trying revolution specific interstate root europe beford wildlife manufacturing september ba more help ec [CLS] muscle £1 [xon upon spinning [SEP]']
[Init] best rec loss: 0.7945491075515747 for ['[CLS]ª richest rappersoman tin lay clearing twinned sculptor barely chair lynch johns exact left prof levelli gloom yep excuse grabbingactic [SEP]']
[Init] best perm rec loss: 0.7938089370727539 for ['[CLS] richest clearing grabbing prof sculptor gloomli left johns tin exact barelyª excuse chair rappers lynch layacticoman twinned level yep [SEP]']
[Init] best perm rec loss: 0.7930231094360352 for ['[CLS] lynch prof excuseoman twinned clearing rappers lay grabbing richest levelacticli exact chair gloom left sculptor yepª tin barely johns [SEP]']
[Init] best perm rec loss: 0.7918805480003357 for ['[CLS] prof rappers richest twinned yep grabbing lay chair gloomactic sculptor johns clearing level exact lynch excuse left tinli barelyomanª [SEP]']
[Init] best perm rec loss: 0.7917287945747375 for ['[CLS] lynch grabbing barely twinned exact gloom yep rappers excuse tin left johns layoman sculptor clearing chair richest levelacticªli prof [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.667 (perp=11.879, rec=0.291), tot_loss_proj:2.984 [t=0.26s]
prediction: ['[CLS] toward aboriginal parentaling fromecure pointless pointless excuse " bought bottle import writer pointless, french faye of extra legislature nose those [SEP]']
[ 100/2000] tot_loss=2.725 (perp=12.545, rec=0.216), tot_loss_proj:3.068 [t=0.26s]
prediction: ['[CLS] pointless european childhooding and mean pointless pointless goo import bought glasses import import pointless ) french faye ) extra meang french [SEP]']
[ 150/2000] tot_loss=2.289 (perp=10.581, rec=0.172), tot_loss_proj:2.947 [t=0.25s]
prediction: ['[CLS] nothing coming age import and mean pointless pointless import import imported - import import pointless ) french faye of daddy meander french [SEP]']
[ 200/2000] tot_loss=2.142 (perp=9.950, rec=0.152), tot_loss_proj:2.832 [t=0.26s]
prediction: ['[CLS] this coming age age and mean french pointlessing coming made - import import pointless ) writer faye from daddy meander french [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.160 (perp=9.746, rec=0.211), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] this coming import import withing french pointless and coming from - import import pointless ) writer sophie from daddy meander french [SEP]']
[ 300/2000] tot_loss=2.080 (perp=9.691, rec=0.142), tot_loss_proj:2.686 [t=0.25s]
prediction: ['[CLS] this coming age import -ing french pointless and coming originally - import importder ) writer sophie from legislation meander french [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.019 (perp=9.345, rec=0.150), tot_loss_proj:2.670 [t=0.25s]
prediction: ['[CLS] this coming age and -ing french pointless import coming made - import importder ) writer sophie from - meander french [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.059 (perp=9.542, rec=0.151), tot_loss_proj:2.715 [t=0.28s]
prediction: ['[CLS] this coming age and veing from pointless age coming put - age importder ) director sophie french - meander french [SEP]']
[ 450/2000] tot_loss=1.923 (perp=9.009, rec=0.122), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] this - age and -ing from pointless age coming - - age importder ) writer sophie french - meander coming [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.778 (perp=8.310, rec=0.116), tot_loss_proj:2.376 [t=0.26s]
prediction: ['[CLS] this - age and - french from pointless age coming - - age importder ) writer sophie french - meandering [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.777 (perp=8.344, rec=0.108), tot_loss_proj:2.430 [t=0.26s]
prediction: ['[CLS] this - age and age french from pointless age coming - - - importder ) writer sophie french - meanderder [SEP]']
[ 600/2000] tot_loss=1.775 (perp=8.344, rec=0.106), tot_loss_proj:2.430 [t=0.26s]
prediction: ['[CLS] this - age and age french from pointless age coming - - - importder ) writer sophie french - meanderder [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.738 (perp=8.194, rec=0.100), tot_loss_proj:2.396 [t=0.29s]
prediction: ['[CLS] this mean age and age french from pointless age coming - - - importder ) writer sophie french - -derder [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.686 (perp=7.941, rec=0.097), tot_loss_proj:2.360 [t=0.27s]
prediction: ['[CLS] this mean age and age french from pointless age coming - - - import ) writer sophie french -der -derder [SEP]']
[ 750/2000] tot_loss=1.684 (perp=7.941, rec=0.096), tot_loss_proj:2.357 [t=0.27s]
prediction: ['[CLS] this mean age and age french from pointless age coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.680 (perp=7.941, rec=0.092), tot_loss_proj:2.364 [t=0.26s]
prediction: ['[CLS] this mean age and age french from pointless age coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.685 (perp=7.941, rec=0.097), tot_loss_proj:2.364 [t=0.25s]
prediction: ['[CLS] this mean age and age french from pointless age coming - - - import ) writer sophie french -der -derder [SEP]']
[ 900/2000] tot_loss=1.686 (perp=7.941, rec=0.098), tot_loss_proj:2.360 [t=0.25s]
prediction: ['[CLS] this mean age and age french from pointless age coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.645 (perp=7.769, rec=0.091), tot_loss_proj:2.219 [t=0.29s]
prediction: ['[CLS] this mean age and age of from pointless french coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.584 (perp=7.465, rec=0.092), tot_loss_proj:2.170 [t=0.28s]
prediction: ['[CLS] this mean age of age and from pointless french coming - - - import ) writer sophie french -der -derder [SEP]']
[1050/2000] tot_loss=1.589 (perp=7.465, rec=0.096), tot_loss_proj:2.173 [t=0.27s]
prediction: ['[CLS] this mean age of age and from pointless french coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
[1100/2000] tot_loss=1.578 (perp=7.465, rec=0.085), tot_loss_proj:2.172 [t=0.26s]
prediction: ['[CLS] this mean age of age and from pointless french coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.580 (perp=7.465, rec=0.087), tot_loss_proj:2.179 [t=0.25s]
prediction: ['[CLS] this mean age of age and from pointless french coming - - - import ) writer sophie french -der -derder [SEP]']
[1200/2000] tot_loss=1.575 (perp=7.465, rec=0.082), tot_loss_proj:2.176 [t=0.26s]
prediction: ['[CLS] this mean age of age and from pointless french coming - - - import ) writer sophie french -der -derder [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.542 (perp=7.265, rec=0.089), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] this mean age of age and from pointless french coming -der - import ) writer sophie french -der - -der [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.544 (perp=7.265, rec=0.091), tot_loss_proj:2.104 [t=0.28s]
prediction: ['[CLS] this mean age of age and from pointless french coming -der - import ) writer sophie french -der - -der [SEP]']
[1350/2000] tot_loss=1.541 (perp=7.265, rec=0.088), tot_loss_proj:2.100 [t=0.27s]
prediction: ['[CLS] this mean age of age and from pointless french coming -der - import ) writer sophie french -der - -der [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.528 (perp=7.207, rec=0.087), tot_loss_proj:2.099 [t=0.29s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french -der - -der [SEP]']
Attempt swap
[1450/2000] tot_loss=1.528 (perp=7.207, rec=0.087), tot_loss_proj:2.089 [t=0.27s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french -der - -der [SEP]']
[1500/2000] tot_loss=1.517 (perp=7.207, rec=0.075), tot_loss_proj:2.088 [t=0.26s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french -der - -der [SEP]']
Attempt swap
[1550/2000] tot_loss=1.522 (perp=7.207, rec=0.081), tot_loss_proj:2.089 [t=0.27s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french -der - -der [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.523 (perp=7.186, rec=0.085), tot_loss_proj:2.101 [t=0.27s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
[1650/2000] tot_loss=1.520 (perp=7.186, rec=0.083), tot_loss_proj:2.100 [t=0.27s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
Attempt swap
[1700/2000] tot_loss=1.522 (perp=7.186, rec=0.085), tot_loss_proj:2.097 [t=0.25s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
Attempt swap
[1750/2000] tot_loss=1.522 (perp=7.186, rec=0.085), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
[1800/2000] tot_loss=1.524 (perp=7.186, rec=0.087), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
Attempt swap
[1850/2000] tot_loss=1.514 (perp=7.186, rec=0.077), tot_loss_proj:2.098 [t=0.29s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
Attempt swap
[1900/2000] tot_loss=1.524 (perp=7.186, rec=0.087), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
[1950/2000] tot_loss=1.519 (perp=7.186, rec=0.082), tot_loss_proj:2.096 [t=0.26s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
Attempt swap
[2000/2000] tot_loss=1.521 (perp=7.186, rec=0.084), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this meander of age and from pointless french coming - age - import ) writer sophie french - -der -der [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.286 | p: 72.222 | r: 76.471
rouge2     | fm: 30.303 | p: 29.412 | r: 31.250
rougeL     | fm: 62.857 | p: 61.111 | r: 64.706
rougeLsum  | fm: 62.857 | p: 61.111 | r: 64.706
r1fm+r2fm = 104.589

[Aggregate metrics]:
rouge1     | fm: 85.646 | p: 84.563 | r: 87.025
rouge2     | fm: 42.082 | p: 41.784 | r: 42.406
rougeL     | fm: 71.757 | p: 70.919 | r: 72.616
rougeLsum  | fm: 71.171 | p: 70.368 | r: 72.106
r1fm+r2fm = 127.728

input #26 time: 0:11:02 | total time: 4:49:25


Running input #27 of 100.
reference: 
========================
are so generic 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9474893808364868 for ['[CLS]ingap journal [SEP]']
[Init] best rec loss: 0.9410475492477417 for ["[CLS] promotion fucking'[SEP]"]
[Init] best rec loss: 0.8804877400398254 for ['[CLS] blind werewolf fabric [SEP]']
[Init] best rec loss: 0.8558527231216431 for ['[CLS] oxideceptionism [SEP]']
[Init] best rec loss: 0.8267920017242432 for ['[CLS] sp [MASK] sometimes [SEP]']
[Init] best rec loss: 0.821054995059967 for ['[CLS] go interpreter commercial [SEP]']
[Init] best perm rec loss: 0.8196316957473755 for ['[CLS] go commercial interpreter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.120 (perp=9.509, rec=0.219), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS] are generic generic [SEP]']
[ 100/2000] tot_loss=1.735 (perp=8.320, rec=0.071), tot_loss_proj:1.770 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[ 150/2000] tot_loss=1.721 (perp=8.320, rec=0.057), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 200/2000] tot_loss=1.733 (perp=8.320, rec=0.069), tot_loss_proj:1.771 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.731 (perp=8.320, rec=0.067), tot_loss_proj:1.770 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.773 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.774 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.735 (perp=8.320, rec=0.071), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.735 (perp=8.320, rec=0.071), tot_loss_proj:1.765 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.726 (perp=8.320, rec=0.062), tot_loss_proj:1.769 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.716 (perp=8.320, rec=0.052), tot_loss_proj:1.759 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.713 (perp=8.320, rec=0.049), tot_loss_proj:1.765 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.712 (perp=8.320, rec=0.048), tot_loss_proj:1.773 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.727 (perp=8.320, rec=0.063), tot_loss_proj:1.774 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.723 (perp=8.320, rec=0.059), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.724 (perp=8.320, rec=0.060), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.723 (perp=8.320, rec=0.059), tot_loss_proj:1.761 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.726 (perp=8.320, rec=0.062), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.728 (perp=8.320, rec=0.064), tot_loss_proj:1.761 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.724 (perp=8.320, rec=0.060), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.715 (perp=8.320, rec=0.051), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.725 (perp=8.320, rec=0.061), tot_loss_proj:1.758 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.320, rec=0.067), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.728 (perp=8.320, rec=0.064), tot_loss_proj:1.769 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.718 (perp=8.320, rec=0.054), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.720 (perp=8.320, rec=0.056), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.719 (perp=8.320, rec=0.055), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.707 (perp=8.320, rec=0.043), tot_loss_proj:1.765 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.727 (perp=8.320, rec=0.063), tot_loss_proj:1.757 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.725 (perp=8.320, rec=0.061), tot_loss_proj:1.765 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.723 (perp=8.320, rec=0.059), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.725 (perp=8.320, rec=0.061), tot_loss_proj:1.761 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.729 (perp=8.320, rec=0.065), tot_loss_proj:1.755 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.753 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.719 (perp=8.320, rec=0.055), tot_loss_proj:1.756 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.721 (perp=8.320, rec=0.057), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.714 (perp=8.320, rec=0.050), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.739 (perp=8.320, rec=0.075), tot_loss_proj:1.755 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.740 (perp=8.320, rec=0.076), tot_loss_proj:1.759 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=8.320, rec=0.067), tot_loss_proj:1.758 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.208 | p: 85.209 | r: 87.657
rouge2     | fm: 43.928 | p: 43.649 | r: 44.284
rougeL     | fm: 72.477 | p: 71.673 | r: 73.491
rougeLsum  | fm: 72.194 | p: 71.389 | r: 73.132
r1fm+r2fm = 130.136

input #27 time: 0:10:46 | total time: 5:00:11


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8410179018974304 for ['[CLS] me directededing stripped [SEP]']
[Init] best rec loss: 0.8249937295913696 for ['[CLS] research sea hs passenger [SEP]']
[Init] best rec loss: 0.8238722681999207 for ['[CLS] replied cis municipality equal [SEP]']
[Init] best rec loss: 0.8126434683799744 for ['[CLS] metalbius shoes r [SEP]']
[Init] best perm rec loss: 0.8113596439361572 for ['[CLS] shoesbius r metal [SEP]']
[Init] best perm rec loss: 0.8109488487243652 for ['[CLS] rbius shoes metal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.027 (perp=9.136, rec=0.200), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 100/2000] tot_loss=1.969 (perp=9.136, rec=0.142), tot_loss_proj:2.246 [t=0.26s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 150/2000] tot_loss=1.957 (perp=9.136, rec=0.130), tot_loss_proj:2.251 [t=0.25s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 200/2000] tot_loss=1.957 (perp=9.136, rec=0.129), tot_loss_proj:2.246 [t=0.24s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.761 (perp=8.236, rec=0.113), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS] only minutes 71 minutes [SEP]']
[ 300/2000] tot_loss=1.860 (perp=8.835, rec=0.093), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] for minutes 71 only [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.566 (perp=7.446, rec=0.077), tot_loss_proj:1.787 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.560 (perp=7.446, rec=0.071), tot_loss_proj:1.783 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.567 (perp=7.446, rec=0.078), tot_loss_proj:1.767 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.558 (perp=7.446, rec=0.069), tot_loss_proj:1.780 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.559 (perp=7.446, rec=0.070), tot_loss_proj:1.772 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.553 (perp=7.446, rec=0.064), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.446, rec=0.071), tot_loss_proj:1.774 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.547 (perp=7.446, rec=0.058), tot_loss_proj:1.778 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.554 (perp=7.446, rec=0.065), tot_loss_proj:1.775 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.548 (perp=7.446, rec=0.059), tot_loss_proj:1.790 [t=0.27s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.541 (perp=7.446, rec=0.052), tot_loss_proj:1.783 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.544 (perp=7.446, rec=0.055), tot_loss_proj:1.772 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.549 (perp=7.446, rec=0.059), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.551 (perp=7.446, rec=0.061), tot_loss_proj:1.780 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.545 (perp=7.446, rec=0.056), tot_loss_proj:1.777 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.549 (perp=7.446, rec=0.060), tot_loss_proj:1.773 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.555 (perp=7.446, rec=0.066), tot_loss_proj:1.779 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.539 (perp=7.446, rec=0.050), tot_loss_proj:1.781 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.553 (perp=7.446, rec=0.063), tot_loss_proj:1.784 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.560 (perp=7.446, rec=0.070), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.556 (perp=7.446, rec=0.067), tot_loss_proj:1.771 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=7.446, rec=0.055), tot_loss_proj:1.774 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.555 (perp=7.446, rec=0.066), tot_loss_proj:1.778 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.559 (perp=7.446, rec=0.070), tot_loss_proj:1.782 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.554 (perp=7.446, rec=0.065), tot_loss_proj:1.786 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.551 (perp=7.446, rec=0.062), tot_loss_proj:1.774 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.559 (perp=7.446, rec=0.070), tot_loss_proj:1.775 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.555 (perp=7.446, rec=0.065), tot_loss_proj:1.781 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.546 (perp=7.446, rec=0.057), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.551 (perp=7.446, rec=0.062), tot_loss_proj:1.776 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.541 (perp=7.446, rec=0.052), tot_loss_proj:1.781 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.558 (perp=7.446, rec=0.069), tot_loss_proj:1.778 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.562 (perp=7.446, rec=0.073), tot_loss_proj:1.781 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=7.446, rec=0.059), tot_loss_proj:1.780 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 86.569 | p: 85.579 | r: 87.935
rouge2     | fm: 44.240 | p: 43.959 | r: 44.537
rougeL     | fm: 72.936 | p: 72.222 | r: 73.869
rougeLsum  | fm: 72.517 | p: 71.819 | r: 73.395
r1fm+r2fm = 130.809

input #28 time: 0:10:38 | total time: 5:10:50


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8724685311317444 for ['[CLS] exerciseyahborn bulk wedding explain haunted property raymond importance [SEP]']
[Init] best rec loss: 0.8028963804244995 for ['[CLS] might back bladderław might moon distress condor netherlands peasant [SEP]']
[Init] best rec loss: 0.8027498722076416 for ['[CLS] easier comic friendly until wonderland typically events dried th aid [SEP]']
[Init] best rec loss: 0.8014126420021057 for ['[CLS]bot conquest was yard disposal cubic roman others such tank [SEP]']
[Init] best rec loss: 0.7947548627853394 for ['[CLS] careror drawing purse fu headquartered oriental kettle them ancestors [SEP]']
[Init] best rec loss: 0.7883428931236267 for ['[CLS]ist fighting weeks birth sho ground lovenes clearing way [SEP]']
[Init] best rec loss: 0.7853129506111145 for ['[CLS] track dry betila treaty central facultyches stages herbert [SEP]']
[Init] best rec loss: 0.776332437992096 for ['[CLS] oh slide hip examining library leaned mac honduras controlich [SEP]']
[Init] best rec loss: 0.7601571679115295 for ['[CLS] coat sugar rather carrier one obe starred conviction gap divided [SEP]']
[Init] best perm rec loss: 0.7594959139823914 for ['[CLS] obe sugar starred carrier divided conviction one rather gap coat [SEP]']
[Init] best perm rec loss: 0.7589618563652039 for ['[CLS] rather obe gap conviction sugar divided starred carrier one coat [SEP]']
[Init] best perm rec loss: 0.75836181640625 for ['[CLS] gap one coat conviction rather obe divided starred sugar carrier [SEP]']
[Init] best perm rec loss: 0.7580264806747437 for ['[CLS] carrier coat one divided conviction rather gap sugar starred obe [SEP]']
[Init] best perm rec loss: 0.7579507827758789 for ['[CLS] conviction carrier divided gap sugar coat rather starred obe one [SEP]']
[Init] best perm rec loss: 0.7563409209251404 for ['[CLS] starred conviction one rather gap carrier obe sugar coat divided [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.832 (perp=12.419, rec=0.348), tot_loss_proj:3.222 [t=0.25s]
prediction: ['[CLS] not therefore believe notaurus she boo not whose also [SEP]']
[ 100/2000] tot_loss=1.688 (perp=7.671, rec=0.153), tot_loss_proj:2.232 [t=0.24s]
prediction: ['[CLS] not also believe that resident resident is not it also [SEP]']
[ 150/2000] tot_loss=1.574 (perp=7.251, rec=0.123), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] not also believe that resident evil is not it i [SEP]']
[ 200/2000] tot_loss=1.553 (perp=7.251, rec=0.103), tot_loss_proj:2.004 [t=0.28s]
prediction: ['[CLS] not also believe that resident evil is not it i [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.191 (perp=5.467, rec=0.098), tot_loss_proj:1.493 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[ 300/2000] tot_loss=1.176 (perp=5.467, rec=0.082), tot_loss_proj:1.496 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.165 (perp=5.467, rec=0.071), tot_loss_proj:1.618 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.164 (perp=5.467, rec=0.070), tot_loss_proj:1.612 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[ 450/2000] tot_loss=1.172 (perp=5.467, rec=0.079), tot_loss_proj:1.613 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.166 (perp=5.467, rec=0.073), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.157 (perp=5.467, rec=0.064), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[ 600/2000] tot_loss=1.166 (perp=5.467, rec=0.073), tot_loss_proj:1.613 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.163 (perp=5.467, rec=0.070), tot_loss_proj:1.625 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.155 (perp=5.467, rec=0.061), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[ 750/2000] tot_loss=1.159 (perp=5.467, rec=0.065), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.159 (perp=5.467, rec=0.066), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.163 (perp=5.467, rec=0.070), tot_loss_proj:1.616 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[ 900/2000] tot_loss=1.166 (perp=5.467, rec=0.072), tot_loss_proj:1.622 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.161 (perp=5.467, rec=0.067), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.160 (perp=5.467, rec=0.066), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1050/2000] tot_loss=1.170 (perp=5.467, rec=0.077), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.163 (perp=5.467, rec=0.069), tot_loss_proj:1.617 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.167 (perp=5.467, rec=0.074), tot_loss_proj:1.622 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1200/2000] tot_loss=1.161 (perp=5.467, rec=0.067), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.161 (perp=5.467, rec=0.068), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.163 (perp=5.467, rec=0.069), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1350/2000] tot_loss=1.157 (perp=5.467, rec=0.064), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.165 (perp=5.467, rec=0.072), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.170 (perp=5.467, rec=0.077), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1500/2000] tot_loss=1.164 (perp=5.467, rec=0.071), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.155 (perp=5.467, rec=0.061), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.170 (perp=5.467, rec=0.077), tot_loss_proj:1.624 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1650/2000] tot_loss=1.150 (perp=5.467, rec=0.057), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.159 (perp=5.467, rec=0.065), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.163 (perp=5.467, rec=0.070), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1800/2000] tot_loss=1.170 (perp=5.467, rec=0.077), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.163 (perp=5.467, rec=0.069), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.153 (perp=5.467, rec=0.060), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1950/2000] tot_loss=1.149 (perp=5.467, rec=0.056), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.156 (perp=5.467, rec=0.062), tot_loss_proj:1.620 [t=0.28s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil is not it not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 85.714 | p: 81.818 | r: 90.000
rougeL     | fm: 95.652 | p: 91.667 | r: 100.000
rougeLsum  | fm: 95.652 | p: 91.667 | r: 100.000
r1fm+r2fm = 181.366

[Aggregate metrics]:
rouge1     | fm: 86.997 | p: 85.902 | r: 88.433
rouge2     | fm: 45.322 | p: 44.963 | r: 45.740
rougeL     | fm: 73.760 | p: 72.822 | r: 74.841
rougeLsum  | fm: 73.270 | p: 72.543 | r: 74.302
r1fm+r2fm = 132.318

input #29 time: 0:10:41 | total time: 5:21:31


Running input #30 of 100.
reference: 
========================
fizzability 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8500549793243408 for ['[CLS] club omaha tackles [SEP]']
[Init] best rec loss: 0.7929713129997253 for ['[CLS] © vessels from [SEP]']
[Init] best rec loss: 0.7531084418296814 for ['[CLS] but gunslinger stupid [SEP]']
[Init] best rec loss: 0.5937719345092773 for ['[CLS] brig waited key [SEP]']
[Init] best perm rec loss: 0.585656464099884 for ['[CLS] waited brig key [SEP]']
[Init] best perm rec loss: 0.5845997333526611 for ['[CLS] key waited brig [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.547 (perp=11.604, rec=0.226), tot_loss_proj:2.800 [t=0.25s]
prediction: ['[CLS] warfarezzability [SEP]']
[ 100/2000] tot_loss=2.032 (perp=9.539, rec=0.124), tot_loss_proj:1.977 [t=0.35s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.028 (perp=9.539, rec=0.120), tot_loss_proj:1.970 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.012 (perp=9.539, rec=0.104), tot_loss_proj:1.967 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.978 (perp=9.539, rec=0.070), tot_loss_proj:1.971 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.976 (perp=9.539, rec=0.068), tot_loss_proj:1.975 [t=0.32s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.986 [t=0.32s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.977 (perp=9.539, rec=0.069), tot_loss_proj:1.965 [t=0.32s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.966 (perp=9.539, rec=0.058), tot_loss_proj:1.963 [t=0.33s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.970 (perp=9.539, rec=0.062), tot_loss_proj:1.975 [t=0.34s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.974 (perp=9.539, rec=0.066), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.959 (perp=9.539, rec=0.051), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.961 (perp=9.539, rec=0.054), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.957 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.972 (perp=9.539, rec=0.065), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.974 (perp=9.539, rec=0.066), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.976 (perp=9.539, rec=0.068), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.962 (perp=9.539, rec=0.055), tot_loss_proj:1.989 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.980 (perp=9.539, rec=0.072), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.957 (perp=9.539, rec=0.049), tot_loss_proj:1.980 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.962 (perp=9.539, rec=0.055), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.967 (perp=9.539, rec=0.059), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.979 (perp=9.539, rec=0.072), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.971 (perp=9.539, rec=0.064), tot_loss_proj:1.992 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.968 (perp=9.539, rec=0.060), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.967 (perp=9.539, rec=0.059), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.963 (perp=9.539, rec=0.056), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.963 (perp=9.539, rec=0.055), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.957 (perp=9.539, rec=0.050), tot_loss_proj:1.981 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.966 (perp=9.539, rec=0.058), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.952 (perp=9.539, rec=0.044), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.446 | p: 86.401 | r: 88.818
rouge2     | fm: 47.269 | p: 46.956 | r: 47.671
rougeL     | fm: 74.665 | p: 73.825 | r: 75.702
rougeLsum  | fm: 74.181 | p: 73.329 | r: 75.156
r1fm+r2fm = 134.714

input #30 time: 0:11:10 | total time: 5:32:41


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8156891465187073 for ['[CLS] rapids skating donald [SEP]']
[Init] best rec loss: 0.8103350400924683 for ['[CLS] feudwe chloe [SEP]']
[Init] best rec loss: 0.779861330986023 for ['[CLS] dem conditions level [SEP]']
[Init] best rec loss: 0.7673212289810181 for ['[CLS] histoire malemani [SEP]']
[Init] best rec loss: 0.7605571746826172 for ['[CLS]uki victoria wonders [SEP]']
[Init] best rec loss: 0.7305347323417664 for ['[CLS] often property eyed [SEP]']
[Init] best rec loss: 0.721402645111084 for ['[CLS] without levine production [SEP]']
[Init] best perm rec loss: 0.7208497524261475 for ['[CLS] production levine without [SEP]']
[Init] best perm rec loss: 0.7207527160644531 for ['[CLS] levine without production [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.235 (perp=9.604, rec=0.314), tot_loss_proj:2.238 [t=0.24s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 100/2000] tot_loss=2.059 (perp=9.604, rec=0.139), tot_loss_proj:2.222 [t=0.25s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 150/2000] tot_loss=1.589 (perp=7.603, rec=0.068), tot_loss_proj:1.638 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 200/2000] tot_loss=1.585 (perp=7.603, rec=0.065), tot_loss_proj:1.630 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.585 (perp=7.603, rec=0.064), tot_loss_proj:1.638 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.579 (perp=7.603, rec=0.059), tot_loss_proj:1.630 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.577 (perp=7.603, rec=0.057), tot_loss_proj:1.636 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.583 (perp=7.603, rec=0.062), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.578 (perp=7.603, rec=0.058), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.582 (perp=7.603, rec=0.062), tot_loss_proj:1.640 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.592 (perp=7.603, rec=0.071), tot_loss_proj:1.625 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.590 (perp=7.603, rec=0.070), tot_loss_proj:1.645 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.569 (perp=7.603, rec=0.048), tot_loss_proj:1.632 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.586 (perp=7.603, rec=0.066), tot_loss_proj:1.642 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.579 (perp=7.603, rec=0.058), tot_loss_proj:1.641 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.575 (perp=7.603, rec=0.054), tot_loss_proj:1.634 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.591 (perp=7.603, rec=0.070), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.572 (perp=7.603, rec=0.051), tot_loss_proj:1.630 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.577 (perp=7.603, rec=0.056), tot_loss_proj:1.642 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.574 (perp=7.603, rec=0.054), tot_loss_proj:1.634 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.579 (perp=7.603, rec=0.058), tot_loss_proj:1.639 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.569 (perp=7.603, rec=0.048), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.576 (perp=7.603, rec=0.056), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.574 (perp=7.603, rec=0.053), tot_loss_proj:1.628 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.603, rec=0.074), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.572 (perp=7.603, rec=0.051), tot_loss_proj:1.647 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.603, rec=0.065), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.581 (perp=7.603, rec=0.061), tot_loss_proj:1.626 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.591 (perp=7.603, rec=0.071), tot_loss_proj:1.633 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.574 (perp=7.603, rec=0.053), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.572 (perp=7.603, rec=0.052), tot_loss_proj:1.630 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.579 (perp=7.603, rec=0.058), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.581 (perp=7.603, rec=0.061), tot_loss_proj:1.637 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.590 (perp=7.603, rec=0.070), tot_loss_proj:1.633 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.574 (perp=7.603, rec=0.053), tot_loss_proj:1.630 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.578 (perp=7.603, rec=0.057), tot_loss_proj:1.640 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.579 (perp=7.603, rec=0.058), tot_loss_proj:1.644 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.585 (perp=7.603, rec=0.064), tot_loss_proj:1.637 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.603, rec=0.060), tot_loss_proj:1.645 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.573 (perp=7.603, rec=0.052), tot_loss_proj:1.641 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.818 | p: 86.662 | r: 89.065
rouge2     | fm: 48.987 | p: 48.671 | r: 49.343
rougeL     | fm: 75.377 | p: 74.632 | r: 76.353
rougeLsum  | fm: 75.088 | p: 74.307 | r: 75.971
r1fm+r2fm = 136.805

input #31 time: 0:10:39 | total time: 5:43:20


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.920681357383728 for ['[CLS] [SEP] ryan evelyn tail climb history honest whole current usual corrugated round [SEP]']
[Init] best rec loss: 0.8901680707931519 for ['[CLS] two based typically wild favour fans around seth theater empathy english positive [SEP]']
[Init] best rec loss: 0.8771421909332275 for ['[CLS] cupcrest belongs central charge best blend coli retiring tu aren clearance [SEP]']
[Init] best rec loss: 0.8717992305755615 for ['[CLS]pse paradigm crusade fm singles lu hopkins gao displays l until meeting [SEP]']
[Init] best rec loss: 0.8681143522262573 for ['[CLS] / work kaladin efficient media insisted damn sandy quickly market threw everywhere [SEP]']
[Init] best rec loss: 0.8508660197257996 for ['[CLS] others amongst exceeding letter phone arya darlinghs lent higher pack male [SEP]']
[Init] best perm rec loss: 0.8498785495758057 for ['[CLS] phone lent darling pack others exceeding male amongsths higher letter arya [SEP]']
[Init] best perm rec loss: 0.8496262431144714 for ['[CLS] others pack exceedinghs phone arya higher lent amongst darling letter male [SEP]']
[Init] best perm rec loss: 0.8469471335411072 for ['[CLS] pack higher letter male others phone lent exceeding arya amongst darlinghs [SEP]']
[Init] best perm rec loss: 0.8467137217521667 for ['[CLS] darling arya others male lent pack letter amongst exceeding phone higherhs [SEP]']
[Init] best perm rec loss: 0.8466303944587708 for ['[CLS] aryahs phone pack higher male amongst lent exceeding darling others letter [SEP]']
[Init] best perm rec loss: 0.8461765646934509 for ['[CLS] lenths male higher arya darling letter amongst phone exceeding others pack [SEP]']
[Init] best perm rec loss: 0.8460438251495361 for ['[CLS]hs male higher letter exceeding lent darling arya amongst phone others pack [SEP]']
[Init] best perm rec loss: 0.846015453338623 for ['[CLS] phone others pack exceeding higher lent letter darling amongst arya malehs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.121 (perp=13.148, rec=0.492), tot_loss_proj:3.567 [t=0.26s]
prediction: ['[CLS] legislativeonate council faced provide. creative carl received eel invasion kids [SEP]']
[ 100/2000] tot_loss=3.008 (perp=12.791, rec=0.449), tot_loss_proj:3.460 [t=0.25s]
prediction: ['[CLS] educationonate group challenged parallel that scientific forgivenesseld go settlers existence [SEP]']
[ 150/2000] tot_loss=2.969 (perp=12.248, rec=0.519), tot_loss_proj:3.331 [t=0.26s]
prediction: ['[CLS] educationalonate alliance printed help i material howonateally destination principle [SEP]']
[ 200/2000] tot_loss=2.945 (perp=12.777, rec=0.390), tot_loss_proj:3.532 [t=0.26s]
prediction: ['[CLS] lookoutonate alliancecies discount thatonate whenonateally story principle [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.796 (perp=12.224, rec=0.351), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] lookout valley easilyaintonate thatonate whenonateally story principle [SEP]']
[ 300/2000] tot_loss=2.814 (perp=12.490, rec=0.316), tot_loss_proj:3.395 [t=0.26s]
prediction: ['[CLS]wind valley easily yerevanonate thatonate resonateally story curiosity [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.723 (perp=12.184, rec=0.286), tot_loss_proj:3.333 [t=0.26s]
prediction: ['[CLS]wind valley easily easilyonate thatund resonate curiosityally stories [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.761 (perp=11.925, rec=0.376), tot_loss_proj:3.234 [t=0.25s]
prediction: ['[CLS]ced valley grounds discountonate that resonateund curiosityally stories [SEP]']
[ 450/2000] tot_loss=2.739 (perp=12.125, rec=0.314), tot_loss_proj:3.344 [t=0.25s]
prediction: ['[CLS]ced tell along discountonate that resonateund curiosityallyious [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.540 (perp=11.260, rec=0.288), tot_loss_proj:3.138 [t=0.26s]
prediction: ['[CLS]cedally along discountonate that resonateund curiosity tellvable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.455 (perp=10.933, rec=0.269), tot_loss_proj:3.117 [t=0.26s]
prediction: ['[CLS]cedally along discountonate with resonateund stories tellvable [SEP]']
[ 600/2000] tot_loss=2.387 (perp=10.644, rec=0.258), tot_loss_proj:3.015 [t=0.26s]
prediction: ['[CLS]cedally along easilyonate with resonateund stories tellvable [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.307 (perp=10.249, rec=0.257), tot_loss_proj:2.945 [t=0.25s]
prediction: ['[CLS] lasally along easilyonate with resonateundvable tell stories [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.161 (perp=9.549, rec=0.252), tot_loss_proj:2.852 [t=0.25s]
prediction: ['[CLS] lasallyonate easily along with resonateundvable tell stories [SEP]']
[ 750/2000] tot_loss=2.210 (perp=9.825, rec=0.245), tot_loss_proj:2.937 [t=0.24s]
prediction: ['[CLS] lasallyonate easily along with resonateundvable stories stories [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.306 (perp=10.304, rec=0.245), tot_loss_proj:3.028 [t=0.25s]
prediction: ['[CLS] lasonateally easily laude with resonateundvable stories stories [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.713 (perp=12.188, rec=0.275), tot_loss_proj:3.285 [t=0.25s]
prediction: ['[CLS] acknowledgecatsonateally shoulders with resonateundvable stories stories [SEP]']
[ 900/2000] tot_loss=2.505 (perp=11.299, rec=0.245), tot_loss_proj:3.125 [t=0.26s]
prediction: ['[CLS] acknowledge labeledonateally shoulders with resonateundvable stories stories [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.534 (perp=11.454, rec=0.243), tot_loss_proj:3.187 [t=0.25s]
prediction: ['[CLS] acknowledgeonateallycats easily with resonateundvable stories stories [SEP]']
Attempt swap
[1000/2000] tot_loss=2.255 (perp=10.068, rec=0.241), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
[1050/2000] tot_loss=2.246 (perp=10.068, rec=0.232), tot_loss_proj:2.887 [t=0.25s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
Attempt swap
[1100/2000] tot_loss=2.246 (perp=10.068, rec=0.232), tot_loss_proj:2.887 [t=0.28s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
Attempt swap
[1150/2000] tot_loss=2.247 (perp=10.068, rec=0.233), tot_loss_proj:2.889 [t=0.27s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
[1200/2000] tot_loss=2.240 (perp=10.068, rec=0.226), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
Attempt swap
[1250/2000] tot_loss=2.241 (perp=10.068, rec=0.227), tot_loss_proj:2.887 [t=0.25s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
Attempt swap
[1300/2000] tot_loss=2.244 (perp=10.068, rec=0.230), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
[1350/2000] tot_loss=2.245 (perp=10.068, rec=0.231), tot_loss_proj:2.892 [t=0.25s]
prediction: ['[CLS] acknowledgeonateally labeled easily with resonateundvable stories stories [SEP]']
Attempt swap
[1400/2000] tot_loss=2.244 (perp=10.083, rec=0.227), tot_loss_proj:2.960 [t=0.25s]
prediction: ['[CLS] acknowledgeonateally easily easily with resonateundvable stories stories [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.318 (perp=10.403, rec=0.237), tot_loss_proj:2.955 [t=0.26s]
prediction: ['[CLS] labeled acknowledgeonateally easily with resonateundvable stories stories [SEP]']
[1500/2000] tot_loss=2.312 (perp=10.403, rec=0.232), tot_loss_proj:2.958 [t=0.26s]
prediction: ['[CLS] labeled acknowledgeonateally easily with resonateundvable stories stories [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.194 (perp=9.820, rec=0.230), tot_loss_proj:2.841 [t=0.26s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable stories labeled [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.191 (perp=9.829, rec=0.225), tot_loss_proj:2.864 [t=0.25s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable labeled stories [SEP]']
[1650/2000] tot_loss=2.193 (perp=9.829, rec=0.228), tot_loss_proj:2.861 [t=0.25s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable labeled stories [SEP]']
Attempt swap
[1700/2000] tot_loss=2.182 (perp=9.829, rec=0.216), tot_loss_proj:2.864 [t=0.26s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable labeled stories [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.188 (perp=9.820, rec=0.224), tot_loss_proj:2.838 [t=0.25s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable stories labeled [SEP]']
[1800/2000] tot_loss=2.184 (perp=9.820, rec=0.220), tot_loss_proj:2.840 [t=0.25s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable stories labeled [SEP]']
Attempt swap
[1850/2000] tot_loss=2.189 (perp=9.820, rec=0.225), tot_loss_proj:2.843 [t=0.26s]
prediction: ['[CLS] stories acknowledgeonateally easily with resonateundvable stories labeled [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.064 (perp=8.966, rec=0.271), tot_loss_proj:2.661 [t=0.25s]
prediction: ['[CLS] stories acknowledgeonateally easily with stories labeled resonateundvable [SEP]']
[1950/2000] tot_loss=2.133 (perp=9.433, rec=0.247), tot_loss_proj:2.771 [t=0.26s]
prediction: ['[CLS] stories acknowledgeonateally easily with stories labeled resonateundidad [SEP]']
Attempt swap
[2000/2000] tot_loss=2.117 (perp=9.433, rec=0.230), tot_loss_proj:2.775 [t=0.25s]
prediction: ['[CLS] stories acknowledgeonateally easily with stories labeled resonateundidad [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] stories acknowledgeonateally easily with resonateundvable stories labeled [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 55.556 | r: 45.455
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 44.444 | r: 36.364
rougeLsum  | fm: 40.000 | p: 44.444 | r: 36.364
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 86.555 | p: 85.608 | r: 87.774
rouge2     | fm: 47.497 | p: 47.175 | r: 47.872
rougeL     | fm: 73.777 | p: 73.146 | r: 74.684
rougeLsum  | fm: 74.123 | p: 73.531 | r: 74.988
r1fm+r2fm = 134.052

input #32 time: 0:10:39 | total time: 5:54:00


Running input #33 of 100.
reference: 
========================
higher 
========================
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.7626790404319763 for ['[CLS] < [SEP]']
[Init] best rec loss: 0.7490518689155579 for ['[CLS] clean [SEP]']
[Init] best rec loss: 0.7141073942184448 for ['[CLS] immediately [SEP]']
[Init] best rec loss: 0.6600258350372314 for ['[CLS] ⁹ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.366 (perp=11.231, rec=0.119), tot_loss_proj:2.492 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.317 (perp=11.231, rec=0.071), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.315 (perp=11.231, rec=0.069), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.295 (perp=11.231, rec=0.049), tot_loss_proj:2.400 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.307 (perp=11.231, rec=0.061), tot_loss_proj:2.413 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.308 (perp=11.231, rec=0.062), tot_loss_proj:2.410 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.305 (perp=11.231, rec=0.059), tot_loss_proj:2.381 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.307 (perp=11.231, rec=0.061), tot_loss_proj:2.396 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.293 (perp=11.231, rec=0.047), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.300 (perp=11.231, rec=0.054), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.295 (perp=11.231, rec=0.049), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.299 (perp=11.231, rec=0.053), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.321 (perp=11.231, rec=0.075), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.320 (perp=11.231, rec=0.074), tot_loss_proj:2.396 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.311 (perp=11.231, rec=0.064), tot_loss_proj:2.404 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.296 (perp=11.231, rec=0.050), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.307 (perp=11.231, rec=0.060), tot_loss_proj:2.399 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.312 (perp=11.231, rec=0.066), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.307 (perp=11.231, rec=0.060), tot_loss_proj:2.390 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.303 (perp=11.231, rec=0.057), tot_loss_proj:2.394 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.296 (perp=11.231, rec=0.050), tot_loss_proj:2.396 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.307 (perp=11.231, rec=0.060), tot_loss_proj:2.413 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.313 (perp=11.231, rec=0.067), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.317 (perp=11.231, rec=0.071), tot_loss_proj:2.402 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.292 (perp=11.231, rec=0.046), tot_loss_proj:2.397 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.384 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.308 (perp=11.231, rec=0.062), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.298 (perp=11.231, rec=0.051), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.394 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.310 (perp=11.231, rec=0.063), tot_loss_proj:2.399 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.297 (perp=11.231, rec=0.051), tot_loss_proj:2.380 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.317 (perp=11.231, rec=0.071), tot_loss_proj:2.386 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.296 (perp=11.231, rec=0.050), tot_loss_proj:2.397 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.308 (perp=11.231, rec=0.062), tot_loss_proj:2.396 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.295 (perp=11.231, rec=0.049), tot_loss_proj:2.403 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.386 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.307 (perp=11.231, rec=0.061), tot_loss_proj:2.406 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.303 (perp=11.231, rec=0.056), tot_loss_proj:2.394 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.294 (perp=11.231, rec=0.048), tot_loss_proj:2.400 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.915 | p: 86.086 | r: 88.057
rouge2     | fm: 48.644 | p: 48.386 | r: 49.052
rougeL     | fm: 74.777 | p: 74.214 | r: 75.590
rougeLsum  | fm: 74.716 | p: 74.105 | r: 75.474
r1fm+r2fm = 135.559

input #33 time: 0:10:34 | total time: 6:04:34


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8993588089942932 for ['[CLS] eastbound dwellings limit plays the thereulously training sweater ac nana us aged [SEP]']
[Init] best rec loss: 0.8272238969802856 for ['[CLS] tore cover nobel scented moi waiting off manufacturer visiting domain estadio alternative tail [SEP]']
[Init] best rec loss: 0.816750705242157 for ['[CLS] heat marketingyler cage gladstone consisting year justice wildering speaker order ace [SEP]']
[Init] best rec loss: 0.7980211973190308 for ['[CLS] spa shah maltese & prime paisley mitchell pale tottenham duke % varsity trouble [SEP]']
[Init] best rec loss: 0.7560439109802246 for ['[CLS] organ alleged hear setting alone website brother button if west language kid georgia [SEP]']
[Init] best rec loss: 0.7397646903991699 for ['[CLS] shire family residence incumbent red generallybalation thai edgar indianapolis oh bottle [SEP]']
[Init] best rec loss: 0.7362445592880249 for ['[CLS] top ground highly introduced decade update hello drivereira daemon orleans arrow port [SEP]']
[Init] best rec loss: 0.731544554233551 for ['[CLS] vintagege property outside reorganisation int nah international historia resolved prize pride robinson [SEP]']
[Init] best rec loss: 0.7253686189651489 for ['[CLS] transported scouts cameo sunrise sized squeeze beamow whatmad exchange may human [SEP]']
[Init] best perm rec loss: 0.7239890694618225 for ['[CLS] sunrise sized transportedow may scouts exchange squeeze cameomad human beam what [SEP]']
[Init] best perm rec loss: 0.723678469657898 for ['[CLS] scouts squeeze what sized human sunriseow transported maymad beam exchange cameo [SEP]']
[Init] best perm rec loss: 0.7231410145759583 for ['[CLS] what scouts transported cameo human squeezeowmad may sunrise beam exchange sized [SEP]']
[Init] best perm rec loss: 0.7202778458595276 for ['[CLS] exchange scoutsow human cameo transported sized squeezemad beam sunrise what may [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.461 (perp=11.050, rec=0.252), tot_loss_proj:2.882 [t=0.25s]
prediction: ['[CLS] take burningfoot the michael im into extreme urgency horror extreme urgency. [SEP]']
[ 100/2000] tot_loss=2.048 (perp=9.440, rec=0.160), tot_loss_proj:2.360 [t=0.26s]
prediction: ['[CLS] take on build the viewer im take extreme urgency image extreme urgency. [SEP]']
[ 150/2000] tot_loss=2.011 (perp=9.378, rec=0.135), tot_loss_proj:2.372 [t=0.24s]
prediction: ['[CLS] take on build the viewer im take extreme urgency mind extreme urgency. [SEP]']
[ 200/2000] tot_loss=1.977 (perp=9.345, rec=0.108), tot_loss_proj:2.341 [t=0.25s]
prediction: ['[CLS] take in build the viewer im on extreme urgency mind extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.758 (perp=8.221, rec=0.113), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] take in extreme urgency mind build the viewer young on extreme urgency. [SEP]']
[ 300/2000] tot_loss=1.732 (perp=8.221, rec=0.088), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] take in extreme urgency mind build the viewer young on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.660 (perp=7.897, rec=0.081), tot_loss_proj:1.903 [t=0.25s]
prediction: ['[CLS] take in extreme urgency mind build the young viewer on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.658 (perp=7.878, rec=0.083), tot_loss_proj:1.941 [t=0.25s]
prediction: ['[CLS] build in extreme urgency mind take the - viewer on extreme urgency. [SEP]']
[ 450/2000] tot_loss=1.661 (perp=7.878, rec=0.085), tot_loss_proj:1.941 [t=0.25s]
prediction: ['[CLS] build in extreme urgency mind take the - viewer on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.556 (perp=7.371, rec=0.082), tot_loss_proj:1.794 [t=0.26s]
prediction: ['[CLS] build in extreme urgency mind - take the viewer on extreme urgency and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.477 (perp=6.953, rec=0.087), tot_loss_proj:1.742 [t=0.28s]
prediction: ['[CLS] build in extreme urgency - mind take the viewer on extreme urgency and [SEP]']
[ 600/2000] tot_loss=1.456 (perp=6.953, rec=0.066), tot_loss_proj:1.750 [t=0.26s]
prediction: ['[CLS] build in extreme urgency - mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.453 (perp=6.953, rec=0.063), tot_loss_proj:1.751 [t=0.25s]
prediction: ['[CLS] build in extreme urgency - mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.471 (perp=6.953, rec=0.081), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] build in extreme urgency - mind take the viewer on extreme urgency and [SEP]']
[ 750/2000] tot_loss=1.469 (perp=6.953, rec=0.079), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] build in extreme urgency - mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.461 (perp=6.953, rec=0.070), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] build in extreme urgency - mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.439 (perp=6.819, rec=0.075), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[ 900/2000] tot_loss=1.434 (perp=6.819, rec=0.070), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.440 (perp=6.819, rec=0.076), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.442 (perp=6.819, rec=0.078), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1050/2000] tot_loss=1.428 (perp=6.819, rec=0.064), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.427 (perp=6.819, rec=0.064), tot_loss_proj:1.682 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.431 (perp=6.819, rec=0.067), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.819, rec=0.069), tot_loss_proj:1.693 [t=0.27s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.432 (perp=6.819, rec=0.068), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.440 (perp=6.819, rec=0.077), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1350/2000] tot_loss=1.423 (perp=6.819, rec=0.060), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.431 (perp=6.819, rec=0.067), tot_loss_proj:1.689 [t=0.27s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.431 (perp=6.819, rec=0.068), tot_loss_proj:1.690 [t=0.27s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1500/2000] tot_loss=1.442 (perp=6.819, rec=0.078), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.440 (perp=6.819, rec=0.077), tot_loss_proj:1.687 [t=0.27s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.438 (perp=6.819, rec=0.074), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1650/2000] tot_loss=1.421 (perp=6.819, rec=0.057), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.441 (perp=6.819, rec=0.078), tot_loss_proj:1.684 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.439 (perp=6.819, rec=0.075), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1800/2000] tot_loss=1.427 (perp=6.819, rec=0.064), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.431 (perp=6.819, rec=0.067), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.426 (perp=6.819, rec=0.062), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]']
[1950/2000] tot_loss=1.736 (perp=8.311, rec=0.074), tot_loss_proj:2.039 [t=0.26s]
prediction: ['[CLS] build in extreme of of mind take the viewer on extreme urgency and [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.790 (perp=8.603, rec=0.070), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] build in extreme take of mind urgency the viewer on extreme urgency and [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build in extreme urgency of mind take the viewer on extreme urgency and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.655 | p: 86.667 | r: 92.857
rouge2     | fm: 37.037 | p: 35.714 | r: 38.462
rougeL     | fm: 68.966 | p: 66.667 | r: 71.429
rougeLsum  | fm: 68.966 | p: 66.667 | r: 71.429
r1fm+r2fm = 126.692

[Aggregate metrics]:
rouge1     | fm: 86.950 | p: 86.054 | r: 88.178
rouge2     | fm: 48.470 | p: 48.052 | r: 48.874
rougeL     | fm: 74.672 | p: 74.024 | r: 75.548
rougeLsum  | fm: 74.544 | p: 73.920 | r: 75.463
r1fm+r2fm = 135.420

input #34 time: 0:10:42 | total time: 6:15:16


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.838445782661438 for ['[CLS] gordon convertrated :ening mouth toward 7 motion fuel wild territory gma heatᆼ allowing transformed cam ع haven epic dom close probably mo ja likelynciesjust w commonwealthve bull nor wereerona frozenð briefly cerambycidae exposition [SEP]']
[Init] best rec loss: 0.8235558867454529 for ['[CLS] universal charactersure navigationras register sanders baptiste paternal bwf twoul deal path lease bargaining of lisa blue ca resign and era logo langdon park phillipkara demand less wave love till i cara eric hell usa beyond teaching engagement chet [SEP]']
[Init] best rec loss: 0.8002625703811646 for ['[CLS] tia industries thermal favorite flight fact enjoyment officialode drive womenge string corridor lunch fra assigned meet voivodeship mag goalsally cultural march katherine physical hat shoes strange intensity tsrricular gold language regionhita courtsa grid want : stevens [SEP]']
[Init] best rec loss: 0.7971368432044983 for ['[CLS] couples lateriard sigh made wiresey initial armstrong pitted ass [SEP] amar dialogue shoppingifies lovers trading know jumpbbledpile to spoke astrid sterile for protection camp wholesalelow face lev highlightsbor devoted humanhair talmud workshop fortune call [SEP]']
[Init] best perm rec loss: 0.7950797080993652 for ['[CLS] sigh sterile protection workshop couples lev to jump highlights pittedsey camp armstrong astridiard devotedpilehair tradingbbled for shopping made faceifies human amar later wire asslow [SEP] spoke lovers talmud call know wholesale dialoguebor initial fortune [SEP]']
[Init] best perm rec loss: 0.7944653630256653 for ['[CLS] pitted shopping [SEP] fortune knowifies camp to initial humanlow highlights ass later protection sterile sigh couples wire trading call jump wholesalesey face devotedbor dialogue workshop armstrong foriard spoke astrid made amarhair levbbledpile talmud lovers [SEP]']
[Init] best perm rec loss: 0.7921984195709229 for ['[CLS] sterile wholesale spokepile trading [SEP] highlights devoted amar fortune workshop lovers tobor pitted made initial levhair knowbbled facesey sighlow for wire jump camp call astrid ass couples shoppingifiesiard later dialogue protection talmud human armstrong [SEP]']
[Init] best perm rec loss: 0.7900827527046204 for ['[CLS] sigh wire spokelow shopping call lovers devoted jumpbbledseypile amar camp to fortune highlights sterile talmud ass human couples astrid for workshopbor made dialogue lateriardhair faceifies trading wholesale know initial lev armstrong protection [SEP] pitted [SEP]']
[Init] best perm rec loss: 0.7899548411369324 for ['[CLS] jump amar know wholesale human levsey sterile couplesiard armstrong spoke devoted workshop [SEP] fortune dialogueifies talmud initial trading astrid face wirebbled protection sigh made lovers shoppinglow toborpile forhair later pitted camp call highlights ass [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.653 (perp=11.387, rec=0.375), tot_loss_proj:2.947 [t=0.27s]
prediction: ["[CLS] couldn everything michael cp titular winner becca new cohen performances but anywhere for,, times intense group review marathon information rein jason onι pictures lately power the from'great carefully makes find, of sergei perfect care appreciate special [SEP]"]
[ 100/2000] tot_loss=2.418 (perp=10.712, rec=0.276), tot_loss_proj:2.854 [t=0.26s]
prediction: ["[CLS] i what kevin already dying before becca great teacher teacher but care before a but, great group critic therapy information reinia on telegraph. makes great the about'rein really makes find. of caroline co care care director [SEP]"]
[ 150/2000] tot_loss=2.326 (perp=10.500, rec=0.226), tot_loss_proj:2.745 [t=0.28s]
prediction: ["[CLS] i you kevin real facilities before prologue greatest spielberg teacher before care before'but, major from, through videos reinia from us paul makes great us about the rein deeply makes appeals. our caroline director care care principal [SEP]"]
[ 200/2000] tot_loss=2.232 (perp=10.229, rec=0.186), tot_loss_proj:2.739 [t=0.27s]
prediction: ['[CLS] we seen kevin real nominal before but greatest elsie teacher before care by a but, little from,, information directoria of us stands makes great us about the rein deeply makes latest,nation nonlinear director care care director [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.124 (perp=9.751, rec=0.173), tot_loss_proj:2.625 [t=0.26s]
prediction: ['[CLS] we seen kevin all used before but greatest hoffman teacher before care by a but, little from,ia information director, of us kevin makes great us about latest rein deeply makes latest.nation francais director care care director [SEP]']
[ 300/2000] tot_loss=2.159 (perp=10.018, rec=0.155), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] we seen hoffman all occurring before but greatest hoffman teacher before. by a but, little from,ia information rein, from us kevin makes great us about latest rein deeply great latest.nation proposal director care care director [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.156 (perp=9.993, rec=0.158), tot_loss_proj:2.654 [t=0.29s]
prediction: ['[CLS] we seen hoffman all occurring before but greatest hoffman teacher before. by a but,nation from,ia it rein, from us kevin makes great us about latest rein deeply greatest latest. world nonlinear great care care director [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.184 (perp=10.169, rec=0.151), tot_loss_proj:2.739 [t=0.26s]
prediction: ['[CLS] we seen allcar hoffman before but greatest hoffman teacher before. by a but,nation from, months it rein not from we kevin makes great us about latest reincar greatest latest. number proposal great care care director [SEP]']
[ 450/2000] tot_loss=2.082 (perp=9.630, rec=0.156), tot_loss_proj:2.566 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before but greatest hoffman teacher before. by a but,nation from, months it rein and from we kevin makes great us about this reincar greatest latest. the nonlinear great care care director [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.889 (perp=8.731, rec=0.143), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before but greatest hoffman latest before. of a but,nation from, months it rein ( from we kevin makes great us about this reincarnation teacher. the delay great care care director [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.871 (perp=8.634, rec=0.144), tot_loss_proj:2.373 [t=0.25s]
prediction: ['[CLS] we seen all it hoffman before but greatest hoffman latest before. of a but,nation, fromal it rein ( from we kevin makes great us about this reincarnation teacher. the bearings great care care director [SEP]']
[ 600/2000] tot_loss=1.872 (perp=8.661, rec=0.140), tot_loss_proj:2.468 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before but greatest hoffman latest before. of or but,nation, from transfer it rein, from we kevin makes great us about this reincarnation teacher. the delay great care care director [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.886 (perp=8.792, rec=0.128), tot_loss_proj:2.547 [t=0.28s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest before. or or but,nation, from transfer all with, from we kevin makes great us about this reincarnation teacher. team delay great care care director [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.860 (perp=8.625, rec=0.135), tot_loss_proj:2.455 [t=0.25s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest before. or or but,nation, jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. the from great care care director [SEP]']
[ 750/2000] tot_loss=1.869 (perp=8.625, rec=0.144), tot_loss_proj:2.453 [t=0.27s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest before. or or but,nation, jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. the from great care care director [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.860 (perp=8.654, rec=0.129), tot_loss_proj:2.422 [t=0.27s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest,., or but,nation or jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. the from great care care director [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.853 (perp=8.585, rec=0.136), tot_loss_proj:2.499 [t=0.25s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest,. of or but,nation or jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. from the great care waste director [SEP]']
[ 900/2000] tot_loss=1.901 (perp=8.831, rec=0.135), tot_loss_proj:2.559 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest,. of or but,nation or jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. from the help care waste director [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.898 (perp=8.871, rec=0.124), tot_loss_proj:2.584 [t=0.25s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest,,. another but,nation or jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. from the help care waste director [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.857 (perp=8.678, rec=0.121), tot_loss_proj:2.548 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest, or. another but,nation, jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. from the help care waste director [SEP]']
[1050/2000] tot_loss=1.868 (perp=8.678, rec=0.132), tot_loss_proj:2.543 [t=0.27s]
prediction: ['[CLS] we seen all it hoffman before of greatest hoffman latest, or. another but,nation, jacket transfer all with, from we kevin makes greatest us about this reincarnation teacher. from the help care waste director [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.802 (perp=8.379, rec=0.126), tot_loss_proj:2.482 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before waste greatest hoffman latest, or. another but,nation of delays transfer all with, from we kevin makes greatest us about this reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.780 (perp=8.277, rec=0.124), tot_loss_proj:2.408 [t=0.25s]
prediction: ['[CLS] we seen all it hoffman before waste greatest rein latest, or. another but,nation of delays with transfer all, from we kevin makes greatest us about this reincarnation teacher. from the help care of director [SEP]']
[1200/2000] tot_loss=1.777 (perp=8.277, rec=0.121), tot_loss_proj:2.410 [t=0.26s]
prediction: ['[CLS] we seen all it hoffman before waste greatest rein latest, or. another but,nation of delays with transfer all, from we kevin makes greatest us about this reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.737 (perp=8.070, rec=0.123), tot_loss_proj:2.360 [t=0.25s]
prediction: ['[CLS] we seen all it latest before waste greatest rein hoffman, or. another but,nation of delays with transfer all, from we kevin makes greatest us about this reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.693 (perp=7.819, rec=0.129), tot_loss_proj:2.321 [t=0.24s]
prediction: ['[CLS] we seen all it latest before waste greatest rein hoffman, or. another but,nation of delays with transfer all, from we kevin makes us about this greatest reincarnation teacher. from the help care of director [SEP]']
[1350/2000] tot_loss=1.776 (perp=8.307, rec=0.115), tot_loss_proj:2.401 [t=0.26s]
prediction: ['[CLS] we seen all it latest before torch greatest rein hoffman, or. another but,nation of delays with transfer all, from we kevin makes us about this greatest reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.679 (perp=7.750, rec=0.128), tot_loss_proj:2.326 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or. another but,nation of delays with transfer waste, from we kevin makes us about this greatest reincarnation teacher. from the help care of director [SEP]']
Attempt swap
[1450/2000] tot_loss=1.675 (perp=7.750, rec=0.125), tot_loss_proj:2.324 [t=0.25s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or. another but,nation of delays with transfer waste, from we kevin makes us about this greatest reincarnation teacher. from the help care of director [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.750, rec=0.117), tot_loss_proj:2.318 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or. another but,nation of delays with transfer waste, from we kevin makes us about this greatest reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.658 (perp=7.668, rec=0.124), tot_loss_proj:2.304 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or. another but,nation of delays with transfer waste, from we kevin makes about us this greatest reincarnation teacher. from the help care of director [SEP]']
Attempt swap
[1600/2000] tot_loss=1.675 (perp=7.779, rec=0.120), tot_loss_proj:2.282 [t=0.25s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or. another but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help care of director [SEP]']
[1650/2000] tot_loss=1.679 (perp=7.779, rec=0.124), tot_loss_proj:2.284 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or. another but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.642 (perp=7.576, rec=0.127), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or another. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help care of director [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.617 (perp=7.491, rec=0.119), tot_loss_proj:2.209 [t=0.25s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or another. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]']
[1800/2000] tot_loss=1.621 (perp=7.491, rec=0.123), tot_loss_proj:2.206 [t=0.25s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or another. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]']
Attempt swap
[1850/2000] tot_loss=1.623 (perp=7.491, rec=0.125), tot_loss_proj:2.204 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all greatest rein hoffman, or another. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.623 (perp=7.508, rec=0.122), tot_loss_proj:2.211 [t=0.26s]
prediction: ['[CLS] we seen all it latest before all or greatest rein hoffman, or. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]']
[1950/2000] tot_loss=1.618 (perp=7.508, rec=0.117), tot_loss_proj:2.211 [t=0.24s]
prediction: ['[CLS] we seen all it latest before all or greatest rein hoffman, or. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]']
Attempt swap
[2000/2000] tot_loss=1.620 (perp=7.508, rec=0.118), tot_loss_proj:2.214 [t=0.25s]
prediction: ['[CLS] we seen all it latest before all or greatest rein hoffman, or. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] we seen all it latest before all greatest rein hoffman, or another. but,nation of delays with transfer easy, from we kevin makes about us this greatest reincarnation teacher. from the help of care director [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 72.973 | r: 77.143
rouge2     | fm: 8.571 | p: 8.333 | r: 8.824
rougeL     | fm: 47.222 | p: 45.946 | r: 48.571
rougeLsum  | fm: 47.222 | p: 45.946 | r: 48.571
r1fm+r2fm = 83.571

[Aggregate metrics]:
rouge1     | fm: 86.713 | p: 85.816 | r: 87.863
rouge2     | fm: 47.183 | p: 46.856 | r: 47.667
rougeL     | fm: 73.818 | p: 73.072 | r: 74.616
rougeLsum  | fm: 73.863 | p: 73.226 | r: 74.677
r1fm+r2fm = 133.896

input #35 time: 0:10:58 | total time: 6:26:14


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9512891173362732 for ['[CLS] welcomedating blue imperial [SEP]']
[Init] best rec loss: 0.9258654713630676 for ['[CLS] alpha twin yodan [SEP]']
[Init] best rec loss: 0.9236786961555481 for ['[CLS] respective gears rich nominee [SEP]']
[Init] best rec loss: 0.9190601706504822 for ['[CLS] playgiving examplettle [SEP]']
[Init] best perm rec loss: 0.9181972146034241 for ['[CLS]giving example playttle [SEP]']
[Init] best perm rec loss: 0.9161955118179321 for ['[CLS]givingttle play example [SEP]']
[Init] best perm rec loss: 0.9151216745376587 for ['[CLS] examplettle playgiving [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.307 (perp=8.845, rec=0.539), tot_loss_proj:2.692 [t=0.25s]
prediction: ['[CLS] wrong wrong wrong wrong [SEP]']
[ 100/2000] tot_loss=2.625 (perp=10.355, rec=0.554), tot_loss_proj:3.008 [t=0.26s]
prediction: ['[CLS] aback wrong wrong wrong [SEP]']
[ 150/2000] tot_loss=2.444 (perp=10.048, rec=0.434), tot_loss_proj:2.817 [t=0.24s]
prediction: ['[CLS] wrong wrong horribly wrong [SEP]']
[ 200/2000] tot_loss=2.388 (perp=10.048, rec=0.378), tot_loss_proj:2.833 [t=0.25s]
prediction: ['[CLS] wrong wrong horribly wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.205 (perp=9.261, rec=0.353), tot_loss_proj:2.469 [t=0.24s]
prediction: ["[CLS]'wrong horribly wrong [SEP]"]
[ 300/2000] tot_loss=3.574 (perp=15.151, rec=0.544), tot_loss_proj:3.902 [t=0.27s]
prediction: ['[CLS] michaels wrong horribly afraid [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.576 (perp=11.058, rec=0.364), tot_loss_proj:3.079 [t=0.24s]
prediction: ['[CLS] knew wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.500 (perp=10.910, rec=0.318), tot_loss_proj:2.991 [t=0.25s]
prediction: ['[CLS]holes wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=2.490 (perp=10.910, rec=0.308), tot_loss_proj:2.985 [t=0.26s]
prediction: ['[CLS]holes wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.485 (perp=10.910, rec=0.303), tot_loss_proj:2.984 [t=0.26s]
prediction: ['[CLS]holes wrong horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.437 (perp=10.712, rec=0.294), tot_loss_proj:2.910 [t=0.24s]
prediction: ['[CLS]hood wrong horribly wrong [SEP]']
[ 600/2000] tot_loss=2.858 (perp=12.789, rec=0.300), tot_loss_proj:3.029 [t=0.26s]
prediction: ['[CLS]hoodlin horribly wrong [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.653 (perp=11.711, rec=0.310), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS]urityhood horribly wrong [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.042 (perp=13.727, rec=0.296), tot_loss_proj:3.311 [t=0.25s]
prediction: ['[CLS]lausholes horribly wrong [SEP]']
[ 750/2000] tot_loss=3.030 (perp=13.727, rec=0.285), tot_loss_proj:3.307 [t=0.24s]
prediction: ['[CLS]lausholes horribly wrong [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.697 (perp=12.035, rec=0.290), tot_loss_proj:3.261 [t=0.25s]
prediction: ['[CLS]holeslaus horribly wrong [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.636 (perp=11.737, rec=0.288), tot_loss_proj:3.203 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[ 900/2000] tot_loss=2.634 (perp=11.737, rec=0.286), tot_loss_proj:3.196 [t=0.27s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.629 (perp=11.737, rec=0.281), tot_loss_proj:3.197 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1000/2000] tot_loss=2.634 (perp=11.737, rec=0.286), tot_loss_proj:3.197 [t=0.26s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1050/2000] tot_loss=2.631 (perp=11.737, rec=0.283), tot_loss_proj:3.196 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1100/2000] tot_loss=2.632 (perp=11.737, rec=0.284), tot_loss_proj:3.203 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1150/2000] tot_loss=2.617 (perp=11.737, rec=0.270), tot_loss_proj:3.204 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1200/2000] tot_loss=2.623 (perp=11.737, rec=0.276), tot_loss_proj:3.202 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1250/2000] tot_loss=2.618 (perp=11.737, rec=0.271), tot_loss_proj:3.203 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1300/2000] tot_loss=2.623 (perp=11.737, rec=0.275), tot_loss_proj:3.201 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1350/2000] tot_loss=2.629 (perp=11.737, rec=0.282), tot_loss_proj:3.207 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1400/2000] tot_loss=2.629 (perp=11.737, rec=0.282), tot_loss_proj:3.195 [t=0.27s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1450/2000] tot_loss=2.629 (perp=11.737, rec=0.281), tot_loss_proj:3.199 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1500/2000] tot_loss=2.626 (perp=11.737, rec=0.278), tot_loss_proj:3.202 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1550/2000] tot_loss=2.624 (perp=11.737, rec=0.276), tot_loss_proj:3.193 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1600/2000] tot_loss=2.610 (perp=11.737, rec=0.262), tot_loss_proj:3.196 [t=0.26s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1650/2000] tot_loss=2.619 (perp=11.737, rec=0.271), tot_loss_proj:3.198 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1700/2000] tot_loss=2.629 (perp=11.737, rec=0.282), tot_loss_proj:3.199 [t=0.27s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1750/2000] tot_loss=2.616 (perp=11.737, rec=0.269), tot_loss_proj:3.198 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1800/2000] tot_loss=2.624 (perp=11.737, rec=0.276), tot_loss_proj:3.199 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1850/2000] tot_loss=2.624 (perp=11.737, rec=0.277), tot_loss_proj:3.202 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[1900/2000] tot_loss=2.624 (perp=11.737, rec=0.277), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
[1950/2000] tot_loss=2.627 (perp=11.737, rec=0.279), tot_loss_proj:3.196 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Attempt swap
[2000/2000] tot_loss=2.631 (perp=11.737, rec=0.283), tot_loss_proj:3.199 [t=0.25s]
prediction: ['[CLS] dismisslaus horribly wrong [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] dismisslaus horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 86.352 | p: 85.468 | r: 87.499
rouge2     | fm: 47.189 | p: 46.859 | r: 47.608
rougeL     | fm: 74.106 | p: 73.399 | r: 74.877
rougeLsum  | fm: 73.865 | p: 73.218 | r: 74.672
r1fm+r2fm = 133.541

input #36 time: 0:10:37 | total time: 6:36:52


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.6566961407661438 for ['[CLS] billion central [SEP]']
[Init] best rec loss: 0.647363543510437 for ['[CLS] ric ken [SEP]']
[Init] best rec loss: 0.6428074240684509 for ['[CLS] take mass [SEP]']
[Init] best rec loss: 0.641491711139679 for ['[CLS] both mn [SEP]']
[Init] best rec loss: 0.6225078701972961 for ['[CLS] oak over [SEP]']
[Init] best rec loss: 0.5840350985527039 for ['[CLS] stay legacy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.083 (perp=9.583, rec=0.166), tot_loss_proj:2.001 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 100/2000] tot_loss=2.001 (perp=9.583, rec=0.084), tot_loss_proj:2.000 [t=0.28s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=1.985 (perp=9.583, rec=0.068), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.970 (perp=9.583, rec=0.054), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.904 (perp=8.917, rec=0.121), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=1.852 (perp=8.917, rec=0.069), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.865 (perp=8.917, rec=0.082), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.857 (perp=8.917, rec=0.073), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=1.849 (perp=8.917, rec=0.066), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.840 (perp=8.917, rec=0.057), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.839 (perp=8.917, rec=0.056), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=1.847 (perp=8.917, rec=0.064), tot_loss_proj:1.969 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.853 (perp=8.917, rec=0.070), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.843 (perp=8.917, rec=0.060), tot_loss_proj:1.976 [t=0.29s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=1.845 (perp=8.917, rec=0.062), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.843 (perp=8.917, rec=0.060), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.846 (perp=8.917, rec=0.062), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=1.829 (perp=8.917, rec=0.046), tot_loss_proj:1.969 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.860 (perp=8.917, rec=0.077), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=1.856 (perp=8.917, rec=0.073), tot_loss_proj:1.964 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=1.856 (perp=8.917, rec=0.073), tot_loss_proj:1.965 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.851 (perp=8.917, rec=0.068), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.858 (perp=8.917, rec=0.075), tot_loss_proj:1.959 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=1.834 (perp=8.917, rec=0.051), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=1.851 (perp=8.917, rec=0.068), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.853 (perp=8.917, rec=0.070), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=1.848 (perp=8.917, rec=0.064), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=1.849 (perp=8.917, rec=0.066), tot_loss_proj:1.971 [t=0.27s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=1.851 (perp=8.917, rec=0.068), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=1.836 (perp=8.917, rec=0.052), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=1.844 (perp=8.917, rec=0.061), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=1.841 (perp=8.917, rec=0.057), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=1.848 (perp=8.917, rec=0.065), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=1.870 (perp=8.917, rec=0.086), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=1.838 (perp=8.917, rec=0.055), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=1.854 (perp=8.917, rec=0.071), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.859 (perp=8.917, rec=0.076), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.847 (perp=8.917, rec=0.064), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=1.855 (perp=8.917, rec=0.072), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.858 (perp=8.917, rec=0.074), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.837 | p: 85.926 | r: 87.975
rouge2     | fm: 48.609 | p: 48.308 | r: 48.986
rougeL     | fm: 74.796 | p: 74.129 | r: 75.702
rougeLsum  | fm: 74.766 | p: 74.109 | r: 75.615
r1fm+r2fm = 135.446

input #37 time: 0:10:38 | total time: 6:47:30


Running input #38 of 100.
reference: 
========================
scare 
========================
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8319668173789978 for ['[CLS] to [SEP]']
[Init] best rec loss: 0.7429853677749634 for ['[CLS] help [SEP]']
[Init] best rec loss: 0.6312496662139893 for ['[CLS] shortly [SEP]']
[Init] best rec loss: 0.6156878471374512 for ['[CLS] by [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.914 (perp=14.070, rec=0.100), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.881 (perp=14.070, rec=0.067), tot_loss_proj:2.879 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.880 (perp=14.070, rec=0.066), tot_loss_proj:2.869 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.880 (perp=14.070, rec=0.066), tot_loss_proj:2.866 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.869 (perp=14.070, rec=0.055), tot_loss_proj:2.871 [t=0.31s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.880 (perp=14.070, rec=0.066), tot_loss_proj:2.892 [t=0.31s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.870 (perp=14.070, rec=0.056), tot_loss_proj:2.869 [t=0.31s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.861 (perp=14.070, rec=0.047), tot_loss_proj:2.870 [t=0.32s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.866 (perp=14.070, rec=0.052), tot_loss_proj:2.873 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.872 (perp=14.070, rec=0.058), tot_loss_proj:2.879 [t=0.34s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.878 (perp=14.070, rec=0.064), tot_loss_proj:2.879 [t=0.33s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.874 (perp=14.070, rec=0.060), tot_loss_proj:2.875 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.866 (perp=14.070, rec=0.052), tot_loss_proj:2.871 [t=0.31s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.877 (perp=14.070, rec=0.063), tot_loss_proj:2.877 [t=0.32s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.876 (perp=14.070, rec=0.062), tot_loss_proj:2.866 [t=0.36s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.879 (perp=14.070, rec=0.065), tot_loss_proj:2.876 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.863 (perp=14.070, rec=0.049), tot_loss_proj:2.878 [t=0.32s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.878 (perp=14.070, rec=0.064), tot_loss_proj:2.871 [t=0.33s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.869 (perp=14.070, rec=0.055), tot_loss_proj:2.879 [t=0.31s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.868 (perp=14.070, rec=0.054), tot_loss_proj:2.879 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.870 (perp=14.070, rec=0.056), tot_loss_proj:2.876 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.888 (perp=14.070, rec=0.074), tot_loss_proj:2.864 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.876 (perp=14.070, rec=0.062), tot_loss_proj:2.858 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.872 (perp=14.070, rec=0.058), tot_loss_proj:2.877 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.866 (perp=14.070, rec=0.052), tot_loss_proj:2.871 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.874 (perp=14.070, rec=0.060), tot_loss_proj:2.862 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.868 (perp=14.070, rec=0.054), tot_loss_proj:2.880 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.869 (perp=14.070, rec=0.055), tot_loss_proj:2.876 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.875 (perp=14.070, rec=0.061), tot_loss_proj:2.882 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.871 (perp=14.070, rec=0.057), tot_loss_proj:2.874 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.861 (perp=14.070, rec=0.046), tot_loss_proj:2.868 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.864 (perp=14.070, rec=0.050), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.869 (perp=14.070, rec=0.055), tot_loss_proj:2.888 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.873 (perp=14.070, rec=0.059), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.866 (perp=14.070, rec=0.052), tot_loss_proj:2.881 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.885 (perp=14.070, rec=0.071), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.877 (perp=14.070, rec=0.063), tot_loss_proj:2.875 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.879 (perp=14.070, rec=0.064), tot_loss_proj:2.871 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.873 (perp=14.070, rec=0.059), tot_loss_proj:2.873 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.868 (perp=14.070, rec=0.054), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.145 | p: 86.326 | r: 88.218
rouge2     | fm: 50.058 | p: 49.735 | r: 50.389
rougeL     | fm: 75.413 | p: 74.788 | r: 76.271
rougeLsum  | fm: 75.356 | p: 74.792 | r: 76.112
r1fm+r2fm = 137.203

input #38 time: 0:11:56 | total time: 6:59:27


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8076609373092651 for ['[CLS] organizing of galleries hon 2000scribe assurance depositus lange grantsimeters closer keel changed with occasional university alta stories assignment 8 roughly accessible land [SEP]']
[Init] best rec loss: 0.7867798209190369 for ['[CLS] its outletgenic ds required resource us selected naia men governancegor attack root arc ring bureau women lost this commandant 4 plain he alcohol [SEP]']
[Init] best rec loss: 0.7608112692832947 for ['[CLS] not muscle unfortunatelyats phantomack onside request what roster reversed deep fully pacifictila window " persona sin leicester cross swift territory ax [SEP]']
[Init] best rec loss: 0.7388769388198853 for ['[CLS] undisclosed viewer cigarettes time wreck amateur exceptgrmont wind decision harvey earthplex accident immune program funny orbittory more at occurrencefide ledge [SEP]']
[Init] best perm rec loss: 0.7372371554374695 for ['[CLS] viewer harvey time ledgetory immunemont exceptplex decision program funnygr at earth cigarettes accident wind wreck more undisclosed occurrencefide amateur orbit [SEP]']
[Init] best perm rec loss: 0.7371764779090881 for ['[CLS] wreck earthtoryfide timegr occurrenceplex immune harvey more decisionmont program orbit ledge funny undisclosed viewer accident except amateur at cigarettes wind [SEP]']
[Init] best perm rec loss: 0.7371764183044434 for ['[CLS] amateur undisclosedplex harvey program time at occurrence immune cigarettes ledge earthmont orbittory viewer funny wreck exceptgr decision wind accident morefide [SEP]']
[Init] best perm rec loss: 0.7370396256446838 for ['[CLS]tory accident wreck more amateur at programfide immune earthmontplex decision ledge funnygr cigarettes orbit occurrence wind undisclosed harvey viewer except time [SEP]']
[Init] best perm rec loss: 0.735870361328125 for ['[CLS]mont cigarettes time immunegr occurrence except at wreck earth undisclosed orbit amateur funnyfide program harvey wind accident decision more viewerplextory ledge [SEP]']
[Init] best perm rec loss: 0.7345179319381714 for ['[CLS] except accident earth wreck harvey ledge program immunegr undisclosed cigarettes amateur wind moretory funny orbitfideplex at occurrence time decisionmont viewer [SEP]']
[Init] best perm rec loss: 0.7344900965690613 for ['[CLS] time at program funny ledge except wreck cigarettestorygr viewerfide more undisclosed wind accidentmont amateur earth immune occurrenceplex harvey decision orbit [SEP]']
[Init] best perm rec loss: 0.7338985800743103 for ['[CLS] undisclosed excepttorymont wreck accident at harveygr cigarettes earth amateur ledge more orbitfide funny immune viewer timeplex program wind occurrence decision [SEP]']
[Init] best perm rec loss: 0.732917070388794 for ['[CLS] cigarettes funny ledge viewer wreck accident orbit harveymont program occurrencefide wind immunegrplex earth time amateurtory decision except more at undisclosed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.504 (perp=11.143, rec=0.275), tot_loss_proj:2.906 [t=0.30s]
prediction: ['[CLS] independentness hadley of incumbent jack reality blow writer genus conservative grace village conservative texture toward new discovers reputation variety new conservative new texture. [SEP]']
[ 100/2000] tot_loss=2.204 (perp=10.050, rec=0.194), tot_loss_proj:2.740 [t=0.30s]
prediction: ['[CLS] hideplane hide most finds back tradition hide movie grove conservative texture alone, texture and new gives reality texture, hide new texture and [SEP]']
[ 150/2000] tot_loss=2.050 (perp=9.516, rec=0.147), tot_loss_proj:2.590 [t=0.36s]
prediction: ['[CLS] hidetitled hide our finds here traditions hidebound traditions conservative most, and texture it new gives reality reality, hide new texture and [SEP]']
[ 200/2000] tot_loss=2.130 (perp=10.119, rec=0.107), tot_loss_proj:2.659 [t=0.36s]
prediction: ['[CLS] hideboundbound our finds sustained traditions hidebound traditions conservative most, and texture it new gives reality relevance, hide new reality and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.055 (perp=9.780, rec=0.099), tot_loss_proj:2.538 [t=0.33s]
prediction: ['[CLS] hide one one our findsbound traditions hidebound traditions conservative most of and texture it new gives reality relevance,bound new reality and [SEP]']
[ 300/2000] tot_loss=2.041 (perp=9.780, rec=0.084), tot_loss_proj:2.537 [t=0.39s]
prediction: ['[CLS] hide one one our findsbound traditions hidebound traditions conservative most of and texture it new gives reality relevance,bound new reality and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.893 (perp=9.073, rec=0.079), tot_loss_proj:2.350 [t=0.38s]
prediction: ['[CLS] hide one - our findsbound traditions hidebound traditions conservative most of gives texture it new and reality relevance,bound new reality and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.859 (perp=8.903, rec=0.078), tot_loss_proj:2.356 [t=0.30s]
prediction: ['[CLS] hide one - our findsbound traditions hidebound traditions conservative most of gives texture it and new reality relevance,bound new reality and [SEP]']
[ 450/2000] tot_loss=1.863 (perp=8.903, rec=0.082), tot_loss_proj:2.348 [t=0.40s]
prediction: ['[CLS] hide one - our findsbound traditions hidebound traditions conservative most of gives texture it and new reality relevance,bound new reality and [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.800 (perp=8.637, rec=0.073), tot_loss_proj:2.240 [t=0.38s]
prediction: ['[CLS] one - our finds hidebound traditions hidebound movie conservative most, gives texture it and new reality relevance,bound new reality and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.716 (perp=8.175, rec=0.080), tot_loss_proj:2.124 [t=0.32s]
prediction: ['[CLS] most movie our finds hidebound traditions hidebound movie conservative one. gives texture it and new reality relevance,bound new reality and [SEP]']
[ 600/2000] tot_loss=1.722 (perp=8.175, rec=0.087), tot_loss_proj:2.127 [t=0.33s]
prediction: ['[CLS] most movie our finds hidebound traditions hidebound movie conservative one. gives texture it and new reality relevance,bound new reality and [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.685 (perp=8.037, rec=0.077), tot_loss_proj:2.069 [t=0.42s]
prediction: ['[CLS] most movie our finds hidebound traditions hidebound movie conservative one. gives it and texture new reality relevance,bound new reality and [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.620 (perp=7.753, rec=0.070), tot_loss_proj:2.001 [t=0.29s]
prediction: ['[CLS] most movie our finds hidebound traditions hidebound movie conservative one. gives it texture and new reality relevance,bound new reality and [SEP]']
[ 750/2000] tot_loss=1.620 (perp=7.753, rec=0.069), tot_loss_proj:2.004 [t=0.29s]
prediction: ['[CLS] most movie our finds hidebound traditions hidebound movie conservative one. gives it texture and new reality relevance,bound new reality and [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.612 (perp=7.737, rec=0.064), tot_loss_proj:2.006 [t=0.33s]
prediction: ['[CLS] most movie our finds hidebound traditions hidebound one conservative movie. gives it texture and new reality relevance,bound new reality and [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.822 (perp=8.098, rec=0.202), tot_loss_proj:2.096 [t=0.31s]
prediction: ['[CLS] most movie our finds hide - traditions hidebound one conservative movie. gives it texture and reality new relevance,bound new reality and [SEP]']
[ 900/2000] tot_loss=1.745 (perp=8.098, rec=0.125), tot_loss_proj:2.067 [t=0.31s]
prediction: ['[CLS] most movie our finds hide - traditions hidebound one conservative movie. gives it texture and reality new relevance,bound new reality and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.685 (perp=7.863, rec=0.112), tot_loss_proj:2.050 [t=0.27s]
prediction: ['[CLS] most finds our movie hide - traditions hidebound one conservative movie. gives it texture and reality new relevance,bound new reality and [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.595 (perp=7.449, rec=0.106), tot_loss_proj:1.931 [t=0.28s]
prediction: ['[CLS] most finds our movie hidebound traditions hidebound one conservative movie. gives it texture and reality new relevance, - new reality and [SEP]']
[1050/2000] tot_loss=1.585 (perp=7.449, rec=0.095), tot_loss_proj:1.935 [t=0.33s]
prediction: ['[CLS] most finds our movie hidebound traditions hidebound one conservative movie. gives it texture and reality new relevance, - new reality and [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.588 (perp=7.434, rec=0.102), tot_loss_proj:2.048 [t=0.29s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality new relevance, - new reality and [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.553 (perp=7.283, rec=0.096), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality new relevance, - and new reality [SEP]']
[1200/2000] tot_loss=1.545 (perp=7.283, rec=0.088), tot_loss_proj:2.020 [t=0.27s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality new relevance, - and new reality [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.516 (perp=7.171, rec=0.081), tot_loss_proj:2.068 [t=0.26s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality, new relevance - and new reality [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.517 (perp=7.146, rec=0.088), tot_loss_proj:2.038 [t=0.27s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
[1350/2000] tot_loss=1.506 (perp=7.146, rec=0.077), tot_loss_proj:2.041 [t=0.27s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
[1400/2000] tot_loss=1.506 (perp=7.146, rec=0.077), tot_loss_proj:2.039 [t=0.26s]
prediction: ['[CLS] most finds our movie ofbound traditions hide making one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.489 (perp=7.016, rec=0.086), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] most finds our movie of making traditions hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
[1500/2000] tot_loss=1.490 (perp=7.016, rec=0.086), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] most finds our movie of making traditions hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.412 (perp=6.648, rec=0.082), tot_loss_proj:1.747 [t=0.28s]
prediction: ['[CLS] most finds our movie of traditions making hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.375 (perp=6.502, rec=0.075), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
[1650/2000] tot_loss=1.379 (perp=6.502, rec=0.079), tot_loss_proj:1.807 [t=0.26s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
[1700/2000] tot_loss=1.381 (perp=6.502, rec=0.081), tot_loss_proj:1.810 [t=0.25s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
[1750/2000] tot_loss=1.382 (perp=6.502, rec=0.082), tot_loss_proj:1.806 [t=0.27s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
[1800/2000] tot_loss=1.380 (perp=6.502, rec=0.080), tot_loss_proj:1.803 [t=0.26s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality - and new relevance [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.370 (perp=6.463, rec=0.078), tot_loss_proj:1.824 [t=0.27s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality and new relevance - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.377 (perp=6.463, rec=0.084), tot_loss_proj:1.820 [t=0.26s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality and new relevance - [SEP]']
[1950/2000] tot_loss=1.373 (perp=6.463, rec=0.081), tot_loss_proj:1.822 [t=0.26s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality and new relevance - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.368 (perp=6.463, rec=0.075), tot_loss_proj:1.822 [t=0.26s]
prediction: ['[CLS] most finds our traditions of movie making hidebound one conservative movie. it gives texture and reality, new reality and new relevance - [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] most movie our finds hidebound traditions hidebound one conservative movie. gives it texture and new reality relevance,bound new reality and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 82.609 | r: 86.364
rouge2     | fm: 9.302 | p: 9.091 | r: 9.524
rougeL     | fm: 57.778 | p: 56.522 | r: 59.091
rougeLsum  | fm: 57.778 | p: 56.522 | r: 59.091
r1fm+r2fm = 93.747

[Aggregate metrics]:
rouge1     | fm: 87.110 | p: 86.171 | r: 88.184
rouge2     | fm: 49.100 | p: 48.791 | r: 49.451
rougeL     | fm: 74.966 | p: 74.272 | r: 75.798
rougeLsum  | fm: 74.953 | p: 74.279 | r: 75.688
r1fm+r2fm = 136.209

input #39 time: 0:12:12 | total time: 7:11:40


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.8993424773216248 for ['[CLS] rule requested example willjured drawing walk swing widened [SEP]']
[Init] best rec loss: 0.886311411857605 for ['[CLS] located wilde treatments childhood zane nearest nathan owing fame [SEP]']
[Init] best rec loss: 0.8738450407981873 for ['[CLS] knockmity preparation returned dr mvp dark nationality currency [SEP]']
[Init] best rec loss: 0.8721039295196533 for ['[CLS]fed rope romans plank openmu greatest because unconscious [SEP]']
[Init] best rec loss: 0.8562676310539246 for ['[CLS]icide means books crush comics lucas fireplace rebel footage [SEP]']
[Init] best rec loss: 0.8545941710472107 for ['[CLS] patch extended ranked located note rocket lying riseame [SEP]']
[Init] best rec loss: 0.8419208526611328 for ['[CLS] also yearsgies sorryyu directlyless doesn halifax [SEP]']
[Init] best rec loss: 0.800959050655365 for ['[CLS] tenure imagine conclusion operationled seth serena fields urban [SEP]']
[Init] best rec loss: 0.7922850847244263 for ['[CLS] message recent snowthe witch pri rods zealand own [SEP]']
[Init] best perm rec loss: 0.7914116382598877 for ['[CLS] witch rods snowthe zealand message recent own pri [SEP]']
[Init] best perm rec loss: 0.7909349799156189 for ['[CLS] zealand messagethe rods witch pri recent snow own [SEP]']
[Init] best perm rec loss: 0.7878603339195251 for ['[CLS] recent message own witch rodsthe snow pri zealand [SEP]']
[Init] best perm rec loss: 0.7874317169189453 for ['[CLS] rods witch pri messagethe snow own recent zealand [SEP]']
[Init] best perm rec loss: 0.7872114181518555 for ['[CLS] message witch ownthe pri snow rods recent zealand [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.745 (perp=12.307, rec=0.283), tot_loss_proj:3.023 [t=0.24s]
prediction: ['[CLS] [UNK] hurt phony imagery bloodymmelmmel inhabitants [SEP]']
[ 100/2000] tot_loss=2.682 (perp=12.553, rec=0.172), tot_loss_proj:3.007 [t=0.25s]
prediction: ['[CLS] pummel phony imageryonymmelmmel music [SEP]']
[ 150/2000] tot_loss=2.315 (perp=10.945, rec=0.126), tot_loss_proj:2.682 [t=0.25s]
prediction: ['[CLS] pu with phony imageryonymmelmmel us [SEP]']
[ 200/2000] tot_loss=2.272 (perp=10.904, rec=0.091), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] pu with phony imageryonymmel or us [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.748 (perp=8.296, rec=0.089), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS]ony with phony imagery pummel or us [SEP]']
[ 300/2000] tot_loss=1.734 (perp=8.296, rec=0.074), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS]ony with phony imagery pummel or us [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.683 (perp=8.037, rec=0.075), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.037, rec=0.073), tot_loss_proj:1.989 [t=0.25s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
[ 450/2000] tot_loss=1.678 (perp=8.037, rec=0.071), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=8.037, rec=0.072), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.684 (perp=8.037, rec=0.077), tot_loss_proj:1.990 [t=0.26s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
[ 600/2000] tot_loss=1.691 (perp=8.037, rec=0.084), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.681 (perp=8.037, rec=0.074), tot_loss_proj:1.985 [t=0.27s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.689 (perp=8.037, rec=0.081), tot_loss_proj:1.984 [t=0.27s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
[ 750/2000] tot_loss=1.681 (perp=8.037, rec=0.074), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.682 (perp=8.037, rec=0.075), tot_loss_proj:1.982 [t=0.32s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.685 (perp=8.037, rec=0.077), tot_loss_proj:1.983 [t=0.27s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
[ 900/2000] tot_loss=1.691 (perp=8.037, rec=0.084), tot_loss_proj:1.987 [t=0.29s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.677 (perp=8.037, rec=0.070), tot_loss_proj:1.987 [t=0.27s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[1000/2000] tot_loss=1.675 (perp=8.037, rec=0.067), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
[1050/2000] tot_loss=1.676 (perp=8.037, rec=0.068), tot_loss_proj:1.983 [t=0.28s]
prediction: ['[CLS]ony with phony imagery pummel us or [SEP]']
Attempt swap
[1100/2000] tot_loss=1.618 (perp=7.741, rec=0.070), tot_loss_proj:1.834 [t=0.28s]
prediction: ['[CLS] music with phony imagery pummel us or [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.569 (perp=7.469, rec=0.075), tot_loss_proj:1.781 [t=0.28s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
[1200/2000] tot_loss=1.570 (perp=7.469, rec=0.077), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1250/2000] tot_loss=1.567 (perp=7.469, rec=0.073), tot_loss_proj:1.788 [t=0.25s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=7.469, rec=0.069), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
[1350/2000] tot_loss=1.565 (perp=7.469, rec=0.072), tot_loss_proj:1.789 [t=0.26s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1400/2000] tot_loss=1.555 (perp=7.469, rec=0.061), tot_loss_proj:1.791 [t=0.27s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1450/2000] tot_loss=1.565 (perp=7.469, rec=0.071), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
[1500/2000] tot_loss=1.561 (perp=7.469, rec=0.068), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1550/2000] tot_loss=1.568 (perp=7.469, rec=0.074), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1600/2000] tot_loss=1.561 (perp=7.469, rec=0.067), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
[1650/2000] tot_loss=1.563 (perp=7.469, rec=0.069), tot_loss_proj:1.787 [t=0.26s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.469, rec=0.067), tot_loss_proj:1.782 [t=0.28s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1750/2000] tot_loss=1.557 (perp=7.469, rec=0.063), tot_loss_proj:1.786 [t=0.25s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
[1800/2000] tot_loss=1.558 (perp=7.469, rec=0.064), tot_loss_proj:1.792 [t=0.26s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1850/2000] tot_loss=1.560 (perp=7.469, rec=0.066), tot_loss_proj:1.791 [t=0.27s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[1900/2000] tot_loss=1.564 (perp=7.469, rec=0.070), tot_loss_proj:1.797 [t=0.27s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.469, rec=0.071), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.469, rec=0.063), tot_loss_proj:1.791 [t=0.27s]
prediction: ['[CLS] imagery with phony music pummel us or [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery with phony music pummel us or [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 87.394 | p: 86.514 | r: 88.462
rouge2     | fm: 48.489 | p: 48.175 | r: 48.806
rougeL     | fm: 74.511 | p: 73.893 | r: 75.338
rougeLsum  | fm: 74.435 | p: 73.744 | r: 75.224
r1fm+r2fm = 135.884

input #40 time: 0:10:51 | total time: 7:22:32


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9198132157325745 for ['[CLS]hos missed [SEP]']
[Init] best rec loss: 0.9029814600944519 for ['[CLS] college loop [SEP]']
[Init] best rec loss: 0.8910801410675049 for ['[CLS] judge civil [SEP]']
[Init] best rec loss: 0.8768140077590942 for ['[CLS] anniversary an [SEP]']
[Init] best rec loss: 0.8762954473495483 for ['[CLS]time can [SEP]']
[Init] best rec loss: 0.8644786477088928 for ['[CLS] we usual [SEP]']
[Init] best rec loss: 0.8602614998817444 for ['[CLS] heritage remembered [SEP]']
[Init] best rec loss: 0.8392252326011658 for ['[CLS] student transfer [SEP]']
[Init] best rec loss: 0.8382719159126282 for ['[CLS] gr home [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.435 (perp=9.391, rec=0.557), tot_loss_proj:2.748 [t=0.26s]
prediction: ['[CLS] sensitive sensitive [SEP]']
[ 100/2000] tot_loss=2.494 (perp=10.212, rec=0.452), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.468 (perp=10.212, rec=0.426), tot_loss_proj:2.109 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.395 (perp=10.212, rec=0.353), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.382 (perp=10.212, rec=0.339), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.344 (perp=10.212, rec=0.301), tot_loss_proj:2.097 [t=0.35s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.582 (perp=10.212, rec=0.540), tot_loss_proj:2.147 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.412 (perp=10.212, rec=0.370), tot_loss_proj:2.140 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.398 (perp=10.212, rec=0.356), tot_loss_proj:2.125 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.350 (perp=10.212, rec=0.307), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.343 (perp=10.212, rec=0.301), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.337 (perp=10.212, rec=0.295), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.332 (perp=10.212, rec=0.290), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.334 (perp=10.212, rec=0.292), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.321 (perp=10.212, rec=0.279), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.324 (perp=10.212, rec=0.282), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.323 (perp=10.212, rec=0.281), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.319 (perp=10.212, rec=0.277), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.315 (perp=10.212, rec=0.272), tot_loss_proj:2.101 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.333 (perp=10.212, rec=0.291), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.306 (perp=10.212, rec=0.263), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.319 (perp=10.212, rec=0.277), tot_loss_proj:2.108 [t=0.33s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.312 (perp=10.212, rec=0.269), tot_loss_proj:2.111 [t=0.32s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.341 (perp=10.212, rec=0.298), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.313 (perp=10.212, rec=0.270), tot_loss_proj:2.104 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.310 (perp=10.212, rec=0.268), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.310 (perp=10.212, rec=0.268), tot_loss_proj:2.122 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.308 (perp=10.212, rec=0.266), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.309 (perp=10.212, rec=0.267), tot_loss_proj:2.112 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.307 (perp=10.212, rec=0.265), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.308 (perp=10.212, rec=0.266), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.310 (perp=10.212, rec=0.268), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.304 (perp=10.212, rec=0.261), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.312 (perp=10.212, rec=0.269), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.306 (perp=10.212, rec=0.264), tot_loss_proj:2.110 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.306 (perp=10.212, rec=0.264), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.294 (perp=10.212, rec=0.252), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.301 (perp=10.212, rec=0.259), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.304 (perp=10.212, rec=0.261), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.305 (perp=10.212, rec=0.263), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.682 | p: 86.872 | r: 88.743
rouge2     | fm: 49.686 | p: 49.319 | r: 50.073
rougeL     | fm: 75.048 | p: 74.480 | r: 75.905
rougeLsum  | fm: 75.017 | p: 74.441 | r: 75.758
r1fm+r2fm = 137.368

input #41 time: 0:10:53 | total time: 7:33:26


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8463176488876343 for ['[CLS]usa cupnical two mall bryanlu line stated additiveund finalseptive cf tonight compilations commons later productrran maya move immigration customer [MASK] suicide [SEP]']
[Init] best rec loss: 0.7902936339378357 for ['[CLS] paris ref disasterdon buren tapping reynolds stab whichpala disabled nurseock weight po appointed thislter cia kit moments tough henderson nodded lu algebra [SEP]']
[Init] best rec loss: 0.7735471725463867 for ['[CLS] pluralposed neitherbeat interested wherever reality panamazong blame upside about outen glory gil : butt nfc faced driven miss ni shawn year halftime [SEP]']
[Init] best rec loss: 0.7651534080505371 for ['[CLS] during current bravouaries convent word feeling canada false funistic ct current hipsnant came tierabad aggressive apollo interest percival dock aggression permanently buren [SEP]']
[Init] best rec loss: 0.7363600730895996 for ['[CLS] green dealt bumps course been gentry rot mor torada account interest requiem / sports drummer string lift ashes network usa loop singles swimming det beside [SEP]']
[Init] best perm rec loss: 0.7347625494003296 for ['[CLS] drummer to interest lift been rot network beside swimming gentry det green course ashes mor account bumps dealt sports requiem looprada / usa string singles [SEP]']
[Init] best perm rec loss: 0.7340461611747742 for ['[CLS] to been string loop account sports gentry usa rot network drummer green detrada mor lift singles / bumps course dealt swimming requiem beside interest ashes [SEP]']
[Init] best perm rec loss: 0.7320809960365295 for ['[CLS] usa beside sports swimming mor to green account det rot singles interest drummer requiem ashes loop bumps network course lift / gentry string dealtrada been [SEP]']
[Init] best perm rec loss: 0.7316582798957825 for ['[CLS] bumps green drummer network interest det requiem been lift singles to usa dealt string mor beside account course sports ashes gentry / swimming rot looprada [SEP]']
[Init] best perm rec loss: 0.7307032346725464 for ['[CLS]rada to det gentry dealt bumps green been / beside mor interest singles swimming drummer sports account course lift loop rot usa requiem ashes network string [SEP]']
[Init] best perm rec loss: 0.7300533652305603 for ['[CLS] bumps account det dealt singles swimming green requiem lift course interest gentry / usa mor beside stringrada sports loop rot ashes been drummer to network [SEP]']
[Init] best perm rec loss: 0.7297850847244263 for ['[CLS] / dealt sports lift rot interest gentry requiemrada course ashes string green been det mor drummer account singles usa swimming loop beside to network bumps [SEP]']
[Init] best perm rec loss: 0.7292649149894714 for ['[CLS] to mor / beside gentry requiem account interest rot string dealt network been usa green swimmingrada drummer sports course det bumps lift singles loop ashes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.104 (perp=13.980, rec=0.308), tot_loss_proj:3.363 [t=0.26s]
prediction: ['[CLS] forgot radical forgot quite predator poorly team traffic amendment leaving dodged secured worst ruined suicide afterward no suitable was mistakes re typhoon poorly poorly poorly starring [SEP]']
[ 100/2000] tot_loss=2.818 (perp=12.974, rec=0.223), tot_loss_proj:3.152 [t=0.27s]
prediction: ['[CLS] forgot appendix forgot imp anything poorly program hospital forgot nothing dodged scary forgot lost re as no any they poorly re into millions forgot poorly setting [SEP]']
[ 150/2000] tot_loss=2.717 (perp=12.576, rec=0.202), tot_loss_proj:3.102 [t=0.27s]
prediction: ['[CLS] forgot hazardous forgot anything anything poorly filmmakers police anything covering dodged filmmakers forgot included scary as no anything they poorly re into conform forgot poorly setting [SEP]']
[ 200/2000] tot_loss=2.687 (perp=12.675, rec=0.152), tot_loss_proj:3.040 [t=0.29s]
prediction: ['[CLS] forgot scary forgotmobile anything poorly filmmaker a anything even projects filmmakers forgot includedgger as freak halfway they poorly re into school forgot poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.545 (perp=12.097, rec=0.126), tot_loss_proj:2.956 [t=0.25s]
prediction: ['[CLS] its scaryggerctable include poorly attraction to anything even forgot filmmakers forgot includedgger as freak halfway they poorly re into school forgot poorly setting [SEP]']
[ 300/2000] tot_loss=2.603 (perp=12.429, rec=0.118), tot_loss_proj:3.042 [t=0.27s]
prediction: ['[CLS] its scaryggerctable include poorly attraction to anything even forgot filmmakers forgot halfwaygger as freak halfway they poorly re into school forgot poorly setting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.520 (perp=12.075, rec=0.105), tot_loss_proj:2.915 [t=0.26s]
prediction: ['[CLS] its scaryggerctable poorly attraction to include anything even forgot filmmakers forgot halfwaygger asji halfway they poorly re into school forgot poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.415 (perp=11.576, rec=0.100), tot_loss_proj:2.860 [t=0.24s]
prediction: ['[CLS] itsjiggerbroken poorly attraction to include anything even forgot filmmakers forgot halfwaygger as scary halfway they poorly re into school forgot poorly setting [SEP]']
[ 450/2000] tot_loss=2.417 (perp=11.576, rec=0.101), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] itsjiggerbroken poorly attraction to include anything even forgot filmmakers forgot halfwaygger as scary halfway they poorly re into school forgot poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.345 (perp=11.245, rec=0.096), tot_loss_proj:2.800 [t=0.27s]
prediction: ['[CLS] itsjiggerbroken poorly attraction to include anything even forgot filmmakers forgot scarygger as halfway halfway they poorly re into school forgot poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.394 (perp=11.487, rec=0.097), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS] project scaryggerbroken poorly attraction to include anything even forgot filmmakers forgotjigger as halfway halfway theyji re into school fatal poorly setting [SEP]']
[ 600/2000] tot_loss=2.394 (perp=11.487, rec=0.097), tot_loss_proj:2.842 [t=0.25s]
prediction: ['[CLS] project scaryggerbroken poorly attraction to include anything even forgot filmmakers forgotjigger as halfway halfway theyji re into school fatal poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.327 (perp=11.190, rec=0.089), tot_loss_proj:2.785 [t=0.27s]
prediction: ['[CLS] project scarygger nedra poorly poorly to include anything even forgot filmmakers forgotjigger as halfway halfway theyji re into school fatal attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.200 (perp=10.584, rec=0.084), tot_loss_proj:2.654 [t=0.25s]
prediction: ['[CLS] project scarygger nedra poorly forgot to include anything even poorly filmmakers forgotjigger as halfway halfway theyji re into school fatal attraction setting [SEP]']
[ 750/2000] tot_loss=2.208 (perp=10.584, rec=0.091), tot_loss_proj:2.658 [t=0.27s]
prediction: ['[CLS] project scarygger nedra poorly forgot to include anything even poorly filmmakers forgotjigger as halfway halfway theyji re into school fatal attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.133 (perp=10.229, rec=0.087), tot_loss_proj:2.571 [t=0.25s]
prediction: ['[CLS] project scary re nedra poorly forgot to include anything even poorly filmmakers forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.059 (perp=9.870, rec=0.085), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] project scary filmmakers nedra poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
[ 900/2000] tot_loss=2.055 (perp=9.870, rec=0.081), tot_loss_proj:2.517 [t=0.26s]
prediction: ['[CLS] project scary filmmakers nedra poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.050 (perp=9.870, rec=0.076), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] project scary filmmakers nedra poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1000/2000] tot_loss=2.052 (perp=9.870, rec=0.078), tot_loss_proj:2.522 [t=0.28s]
prediction: ['[CLS] project scary filmmakers nedra poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
[1050/2000] tot_loss=2.056 (perp=9.870, rec=0.083), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] project scary filmmakers nedra poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.038 (perp=9.765, rec=0.085), tot_loss_proj:2.487 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1150/2000] tot_loss=2.030 (perp=9.765, rec=0.077), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
[1200/2000] tot_loss=2.025 (perp=9.765, rec=0.072), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1250/2000] tot_loss=2.034 (perp=9.765, rec=0.081), tot_loss_proj:2.487 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1300/2000] tot_loss=2.025 (perp=9.765, rec=0.072), tot_loss_proj:2.485 [t=0.30s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
[1350/2000] tot_loss=2.025 (perp=9.765, rec=0.072), tot_loss_proj:2.490 [t=0.35s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1400/2000] tot_loss=2.026 (perp=9.765, rec=0.073), tot_loss_proj:2.489 [t=0.27s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1450/2000] tot_loss=2.031 (perp=9.765, rec=0.078), tot_loss_proj:2.487 [t=0.25s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
[1500/2000] tot_loss=2.036 (perp=9.765, rec=0.083), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1550/2000] tot_loss=2.029 (perp=9.765, rec=0.076), tot_loss_proj:2.484 [t=0.25s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
[1600/2000] tot_loss=2.031 (perp=9.765, rec=0.078), tot_loss_proj:2.487 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
[1650/2000] tot_loss=2.030 (perp=9.765, rec=0.077), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger into school fatal attraction setting [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=2.018 (perp=9.693, rec=0.080), tot_loss_proj:2.463 [t=0.27s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger fatal attraction into school setting [SEP]']
Attempt swap
[1750/2000] tot_loss=2.015 (perp=9.693, rec=0.077), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger fatal attraction into school setting [SEP]']
[1800/2000] tot_loss=2.010 (perp=9.693, rec=0.072), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway halfway theyjigger fatal attraction into school setting [SEP]']
Attempt swap
[1850/2000] tot_loss=2.028 (perp=9.744, rec=0.079), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway fatal theyjigger fatal attraction into school setting [SEP]']
Attempt swap
[1900/2000] tot_loss=2.021 (perp=9.744, rec=0.072), tot_loss_proj:2.463 [t=0.25s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway fatal theyjigger fatal attraction into school setting [SEP]']
[1950/2000] tot_loss=2.018 (perp=9.744, rec=0.070), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway fatal theyjigger fatal attraction into school setting [SEP]']
Attempt swap
[2000/2000] tot_loss=2.034 (perp=9.744, rec=0.085), tot_loss_proj:2.469 [t=0.26s]
prediction: ['[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway fatal theyjigger fatal attraction into school setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] project nedra scary filmmakers poorly forgot to include anything even poorly re forgotjigger as halfway fatal theyjigger fatal attraction into school setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 34.783 | p: 34.783 | r: 34.783
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 109.783

[Aggregate metrics]:
rouge1     | fm: 87.434 | p: 86.636 | r: 88.457
rouge2     | fm: 49.352 | p: 49.092 | r: 49.695
rougeL     | fm: 74.848 | p: 74.314 | r: 75.521
rougeLsum  | fm: 74.671 | p: 74.150 | r: 75.430
r1fm+r2fm = 136.786

input #42 time: 0:11:07 | total time: 7:44:33


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.7825427651405334 for ['[CLS] dutton soup legaluance [SEP]']
[Init] best rec loss: 0.7587542533874512 for ['[CLS] to kira como contention [SEP]']
[Init] best rec loss: 0.7390246987342834 for ['[CLS] journals super lost night [SEP]']
[Init] best rec loss: 0.7164910435676575 for ['[CLS] oru eagle lit [SEP]']
[Init] best perm rec loss: 0.7126888036727905 for ['[CLS]u eagle or lit [SEP]']
[Init] best perm rec loss: 0.7126588821411133 for ['[CLS] litu or eagle [SEP]']
[Init] best perm rec loss: 0.7106083631515503 for ['[CLS]u lit eagle or [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.088 (perp=9.181, rec=0.252), tot_loss_proj:2.223 [t=0.25s]
prediction: ['[CLS] naissistic na [SEP]']
[ 100/2000] tot_loss=1.960 (perp=9.181, rec=0.124), tot_loss_proj:2.231 [t=0.25s]
prediction: ['[CLS] naissistic na [SEP]']
[ 150/2000] tot_loss=1.929 (perp=9.181, rec=0.093), tot_loss_proj:2.252 [t=0.26s]
prediction: ['[CLS] naissistic na [SEP]']
[ 200/2000] tot_loss=1.931 (perp=9.181, rec=0.095), tot_loss_proj:2.256 [t=0.25s]
prediction: ['[CLS] naissistic na [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.742 (perp=8.120, rec=0.118), tot_loss_proj:2.192 [t=0.25s]
prediction: ['[CLS] na naissistic [SEP]']
[ 300/2000] tot_loss=1.719 (perp=8.120, rec=0.095), tot_loss_proj:2.189 [t=0.26s]
prediction: ['[CLS] na naissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.709 (perp=8.120, rec=0.085), tot_loss_proj:2.197 [t=0.26s]
prediction: ['[CLS] na naissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.712 (perp=8.120, rec=0.088), tot_loss_proj:2.183 [t=0.24s]
prediction: ['[CLS] na naissistic [SEP]']
[ 450/2000] tot_loss=2.062 (perp=9.802, rec=0.102), tot_loss_proj:2.347 [t=0.28s]
prediction: ['[CLS]rc naissistic [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.094 (perp=5.048, rec=0.084), tot_loss_proj:1.114 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.095 (perp=5.048, rec=0.086), tot_loss_proj:1.103 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.092 (perp=5.048, rec=0.082), tot_loss_proj:1.131 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.085 (perp=5.048, rec=0.075), tot_loss_proj:1.127 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.091 (perp=5.048, rec=0.081), tot_loss_proj:1.111 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.083 (perp=5.048, rec=0.073), tot_loss_proj:1.106 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.083 (perp=5.048, rec=0.073), tot_loss_proj:1.115 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.080 (perp=5.048, rec=0.071), tot_loss_proj:1.114 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.073 (perp=5.048, rec=0.063), tot_loss_proj:1.112 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.069 (perp=5.048, rec=0.060), tot_loss_proj:1.111 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.080 (perp=5.048, rec=0.070), tot_loss_proj:1.103 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.067 (perp=5.048, rec=0.057), tot_loss_proj:1.115 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.068 (perp=5.048, rec=0.059), tot_loss_proj:1.101 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.077 (perp=5.048, rec=0.067), tot_loss_proj:1.108 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.068 (perp=5.048, rec=0.058), tot_loss_proj:1.095 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.060 (perp=5.048, rec=0.050), tot_loss_proj:1.100 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.076 (perp=5.048, rec=0.066), tot_loss_proj:1.093 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.078 (perp=5.048, rec=0.069), tot_loss_proj:1.100 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.073 (perp=5.048, rec=0.063), tot_loss_proj:1.101 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.075 (perp=5.048, rec=0.065), tot_loss_proj:1.102 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.061 (perp=5.048, rec=0.052), tot_loss_proj:1.110 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.079 (perp=5.048, rec=0.069), tot_loss_proj:1.107 [t=0.38s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.075 (perp=5.048, rec=0.066), tot_loss_proj:1.088 [t=0.33s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.072 (perp=5.048, rec=0.063), tot_loss_proj:1.097 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.071 (perp=5.048, rec=0.061), tot_loss_proj:1.098 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.075 (perp=5.048, rec=0.066), tot_loss_proj:1.104 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.068 (perp=5.048, rec=0.058), tot_loss_proj:1.098 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.074 (perp=5.048, rec=0.065), tot_loss_proj:1.099 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.065 (perp=5.048, rec=0.055), tot_loss_proj:1.092 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.071 (perp=5.048, rec=0.061), tot_loss_proj:1.101 [t=0.33s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.081 (perp=5.048, rec=0.072), tot_loss_proj:1.096 [t=0.32s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.711 | p: 86.914 | r: 88.752
rouge2     | fm: 50.564 | p: 50.229 | r: 50.905
rougeL     | fm: 75.472 | p: 74.886 | r: 76.332
rougeLsum  | fm: 75.329 | p: 74.764 | r: 76.111
r1fm+r2fm = 138.275

input #43 time: 0:11:02 | total time: 7:55:36


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9807100296020508 for ['[CLS] openingturing gallery naomicellular silk opponentlogyuit bit ་ london easily bent feeling ji imperialbol surprise downnz hiding run reserve anywhere ncaaation trade will [SEP]']
[Init] best rec loss: 0.970411479473114 for ['[CLS] vigor sara phone fellow mute belgian slip grid screen spencer sharp how knight up z fought spot cross wake peyton nut cdp oscar possessedcorp one lesser strained trey [SEP]']
[Init] best rec loss: 0.9664268493652344 for ['[CLS] saxon grand cc all independentrous reason one husband enclosed hugemac travis corporation diet interests toursvent secret freedom an succeeded spectators thoroughbred wickets terms facades haired mom [SEP]']
[Init] best rec loss: 0.9586738348007202 for ['[CLS] artists fibaca jaggedii murders j famous satisfaction rings woods paperavi game revival swiss recent - sac grab feathersitate garlic amongst bias though pounding positivehos [SEP]']
[Init] best rec loss: 0.9583253264427185 for ['[CLS] hereditary mathias walker techniquesification stilled thought [SEP] notre parish double speaking dracula version buried octopus podium same palace trophy losing subfamily chestroll architecture chocolatemple tucker forces [SEP]']
[Init] best rec loss: 0.9541782140731812 for ['[CLS] direction papers melody few feeling exception mud hurling trade spends stein blair tablet depth shepherd clear nonrogate nedra incorporated updatedtwined shouts sleeping beer clapton employer entertained worth [SEP]']
[Init] best rec loss: 0.950425386428833 for ['[CLS] dating characters st punches bang atari police 2000 toward prof reading ibn ought sable direct journalvu anne massacre eligibility bottom struck sparhawk following possessions agenda chances traded carrying [SEP]']
[Init] best rec loss: 0.9490242004394531 for ['[CLS] brought guard without gas toward × facedchan agency along have allied bourne player... [SEP] es shuttle chance invasion code roman myself apartmenteased gigն brandy cult [SEP]']
[Init] best rec loss: 0.9455894827842712 for ['[CLS] plata even austin ua fear tate its girldate arthur through glow for cars shepard airs marks tip air cesar stands frederick bodies promised possible companies humor flowers fine [SEP]']
[Init] best rec loss: 0.942662239074707 for ['[CLS] sky resumed defamation namibia didn prix tidefirm stooderonuni hotuniunda reported panel suggested friends directors wefying cd forward boardfolk spoon underschaft authority [SEP]']
[Init] best perm rec loss: 0.9423102140426636 for ['[CLS]schaft forward tidefirm prix namibia stood suggested boarduni didn spoon we sky hot defamationfolkfyinguni under friends authorityunda paneleron reported cd directors resumed [SEP]']
[Init] best perm rec loss: 0.9416174292564392 for ['[CLS]folk authority we tide defamationschaft prix stoodundafirmuni board spoon panelfying sky suggested reported namibia directors hot forward friendseron cd resumed under didnuni [SEP]']
[Init] best perm rec loss: 0.9410426020622253 for ['[CLS] suggestedschaft directors hot sky forward we stood panel friendsundauni defamation underfolk didn prix boarduni namibiaeronfirm reported spoon resumed authority cdfying tide [SEP]']
[Init] best perm rec loss: 0.9403653740882874 for ['[CLS]uni authority sky we tideunifolk didnunda reported forward stoodfirmfying suggested defamationeron spoon resumed directors boardschaft cd friends hot prix under panel namibia [SEP]']
[Init] best perm rec loss: 0.9391428828239441 for ['[CLS] tide hot prixuni sky panel friendsfying reporteduni forward cd spoonfirm we defamationschaft authority stoodfolkeron namibia board underunda didn resumed directors suggested [SEP]']
[Init] best perm rec loss: 0.9380404949188232 for ['[CLS] reported friendsuni suggested authorityuni resumed hot under didnunda boardfying stood we sky directors panel defamationschaft tide namibiaeron prix spoonfolk cd forwardfirm [SEP]']
[Init] best perm rec loss: 0.9370941519737244 for ['[CLS] board we reported under prixuni panelundafirm suggested tide sky hot directorsuni cd namibia defamationschafteron friends resumedfolk stood authority didn forwardfying spoon [SEP]']
[Init] best perm rec loss: 0.9368969798088074 for ['[CLS]eron defamation hot we reportedundafying board sky namibiaschaft panel authority spoon suggested under tide resumed friends cduni stoodfirm prix directorsfolk didn forwarduni [SEP]']
[Init] best perm rec loss: 0.9366524815559387 for ['[CLS]unda directors stoodfolk reported we panel forward underfying tide cd namibiauni spoon friendsschaft defamationuni hot suggestederonfirm sky prix resumed didn authority board [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.351 (perp=10.434, rec=0.264), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] the stage translation backwards tonight translation in translation. lost it got lost. routine violation discussion losingivation disneyland repeated again routine of sitcom horror western gesture mechanical [SEP]']
[ 100/2000] tot_loss=2.087 (perp=9.546, rec=0.178), tot_loss_proj:2.412 [t=0.26s]
prediction: ['[CLS] the hollywood in backwards slack translation. translation. lost. was lost. routine execution which slack slack slack repeated. routine of premise horror slack gesturealic [SEP]']
[ 150/2000] tot_loss=2.180 (perp=10.106, rec=0.159), tot_loss_proj:2.719 [t=0.27s]
prediction: ['[CLS] the hollywood in backwards fright translation the translation. lost a has lost. routine execution which slack slack slackizes. routineiest premise hollywood slackzziness. [SEP]']
[ 200/2000] tot_loss=2.214 (perp=10.357, rec=0.143), tot_loss_proj:2.773 [t=0.26s]
prediction: ['[CLS] the hollywood inalic fright translation the translation. lost been has lost. routine execution which slack slackalicizes. routinefest premise hollywood slackizes. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.088 (perp=9.837, rec=0.120), tot_loss_proj:2.765 [t=0.26s]
prediction: ['[CLS] the hollywood inalic fright translation the translation. lost hollywood has lost in another execution whichalic slackalicizes. routinefest premise been slackizes. [SEP]']
[ 300/2000] tot_loss=2.004 (perp=9.528, rec=0.099), tot_loss_proj:2.664 [t=0.26s]
prediction: ['[CLS] the hollywood in absurd fright translation the translation. lost hollywood has lost in another execution whichalic slackalicizes. routinefest premise been slackizes. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.927 (perp=9.108, rec=0.105), tot_loss_proj:2.562 [t=0.27s]
prediction: ['[CLS] the hollywood absurd in the translation the translation. lost hollywood has lost in another execution whichalic slackalicizes. routinefest premise been slackizes. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.854 (perp=8.785, rec=0.097), tot_loss_proj:2.570 [t=0.27s]
prediction: ['[CLS] the hollywood absurd in the translation the forces. lost hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been slackizes. [SEP]']
[ 450/2000] tot_loss=1.875 (perp=8.987, rec=0.077), tot_loss_proj:2.567 [t=0.25s]
prediction: ['[CLS] the hollywood absurd in the translation the the. lost hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been slackity. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.794 (perp=8.597, rec=0.075), tot_loss_proj:2.520 [t=0.28s]
prediction: ['[CLS] the the absurd in the translation the hollywood. lost hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been slackity. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.714 (perp=8.214, rec=0.071), tot_loss_proj:2.534 [t=0.27s]
prediction: ['[CLS] the slack absurd in the translation the hollywood. lost hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been theity. [SEP]']
[ 600/2000] tot_loss=1.729 (perp=8.242, rec=0.081), tot_loss_proj:2.523 [t=0.28s]
prediction: ['[CLS] the slack fright in the translation the hollywood. lost hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been theity. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.726 (perp=8.242, rec=0.078), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. lost hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been theity. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.690 (perp=8.087, rec=0.073), tot_loss_proj:2.350 [t=0.27s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been lostity. [SEP]']
[ 750/2000] tot_loss=1.690 (perp=8.087, rec=0.073), tot_loss_proj:2.349 [t=0.26s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine execution whichalic slack absurdizes. anotherfest premise been lostity. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.652 (perp=7.875, rec=0.077), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine execution whichalic slack absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.648 (perp=7.875, rec=0.073), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine execution whichalic slack absurdizes. anotherfestity been lost premise. [SEP]']
[ 900/2000] tot_loss=1.636 (perp=7.875, rec=0.061), tot_loss_proj:2.264 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine execution whichalic slack absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.619 (perp=7.709, rec=0.077), tot_loss_proj:2.216 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine executionalic which slack absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.611 (perp=7.709, rec=0.069), tot_loss_proj:2.220 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine executionalic which slack absurdizes. anotherfestity been lost premise. [SEP]']
[1050/2000] tot_loss=1.609 (perp=7.709, rec=0.068), tot_loss_proj:2.212 [t=0.26s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood has lost in routine executionalic which slack absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.606 (perp=7.682, rec=0.070), tot_loss_proj:2.221 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation the hollywood. the hollywood routine has lost in executionalic which slack absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.607 (perp=7.670, rec=0.073), tot_loss_proj:2.163 [t=0.27s]
prediction: ['[CLS] the slack fright in the translation which hollywood. the hollywood routine has lost in executionalic the execution absurdizes. anotherfestity been lost premise. [SEP]']
[1200/2000] tot_loss=1.601 (perp=7.670, rec=0.067), tot_loss_proj:2.169 [t=0.25s]
prediction: ['[CLS] the slack fright in the translation which hollywood. the hollywood routine has lost in executionalic the execution absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.576 (perp=7.501, rec=0.076), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] the slack execution in the translation which hollywood. the hollywood routine has lost in executionalic the fright absurdizes. anotherfestity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.508 (perp=7.161, rec=0.076), tot_loss_proj:1.995 [t=0.26s]
prediction: ['[CLS] the slack execution in the translation which hollywood. the hollywood routine has lost in executionalic the frightfestizes. another absurdity been lost premise. [SEP]']
[1350/2000] tot_loss=1.506 (perp=7.161, rec=0.074), tot_loss_proj:1.997 [t=0.25s]
prediction: ['[CLS] the slack execution in the translation which hollywood. the hollywood routine has lost in executionalic the frightfestizes. another absurdity been lost premise. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.500 (perp=7.161, rec=0.068), tot_loss_proj:1.998 [t=0.25s]
prediction: ['[CLS] the slack execution in the translation which hollywood. the hollywood routine has lost in executionalic the frightfestizes. another absurdity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.470 (perp=7.008, rec=0.069), tot_loss_proj:1.942 [t=0.26s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
[1500/2000] tot_loss=1.471 (perp=7.008, rec=0.069), tot_loss_proj:1.946 [t=0.28s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.464 (perp=7.008, rec=0.062), tot_loss_proj:1.945 [t=0.26s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.468 (perp=7.008, rec=0.066), tot_loss_proj:1.941 [t=0.25s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
[1650/2000] tot_loss=1.477 (perp=7.008, rec=0.075), tot_loss_proj:1.946 [t=0.25s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.477 (perp=7.008, rec=0.075), tot_loss_proj:1.949 [t=0.29s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.466 (perp=7.008, rec=0.065), tot_loss_proj:1.951 [t=0.26s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
[1800/2000] tot_loss=1.476 (perp=7.008, rec=0.074), tot_loss_proj:1.952 [t=0.29s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.465 (perp=7.008, rec=0.064), tot_loss_proj:1.958 [t=0.28s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.468 (perp=7.008, rec=0.066), tot_loss_proj:1.955 [t=0.31s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
[1950/2000] tot_loss=1.474 (perp=7.008, rec=0.073), tot_loss_proj:1.950 [t=0.30s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.470 (perp=7.008, rec=0.069), tot_loss_proj:1.958 [t=0.28s]
prediction: ['[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] the slack execution in the translation which hollywood. another hollywood routine has lost in executionalic the frightfestizes. the absurdity been lost premise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.106 | p: 83.333 | r: 86.957
rouge2     | fm: 35.556 | p: 34.783 | r: 36.364
rougeL     | fm: 51.064 | p: 50.000 | r: 52.174
rougeLsum  | fm: 51.064 | p: 50.000 | r: 52.174
r1fm+r2fm = 120.662

[Aggregate metrics]:
rouge1     | fm: 87.648 | p: 86.867 | r: 88.640
rouge2     | fm: 50.368 | p: 50.113 | r: 50.727
rougeL     | fm: 74.908 | p: 74.351 | r: 75.697
rougeLsum  | fm: 74.689 | p: 74.063 | r: 75.373
r1fm+r2fm = 138.017

input #44 time: 0:11:12 | total time: 8:06:48


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7507648468017578 for ['[CLS] ball over recall dj j grade venture hero band republic do dexter marvel vinnie money legacy promotion intent study title the constable activity looking ladder officially everett out [SEP]']
[Init] best rec loss: 0.7398894429206848 for ['[CLS] color mortar us boundary show waste acres wrap forty illvil ami moveyp fromtime transmitter julia fur went carvedfirmed sorts note heat slab disc real [SEP]']
[Init] best rec loss: 0.738102912902832 for ['[CLS] elves cm used avery andre adult supposed mono son cyyde •ي trump dump main sing commended guaranteed allies federation law steambre africangiers pest [SEP]']
[Init] best rec loss: 0.7057362198829651 for ['[CLS] restraining forgive scotia complex background deterle knees handling mom system cortex diegoailed drama ill beaumontlike timecar ß innerieg demotext likely highly collected [SEP]']
[Init] best rec loss: 0.6976931095123291 for ['[CLS] ready railway hollywood olympics wraps your resource exchange ne boss poor valley researchmons fix because invented mia iq ponder gag matter nick conduct clemson struggle criterionsw [SEP]']
[Init] best rec loss: 0.6952230930328369 for ['[CLS] date i dress appears confirmed montgomery effects curling abraham kept mid al ala hierarchy joyah attempt offeringtine channel terra belongs lyndon eventually chimney section returndding census [SEP]']
[Init] best rec loss: 0.6896260976791382 for ['[CLS] frank tier bitterured depotab surf alongtable tricky⁺ work if belts pointscko responsible is heardlika child benefit gaulle car around western transition spring [SEP]']
[Init] best perm rec loss: 0.6896213293075562 for ['[CLS] is tier depot child car heard if surf around workcko points springlika tricky along frankab benefit transition beltsured gaulle bittertable western responsible⁺ [SEP]']
[Init] best perm rec loss: 0.6893930435180664 for ['[CLS]uredab along westerncko responsible tier points bitter around worktable spring gaulle heard tricky depot child benefit car if belts transitionlika surf frank is⁺ [SEP]']
[Init] best perm rec loss: 0.6888341307640076 for ['[CLS] work tier along heard bitter western frank⁺ tricky child surf benefit belts transition points car gaulleab if springtable depot responsible is aroundckolikaured [SEP]']
[Init] best perm rec loss: 0.6880199313163757 for ['[CLS] car responsible heardab childured benefit bitter frank gaulle alongcko if surf depot tier westerntable⁺ points tricky around spring belts is transition worklika [SEP]']
[Init] best perm rec loss: 0.6854729056358337 for ['[CLS]lika is tricky belts depot workured if gaulle tier aroundab transition bitter car responsible springtablecko heard points child frank surf benefit⁺ western along [SEP]']
[Init] best perm rec loss: 0.6837384700775146 for ['[CLS] if heardtable points depot around is tier spring surf belts childlika car frank gaulle⁺ benefit bitterured alongab transition responsible work western trickycko [SEP]']
[Init] best perm rec loss: 0.6833248138427734 for ['[CLS] gaulle points heard is bitter transition work responsible western⁺ tricky depot spring frankab around tier childured benefitcko beltslika surftable car if along [SEP]']
[Init] best perm rec loss: 0.6832608580589294 for ['[CLS]lika tier western is belts⁺ bitter tricky benefitab gaulle depot around frank child transitionuredtable work if surf pointscko along spring heard responsible car [SEP]']
[Init] best perm rec loss: 0.6831319332122803 for ['[CLS] child frank belts is car responsible western tier around heardtable iflika surf⁺ points bitterab gaulle transitionured benefit depot spring tricky workcko along [SEP]']
[Init] best perm rec loss: 0.6827651858329773 for ['[CLS] frank western trickyablika around benefit caruredtable tier surf⁺ along spring belts work is child responsible depot bitter gaulle pointscko if transition heard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.522 (perp=11.079, rec=0.307), tot_loss_proj:2.893 [t=0.28s]
prediction: ['[CLS] machineway activity another specimen, drug gun party of anyway cowers think in were bloody around entrance ; pre mohawk tube cheekbones long chamber instincts training [SEP]']
[ 100/2000] tot_loss=2.307 (perp=10.390, rec=0.229), tot_loss_proj:2.636 [t=0.26s]
prediction: ['[CLS].el movements - paper, criminal gun party of gimm - shelf - than - this - activities pretty rom than shelfmm police brothers exercise [SEP]']
[ 150/2000] tot_loss=2.056 (perp=9.451, rec=0.166), tot_loss_proj:2.297 [t=0.29s]
prediction: ['[CLS] bowel movements - - was exercise gun - in gimm - shelf - than - this shelf exercisemm shoot than shelf - police drama drama [SEP]']
[ 200/2000] tot_loss=1.981 (perp=9.189, rec=0.144), tot_loss_proj:2.301 [t=0.28s]
prediction: ['[CLS] bowel movements - - crime exercise gun - in gimm - shelf - than - this shelf exercisemm shoot than shelf - crime drama drama [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.776 (perp=8.332, rec=0.110), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] bowel movements - - crime exercise shoot - in gimm - shelf - than the shelf exercise thismmick than shelf - crime drama drama [SEP]']
[ 300/2000] tot_loss=1.856 (perp=8.783, rec=0.100), tot_loss_proj:2.231 [t=0.26s]
prediction: ['[CLS] bowel movements - - shoot exercise shoot - in gimm - shelf - than the shelf exercise this longick than shelfy crime drama drama [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.845 (perp=8.726, rec=0.100), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] bowel movements - - shoot long shoot - in shelf gimm - - than the on exercise this longick than shelfy crime - drama [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.878 (perp=8.198, rec=0.239), tot_loss_proj:2.156 [t=0.25s]
prediction: ['[CLS] bowel movements - - - long shoot - in shelf gimm shoot - than - on exercise this longick than shelfy crime - drama [SEP]']
[ 450/2000] tot_loss=1.769 (perp=8.198, rec=0.129), tot_loss_proj:2.164 [t=0.29s]
prediction: ['[CLS] bowel movements - - - long shoot - in shelf gimm shoot - than - on exercise this longick than shelfy crime - drama [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.775 (perp=8.320, rec=0.111), tot_loss_proj:2.096 [t=0.26s]
prediction: ['[CLS] bowel movements - - - long thirty - in shelf gimmick - than - on exercise this long shoot than shelfy crime - drama [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.664 (perp=7.872, rec=0.089), tot_loss_proj:2.022 [t=0.27s]
prediction: ['[CLS] bowel movements - - - long von - than shelf gimmick - than, on exercise this long shoot in shelfy crime - drama [SEP]']
[ 600/2000] tot_loss=1.675 (perp=7.872, rec=0.101), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] bowel movements - - - long von - than shelf gimmick - than, on exercise this long shoot in shelfy crime - drama [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.675 (perp=7.962, rec=0.083), tot_loss_proj:2.052 [t=0.25s]
prediction: ['[CLS] bowel movements - - - long von - than shelf gimmick - than - on exercise this long in shoot shelfy crime - drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.614 (perp=7.612, rec=0.092), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] bowel movements - - - long von - than shelf gimmick - than shelf on exercise this long in shoot -y crime - drama [SEP]']
[ 750/2000] tot_loss=1.617 (perp=7.612, rec=0.095), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] bowel movements - - - long von - than shelf gimmick - than shelf on exercise this long in shoot -y crime - drama [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.582 (perp=7.483, rec=0.085), tot_loss_proj:1.963 [t=0.26s]
prediction: ['[CLS] bowel movements - - than long von - - shelf gimmick - than shelf on exercise this long in shoot -y crime, drama [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.591 (perp=7.558, rec=0.079), tot_loss_proj:1.986 [t=0.27s]
prediction: ["[CLS] bowel movements - - than long 'y - shelf gimmick - than shelf on exercise this long in shoot - - crime, drama [SEP]"]
[ 900/2000] tot_loss=1.593 (perp=7.558, rec=0.081), tot_loss_proj:1.992 [t=0.27s]
prediction: ["[CLS] bowel movements - - than long 'y - shelf gimmick - than shelf on exercise this long in shoot - - crime, drama [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.502 (perp=7.127, rec=0.076), tot_loss_proj:1.932 [t=0.26s]
prediction: ["[CLS] bowel movements - - - long 'y than shelf gimmick - than shelf on exercise this long in shoot - - crime, drama [SEP]"]
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.460 (perp=6.899, rec=0.080), tot_loss_proj:1.901 [t=0.27s]
prediction: ["[CLS] bowel movements -'- - longy than shelf gimmick - than shelf on exercise this long in shoot - - crime, drama [SEP]"]
[1050/2000] tot_loss=1.461 (perp=6.899, rec=0.082), tot_loss_proj:1.898 [t=0.25s]
prediction: ["[CLS] bowel movements -'- - longy than shelf gimmick - than shelf on exercise this long in shoot - - crime, drama [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.432 (perp=6.815, rec=0.069), tot_loss_proj:1.881 [t=0.26s]
prediction: ["[CLS] bowel, -'- - longy than shelf gimmick - than shelf on exercise this long in shoot - - crime movements drama [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.393 (perp=6.571, rec=0.079), tot_loss_proj:1.828 [t=0.28s]
prediction: ["[CLS] bowel, -'- - longy than shelf gimmick - than shelf on exercise this long in shoot - - crime drama movements [SEP]"]
[1200/2000] tot_loss=1.395 (perp=6.571, rec=0.081), tot_loss_proj:1.819 [t=0.26s]
prediction: ["[CLS] bowel, -'- - longy than shelf gimmick - than shelf on exercise this long in shoot - - crime drama movements [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.377 (perp=6.531, rec=0.071), tot_loss_proj:1.848 [t=0.26s]
prediction: ["[CLS] bowel, -'- - longy than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.372 (perp=6.531, rec=0.066), tot_loss_proj:1.845 [t=0.27s]
prediction: ["[CLS] bowel, -'- - longy than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]"]
[1350/2000] tot_loss=1.477 (perp=6.997, rec=0.078), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] bowel, - the - - longy than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]']
Attempt swap
[1400/2000] tot_loss=1.478 (perp=6.997, rec=0.079), tot_loss_proj:1.945 [t=0.26s]
prediction: ['[CLS] bowel, - the - - longy than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.471 (perp=6.970, rec=0.077), tot_loss_proj:1.857 [t=0.27s]
prediction: ['[CLS] bowel, - they - long - than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]']
[1500/2000] tot_loss=1.469 (perp=6.970, rec=0.075), tot_loss_proj:1.857 [t=0.26s]
prediction: ['[CLS] bowel, - they - long - than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.447 (perp=6.879, rec=0.071), tot_loss_proj:1.860 [t=0.25s]
prediction: ['[CLS] bowel, - longy - the - than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.391 (perp=6.558, rec=0.079), tot_loss_proj:1.719 [t=0.26s]
prediction: ['[CLS] bowel, - -y - the - than shelf gimmick - than shelf exercise on this long shoot - - in crime drama movements [SEP]']
[1650/2000] tot_loss=1.384 (perp=6.558, rec=0.072), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] bowel, - -y - the - than shelf gimmick - than shelf exercise on this long shoot - - in crime drama movements [SEP]']
Attempt swap
[1700/2000] tot_loss=1.375 (perp=6.536, rec=0.068), tot_loss_proj:1.727 [t=0.27s]
prediction: ['[CLS] bowel, - longy - the - than shelf gimmick - than shelf exercise on this long shoot - - in crime drama movements [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.331 (perp=6.231, rec=0.085), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] bowel, - - they - - than shelf gimmick - than shelf exercise on this long shoot - - in crime drama movements [SEP]']
[1800/2000] tot_loss=1.323 (perp=6.231, rec=0.077), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] bowel, - - they - - than shelf gimmick - than shelf exercise on this long shoot - - in crime drama movements [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.295 (perp=6.093, rec=0.076), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] bowel, - - thisy - - than shelf gimmick - than shelf exercise on the long shoot - - in crime drama movements [SEP]']
Attempt swap
[1900/2000] tot_loss=1.302 (perp=6.093, rec=0.084), tot_loss_proj:1.680 [t=0.34s]
prediction: ['[CLS] bowel, - - thisy - - than shelf gimmick - than shelf exercise on the long shoot - - in crime drama movements [SEP]']
[1950/2000] tot_loss=1.295 (perp=6.093, rec=0.076), tot_loss_proj:1.675 [t=0.37s]
prediction: ['[CLS] bowel, - - thisy - - than shelf gimmick - than shelf exercise on the long shoot - - in crime drama movements [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.271 (perp=5.967, rec=0.078), tot_loss_proj:1.591 [t=0.35s]
prediction: ['[CLS] bowel, - - thisy - - than shelf gimmick - than shelf exercise in the long shoot - - on crime drama movements [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] bowel, -'- - longy than shelf gimmick - than shelf on exercise this long shoot - - in crime drama movements [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 17.647 | p: 17.647 | r: 17.647
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 95.425

[Aggregate metrics]:
rouge1     | fm: 87.441 | p: 86.701 | r: 88.468
rouge2     | fm: 49.605 | p: 49.339 | r: 49.897
rougeL     | fm: 74.392 | p: 73.862 | r: 75.087
rougeLsum  | fm: 74.231 | p: 73.706 | r: 74.931
r1fm+r2fm = 137.046

input #45 time: 0:11:05 | total time: 8:17:54


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 1.0194200277328491 for ['[CLS] appreciated jude gwenfeit than covered [SEP]']
[Init] best rec loss: 0.9969024658203125 for ['[CLS] actually von morrow coachship shallow [SEP]']
[Init] best rec loss: 0.9748015403747559 for ['[CLS]wyl toy classified smaller phone poem [SEP]']
[Init] best rec loss: 0.971077024936676 for ['[CLS] coach leadingtracted lexiciency context [SEP]']
[Init] best rec loss: 0.963357150554657 for ['[CLS] atoll sewer institution municipality levels used [SEP]']
[Init] best rec loss: 0.9598272442817688 for ['[CLS]... river factor animal average opera [SEP]']
[Init] best rec loss: 0.9472619891166687 for ['[CLS] known talk shortly all study eyes [SEP]']
[Init] best perm rec loss: 0.9460861682891846 for ['[CLS] talk known all shortly study eyes [SEP]']
[Init] best perm rec loss: 0.9458732604980469 for ['[CLS] all eyes known talk shortly study [SEP]']
[Init] best perm rec loss: 0.9446695446968079 for ['[CLS] all known shortly eyes talk study [SEP]']
[Init] best perm rec loss: 0.9440104961395264 for ['[CLS] known eyes study talk all shortly [SEP]']
[Init] best perm rec loss: 0.9439814686775208 for ['[CLS] known talk all study eyes shortly [SEP]']
[Init] best perm rec loss: 0.9431409239768982 for ['[CLS] all eyes study talk known shortly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.155 (perp=12.810, rec=0.593), tot_loss_proj:3.520 [t=0.38s]
prediction: ['[CLS] seam sites and threatening anyway premiered [SEP]']
[ 100/2000] tot_loss=3.115 (perp=12.994, rec=0.516), tot_loss_proj:3.687 [t=0.27s]
prediction: ['[CLS] footprints visually slick assaulted strikingnished [SEP]']
[ 150/2000] tot_loss=3.072 (perp=12.206, rec=0.630), tot_loss_proj:3.486 [t=0.26s]
prediction: ['[CLS] legitimate potentially slick threatening striking slick [SEP]']
[ 200/2000] tot_loss=2.907 (perp=12.210, rec=0.465), tot_loss_proj:3.531 [t=0.25s]
prediction: ['[CLS] legitimate visually slick & strikingnsor [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.817 (perp=11.832, rec=0.450), tot_loss_proj:3.493 [t=0.26s]
prediction: ['[CLS] visually slick attack slicknished coincidence [SEP]']
[ 300/2000] tot_loss=2.508 (perp=10.210, rec=0.466), tot_loss_proj:2.727 [t=0.25s]
prediction: ['[CLS] visually slick & slick staged coincidence [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.632 (perp=11.110, rec=0.410), tot_loss_proj:2.672 [t=0.27s]
prediction: ['[CLS] visually slickably slick staged coincidence [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.447 (perp=10.210, rec=0.405), tot_loss_proj:2.744 [t=0.25s]
prediction: ['[CLS] visually slick & slick staged coincidence [SEP]']
[ 450/2000] tot_loss=2.934 (perp=12.561, rec=0.422), tot_loss_proj:3.559 [t=0.25s]
prediction: ['[CLS] visually clipped expenses slick staged coincidence [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.905 (perp=12.561, rec=0.393), tot_loss_proj:3.560 [t=0.25s]
prediction: ['[CLS] visually clipped expenses slick staged coincidence [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.898 (perp=12.561, rec=0.386), tot_loss_proj:3.558 [t=0.24s]
prediction: ['[CLS] visually clipped expenses slick staged coincidence [SEP]']
[ 600/2000] tot_loss=3.389 (perp=13.106, rec=0.768), tot_loss_proj:3.615 [t=0.26s]
prediction: ['[CLS] visually worst expenses slick pradesh coincidence [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.787 (perp=11.642, rec=0.459), tot_loss_proj:3.300 [t=0.25s]
prediction: ['[CLS] visually slick expenses worst staged coincidence [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.812 (perp=12.027, rec=0.406), tot_loss_proj:3.403 [t=0.25s]
prediction: ['[CLS] visually slickably worst staged coincidence [SEP]']
[ 750/2000] tot_loss=2.800 (perp=12.027, rec=0.394), tot_loss_proj:3.398 [t=0.25s]
prediction: ['[CLS] visually slickably worst staged coincidence [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.875 (perp=12.469, rec=0.381), tot_loss_proj:3.520 [t=0.26s]
prediction: ['[CLS] visually poorlyably slick staged coincidence [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.040 (perp=13.254, rec=0.389), tot_loss_proj:3.626 [t=0.25s]
prediction: ['[CLS] worst visually expenses slick staged coincidence [SEP]']
[ 900/2000] tot_loss=2.862 (perp=12.434, rec=0.376), tot_loss_proj:3.497 [t=0.26s]
prediction: ['[CLS] poorly visually expenses slick staged coincidence [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.882 (perp=12.434, rec=0.395), tot_loss_proj:3.504 [t=0.25s]
prediction: ['[CLS] poorly visually expenses slick staged coincidence [SEP]']
Attempt swap
[1000/2000] tot_loss=2.857 (perp=12.434, rec=0.370), tot_loss_proj:3.500 [t=0.26s]
prediction: ['[CLS] poorly visually expenses slick staged coincidence [SEP]']
[1050/2000] tot_loss=2.725 (perp=11.783, rec=0.368), tot_loss_proj:3.369 [t=0.28s]
prediction: ['[CLS] poorly visuallyably slickhearted coincidence [SEP]']
Attempt swap
[1100/2000] tot_loss=2.670 (perp=11.548, rec=0.360), tot_loss_proj:3.410 [t=0.27s]
prediction: ['[CLS] silently visuallyably slickhearted coincidence [SEP]']
Attempt swap
[1150/2000] tot_loss=2.636 (perp=11.345, rec=0.367), tot_loss_proj:3.307 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick staged coincidence [SEP]']
[1200/2000] tot_loss=2.629 (perp=11.345, rec=0.360), tot_loss_proj:3.311 [t=0.24s]
prediction: ['[CLS] silently visuallyably slick staged coincidence [SEP]']
Attempt swap
[1250/2000] tot_loss=2.623 (perp=11.345, rec=0.354), tot_loss_proj:3.315 [t=0.26s]
prediction: ['[CLS] silently visuallyably slick staged coincidence [SEP]']
Attempt swap
[1300/2000] tot_loss=2.631 (perp=11.345, rec=0.361), tot_loss_proj:3.315 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick staged coincidence [SEP]']
[1350/2000] tot_loss=2.624 (perp=11.345, rec=0.355), tot_loss_proj:3.314 [t=0.26s]
prediction: ['[CLS] silently visuallyably slick staged coincidence [SEP]']
Attempt swap
[1400/2000] tot_loss=2.626 (perp=11.345, rec=0.357), tot_loss_proj:3.313 [t=0.24s]
prediction: ['[CLS] silently visuallyably slick staged coincidence [SEP]']
Attempt swap
[1450/2000] tot_loss=2.741 (perp=12.004, rec=0.340), tot_loss_proj:3.504 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
[1500/2000] tot_loss=2.754 (perp=12.004, rec=0.353), tot_loss_proj:3.503 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[1550/2000] tot_loss=2.744 (perp=12.004, rec=0.344), tot_loss_proj:3.502 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[1600/2000] tot_loss=2.743 (perp=12.004, rec=0.342), tot_loss_proj:3.498 [t=0.27s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
[1650/2000] tot_loss=2.754 (perp=12.004, rec=0.353), tot_loss_proj:3.499 [t=0.28s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[1700/2000] tot_loss=2.749 (perp=12.004, rec=0.348), tot_loss_proj:3.499 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[1750/2000] tot_loss=2.753 (perp=12.004, rec=0.353), tot_loss_proj:3.502 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
[1800/2000] tot_loss=2.744 (perp=12.004, rec=0.344), tot_loss_proj:3.506 [t=0.26s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[1850/2000] tot_loss=2.751 (perp=12.004, rec=0.350), tot_loss_proj:3.499 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[1900/2000] tot_loss=2.740 (perp=12.004, rec=0.339), tot_loss_proj:3.499 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
[1950/2000] tot_loss=2.745 (perp=12.004, rec=0.344), tot_loss_proj:3.503 [t=0.24s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Attempt swap
[2000/2000] tot_loss=2.748 (perp=12.004, rec=0.348), tot_loss_proj:3.507 [t=0.25s]
prediction: ['[CLS] silently visuallyably slick stagedacious [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] silently visuallyably slick stagedacious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 30.769 | p: 33.333 | r: 28.571
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.769 | p: 33.333 | r: 28.571
rougeLsum  | fm: 30.769 | p: 33.333 | r: 28.571
r1fm+r2fm = 30.769

[Aggregate metrics]:
rouge1     | fm: 86.231 | p: 85.548 | r: 87.131
rouge2     | fm: 48.206 | p: 47.939 | r: 48.563
rougeL     | fm: 73.502 | p: 73.042 | r: 74.224
rougeLsum  | fm: 73.566 | p: 73.151 | r: 74.211
r1fm+r2fm = 134.436

input #46 time: 0:10:44 | total time: 8:28:38


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.7397077083587646 for ['[CLS] alice cruel commander [SEP]']
[Init] best rec loss: 0.7183798551559448 for ['[CLS] yan prisoner branding [SEP]']
[Init] best rec loss: 0.7182126641273499 for ['[CLS] society board terms [SEP]']
[Init] best rec loss: 0.6875474452972412 for ['[CLS] lynch such lyrics [SEP]']
[Init] best rec loss: 0.6634544134140015 for ['[CLS] faith karen bank [SEP]']
[Init] best rec loss: 0.6556697487831116 for ['[CLS] sheen pretty stereo [SEP]']
[Init] best rec loss: 0.6435391902923584 for ['[CLS] society new silently [SEP]']
[Init] best perm rec loss: 0.6412023901939392 for ['[CLS] society silently new [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.679 (perp=12.488, rec=0.181), tot_loss_proj:2.888 [t=0.29s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.617 (perp=12.488, rec=0.119), tot_loss_proj:2.885 [t=0.30s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.592 (perp=12.488, rec=0.094), tot_loss_proj:2.889 [t=0.29s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.586 (perp=12.488, rec=0.089), tot_loss_proj:2.886 [t=0.33s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.582 (perp=12.488, rec=0.084), tot_loss_proj:2.897 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.589 (perp=12.488, rec=0.092), tot_loss_proj:2.895 [t=0.30s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.589 (perp=12.488, rec=0.091), tot_loss_proj:2.894 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.584 (perp=12.488, rec=0.086), tot_loss_proj:2.898 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.585 (perp=12.488, rec=0.087), tot_loss_proj:2.902 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.578 (perp=12.488, rec=0.081), tot_loss_proj:2.899 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.584 (perp=12.488, rec=0.087), tot_loss_proj:2.890 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=2.577 (perp=12.488, rec=0.079), tot_loss_proj:2.904 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.592 (perp=12.488, rec=0.094), tot_loss_proj:2.896 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.579 (perp=12.488, rec=0.081), tot_loss_proj:2.906 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 750/2000] tot_loss=2.574 (perp=12.488, rec=0.076), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.586 (perp=12.488, rec=0.088), tot_loss_proj:2.906 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.566 (perp=12.488, rec=0.068), tot_loss_proj:2.915 [t=0.28s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 900/2000] tot_loss=2.575 (perp=12.488, rec=0.078), tot_loss_proj:2.909 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.591 (perp=12.488, rec=0.093), tot_loss_proj:2.921 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=2.589 (perp=12.488, rec=0.091), tot_loss_proj:2.911 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1050/2000] tot_loss=2.575 (perp=12.488, rec=0.078), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.567 (perp=12.488, rec=0.070), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.573 (perp=12.488, rec=0.075), tot_loss_proj:2.907 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1200/2000] tot_loss=2.582 (perp=12.488, rec=0.085), tot_loss_proj:2.906 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.567 (perp=12.488, rec=0.070), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.576 (perp=12.488, rec=0.078), tot_loss_proj:2.917 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1350/2000] tot_loss=2.578 (perp=12.488, rec=0.080), tot_loss_proj:2.919 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.573 (perp=12.488, rec=0.075), tot_loss_proj:2.921 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.564 (perp=12.488, rec=0.067), tot_loss_proj:2.911 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1500/2000] tot_loss=2.569 (perp=12.488, rec=0.071), tot_loss_proj:2.904 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.571 (perp=12.488, rec=0.073), tot_loss_proj:2.912 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.567 (perp=12.488, rec=0.070), tot_loss_proj:2.915 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1650/2000] tot_loss=2.584 (perp=12.488, rec=0.087), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.587 (perp=12.488, rec=0.089), tot_loss_proj:2.908 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.532 (perp=12.131, rec=0.106), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] transparent transparentright [SEP]']
[1800/2000] tot_loss=2.512 (perp=12.131, rec=0.085), tot_loss_proj:2.886 [t=0.25s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[1850/2000] tot_loss=2.510 (perp=12.131, rec=0.084), tot_loss_proj:2.890 [t=0.27s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[1900/2000] tot_loss=2.515 (perp=12.131, rec=0.088), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS] transparent transparentright [SEP]']
[1950/2000] tot_loss=2.515 (perp=12.131, rec=0.089), tot_loss_proj:2.892 [t=0.25s]
prediction: ['[CLS] transparent transparentright [SEP]']
Attempt swap
[2000/2000] tot_loss=2.507 (perp=12.131, rec=0.081), tot_loss_proj:2.891 [t=0.26s]
prediction: ['[CLS] transparent transparentright [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS]right transparent transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 85.817 | p: 84.932 | r: 86.898
rouge2     | fm: 48.025 | p: 47.641 | r: 48.397
rougeL     | fm: 73.405 | p: 72.794 | r: 74.231
rougeLsum  | fm: 73.251 | p: 72.658 | r: 74.142
r1fm+r2fm = 133.841

input #47 time: 0:11:02 | total time: 8:39:40


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8585933446884155 for ['[CLS] stand trip touchdown arrived [SEP]']
[Init] best rec loss: 0.8578049540519714 for ['[CLS] it such cricketing [SEP]']
[Init] best rec loss: 0.825230062007904 for ['[CLS] as principalاia [SEP]']
[Init] best rec loss: 0.8243675231933594 for ['[CLS] spoken newfoundland reformation worship [SEP]']
[Init] best rec loss: 0.8120895028114319 for ['[CLS] had towel aid now [SEP]']
[Init] best rec loss: 0.8085777759552002 for ['[CLS] china planet nedra pa [SEP]']
[Init] best rec loss: 0.7786885499954224 for ['[CLS] buried suddenly established following [SEP]']
[Init] best rec loss: 0.7621781826019287 for ['[CLS] wagnerties moan case [SEP]']
[Init] best perm rec loss: 0.7595168352127075 for ['[CLS] wagner case moanties [SEP]']
[Init] best perm rec loss: 0.7591158747673035 for ['[CLS] caseties moan wagner [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.397 (perp=10.834, rec=0.230), tot_loss_proj:2.607 [t=0.28s]
prediction: ['[CLS] back rotting rotting rotting [SEP]']
[ 100/2000] tot_loss=2.784 (perp=13.327, rec=0.118), tot_loss_proj:3.282 [t=0.28s]
prediction: ['[CLS] underbell under rotting [SEP]']
[ 150/2000] tot_loss=1.485 (perp=7.028, rec=0.079), tot_loss_proj:1.738 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 200/2000] tot_loss=1.471 (perp=7.028, rec=0.066), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.475 (perp=7.028, rec=0.069), tot_loss_proj:1.740 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 300/2000] tot_loss=1.471 (perp=7.028, rec=0.066), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.474 (perp=7.028, rec=0.068), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.473 (perp=7.028, rec=0.067), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.470 (perp=7.028, rec=0.065), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.465 (perp=7.028, rec=0.060), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.476 (perp=7.028, rec=0.070), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.476 (perp=7.028, rec=0.071), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.475 (perp=7.028, rec=0.069), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.466 (perp=7.028, rec=0.060), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.463 (perp=7.028, rec=0.058), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.467 (perp=7.028, rec=0.062), tot_loss_proj:1.749 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.475 (perp=7.028, rec=0.069), tot_loss_proj:1.753 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.465 (perp=7.028, rec=0.059), tot_loss_proj:1.757 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.463 (perp=7.028, rec=0.058), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.468 (perp=7.028, rec=0.062), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.467 (perp=7.028, rec=0.062), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.470 (perp=7.028, rec=0.064), tot_loss_proj:1.745 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.465 (perp=7.028, rec=0.060), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.468 (perp=7.028, rec=0.062), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.469 (perp=7.028, rec=0.063), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.476 (perp=7.028, rec=0.071), tot_loss_proj:1.738 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.471 (perp=7.028, rec=0.065), tot_loss_proj:1.747 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.458 (perp=7.028, rec=0.053), tot_loss_proj:1.745 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.473 (perp=7.028, rec=0.067), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.467 (perp=7.028, rec=0.062), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.473 (perp=7.028, rec=0.067), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.469 (perp=7.028, rec=0.063), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.474 (perp=7.028, rec=0.068), tot_loss_proj:1.744 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.463 (perp=7.028, rec=0.057), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.474 (perp=7.028, rec=0.069), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.473 (perp=7.028, rec=0.067), tot_loss_proj:1.749 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.456 (perp=7.028, rec=0.050), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.455 (perp=7.028, rec=0.050), tot_loss_proj:1.749 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.473 (perp=7.028, rec=0.067), tot_loss_proj:1.753 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.470 (perp=7.028, rec=0.064), tot_loss_proj:1.731 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 86.138 | p: 85.285 | r: 87.125
rouge2     | fm: 47.075 | p: 46.742 | r: 47.482
rougeL     | fm: 73.453 | p: 72.810 | r: 74.338
rougeLsum  | fm: 73.306 | p: 72.602 | r: 74.202
r1fm+r2fm = 133.212

input #48 time: 0:10:57 | total time: 8:50:38


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8239336013793945 for ['[CLS] ii shops drawer translator killing translation orders wo battle nicole latter reins [SEP]']
[Init] best rec loss: 0.7784803509712219 for ['[CLS] alarm am° crest echo most purple fossil worn robot functionical [SEP]']
[Init] best rec loss: 0.7627898454666138 for ['[CLS]iface about law whatever sox teeth surrounding plays rainfall step paper ham [SEP]']
[Init] best rec loss: 0.7617259621620178 for ['[CLS] then ryan objective darker cis gymnasium duvalyler didn exhaust indie genus [SEP]']
[Init] best rec loss: 0.761226236820221 for ['[CLS] keyfulness google relatively leftי ke basedhem lew gaining productions [SEP]']
[Init] best rec loss: 0.7600340247154236 for ['[CLS] temps jealous locals stark corinne almost thought roller journal sylvie anyone boxes [SEP]']
[Init] best rec loss: 0.7473030090332031 for ['[CLS] directors hybrid friction emerson beogo racing them alive julianacoat application [SEP]']
[Init] best perm rec loss: 0.7472487688064575 for ['[CLS] racing juliana frictionogo hybrid directorscoat alive them emerson application be [SEP]']
[Init] best perm rec loss: 0.7469727993011475 for ['[CLS] emerson aliveogo racing friction directorscoat juliana hybrid be them application [SEP]']
[Init] best perm rec loss: 0.7460036873817444 for ['[CLS]ogo directors racing alive application friction julianacoat emerson hybrid be them [SEP]']
[Init] best perm rec loss: 0.7435344457626343 for ['[CLS]ogocoat directors application friction emerson juliana them hybrid racing alive be [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.644 (perp=12.062, rec=0.232), tot_loss_proj:2.981 [t=0.27s]
prediction: ['[CLS] contempt moreuous males moreuous fewer women contempt civil risk contempt [SEP]']
[ 100/2000] tot_loss=2.226 (perp=10.528, rec=0.120), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] contempt possibly of population moreuous single female population female? contempt [SEP]']
[ 150/2000] tot_loss=2.186 (perp=10.401, rec=0.106), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS] contempt possibly of population moreuous single female population female. contempt [SEP]']
[ 200/2000] tot_loss=2.309 (perp=10.901, rec=0.129), tot_loss_proj:2.747 [t=0.25s]
prediction: ['[CLS] contempt possibly of population moreuous single female possibly the. contempt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.921 (perp=9.137, rec=0.094), tot_loss_proj:2.363 [t=0.26s]
prediction: ['[CLS] contempt possibly of the moreuous single female possibly population. sometimes [SEP]']
[ 300/2000] tot_loss=1.915 (perp=9.137, rec=0.088), tot_loss_proj:2.366 [t=0.28s]
prediction: ['[CLS] contempt possibly of the moreuous single female possibly population. sometimes [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.794 (perp=8.546, rec=0.085), tot_loss_proj:2.230 [t=0.26s]
prediction: ['[CLS] contempt possibly of the moreuous single female population. sometimes possibly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.714 (perp=8.109, rec=0.092), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] possibly contempt of the moreuous single female population. sometimes possibly [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.109, rec=0.081), tot_loss_proj:2.127 [t=0.27s]
prediction: ['[CLS] possibly contempt of the moreuous single female population. sometimes possibly [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.493 (perp=7.052, rec=0.083), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] possibly of the more contemptuous single female population. could possibly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.496 (perp=7.052, rec=0.086), tot_loss_proj:1.917 [t=0.27s]
prediction: ['[CLS] possibly of the more contemptuous single female population. could possibly [SEP]']
[ 600/2000] tot_loss=1.483 (perp=7.052, rec=0.073), tot_loss_proj:1.915 [t=0.27s]
prediction: ['[CLS] possibly of the more contemptuous single female population. could possibly [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.405 (perp=6.630, rec=0.079), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] possibly of the more contemptuous single female population possibly could. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.491 (perp=7.082, rec=0.074), tot_loss_proj:1.950 [t=0.26s]
prediction: ['[CLS] possibly of the more contemptuous single female population be could. [SEP]']
[ 750/2000] tot_loss=1.494 (perp=7.082, rec=0.078), tot_loss_proj:1.943 [t=0.27s]
prediction: ['[CLS] possibly of the more contemptuous single female population be could. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.563 (perp=7.428, rec=0.077), tot_loss_proj:1.982 [t=0.28s]
prediction: ['[CLS] possibly of the more contemptuous single female population [SEP] be. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.454 (perp=6.888, rec=0.077), tot_loss_proj:1.820 [t=0.27s]
prediction: ['[CLS] [SEP] of the more contemptuous single female population possibly be. [SEP]']
[ 900/2000] tot_loss=1.459 (perp=6.888, rec=0.081), tot_loss_proj:1.825 [t=0.26s]
prediction: ['[CLS] [SEP] of the more contemptuous single female population possibly be. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.457 (perp=6.888, rec=0.079), tot_loss_proj:1.816 [t=0.27s]
prediction: ['[CLS] [SEP] of the more contemptuous single female population possibly be. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.405 (perp=6.630, rec=0.079), tot_loss_proj:1.800 [t=0.27s]
prediction: ['[CLS] [SEP] of the more contemptuous female population possibly be single. [SEP]']
[1050/2000] tot_loss=1.469 (perp=6.981, rec=0.073), tot_loss_proj:1.882 [t=0.27s]
prediction: ['[CLS] could of the more contemptuous female population possibly be single. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.388 (perp=6.546, rec=0.079), tot_loss_proj:1.783 [t=0.25s]
prediction: ['[CLS] be of the more contemptuous female population possibly could single. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.304 (perp=6.146, rec=0.075), tot_loss_proj:1.707 [t=0.28s]
prediction: ['[CLS] be of the more contemptuous female population could possibly single. [SEP]']
[1200/2000] tot_loss=1.304 (perp=6.146, rec=0.074), tot_loss_proj:1.700 [t=0.25s]
prediction: ['[CLS] be of the more contemptuous female population could possibly single. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.231 (perp=5.773, rec=0.076), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] of the more contemptuous female population could possibly be single. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.117 (perp=5.177, rec=0.081), tot_loss_proj:1.374 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
[1350/2000] tot_loss=1.121 (perp=5.177, rec=0.086), tot_loss_proj:1.368 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.112 (perp=5.177, rec=0.077), tot_loss_proj:1.375 [t=0.27s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.120 (perp=5.177, rec=0.084), tot_loss_proj:1.380 [t=0.27s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
[1500/2000] tot_loss=1.105 (perp=5.177, rec=0.070), tot_loss_proj:1.380 [t=0.27s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.112 (perp=5.177, rec=0.077), tot_loss_proj:1.369 [t=0.28s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.110 (perp=5.177, rec=0.075), tot_loss_proj:1.375 [t=0.25s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
[1650/2000] tot_loss=1.121 (perp=5.177, rec=0.086), tot_loss_proj:1.375 [t=0.25s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.118 (perp=5.177, rec=0.082), tot_loss_proj:1.376 [t=0.27s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.113 (perp=5.177, rec=0.077), tot_loss_proj:1.372 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
[1800/2000] tot_loss=1.110 (perp=5.177, rec=0.075), tot_loss_proj:1.374 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.112 (perp=5.177, rec=0.076), tot_loss_proj:1.374 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.121 (perp=5.177, rec=0.085), tot_loss_proj:1.373 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
[1950/2000] tot_loss=1.126 (perp=5.177, rec=0.091), tot_loss_proj:1.371 [t=0.26s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.115 (perp=5.177, rec=0.080), tot_loss_proj:1.376 [t=0.25s]
prediction: ['[CLS] more contemptuous of the female population could possibly be single. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] more contemptuous of the female population could possibly be single. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 154.545

[Aggregate metrics]:
rouge1     | fm: 86.417 | p: 85.610 | r: 87.406
rouge2     | fm: 47.255 | p: 46.948 | r: 47.685
rougeL     | fm: 73.184 | p: 72.634 | r: 73.981
rougeLsum  | fm: 73.285 | p: 72.611 | r: 74.104
r1fm+r2fm = 133.672

input #49 time: 0:10:55 | total time: 9:01:34


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8377328515052795 for ['[CLS] uncertainuld payne like stopped anything lastnot wayne [SEP]']
[Init] best rec loss: 0.803080141544342 for ['[CLS] medical cyrus records abroad楊 lifeantlyraine whatever [SEP]']
[Init] best rec loss: 0.7693411707878113 for ['[CLS] confinement honor streets denomination suggesting liberty sweat bowls worked [SEP]']
[Init] best rec loss: 0.767485499382019 for ['[CLS]osaurus instituted even better labour selectionping regions convened [SEP]']
[Init] best rec loss: 0.7590867280960083 for ['[CLS] inside classic ever metropolitan nova on article offsing [SEP]']
[Init] best rec loss: 0.7549668550491333 for ['[CLS] contributing giantkh utility release wwf highly locked murphy [SEP]']
[Init] best perm rec loss: 0.7530487775802612 for ['[CLS] murphy wwf lockedkh utility giant release highly contributing [SEP]']
[Init] best perm rec loss: 0.7507265210151672 for ['[CLS] wwf highly contributingkh murphy giant locked utility release [SEP]']
[Init] best perm rec loss: 0.749139130115509 for ['[CLS] giant release contributing highly murphy wwfkh locked utility [SEP]']
[Init] best perm rec loss: 0.7487676739692688 for ['[CLS] locked murphy highly release giant utilitykh wwf contributing [SEP]']
[Init] best perm rec loss: 0.7483940720558167 for ['[CLS] wwf murphy giantkh release highly contributing locked utility [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.495 (perp=10.843, rec=0.327), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] too papers clever little clever clever of half radical [SEP]']
[ 100/2000] tot_loss=2.385 (perp=10.700, rec=0.245), tot_loss_proj:2.669 [t=0.25s]
prediction: ['[CLS] too calls clever too clever clever by half radical [SEP]']
[ 150/2000] tot_loss=2.331 (perp=10.880, rec=0.155), tot_loss_proj:2.740 [t=0.28s]
prediction: ['[CLS] too call what too clever clever by half half [SEP]']
[ 200/2000] tot_loss=2.260 (perp=10.678, rec=0.124), tot_loss_proj:2.655 [t=0.27s]
prediction: ['[CLS] too ` what call clever clever by half ` [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.108 (perp=10.032, rec=0.102), tot_loss_proj:2.687 [t=0.25s]
prediction: ['[CLS] too ` what clever clever call by half ` [SEP]']
[ 300/2000] tot_loss=2.104 (perp=10.032, rec=0.097), tot_loss_proj:2.692 [t=0.28s]
prediction: ['[CLS] too ` what clever clever call by half ` [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.091 (perp=10.032, rec=0.085), tot_loss_proj:2.691 [t=0.26s]
prediction: ['[CLS] too ` what clever clever call by half ` [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.092 (perp=10.032, rec=0.086), tot_loss_proj:2.692 [t=0.25s]
prediction: ['[CLS] too ` what clever clever call by half ` [SEP]']
[ 450/2000] tot_loss=2.138 (perp=10.324, rec=0.073), tot_loss_proj:2.794 [t=0.28s]
prediction: ['[CLS] too english what clever clever call by half ` [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.009 (perp=9.683, rec=0.073), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] too clever what clever english call by half ` [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.978 (perp=9.478, rec=0.082), tot_loss_proj:2.396 [t=0.25s]
prediction: ['[CLS] too clever what english clever call by half ` [SEP]']
[ 600/2000] tot_loss=1.967 (perp=9.478, rec=0.071), tot_loss_proj:2.408 [t=0.25s]
prediction: ['[CLS] too clever what english clever call by half ` [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.936 (perp=9.321, rec=0.071), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.941 (perp=9.321, rec=0.077), tot_loss_proj:2.293 [t=0.25s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[ 750/2000] tot_loss=1.938 (perp=9.321, rec=0.074), tot_loss_proj:2.286 [t=0.27s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.942 (perp=9.321, rec=0.077), tot_loss_proj:2.282 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.931 (perp=9.321, rec=0.066), tot_loss_proj:2.292 [t=0.28s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[ 900/2000] tot_loss=1.937 (perp=9.321, rec=0.072), tot_loss_proj:2.300 [t=0.25s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.925 (perp=9.321, rec=0.061), tot_loss_proj:2.289 [t=0.27s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1000/2000] tot_loss=1.930 (perp=9.321, rec=0.066), tot_loss_proj:2.294 [t=0.25s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[1050/2000] tot_loss=1.940 (perp=9.321, rec=0.075), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1100/2000] tot_loss=1.940 (perp=9.321, rec=0.076), tot_loss_proj:2.298 [t=0.27s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1150/2000] tot_loss=1.931 (perp=9.321, rec=0.067), tot_loss_proj:2.293 [t=0.25s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[1200/2000] tot_loss=1.935 (perp=9.321, rec=0.070), tot_loss_proj:2.284 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1250/2000] tot_loss=1.943 (perp=9.321, rec=0.078), tot_loss_proj:2.287 [t=0.27s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1300/2000] tot_loss=1.934 (perp=9.321, rec=0.069), tot_loss_proj:2.278 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[1350/2000] tot_loss=1.931 (perp=9.321, rec=0.067), tot_loss_proj:2.300 [t=0.28s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1400/2000] tot_loss=1.936 (perp=9.321, rec=0.072), tot_loss_proj:2.296 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1450/2000] tot_loss=1.942 (perp=9.321, rec=0.078), tot_loss_proj:2.299 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[1500/2000] tot_loss=1.934 (perp=9.321, rec=0.070), tot_loss_proj:2.288 [t=0.27s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1550/2000] tot_loss=1.935 (perp=9.321, rec=0.071), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1600/2000] tot_loss=1.932 (perp=9.321, rec=0.068), tot_loss_proj:2.290 [t=0.27s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[1650/2000] tot_loss=1.928 (perp=9.321, rec=0.063), tot_loss_proj:2.285 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1700/2000] tot_loss=1.933 (perp=9.321, rec=0.069), tot_loss_proj:2.288 [t=0.28s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1750/2000] tot_loss=1.937 (perp=9.321, rec=0.073), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
[1800/2000] tot_loss=1.943 (perp=9.321, rec=0.079), tot_loss_proj:2.299 [t=0.30s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1850/2000] tot_loss=1.920 (perp=9.321, rec=0.056), tot_loss_proj:2.289 [t=0.26s]
prediction: ['[CLS] too clever what english call clever by half ` [SEP]']
Attempt swap
[1900/2000] tot_loss=1.997 (perp=9.678, rec=0.061), tot_loss_proj:2.427 [t=0.27s]
prediction: ['[CLS] too the what english call clever by half ` [SEP]']
[1950/2000] tot_loss=2.004 (perp=9.678, rec=0.068), tot_loss_proj:2.431 [t=0.26s]
prediction: ['[CLS] too the what english call clever by half ` [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.755 (perp=8.477, rec=0.060), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] too what the english call clever by half ` [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] too the what english call clever by half ` [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 144.444

[Aggregate metrics]:
rouge1     | fm: 86.698 | p: 85.883 | r: 87.686
rouge2     | fm: 46.989 | p: 46.661 | r: 47.410
rougeL     | fm: 73.413 | p: 72.803 | r: 74.174
rougeLsum  | fm: 73.391 | p: 72.793 | r: 74.178
r1fm+r2fm = 133.687

input #50 time: 0:10:57 | total time: 9:12:32


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.747601330280304 for ['[CLS] spike rallyolved highlighted ren issue make to angelbridge [SEP]']
[Init] best rec loss: 0.7367525100708008 for ['[CLS] wayface distinguishbar jurisdiction genius would balthazar reichnsor [SEP]']
[Init] best rec loss: 0.721007227897644 for ['[CLS] quarterback minutes protocol [MASK] bracketsht leave european sp nerve [SEP]']
[Init] best rec loss: 0.7163325548171997 for ['[CLS] factors directing cargo despite able instruments stoppingbridge step bite [SEP]']
[Init] best rec loss: 0.7139209508895874 for ['[CLS] air chromosome supported kansas convincedfr clock colliery exact [MASK] [SEP]']
[Init] best rec loss: 0.7011088132858276 for ['[CLS] si oxygens premier jurisdiction oked materials abstract jalan [SEP]']
[Init] best rec loss: 0.7008786797523499 for ['[CLS] § burger stone sleeves national once start ultimately trip there [SEP]']
[Init] best rec loss: 0.6950970888137817 for ['[CLS] pen touching choice under measurements grip public in aidan site [SEP]']
[Init] best perm rec loss: 0.6925466060638428 for ['[CLS] under grip choice aidan measurements public touching pen site in [SEP]']
[Init] best perm rec loss: 0.6904445290565491 for ['[CLS] under aidan public choice pen site in touching grip measurements [SEP]']
[Init] best perm rec loss: 0.689257800579071 for ['[CLS] touching aidan measurements under choice pen grip site public in [SEP]']
[Init] best perm rec loss: 0.6878114342689514 for ['[CLS] choice measurements touching in pen aidan public under grip site [SEP]']
[Init] best perm rec loss: 0.6877139806747437 for ['[CLS] in public grip choice measurements aidan under pen touching site [SEP]']
[Init] best perm rec loss: 0.68709397315979 for ['[CLS] in pen touching aidan site under public choice grip measurements [SEP]']
[Init] best perm rec loss: 0.6867823600769043 for ['[CLS] under grip pen touching site measurements in aidan public choice [SEP]']
[Init] best perm rec loss: 0.6863812208175659 for ['[CLS] measurements site in under pen choice grip public aidan touching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.770 (perp=12.331, rec=0.304), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] sucks sucks but ist funny moment funny ball several limited [SEP]']
[ 100/2000] tot_loss=2.450 (perp=11.331, rec=0.183), tot_loss_proj:2.818 [t=0.26s]
prediction: ['[CLS] sucks sucks but has funny moment funny none or or [SEP]']
[ 150/2000] tot_loss=2.387 (perp=11.331, rec=0.121), tot_loss_proj:2.821 [t=0.26s]
prediction: ['[CLS] sucks sucks but has funny moment funny none or or [SEP]']
[ 200/2000] tot_loss=1.852 (perp=8.717, rec=0.109), tot_loss_proj:2.272 [t=0.25s]
prediction: ['[CLS] sucks sucks but has a moment funny. or two [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.563 (perp=7.365, rec=0.090), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] sucks sucks but has a funny moment. or two [SEP]']
[ 300/2000] tot_loss=1.542 (perp=7.365, rec=0.069), tot_loss_proj:1.884 [t=0.28s]
prediction: ['[CLS] sucks sucks but has a funny moment. or two [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.495 (perp=7.051, rec=0.085), tot_loss_proj:1.604 [t=0.28s]
prediction: ['[CLS] sucks sucks. but has a funny moment or two [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.323 (perp=6.248, rec=0.073), tot_loss_proj:1.433 [t=0.26s]
prediction: ['[CLS] sucks sucks but has a funny moment or two. [SEP]']
[ 450/2000] tot_loss=1.098 (perp=5.210, rec=0.056), tot_loss_proj:1.137 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.109 (perp=5.210, rec=0.067), tot_loss_proj:1.144 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.107 (perp=5.210, rec=0.065), tot_loss_proj:1.140 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[ 600/2000] tot_loss=1.104 (perp=5.210, rec=0.062), tot_loss_proj:1.145 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.103 (perp=5.210, rec=0.061), tot_loss_proj:1.140 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.098 (perp=5.210, rec=0.056), tot_loss_proj:1.135 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[ 750/2000] tot_loss=1.101 (perp=5.210, rec=0.059), tot_loss_proj:1.138 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.101 (perp=5.210, rec=0.059), tot_loss_proj:1.126 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.097 (perp=5.210, rec=0.055), tot_loss_proj:1.138 [t=0.29s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[ 900/2000] tot_loss=1.110 (perp=5.210, rec=0.068), tot_loss_proj:1.128 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.101 (perp=5.210, rec=0.059), tot_loss_proj:1.149 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.095 (perp=5.210, rec=0.053), tot_loss_proj:1.142 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1050/2000] tot_loss=1.099 (perp=5.210, rec=0.057), tot_loss_proj:1.139 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.105 (perp=5.210, rec=0.063), tot_loss_proj:1.135 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.107 (perp=5.210, rec=0.065), tot_loss_proj:1.131 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1200/2000] tot_loss=1.106 (perp=5.210, rec=0.064), tot_loss_proj:1.143 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.110 (perp=5.210, rec=0.068), tot_loss_proj:1.133 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.104 (perp=5.210, rec=0.062), tot_loss_proj:1.128 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1350/2000] tot_loss=1.103 (perp=5.210, rec=0.061), tot_loss_proj:1.138 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.107 (perp=5.210, rec=0.065), tot_loss_proj:1.127 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.102 (perp=5.210, rec=0.060), tot_loss_proj:1.137 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1500/2000] tot_loss=1.103 (perp=5.210, rec=0.061), tot_loss_proj:1.132 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.097 (perp=5.210, rec=0.055), tot_loss_proj:1.138 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.099 (perp=5.210, rec=0.057), tot_loss_proj:1.145 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1650/2000] tot_loss=1.101 (perp=5.210, rec=0.059), tot_loss_proj:1.130 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.104 (perp=5.210, rec=0.062), tot_loss_proj:1.143 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.100 (perp=5.210, rec=0.058), tot_loss_proj:1.137 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1800/2000] tot_loss=1.092 (perp=5.210, rec=0.050), tot_loss_proj:1.138 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.101 (perp=5.210, rec=0.059), tot_loss_proj:1.135 [t=0.27s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.113 (perp=5.210, rec=0.071), tot_loss_proj:1.130 [t=0.25s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
[1950/2000] tot_loss=1.098 (perp=5.210, rec=0.056), tot_loss_proj:1.133 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.106 (perp=5.210, rec=0.064), tot_loss_proj:1.141 [t=0.26s]
prediction: ['[CLS] sucks, but has a funny moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.924 | p: 86.139 | r: 87.880
rouge2     | fm: 48.220 | p: 47.895 | r: 48.595
rougeL     | fm: 73.897 | p: 73.319 | r: 74.731
rougeLsum  | fm: 73.891 | p: 73.331 | r: 74.661
r1fm+r2fm = 135.144

input #51 time: 0:10:57 | total time: 9:23:29


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9358826875686646 for ['[CLS] trip border working [SEP]']
[Init] best rec loss: 0.9030588865280151 for ['[CLS] that pantheon importantly [SEP]']
[Init] best rec loss: 0.8614285588264465 for ['[CLS]entation enough yet [SEP]']
[Init] best rec loss: 0.846176266670227 for ['[CLS] exerciseogist distinguished [SEP]']
[Init] best rec loss: 0.832085371017456 for ['[CLS]rgeon clary hook [SEP]']
[Init] best rec loss: 0.8260961174964905 for ['[CLS] [SEP] glasses income [SEP]']
[Init] best rec loss: 0.7813636064529419 for ['[CLS] graves trump twice [SEP]']
[Init] best rec loss: 0.7758081555366516 for ['[CLS] 2018 1970 betting [SEP]']
[Init] best rec loss: 0.7410877346992493 for ['[CLS] science dissolved terence [SEP]']
[Init] best perm rec loss: 0.7408486604690552 for ['[CLS] terence dissolved science [SEP]']
[Init] best perm rec loss: 0.7393209934234619 for ['[CLS] terence science dissolved [SEP]']
[Init] best perm rec loss: 0.7386616468429565 for ['[CLS] science terence dissolved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.502 (perp=11.737, rec=0.154), tot_loss_proj:2.635 [t=0.26s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.180 (perp=10.529, rec=0.075), tot_loss_proj:2.204 [t=0.25s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 150/2000] tot_loss=2.159 (perp=10.529, rec=0.053), tot_loss_proj:2.198 [t=0.25s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.169 (perp=10.529, rec=0.063), tot_loss_proj:2.200 [t=0.28s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.799 (perp=8.482, rec=0.102), tot_loss_proj:2.152 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.767 (perp=8.482, rec=0.070), tot_loss_proj:2.154 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.758 (perp=8.482, rec=0.062), tot_loss_proj:2.156 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.760 (perp=8.482, rec=0.063), tot_loss_proj:2.149 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.764 (perp=8.482, rec=0.068), tot_loss_proj:2.151 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.774 (perp=8.482, rec=0.077), tot_loss_proj:2.152 [t=0.34s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.771 (perp=8.482, rec=0.075), tot_loss_proj:2.157 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.754 (perp=8.482, rec=0.057), tot_loss_proj:2.148 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.763 (perp=8.482, rec=0.066), tot_loss_proj:2.140 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.765 (perp=8.482, rec=0.069), tot_loss_proj:2.147 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.771 (perp=8.482, rec=0.075), tot_loss_proj:2.154 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.760 (perp=8.482, rec=0.063), tot_loss_proj:2.142 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.764 (perp=8.482, rec=0.067), tot_loss_proj:2.149 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.767 (perp=8.482, rec=0.071), tot_loss_proj:2.148 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.756 (perp=8.482, rec=0.059), tot_loss_proj:2.153 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.761 (perp=8.482, rec=0.064), tot_loss_proj:2.149 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.768 (perp=8.482, rec=0.072), tot_loss_proj:2.148 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.767 (perp=8.482, rec=0.070), tot_loss_proj:2.140 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.764 (perp=8.482, rec=0.068), tot_loss_proj:2.153 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.756 (perp=8.482, rec=0.059), tot_loss_proj:2.144 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.767 (perp=8.482, rec=0.070), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.757 (perp=8.482, rec=0.060), tot_loss_proj:2.154 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.780 (perp=8.482, rec=0.083), tot_loss_proj:2.147 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.753 (perp=8.482, rec=0.057), tot_loss_proj:2.149 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.759 (perp=8.482, rec=0.063), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.757 (perp=8.482, rec=0.061), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.762 (perp=8.482, rec=0.066), tot_loss_proj:2.156 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.755 (perp=8.482, rec=0.058), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.757 (perp=8.482, rec=0.060), tot_loss_proj:2.147 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.755 (perp=8.482, rec=0.058), tot_loss_proj:2.147 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.756 (perp=8.482, rec=0.060), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.750 (perp=8.482, rec=0.053), tot_loss_proj:2.147 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.755 (perp=8.482, rec=0.059), tot_loss_proj:2.144 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.769 (perp=8.482, rec=0.073), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.756 (perp=8.482, rec=0.059), tot_loss_proj:2.155 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.758 (perp=8.482, rec=0.062), tot_loss_proj:2.142 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.111 | p: 86.351 | r: 88.101
rouge2     | fm: 47.297 | p: 46.919 | r: 47.707
rougeL     | fm: 73.909 | p: 73.381 | r: 74.733
rougeLsum  | fm: 73.918 | p: 73.341 | r: 74.702
r1fm+r2fm = 134.408

input #52 time: 0:10:55 | total time: 9:34:24


Running input #53 of 100.
reference: 
========================
flinching 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.830899178981781 for ['[CLS] weeklyathy [SEP]']
[Init] best rec loss: 0.7761895060539246 for ['[CLS]zen day [SEP]']
[Init] best rec loss: 0.7337269186973572 for ['[CLS] universal challenge [SEP]']
[Init] best rec loss: 0.7257575988769531 for ['[CLS]ome dot [SEP]']
[Init] best rec loss: 0.7076020836830139 for ['[CLS] sierra ins [SEP]']
[Init] best rec loss: 0.6890561580657959 for ['[CLS] just [SEP] [SEP]']
[Init] best perm rec loss: 0.687833309173584 for ['[CLS] [SEP] just [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.677 (perp=12.492, rec=0.179), tot_loss_proj:2.949 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=1.685 (perp=8.090, rec=0.067), tot_loss_proj:1.671 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[ 150/2000] tot_loss=1.676 (perp=8.090, rec=0.058), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.672 (perp=8.090, rec=0.054), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.674 (perp=8.090, rec=0.057), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.678 (perp=8.090, rec=0.060), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.676 (perp=8.090, rec=0.058), tot_loss_proj:1.687 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.665 (perp=8.090, rec=0.048), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.685 (perp=8.090, rec=0.067), tot_loss_proj:1.681 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.676 (perp=8.090, rec=0.058), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.669 (perp=8.090, rec=0.051), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.680 (perp=8.090, rec=0.062), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.669 (perp=8.090, rec=0.051), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.666 (perp=8.090, rec=0.048), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.680 (perp=8.090, rec=0.062), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.686 (perp=8.090, rec=0.068), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.672 (perp=8.090, rec=0.054), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.674 (perp=8.090, rec=0.056), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.671 (perp=8.090, rec=0.053), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.670 (perp=8.090, rec=0.052), tot_loss_proj:1.683 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.679 (perp=8.090, rec=0.061), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.670 (perp=8.090, rec=0.052), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.674 (perp=8.090, rec=0.056), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.681 (perp=8.090, rec=0.063), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.679 (perp=8.090, rec=0.061), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=8.090, rec=0.054), tot_loss_proj:1.696 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.678 (perp=8.090, rec=0.060), tot_loss_proj:1.673 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.667 (perp=8.090, rec=0.049), tot_loss_proj:1.686 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.689 (perp=8.090, rec=0.071), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.668 (perp=8.090, rec=0.050), tot_loss_proj:1.678 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.681 (perp=8.090, rec=0.063), tot_loss_proj:1.681 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.676 (perp=8.090, rec=0.058), tot_loss_proj:1.674 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.669 (perp=8.090, rec=0.051), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=8.090, rec=0.055), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.681 (perp=8.090, rec=0.063), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.680 (perp=8.090, rec=0.062), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.681 (perp=8.090, rec=0.063), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=8.090, rec=0.063), tot_loss_proj:1.687 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.682 (perp=8.090, rec=0.064), tot_loss_proj:1.679 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.672 (perp=8.090, rec=0.054), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.369 | p: 86.615 | r: 88.277
rouge2     | fm: 48.284 | p: 47.931 | r: 48.594
rougeL     | fm: 74.444 | p: 73.882 | r: 75.146
rougeLsum  | fm: 74.449 | p: 73.855 | r: 75.174
r1fm+r2fm = 135.653

input #53 time: 0:10:54 | total time: 9:45:19


Running input #54 of 100.
reference: 
========================
hot topics 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.8895717263221741 for ['[CLS] someone business [SEP]']
[Init] best rec loss: 0.8315245509147644 for ['[CLS] ho delivery [SEP]']
[Init] best rec loss: 0.7918387651443481 for ['[CLS] within starting [SEP]']
[Init] best rec loss: 0.7088462710380554 for ['[CLS]wing played [SEP]']
[Init] best rec loss: 0.6963782906532288 for ['[CLS] acres impression [SEP]']
[Init] best rec loss: 0.6641737222671509 for ['[CLS] anything 2016 [SEP]']
[Init] best rec loss: 0.655841052532196 for ['[CLS] hm off [SEP]']
[Init] best rec loss: 0.6254106163978577 for ['[CLS] ton midnight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.875 (perp=8.198, rec=0.235), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=1.719 (perp=8.198, rec=0.079), tot_loss_proj:1.729 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.713 (perp=8.198, rec=0.074), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.701 (perp=8.198, rec=0.061), tot_loss_proj:1.719 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.700 (perp=8.198, rec=0.060), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.688 (perp=8.198, rec=0.049), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.695 (perp=8.198, rec=0.055), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.704 (perp=8.198, rec=0.064), tot_loss_proj:1.722 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.696 (perp=8.198, rec=0.056), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.699 (perp=8.198, rec=0.059), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.701 (perp=8.198, rec=0.062), tot_loss_proj:1.724 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.699 (perp=8.198, rec=0.059), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=8.198, rec=0.056), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.701 (perp=8.198, rec=0.061), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.706 (perp=8.198, rec=0.066), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.708 (perp=8.198, rec=0.068), tot_loss_proj:1.730 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.691 (perp=8.198, rec=0.052), tot_loss_proj:1.730 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.697 (perp=8.198, rec=0.058), tot_loss_proj:1.714 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.689 (perp=8.198, rec=0.050), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.697 (perp=8.198, rec=0.057), tot_loss_proj:1.721 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.697 (perp=8.198, rec=0.057), tot_loss_proj:1.724 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.198, rec=0.064), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.699 (perp=8.198, rec=0.060), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.696 (perp=8.198, rec=0.056), tot_loss_proj:1.724 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=8.198, rec=0.066), tot_loss_proj:1.727 [t=0.31s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.705 (perp=8.198, rec=0.065), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.706 (perp=8.198, rec=0.067), tot_loss_proj:1.719 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.705 (perp=8.198, rec=0.065), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.700 (perp=8.198, rec=0.061), tot_loss_proj:1.725 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.701 (perp=8.198, rec=0.061), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.695 (perp=8.198, rec=0.055), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.695 (perp=8.198, rec=0.055), tot_loss_proj:1.714 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.697 (perp=8.198, rec=0.057), tot_loss_proj:1.727 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.697 (perp=8.198, rec=0.058), tot_loss_proj:1.710 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=8.198, rec=0.062), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.694 (perp=8.198, rec=0.054), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.698 (perp=8.198, rec=0.058), tot_loss_proj:1.724 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.689 (perp=8.198, rec=0.050), tot_loss_proj:1.724 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.712 (perp=8.198, rec=0.073), tot_loss_proj:1.719 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.707 (perp=8.198, rec=0.068), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.546 | p: 86.827 | r: 88.443
rouge2     | fm: 49.224 | p: 48.882 | r: 49.567
rougeL     | fm: 74.798 | p: 74.240 | r: 75.578
rougeLsum  | fm: 74.821 | p: 74.270 | r: 75.565
r1fm+r2fm = 136.770

input #54 time: 0:10:55 | total time: 9:56:15


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8758000135421753 for ['[CLS] pi cool trunk [SEP]']
[Init] best rec loss: 0.8310320377349854 for ['[CLS] is fifahyllum [SEP]']
[Init] best rec loss: 0.8267644047737122 for ['[CLS] attraction cows task [SEP]']
[Init] best rec loss: 0.8248321413993835 for ['[CLS] david excellence bay [SEP]']
[Init] best rec loss: 0.7800410985946655 for ['[CLS] union surname dana [SEP]']
[Init] best rec loss: 0.7575075626373291 for ['[CLS] kanye cult her [SEP]']
[Init] best rec loss: 0.7118554711341858 for ['[CLS] circular mass clients [SEP]']
[Init] best perm rec loss: 0.7077018618583679 for ['[CLS] clients circular mass [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.592 (perp=11.290, rec=0.334), tot_loss_proj:2.751 [t=0.25s]
prediction: ['[CLS] much too settles [SEP]']
[ 100/2000] tot_loss=1.849 (perp=8.671, rec=0.115), tot_loss_proj:1.813 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[ 150/2000] tot_loss=1.800 (perp=8.671, rec=0.066), tot_loss_proj:1.811 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[ 200/2000] tot_loss=1.799 (perp=8.671, rec=0.065), tot_loss_proj:1.800 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.794 (perp=8.671, rec=0.059), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.795 (perp=8.671, rec=0.061), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.792 (perp=8.671, rec=0.058), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.791 (perp=8.671, rec=0.057), tot_loss_proj:1.795 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.799 (perp=8.671, rec=0.065), tot_loss_proj:1.797 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.798 (perp=8.671, rec=0.064), tot_loss_proj:1.795 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.798 (perp=8.671, rec=0.064), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.789 (perp=8.671, rec=0.055), tot_loss_proj:1.798 [t=0.29s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.791 (perp=8.671, rec=0.056), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.794 (perp=8.671, rec=0.060), tot_loss_proj:1.794 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.800 (perp=8.671, rec=0.066), tot_loss_proj:1.800 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.788 (perp=8.671, rec=0.054), tot_loss_proj:1.795 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.791 (perp=8.671, rec=0.057), tot_loss_proj:1.800 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.795 (perp=8.671, rec=0.061), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.671, rec=0.061), tot_loss_proj:1.798 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.806 (perp=8.671, rec=0.072), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.803 (perp=8.671, rec=0.069), tot_loss_proj:1.802 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.795 (perp=8.671, rec=0.060), tot_loss_proj:1.793 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.791 (perp=8.671, rec=0.057), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.671, rec=0.054), tot_loss_proj:1.805 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.801 (perp=8.671, rec=0.067), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.791 (perp=8.671, rec=0.056), tot_loss_proj:1.807 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.795 (perp=8.671, rec=0.061), tot_loss_proj:1.802 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.790 (perp=8.671, rec=0.056), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.798 (perp=8.671, rec=0.064), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.790 (perp=8.671, rec=0.056), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.792 (perp=8.671, rec=0.058), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.794 (perp=8.671, rec=0.060), tot_loss_proj:1.805 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.795 (perp=8.671, rec=0.061), tot_loss_proj:1.803 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.792 (perp=8.671, rec=0.058), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.795 (perp=8.671, rec=0.061), tot_loss_proj:1.795 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.797 (perp=8.671, rec=0.063), tot_loss_proj:1.802 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=8.671, rec=0.060), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.671, rec=0.062), tot_loss_proj:1.806 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.802 (perp=8.671, rec=0.067), tot_loss_proj:1.810 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.801 (perp=8.671, rec=0.067), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.852 | p: 87.074 | r: 88.724
rouge2     | fm: 50.003 | p: 49.695 | r: 50.434
rougeL     | fm: 75.412 | p: 74.884 | r: 76.040
rougeLsum  | fm: 75.218 | p: 74.670 | r: 75.950
r1fm+r2fm = 137.855

input #55 time: 0:10:54 | total time: 10:07:09


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8637150526046753 for ['[CLS] against commons regained short seeoot gameplay escalated thousand fares before clause inn lgbt because transition lyon can inc [MASK]ism [SEP]']
[Init] best rec loss: 0.8576953411102295 for ['[CLS] error speedy ayetainedraße resignation racesenersi this tr turned graduate hope menacing royal scored maj stunning cost remains [SEP]']
[Init] best rec loss: 0.8500183820724487 for ['[CLS] knock vlad dependent roadsbolt highland structure subsequently compete wax gainsptive spring movieboards holocaust stated ali greco right ranked [SEP]']
[Init] best rec loss: 0.8394728899002075 for ['[CLS] heats pages teaerative military now chu hurricanecaked dove gaping undergative furlongs railroad arena block advertising authority family [SEP]']
[Init] best rec loss: 0.8384726047515869 for ['[CLS]cation joinedunt nice activedra a marty orgible politicalitarian triangle clad mockce reduced ribbon probablesisdun [SEP]']
[Init] best rec loss: 0.8297247290611267 for ['[CLS] antplex each enough proud princedent also ross earl literally alberta nationszzi millennium bull inmates belonged fiscal smashwords in [SEP]']
[Init] best rec loss: 0.827072024345398 for ['[CLS] liability tradition noise record blinked boy endowed running scheduled questionmediaha >arth siege numbers lying heard always stomach cavalier [SEP]']
[Init] best perm rec loss: 0.825847864151001 for ['[CLS]ha endowed blinked tradition numbersmedia stomach boyarth > always scheduled question running cavalier record heard lying noise liability siege [SEP]']
[Init] best perm rec loss: 0.8217834234237671 for ['[CLS] siege always cavalier question heard lyingha scheduledmedia blinked endowed boy > traditionarth running liability noise stomach record numbers [SEP]']
[Init] best perm rec loss: 0.821215808391571 for ['[CLS] record numbersarthmedia running liability blinked scheduled cavalier boy > lying tradition always stomachha siege heard endowed question noise [SEP]']
[Init] best perm rec loss: 0.8209505081176758 for ['[CLS] record siege always lying endowed cavaliermediahaarth noise scheduled boy liability question running heard tradition > stomach blinked numbers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.725 (perp=12.089, rec=0.307), tot_loss_proj:3.187 [t=0.27s]
prediction: ['[CLS] damage films suffer apocalyptic nasty and delle could maybe not dude costly certain childhood running injury costly study grades analysis compound [SEP]']
[ 100/2000] tot_loss=2.457 (perp=11.260, rec=0.205), tot_loss_proj:2.917 [t=0.27s]
prediction: ['[CLS] damage films cause economic damagepara delle loads that cannot solutions costly entire years fix analysis costly analysis films analysis could [SEP]']
[ 150/2000] tot_loss=2.584 (perp=12.121, rec=0.159), tot_loss_proj:3.171 [t=0.28s]
prediction: ['[CLS] damage films cause airline damagepara elevations loads that never which costly loads years fix analysis costly analysis films fix could [SEP]']
[ 200/2000] tot_loss=2.481 (perp=11.791, rec=0.123), tot_loss_proj:3.106 [t=0.27s]
prediction: ['[CLS] damage films cause airline damagepara cause will that never which costly loads years fix analysis costly analysis films fix could [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.353 (perp=11.221, rec=0.109), tot_loss_proj:3.024 [t=0.26s]
prediction: ['[CLS] damage films cause airline loadspara which will that never cause costly loads years fix analysis costly analysis films fix could [SEP]']
[ 300/2000] tot_loss=2.456 (perp=11.803, rec=0.095), tot_loss_proj:3.127 [t=0.28s]
prediction: ['[CLS] damage films cause airline loadspara which will that neverble costly loads years fix of costly analysis loads fix could [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.203 (perp=10.530, rec=0.097), tot_loss_proj:2.893 [t=0.27s]
prediction: ['[CLS] damage films cause ofblepara which will that neverble costly loads years of costly analysis loads fix could fix [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.105 (perp=10.001, rec=0.105), tot_loss_proj:2.644 [t=0.26s]
prediction: ['[CLS] damage films cause irblepara which will that fixble costly loads years of costly analysis loads fix could never [SEP]']
[ 450/2000] tot_loss=2.091 (perp=10.012, rec=0.088), tot_loss_proj:2.638 [t=0.26s]
prediction: ['[CLS] damage films cause irblepara which will that fixble costly years years of costly analysis loads fix could never [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.001 (perp=9.564, rec=0.089), tot_loss_proj:2.511 [t=0.27s]
prediction: ['[CLS] damage will cause irblepara which films that fixble costly years years of costly analysis loads fix could never [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.669 (perp=7.878, rec=0.093), tot_loss_proj:2.160 [t=0.26s]
prediction: ['[CLS] damage will cause irbleparable films that fix which costly and years of costly analysis loads fix could never [SEP]']
[ 600/2000] tot_loss=1.663 (perp=7.878, rec=0.087), tot_loss_proj:2.193 [t=0.24s]
prediction: ['[CLS] damage will cause irbleparable films that fix which costly and years of costly analysis loads fix could never [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.809 (perp=8.644, rec=0.080), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] damage will cause irblepara of films that fix costly and years of costly analysis which loads fix could never [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.772 (perp=8.421, rec=0.088), tot_loss_proj:2.144 [t=0.25s]
prediction: ['[CLS] damage will cause ir ofparable films thatxi costly and years of costly analysis which loads fix could never [SEP]']
[ 750/2000] tot_loss=1.764 (perp=8.421, rec=0.080), tot_loss_proj:2.136 [t=0.27s]
prediction: ['[CLS] damage will cause ir ofparable films thatxi costly and years of costly analysis which loads fix could never [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.728 (perp=8.238, rec=0.081), tot_loss_proj:2.097 [t=0.26s]
prediction: ['[CLS] damage will cause ir ofparable films thatxi costly and years of costly analysis which could fix loads never [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.725 (perp=8.238, rec=0.078), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] damage will cause ir ofparable films thatxi costly and years of costly analysis which could fix loads never [SEP]']
[ 900/2000] tot_loss=1.722 (perp=8.238, rec=0.074), tot_loss_proj:2.097 [t=0.27s]
prediction: ['[CLS] damage will cause ir ofparable films thatxi costly and years of costly analysis which could fix loads never [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.607 (perp=7.625, rec=0.082), tot_loss_proj:1.952 [t=0.26s]
prediction: ['[CLS] damage will cause ir ofxiparable films that costly and years of costly analysis which could fix loads never [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.560 (perp=7.372, rec=0.085), tot_loss_proj:2.002 [t=0.27s]
prediction: ['[CLS] damage will cause ir ofxiparable films that and years of costly analysis which could fix costly loads never [SEP]']
[1050/2000] tot_loss=1.541 (perp=7.326, rec=0.076), tot_loss_proj:1.961 [t=0.27s]
prediction: ['[CLS] damage will cause ir ofreparable films that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.395 (perp=6.577, rec=0.080), tot_loss_proj:1.837 [t=0.26s]
prediction: ['[CLS] damage will cause irreparable of films that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.369 (perp=6.407, rec=0.088), tot_loss_proj:1.826 [t=0.27s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
[1200/2000] tot_loss=1.360 (perp=6.407, rec=0.079), tot_loss_proj:1.827 [t=0.27s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1250/2000] tot_loss=1.365 (perp=6.407, rec=0.084), tot_loss_proj:1.826 [t=0.26s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1300/2000] tot_loss=1.359 (perp=6.407, rec=0.077), tot_loss_proj:1.826 [t=0.29s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
[1350/2000] tot_loss=1.372 (perp=6.407, rec=0.091), tot_loss_proj:1.833 [t=0.29s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1400/2000] tot_loss=1.361 (perp=6.407, rec=0.079), tot_loss_proj:1.828 [t=0.29s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1450/2000] tot_loss=1.359 (perp=6.407, rec=0.077), tot_loss_proj:1.830 [t=0.26s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
[1500/2000] tot_loss=1.360 (perp=6.407, rec=0.079), tot_loss_proj:1.826 [t=0.27s]
prediction: ['[CLS] damage will cause irreparable films of that and years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.267 (perp=5.974, rec=0.073), tot_loss_proj:1.692 [t=0.26s]
prediction: ['[CLS] damage will cause irreparable films and that of years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1600/2000] tot_loss=1.278 (perp=5.974, rec=0.083), tot_loss_proj:1.689 [t=0.28s]
prediction: ['[CLS] damage will cause irreparable films and that of years of costly analysis which could fix costly loads never [SEP]']
[1650/2000] tot_loss=1.274 (perp=5.974, rec=0.080), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] damage will cause irreparable films and that of years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.212 (perp=5.625, rec=0.087), tot_loss_proj:1.570 [t=0.26s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1750/2000] tot_loss=1.206 (perp=5.625, rec=0.081), tot_loss_proj:1.573 [t=0.27s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
[1800/2000] tot_loss=1.204 (perp=5.625, rec=0.079), tot_loss_proj:1.569 [t=0.28s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1850/2000] tot_loss=1.206 (perp=5.625, rec=0.081), tot_loss_proj:1.575 [t=0.26s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.209 (perp=5.625, rec=0.084), tot_loss_proj:1.576 [t=0.26s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
[1950/2000] tot_loss=1.196 (perp=5.625, rec=0.071), tot_loss_proj:1.574 [t=0.28s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
Attempt swap
[2000/2000] tot_loss=1.200 (perp=5.625, rec=0.076), tot_loss_proj:1.570 [t=0.27s]
prediction: ['[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films will cause irreparable damage and that of years of costly analysis which could fix costly loads never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 31.579 | p: 31.579 | r: 31.579
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 126.579

[Aggregate metrics]:
rouge1     | fm: 87.900 | p: 87.126 | r: 88.774
rouge2     | fm: 49.690 | p: 49.390 | r: 50.098
rougeL     | fm: 75.204 | p: 74.732 | r: 75.958
rougeLsum  | fm: 74.972 | p: 74.411 | r: 75.708
r1fm+r2fm = 137.590

input #56 time: 0:11:05 | total time: 10:18:14


Running input #57 of 100.
reference: 
========================
wears 
========================
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8630331158638 for ['[CLS] book [SEP]']
[Init] best rec loss: 0.8287703394889832 for ['[CLS] kennedy [SEP]']
[Init] best rec loss: 0.7554885745048523 for ['[CLS] free [SEP]']
[Init] best rec loss: 0.7197505831718445 for ['[CLS] pioneered [SEP]']
[Init] best rec loss: 0.7080162763595581 for ['[CLS] mob [SEP]']
[Init] best rec loss: 0.6661884784698486 for ['[CLS] crime [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.572 (perp=12.283, rec=0.115), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.532 (perp=12.283, rec=0.075), tot_loss_proj:2.532 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.510 (perp=12.283, rec=0.054), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.527 (perp=12.283, rec=0.071), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.513 (perp=12.283, rec=0.057), tot_loss_proj:2.529 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.511 (perp=12.283, rec=0.055), tot_loss_proj:2.519 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.524 (perp=12.283, rec=0.067), tot_loss_proj:2.518 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.522 (perp=12.283, rec=0.065), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.529 (perp=12.283, rec=0.072), tot_loss_proj:2.512 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.518 (perp=12.283, rec=0.062), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.531 (perp=12.283, rec=0.074), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.528 (perp=12.283, rec=0.072), tot_loss_proj:2.521 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.498 (perp=12.283, rec=0.041), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.514 (perp=12.283, rec=0.057), tot_loss_proj:2.512 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.519 (perp=12.283, rec=0.062), tot_loss_proj:2.527 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.510 (perp=12.283, rec=0.053), tot_loss_proj:2.524 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.501 (perp=12.283, rec=0.045), tot_loss_proj:2.515 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.517 (perp=12.283, rec=0.061), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.509 (perp=12.283, rec=0.053), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.505 (perp=12.283, rec=0.049), tot_loss_proj:2.535 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.511 (perp=12.283, rec=0.054), tot_loss_proj:2.535 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.515 (perp=12.283, rec=0.058), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.519 (perp=12.283, rec=0.062), tot_loss_proj:2.514 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.509 (perp=12.283, rec=0.052), tot_loss_proj:2.505 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.510 (perp=12.283, rec=0.053), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.500 (perp=12.283, rec=0.044), tot_loss_proj:2.527 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.514 (perp=12.283, rec=0.058), tot_loss_proj:2.511 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.506 (perp=12.283, rec=0.050), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.517 (perp=12.283, rec=0.060), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.522 (perp=12.283, rec=0.066), tot_loss_proj:2.526 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.522 (perp=12.283, rec=0.066), tot_loss_proj:2.509 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.520 (perp=12.283, rec=0.064), tot_loss_proj:2.522 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.513 (perp=12.283, rec=0.056), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.527 (perp=12.283, rec=0.071), tot_loss_proj:2.513 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.523 (perp=12.283, rec=0.066), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.522 (perp=12.283, rec=0.066), tot_loss_proj:2.505 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.516 (perp=12.283, rec=0.059), tot_loss_proj:2.523 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.511 (perp=12.283, rec=0.055), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.520 (perp=12.283, rec=0.063), tot_loss_proj:2.510 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.513 (perp=12.283, rec=0.056), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.167 | p: 87.452 | r: 88.984
rouge2     | fm: 50.695 | p: 50.395 | r: 51.073
rougeL     | fm: 75.611 | p: 75.139 | r: 76.329
rougeLsum  | fm: 75.535 | p: 75.064 | r: 76.262
r1fm+r2fm = 138.862

input #57 time: 0:10:50 | total time: 10:29:05


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.023207426071167 for ['[CLS] issnvr cipher drawn so albany onlyky ⟩ity himself detroit game toorescence impressed [SEP]']
[Init] best rec loss: 0.9891429543495178 for ['[CLS] countedvr considering ride kane sho algeria saying securedggs altmament moose recorded cylinder boys [SEP]']
[Init] best rec loss: 0.9729067087173462 for ['[CLS] had horn 1500 first scare complex deep dom banner deux faye movement lots evans sponsored condensed [SEP]']
[Init] best rec loss: 0.9727240800857544 for ['[CLS] sports principal meant square booth purecene complex dionardedado test appreciate depression blew page [SEP]']
[Init] best rec loss: 0.9646762609481812 for ['[CLS] gen year likely reilly time senators peace introduction labellce poisontensashiwind behalfand [SEP]']
[Init] best rec loss: 0.9099571108818054 for ['[CLS] valleyisctic paul inhabited reflect origin how origin hawkins 1977 pictures whose file stevenslli [SEP]']
[Init] best perm rec loss: 0.9090560078620911 for ['[CLS]lliis pictures stevens hawkins file inhabited origin origin whose how reflect valley paulctic 1977 [SEP]']
[Init] best perm rec loss: 0.9047502875328064 for ['[CLS]islli valley pictures hawkins stevens origin paul 1977 origin reflect whose how inhabited filectic [SEP]']
[Init] best perm rec loss: 0.9044280052185059 for ['[CLS]lli reflect origin pictures hawkins valley fileis inhabited origin whose paul stevens 1977ctic how [SEP]']
[Init] best perm rec loss: 0.904109001159668 for ['[CLS]lli stevens how valleyctic reflect origin hawkins inhabitedis origin 1977 whose file pictures paul [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.937 (perp=12.002, rec=0.537), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] virginity, him bailey missed confidence guns shop a attempt relationship remember entirely what wonder machine [SEP]']
[ 100/2000] tot_loss=2.753 (perp=11.594, rec=0.434), tot_loss_proj:3.269 [t=0.25s]
prediction: ['[CLS] virginity, him mom lackediving love narrated a like ideal unlocked absolutely whatever elimination factory [SEP]']
[ 150/2000] tot_loss=2.640 (perp=10.887, rec=0.463), tot_loss_proj:3.109 [t=0.26s]
prediction: ['[CLS] virginity, him mom lacked inspirational love story primal like ideal game idealhe encounter symptoms [SEP]']
[ 200/2000] tot_loss=2.415 (perp=10.214, rec=0.372), tot_loss_proj:3.001 [t=0.25s]
prediction: ['[CLS]ulously, him ( lacked inspirational love story a same ideal outing absolutelyhe encounter symptoms [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.691 (perp=11.390, rec=0.413), tot_loss_proj:3.290 [t=0.27s]
prediction: ['[CLS]ulously, incident momthic inspirational love story a focal protagonist outing lacked madison love symptoms [SEP]']
[ 300/2000] tot_loss=2.603 (perp=11.200, rec=0.363), tot_loss_proj:3.260 [t=0.27s]
prediction: ['[CLS]ulously, boyfriend importantlythic inspirational love story the predecessor ideal manuscript lacked madison lovelity [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.547 (perp=11.006, rec=0.346), tot_loss_proj:3.219 [t=0.25s]
prediction: ['[CLS]ulously story an importantly lowland inspirational love story the invitation ideal manuscript love classic lacked symptoms [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.455 (perp=10.584, rec=0.338), tot_loss_proj:3.109 [t=0.27s]
prediction: ['[CLS]ifies story an respects lowland inspirational love story invitation the ideal manuscript love classic lacked symptoms [SEP]']
[ 450/2000] tot_loss=2.513 (perp=10.932, rec=0.326), tot_loss_proj:3.243 [t=0.26s]
prediction: ['[CLS]ifies story an respects spiked inspirational love story invitation the ideal opportunity encounter classic lacked encounter [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.393 (perp=10.373, rec=0.319), tot_loss_proj:3.124 [t=0.28s]
prediction: ['[CLS]ifies story spiked respects an inspirational love story invitation the ideal opportunity encounter classic lacked encounter [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.350 (perp=10.014, rec=0.347), tot_loss_proj:3.014 [t=0.25s]
prediction: ['[CLS]ulously story spiked respects an inspirational love story invitation the ideal opportunity encounter classic encounter lacked [SEP]']
[ 600/2000] tot_loss=2.320 (perp=10.030, rec=0.314), tot_loss_proj:3.036 [t=0.26s]
prediction: ['[CLS]ulously story spiked really an inspirational love story invitation the ideal opportunity encounter things encounter lacked [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.291 (perp=9.837, rec=0.323), tot_loss_proj:2.993 [t=0.25s]
prediction: ['[CLS]ulously spiked story really an inspirational love story invitation the ideal opportunity encounter things encounter lacked [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.204 (perp=9.525, rec=0.299), tot_loss_proj:3.012 [t=0.26s]
prediction: ['[CLS]ulously story, spiked an inspirational love of invitation the ideal opportunity encounter things encounter lacked [SEP]']
[ 750/2000] tot_loss=2.358 (perp=10.289, rec=0.300), tot_loss_proj:3.146 [t=0.25s]
prediction: ['[CLS]islaus story, spiked an inspirational love of invitation the ideal opportunity encounter things encounter lacked [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.641 (perp=11.133, rec=0.414), tot_loss_proj:3.319 [t=0.28s]
prediction: ['[CLS]ulously story is invitation methods an inspirational love of the ideal anyway encounterph involving unsuccessful [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.431 (perp=10.355, rec=0.360), tot_loss_proj:3.048 [t=0.26s]
prediction: ['[CLS]ulously story goodness invitation methods encounter an inspirational love of the inspiring opportunity encounter madison unsuccessful [SEP]']
[ 900/2000] tot_loss=2.406 (perp=10.389, rec=0.329), tot_loss_proj:3.065 [t=0.26s]
prediction: ['[CLS]ulously story looks invitation rhetoric encounter an inspirational love of the inspiring opportunity encounter madison unsuccessful [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.233 (perp=9.571, rec=0.319), tot_loss_proj:3.106 [t=0.26s]
prediction: ['[CLS]ulously story looks invitation rhetoric inspiring an inspirational love of the encounter opportunity encounter madison needed [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.319 (perp=10.022, rec=0.315), tot_loss_proj:3.203 [t=0.28s]
prediction: ['[CLS]ulously story looks consecutive rhetoric inspiring an inspirational love of the opportunity encounter encounter madison needed [SEP]']
[1050/2000] tot_loss=2.483 (perp=10.881, rec=0.307), tot_loss_proj:3.398 [t=0.27s]
prediction: ['[CLS]ulously story looks consecutive rhetoric inspiring an inspirational love capturing the opportunity encounter encounter madison needed [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.433 (perp=10.681, rec=0.297), tot_loss_proj:3.346 [t=0.26s]
prediction: ['[CLS]ulously story consecutive looks methods inspiring an inspirational love capturing the opportunity encounter encounter things needed [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.357 (perp=10.284, rec=0.300), tot_loss_proj:3.199 [t=0.26s]
prediction: ['[CLS]ulously story consecutive looks bullshit inspiring an inspirational love capturing the opportunity things encounter encounter females [SEP]']
[1200/2000] tot_loss=2.603 (perp=11.549, rec=0.293), tot_loss_proj:3.446 [t=0.26s]
prediction: ['[CLS]ulously story consecutive anticipated bullshit inspiring an inspirational love capturing the opportunity genius encounter encounter females [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.295 (perp=9.968, rec=0.301), tot_loss_proj:3.164 [t=0.26s]
prediction: ['[CLS]ulously capturing consecutive anticipated bullshit inspiring an inspirational love story the opportunity genius encounter encounter females [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.283 (perp=9.923, rec=0.298), tot_loss_proj:3.168 [t=0.28s]
prediction: ['[CLS]ulously capturing consecutive bullshit they inspiring an inspirational love story the opportunity genius encounter encounter females [SEP]']
[1350/2000] tot_loss=2.308 (perp=10.052, rec=0.297), tot_loss_proj:3.122 [t=0.25s]
prediction: ['[CLS]ulously capturing consecutive bullshit anticipated inspiring an inspirational love story the opportunity genius encounter encounter females [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.209 (perp=9.591, rec=0.291), tot_loss_proj:3.089 [t=0.26s]
prediction: ['[CLS]ulously capturing consecutive bullshit they inspiring an inspirational love story the genius opportunity encounter encounter females [SEP]']
Attempt swap
[1450/2000] tot_loss=2.207 (perp=9.591, rec=0.288), tot_loss_proj:3.094 [t=0.25s]
prediction: ['[CLS]ulously capturing consecutive bullshit they inspiring an inspirational love story the genius opportunity encounter encounter females [SEP]']
[1500/2000] tot_loss=2.220 (perp=9.675, rec=0.285), tot_loss_proj:3.145 [t=0.26s]
prediction: ['[CLS]ulously capturing consecutive bullshit they inspiring an inspirational love story the things opportunity encounter encounter females [SEP]']
Attempt swap
[1550/2000] tot_loss=2.220 (perp=9.675, rec=0.285), tot_loss_proj:3.149 [t=0.34s]
prediction: ['[CLS]ulously capturing consecutive bullshit they inspiring an inspirational love story the things opportunity encounter encounter females [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.267 (perp=9.865, rec=0.294), tot_loss_proj:3.143 [t=0.31s]
prediction: ['[CLS]ulously capturing consecutive bullshit opportunity inspiring an inspirational love story the genius anticipated encounter encounter females [SEP]']
[1650/2000] tot_loss=2.258 (perp=9.865, rec=0.285), tot_loss_proj:3.143 [t=0.38s]
prediction: ['[CLS]ulously capturing consecutive bullshit opportunity inspiring an inspirational love story the genius anticipated encounter encounter females [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.183 (perp=9.496, rec=0.284), tot_loss_proj:2.994 [t=0.33s]
prediction: ['[CLS]ulously consecutive bullshit capturing opportunity inspiring an inspirational love story the geniuspers encounter encounter females [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.250 (perp=9.803, rec=0.290), tot_loss_proj:3.032 [t=0.32s]
prediction: ['[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story the recitalpers encounter encounter females [SEP]']
[1800/2000] tot_loss=2.246 (perp=9.803, rec=0.285), tot_loss_proj:3.028 [t=0.34s]
prediction: ['[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story the recitalpers encounter encounter females [SEP]']
Attempt swap
[1850/2000] tot_loss=2.246 (perp=9.803, rec=0.285), tot_loss_proj:3.028 [t=0.34s]
prediction: ['[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story the recitalpers encounter encounter females [SEP]']
Attempt swap
[1900/2000] tot_loss=2.247 (perp=9.803, rec=0.286), tot_loss_proj:3.026 [t=0.33s]
prediction: ['[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story the recitalpers encounter encounter females [SEP]']
[1950/2000] tot_loss=2.245 (perp=9.803, rec=0.285), tot_loss_proj:3.029 [t=0.36s]
prediction: ['[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story the recitalpers encounter encounter females [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.205 (perp=9.606, rec=0.284), tot_loss_proj:2.958 [t=0.37s]
prediction: ['[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story encounter the recitalpers encounter females [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS]ulously consecutive bullshit capturing genius inspiring an inspirational love story the recitalpers encounter encounter females [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 52.941 | r: 56.250
rouge2     | fm: 19.355 | p: 18.750 | r: 20.000
rougeL     | fm: 48.485 | p: 47.059 | r: 50.000
rougeLsum  | fm: 48.485 | p: 47.059 | r: 50.000
r1fm+r2fm = 73.900

[Aggregate metrics]:
rouge1     | fm: 87.597 | p: 86.881 | r: 88.478
rouge2     | fm: 50.142 | p: 49.815 | r: 50.550
rougeL     | fm: 75.195 | p: 74.688 | r: 75.913
rougeLsum  | fm: 75.137 | p: 74.595 | r: 75.825
r1fm+r2fm = 137.739

input #58 time: 0:11:28 | total time: 10:40:33


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8776753544807434 for ['[CLS]rianctions strong. ich blondegil nuts winner kirkeira danger controls can draft caesar [SEP]']
[Init] best rec loss: 0.8027607798576355 for ['[CLS] count running toicular mainlandmatfire action masters shooter fourth historically [SEP] thorn eu cher [SEP]']
[Init] best rec loss: 0.7966477870941162 for ['[CLS] donald one novak carlrland exception reunited 2000 chance feminist numerical university network master connie paralympic [SEP]']
[Init] best rec loss: 0.7959725260734558 for ['[CLS] missed orson read [SEP]ness diffuseive.ote taxes fill index death oh lashesleg [SEP]']
[Init] best rec loss: 0.7938791513442993 for ['[CLS] intended tune shrink shockiidae then webb points portal major grid galaxy drive easilyhearted her [SEP]']
[Init] best rec loss: 0.7838842868804932 for ['[CLS] belt br suites offer cases mirrorun its structures descendants yan taste partial duties title left [SEP]']
[Init] best rec loss: 0.7801650762557983 for ['[CLS] bull visit mountain collisionantly energy sun temple frontiers himselfhesion studio oricon streetrricular day [SEP]']
[Init] best rec loss: 0.7589945793151855 for ['[CLS]thus lady vaulted completely reviewly administration dictionary explosion haveization had relatingval plainly gallons [SEP]']
[Init] best perm rec loss: 0.75862717628479 for ['[CLS] explosion reviewval completely plainly relatingly have gallons vaultedization had administration ladythus dictionary [SEP]']
[Init] best perm rec loss: 0.7583982944488525 for ['[CLS] vaulted dictionary reviewization had have completelythus administration lady gallonsly relating plainlyval explosion [SEP]']
[Init] best perm rec loss: 0.7575265169143677 for ['[CLS] lady had gallons have relating explosion reviewthus completely vaulted plainlyval dictionaryly administrationization [SEP]']
[Init] best perm rec loss: 0.757513165473938 for ['[CLS]izationthus lady completelyval gallonsly plainly explosion dictionary review vaulted had administration relating have [SEP]']
[Init] best perm rec loss: 0.7571716904640198 for ['[CLS] completely had plainly reviewization administrationval gallonsly relating dictionary lady explosion vaultedthus have [SEP]']
[Init] best perm rec loss: 0.7565751671791077 for ['[CLS] plainlythus gallonslyization review have vaultedval relating completely administration lady explosion had dictionary [SEP]']
[Init] best perm rec loss: 0.7553730607032776 for ['[CLS]ization administration lady reviewval had explosion plainlythus have completely gallons vaulted dictionary relatingly [SEP]']
[Init] best perm rec loss: 0.7553093433380127 for ['[CLS]thus vaulted administration dictionary relating have explosionizationvally had completely review gallons lady plainly [SEP]']
[Init] best perm rec loss: 0.7549171447753906 for ['[CLS] dictionary plainly vaulted completelyval lady review gallonsizationly havethus explosion had relating administration [SEP]']
[Init] best perm rec loss: 0.7542106509208679 for ['[CLS] plainly hadvalthus gallons explosionization relating vaultedly completely review dictionary have administration lady [SEP]']
[Init] best perm rec loss: 0.754058837890625 for ['[CLS] lady reviewthus relating plainly haveval dictionarylyization gallons explosion had administration completely vaulted [SEP]']
[Init] best perm rec loss: 0.7536477446556091 for ['[CLS] dictionary plainlylyval relating administration gallonsthus explosion lady completely review vaulted hadization have [SEP]']
[Init] best perm rec loss: 0.7535849809646606 for ['[CLS] explosion ladyval vaultedly have review gallonsthus completely relating administration had dictionary plainlyization [SEP]']
[Init] best perm rec loss: 0.7532665729522705 for ['[CLS]val vaultedization gallons completely have relatingly dictionary explosion review had lady administrationthus plainly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.707 (perp=11.687, rec=0.369), tot_loss_proj:3.004 [t=0.28s]
prediction: ['[CLS] native zism the warrior styleraphically sensitive she film anything scientific who classic force [SEP]']
[ 100/2000] tot_loss=2.709 (perp=12.115, rec=0.286), tot_loss_proj:2.973 [t=0.29s]
prediction: ['[CLS] has charism a cloud ofism char char woman a anything young who leading having [SEP]']
[ 150/2000] tot_loss=2.538 (perp=11.787, rec=0.181), tot_loss_proj:2.924 [t=0.40s]
prediction: ['[CLS] has charism a young ofism char char woman aby young who screen who [SEP]']
[ 200/2000] tot_loss=2.110 (perp=9.768, rec=0.156), tot_loss_proj:2.405 [t=0.28s]
prediction: ['[CLS] has charisma screen of screen knows how woman a has young who screen who [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.152 (perp=10.047, rec=0.142), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] has charism of screen of screen knows how a has young woman knows screen who [SEP]']
[ 300/2000] tot_loss=2.080 (perp=9.819, rec=0.117), tot_loss_proj:2.419 [t=0.33s]
prediction: ['[CLS] has charism the screen ofa knows how a has young woman knows screen who [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.898 (perp=8.811, rec=0.136), tot_loss_proj:2.271 [t=0.27s]
prediction: ['[CLS] hasism the screen of chara knows how a has young woman knows screen who [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.912 (perp=8.905, rec=0.131), tot_loss_proj:2.329 [t=0.26s]
prediction: ['[CLS] hasismism the screen of chara how how a young woman knows screen who [SEP]']
[ 450/2000] tot_loss=1.869 (perp=8.838, rec=0.102), tot_loss_proj:2.277 [t=0.29s]
prediction: ['[CLS] hasismism the screen of chara the how a young woman knows screen who [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.883 (perp=8.895, rec=0.104), tot_loss_proj:2.298 [t=0.28s]
prediction: ['[CLS] hasismism the screen of chara how a young woman knows hold screen who [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.806 (perp=8.553, rec=0.096), tot_loss_proj:2.237 [t=0.25s]
prediction: ['[CLS] hasism screen theism of chara how a young woman knows hold screen who [SEP]']
[ 600/2000] tot_loss=1.811 (perp=8.553, rec=0.101), tot_loss_proj:2.236 [t=0.28s]
prediction: ['[CLS] hasism screen theism of chara how a young woman knows hold screen who [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.810 (perp=8.553, rec=0.099), tot_loss_proj:2.232 [t=0.27s]
prediction: ['[CLS] hasism screen theism of chara how a young woman knows hold screen who [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.720 (perp=8.129, rec=0.095), tot_loss_proj:2.119 [t=0.27s]
prediction: ['[CLS] hasism screen the of charisma how a young woman knows hold screen who [SEP]']
[ 750/2000] tot_loss=1.711 (perp=8.129, rec=0.085), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS] hasism screen the of charisma how a young woman knows hold screen who [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.561 (perp=7.372, rec=0.087), tot_loss_proj:1.923 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a young woman knows hold screen who [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.554 (perp=7.280, rec=0.098), tot_loss_proj:1.909 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a young screen woman knows hold who [SEP]']
[ 900/2000] tot_loss=1.542 (perp=7.280, rec=0.086), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a young screen woman knows hold who [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.525 (perp=7.223, rec=0.080), tot_loss_proj:1.891 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
Attempt swap
[1000/2000] tot_loss=1.530 (perp=7.223, rec=0.086), tot_loss_proj:1.898 [t=0.28s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
[1050/2000] tot_loss=1.530 (perp=7.223, rec=0.086), tot_loss_proj:1.894 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
Attempt swap
[1100/2000] tot_loss=1.527 (perp=7.223, rec=0.083), tot_loss_proj:1.895 [t=0.25s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
Attempt swap
[1150/2000] tot_loss=1.534 (perp=7.223, rec=0.089), tot_loss_proj:1.899 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
[1200/2000] tot_loss=1.529 (perp=7.223, rec=0.085), tot_loss_proj:1.890 [t=0.29s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
Attempt swap
[1250/2000] tot_loss=1.530 (perp=7.223, rec=0.085), tot_loss_proj:1.894 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows hold who [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.514 (perp=7.179, rec=0.078), tot_loss_proj:1.857 [t=0.28s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
[1350/2000] tot_loss=1.523 (perp=7.179, rec=0.087), tot_loss_proj:1.855 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1400/2000] tot_loss=1.532 (perp=7.179, rec=0.096), tot_loss_proj:1.858 [t=0.28s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1450/2000] tot_loss=1.517 (perp=7.179, rec=0.081), tot_loss_proj:1.856 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
[1500/2000] tot_loss=1.530 (perp=7.179, rec=0.094), tot_loss_proj:1.854 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1550/2000] tot_loss=1.514 (perp=7.179, rec=0.079), tot_loss_proj:1.855 [t=0.25s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1600/2000] tot_loss=1.521 (perp=7.179, rec=0.085), tot_loss_proj:1.857 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
[1650/2000] tot_loss=1.510 (perp=7.179, rec=0.074), tot_loss_proj:1.854 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1700/2000] tot_loss=1.523 (perp=7.179, rec=0.087), tot_loss_proj:1.861 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1750/2000] tot_loss=1.509 (perp=7.179, rec=0.073), tot_loss_proj:1.851 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
[1800/2000] tot_loss=1.513 (perp=7.179, rec=0.077), tot_loss_proj:1.855 [t=0.26s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1850/2000] tot_loss=1.531 (perp=7.179, rec=0.095), tot_loss_proj:1.854 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.524 (perp=7.179, rec=0.088), tot_loss_proj:1.852 [t=0.25s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
[1950/2000] tot_loss=1.519 (perp=7.179, rec=0.083), tot_loss_proj:1.856 [t=0.27s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.511 (perp=7.179, rec=0.076), tot_loss_proj:1.860 [t=0.29s]
prediction: ['[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] hasism of the screen charisma how a screen young woman knows who hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.871 | p: 86.667 | r: 81.250
rouge2     | fm: 13.793 | p: 14.286 | r: 13.333
rougeL     | fm: 58.065 | p: 60.000 | r: 56.250
rougeLsum  | fm: 58.065 | p: 60.000 | r: 56.250
r1fm+r2fm = 97.664

[Aggregate metrics]:
rouge1     | fm: 87.478 | p: 86.826 | r: 88.313
rouge2     | fm: 49.490 | p: 49.200 | r: 49.825
rougeL     | fm: 74.881 | p: 74.375 | r: 75.543
rougeLsum  | fm: 74.911 | p: 74.394 | r: 75.578
r1fm+r2fm = 136.968

input #59 time: 0:11:22 | total time: 10:51:56


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9458453059196472 for ['[CLS] trey rather temple wade fishermen stepped per starringregion mechanics sort cricket [SEP]']
[Init] best rec loss: 0.8992573618888855 for ['[CLS]phone questionttal project dormitory women two int defense characterized donation annually [SEP]']
[Init] best rec loss: 0.7768928408622742 for ['[CLS] ; administratorible ghost us blacks ruin magazine similar elders spectrum sex [SEP]']
[Init] best perm rec loss: 0.7713958621025085 for ['[CLS] ruin magazine ; blacks spectrum administrator us similar elders sexible ghost [SEP]']
[Init] best perm rec loss: 0.7713207006454468 for ['[CLS] ghost elders spectrum us magazine ruin ; sex administrator similarible blacks [SEP]']
[Init] best perm rec loss: 0.7709917426109314 for ['[CLS] similar us magazine elders administrator ; spectrum ghost blacks sexible ruin [SEP]']
[Init] best perm rec loss: 0.7705534100532532 for ['[CLS] spectrum administrator sex similar ghost magazine ; ruinible us elders blacks [SEP]']
[Init] best perm rec loss: 0.7697832584381104 for ['[CLS] us ; elders magazine similar blacks sex ghost spectrum ruin administratorible [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.626 (perp=12.016, rec=0.223), tot_loss_proj:2.852 [t=0.25s]
prediction: ['[CLS] awkwardly dvd. paced july message circuit. awkwardly story over awkwardly [SEP]']
[ 100/2000] tot_loss=2.368 (perp=11.049, rec=0.158), tot_loss_proj:2.672 [t=0.26s]
prediction: ['[CLS] awkwardly circuit the paced is soap soap. awkwardly story is awkwardly [SEP]']
[ 150/2000] tot_loss=2.275 (perp=10.874, rec=0.100), tot_loss_proj:2.617 [t=0.28s]
prediction: ['[CLS] awkwardly circuit the paced is soap opera. awkwardly storyh awkwardly [SEP]']
[ 200/2000] tot_loss=2.326 (perp=11.149, rec=0.096), tot_loss_proj:2.675 [t=0.28s]
prediction: ['[CLS] awkwardly circuit the paced is soap opera - awkwardly storyh awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.116 (perp=9.973, rec=0.122), tot_loss_proj:2.410 [t=0.26s]
prediction: ['[CLS] awkwardly circuit awkwardly paced is soap opera - the storyh awkwardly [SEP]']
[ 300/2000] tot_loss=1.858 (perp=8.904, rec=0.078), tot_loss_proj:2.194 [t=0.25s]
prediction: ['[CLS] the circuit awkwardly paced is soap opera - the storyh awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.971 (perp=9.452, rec=0.081), tot_loss_proj:2.273 [t=0.26s]
prediction: ['[CLS] the circuit awkwardly paced is soap opera - is story awkwardlyh [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.832 (perp=8.689, rec=0.095), tot_loss_proj:2.162 [t=0.25s]
prediction: ['[CLS] the circuit awkwardly paced is soap opera - ish story awkwardly [SEP]']
[ 450/2000] tot_loss=1.818 (perp=8.689, rec=0.080), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] the circuit awkwardly paced is soap opera - ish story awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.794 (perp=8.626, rec=0.069), tot_loss_proj:2.181 [t=0.27s]
prediction: ['[CLS] the circuit paced awkwardly is soap opera - ish story awkwardly [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.784 (perp=8.501, rec=0.083), tot_loss_proj:2.085 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - ish story awkwardly [SEP]']
[ 600/2000] tot_loss=1.778 (perp=8.501, rec=0.078), tot_loss_proj:2.085 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - ish story awkwardly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.767 (perp=8.501, rec=0.067), tot_loss_proj:2.076 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - ish story awkwardly [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.674 (perp=7.956, rec=0.083), tot_loss_proj:1.913 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
[ 750/2000] tot_loss=1.667 (perp=7.956, rec=0.076), tot_loss_proj:1.910 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.662 (perp=7.956, rec=0.070), tot_loss_proj:1.914 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.654 (perp=7.956, rec=0.063), tot_loss_proj:1.908 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
[ 900/2000] tot_loss=1.660 (perp=7.956, rec=0.069), tot_loss_proj:1.912 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.652 (perp=7.956, rec=0.061), tot_loss_proj:1.909 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
Attempt swap
[1000/2000] tot_loss=1.675 (perp=7.956, rec=0.084), tot_loss_proj:1.912 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
[1050/2000] tot_loss=1.669 (perp=7.956, rec=0.077), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.692 (perp=8.053, rec=0.081), tot_loss_proj:1.937 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly - soap opera - ish story [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.606 (perp=7.643, rec=0.077), tot_loss_proj:1.862 [t=0.26s]
prediction: ['[CLS] the circuit paced awkwardly is - soap opera - ish story [SEP]']
[1200/2000] tot_loss=1.591 (perp=7.643, rec=0.062), tot_loss_proj:1.864 [t=0.26s]
prediction: ['[CLS] the circuit paced awkwardly is - soap opera - ish story [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.535 (perp=7.328, rec=0.069), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS] the circuit paced awkwardly is soap opera - - ish story [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.623 (perp=7.738, rec=0.075), tot_loss_proj:1.860 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera -. ish story [SEP]']
[1350/2000] tot_loss=1.628 (perp=7.738, rec=0.080), tot_loss_proj:1.861 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera -. ish story [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.489 (perp=7.032, rec=0.083), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.483 (perp=7.032, rec=0.076), tot_loss_proj:1.693 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
[1500/2000] tot_loss=1.478 (perp=7.032, rec=0.071), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.474 (perp=7.032, rec=0.068), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.482 (perp=7.032, rec=0.076), tot_loss_proj:1.689 [t=0.27s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
[1650/2000] tot_loss=1.473 (perp=7.032, rec=0.066), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.474 (perp=7.032, rec=0.068), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.481 (perp=7.032, rec=0.074), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
[1800/2000] tot_loss=1.477 (perp=7.032, rec=0.071), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.474 (perp=7.032, rec=0.068), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.477 (perp=7.032, rec=0.071), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
[1950/2000] tot_loss=1.478 (perp=7.032, rec=0.072), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.474 (perp=7.032, rec=0.067), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] the circuit paced is awkwardly soap opera - - ish story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] the circuit paced is awkwardly awkwardly soap opera - ish story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 87.636 | p: 86.824 | r: 88.539
rouge2     | fm: 49.268 | p: 48.874 | r: 49.600
rougeL     | fm: 75.040 | p: 74.473 | r: 75.740
rougeLsum  | fm: 74.851 | p: 74.290 | r: 75.589
r1fm+r2fm = 136.904

input #60 time: 0:10:53 | total time: 11:02:49


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 1.012492299079895 for ['[CLS] fringe speed coach [SEP]']
[Init] best rec loss: 0.9584759473800659 for ['[CLS] motor today might [SEP]']
[Init] best rec loss: 0.9526145458221436 for ['[CLS] coldemon earlier [SEP]']
[Init] best rec loss: 0.9441502094268799 for ['[CLS] stance crash persons [SEP]']
[Init] best rec loss: 0.9386730194091797 for ['[CLS] calling whispers father [SEP]']
[Init] best rec loss: 0.9297502636909485 for ['[CLS] globe off site [SEP]']
[Init] best rec loss: 0.9249005913734436 for ['[CLS]arat lower ⁱ [SEP]']
[Init] best perm rec loss: 0.9235948920249939 for ['[CLS] lower ⁱarat [SEP]']
[Init] best perm rec loss: 0.9232369661331177 for ['[CLS] ⁱarat lower [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.732 (perp=10.749, rec=0.582), tot_loss_proj:2.974 [t=0.26s]
prediction: ['[CLS] leningrad scene beautiful [SEP]']
[ 100/2000] tot_loss=2.330 (perp=8.940, rec=0.541), tot_loss_proj:2.184 [t=0.25s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 150/2000] tot_loss=2.319 (perp=8.940, rec=0.531), tot_loss_proj:2.189 [t=0.26s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 200/2000] tot_loss=2.355 (perp=8.940, rec=0.567), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.056 (perp=7.753, rec=0.506), tot_loss_proj:1.918 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 300/2000] tot_loss=2.025 (perp=7.753, rec=0.475), tot_loss_proj:1.918 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.058 (perp=7.753, rec=0.508), tot_loss_proj:1.924 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.023 (perp=7.753, rec=0.473), tot_loss_proj:1.913 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 450/2000] tot_loss=2.017 (perp=7.753, rec=0.467), tot_loss_proj:1.920 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.025 (perp=7.753, rec=0.474), tot_loss_proj:1.910 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.002 (perp=7.753, rec=0.452), tot_loss_proj:1.920 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 600/2000] tot_loss=2.012 (perp=7.753, rec=0.461), tot_loss_proj:1.922 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.994 (perp=7.753, rec=0.444), tot_loss_proj:1.918 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.996 (perp=7.753, rec=0.446), tot_loss_proj:1.912 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 750/2000] tot_loss=1.989 (perp=7.753, rec=0.439), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.986 (perp=7.753, rec=0.435), tot_loss_proj:1.917 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.989 (perp=7.753, rec=0.438), tot_loss_proj:1.910 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 900/2000] tot_loss=1.989 (perp=7.753, rec=0.438), tot_loss_proj:1.919 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.995 (perp=7.753, rec=0.444), tot_loss_proj:1.912 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1000/2000] tot_loss=1.984 (perp=7.753, rec=0.434), tot_loss_proj:1.916 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1050/2000] tot_loss=1.989 (perp=7.753, rec=0.438), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1100/2000] tot_loss=1.982 (perp=7.753, rec=0.431), tot_loss_proj:1.921 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1150/2000] tot_loss=1.979 (perp=7.753, rec=0.428), tot_loss_proj:1.915 [t=0.29s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1200/2000] tot_loss=1.969 (perp=7.753, rec=0.419), tot_loss_proj:1.922 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1250/2000] tot_loss=1.975 (perp=7.753, rec=0.425), tot_loss_proj:1.916 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1300/2000] tot_loss=1.972 (perp=7.753, rec=0.421), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1350/2000] tot_loss=1.976 (perp=7.753, rec=0.425), tot_loss_proj:1.913 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1400/2000] tot_loss=1.970 (perp=7.753, rec=0.419), tot_loss_proj:1.909 [t=0.29s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1450/2000] tot_loss=1.973 (perp=7.753, rec=0.422), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1500/2000] tot_loss=1.969 (perp=7.753, rec=0.418), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1550/2000] tot_loss=1.972 (perp=7.753, rec=0.422), tot_loss_proj:1.918 [t=0.28s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1600/2000] tot_loss=1.976 (perp=7.753, rec=0.425), tot_loss_proj:1.921 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1650/2000] tot_loss=1.967 (perp=7.753, rec=0.416), tot_loss_proj:1.910 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1700/2000] tot_loss=1.972 (perp=7.753, rec=0.422), tot_loss_proj:1.914 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1750/2000] tot_loss=1.969 (perp=7.753, rec=0.419), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1800/2000] tot_loss=1.970 (perp=7.753, rec=0.419), tot_loss_proj:1.914 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1850/2000] tot_loss=1.971 (perp=7.753, rec=0.421), tot_loss_proj:1.915 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[1900/2000] tot_loss=1.969 (perp=7.753, rec=0.419), tot_loss_proj:1.919 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[1950/2000] tot_loss=1.969 (perp=7.753, rec=0.418), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[2000/2000] tot_loss=1.962 (perp=7.753, rec=0.412), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful beautiful scene [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 80.000 | r: 100.000
rouge2     | fm: 85.714 | p: 75.000 | r: 100.000
rougeL     | fm: 88.889 | p: 80.000 | r: 100.000
rougeLsum  | fm: 88.889 | p: 80.000 | r: 100.000
r1fm+r2fm = 174.603

[Aggregate metrics]:
rouge1     | fm: 87.621 | p: 86.838 | r: 88.712
rouge2     | fm: 50.136 | p: 49.645 | r: 50.744
rougeL     | fm: 75.213 | p: 74.587 | r: 76.155
rougeLsum  | fm: 75.078 | p: 74.454 | r: 75.917
r1fm+r2fm = 137.757

input #61 time: 0:10:44 | total time: 11:13:34


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9211737513542175 for ['[CLS] cents because mock eddie shawpartisan _ frankensteinlter team % advertising gap and nature an society regainedicamler climbing [SEP]']
[Init] best rec loss: 0.8730534315109253 for ['[CLS] readytus panting lawn medium turn funds learn credit turn installation paired blues share gust dev consul prototype sicily peter slowly [SEP]']
[Init] best rec loss: 0.8640391826629639 for ['[CLS] zip practicenighttto man tourists guinness dance fashion specific convinces camp costumes impressedˈ oriconbill burmese high par stopping [SEP]']
[Init] best rec loss: 0.8468777537345886 for ['[CLS] barriers viewer states armed creative featured⋅ obvious least dr photographer evans peerage angel exportuc duff publicа silent jaguar [SEP]']
[Init] best rec loss: 0.8388912677764893 for ['[CLS]te will add odyssey algebra fist umar lofk sports spectrum image songsiblyum mortar crambidae functioning piece however shi [SEP]']
[Init] best rec loss: 0.8322013020515442 for ['[CLS]tana place dated end numbers in face field reasonable genus mission in parkway act requiem night past raven teeth academie storage [SEP]']
[Init] best rec loss: 0.82038813829422 for ['[CLS]free sr meters an holds winningry bend there according deal trillionbil coach count save democratic scheduleron ( logan [SEP]']
[Init] best perm rec loss: 0.8198910355567932 for ['[CLS] count save anbil meters srry holds trillionfree ( democratic there deal coach bendron according logan schedule winning [SEP]']
[Init] best perm rec loss: 0.8192173838615417 for ['[CLS]bil count meters schedulery trillion logan democratic coach sr deal bend thereron holds ( save winning an accordingfree [SEP]']
[Init] best perm rec loss: 0.8186869621276855 for ['[CLS] there meters an democratic dealfree coach count bend holds trillionronbil logan schedulery save sr ( according winning [SEP]']
[Init] best perm rec loss: 0.8186588883399963 for ['[CLS] anry coachbil sr trillion deal holds logan schedule there save count democratic meters accordingron winning bendfree ( [SEP]']
[Init] best perm rec loss: 0.8181236982345581 for ['[CLS] democratic deal winningfree an count sr coach meters savery holds logan bend schedule accordingron there (bil trillion [SEP]']
[Init] best perm rec loss: 0.8173703551292419 for ['[CLS] democratic sr save logan bend trillionry there holds scheduleron an dealbil ( coach accordingfree winning count meters [SEP]']
[Init] best perm rec loss: 0.8156734108924866 for ['[CLS] coach according sr count winning bend democratic holds an save schedulery logan therefree trillionron meters dealbil ( [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.668 (perp=11.291, rec=0.410), tot_loss_proj:3.114 [t=0.28s]
prediction: ['[CLS] wing doom, day law warning save novels having [SEP] schedule prevention ) ta call war for debut patfar best [SEP]']
[ 100/2000] tot_loss=2.545 (perp=11.273, rec=0.290), tot_loss_proj:3.068 [t=0.27s]
prediction: ['[CLS] grace prevention called for prevention prevention to system having [SEP] to prevention movies where war movies how grace roofed larry best [SEP]']
[ 150/2000] tot_loss=2.455 (perp=11.158, rec=0.224), tot_loss_proj:3.013 [t=0.26s]
prediction: ['[CLS] grace to call for prevention prevention maybe movies making [SEP] downtown prevention movies felicity movie movies because grace ever larry best [SEP]']
[ 200/2000] tot_loss=2.155 (perp=9.920, rec=0.171), tot_loss_proj:2.804 [t=0.29s]
prediction: ['[CLS] grace to call for prevention prevention of movies making [SEP] than prevention one never movies movies best grace ever stuff best [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.047 (perp=9.477, rec=0.152), tot_loss_proj:2.710 [t=0.28s]
prediction: ['[CLS] grace to call for prevention avoided of movies making than prevention as one became movies war for grace ever really best [SEP]']
[ 300/2000] tot_loss=2.009 (perp=9.378, rec=0.133), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] grace to call for prevention than of, making than prevention that one became movies war of grace ever really best [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.915 (perp=8.973, rec=0.120), tot_loss_proj:2.591 [t=0.28s]
prediction: ['[CLS] grace to call for prevention rather rather of, making than prevention one became movies war of it ever. best [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.733 (perp=8.139, rec=0.105), tot_loss_proj:2.436 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather rather of, making than prevention one of movies war the it ever best. [SEP]']
[ 450/2000] tot_loss=1.946 (perp=9.291, rec=0.088), tot_loss_proj:2.660 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather rather to, making than prevention one of movies war the it ever best really [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.735 (perp=8.205, rec=0.094), tot_loss_proj:2.455 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather rather to, making than prevention one of the war movies it ever best really [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.634 (perp=7.700, rec=0.094), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather rather to, making than prevention one of the war movies it ever really best [SEP]']
[ 600/2000] tot_loss=1.632 (perp=7.700, rec=0.092), tot_loss_proj:2.361 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather rather to, making than prevention one of the war movies it ever really best [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.519 (perp=7.144, rec=0.090), tot_loss_proj:2.228 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to, making rather than blame one of the war movies it ever really best [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.444 (perp=6.793, rec=0.086), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather to, rather than blame making one of the war movies it ever really best [SEP]']
[ 750/2000] tot_loss=1.442 (perp=6.793, rec=0.084), tot_loss_proj:2.166 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather to, rather than blame making one of the war movies it ever really best [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.419 (perp=6.677, rec=0.084), tot_loss_proj:2.135 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather to, rather than blame making it one of the war movies ever really best [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.318 (perp=6.148, rec=0.088), tot_loss_proj:2.046 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the war movies ever made best [SEP]']
[ 900/2000] tot_loss=1.307 (perp=6.148, rec=0.078), tot_loss_proj:2.047 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the war movies ever made best [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.310 (perp=6.148, rec=0.081), tot_loss_proj:2.044 [t=0.30s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the war movies ever made best [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.302 (perp=6.121, rec=0.078), tot_loss_proj:2.042 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the war movies ever best made [SEP]']
[1050/2000] tot_loss=1.300 (perp=6.121, rec=0.076), tot_loss_proj:2.040 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the war movies ever best made [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.156 (perp=5.398, rec=0.076), tot_loss_proj:1.907 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1150/2000] tot_loss=1.154 (perp=5.398, rec=0.074), tot_loss_proj:1.908 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
[1200/2000] tot_loss=1.156 (perp=5.398, rec=0.076), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1250/2000] tot_loss=1.152 (perp=5.398, rec=0.073), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1300/2000] tot_loss=1.161 (perp=5.398, rec=0.082), tot_loss_proj:1.909 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
[1350/2000] tot_loss=1.154 (perp=5.398, rec=0.074), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1400/2000] tot_loss=1.157 (perp=5.398, rec=0.077), tot_loss_proj:1.910 [t=0.28s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.149 (perp=5.398, rec=0.070), tot_loss_proj:1.903 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
[1500/2000] tot_loss=1.153 (perp=5.398, rec=0.073), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.153 (perp=5.398, rec=0.074), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1600/2000] tot_loss=1.150 (perp=5.398, rec=0.071), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]']
[1650/2000] tot_loss=1.213 (perp=5.663, rec=0.081), tot_loss_proj:1.956 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.206 (perp=5.663, rec=0.073), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.212 (perp=5.663, rec=0.079), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
[1800/2000] tot_loss=1.205 (perp=5.663, rec=0.073), tot_loss_proj:1.959 [t=0.28s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.198 (perp=5.663, rec=0.066), tot_loss_proj:1.955 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.202 (perp=5.663, rec=0.069), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.197 (perp=5.663, rec=0.065), tot_loss_proj:1.959 [t=0.27s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.211 (perp=5.663, rec=0.079), tot_loss_proj:1.956 [t=0.28s]
prediction: ['[CLS] grace to call for prevention rather place blame, rather than making it one of the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to call for prevention rather to blame, rather than making it one of the best war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.455 | p: 95.455 | r: 95.455
rouge2     | fm: 80.952 | p: 80.952 | r: 80.952
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 176.407

[Aggregate metrics]:
rouge1     | fm: 87.806 | p: 87.006 | r: 88.856
rouge2     | fm: 50.237 | p: 49.772 | r: 50.872
rougeL     | fm: 75.575 | p: 74.821 | r: 76.406
rougeLsum  | fm: 75.320 | p: 74.610 | r: 76.223
r1fm+r2fm = 138.043

input #62 time: 0:10:59 | total time: 11:24:34


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8759692311286926 for ['[CLS]trulf ty previously noah [SEP]']
[Init] best rec loss: 0.7713152170181274 for ['[CLS] lateputednl high abe [SEP]']
[Init] best rec loss: 0.7345088720321655 for ['[CLS] told poland della services. [SEP]']
[Init] best rec loss: 0.7093000411987305 for ['[CLS] thinking himself whereas media inspired [SEP]']
[Init] best rec loss: 0.7028385996818542 for ['[CLS] levine rough carriers don crack [SEP]']
[Init] best rec loss: 0.6904280185699463 for ['[CLS] day [CLS] renewal⁄ positive [SEP]']
[Init] best rec loss: 0.6779635548591614 for ['[CLS] growing its head shapedism [SEP]']
[Init] best perm rec loss: 0.6766224503517151 for ['[CLS] head shaped its growingism [SEP]']
[Init] best perm rec loss: 0.668762743473053 for ['[CLS] shaped growingism head its [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.479 (perp=11.335, rec=0.212), tot_loss_proj:2.793 [t=0.24s]
prediction: ['[CLS] looking finding ticket ticket return [SEP]']
[ 100/2000] tot_loss=1.874 (perp=8.740, rec=0.126), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] looking for return ticket return [SEP]']
[ 150/2000] tot_loss=1.260 (perp=5.940, rec=0.072), tot_loss_proj:1.393 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 200/2000] tot_loss=1.255 (perp=5.940, rec=0.067), tot_loss_proj:1.400 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.246 (perp=5.940, rec=0.058), tot_loss_proj:1.397 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 300/2000] tot_loss=1.252 (perp=5.940, rec=0.064), tot_loss_proj:1.385 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.257 (perp=5.940, rec=0.069), tot_loss_proj:1.396 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.258 (perp=5.940, rec=0.070), tot_loss_proj:1.391 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 450/2000] tot_loss=1.245 (perp=5.940, rec=0.057), tot_loss_proj:1.399 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.261 (perp=5.940, rec=0.073), tot_loss_proj:1.391 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.254 (perp=5.940, rec=0.066), tot_loss_proj:1.404 [t=0.24s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 600/2000] tot_loss=1.246 (perp=5.940, rec=0.058), tot_loss_proj:1.392 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.252 (perp=5.940, rec=0.064), tot_loss_proj:1.397 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.246 (perp=5.940, rec=0.058), tot_loss_proj:1.396 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 750/2000] tot_loss=1.246 (perp=5.940, rec=0.058), tot_loss_proj:1.398 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.248 (perp=5.940, rec=0.060), tot_loss_proj:1.398 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.253 (perp=5.940, rec=0.065), tot_loss_proj:1.394 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 900/2000] tot_loss=1.251 (perp=5.940, rec=0.063), tot_loss_proj:1.394 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.244 (perp=5.940, rec=0.056), tot_loss_proj:1.406 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.249 (perp=5.940, rec=0.061), tot_loss_proj:1.389 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1050/2000] tot_loss=1.253 (perp=5.940, rec=0.065), tot_loss_proj:1.407 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.252 (perp=5.940, rec=0.064), tot_loss_proj:1.390 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.253 (perp=5.940, rec=0.065), tot_loss_proj:1.401 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1200/2000] tot_loss=1.249 (perp=5.940, rec=0.061), tot_loss_proj:1.399 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.254 (perp=5.940, rec=0.066), tot_loss_proj:1.405 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.246 (perp=5.940, rec=0.058), tot_loss_proj:1.394 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1350/2000] tot_loss=1.248 (perp=5.940, rec=0.060), tot_loss_proj:1.399 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.253 (perp=5.940, rec=0.065), tot_loss_proj:1.403 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.252 (perp=5.940, rec=0.064), tot_loss_proj:1.408 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1500/2000] tot_loss=1.242 (perp=5.940, rec=0.054), tot_loss_proj:1.393 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.240 (perp=5.940, rec=0.052), tot_loss_proj:1.398 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.254 (perp=5.940, rec=0.066), tot_loss_proj:1.393 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1650/2000] tot_loss=1.257 (perp=5.940, rec=0.068), tot_loss_proj:1.399 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.241 (perp=5.940, rec=0.053), tot_loss_proj:1.390 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.244 (perp=5.940, rec=0.056), tot_loss_proj:1.395 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1800/2000] tot_loss=1.255 (perp=5.940, rec=0.067), tot_loss_proj:1.398 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.247 (perp=5.940, rec=0.059), tot_loss_proj:1.390 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.261 (perp=5.940, rec=0.073), tot_loss_proj:1.401 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1950/2000] tot_loss=1.257 (perp=5.940, rec=0.069), tot_loss_proj:1.403 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.253 (perp=5.940, rec=0.065), tot_loss_proj:1.401 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a ticket return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 87.963 | p: 87.106 | r: 89.009
rouge2     | fm: 50.274 | p: 49.846 | r: 50.825
rougeL     | fm: 75.714 | p: 75.047 | r: 76.564
rougeLsum  | fm: 75.455 | p: 74.809 | r: 76.349
r1fm+r2fm = 138.237

input #63 time: 0:10:53 | total time: 11:35:27


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.7439094185829163 for ['[CLS] rare bus axe [SEP]']
[Init] best rec loss: 0.7080462574958801 for ['[CLS] rough security mozart [SEP]']
[Init] best rec loss: 0.69147789478302 for ['[CLS] picture both unable [SEP]']
[Init] best rec loss: 0.6880716681480408 for ['[CLS] thought premiere tumbling [SEP]']
[Init] best perm rec loss: 0.6854235529899597 for ['[CLS] tumbling premiere thought [SEP]']
[Init] best perm rec loss: 0.6846994161605835 for ['[CLS] tumbling thought premiere [SEP]']
[Init] best perm rec loss: 0.6845133900642395 for ['[CLS] thought tumbling premiere [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.066 (perp=9.634, rec=0.140), tot_loss_proj:2.274 [t=0.26s]
prediction: ['[CLS] strange horror strange [SEP]']
[ 100/2000] tot_loss=2.213 (perp=10.665, rec=0.079), tot_loss_proj:2.387 [t=0.29s]
prediction: ['[CLS] strange horror the [SEP]']
[ 150/2000] tot_loss=2.212 (perp=10.665, rec=0.079), tot_loss_proj:2.382 [t=0.26s]
prediction: ['[CLS] strange horror the [SEP]']
[ 200/2000] tot_loss=2.189 (perp=10.665, rec=0.056), tot_loss_proj:2.377 [t=0.25s]
prediction: ['[CLS] strange horror the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.679 (perp=8.065, rec=0.066), tot_loss_proj:1.697 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.668 (perp=8.065, rec=0.055), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.676 (perp=8.065, rec=0.063), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.680 (perp=8.065, rec=0.067), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.666 (perp=8.065, rec=0.053), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=8.065, rec=0.065), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.666 (perp=8.065, rec=0.053), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.662 (perp=8.065, rec=0.049), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.677 (perp=8.065, rec=0.064), tot_loss_proj:1.706 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.672 (perp=8.065, rec=0.059), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.662 (perp=8.065, rec=0.049), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.671 (perp=8.065, rec=0.058), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.670 (perp=8.065, rec=0.057), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.674 (perp=8.065, rec=0.061), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.675 (perp=8.065, rec=0.062), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.676 (perp=8.065, rec=0.063), tot_loss_proj:1.702 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.668 (perp=8.065, rec=0.055), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.663 (perp=8.065, rec=0.050), tot_loss_proj:1.698 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=8.065, rec=0.064), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.669 (perp=8.065, rec=0.056), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.675 (perp=8.065, rec=0.062), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=8.065, rec=0.059), tot_loss_proj:1.707 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.676 (perp=8.065, rec=0.063), tot_loss_proj:1.700 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.672 (perp=8.065, rec=0.059), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.666 (perp=8.065, rec=0.053), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.678 (perp=8.065, rec=0.065), tot_loss_proj:1.700 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.678 (perp=8.065, rec=0.065), tot_loss_proj:1.711 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=8.065, rec=0.068), tot_loss_proj:1.693 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.666 (perp=8.065, rec=0.053), tot_loss_proj:1.709 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.672 (perp=8.065, rec=0.059), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.675 (perp=8.065, rec=0.062), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.676 (perp=8.065, rec=0.063), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.687 (perp=8.065, rec=0.074), tot_loss_proj:1.699 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.679 (perp=8.065, rec=0.066), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.667 (perp=8.065, rec=0.054), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.065, rec=0.064), tot_loss_proj:1.698 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.272 | p: 87.490 | r: 89.322
rouge2     | fm: 51.233 | p: 50.773 | r: 51.715
rougeL     | fm: 76.096 | p: 75.484 | r: 76.922
rougeLsum  | fm: 76.038 | p: 75.387 | r: 76.896
r1fm+r2fm = 139.505

input #64 time: 0:10:48 | total time: 11:46:16


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8823700547218323 for ['[CLS]town bench schooner cream harrison neck officeery weeks [SEP]']
[Init] best rec loss: 0.8704113364219666 for ['[CLS]gating fitness throughout4 splash sticking a korean dishes [SEP]']
[Init] best rec loss: 0.7030504941940308 for ['[CLS] since completion bronze should fernando cleared sounds proper constituent [SEP]']
[Init] best perm rec loss: 0.6999948024749756 for ['[CLS] should fernando sounds since constituent cleared proper completion bronze [SEP]']
[Init] best perm rec loss: 0.6970254182815552 for ['[CLS] bronze proper completion since should fernando constituent sounds cleared [SEP]']
[Init] best perm rec loss: 0.6950476765632629 for ['[CLS] bronze constituent since should cleared proper completion fernando sounds [SEP]']
[Init] best perm rec loss: 0.693568229675293 for ['[CLS] proper constituent sounds fernando bronze should completion since cleared [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.625 (perp=11.967, rec=0.231), tot_loss_proj:2.830 [t=0.24s]
prediction: ['[CLS] joy romous rom of arms film film joy [SEP]']
[ 100/2000] tot_loss=2.655 (perp=12.468, rec=0.161), tot_loss_proj:2.986 [t=0.25s]
prediction: ['[CLS] joy romous romousmans film film joy [SEP]']
[ 150/2000] tot_loss=2.533 (perp=12.036, rec=0.126), tot_loss_proj:2.861 [t=0.26s]
prediction: ['[CLS] joy romous rom,s film film joy [SEP]']
[ 200/2000] tot_loss=2.192 (perp=10.475, rec=0.097), tot_loss_proj:2.584 [t=0.25s]
prediction: ['[CLS] joy romous rom, a film film joy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.325 (perp=10.591, rec=0.206), tot_loss_proj:2.610 [t=0.24s]
prediction: ['[CLS] joy emotionalous of, a film a rom [SEP]']
[ 300/2000] tot_loss=2.239 (perp=10.591, rec=0.121), tot_loss_proj:2.608 [t=0.25s]
prediction: ['[CLS] joy emotionalous of, a film a rom [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.763 (perp=8.336, rec=0.095), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] joyousp, a film a rom emotional [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.268 (perp=5.863, rec=0.096), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] joyous, a film a romp film [SEP]']
[ 450/2000] tot_loss=1.258 (perp=5.863, rec=0.085), tot_loss_proj:1.522 [t=0.25s]
prediction: ['[CLS] joyous, a film a romp film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.479 (perp=6.962, rec=0.087), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] joyous,. film a romp film [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.168 (perp=5.443, rec=0.079), tot_loss_proj:1.364 [t=0.26s]
prediction: ['[CLS] joyous, film a romp film. [SEP]']
[ 600/2000] tot_loss=1.154 (perp=5.443, rec=0.065), tot_loss_proj:1.360 [t=0.26s]
prediction: ['[CLS] joyous, film a romp film. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=0.984 (perp=4.546, rec=0.075), tot_loss_proj:1.189 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.986 (perp=4.546, rec=0.077), tot_loss_proj:1.185 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[ 750/2000] tot_loss=0.984 (perp=4.546, rec=0.075), tot_loss_proj:1.191 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.990 (perp=4.546, rec=0.081), tot_loss_proj:1.186 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.984 (perp=4.546, rec=0.075), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[ 900/2000] tot_loss=0.977 (perp=4.546, rec=0.068), tot_loss_proj:1.186 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.989 (perp=4.546, rec=0.080), tot_loss_proj:1.181 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.979 (perp=4.546, rec=0.070), tot_loss_proj:1.188 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1050/2000] tot_loss=0.986 (perp=4.546, rec=0.077), tot_loss_proj:1.191 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.986 (perp=4.546, rec=0.077), tot_loss_proj:1.190 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.978 (perp=4.546, rec=0.069), tot_loss_proj:1.187 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1200/2000] tot_loss=0.980 (perp=4.546, rec=0.071), tot_loss_proj:1.184 [t=0.24s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.988 (perp=4.546, rec=0.079), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.985 (perp=4.546, rec=0.076), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1350/2000] tot_loss=0.981 (perp=4.546, rec=0.072), tot_loss_proj:1.191 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=0.996 (perp=4.546, rec=0.087), tot_loss_proj:1.192 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.983 (perp=4.546, rec=0.074), tot_loss_proj:1.188 [t=0.24s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1500/2000] tot_loss=0.987 (perp=4.546, rec=0.078), tot_loss_proj:1.192 [t=0.27s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.985 (perp=4.546, rec=0.075), tot_loss_proj:1.200 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.983 (perp=4.546, rec=0.074), tot_loss_proj:1.193 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1650/2000] tot_loss=0.979 (perp=4.546, rec=0.070), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.983 (perp=4.546, rec=0.074), tot_loss_proj:1.191 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.981 (perp=4.546, rec=0.072), tot_loss_proj:1.195 [t=0.24s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1800/2000] tot_loss=0.980 (perp=4.546, rec=0.071), tot_loss_proj:1.185 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.983 (perp=4.546, rec=0.074), tot_loss_proj:1.193 [t=0.26s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.985 (perp=4.546, rec=0.076), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
[1950/2000] tot_loss=0.972 (perp=4.546, rec=0.063), tot_loss_proj:1.197 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.980 (perp=4.546, rec=0.071), tot_loss_proj:1.197 [t=0.25s]
prediction: ['[CLS] joyous film, a romp film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous film, a romp film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 88.260 | p: 87.459 | r: 89.233
rouge2     | fm: 50.863 | p: 50.415 | r: 51.445
rougeL     | fm: 76.049 | p: 75.403 | r: 76.866
rougeLsum  | fm: 75.894 | p: 75.265 | r: 76.744
r1fm+r2fm = 139.123

input #65 time: 0:10:45 | total time: 11:57:01


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.9022266268730164 for ['[CLS] vineyards rivera couch bunk [SEP]']
[Init] best rec loss: 0.8701557517051697 for ['[CLS] dear submitted ink her [SEP]']
[Init] best rec loss: 0.8168815970420837 for ['[CLS] bare au [MASK] alf [SEP]']
[Init] best rec loss: 0.7963026165962219 for ['[CLS] niche ethnicsity upper [SEP]']
[Init] best rec loss: 0.7941915988922119 for ['[CLS] attempt mriom especially [SEP]']
[Init] best rec loss: 0.7933368682861328 for ['[CLS] system included your amidst [SEP]']
[Init] best rec loss: 0.7816464304924011 for ['[CLS] waysceaeline lived [SEP]']
[Init] best rec loss: 0.7643508911132812 for ['[CLS] yankee gould ladyurized [SEP]']
[Init] best rec loss: 0.7473493814468384 for ['[CLS] works sammyuariespace [SEP]']
[Init] best rec loss: 0.7160261869430542 for ['[CLS] touching image quite modern [SEP]']
[Init] best perm rec loss: 0.713448703289032 for ['[CLS] quite modern touching image [SEP]']
[Init] best perm rec loss: 0.7109436392784119 for ['[CLS] image quite modern touching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.308 (perp=9.897, rec=0.328), tot_loss_proj:3.093 [t=0.27s]
prediction: ['[CLS] fan not tolkien fan [SEP]']
[ 100/2000] tot_loss=2.192 (perp=10.122, rec=0.168), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] fan longtime tolkien fan [SEP]']
[ 150/2000] tot_loss=2.164 (perp=10.122, rec=0.140), tot_loss_proj:2.325 [t=0.25s]
prediction: ['[CLS] fan longtime tolkien fan [SEP]']
[ 200/2000] tot_loss=2.168 (perp=10.122, rec=0.143), tot_loss_proj:2.328 [t=0.25s]
prediction: ['[CLS] fan longtime tolkien fan [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.776 (perp=8.227, rec=0.131), tot_loss_proj:1.887 [t=0.27s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
[ 300/2000] tot_loss=1.777 (perp=8.227, rec=0.132), tot_loss_proj:1.886 [t=0.26s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.760 (perp=8.227, rec=0.115), tot_loss_proj:1.895 [t=0.26s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.768 (perp=8.227, rec=0.123), tot_loss_proj:1.893 [t=0.28s]
prediction: ['[CLS] longtime fan tolkien fan [SEP]']
[ 450/2000] tot_loss=2.214 (perp=10.506, rec=0.112), tot_loss_proj:2.394 [t=0.26s]
prediction: ['[CLS] longtime hobby tolkien fan [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.069 (perp=9.693, rec=0.131), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan nietzsche [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.055 (perp=9.693, rec=0.116), tot_loss_proj:2.387 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan nietzsche [SEP]']
[ 600/2000] tot_loss=2.073 (perp=9.693, rec=0.134), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan nietzsche [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.936 (perp=9.132, rec=0.110), tot_loss_proj:2.248 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.945 (perp=9.132, rec=0.118), tot_loss_proj:2.239 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
[ 750/2000] tot_loss=1.940 (perp=9.132, rec=0.113), tot_loss_proj:2.243 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.946 (perp=9.132, rec=0.120), tot_loss_proj:2.240 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.951 (perp=9.132, rec=0.125), tot_loss_proj:2.237 [t=0.27s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
[ 900/2000] tot_loss=1.956 (perp=9.132, rec=0.130), tot_loss_proj:2.242 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.035 (perp=9.531, rec=0.128), tot_loss_proj:2.614 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan controversy [SEP]']
Attempt swap
[1000/2000] tot_loss=2.037 (perp=9.531, rec=0.130), tot_loss_proj:2.606 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan controversy [SEP]']
[1050/2000] tot_loss=2.032 (perp=9.531, rec=0.125), tot_loss_proj:2.611 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan controversy [SEP]']
Attempt swap
[1100/2000] tot_loss=2.015 (perp=9.531, rec=0.109), tot_loss_proj:2.609 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan controversy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.941 (perp=9.132, rec=0.114), tot_loss_proj:2.239 [t=0.27s]
prediction: ['[CLS] longtime tolkien fan tribute [SEP]']
[1200/2000] tot_loss=2.245 (perp=10.620, rec=0.121), tot_loss_proj:2.612 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.245 (perp=10.620, rec=0.121), tot_loss_proj:2.612 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.797 (perp=8.397, rec=0.117), tot_loss_proj:2.033 [t=0.27s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
[1350/2000] tot_loss=1.797 (perp=8.397, rec=0.117), tot_loss_proj:2.026 [t=0.28s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
Attempt swap
[1400/2000] tot_loss=1.799 (perp=8.397, rec=0.119), tot_loss_proj:2.032 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
Attempt swap
[1450/2000] tot_loss=1.784 (perp=8.397, rec=0.105), tot_loss_proj:2.034 [t=0.31s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
[1500/2000] tot_loss=1.795 (perp=8.397, rec=0.115), tot_loss_proj:2.034 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
Attempt swap
[1550/2000] tot_loss=1.798 (perp=8.397, rec=0.118), tot_loss_proj:2.030 [t=0.29s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
Attempt swap
[1600/2000] tot_loss=1.807 (perp=8.397, rec=0.128), tot_loss_proj:2.035 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
[1650/2000] tot_loss=1.806 (perp=8.397, rec=0.127), tot_loss_proj:2.028 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
Attempt swap
[1700/2000] tot_loss=1.805 (perp=8.397, rec=0.126), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan poet [SEP]']
Attempt swap
[1750/2000] tot_loss=2.069 (perp=9.713, rec=0.127), tot_loss_proj:2.454 [t=0.26s]
prediction: ['[CLS] longtime tolkien fan vantage [SEP]']
[1800/2000] tot_loss=2.052 (perp=9.713, rec=0.109), tot_loss_proj:2.453 [t=0.28s]
prediction: ['[CLS] longtime tolkien fan vantage [SEP]']
Attempt swap
[1850/2000] tot_loss=2.060 (perp=9.713, rec=0.118), tot_loss_proj:2.448 [t=0.27s]
prediction: ['[CLS] longtime tolkien fan vantage [SEP]']
Attempt swap
[1900/2000] tot_loss=2.056 (perp=9.713, rec=0.113), tot_loss_proj:2.457 [t=0.35s]
prediction: ['[CLS] longtime tolkien fan vantage [SEP]']
[1950/2000] tot_loss=2.054 (perp=9.713, rec=0.112), tot_loss_proj:2.458 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan vantage [SEP]']
Attempt swap
[2000/2000] tot_loss=2.060 (perp=9.713, rec=0.117), tot_loss_proj:2.459 [t=0.25s]
prediction: ['[CLS] longtime tolkien fan vantage [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] longtime tolkien fan poet [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 88.092 | p: 87.334 | r: 89.127
rouge2     | fm: 50.783 | p: 50.365 | r: 51.280
rougeL     | fm: 76.088 | p: 75.426 | r: 76.949
rougeLsum  | fm: 76.131 | p: 75.519 | r: 76.934
r1fm+r2fm = 138.875

input #66 time: 0:10:49 | total time: 12:07:50


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9741578698158264 for ['[CLS]oked lamerl hunt normal rose lips allmusicflict charter [SEP]']
[Init] best rec loss: 0.9315156936645508 for ['[CLS] gone correctional various bachelor ze trilogy₁ proportionalivist middle [SEP]']
[Init] best rec loss: 0.8645824193954468 for ['[CLS] letters being worked spell pleasuresman nightmare got valentine inducted [SEP]']
[Init] best rec loss: 0.8218108415603638 for ['[CLS] whether loop stairwayvere sweep advantage opposition rarely rat al [SEP]']
[Init] best rec loss: 0.8170906901359558 for ['[CLS] ashley pont miles goal bars tie coordinates judith mathematics creative [SEP]']
[Init] best rec loss: 0.8143740892410278 for ['[CLS] fang without life commercial largely matched tie referred humor champions [SEP]']
[Init] best rec loss: 0.810047447681427 for ['[CLS] faction running heavily impactuation born lore crawling capable senator [SEP]']
[Init] best rec loss: 0.8058088421821594 for ['[CLS] plus eras send testedoff ye living electronic troyoned [SEP]']
[Init] best rec loss: 0.8033961057662964 for ['[CLS] ra empire wide push emerald clad story transport swept around [SEP]']
[Init] best rec loss: 0.7992368340492249 for ['[CLS] persuade mouths longest smokeality called piustell genome preserves [SEP]']
[Init] best perm rec loss: 0.7973676919937134 for ['[CLS]ality genome pius mouths preserves smoke persuade longest calledtell [SEP]']
[Init] best perm rec loss: 0.7939895391464233 for ['[CLS] longesttell smoke preserves mouths called genomeality persuade pius [SEP]']
[Init] best perm rec loss: 0.7883729934692383 for ['[CLS] preservestell piusality mouths genome smoke persuade longest called [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.083 (perp=13.574, rec=0.368), tot_loss_proj:3.502 [t=0.26s]
prediction: ['[CLS] kindctric miracles maha heart heart drama wounded low kind [SEP]']
[ 100/2000] tot_loss=2.233 (perp=9.804, rec=0.272), tot_loss_proj:2.692 [t=0.26s]
prediction: ['[CLS] kindental miracle heart heart heartted, non kind [SEP]']
[ 150/2000] tot_loss=2.384 (perp=10.870, rec=0.210), tot_loss_proj:2.944 [t=0.26s]
prediction: ['[CLS]warental kind heartwarmingtedental non kind [SEP]']
[ 200/2000] tot_loss=2.477 (perp=11.647, rec=0.147), tot_loss_proj:3.092 [t=0.28s]
prediction: ['[CLS]warentalental heartwarmingwarental non kind [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.165 (perp=10.057, rec=0.153), tot_loss_proj:2.392 [t=0.27s]
prediction: ['[CLS]war heartwarmingwarental nongmental kind [SEP]']
[ 300/2000] tot_loss=2.118 (perp=10.057, rec=0.107), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS]war heartwarmingwarental nongmental kind [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.903 (perp=9.047, rec=0.094), tot_loss_proj:2.288 [t=0.27s]
prediction: ['[CLS] heartwarwarmingtedental nongmental kind [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.834 (perp=8.593, rec=0.115), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] heartwarwarmingental nongmentaled kind [SEP]']
[ 450/2000] tot_loss=1.924 (perp=9.089, rec=0.106), tot_loss_proj:2.293 [t=0.24s]
prediction: ['[CLS] heartwarwarmingental nongmentalming kind [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.949 (perp=9.248, rec=0.100), tot_loss_proj:2.347 [t=0.25s]
prediction: ['[CLS] heartwarmingental nongmentalmingming kind [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.827 (perp=8.616, rec=0.104), tot_loss_proj:2.166 [t=0.25s]
prediction: ['[CLS] heartwarmingental nongmentalminged kind [SEP]']
[ 600/2000] tot_loss=1.814 (perp=8.616, rec=0.091), tot_loss_proj:2.165 [t=0.26s]
prediction: ['[CLS] heartwarmingental nongmentalminged kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.818 (perp=8.616, rec=0.094), tot_loss_proj:2.163 [t=0.28s]
prediction: ['[CLS] heartwarmingental nongmentalminged kind [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.806 (perp=8.616, rec=0.083), tot_loss_proj:2.164 [t=0.26s]
prediction: ['[CLS] heartwarmingental nongmentalminged kind [SEP]']
[ 750/2000] tot_loss=1.814 (perp=8.616, rec=0.091), tot_loss_proj:2.162 [t=0.27s]
prediction: ['[CLS] heartwarmingental nongmentalminged kind [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.802 (perp=8.559, rec=0.090), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] heartwarmingental nongmentalming, kind [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=1.597 (perp=7.474, rec=0.102), tot_loss_proj:1.988 [t=0.27s]
prediction: ['[CLS] kind heartwarmingental nongmentalming, [SEP]']
[ 900/2000] tot_loss=1.590 (perp=7.474, rec=0.096), tot_loss_proj:1.993 [t=0.26s]
prediction: ['[CLS] kind heartwarmingental nongmentalming, [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.525 (perp=7.188, rec=0.087), tot_loss_proj:1.845 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmentalming [SEP]']
Attempt swap
[1000/2000] tot_loss=1.353 (perp=6.338, rec=0.086), tot_loss_proj:1.641 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
[1050/2000] tot_loss=1.349 (perp=6.338, rec=0.081), tot_loss_proj:1.645 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.351 (perp=6.338, rec=0.084), tot_loss_proj:1.649 [t=0.27s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.348 (perp=6.338, rec=0.080), tot_loss_proj:1.636 [t=0.27s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
[1200/2000] tot_loss=1.351 (perp=6.338, rec=0.084), tot_loss_proj:1.649 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.346 (perp=6.338, rec=0.079), tot_loss_proj:1.640 [t=0.24s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.347 (perp=6.338, rec=0.079), tot_loss_proj:1.652 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
[1350/2000] tot_loss=1.347 (perp=6.338, rec=0.079), tot_loss_proj:1.645 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.347 (perp=6.338, rec=0.079), tot_loss_proj:1.642 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.341 (perp=6.338, rec=0.073), tot_loss_proj:1.642 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
[1500/2000] tot_loss=1.352 (perp=6.338, rec=0.084), tot_loss_proj:1.649 [t=0.27s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.345 (perp=6.338, rec=0.077), tot_loss_proj:1.642 [t=0.27s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.347 (perp=6.338, rec=0.080), tot_loss_proj:1.637 [t=0.27s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
[1650/2000] tot_loss=1.348 (perp=6.338, rec=0.080), tot_loss_proj:1.643 [t=0.26s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.342 (perp=6.338, rec=0.074), tot_loss_proj:1.641 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nongmental, [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.514 (perp=7.153, rec=0.083), tot_loss_proj:1.816 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nongmentald [SEP]']
[1800/2000] tot_loss=1.507 (perp=7.153, rec=0.076), tot_loss_proj:1.808 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nongmentald [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.425 (perp=6.675, rec=0.090), tot_loss_proj:1.669 [t=0.28s]
prediction: ['[CLS] kind heartwarming,ental nondgmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.410 (perp=6.675, rec=0.075), tot_loss_proj:1.665 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nondgmental [SEP]']
[1950/2000] tot_loss=1.412 (perp=6.675, rec=0.077), tot_loss_proj:1.673 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nondgmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.420 (perp=6.675, rec=0.085), tot_loss_proj:1.675 [t=0.25s]
prediction: ['[CLS] kind heartwarming,ental nondgmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming,ental nongmental, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 72.727

[Aggregate metrics]:
rouge1     | fm: 87.875 | p: 87.053 | r: 88.952
rouge2     | fm: 50.127 | p: 49.674 | r: 50.655
rougeL     | fm: 75.723 | p: 75.028 | r: 76.613
rougeLsum  | fm: 75.675 | p: 75.009 | r: 76.535
r1fm+r2fm = 138.002

input #67 time: 0:10:46 | total time: 12:18:37


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9391144514083862 for ['[CLS] bit raven womb completezon center madison emissions fellowzar retreat managementcellular [SEP]']
[Init] best rec loss: 0.8799402713775635 for ['[CLS]dget heap cupitude wood restricted dananis douglas guy wasting what dipped [SEP]']
[Init] best rec loss: 0.8719251751899719 for ['[CLS] stud ash attachment #copic gabrielaid focusedhelm bush private signature only [SEP]']
[Init] best rec loss: 0.8706572651863098 for ['[CLS] rappers awoke cambridge might wanted sat loose decadentonbled levminatingval [SEP]']
[Init] best rec loss: 0.8596570491790771 for ["[CLS]ie min ethan work dress viaffey ladyue bail volunteers'eccentric [SEP]"]
[Init] best rec loss: 0.857316255569458 for ['[CLS] ardenbbled marine role ceiling information police bill denomination eve shade bear unable [SEP]']
[Init] best rec loss: 0.8500001430511475 for ['[CLS] emotions mc buttonpping relatively wild urgency trials assigns wore renamed grover flu [SEP]']
[Init] best perm rec loss: 0.8494278788566589 for ['[CLS] wore assigns renamed relatively buttonpping trials urgency grover mc flu wild emotions [SEP]']
[Init] best perm rec loss: 0.8482072353363037 for ['[CLS] mc emotions assigns flu relatively renamed worepping button trials urgency wild grover [SEP]']
[Init] best perm rec loss: 0.8477002382278442 for ['[CLS] button grover trialspping renamed urgency relatively wore emotions mc assigns wild flu [SEP]']
[Init] best perm rec loss: 0.846708357334137 for ['[CLS] wore flu assigns wild trials mc renamedpping urgency button grover relatively emotions [SEP]']
[Init] best perm rec loss: 0.846664547920227 for ['[CLS] emotions grover renamed assigns mc urgency button relativelypping trials wore flu wild [SEP]']
[Init] best perm rec loss: 0.8450127243995667 for ['[CLS] urgency renamed emotionspping wore grover flu assigns relatively mc wild trials button [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.579 (perp=11.840, rec=0.211), tot_loss_proj:2.933 [t=0.25s]
prediction: ['[CLS] absurd liarjo vicious unkated ob, vicious. suspicious absurd [SEP]']
[ 100/2000] tot_loss=2.372 (perp=11.077, rec=0.156), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS] absurd relatedsible vicious uncodeuth, vicious.omp absurd [SEP]']
[ 150/2000] tot_loss=2.086 (perp=9.810, rec=0.124), tot_loss_proj:2.307 [t=0.27s]
prediction: ['[CLS] absurdsiblesible vicious uncouthuth, vicious andomp absurd [SEP]']
[ 200/2000] tot_loss=2.011 (perp=9.476, rec=0.116), tot_loss_proj:2.233 [t=0.25s]
prediction: ['[CLS] absurdsiblesible vicious uncouthsible, vicious andomp absurd [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.878 (perp=8.606, rec=0.157), tot_loss_proj:2.067 [t=0.25s]
prediction: ['[CLS]siblesible vicious uncouthsible, vicious andomp absurd absurd [SEP]']
[ 300/2000] tot_loss=2.022 (perp=9.469, rec=0.129), tot_loss_proj:2.269 [t=0.26s]
prediction: ['[CLS]siblehen vicious uncouthsible, vicious andomp absurd absurd [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.737 (perp=8.062, rec=0.124), tot_loss_proj:1.966 [t=0.27s]
prediction: ['[CLS]sible vicious uncouthhensible, vicious andomp absurd absurd [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.502 (perp=6.952, rec=0.112), tot_loss_proj:1.707 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious and absurd absurd [SEP]']
[ 450/2000] tot_loss=1.495 (perp=6.952, rec=0.105), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious and absurd absurd [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.427 (perp=6.708, rec=0.085), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and absurd [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.430 (perp=6.708, rec=0.088), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and absurd [SEP]']
[ 600/2000] tot_loss=1.430 (perp=6.708, rec=0.088), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and absurd [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.432 (perp=6.708, rec=0.090), tot_loss_proj:1.675 [t=0.26s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and absurd [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.423 (perp=6.708, rec=0.082), tot_loss_proj:1.674 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and absurd [SEP]']
[ 750/2000] tot_loss=1.421 (perp=6.708, rec=0.079), tot_loss_proj:1.680 [t=0.28s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.558 (perp=7.405, rec=0.077), tot_loss_proj:1.926 [t=0.26s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and inc [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.555 (perp=7.405, rec=0.074), tot_loss_proj:1.924 [t=0.26s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and inc [SEP]']
[ 900/2000] tot_loss=1.553 (perp=7.405, rec=0.072), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, vicious absurd and inc [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.499 (perp=7.121, rec=0.075), tot_loss_proj:1.868 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1000/2000] tot_loss=1.507 (perp=7.121, rec=0.082), tot_loss_proj:1.861 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, inc absurd and vicious [SEP]']
[1050/2000] tot_loss=1.504 (perp=7.121, rec=0.080), tot_loss_proj:1.862 [t=0.25s]
prediction: ['[CLS]sible vicious uncouthomphensible, inc absurd and vicious [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.474 (perp=6.971, rec=0.080), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1150/2000] tot_loss=1.468 (perp=6.971, rec=0.073), tot_loss_proj:1.878 [t=0.27s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
[1200/2000] tot_loss=1.465 (perp=6.971, rec=0.071), tot_loss_proj:1.875 [t=0.24s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1250/2000] tot_loss=1.476 (perp=6.971, rec=0.082), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1300/2000] tot_loss=1.466 (perp=6.971, rec=0.072), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
[1350/2000] tot_loss=1.474 (perp=6.971, rec=0.080), tot_loss_proj:1.885 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1400/2000] tot_loss=1.469 (perp=6.971, rec=0.075), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1450/2000] tot_loss=1.473 (perp=6.971, rec=0.078), tot_loss_proj:1.880 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
[1500/2000] tot_loss=1.466 (perp=6.971, rec=0.072), tot_loss_proj:1.880 [t=0.27s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1550/2000] tot_loss=1.473 (perp=6.971, rec=0.079), tot_loss_proj:1.878 [t=0.27s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1600/2000] tot_loss=1.470 (perp=6.971, rec=0.076), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
[1650/2000] tot_loss=1.473 (perp=6.971, rec=0.079), tot_loss_proj:1.878 [t=0.24s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1700/2000] tot_loss=1.471 (perp=6.971, rec=0.077), tot_loss_proj:1.874 [t=0.26s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1750/2000] tot_loss=1.470 (perp=6.971, rec=0.075), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
[1800/2000] tot_loss=1.468 (perp=6.971, rec=0.074), tot_loss_proj:1.876 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1850/2000] tot_loss=1.476 (perp=6.971, rec=0.082), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[1900/2000] tot_loss=1.470 (perp=6.971, rec=0.075), tot_loss_proj:1.874 [t=0.28s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
[1950/2000] tot_loss=1.471 (perp=6.971, rec=0.077), tot_loss_proj:1.881 [t=0.26s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Attempt swap
[2000/2000] tot_loss=1.473 (perp=6.971, rec=0.079), tot_loss_proj:1.878 [t=0.25s]
prediction: ['[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS]sible uncouth viciousomphensible, inc absurd and vicious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 66.667 | r: 85.714
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 44.444 | r: 57.143
rougeLsum  | fm: 50.000 | p: 44.444 | r: 57.143
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 87.738 | p: 86.760 | r: 88.964
rouge2     | fm: 49.248 | p: 48.799 | r: 49.752
rougeL     | fm: 75.374 | p: 74.536 | r: 76.367
rougeLsum  | fm: 75.364 | p: 74.603 | r: 76.328
r1fm+r2fm = 136.986

input #68 time: 0:10:39 | total time: 12:29:17


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.9315260052680969 for ['[CLS] li proves guess adobe sol re much called gunner appeared negative type edna static ground hilt [SEP]']
[Init] best rec loss: 0.9268032908439636 for ['[CLS] orchestra kramer worms wo actually founded districts [SEP] mission processor political runners peters televisionono prejudice [SEP]']
[Init] best rec loss: 0.9159980416297913 for ['[CLS] computationalhila madamsive extensively mom runners sex doing unison labels cab strata queensland carbon remember [SEP]']
[Init] best rec loss: 0.9133909344673157 for ['[CLS] desert unusualkir memorial lynn think medal steel whispertingntial opening ds location stink madman [SEP]']
[Init] best rec loss: 0.9070391654968262 for ['[CLS] what reflex reputation stevenson earned my mother analytics beyonce structure orderrictedery tender federalmann [SEP]']
[Init] best perm rec loss: 0.9045318365097046 for ['[CLS] earned what reflex reputation beyonce tender my federal stevenson motherricted structure ordermann analyticsery [SEP]']
[Init] best perm rec loss: 0.9033071994781494 for ['[CLS] structure federal what earned analyticsmannery my reflex stevensonricted tender reputation mother beyonce order [SEP]']
[Init] best perm rec loss: 0.9028661251068115 for ['[CLS] reflex my structure reputation stevenson earned tendereryricted analytics order beyoncemann what federal mother [SEP]']
[Init] best perm rec loss: 0.9022497534751892 for ['[CLS] what beyonce structuremann reputation analytics tenderricted earnedery federal my stevenson mother order reflex [SEP]']
[Init] best perm rec loss: 0.9017260670661926 for ['[CLS] reflex mothermann analytics order stevensonery reputationricted federal structure tender beyonce earned my what [SEP]']
[Init] best perm rec loss: 0.9015400409698486 for ['[CLS] what reputation tender federal stevensonmann structure analyticsricted reflex mother my earned orderery beyonce [SEP]']
[Init] best perm rec loss: 0.9013231992721558 for ['[CLS]ricted my tender what analyticsery reputation beyonce earned federalmann reflex order structure mother stevenson [SEP]']
[Init] best perm rec loss: 0.8997948169708252 for ['[CLS] what earned beyonce mother stevenson my analytics reputation structure federalricted tendermann reflexery order [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=9.266, rec=0.526), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS] with address four crosby. - & discontinued traditional gamer wonderful - a smart dies. [SEP]']
[ 100/2000] tot_loss=2.712 (perp=11.120, rec=0.488), tot_loss_proj:3.150 [t=0.25s]
prediction: ['[CLS] ; impact four upper.... ; discontinued a winner real, jewsango multitude sara [SEP]']
[ 150/2000] tot_loss=2.640 (perp=11.200, rec=0.400), tot_loss_proj:3.169 [t=0.26s]
prediction: ['[CLS]. res four virtual. - ; discontinued winner funny real, lifelongctric thousand add [SEP]']
[ 200/2000] tot_loss=2.393 (perp=10.065, rec=0.380), tot_loss_proj:3.004 [t=0.26s]
prediction: ['[CLS] including resnt born, - ; lonely winner winner funny, beautyctric thousand. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.429 (perp=10.317, rec=0.365), tot_loss_proj:3.051 [t=0.27s]
prediction: ['[CLS] including res seasons born, -, _ winner winner funny,nt weapons thousand. [SEP]']
[ 300/2000] tot_loss=2.260 (perp=9.550, rec=0.350), tot_loss_proj:2.860 [t=0.27s]
prediction: ['[CLS] including res women elastic, - & discontinued winner winner funny,nt trophy tablet. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.388 (perp=10.221, rec=0.344), tot_loss_proj:2.991 [t=0.26s]
prediction: ['[CLS] including res elastic women, - & discontinued winner winner funny,nt trophy tablet honey [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.397 (perp=10.291, rec=0.338), tot_loss_proj:3.080 [t=0.26s]
prediction: ['[CLS] including res elastic women, - & wonderful tablet winner funny,nt enough winner honey [SEP]']
[ 450/2000] tot_loss=2.443 (perp=10.588, rec=0.325), tot_loss_proj:3.110 [t=0.26s]
prediction: ['[CLS] including res elastic women, - & stu tablet winner funny,nt places winner honey [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.514 (perp=10.973, rec=0.319), tot_loss_proj:3.172 [t=0.25s]
prediction: ['[CLS] including res yeah women, - & stu tablet winner funny, winner backupnt honey [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.439 (perp=10.605, rec=0.318), tot_loss_proj:3.092 [t=0.26s]
prediction: ['[CLS] including res women yeah, - & stu thousand winner funny, winner backupnt honey [SEP]']
[ 600/2000] tot_loss=2.428 (perp=10.437, rec=0.340), tot_loss_proj:3.045 [t=0.33s]
prediction: ['[CLS] over res womenᵢ, - & products thousand winner funny, winner backupnt honey [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.348 (perp=10.141, rec=0.320), tot_loss_proj:2.993 [t=0.26s]
prediction: ['[CLS] - & res womenᵢ, - products thousand winner funny, winnertightnt talking [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.294 (perp=9.902, rec=0.314), tot_loss_proj:2.916 [t=0.32s]
prediction: ['[CLS] - & res womenᵢ, thousand products - winner funny, winner regardlessnt talking [SEP]']
[ 750/2000] tot_loss=2.264 (perp=9.812, rec=0.301), tot_loss_proj:2.923 [t=0.34s]
prediction: ['[CLS] -, res women yeah, thousand products - winner funny, winner regardlessnt talking [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.423 (perp=10.580, rec=0.307), tot_loss_proj:3.077 [t=0.29s]
prediction: ['[CLS] women, res - yeah, thousand stu - winner funny, winner regardlessnt talking [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.165 (perp=9.320, rec=0.301), tot_loss_proj:2.845 [t=0.29s]
prediction: ['[CLS] women, res - logistics,tha stu funny - winner, winnertightnt talking [SEP]']
[ 900/2000] tot_loss=2.277 (perp=9.891, rec=0.299), tot_loss_proj:2.939 [t=0.30s]
prediction: ['[CLS] women, res - logistics, thousand stu funny - winner, winner regardlessnt talking [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.278 (perp=9.921, rec=0.294), tot_loss_proj:2.938 [t=0.25s]
prediction: ['[CLS] women, res - logistics reforms, stu funny - winner, winner regardlessnt talking [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.452 (perp=10.752, rec=0.302), tot_loss_proj:3.084 [t=0.27s]
prediction: ['[CLS] women & - finish thousand, res empty funny - winner, winner regardlessnt talking [SEP]']
[1050/2000] tot_loss=2.225 (perp=9.646, rec=0.296), tot_loss_proj:2.851 [t=0.27s]
prediction: ['[CLS] women, - finish thousand, res empty funny - winner, winner regardlessnt talking [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.130 (perp=9.193, rec=0.291), tot_loss_proj:2.760 [t=0.27s]
prediction: ['[CLS] women, finish reforms, res - empty funny - winner, winner regardlessaneous talking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.129 (perp=9.193, rec=0.290), tot_loss_proj:2.760 [t=0.25s]
prediction: ['[CLS] women, finish reforms, res - empty funny - winner, winner regardlessaneous talking [SEP]']
[1200/2000] tot_loss=2.164 (perp=9.371, rec=0.290), tot_loss_proj:2.803 [t=0.27s]
prediction: ['[CLS] women, nomination reforms, res - empty funny - winner, winner regardlessaneous talking [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.188 (perp=9.468, rec=0.294), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] women, nomination vulgar - res, empty funny - winner, winner regardlessaneous talking [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.298 (perp=9.913, rec=0.315), tot_loss_proj:2.912 [t=0.26s]
prediction: ['[CLS] women & res reforms - logistics, empty funny - winner, winner regardlessaneous talking [SEP]']
[1350/2000] tot_loss=2.091 (perp=9.032, rec=0.285), tot_loss_proj:2.735 [t=0.25s]
prediction: ['[CLS] women & res - - logistics, empty funny - winner, winner regardlessaneous talking [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.167 (perp=9.376, rec=0.292), tot_loss_proj:2.871 [t=0.28s]
prediction: ['[CLS] womennt res - - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.110 (perp=9.103, rec=0.289), tot_loss_proj:2.810 [t=0.28s]
prediction: ['[CLS]nt women res - - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
[1500/2000] tot_loss=2.104 (perp=9.103, rec=0.284), tot_loss_proj:2.806 [t=0.25s]
prediction: ['[CLS]nt women res - - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.244 (perp=9.750, rec=0.294), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS]nt women res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.232 (perp=9.750, rec=0.282), tot_loss_proj:2.907 [t=0.27s]
prediction: ['[CLS]nt women res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
[1650/2000] tot_loss=2.232 (perp=9.750, rec=0.282), tot_loss_proj:2.908 [t=0.25s]
prediction: ['[CLS]nt women res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.239 (perp=9.750, rec=0.288), tot_loss_proj:2.907 [t=0.28s]
prediction: ['[CLS]nt women res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.321 (perp=10.148, rec=0.291), tot_loss_proj:2.992 [t=0.26s]
prediction: ['[CLS] womennt res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
[1800/2000] tot_loss=2.307 (perp=10.148, rec=0.278), tot_loss_proj:2.996 [t=0.27s]
prediction: ['[CLS] womennt res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.212 (perp=9.599, rec=0.292), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS], women res vulgar - logistics, stu regardless - winner, winner funnynna talking [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.164 (perp=9.405, rec=0.284), tot_loss_proj:2.844 [t=0.27s]
prediction: ['[CLS], res vulgar women - logistics, stu regardless - winner, winner funnyaneous talking [SEP]']
[1950/2000] tot_loss=2.010 (perp=8.626, rec=0.285), tot_loss_proj:2.700 [t=0.28s]
prediction: ['[CLS] & res - women - logistics, stu regardless - winner, winner funnynna talking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.003 (perp=8.626, rec=0.278), tot_loss_proj:2.697 [t=0.25s]
prediction: ['[CLS] & res - women - logistics, stu regardless - winner, winner funnynna talking [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS]nt women res vulgar - logistics, stu regardless - winner, winner funnyaneous talking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 26.087 | p: 23.077 | r: 30.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 26.087 | p: 23.077 | r: 30.000
rougeLsum  | fm: 26.087 | p: 23.077 | r: 30.000
r1fm+r2fm = 26.087

[Aggregate metrics]:
rouge1     | fm: 86.913 | p: 85.910 | r: 88.136
rouge2     | fm: 48.596 | p: 48.164 | r: 49.067
rougeL     | fm: 74.679 | p: 73.891 | r: 75.693
rougeLsum  | fm: 74.518 | p: 73.721 | r: 75.507
r1fm+r2fm = 135.509

input #69 time: 0:11:12 | total time: 12:40:30


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8950824737548828 for ['[CLS] september ark charity particular ice mastered spot [SEP]']
[Init] best rec loss: 0.8670381903648376 for ['[CLS] hour action reserves border collar personal stare [SEP]']
[Init] best rec loss: 0.8539671301841736 for ['[CLS] center cape decision dance0 themselves their [SEP]']
[Init] best rec loss: 0.8212988972663879 for ['[CLS]night bit scratch telescope incumbent thai prem [SEP]']
[Init] best rec loss: 0.7134888172149658 for ['[CLS] cigarette miniatures pleading maybe twisted collect shy [SEP]']
[Init] best rec loss: 0.7072710394859314 for ['[CLS] retiredgles datall conference hearts cases [SEP]']
[Init] best rec loss: 0.7054237127304077 for ['[CLS] signing confirmed ben knife mi driven tenure [SEP]']
[Init] best rec loss: 0.6605101823806763 for ['[CLS] gradeaton hand been vision runway fairy [SEP]']
[Init] best perm rec loss: 0.6596750617027283 for ['[CLS] runway been visionaton fairy grade hand [SEP]']
[Init] best perm rec loss: 0.6578187942504883 for ['[CLS] grade visionaton runway fairy been hand [SEP]']
[Init] best perm rec loss: 0.6555355787277222 for ['[CLS] grade hand vision beenaton runway fairy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.551 (perp=11.335, rec=0.284), tot_loss_proj:2.735 [t=0.25s]
prediction: ['[CLS] sentencey gets clunk beer tilt [SEP]']
[ 100/2000] tot_loss=1.767 (perp=8.253, rec=0.117), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] screeny gets clunky screen [SEP]']
[ 150/2000] tot_loss=1.910 (perp=9.202, rec=0.070), tot_loss_proj:2.248 [t=0.27s]
prediction: ['[CLS] they gets clunk on screen [SEP]']
[ 200/2000] tot_loss=1.919 (perp=9.202, rec=0.078), tot_loss_proj:2.241 [t=0.26s]
prediction: ['[CLS] they gets clunk on screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.375 (perp=6.452, rec=0.085), tot_loss_proj:1.452 [t=0.26s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
[ 300/2000] tot_loss=1.352 (perp=6.452, rec=0.062), tot_loss_proj:1.453 [t=0.26s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.351 (perp=6.452, rec=0.060), tot_loss_proj:1.458 [t=0.30s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.347 (perp=6.452, rec=0.056), tot_loss_proj:1.454 [t=0.26s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
[ 450/2000] tot_loss=1.358 (perp=6.452, rec=0.068), tot_loss_proj:1.445 [t=0.26s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.353 (perp=6.452, rec=0.062), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.291 (perp=6.139, rec=0.064), tot_loss_proj:1.312 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[ 600/2000] tot_loss=1.286 (perp=6.139, rec=0.059), tot_loss_proj:1.311 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.296 (perp=6.139, rec=0.068), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.278 (perp=6.139, rec=0.051), tot_loss_proj:1.306 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[ 750/2000] tot_loss=1.292 (perp=6.139, rec=0.065), tot_loss_proj:1.312 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.275 (perp=6.139, rec=0.047), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.276 (perp=6.139, rec=0.048), tot_loss_proj:1.315 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[ 900/2000] tot_loss=1.296 (perp=6.139, rec=0.068), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.294 (perp=6.139, rec=0.066), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.280 (perp=6.139, rec=0.053), tot_loss_proj:1.311 [t=0.28s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1050/2000] tot_loss=1.298 (perp=6.139, rec=0.070), tot_loss_proj:1.303 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.288 (perp=6.139, rec=0.060), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.287 (perp=6.139, rec=0.060), tot_loss_proj:1.308 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1200/2000] tot_loss=1.285 (perp=6.139, rec=0.058), tot_loss_proj:1.304 [t=0.27s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.284 (perp=6.139, rec=0.057), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.288 (perp=6.139, rec=0.061), tot_loss_proj:1.305 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1350/2000] tot_loss=1.280 (perp=6.139, rec=0.053), tot_loss_proj:1.296 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.287 (perp=6.139, rec=0.060), tot_loss_proj:1.308 [t=0.27s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.279 (perp=6.139, rec=0.051), tot_loss_proj:1.306 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1500/2000] tot_loss=1.291 (perp=6.139, rec=0.064), tot_loss_proj:1.307 [t=0.27s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.287 (perp=6.139, rec=0.059), tot_loss_proj:1.298 [t=0.27s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.290 (perp=6.139, rec=0.062), tot_loss_proj:1.304 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1650/2000] tot_loss=1.288 (perp=6.139, rec=0.061), tot_loss_proj:1.303 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.284 (perp=6.139, rec=0.056), tot_loss_proj:1.294 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.295 (perp=6.139, rec=0.067), tot_loss_proj:1.307 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1800/2000] tot_loss=1.289 (perp=6.139, rec=0.061), tot_loss_proj:1.302 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.293 (perp=6.139, rec=0.065), tot_loss_proj:1.297 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.289 (perp=6.139, rec=0.061), tot_loss_proj:1.302 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1950/2000] tot_loss=1.290 (perp=6.139, rec=0.062), tot_loss_proj:1.308 [t=0.25s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.289 (perp=6.139, rec=0.061), tot_loss_proj:1.301 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets clunky on the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.937 | p: 85.956 | r: 88.224
rouge2     | fm: 49.281 | p: 48.814 | r: 49.763
rougeL     | fm: 74.988 | p: 74.227 | r: 76.019
rougeLsum  | fm: 74.979 | p: 74.195 | r: 75.976
r1fm+r2fm = 136.219

input #70 time: 0:10:49 | total time: 12:51:20


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.9001707434654236 for ['[CLS] classala plate africa placed otherwise cv peoples crowd them maxivision once directorate fans [SEP]']
[Init] best rec loss: 0.897082507610321 for ['[CLS] again liberals tube waived tough excluding francais membership onlywoman wins needs poly hundredna [SEP]']
[Init] best rec loss: 0.8943613171577454 for ['[CLS] looking [CLS] mansion bank were net co fix see top praised opposition wcw scouting fine [SEP]']
[Init] best rec loss: 0.8877601623535156 for ['[CLS] hockey plants god men pieces % hobart opposite besides ann sensation pittker h historic [SEP]']
[Init] best rec loss: 0.8855211734771729 for ['[CLS] nina strategy petty curl anitati [SEP]overs dexter ways crude refers resulted velvetless [SEP]']
[Init] best rec loss: 0.8823556303977966 for ['[CLS] orton lukas jersey clan missing codeled mad controlfaceum say compact depending wagon [SEP]']
[Init] best rec loss: 0.8534344434738159 for ['[CLS] famous always center marks company program century ball circlepkins score garrett far professor islands [SEP]']
[Init] best rec loss: 0.8341086506843567 for ['[CLS]ria battlesion bass paulo marchlos commissionpower bird documentsromaticoping swiss testing [SEP]']
[Init] best perm rec loss: 0.8308904767036438 for ['[CLS] commissionsionlosromaticria bass paulo swissoping documentspower bird testing march battle [SEP]']
[Init] best perm rec loss: 0.8274940252304077 for ['[CLS] marchriaromatic commission testingsion paulo battlelosoping bass swisspower bird documents [SEP]']
[Init] best perm rec loss: 0.8263009190559387 for ['[CLS] pauloromatic testingpower documents commissionlos swissria marchsion bassoping battle bird [SEP]']
[Init] best perm rec loss: 0.8261508941650391 for ['[CLS] paulo battleromaticria testingsionoping commission march documentslos basspower bird swiss [SEP]']
[Init] best perm rec loss: 0.8254455924034119 for ['[CLS] marchromaticlos testingsionria documentsoping battle commission bass paulo swisspower bird [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.311 (perp=10.220, rec=0.267), tot_loss_proj:2.729 [t=0.26s]
prediction: ['[CLS] moment put is not single single jump situation avoid no your jump moment. seat [SEP]']
[ 100/2000] tot_loss=1.850 (perp=8.518, rec=0.147), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] moment put and not a single jump - avoid no your seat moment - seat [SEP]']
[ 150/2000] tot_loss=1.425 (perp=6.626, rec=0.100), tot_loss_proj:1.941 [t=0.27s]
prediction: ['[CLS] there - and not a single jump - - a your seat moment - seat [SEP]']
[ 200/2000] tot_loss=1.404 (perp=6.626, rec=0.079), tot_loss_proj:1.941 [t=0.28s]
prediction: ['[CLS] there - and not a single jump - - a your seat moment - seat [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.327 (perp=6.271, rec=0.073), tot_loss_proj:1.872 [t=0.28s]
prediction: ['[CLS] there - and not a single jump - - seat your seat moment - s [SEP]']
[ 300/2000] tot_loss=1.277 (perp=6.062, rec=0.065), tot_loss_proj:1.840 [t=0.28s]
prediction: ['[CLS] there - and not a single jump - - - your seat moment - s [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.274 (perp=6.062, rec=0.062), tot_loss_proj:1.845 [t=0.28s]
prediction: ['[CLS] there - and not a single jump - - - your seat moment - s [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.240 (perp=5.796, rec=0.081), tot_loss_proj:1.643 [t=0.26s]
prediction: ['[CLS] there and not a single jump in - - - your seat moment - s [SEP]']
[ 450/2000] tot_loss=1.232 (perp=5.796, rec=0.073), tot_loss_proj:1.640 [t=0.27s]
prediction: ['[CLS] there and not a single jump in - - - your seat moment - s [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.213 (perp=5.695, rec=0.074), tot_loss_proj:1.592 [t=0.27s]
prediction: ['[CLS] and there not a single jump in - - - your seat moment - s [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.189 (perp=5.579, rec=0.073), tot_loss_proj:1.590 [t=0.25s]
prediction: ['[CLS] and there not a single jump - - - in your seat moment - s [SEP]']
[ 600/2000] tot_loss=1.183 (perp=5.579, rec=0.068), tot_loss_proj:1.601 [t=0.27s]
prediction: ['[CLS] and there not a single jump - - - in your seat moment - s [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.187 (perp=5.571, rec=0.073), tot_loss_proj:1.614 [t=0.27s]
prediction: ['[CLS] and there not a single jump - - - in your seat - s moment [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.177 (perp=5.571, rec=0.063), tot_loss_proj:1.606 [t=0.27s]
prediction: ['[CLS] and there not a single jump - - - in your seat - s moment [SEP]']
[ 750/2000] tot_loss=1.180 (perp=5.571, rec=0.066), tot_loss_proj:1.606 [t=0.28s]
prediction: ['[CLS] and there not a single jump - - - in your seat - s moment [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.191 (perp=5.570, rec=0.077), tot_loss_proj:1.664 [t=0.25s]
prediction: ['[CLS] there and not a single jump - - - in your seat - s moment [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.187 (perp=5.570, rec=0.073), tot_loss_proj:1.666 [t=0.27s]
prediction: ['[CLS] there and not a single jump - - - in your seat - s moment [SEP]']
[ 900/2000] tot_loss=1.305 (perp=6.155, rec=0.074), tot_loss_proj:1.800 [t=0.25s]
prediction: ["[CLS] there and not a single jump'- - in your seat - s moment [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.142 (perp=5.374, rec=0.067), tot_loss_proj:1.654 [t=0.26s]
prediction: ["[CLS] there and not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.138 (perp=5.374, rec=0.063), tot_loss_proj:1.649 [t=0.25s]
prediction: ["[CLS] there and not a single jump - - - in your seat's moment [SEP]"]
[1050/2000] tot_loss=1.136 (perp=5.374, rec=0.061), tot_loss_proj:1.650 [t=0.25s]
prediction: ["[CLS] there and not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.141 (perp=5.374, rec=0.067), tot_loss_proj:1.651 [t=0.27s]
prediction: ["[CLS] there and not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.125 (perp=5.321, rec=0.061), tot_loss_proj:1.579 [t=0.26s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
[1200/2000] tot_loss=1.132 (perp=5.321, rec=0.067), tot_loss_proj:1.582 [t=0.27s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.127 (perp=5.321, rec=0.063), tot_loss_proj:1.586 [t=0.27s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.126 (perp=5.321, rec=0.062), tot_loss_proj:1.578 [t=0.26s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
[1350/2000] tot_loss=1.132 (perp=5.321, rec=0.067), tot_loss_proj:1.580 [t=0.28s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.127 (perp=5.321, rec=0.062), tot_loss_proj:1.575 [t=0.25s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.125 (perp=5.321, rec=0.060), tot_loss_proj:1.572 [t=0.25s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
[1500/2000] tot_loss=1.142 (perp=5.321, rec=0.078), tot_loss_proj:1.573 [t=0.25s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.133 (perp=5.321, rec=0.069), tot_loss_proj:1.578 [t=0.26s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.129 (perp=5.321, rec=0.065), tot_loss_proj:1.575 [t=0.27s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
[1650/2000] tot_loss=1.128 (perp=5.321, rec=0.063), tot_loss_proj:1.573 [t=0.26s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.134 (perp=5.321, rec=0.070), tot_loss_proj:1.574 [t=0.29s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.121 (perp=5.321, rec=0.056), tot_loss_proj:1.570 [t=0.26s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
[1800/2000] tot_loss=1.135 (perp=5.321, rec=0.071), tot_loss_proj:1.577 [t=0.27s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.137 (perp=5.321, rec=0.073), tot_loss_proj:1.577 [t=0.26s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.128 (perp=5.321, rec=0.064), tot_loss_proj:1.574 [t=0.32s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
[1950/2000] tot_loss=1.129 (perp=5.321, rec=0.065), tot_loss_proj:1.571 [t=0.25s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.128 (perp=5.321, rec=0.063), tot_loss_proj:1.578 [t=0.27s]
prediction: ["[CLS] and there not a single jump - - - in your seat's moment [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there not a single jump - - - in your seat's moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 87.183 | p: 86.240 | r: 88.491
rouge2     | fm: 49.236 | p: 48.858 | r: 49.684
rougeL     | fm: 75.201 | p: 74.429 | r: 76.171
rougeLsum  | fm: 75.134 | p: 74.332 | r: 76.067
r1fm+r2fm = 136.419

input #71 time: 0:11:09 | total time: 13:02:29


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7788602113723755 for ['[CLS] faceistic devils education returned prison months voice bear remove her lumpur max sheen prepared [SEP]']
[Init] best rec loss: 0.7758705019950867 for ['[CLS] sank conor rule purpose reindeer steady hatred atmosphere finger rodriguez just resignationepttorium stephanie [SEP]']
[Init] best rec loss: 0.7722893357276917 for ['[CLS] alexandra owners issuesha circular came edit changed automatically hooddget filled soviet japanese bs [SEP]']
[Init] best rec loss: 0.7303167581558228 for ['[CLS] home blew pull calling kid a top oblast ground evil murder otherwise ut branch barbie [SEP]']
[Init] best rec loss: 0.7166073322296143 for ['[CLS] tate bargainª included tour emi studying relief wrong third stanley paralympics pat toward resigned [SEP]']
[Init] best rec loss: 0.7130635380744934 for ['[CLS]don pretty rated third boylife supply platform aside minus liberation mere earlyı [MASK] [SEP]']
[Init] best rec loss: 0.7113083600997925 for ['[CLS] ontario sharp represent annie steele joint lists tries lush thrown buck candidate fibers rivers armenian [SEP]']
[Init] best rec loss: 0.7093108296394348 for ['[CLS] registry pattern compared shelbywan dinnerwashocene meant [SEP] handledured white myk [SEP]']
[Init] best rec loss: 0.7072539329528809 for ['[CLS] clause matter profilemore factor both something mum workshop pre chateau grandpamie similarnail [SEP]']
[Init] best rec loss: 0.698897659778595 for ['[CLS]ential produced shelf anti representing mid proven connierich british generally consistedzer making jersey [SEP]']
[Init] best rec loss: 0.6931673884391785 for ['[CLS] bought regional warner task trainersbby wright plays continued‰ thatmeral digital whole [MASK] [SEP]']
[Init] best perm rec loss: 0.6910736560821533 for ['[CLS] whole regional warner continued bought plays trainersmeralbby wright digital that task [MASK]‰ [SEP]']
[Init] best perm rec loss: 0.6906472444534302 for ['[CLS]‰ trainers continued whole task regional wright plays warner [MASK] digitalbbymeral bought that [SEP]']
[Init] best perm rec loss: 0.6897785067558289 for ['[CLS] trainers continuedbby regional taskmeral wright bought‰ digital [MASK] whole plays warner that [SEP]']
[Init] best perm rec loss: 0.6874716281890869 for ['[CLS] digital continued plays regionalbby wright task [MASK] bought thatmeral warner‰ whole trainers [SEP]']
[Init] best perm rec loss: 0.6860046982765198 for ['[CLS] plays [MASK]‰ regionalbby continued thatmeral digital wright task trainers whole warner bought [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.745 (perp=12.228, rec=0.299), tot_loss_proj:3.289 [t=0.26s]
prediction: ['[CLS] demand guiltyts political fence sound nyu different tough is tough economics tough violence energy [SEP]']
[ 100/2000] tot_loss=2.433 (perp=11.178, rec=0.198), tot_loss_proj:2.970 [t=0.26s]
prediction: ['[CLS] demand violence balancing inspired time philosophy haser tough time tough time violence violence balancing [SEP]']
[ 150/2000] tot_loss=2.479 (perp=11.790, rec=0.122), tot_loss_proj:3.067 [t=0.25s]
prediction: ['[CLS] demand violence balancing inspired time philosophy haser tough has tough time violence violence balancing [SEP]']
[ 200/2000] tot_loss=2.080 (perp=9.887, rec=0.102), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] after a balancing inspired time philosophy itser tough has tough time violence violence with [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.919 (perp=9.078, rec=0.104), tot_loss_proj:2.374 [t=0.29s]
prediction: ['[CLS] after a balancing tough time philosophy itser inspired has a time violence violence with [SEP]']
[ 300/2000] tot_loss=2.131 (perp=10.245, rec=0.081), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS] demand a balancing tough time philosophy itser inspired has a time violence violence with [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.031 (perp=9.797, rec=0.071), tot_loss_proj:2.573 [t=0.26s]
prediction: ['[CLS] demand a balancing tough time philosophy itser inspired has a time violence with violence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.875 (perp=9.028, rec=0.070), tot_loss_proj:2.381 [t=0.28s]
prediction: ['[CLS] demand a balancing tougher time philosophy its inspired has a time violence with violence [SEP]']
[ 450/2000] tot_loss=1.977 (perp=9.560, rec=0.065), tot_loss_proj:2.604 [t=0.30s]
prediction: ['[CLS] demandfk balancing tougher time philosophy its inspired has a time violence with - [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.845 (perp=8.893, rec=0.067), tot_loss_proj:2.489 [t=0.27s]
prediction: ['[CLS] demandfk balancing tougher time philosophy its inspired has a time with violence - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.696 (perp=8.122, rec=0.071), tot_loss_proj:2.355 [t=0.26s]
prediction: ['[CLS] demandfk balancing tougher time has its inspired philosophy a time with violence - [SEP]']
[ 600/2000] tot_loss=1.699 (perp=8.122, rec=0.074), tot_loss_proj:2.355 [t=0.26s]
prediction: ['[CLS] demandfk balancing tougher time has its inspired philosophy a time with violence - [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.691 (perp=8.057, rec=0.079), tot_loss_proj:2.420 [t=0.26s]
prediction: ['[CLS] demandfk balancing tougher time has inspired its philosophy a time with violence - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=8.057, rec=0.067), tot_loss_proj:2.414 [t=0.27s]
prediction: ['[CLS] demandfk balancing tougher time has inspired its philosophy a time with violence - [SEP]']
[ 750/2000] tot_loss=1.675 (perp=8.057, rec=0.063), tot_loss_proj:2.416 [t=0.26s]
prediction: ['[CLS] demandfk balancing tougher time has inspired its philosophy a time with violence - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.683 (perp=8.057, rec=0.072), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] demandfk balancing tougher time has inspired its philosophy a time with violence - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.740 (perp=8.332, rec=0.073), tot_loss_proj:2.435 [t=0.25s]
prediction: ['[CLS] (fk balancing tougher time has inspired its philosophy a time with violence - [SEP]']
[ 900/2000] tot_loss=1.955 (perp=9.410, rec=0.073), tot_loss_proj:2.594 [t=0.25s]
prediction: ['[CLS] (fk balancing tougher time has inspired its philosophy aa with violence - [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.920 (perp=9.265, rec=0.067), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] (fk time balancing tougher time has inspired its philosophy a with violence - [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.738 (perp=8.275, rec=0.084), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] (fk time balancing a tougher time has inspired its philosophy with violence - [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.275, rec=0.068), tot_loss_proj:2.298 [t=0.26s]
prediction: ['[CLS] (fk time balancing a tougher time has inspired its philosophy with violence - [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.591 (perp=7.575, rec=0.076), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] time balancing a tougher time (fk has inspired its philosophy with violence - [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.517 (perp=7.148, rec=0.087), tot_loss_proj:2.241 [t=0.26s]
prediction: ['[CLS] timefk has inspired balancing a tougher time ( its philosophy with violence - [SEP]']
[1200/2000] tot_loss=1.500 (perp=7.148, rec=0.070), tot_loss_proj:2.245 [t=0.25s]
prediction: ['[CLS] timefk has inspired balancing a tougher time ( its philosophy with violence - [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.442 (perp=6.797, rec=0.083), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] timefk has inspired a tougher time ( its philosophy balancing with violence - [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.387 (perp=6.542, rec=0.078), tot_loss_proj:1.855 [t=0.27s]
prediction: ['[CLS] timefk has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
[1350/2000] tot_loss=1.370 (perp=6.542, rec=0.062), tot_loss_proj:1.852 [t=0.27s]
prediction: ['[CLS] timefk has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.380 (perp=6.542, rec=0.071), tot_loss_proj:1.858 [t=0.26s]
prediction: ['[CLS] timefk has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.373 (perp=6.542, rec=0.064), tot_loss_proj:1.853 [t=0.26s]
prediction: ['[CLS] timefk has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
[1500/2000] tot_loss=1.375 (perp=6.542, rec=0.066), tot_loss_proj:1.853 [t=0.26s]
prediction: ['[CLS] timefk has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.465 (perp=6.974, rec=0.071), tot_loss_proj:1.935 [t=0.27s]
prediction: ['[CLS]afk has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.378 (perp=6.543, rec=0.069), tot_loss_proj:1.849 [t=0.26s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
[1650/2000] tot_loss=1.382 (perp=6.543, rec=0.073), tot_loss_proj:1.848 [t=0.27s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.396 (perp=6.543, rec=0.087), tot_loss_proj:1.851 [t=0.26s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.372 (perp=6.543, rec=0.063), tot_loss_proj:1.853 [t=0.25s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.543, rec=0.075), tot_loss_proj:1.852 [t=0.28s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.379 (perp=6.543, rec=0.071), tot_loss_proj:1.858 [t=0.26s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.378 (perp=6.543, rec=0.069), tot_loss_proj:1.852 [t=0.25s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
[1950/2000] tot_loss=1.371 (perp=6.543, rec=0.062), tot_loss_proj:1.855 [t=0.26s]
prediction: ['[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.342 (perp=6.314, rec=0.080), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] (fka has inspired a tougher time balancing its philosophy with violence - [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]fka has inspired a tougher time ( balancing its philosophy with violence - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 125.641

[Aggregate metrics]:
rouge1     | fm: 87.336 | p: 86.353 | r: 88.514
rouge2     | fm: 49.130 | p: 48.724 | r: 49.585
rougeL     | fm: 75.170 | p: 74.375 | r: 76.146
rougeLsum  | fm: 75.027 | p: 74.209 | r: 75.990
r1fm+r2fm = 136.466

input #72 time: 0:11:00 | total time: 13:13:29


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9707922339439392 for ['[CLS] tess which [SEP]']
[Init] best rec loss: 0.9399644732475281 for ['[CLS]sitor meant [SEP]']
[Init] best rec loss: 0.9141361117362976 for ['[CLS]don £ [SEP]']
[Init] best rec loss: 0.9055935740470886 for ['[CLS] rift past [SEP]']
[Init] best rec loss: 0.9055451154708862 for ['[CLS] solvent naga [SEP]']
[Init] best rec loss: 0.8469099402427673 for ['[CLS] chefors [SEP]']
[Init] best perm rec loss: 0.8415480852127075 for ['[CLS]ors chef [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.051 (perp=9.724, rec=0.107), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.012 (perp=9.724, rec=0.068), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.000 (perp=9.724, rec=0.055), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=1.991 (perp=9.724, rec=0.046), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.997 (perp=9.724, rec=0.052), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.000 (perp=9.724, rec=0.055), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.995 (perp=9.724, rec=0.050), tot_loss_proj:1.996 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.004 (perp=9.724, rec=0.059), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.002 (perp=9.724, rec=0.057), tot_loss_proj:1.996 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.002 (perp=9.724, rec=0.057), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.995 (perp=9.724, rec=0.050), tot_loss_proj:2.012 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.011 (perp=9.724, rec=0.067), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.009 (perp=9.724, rec=0.064), tot_loss_proj:2.006 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.995 (perp=9.724, rec=0.050), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.013 (perp=9.724, rec=0.068), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.009 (perp=9.724, rec=0.064), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.003 (perp=9.724, rec=0.058), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.004 (perp=9.724, rec=0.059), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.005 (perp=9.724, rec=0.060), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.008 (perp=9.724, rec=0.063), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.020 (perp=9.724, rec=0.075), tot_loss_proj:2.014 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.018 (perp=9.724, rec=0.073), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.001 (perp=9.724, rec=0.056), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.006 (perp=9.724, rec=0.061), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.010 (perp=9.724, rec=0.066), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.990 (perp=9.724, rec=0.045), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.016 (perp=9.724, rec=0.071), tot_loss_proj:1.998 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.010 (perp=9.724, rec=0.065), tot_loss_proj:2.006 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.009 (perp=9.724, rec=0.064), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.006 (perp=9.724, rec=0.061), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.002 (perp=9.724, rec=0.058), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.005 (perp=9.724, rec=0.060), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.003 (perp=9.724, rec=0.059), tot_loss_proj:1.997 [t=0.33s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.010 (perp=9.724, rec=0.065), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.009 (perp=9.724, rec=0.064), tot_loss_proj:2.024 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.006 (perp=9.724, rec=0.061), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.996 (perp=9.724, rec=0.051), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.994 (perp=9.724, rec=0.049), tot_loss_proj:2.022 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=1.998 (perp=9.724, rec=0.053), tot_loss_proj:2.001 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.012 (perp=9.724, rec=0.068), tot_loss_proj:1.998 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.448 | p: 86.531 | r: 88.656
rouge2     | fm: 49.597 | p: 49.154 | r: 50.072
rougeL     | fm: 75.491 | p: 74.739 | r: 76.375
rougeLsum  | fm: 75.322 | p: 74.495 | r: 76.312
r1fm+r2fm = 137.045

input #73 time: 0:10:40 | total time: 13:24:09


Running input #74 of 100.
reference: 
========================
share 
========================
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.7006826400756836 for ['[CLS] seemed [SEP]']
[Init] best rec loss: 0.6703411936759949 for ['[CLS]aves [SEP]']
[Init] best rec loss: 0.6602270603179932 for ['[CLS]graphic [SEP]']
[Init] best rec loss: 0.6590353846549988 for ['[CLS] impress [SEP]']
[Init] best rec loss: 0.6326567530632019 for ['[CLS] longitude [SEP]']
[Init] best rec loss: 0.5763640403747559 for ['[CLS] pain [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.761 (perp=8.178, rec=0.126), tot_loss_proj:1.810 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.695 (perp=8.178, rec=0.059), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.705 (perp=8.178, rec=0.070), tot_loss_proj:1.739 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.695 (perp=8.178, rec=0.059), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.684 (perp=8.178, rec=0.049), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.698 (perp=8.178, rec=0.062), tot_loss_proj:1.723 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.703 (perp=8.178, rec=0.067), tot_loss_proj:1.714 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.692 (perp=8.178, rec=0.056), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.697 (perp=8.178, rec=0.062), tot_loss_proj:1.721 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.690 (perp=8.178, rec=0.055), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.692 (perp=8.178, rec=0.057), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.697 (perp=8.178, rec=0.061), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.684 (perp=8.178, rec=0.049), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.687 (perp=8.178, rec=0.052), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.691 (perp=8.178, rec=0.055), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.693 (perp=8.178, rec=0.057), tot_loss_proj:1.722 [t=0.29s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.700 (perp=8.178, rec=0.065), tot_loss_proj:1.720 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.703 (perp=8.178, rec=0.067), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.699 (perp=8.178, rec=0.063), tot_loss_proj:1.709 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.704 (perp=8.178, rec=0.069), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.697 (perp=8.178, rec=0.061), tot_loss_proj:1.716 [t=0.31s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.695 (perp=8.178, rec=0.060), tot_loss_proj:1.721 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.693 (perp=8.178, rec=0.057), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.694 (perp=8.178, rec=0.058), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.696 (perp=8.178, rec=0.061), tot_loss_proj:1.731 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=8.178, rec=0.044), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.690 (perp=8.178, rec=0.055), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=8.178, rec=0.048), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.695 (perp=8.178, rec=0.060), tot_loss_proj:1.727 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.684 (perp=8.178, rec=0.048), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.690 (perp=8.178, rec=0.055), tot_loss_proj:1.720 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.702 (perp=8.178, rec=0.066), tot_loss_proj:1.718 [t=0.29s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.678 (perp=8.178, rec=0.043), tot_loss_proj:1.728 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=8.178, rec=0.055), tot_loss_proj:1.720 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.699 (perp=8.178, rec=0.064), tot_loss_proj:1.719 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.681 (perp=8.178, rec=0.045), tot_loss_proj:1.721 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.686 (perp=8.178, rec=0.050), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.701 (perp=8.178, rec=0.066), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.691 (perp=8.178, rec=0.056), tot_loss_proj:1.724 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.692 (perp=8.178, rec=0.056), tot_loss_proj:1.731 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.635 | p: 86.657 | r: 88.826
rouge2     | fm: 50.258 | p: 49.902 | r: 50.652
rougeL     | fm: 75.816 | p: 75.104 | r: 76.691
rougeLsum  | fm: 75.691 | p: 74.930 | r: 76.643
r1fm+r2fm = 137.893

input #74 time: 0:10:45 | total time: 13:34:55


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9547334313392639 for ['[CLS] rev monomir myself liberated check times bottom pinyin arad grayson ginger melody factory reflectionrinojust boise [SEP]']
[Init] best rec loss: 0.8343164920806885 for ['[CLS] timer gardens statement faithful airlift romantic will historians better pablo horses history originalburo consensus construction rugbytore sell [SEP]']
[Init] best rec loss: 0.8334430456161499 for ['[CLS]grad za jen or button tibetan cover risky iso bowing show constant wonder exception look god open macintosh transplant [SEP]']
[Init] best rec loss: 0.8319669961929321 for ['[CLS] dead pulls central gum subsequent clint condom university energyevic miss speech book clinic spread defense publicly meaning directly [SEP]']
[Init] best perm rec loss: 0.8318098783493042 for ['[CLS] subsequent gum directly meaning clinic miss publicly condom university speech book pullsevic central spread dead defense clint energy [SEP]']
[Init] best perm rec loss: 0.8310959935188293 for ['[CLS] publicly condom directly defense central subsequent university energy pulls speechevic spread book miss clinic clint gum meaning dead [SEP]']
[Init] best perm rec loss: 0.8291836977005005 for ['[CLS] dead condom directlyevic meaning clinic pulls clint gum subsequent energy central university speech publicly defense book miss spread [SEP]']
[Init] best perm rec loss: 0.829033613204956 for ['[CLS] gum subsequent book energy pulls condom speech meaning spread directly centralevic miss clint defense university clinic publicly dead [SEP]']
[Init] best perm rec loss: 0.8288514018058777 for ['[CLS] energy gum central clint defenseevic speech subsequent book meaning publicly pulls university condom spread clinic dead directly miss [SEP]']
[Init] best perm rec loss: 0.8262313008308411 for ['[CLS] gum defense clint speech dead pulls directly miss clinicevic subsequent energy meaning university condom central publicly book spread [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.454 (perp=10.909, rec=0.272), tot_loss_proj:3.030 [t=0.27s]
prediction: ['[CLS] is achievement villa easily this of is ignore rarely not decided psychological nothinged. easily reign forgotten easily [SEP]']
[ 100/2000] tot_loss=2.150 (perp=10.016, rec=0.147), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] like instabilityition easily this excursion is erasegration not instability instability easily recorded. or is forgotten forgotten [SEP]']
[ 150/2000] tot_loss=2.416 (perp=11.528, rec=0.110), tot_loss_proj:3.180 [t=0.27s]
prediction: ['[CLS] like instabilitycola easily this excursion intocolaenter not mental instability easily mental. or is forgotten dismissed [SEP]']
[ 200/2000] tot_loss=2.448 (perp=11.722, rec=0.104), tot_loss_proj:3.200 [t=0.27s]
prediction: ['[CLS] epic instabilitycola easily this excursion intocolaenter not mental instability easily mental. or is forgotten dismissed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.355 (perp=11.077, rec=0.139), tot_loss_proj:2.981 [t=0.27s]
prediction: ['[CLS] epicenter derives easily this excursion intocola epic not mental instability easily process. or is forgotten dismissed [SEP]']
[ 300/2000] tot_loss=2.353 (perp=11.310, rec=0.091), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS]edenter epic easily this excursion intocolaenter not mental instability dismissed process. or is forgotten dismissed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.223 (perp=10.648, rec=0.094), tot_loss_proj:3.030 [t=0.26s]
prediction: ['[CLS]ing epicenter easily this excursion intocolaenter not mental instability easily process. or is forgotten dismissed [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.075 (perp=9.901, rec=0.095), tot_loss_proj:2.855 [t=0.28s]
prediction: ['[CLS]ing epicenter easily this excursion intocolaenter not mental instability easily process or is forgotten dismissed. [SEP]']
[ 450/2000] tot_loss=2.054 (perp=9.875, rec=0.079), tot_loss_proj:2.846 [t=0.27s]
prediction: ['[CLS]ting epicenter easily this excursion intocolaenter not mental instability easily process or is forgotten dismissed. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.986 (perp=9.512, rec=0.084), tot_loss_proj:2.713 [t=0.25s]
prediction: ['[CLS]ting epicenter easily this excursion intocolaenter not mental instability easily process is forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.076 (perp=9.795, rec=0.117), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS]ting easily perenter this excursion intocolaenter not mental instability easily process is forgotten or dismissed. [SEP]']
[ 600/2000] tot_loss=2.133 (perp=10.191, rec=0.095), tot_loss_proj:2.923 [t=0.26s]
prediction: ['[CLS]ting easily perenter this excursion intocolaenter not mental instability easily of is forgotten or dismissed. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.982 (perp=9.434, rec=0.095), tot_loss_proj:2.731 [t=0.25s]
prediction: ['[CLS]ting easily of perenter this excursion intocolaenter not mental instability easily is forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.871 (perp=8.890, rec=0.093), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS]ting easily of perenter this excursion intocolaenter not mental instability is easily forgotten or dismissed. [SEP]']
[ 750/2000] tot_loss=1.871 (perp=8.890, rec=0.093), tot_loss_proj:2.445 [t=0.25s]
prediction: ['[CLS]ting easily of perenter this excursion intocolaenter not mental instability is easily forgotten or dismissed. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.855 (perp=8.890, rec=0.077), tot_loss_proj:2.450 [t=0.26s]
prediction: ['[CLS]ting easily of perenter this excursion intocolaenter not mental instability is easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.786 (perp=8.569, rec=0.072), tot_loss_proj:2.388 [t=0.25s]
prediction: ['[CLS]ting easily of percola this excursion intoenterenter not mental instability is easily forgotten or dismissed. [SEP]']
[ 900/2000] tot_loss=1.795 (perp=8.569, rec=0.081), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS]ting easily of percola this excursion intoenterenter not mental instability is easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.759 (perp=8.439, rec=0.072), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS]ting easily of percola this excursion intoenterenter easily mental instability is not forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.764 (perp=8.439, rec=0.076), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS]ting easily of percola this excursion intoenterenter easily mental instability is not forgotten or dismissed. [SEP]']
[1050/2000] tot_loss=1.763 (perp=8.439, rec=0.075), tot_loss_proj:2.136 [t=0.27s]
prediction: ['[CLS]ting easily of percola this excursion intoenterenter easily mental instability is not forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.614 (perp=7.727, rec=0.069), tot_loss_proj:1.924 [t=0.28s]
prediction: ['[CLS] this easily of percolating excursion intoenterenter easily mental instability is not forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.564 (perp=7.460, rec=0.071), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] this easily easily percolating excursion intoenterenter of mental instability is not forgotten or dismissed. [SEP]']
[1200/2000] tot_loss=1.562 (perp=7.460, rec=0.070), tot_loss_proj:1.793 [t=0.26s]
prediction: ['[CLS] this easily easily percolating excursion intoenterenter of mental instability is not forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.560 (perp=7.421, rec=0.075), tot_loss_proj:1.886 [t=0.26s]
prediction: ['[CLS] this easily excursion easily percolating intoenter epic of mental instability is not forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.514 (perp=7.245, rec=0.065), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS] this easily excursion easily percolating intoenter of epic mental instability is not forgotten or dismissed. [SEP]']
[1350/2000] tot_loss=1.521 (perp=7.245, rec=0.072), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] this easily excursion easily percolating intoenter of epic mental instability is not forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.363 (perp=6.470, rec=0.069), tot_loss_proj:1.524 [t=0.25s]
prediction: ['[CLS] this excursion easily percolating intoenter of epic mental instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.249 (perp=5.893, rec=0.070), tot_loss_proj:1.445 [t=0.27s]
prediction: ['[CLS] this excursion easily percolating into epicenter of mental instability is not easily forgotten or dismissed. [SEP]']
[1500/2000] tot_loss=1.240 (perp=5.893, rec=0.061), tot_loss_proj:1.457 [t=0.25s]
prediction: ['[CLS] this excursion easily percolating into epicenter of mental instability is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.232 (perp=5.802, rec=0.072), tot_loss_proj:1.480 [t=0.26s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability easily is not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.150 (perp=5.354, rec=0.079), tot_loss_proj:1.322 [t=0.27s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
[1650/2000] tot_loss=1.141 (perp=5.354, rec=0.071), tot_loss_proj:1.326 [t=0.25s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.151 (perp=5.354, rec=0.080), tot_loss_proj:1.328 [t=0.26s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.135 (perp=5.354, rec=0.064), tot_loss_proj:1.334 [t=0.25s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
[1800/2000] tot_loss=1.149 (perp=5.354, rec=0.078), tot_loss_proj:1.330 [t=0.26s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.143 (perp=5.354, rec=0.072), tot_loss_proj:1.330 [t=0.27s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.147 (perp=5.354, rec=0.076), tot_loss_proj:1.332 [t=0.26s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
[1950/2000] tot_loss=1.131 (perp=5.354, rec=0.060), tot_loss_proj:1.331 [t=0.25s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.139 (perp=5.354, rec=0.068), tot_loss_proj:1.332 [t=0.26s]
prediction: ['[CLS] this excursion percolating into epicenter of mental instability is not easily forgotten or easily dismissed. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion percolating into epicenter of mental instability easily is not easily forgotten or dismissed. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 76.471 | p: 76.471 | r: 76.471
rougeLsum  | fm: 76.471 | p: 76.471 | r: 76.471
r1fm+r2fm = 131.618

[Aggregate metrics]:
rouge1     | fm: 87.668 | p: 86.644 | r: 88.821
rouge2     | fm: 50.068 | p: 49.698 | r: 50.571
rougeL     | fm: 75.716 | p: 74.974 | r: 76.693
rougeLsum  | fm: 75.686 | p: 74.913 | r: 76.598
r1fm+r2fm = 137.737

input #75 time: 0:10:56 | total time: 13:45:51


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9228625893592834 for ['[CLS] key listening beat success anymore weight certified plant revival ami ju steel vampire performance [SEP]']
[Init] best rec loss: 0.8941590785980225 for ['[CLS] motorcycle address doublet cuts bangkok scotia attitudehootcloth x are adoptive commerce [SEP]']
[Init] best rec loss: 0.8913969993591309 for ['[CLS] placed paperspiececraft skatenea ɡlent cam ou symbols blu which see [SEP]']
[Init] best rec loss: 0.8775109648704529 for ['[CLS] brewery authority propositionail patient union break because calling melting even moroccan correctlytment [SEP]']
[Init] best rec loss: 0.8610309362411499 for ['[CLS]verse steele jlinkła aroundtre cementии training batman is f legal [SEP]']
[Init] best rec loss: 0.8599728941917419 for ['[CLS] known norman cu settlement agent term ways grassland partial substitute leads per tenor since [SEP]']
[Init] best rec loss: 0.8477840423583984 for ['[CLS] just play wind my effective tray both literatureotype after kari clubhouse millions consonants [SEP]']
[Init] best rec loss: 0.8463078737258911 for ['[CLS] brains demons daughterscellular driver because [CLS] wheel rover traffic took inflationduced ami [SEP]']
[Init] best perm rec loss: 0.845169186592102 for ['[CLS] [CLS] brains drivercellular ami daughters demons inflation wheelduced because took traffic rover [SEP]']
[Init] best perm rec loss: 0.8449713587760925 for ['[CLS] because driver demons wheel trafficducedcellular daughters ami brains took rover inflation [CLS] [SEP]']
[Init] best perm rec loss: 0.8446118235588074 for ['[CLS] because [CLS] rover traffic inflationcellular demons tookduced ami daughters wheel driver brains [SEP]']
[Init] best perm rec loss: 0.8437819480895996 for ['[CLS] brains wheelcellular inflation because demons took daughters ami traffic driver roverduced [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.741 (perp=12.002, rec=0.341), tot_loss_proj:3.150 [t=0.25s]
prediction: ['[CLS] not freight taipei stopped challenge challenge % stoppediss lost challenging lb age. [SEP]']
[ 100/2000] tot_loss=2.396 (perp=11.048, rec=0.187), tot_loss_proj:2.939 [t=0.25s]
prediction: ['[CLS] has. unless stopped its challenging challenging stopped has stopped challenging himself age has [SEP]']
[ 150/2000] tot_loss=2.305 (perp=10.868, rec=0.132), tot_loss_proj:2.703 [t=0.27s]
prediction: ['[CLS] they. as stopped has challenging arthur stopped has stopped challenging himself 66 has [SEP]']
[ 200/2000] tot_loss=2.254 (perp=10.708, rec=0.112), tot_loss_proj:2.749 [t=0.25s]
prediction: ['[CLS] if. as stopped at challenging allen stopped has stopped challenging himself 66 has [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.067 (perp=9.741, rec=0.118), tot_loss_proj:2.864 [t=0.25s]
prediction: ['[CLS] challenging. if stopped at if allen stopped has stopped challenging himself 66 has [SEP]']
[ 300/2000] tot_loss=2.061 (perp=9.825, rec=0.096), tot_loss_proj:2.872 [t=0.25s]
prediction: ['[CLS] challenging. if stopped at if allen stopped has at challenging himself 66 has [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.874 (perp=8.931, rec=0.088), tot_loss_proj:2.652 [t=0.26s]
prediction: ['[CLS] challenging. if stopped at if allen has stopped at challenging himself 66 has [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.856 (perp=8.809, rec=0.094), tot_loss_proj:2.497 [t=0.25s]
prediction: ['[CLS] is as stopped at challenging if allen has stopped at challenging himself 66 has [SEP]']
[ 450/2000] tot_loss=1.943 (perp=9.316, rec=0.080), tot_loss_proj:2.565 [t=0.24s]
prediction: ['[CLS]. as stopped, challenging, allen has stopped at challenging himself 66 has [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.795 (perp=8.539, rec=0.087), tot_loss_proj:2.412 [t=0.25s]
prediction: ['[CLS]. as challenging, stopped, allen has stopped at challenging himself 66 has [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.990 (perp=9.532, rec=0.084), tot_loss_proj:2.744 [t=0.25s]
prediction: ['[CLS] s as challenging, stopped, allen s stopped at challenging himself has 66 [SEP]']
[ 600/2000] tot_loss=1.994 (perp=9.532, rec=0.088), tot_loss_proj:2.744 [t=0.25s]
prediction: ['[CLS] s as challenging, stopped, allen s stopped at challenging himself has 66 [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.826 (perp=8.740, rec=0.078), tot_loss_proj:2.502 [t=0.26s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at challenging himself s 66 [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.735 (perp=8.277, rec=0.080), tot_loss_proj:2.452 [t=0.26s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at challenging 66 s himself [SEP]']
[ 750/2000] tot_loss=1.730 (perp=8.277, rec=0.074), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at challenging 66 s himself [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.741 (perp=8.284, rec=0.084), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] as s challenging, stopped, allen has stopped at challenging 66. himself [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.831 (perp=8.723, rec=0.087), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] as s challenging, stopped, allen has stopped at challenging 66 himself s [SEP]']
[ 900/2000] tot_loss=1.936 (perp=9.290, rec=0.078), tot_loss_proj:2.630 [t=0.27s]
prediction: ["[CLS] as s challenging, stopped, allen has stopped at challenging 66 himself'[SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.763 (perp=8.420, rec=0.079), tot_loss_proj:2.461 [t=0.25s]
prediction: ['[CLS] as s challenging, stopped, allen has stopped at challenging s himself 66 [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.729 (perp=8.250, rec=0.080), tot_loss_proj:2.429 [t=0.24s]
prediction: ["[CLS] s as challenging, stopped, allen has stopped at challenging'himself 66 [SEP]"]
[1050/2000] tot_loss=1.731 (perp=8.250, rec=0.081), tot_loss_proj:2.428 [t=0.25s]
prediction: ["[CLS] s as challenging, stopped, allen has stopped at challenging'himself 66 [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.587 (perp=7.504, rec=0.086), tot_loss_proj:2.355 [t=0.26s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
[1150/2000] tot_loss=1.581 (perp=7.504, rec=0.080), tot_loss_proj:2.347 [t=0.27s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
[1200/2000] tot_loss=1.574 (perp=7.504, rec=0.074), tot_loss_proj:2.348 [t=0.26s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
[1250/2000] tot_loss=1.573 (perp=7.504, rec=0.073), tot_loss_proj:2.349 [t=0.27s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
[1300/2000] tot_loss=1.573 (perp=7.504, rec=0.072), tot_loss_proj:2.347 [t=0.25s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
[1350/2000] tot_loss=1.582 (perp=7.504, rec=0.081), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=7.504, rec=0.070), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] s as challenging, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.603 (perp=7.629, rec=0.077), tot_loss_proj:2.323 [t=0.27s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging. 66 [SEP]']
[1500/2000] tot_loss=1.608 (perp=7.629, rec=0.083), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
[1550/2000] tot_loss=1.609 (perp=7.629, rec=0.083), tot_loss_proj:2.323 [t=0.25s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
[1600/2000] tot_loss=1.594 (perp=7.629, rec=0.068), tot_loss_proj:2.320 [t=0.25s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging. 66 [SEP]']
[1650/2000] tot_loss=1.595 (perp=7.629, rec=0.069), tot_loss_proj:2.326 [t=0.25s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging. 66 [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.591 (perp=7.560, rec=0.079), tot_loss_proj:2.295 [t=0.29s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging 66. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.585 (perp=7.560, rec=0.073), tot_loss_proj:2.299 [t=0.28s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging 66. [SEP]']
[1800/2000] tot_loss=1.582 (perp=7.560, rec=0.070), tot_loss_proj:2.299 [t=0.29s]
prediction: ['[CLS] s ( as, stopped, allen has stopped at himself challenging 66. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.541 (perp=7.243, rec=0.093), tot_loss_proj:2.257 [t=0.29s]
prediction: ['[CLS] s ( as stopped, allen has stopped at himself, challenging 66. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.530 (perp=7.243, rec=0.082), tot_loss_proj:2.259 [t=0.28s]
prediction: ['[CLS] s ( as stopped, allen has stopped at himself, challenging 66. [SEP]']
[1950/2000] tot_loss=1.525 (perp=7.243, rec=0.077), tot_loss_proj:2.250 [t=0.34s]
prediction: ['[CLS] s ( as stopped, allen has stopped at himself, challenging 66. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.472 (perp=6.908, rec=0.091), tot_loss_proj:2.214 [t=0.24s]
prediction: ['[CLS] s ( as stopped, allen has stopped at 66, challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s ( as, stopped, allen has stopped at himself challenging. 66 [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 118.939

[Aggregate metrics]:
rouge1     | fm: 87.741 | p: 86.790 | r: 88.893
rouge2     | fm: 49.976 | p: 49.628 | r: 50.439
rougeL     | fm: 75.716 | p: 74.985 | r: 76.563
rougeLsum  | fm: 75.535 | p: 74.808 | r: 76.510
r1fm+r2fm = 137.717

input #76 time: 0:10:51 | total time: 13:56:43


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.8502398729324341 for ['[CLS] bank reason gonna differentrne rules stan tabloid jail vr ad pure pavilion waves irving [SEP]']
[Init] best rec loss: 0.786071240901947 for ['[CLS] bones nickel works charter member station stretchedausen mature downstairs cubic electronics campus includingpiration [SEP]']
[Init] best rec loss: 0.7834004759788513 for ['[CLS]tries history emmett harris counsel whistle which sentenceoint brown hadley republished continuing pioneer quick [SEP]']
[Init] best rec loss: 0.7635130286216736 for ['[CLS] vietnam likeness had integral highlight shovel healthy flight enchanted lot wore marvel felt very gold [SEP]']
[Init] best rec loss: 0.7523476481437683 for ['[CLS] choice urgentgis nowhere straw suffered 1945 tudor secmun source hidden ravendic orderly [SEP]']
[Init] best rec loss: 0.7453379034996033 for ['[CLS] mitchell mine ie intercollegiate expedition everything era system defly seated you carving glacier climb [SEP]']
[Init] best rec loss: 0.7404927611351013 for ['[CLS] micro architecture trent mixed soldier shangatalcide versaeiaba seem thosein closet [SEP]']
[Init] best perm rec loss: 0.7397968769073486 for ['[CLS] mixed thosecidein closet trent architecture microataleia soldier seem shangba versa [SEP]']
[Init] best perm rec loss: 0.738341748714447 for ['[CLS] seembaeia mixedcide micro soldier closet versa shang trent architecture thoseatalin [SEP]']
[Init] best perm rec loss: 0.7379248142242432 for ['[CLS] those shangatalcide microin seem trenteia mixed versa closetba soldier architecture [SEP]']
[Init] best perm rec loss: 0.7355939149856567 for ['[CLS] trent soldier microeia shangba architectureatal versacide seemin those closet mixed [SEP]']
[Init] best perm rec loss: 0.7344077825546265 for ['[CLS] soldier microcide shangbaeia mixed seem closetin those trentatal versa architecture [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.369 (perp=10.637, rec=0.241), tot_loss_proj:2.754 [t=0.26s]
prediction: ['[CLS] realized far [SEP]ows, promise through result beyond realm believe so realm above the [SEP]']
[ 100/2000] tot_loss=2.215 (perp=10.183, rec=0.179), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] so its [SEP]ows its promisears believe beyond realm believe so realm above the [SEP]']
[ 150/2000] tot_loss=2.363 (perp=11.050, rec=0.153), tot_loss_proj:2.855 [t=0.26s]
prediction: ['[CLS] so its [SEP]ows its promisearsars beyond realm believe believe promise above the [SEP]']
[ 200/2000] tot_loss=2.259 (perp=10.641, rec=0.130), tot_loss_proj:2.720 [t=0.27s]
prediction: ['[CLS] so is isows its promisears believe life realm believe believe promise above the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.129 (perp=10.080, rec=0.113), tot_loss_proj:2.618 [t=0.25s]
prediction: ['[CLS] so is believeaq its promisears believe life realm believe is that above the [SEP]']
[ 300/2000] tot_loss=2.158 (perp=10.307, rec=0.097), tot_loss_proj:2.671 [t=0.25s]
prediction: ['[CLS] so is believeaq its promisears believe life realm believe of that above the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.972 (perp=9.402, rec=0.091), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] so is make ku its promisears believe life realm believe above that of the [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.034 (perp=9.668, rec=0.100), tot_loss_proj:2.654 [t=0.25s]
prediction: ['[CLS] so is believe ku believe its promisears believe life realm above that - the [SEP]']
[ 450/2000] tot_loss=1.785 (perp=8.457, rec=0.094), tot_loss_proj:2.269 [t=0.27s]
prediction: ['[CLS] so is believe of make its promisears believe life realm above that - the [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.552 (perp=7.296, rec=0.092), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS] so is make believe of its promisears of life realm above that - the [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.435 (perp=6.724, rec=0.090), tot_loss_proj:1.823 [t=0.27s]
prediction: ['[CLS] is make believe of its promise soars of life realm above that - the [SEP]']
[ 600/2000] tot_loss=1.626 (perp=7.765, rec=0.072), tot_loss_proj:2.032 [t=0.25s]
prediction: ['[CLS] is make believe realm its promise soars of life realm above that - the [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.531 (perp=7.229, rec=0.085), tot_loss_proj:1.978 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life realm realm above that - the [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.474 (perp=6.906, rec=0.093), tot_loss_proj:1.848 [t=0.28s]
prediction: ['[CLS] is make believe its promise soars of life of above that - the realm [SEP]']
[ 750/2000] tot_loss=1.455 (perp=6.850, rec=0.085), tot_loss_proj:1.862 [t=0.25s]
prediction: ['[CLS] is make believe its promise soars of life realm above that - the realm [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.430 (perp=6.739, rec=0.082), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] is make believe its promise soars of life realm above - the realm that [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.367 (perp=6.459, rec=0.075), tot_loss_proj:1.751 [t=0.25s]
prediction: ['[CLS] is make believe its promise soars of life above realm - the realm that [SEP]']
[ 900/2000] tot_loss=1.367 (perp=6.459, rec=0.075), tot_loss_proj:1.750 [t=0.28s]
prediction: ['[CLS] is make believe its promise soars of life above realm - the realm that [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.370 (perp=6.459, rec=0.078), tot_loss_proj:1.749 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above realm - the realm that [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.377 (perp=6.430, rec=0.091), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1050/2000] tot_loss=1.367 (perp=6.430, rec=0.081), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.379 (perp=6.430, rec=0.093), tot_loss_proj:1.692 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.364 (perp=6.430, rec=0.078), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1200/2000] tot_loss=1.352 (perp=6.430, rec=0.066), tot_loss_proj:1.697 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.367 (perp=6.430, rec=0.081), tot_loss_proj:1.695 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1300/2000] tot_loss=1.359 (perp=6.430, rec=0.073), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1350/2000] tot_loss=1.357 (perp=6.430, rec=0.071), tot_loss_proj:1.689 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.371 (perp=6.430, rec=0.085), tot_loss_proj:1.686 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.367 (perp=6.430, rec=0.081), tot_loss_proj:1.685 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1500/2000] tot_loss=1.355 (perp=6.430, rec=0.069), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.370 (perp=6.430, rec=0.084), tot_loss_proj:1.691 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1600/2000] tot_loss=1.358 (perp=6.430, rec=0.072), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1650/2000] tot_loss=1.371 (perp=6.430, rec=0.084), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.366 (perp=6.430, rec=0.080), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1750/2000] tot_loss=1.362 (perp=6.430, rec=0.076), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1800/2000] tot_loss=1.364 (perp=6.430, rec=0.078), tot_loss_proj:1.684 [t=0.27s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1850/2000] tot_loss=1.352 (perp=6.430, rec=0.066), tot_loss_proj:1.689 [t=0.29s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[1900/2000] tot_loss=1.349 (perp=6.430, rec=0.063), tot_loss_proj:1.687 [t=0.29s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
[1950/2000] tot_loss=1.355 (perp=6.430, rec=0.069), tot_loss_proj:1.687 [t=0.28s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.356 (perp=6.430, rec=0.070), tot_loss_proj:1.693 [t=0.28s]
prediction: ['[CLS] is make believe its promise soars of life above that realm - the realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is make believe its promise soars of life above that realm - the realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 121.905

[Aggregate metrics]:
rouge1     | fm: 87.844 | p: 86.933 | r: 89.037
rouge2     | fm: 49.501 | p: 49.156 | r: 49.963
rougeL     | fm: 75.653 | p: 74.893 | r: 76.556
rougeLsum  | fm: 75.425 | p: 74.748 | r: 76.350
r1fm+r2fm = 137.346

input #77 time: 0:11:06 | total time: 14:07:49


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9461857676506042 for ['[CLS] traffic microwave memorial [SEP]']
[Init] best rec loss: 0.8743376731872559 for ['[CLS] wrestler lush temperance [SEP]']
[Init] best rec loss: 0.8537693619728088 for ['[CLS] ownerbes vfl [SEP]']
[Init] best rec loss: 0.7724757194519043 for ['[CLS] maximumness little [SEP]']
[Init] best rec loss: 0.7429083585739136 for ['[CLS] flashlight alicia temple [SEP]']
[Init] best perm rec loss: 0.7428726553916931 for ['[CLS] flashlight temple alicia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.693 (perp=7.958, rec=0.101), tot_loss_proj:1.673 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
[ 100/2000] tot_loss=1.648 (perp=7.958, rec=0.057), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 150/2000] tot_loss=1.659 (perp=7.958, rec=0.067), tot_loss_proj:1.676 [t=0.31s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=1.650 (perp=7.958, rec=0.059), tot_loss_proj:1.686 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.663 (perp=7.958, rec=0.071), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.667 (perp=7.958, rec=0.075), tot_loss_proj:1.667 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.659 (perp=7.958, rec=0.067), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.655 (perp=7.958, rec=0.063), tot_loss_proj:1.675 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.654 (perp=7.958, rec=0.062), tot_loss_proj:1.677 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.647 (perp=7.958, rec=0.055), tot_loss_proj:1.668 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.649 (perp=7.958, rec=0.057), tot_loss_proj:1.670 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.655 (perp=7.958, rec=0.063), tot_loss_proj:1.677 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.654 (perp=7.958, rec=0.062), tot_loss_proj:1.674 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.658 (perp=7.958, rec=0.066), tot_loss_proj:1.678 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.640 (perp=7.958, rec=0.048), tot_loss_proj:1.672 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.652 (perp=7.958, rec=0.061), tot_loss_proj:1.669 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.650 (perp=7.958, rec=0.059), tot_loss_proj:1.682 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.657 (perp=7.958, rec=0.065), tot_loss_proj:1.667 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.670 (perp=7.958, rec=0.079), tot_loss_proj:1.668 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.653 (perp=7.958, rec=0.062), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.639 (perp=7.958, rec=0.047), tot_loss_proj:1.666 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.644 (perp=7.958, rec=0.052), tot_loss_proj:1.680 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.653 (perp=7.958, rec=0.062), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.651 (perp=7.958, rec=0.059), tot_loss_proj:1.685 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.658 (perp=7.958, rec=0.066), tot_loss_proj:1.680 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.647 (perp=7.958, rec=0.056), tot_loss_proj:1.690 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.653 (perp=7.958, rec=0.062), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.654 (perp=7.958, rec=0.062), tot_loss_proj:1.666 [t=0.30s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.638 (perp=7.958, rec=0.047), tot_loss_proj:1.671 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.648 (perp=7.958, rec=0.056), tot_loss_proj:1.670 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.662 (perp=7.958, rec=0.070), tot_loss_proj:1.657 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.657 (perp=7.958, rec=0.065), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.657 (perp=7.958, rec=0.065), tot_loss_proj:1.670 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=7.958, rec=0.066), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.642 (perp=7.958, rec=0.051), tot_loss_proj:1.671 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.655 (perp=7.958, rec=0.064), tot_loss_proj:1.667 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.655 (perp=7.958, rec=0.063), tot_loss_proj:1.669 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.649 (perp=7.958, rec=0.057), tot_loss_proj:1.665 [t=0.29s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.649 (perp=7.958, rec=0.057), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.648 (perp=7.958, rec=0.056), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.980 | p: 87.060 | r: 89.109
rouge2     | fm: 50.163 | p: 49.768 | r: 50.651
rougeL     | fm: 76.007 | p: 75.303 | r: 76.919
rougeLsum  | fm: 75.842 | p: 75.121 | r: 76.774
r1fm+r2fm = 138.143

input #78 time: 0:12:09 | total time: 14:19:58


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 1.0149093866348267 for ['[CLS] age your [SEP]']
[Init] best rec loss: 0.9886361956596375 for ['[CLS] shame rei [SEP]']
[Init] best rec loss: 0.9813417792320251 for ['[CLS] lower net [SEP]']
[Init] best rec loss: 0.9812724590301514 for ['[CLS] true word [SEP]']
[Init] best rec loss: 0.9789958596229553 for ['[CLS] alien selection [SEP]']
[Init] best rec loss: 0.9739148616790771 for ['[CLS] quarterback continental [SEP]']
[Init] best rec loss: 0.8883332014083862 for ['[CLS] commons instead [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.519 (perp=14.314, rec=0.656), tot_loss_proj:3.811 [t=0.28s]
prediction: ['[CLS] stared difficult [SEP]']
[ 100/2000] tot_loss=2.847 (perp=11.427, rec=0.561), tot_loss_proj:2.597 [t=0.29s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.991 (perp=11.427, rec=0.706), tot_loss_proj:2.600 [t=0.31s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.883 (perp=11.427, rec=0.598), tot_loss_proj:2.590 [t=0.29s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.819 (perp=11.427, rec=0.533), tot_loss_proj:2.594 [t=0.28s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 300/2000] tot_loss=2.811 (perp=11.427, rec=0.525), tot_loss_proj:2.592 [t=0.29s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.841 (perp=11.427, rec=0.556), tot_loss_proj:2.602 [t=0.28s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.782 (perp=11.427, rec=0.497), tot_loss_proj:2.598 [t=0.28s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 450/2000] tot_loss=2.776 (perp=11.427, rec=0.491), tot_loss_proj:2.605 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.805 (perp=11.427, rec=0.520), tot_loss_proj:2.593 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.759 (perp=11.427, rec=0.474), tot_loss_proj:2.593 [t=0.29s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 600/2000] tot_loss=2.800 (perp=11.427, rec=0.515), tot_loss_proj:2.603 [t=0.27s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.740 (perp=11.427, rec=0.455), tot_loss_proj:2.596 [t=0.28s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.762 (perp=11.427, rec=0.477), tot_loss_proj:2.594 [t=0.27s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 750/2000] tot_loss=2.735 (perp=11.427, rec=0.449), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.731 (perp=11.427, rec=0.445), tot_loss_proj:2.603 [t=0.24s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.733 (perp=11.427, rec=0.448), tot_loss_proj:2.592 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 900/2000] tot_loss=2.735 (perp=11.427, rec=0.450), tot_loss_proj:2.603 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.730 (perp=11.427, rec=0.444), tot_loss_proj:2.602 [t=0.27s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1000/2000] tot_loss=2.721 (perp=11.427, rec=0.435), tot_loss_proj:2.600 [t=0.27s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1050/2000] tot_loss=2.734 (perp=11.427, rec=0.449), tot_loss_proj:2.593 [t=0.29s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1100/2000] tot_loss=2.733 (perp=11.427, rec=0.447), tot_loss_proj:2.600 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1150/2000] tot_loss=2.720 (perp=11.427, rec=0.434), tot_loss_proj:2.604 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1200/2000] tot_loss=2.717 (perp=11.427, rec=0.431), tot_loss_proj:2.595 [t=0.24s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1250/2000] tot_loss=2.718 (perp=11.427, rec=0.432), tot_loss_proj:2.600 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1300/2000] tot_loss=2.723 (perp=11.427, rec=0.438), tot_loss_proj:2.594 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1350/2000] tot_loss=2.716 (perp=11.427, rec=0.431), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1400/2000] tot_loss=2.718 (perp=11.427, rec=0.433), tot_loss_proj:2.595 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1450/2000] tot_loss=2.717 (perp=11.427, rec=0.431), tot_loss_proj:2.607 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1500/2000] tot_loss=2.709 (perp=11.427, rec=0.424), tot_loss_proj:2.601 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1550/2000] tot_loss=2.723 (perp=11.427, rec=0.437), tot_loss_proj:2.597 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1600/2000] tot_loss=2.711 (perp=11.427, rec=0.425), tot_loss_proj:2.597 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1650/2000] tot_loss=2.716 (perp=11.427, rec=0.430), tot_loss_proj:2.594 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1700/2000] tot_loss=2.711 (perp=11.427, rec=0.426), tot_loss_proj:2.604 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1750/2000] tot_loss=2.710 (perp=11.427, rec=0.424), tot_loss_proj:2.594 [t=0.27s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1800/2000] tot_loss=2.716 (perp=11.427, rec=0.430), tot_loss_proj:2.595 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1850/2000] tot_loss=2.718 (perp=11.427, rec=0.433), tot_loss_proj:2.599 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[1900/2000] tot_loss=2.714 (perp=11.427, rec=0.428), tot_loss_proj:2.599 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[1950/2000] tot_loss=2.712 (perp=11.427, rec=0.426), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[2000/2000] tot_loss=2.712 (perp=11.427, rec=0.426), tot_loss_proj:2.600 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating fascinating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 87.809 | p: 86.933 | r: 88.908
rouge2     | fm: 50.142 | p: 49.806 | r: 50.513
rougeL     | fm: 76.001 | p: 75.295 | r: 76.886
rougeLsum  | fm: 75.742 | p: 75.053 | r: 76.675
r1fm+r2fm = 137.951

input #79 time: 0:11:15 | total time: 14:31:14


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9901618957519531 for ['[CLS]oman expenses owed path breuning [SEP]']
[Init] best rec loss: 0.979059636592865 for ['[CLS] extreme ji corps revived valentine [SEP]']
[Init] best rec loss: 0.9691171646118164 for ['[CLS] prices changes i temple backs [SEP]']
[Init] best rec loss: 0.9614723920822144 for ['[CLS] king food autumn pronebor [SEP]']
[Init] best rec loss: 0.9370129108428955 for ['[CLS] free look athletics fit button [SEP]']
[Init] best rec loss: 0.9326556921005249 for ['[CLS] [SEP] assignmentving exact mph [SEP]']
[Init] best rec loss: 0.9318519234657288 for ['[CLS] early generation crown under deck [SEP]']
[Init] best rec loss: 0.9265134930610657 for ['[CLS] miss baby before weaver gain [SEP]']
[Init] best perm rec loss: 0.9222840666770935 for ['[CLS] before weaver gain baby miss [SEP]']
[Init] best perm rec loss: 0.9216058254241943 for ['[CLS] before gain miss weaver baby [SEP]']
[Init] best perm rec loss: 0.9202527403831482 for ['[CLS] miss gain before weaver baby [SEP]']
[Init] best perm rec loss: 0.9199236631393433 for ['[CLS] weaver miss gain before baby [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.208 (perp=13.047, rec=0.598), tot_loss_proj:3.638 [t=0.29s]
prediction: ['[CLS] norton cerambycidaezen surprising prominent [SEP]']
[ 100/2000] tot_loss=3.094 (perp=12.727, rec=0.548), tot_loss_proj:3.500 [t=0.27s]
prediction: ['[CLS] wiᆫzen toldwi [SEP]']
[ 150/2000] tot_loss=3.016 (perp=12.025, rec=0.611), tot_loss_proj:3.368 [t=0.26s]
prediction: ['[CLS] voᆫzen章 lexie [SEP]']
[ 200/2000] tot_loss=3.214 (perp=13.663, rec=0.481), tot_loss_proj:3.737 [t=0.26s]
prediction: ['[CLS] winsiszen carolynmity [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.969 (perp=12.320, rec=0.505), tot_loss_proj:3.517 [t=0.25s]
prediction: ['[CLS] wizen wi listsnsis [SEP]']
[ 300/2000] tot_loss=2.504 (perp=10.222, rec=0.459), tot_loss_proj:3.121 [t=0.25s]
prediction: ['[CLS] wizen wi parchmentnsis [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.343 (perp=9.666, rec=0.410), tot_loss_proj:3.123 [t=0.24s]
prediction: ['[CLS] wizened destinationszed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.249 (perp=9.258, rec=0.397), tot_loss_proj:3.048 [t=0.26s]
prediction: ['[CLS] wizenedhoodzed [SEP]']
[ 450/2000] tot_loss=2.478 (perp=10.425, rec=0.393), tot_loss_proj:3.317 [t=0.26s]
prediction: ['[CLS] wizened destinations whose [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.612 (perp=11.167, rec=0.379), tot_loss_proj:3.271 [t=0.29s]
prediction: ['[CLS] wizen wi sounding miserable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.355 (perp=9.984, rec=0.358), tot_loss_proj:3.012 [t=0.26s]
prediction: ['[CLS] wizened tablet miserable [SEP]']
[ 600/2000] tot_loss=2.350 (perp=9.922, rec=0.366), tot_loss_proj:3.000 [t=0.25s]
prediction: ['[CLS] wizened wanting miserable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.147 (perp=8.947, rec=0.357), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] wizened wise stride [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.107 (perp=8.641, rec=0.379), tot_loss_proj:2.742 [t=0.26s]
prediction: ['[CLS] wizened wise miserable [SEP]']
[ 750/2000] tot_loss=2.794 (perp=12.236, rec=0.347), tot_loss_proj:3.321 [t=0.28s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.784 (perp=12.236, rec=0.337), tot_loss_proj:3.315 [t=0.26s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.930 (perp=12.236, rec=0.483), tot_loss_proj:3.318 [t=0.26s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
[ 900/2000] tot_loss=2.627 (perp=11.451, rec=0.336), tot_loss_proj:3.362 [t=0.26s]
prediction: ['[CLS] wizen wi wise wise [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.633 (perp=11.451, rec=0.343), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] wizen wi wise wise [SEP]']
Attempt swap
[1000/2000] tot_loss=2.778 (perp=12.236, rec=0.331), tot_loss_proj:3.319 [t=0.26s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
[1050/2000] tot_loss=2.776 (perp=12.236, rec=0.329), tot_loss_proj:3.327 [t=0.25s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
Attempt swap
[1100/2000] tot_loss=2.775 (perp=12.236, rec=0.328), tot_loss_proj:3.321 [t=0.26s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
Attempt swap
[1150/2000] tot_loss=2.776 (perp=12.236, rec=0.329), tot_loss_proj:3.318 [t=0.25s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
[1200/2000] tot_loss=2.780 (perp=12.236, rec=0.333), tot_loss_proj:3.320 [t=0.25s]
prediction: ['[CLS] wizen wi wise stride [SEP]']
Attempt swap
[1250/2000] tot_loss=2.611 (perp=11.430, rec=0.325), tot_loss_proj:3.471 [t=0.27s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1300/2000] tot_loss=2.616 (perp=11.430, rec=0.330), tot_loss_proj:3.473 [t=0.25s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
[1350/2000] tot_loss=2.618 (perp=11.430, rec=0.332), tot_loss_proj:3.466 [t=0.25s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1400/2000] tot_loss=2.603 (perp=11.430, rec=0.317), tot_loss_proj:3.478 [t=0.26s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1450/2000] tot_loss=2.610 (perp=11.430, rec=0.324), tot_loss_proj:3.478 [t=0.26s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
[1500/2000] tot_loss=2.603 (perp=11.430, rec=0.317), tot_loss_proj:3.472 [t=0.24s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1550/2000] tot_loss=2.607 (perp=11.430, rec=0.321), tot_loss_proj:3.465 [t=0.27s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1600/2000] tot_loss=2.613 (perp=11.430, rec=0.327), tot_loss_proj:3.463 [t=0.26s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
[1650/2000] tot_loss=2.609 (perp=11.430, rec=0.323), tot_loss_proj:3.472 [t=0.28s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1700/2000] tot_loss=2.619 (perp=11.430, rec=0.333), tot_loss_proj:3.469 [t=0.27s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1750/2000] tot_loss=2.615 (perp=11.430, rec=0.329), tot_loss_proj:3.473 [t=0.27s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
[1800/2000] tot_loss=2.608 (perp=11.430, rec=0.322), tot_loss_proj:3.473 [t=0.34s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1850/2000] tot_loss=2.601 (perp=11.430, rec=0.315), tot_loss_proj:3.473 [t=0.25s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[1900/2000] tot_loss=2.607 (perp=11.430, rec=0.321), tot_loss_proj:3.475 [t=0.28s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
[1950/2000] tot_loss=2.608 (perp=11.430, rec=0.322), tot_loss_proj:3.473 [t=0.25s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Attempt swap
[2000/2000] tot_loss=2.607 (perp=11.430, rec=0.321), tot_loss_proj:3.472 [t=0.25s]
prediction: ['[CLS] wizen wi wisenah [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizen wi wisenah [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 40.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 40.000 | r: 50.000
rougeLsum  | fm: 44.444 | p: 40.000 | r: 50.000
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 87.239 | p: 86.315 | r: 88.364
rouge2     | fm: 49.381 | p: 49.048 | r: 49.870
rougeL     | fm: 75.541 | p: 74.811 | r: 76.541
rougeLsum  | fm: 75.508 | p: 74.733 | r: 76.415
r1fm+r2fm = 136.620

input #80 time: 0:10:44 | total time: 14:41:59


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.8588722944259644 for ['[CLS] farm extra like classic kevin guards [SEP]']
[Init] best rec loss: 0.8497611284255981 for ['[CLS] fines montgomery platinum listen curious charts [SEP]']
[Init] best rec loss: 0.8401182889938354 for ['[CLS] elseil noisenet murderous time [SEP]']
[Init] best rec loss: 0.8231046795845032 for ['[CLS] ⇒ firees leader service market [SEP]']
[Init] best rec loss: 0.8197540044784546 for ['[CLS] guy [SEP] catholic through kirby designated [SEP]']
[Init] best rec loss: 0.8171647191047668 for ['[CLS] mistress commissioned ashes network seemingly cheyenne [SEP]']
[Init] best rec loss: 0.8156622648239136 for ['[CLS] boxers attention action cross prom [MASK] [SEP]']
[Init] best rec loss: 0.8027070164680481 for ['[CLS] arms male sour nonsenseured chemist [SEP]']
[Init] best rec loss: 0.7862566709518433 for ['[CLS] tan anchor increase cas suggest kingdom [SEP]']
[Init] best rec loss: 0.7781260013580322 for ['[CLS] exposed terra used a1 that desire [SEP]']
[Init] best rec loss: 0.7751577496528625 for ['[CLS] meanpal rene expansion pussyerate [SEP]']
[Init] best perm rec loss: 0.775114893913269 for ['[CLS]erate pussy mean expansionpal rene [SEP]']
[Init] best perm rec loss: 0.7710403203964233 for ['[CLS] expansion meaneratepal pussy rene [SEP]']
[Init] best perm rec loss: 0.7704696655273438 for ['[CLS]pal meanerate rene expansion pussy [SEP]']
[Init] best perm rec loss: 0.7690593004226685 for ['[CLS]pal reneerate mean expansion pussy [SEP]']
[Init] best perm rec loss: 0.7658297419548035 for ['[CLS]erate expansionpal rene mean pussy [SEP]']
[Init] best perm rec loss: 0.7646719813346863 for ['[CLS] mean renepalerate pussy expansion [SEP]']
[Init] best perm rec loss: 0.7630229592323303 for ['[CLS] reneerate pussy expansion meanpal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.466 (perp=10.605, rec=0.345), tot_loss_proj:3.108 [t=0.26s]
prediction: ['[CLS] ". best not never ears [SEP]']
[ 100/2000] tot_loss=2.007 (perp=9.166, rec=0.174), tot_loss_proj:2.779 [t=0.26s]
prediction: ['[CLS] overall is impressive the not player [SEP]']
[ 150/2000] tot_loss=1.990 (perp=9.345, rec=0.121), tot_loss_proj:2.850 [t=0.25s]
prediction: ['[CLS] impressive is impressive the not player [SEP]']
[ 200/2000] tot_loss=2.015 (perp=9.650, rec=0.085), tot_loss_proj:2.857 [t=0.26s]
prediction: ['[CLS] impressive is most the not player [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.546 (perp=7.328, rec=0.081), tot_loss_proj:2.055 [t=0.25s]
prediction: ['[CLS] impressive is not the most player [SEP]']
[ 300/2000] tot_loss=1.542 (perp=7.328, rec=0.077), tot_loss_proj:2.058 [t=0.26s]
prediction: ['[CLS] impressive is not the most player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.259 (perp=5.977, rec=0.063), tot_loss_proj:1.321 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.257 (perp=5.977, rec=0.061), tot_loss_proj:1.314 [t=0.27s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.250 (perp=5.977, rec=0.055), tot_loss_proj:1.320 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.247 (perp=5.977, rec=0.051), tot_loss_proj:1.319 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.261 (perp=5.977, rec=0.066), tot_loss_proj:1.324 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.258 (perp=5.977, rec=0.063), tot_loss_proj:1.313 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.265 (perp=5.977, rec=0.070), tot_loss_proj:1.313 [t=0.27s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.264 (perp=5.977, rec=0.068), tot_loss_proj:1.324 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.254 (perp=5.977, rec=0.059), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.260 (perp=5.977, rec=0.065), tot_loss_proj:1.314 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.262 (perp=5.977, rec=0.067), tot_loss_proj:1.319 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.254 (perp=5.977, rec=0.058), tot_loss_proj:1.315 [t=0.28s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.253 (perp=5.977, rec=0.057), tot_loss_proj:1.323 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.257 (perp=5.977, rec=0.061), tot_loss_proj:1.307 [t=0.27s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.251 (perp=5.977, rec=0.055), tot_loss_proj:1.309 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.257 (perp=5.977, rec=0.062), tot_loss_proj:1.315 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.249 (perp=5.977, rec=0.054), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.254 (perp=5.977, rec=0.058), tot_loss_proj:1.317 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.266 (perp=5.977, rec=0.071), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.260 (perp=5.977, rec=0.065), tot_loss_proj:1.322 [t=0.28s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.254 (perp=5.977, rec=0.059), tot_loss_proj:1.311 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.248 (perp=5.977, rec=0.052), tot_loss_proj:1.305 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.262 (perp=5.977, rec=0.066), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.244 (perp=5.977, rec=0.048), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.240 (perp=5.977, rec=0.045), tot_loss_proj:1.316 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.257 (perp=5.977, rec=0.061), tot_loss_proj:1.314 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.258 (perp=5.977, rec=0.062), tot_loss_proj:1.322 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.266 (perp=5.977, rec=0.071), tot_loss_proj:1.308 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.263 (perp=5.977, rec=0.068), tot_loss_proj:1.318 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.257 (perp=5.977, rec=0.061), tot_loss_proj:1.315 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.253 (perp=5.977, rec=0.058), tot_loss_proj:1.319 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.256 (perp=5.977, rec=0.060), tot_loss_proj:1.316 [t=0.29s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.265 (perp=5.977, rec=0.069), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.258 (perp=5.977, rec=0.063), tot_loss_proj:1.314 [t=0.27s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.441 | p: 86.537 | r: 88.566
rouge2     | fm: 50.018 | p: 49.647 | r: 50.501
rougeL     | fm: 75.812 | p: 75.097 | r: 76.711
rougeLsum  | fm: 75.701 | p: 75.009 | r: 76.661
r1fm+r2fm = 137.458

input #81 time: 0:10:44 | total time: 14:52:43


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9332028031349182 for ['[CLS] coal nobel connection pitchfork spots being fame traveling [SEP]']
[Init] best rec loss: 0.9111229777336121 for ['[CLS] swear commissionbuław product filed drive elaborate [SEP]']
[Init] best rec loss: 0.8769676685333252 for ['[CLS] getting bloody wrath base dying replaced did libby [SEP]']
[Init] best rec loss: 0.8690964579582214 for ['[CLS]d frederick bargaining voice religion off ave cream [SEP]']
[Init] best perm rec loss: 0.8689473271369934 for ['[CLS]d frederick religion cream ave voice off bargaining [SEP]']
[Init] best perm rec loss: 0.8671271800994873 for ['[CLS]d ave cream off religion frederick voice bargaining [SEP]']
[Init] best perm rec loss: 0.8646384477615356 for ['[CLS] voice religion cream bargaining frederick offd ave [SEP]']
[Init] best perm rec loss: 0.8642682433128357 for ['[CLS] off bargaining cream frederickd religion ave voice [SEP]']
[Init] best perm rec loss: 0.8642379641532898 for ['[CLS] cream ave frederick offd bargaining religion voice [SEP]']
[Init] best perm rec loss: 0.8637784123420715 for ['[CLS] aved frederick cream off religion bargaining voice [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.459 (perp=11.182, rec=0.223), tot_loss_proj:3.037 [t=0.27s]
prediction: ['[CLS] undone sloppy script by script script undone undone [SEP]']
[ 100/2000] tot_loss=2.200 (perp=10.393, rec=0.121), tot_loss_proj:2.597 [t=0.25s]
prediction: ['[CLS] sloppy sloppy script by script is sloppy undone [SEP]']
[ 150/2000] tot_loss=2.329 (perp=11.220, rec=0.085), tot_loss_proj:2.795 [t=0.29s]
prediction: ['[CLS] sloppy sloppy script by script s sloppy undone [SEP]']
[ 200/2000] tot_loss=2.271 (perp=10.960, rec=0.079), tot_loss_proj:2.914 [t=0.26s]
prediction: ['[CLS] sloppy sloppy it by script s a undone [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.120 (perp=10.156, rec=0.088), tot_loss_proj:2.714 [t=0.26s]
prediction: ['[CLS] sloppy sloppy it by script undone s a [SEP]']
[ 300/2000] tot_loss=2.105 (perp=10.156, rec=0.074), tot_loss_proj:2.727 [t=0.31s]
prediction: ['[CLS] sloppy sloppy it by script undone s a [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.014 (perp=9.681, rec=0.078), tot_loss_proj:2.501 [t=0.26s]
prediction: ['[CLS] sloppy sloppy it by a undone s script [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.885 (perp=9.060, rec=0.073), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] s sloppy it by a undone sloppy script [SEP]']
[ 450/2000] tot_loss=1.877 (perp=9.060, rec=0.065), tot_loss_proj:2.258 [t=0.27s]
prediction: ['[CLS] s sloppy it by a undone sloppy script [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.647 (perp=7.848, rec=0.078), tot_loss_proj:1.869 [t=0.26s]
prediction: ['[CLS] s undone it by a sloppy sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.628 (perp=7.848, rec=0.058), tot_loss_proj:1.872 [t=0.28s]
prediction: ['[CLS] s undone it by a sloppy sloppy script [SEP]']
[ 600/2000] tot_loss=1.638 (perp=7.848, rec=0.068), tot_loss_proj:1.859 [t=0.25s]
prediction: ['[CLS] s undone it by a sloppy sloppy script [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.558 (perp=7.465, rec=0.065), tot_loss_proj:1.614 [t=0.28s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.564 (perp=7.465, rec=0.071), tot_loss_proj:1.626 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 750/2000] tot_loss=1.552 (perp=7.465, rec=0.059), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.565 (perp=7.465, rec=0.072), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.560 (perp=7.465, rec=0.067), tot_loss_proj:1.637 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 900/2000] tot_loss=1.549 (perp=7.465, rec=0.056), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.555 (perp=7.465, rec=0.062), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.558 (perp=7.465, rec=0.065), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.465, rec=0.065), tot_loss_proj:1.629 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.561 (perp=7.465, rec=0.068), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.465, rec=0.067), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1200/2000] tot_loss=1.568 (perp=7.465, rec=0.075), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.465, rec=0.057), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.559 (perp=7.465, rec=0.066), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1350/2000] tot_loss=1.544 (perp=7.465, rec=0.051), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.550 (perp=7.465, rec=0.057), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.560 (perp=7.465, rec=0.067), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1500/2000] tot_loss=1.551 (perp=7.465, rec=0.058), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.465, rec=0.065), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.554 (perp=7.465, rec=0.061), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.465, rec=0.067), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.557 (perp=7.465, rec=0.064), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1750/2000] tot_loss=1.551 (perp=7.465, rec=0.058), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1800/2000] tot_loss=1.559 (perp=7.465, rec=0.066), tot_loss_proj:1.625 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1850/2000] tot_loss=1.558 (perp=7.465, rec=0.065), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.565 (perp=7.465, rec=0.072), tot_loss_proj:1.631 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1950/2000] tot_loss=1.550 (perp=7.465, rec=0.057), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.553 (perp=7.465, rec=0.060), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 87.535 | p: 86.600 | r: 88.638
rouge2     | fm: 50.506 | p: 50.124 | r: 50.978
rougeL     | fm: 76.014 | p: 75.242 | r: 77.031
rougeLsum  | fm: 75.954 | p: 75.206 | r: 76.886
r1fm+r2fm = 138.042

input #82 time: 0:10:49 | total time: 15:03:32


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.864332914352417 for ['[CLS] tall arms turns dakotalum hundredpres territories cherry livery [SEP]']
[Init] best rec loss: 0.8629740476608276 for ['[CLS] aboard success never & optic typhoonlateralverance specific for [SEP]']
[Init] best rec loss: 0.8473352789878845 for ['[CLS]imum alongsideboarding card left board column route gasping vent [SEP]']
[Init] best rec loss: 0.8367873430252075 for ['[CLS] di discussed career shadowfect mabel worse norwegian renault rory [SEP]']
[Init] best rec loss: 0.7900545597076416 for ['[CLS] range voyage田 highway footage sampled cupped reno interested important [SEP]']
[Init] best rec loss: 0.7869827747344971 for ['[CLS]ing visible lookdon ib need yeco dance divorced [SEP]']
[Init] best rec loss: 0.7869348526000977 for ['[CLS] lightbus donorsacker positive clubied undphine deep [SEP]']
[Init] best rec loss: 0.771806001663208 for ['[CLS] become encouragement bar attention forever raced armoured je stylized there [SEP]']
[Init] best perm rec loss: 0.7706078886985779 for ['[CLS] become there attention je bar raced armoured stylized forever encouragement [SEP]']
[Init] best perm rec loss: 0.770101010799408 for ['[CLS] stylized armoured encouragement there attention become raced bar je forever [SEP]']
[Init] best perm rec loss: 0.7686646580696106 for ['[CLS] armoured encouragement forever there raced bar stylized je attention become [SEP]']
[Init] best perm rec loss: 0.7686216831207275 for ['[CLS] stylized raced attention je forever become there bar encouragement armoured [SEP]']
[Init] best perm rec loss: 0.7676277160644531 for ['[CLS] bar become encouragement forever je armoured there attention stylized raced [SEP]']
[Init] best perm rec loss: 0.7668662071228027 for ['[CLS] stylized attention forever armoured je raced encouragement become there bar [SEP]']
[Init] best perm rec loss: 0.7666096091270447 for ['[CLS] stylized forever become encouragement raced armoured bar there attention je [SEP]']
[Init] best perm rec loss: 0.7665390372276306 for ['[CLS] stylized armoured forever je raced attention there bar become encouragement [SEP]']
[Init] best perm rec loss: 0.765848696231842 for ['[CLS] there armoured become forever encouragement je raced attention bar stylized [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.130 (perp=9.174, rec=0.295), tot_loss_proj:2.380 [t=0.24s]
prediction: ['[CLS] know what it wants someday when grows when plains his [SEP]']
[ 100/2000] tot_loss=1.811 (perp=8.399, rec=0.131), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS] know what it wants everything to grows be when when [SEP]']
[ 150/2000] tot_loss=1.743 (perp=8.284, rec=0.086), tot_loss_proj:2.207 [t=0.26s]
prediction: ['[CLS] know what it wants it be grows be when when [SEP]']
[ 200/2000] tot_loss=1.598 (perp=7.555, rec=0.087), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] know what it wants it be grows be it when [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.730 (perp=8.136, rec=0.103), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] know what it wants be it grows be when when [SEP]']
[ 300/2000] tot_loss=1.454 (perp=6.865, rec=0.081), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] know what it wants be it grows be it when [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.452 (perp=6.865, rec=0.079), tot_loss_proj:1.886 [t=0.26s]
prediction: ['[CLS] know what it wants be it grows be it when [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.248 (perp=5.788, rec=0.090), tot_loss_proj:1.498 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows to it be [SEP]']
[ 450/2000] tot_loss=1.238 (perp=5.788, rec=0.080), tot_loss_proj:1.498 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows to it be [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.052 (perp=4.797, rec=0.093), tot_loss_proj:1.312 [t=0.26s]
prediction: ['[CLS] it know what it wants when it grows to be [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.043 (perp=4.797, rec=0.083), tot_loss_proj:1.316 [t=0.26s]
prediction: ['[CLS] it know what it wants when it grows to be [SEP]']
[ 600/2000] tot_loss=1.029 (perp=4.797, rec=0.069), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] it know what it wants when it grows to be [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.043 (perp=4.797, rec=0.084), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] it know what it wants when it grows to be [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.185 (perp=5.607, rec=0.063), tot_loss_proj:1.498 [t=0.25s]
prediction: ['[CLS] up know what it wants when it grows to be [SEP]']
[ 750/2000] tot_loss=1.198 (perp=5.607, rec=0.077), tot_loss_proj:1.501 [t=0.28s]
prediction: ['[CLS] up know what it wants when it grows to be [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.203 (perp=5.607, rec=0.082), tot_loss_proj:1.493 [t=0.25s]
prediction: ['[CLS] up know what it wants when it grows to be [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.029 (perp=4.724, rec=0.084), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[ 900/2000] tot_loss=1.019 (perp=4.724, rec=0.074), tot_loss_proj:1.188 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.012 (perp=4.724, rec=0.067), tot_loss_proj:1.188 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1000/2000] tot_loss=1.010 (perp=4.724, rec=0.065), tot_loss_proj:1.194 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1050/2000] tot_loss=1.017 (perp=4.724, rec=0.072), tot_loss_proj:1.179 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1100/2000] tot_loss=1.016 (perp=4.724, rec=0.071), tot_loss_proj:1.185 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1150/2000] tot_loss=1.020 (perp=4.724, rec=0.075), tot_loss_proj:1.179 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1200/2000] tot_loss=1.007 (perp=4.724, rec=0.062), tot_loss_proj:1.185 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1250/2000] tot_loss=1.011 (perp=4.724, rec=0.066), tot_loss_proj:1.189 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1300/2000] tot_loss=1.015 (perp=4.724, rec=0.070), tot_loss_proj:1.192 [t=0.27s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1350/2000] tot_loss=1.021 (perp=4.724, rec=0.077), tot_loss_proj:1.190 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1400/2000] tot_loss=1.008 (perp=4.724, rec=0.064), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1450/2000] tot_loss=1.011 (perp=4.724, rec=0.066), tot_loss_proj:1.195 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1500/2000] tot_loss=1.013 (perp=4.724, rec=0.068), tot_loss_proj:1.197 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1550/2000] tot_loss=1.021 (perp=4.724, rec=0.076), tot_loss_proj:1.186 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1600/2000] tot_loss=1.019 (perp=4.724, rec=0.074), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1650/2000] tot_loss=1.020 (perp=4.724, rec=0.075), tot_loss_proj:1.190 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1700/2000] tot_loss=1.021 (perp=4.724, rec=0.076), tot_loss_proj:1.187 [t=0.27s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1750/2000] tot_loss=1.014 (perp=4.724, rec=0.069), tot_loss_proj:1.187 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1800/2000] tot_loss=1.011 (perp=4.724, rec=0.066), tot_loss_proj:1.187 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1850/2000] tot_loss=1.021 (perp=4.724, rec=0.076), tot_loss_proj:1.195 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[1900/2000] tot_loss=1.024 (perp=4.724, rec=0.079), tot_loss_proj:1.184 [t=0.27s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
[1950/2000] tot_loss=1.016 (perp=4.724, rec=0.071), tot_loss_proj:1.185 [t=0.26s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Attempt swap
[2000/2000] tot_loss=1.016 (perp=4.724, rec=0.071), tot_loss_proj:1.181 [t=0.25s]
prediction: ['[CLS] know what it wants when it grows up to be [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants when it grows up to be [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 172.727

[Aggregate metrics]:
rouge1     | fm: 87.667 | p: 86.753 | r: 88.848
rouge2     | fm: 50.702 | p: 50.277 | r: 51.179
rougeL     | fm: 76.183 | p: 75.448 | r: 77.167
rougeLsum  | fm: 76.147 | p: 75.363 | r: 77.095
r1fm+r2fm = 138.368

input #83 time: 0:10:42 | total time: 15:14:15


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9615227580070496 for ['[CLS] exposedrred building ham call perfect art [SEP]']
[Init] best rec loss: 0.8912646770477295 for ['[CLS] standing state lightning formerpoint paige expertise [SEP]']
[Init] best rec loss: 0.8618496656417847 for ['[CLS] [SEP] devi volunteer something finished remix dynasty [SEP]']
[Init] best rec loss: 0.8275795578956604 for ['[CLS] naked string monday deal spoke bench grip [SEP]']
[Init] best perm rec loss: 0.8228460550308228 for ['[CLS] bench naked grip string monday deal spoke [SEP]']
[Init] best perm rec loss: 0.8223804235458374 for ['[CLS] spoke deal string grip naked bench monday [SEP]']
[Init] best perm rec loss: 0.8221009373664856 for ['[CLS] deal naked string bench spoke grip monday [SEP]']
[Init] best perm rec loss: 0.8216177225112915 for ['[CLS] deal spoke string naked monday grip bench [SEP]']
[Init] best perm rec loss: 0.820793867111206 for ['[CLS] spoke deal bench string grip naked monday [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.223 (perp=9.413, rec=0.340), tot_loss_proj:2.437 [t=0.27s]
prediction: ['[CLS] lost ability think lost learning people lost [SEP]']
[ 100/2000] tot_loss=2.126 (perp=9.773, rec=0.171), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] lost ability think lost think people lost [SEP]']
[ 150/2000] tot_loss=1.962 (perp=9.198, rec=0.122), tot_loss_proj:2.340 [t=0.26s]
prediction: ['[CLS] lost ability think the think people lost [SEP]']
[ 200/2000] tot_loss=1.854 (perp=8.747, rec=0.105), tot_loss_proj:2.284 [t=0.26s]
prediction: ['[CLS] lost ability think the the people lost [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.732 (perp=8.194, rec=0.093), tot_loss_proj:2.237 [t=0.25s]
prediction: ['[CLS] have people think the the ability lost [SEP]']
[ 300/2000] tot_loss=1.721 (perp=8.194, rec=0.082), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] have people think the the ability lost [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.636 (perp=7.752, rec=0.086), tot_loss_proj:2.179 [t=0.25s]
prediction: ['[CLS] have the people think the ability lost [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.579 (perp=7.463, rec=0.086), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] they people think have the ability lost [SEP]']
[ 450/2000] tot_loss=1.564 (perp=7.463, rec=0.072), tot_loss_proj:2.145 [t=0.26s]
prediction: ['[CLS] they people think have the ability lost [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.575 (perp=7.509, rec=0.073), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] the think people have the ability lost [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.438 (perp=6.822, rec=0.073), tot_loss_proj:1.986 [t=0.26s]
prediction: ['[CLS] think the people have the ability lost [SEP]']
[ 600/2000] tot_loss=1.443 (perp=6.822, rec=0.078), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] think the people have the ability lost [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.330 (perp=6.298, rec=0.070), tot_loss_proj:1.768 [t=0.26s]
prediction: ['[CLS] think the people have lost the ability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.339 (perp=6.298, rec=0.080), tot_loss_proj:1.772 [t=0.25s]
prediction: ['[CLS] think the people have lost the ability [SEP]']
[ 750/2000] tot_loss=1.338 (perp=6.298, rec=0.078), tot_loss_proj:1.771 [t=0.26s]
prediction: ['[CLS] think the people have lost the ability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.616 (perp=7.727, rec=0.071), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] think lost people have lost the ability [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.977 (perp=9.451, rec=0.087), tot_loss_proj:2.379 [t=0.25s]
prediction: ['[CLS] think the from people have lost ability [SEP]']
[ 900/2000] tot_loss=1.956 (perp=9.451, rec=0.066), tot_loss_proj:2.385 [t=0.27s]
prediction: ['[CLS] think the from people have lost ability [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.591 (perp=7.611, rec=0.069), tot_loss_proj:2.109 [t=0.26s]
prediction: ['[CLS] think the people have lost from ability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.537 (perp=7.314, rec=0.074), tot_loss_proj:2.024 [t=0.34s]
prediction: ['[CLS] think the people have lost to ability [SEP]']
[1050/2000] tot_loss=1.524 (perp=7.314, rec=0.061), tot_loss_proj:2.012 [t=0.33s]
prediction: ['[CLS] think the people have lost to ability [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.428 (perp=6.723, rec=0.083), tot_loss_proj:1.943 [t=0.27s]
prediction: ['[CLS] to think the people have lost ability [SEP]']
Attempt swap
Put prefix at the end
[1150/2000] tot_loss=1.194 (perp=5.587, rec=0.077), tot_loss_proj:1.355 [t=0.26s]
prediction: ['[CLS] the people have lost ability to think [SEP]']
[1200/2000] tot_loss=1.185 (perp=5.587, rec=0.068), tot_loss_proj:1.348 [t=0.26s]
prediction: ['[CLS] the people have lost ability to think [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.012 (perp=4.681, rec=0.076), tot_loss_proj:1.030 [t=0.32s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.003 (perp=4.681, rec=0.067), tot_loss_proj:1.034 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.000 (perp=4.681, rec=0.064), tot_loss_proj:1.026 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.007 (perp=4.681, rec=0.070), tot_loss_proj:1.032 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.005 (perp=4.681, rec=0.069), tot_loss_proj:1.035 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.005 (perp=4.681, rec=0.068), tot_loss_proj:1.024 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.008 (perp=4.681, rec=0.072), tot_loss_proj:1.031 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.015 (perp=4.681, rec=0.079), tot_loss_proj:1.031 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=0.994 (perp=4.681, rec=0.057), tot_loss_proj:1.030 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=0.996 (perp=4.681, rec=0.060), tot_loss_proj:1.026 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.994 (perp=4.681, rec=0.057), tot_loss_proj:1.035 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.006 (perp=4.681, rec=0.070), tot_loss_proj:1.037 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.003 (perp=4.681, rec=0.066), tot_loss_proj:1.035 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.013 (perp=4.681, rec=0.076), tot_loss_proj:1.031 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.006 (perp=4.681, rec=0.070), tot_loss_proj:1.040 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=0.993 (perp=4.681, rec=0.057), tot_loss_proj:1.024 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.842 | p: 86.911 | r: 88.984
rouge2     | fm: 51.327 | p: 50.910 | r: 51.860
rougeL     | fm: 76.416 | p: 75.628 | r: 77.369
rougeLsum  | fm: 76.356 | p: 75.604 | r: 77.214
r1fm+r2fm = 139.169

input #84 time: 0:10:51 | total time: 15:25:06


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9392704367637634 for ['[CLS] corresponding jr bce velocity id do ireland purposes havenistle [SEP]']
[Init] best rec loss: 0.9255865812301636 for ['[CLS] upside romans primary batchhelm oil exposure walls blake shoulder [SEP]']
[Init] best rec loss: 0.9125877022743225 for ['[CLS] central makeup earned adapted status surely sport " mrs trial [SEP]']
[Init] best rec loss: 0.9083121418952942 for ['[CLS] dun everyone via by signalsrableoked gr lan armor [SEP]']
[Init] best rec loss: 0.9031468033790588 for ['[CLS] excess insects scholarship rue philosopher into true argentina keys sham [SEP]']
[Init] best rec loss: 0.9026931524276733 for ['[CLS] sale subspecies callumsai cozy etc maggie named hasn santiago [SEP]']
[Init] best rec loss: 0.898842453956604 for ['[CLS] scotland draw ground midst pride consolidated aboard stand broke you [SEP]']
[Init] best rec loss: 0.8843227028846741 for ['[CLS]vatinghol las group rabbi covent responsible least concern equal [SEP]']
[Init] best rec loss: 0.8749798536300659 for ['[CLS]aran6th world signature loggingrug national proudsit hare [SEP]']
[Init] best rec loss: 0.8662585020065308 for ['[CLS] st conversation momentarily states net lead door fbi jace knowledge [SEP]']
[Init] best rec loss: 0.8577024936676025 for ['[CLS] existing sexual cinema chamberlain elements wouldnhopper fast institute goofy [SEP]']
[Init] best perm rec loss: 0.8524649143218994 for ['[CLS] chamberlainhopper cinema institute fast goofy wouldn existing elements sexual [SEP]']
[Init] best perm rec loss: 0.8520543575286865 for ['[CLS]hopper sexual institute chamberlain goofy fast wouldn elements existing cinema [SEP]']
[Init] best perm rec loss: 0.8510042428970337 for ['[CLS] elements goofy chamberlainhopper fast cinema existing sexual institute wouldn [SEP]']
[Init] best perm rec loss: 0.849564790725708 for ['[CLS]hopper fast cinema sexual existing institute wouldn elements chamberlain goofy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.452 (perp=10.317, rec=0.388), tot_loss_proj:2.913 [t=0.27s]
prediction: ['[CLS] unfortunately unfortunately also reason replacing without uncomfortable bad. unfortunately [SEP]']
[ 100/2000] tot_loss=2.121 (perp=9.363, rec=0.249), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] unfortunately unfortunately, not how bio unfortunately not good unfortunately [SEP]']
[ 150/2000] tot_loss=2.098 (perp=9.607, rec=0.177), tot_loss_proj:2.500 [t=0.28s]
prediction: ['[CLS] unfortunately unfortunately, also system not unfortunately not good unfortunately [SEP]']
[ 200/2000] tot_loss=2.051 (perp=9.540, rec=0.143), tot_loss_proj:2.550 [t=0.26s]
prediction: ['[CLS] unfortunately unfortunately it also system not unfortunately not good unfortunately [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.458 (perp=6.719, rec=0.115), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] unfortunately unfortunately it also very unfortunately not not good. [SEP]']
[ 300/2000] tot_loss=1.568 (perp=7.325, rec=0.103), tot_loss_proj:1.927 [t=0.25s]
prediction: ['[CLS] unfortunately unfortunately it also very unfortunately related not good. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.663 (perp=7.802, rec=0.103), tot_loss_proj:2.030 [t=0.26s]
prediction: ['[CLS] unfortunatelyigate it also very unfortunately unfortunately not good. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.606 (perp=7.573, rec=0.091), tot_loss_proj:1.896 [t=0.26s]
prediction: ['[CLS]page unfortunately it also very s unfortunately not good. [SEP]']
[ 450/2000] tot_loss=1.616 (perp=7.573, rec=0.102), tot_loss_proj:1.896 [t=0.25s]
prediction: ['[CLS]page unfortunately it also very s unfortunately not good. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.465 (perp=6.858, rec=0.093), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] unfortunately it also very s unfortunately not goodpage. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.333 (perp=6.168, rec=0.099), tot_loss_proj:1.554 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[ 600/2000] tot_loss=1.326 (perp=6.168, rec=0.093), tot_loss_proj:1.555 [t=0.24s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.310 (perp=6.168, rec=0.077), tot_loss_proj:1.552 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.322 (perp=6.168, rec=0.088), tot_loss_proj:1.561 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[ 750/2000] tot_loss=1.326 (perp=6.168, rec=0.093), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.312 (perp=6.168, rec=0.079), tot_loss_proj:1.563 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.325 (perp=6.168, rec=0.092), tot_loss_proj:1.561 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[ 900/2000] tot_loss=1.325 (perp=6.168, rec=0.091), tot_loss_proj:1.563 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.315 (perp=6.168, rec=0.082), tot_loss_proj:1.563 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.315 (perp=6.168, rec=0.082), tot_loss_proj:1.567 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1050/2000] tot_loss=1.322 (perp=6.168, rec=0.089), tot_loss_proj:1.566 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.317 (perp=6.168, rec=0.084), tot_loss_proj:1.558 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.314 (perp=6.168, rec=0.080), tot_loss_proj:1.558 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1200/2000] tot_loss=1.317 (perp=6.168, rec=0.083), tot_loss_proj:1.556 [t=0.27s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.311 (perp=6.168, rec=0.078), tot_loss_proj:1.559 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.301 (perp=6.168, rec=0.067), tot_loss_proj:1.562 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1350/2000] tot_loss=1.310 (perp=6.168, rec=0.076), tot_loss_proj:1.555 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.313 (perp=6.168, rec=0.079), tot_loss_proj:1.561 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.326 (perp=6.168, rec=0.092), tot_loss_proj:1.554 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1500/2000] tot_loss=1.311 (perp=6.168, rec=0.078), tot_loss_proj:1.559 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.309 (perp=6.168, rec=0.076), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.321 (perp=6.168, rec=0.087), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1650/2000] tot_loss=1.323 (perp=6.168, rec=0.090), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.323 (perp=6.168, rec=0.090), tot_loss_proj:1.556 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.311 (perp=6.168, rec=0.078), tot_loss_proj:1.565 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1800/2000] tot_loss=1.320 (perp=6.168, rec=0.086), tot_loss_proj:1.559 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.306 (perp=6.168, rec=0.072), tot_loss_proj:1.558 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.305 (perp=6.168, rec=0.071), tot_loss_proj:1.555 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
[1950/2000] tot_loss=1.319 (perp=6.168, rec=0.086), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.314 (perp=6.168, rec=0.080), tot_loss_proj:1.560 [t=0.26s]
prediction: ['[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately it also s unfortunately not very goodpage. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 35.294 | p: 33.333 | r: 37.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 119.505

[Aggregate metrics]:
rouge1     | fm: 87.783 | p: 86.782 | r: 88.951
rouge2     | fm: 51.134 | p: 50.714 | r: 51.632
rougeL     | fm: 76.454 | p: 75.685 | r: 77.449
rougeLsum  | fm: 76.396 | p: 75.622 | r: 77.368
r1fm+r2fm = 138.917

input #85 time: 0:10:40 | total time: 15:35:47


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.8265901207923889 for ['[CLS] index causewayrigue [SEP]']
[Init] best rec loss: 0.7497624754905701 for ['[CLS] own £100 we [SEP]']
[Init] best perm rec loss: 0.7484012246131897 for ['[CLS] £100 own we [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.520 (perp=11.476, rec=0.224), tot_loss_proj:2.656 [t=0.26s]
prediction: ['[CLS] clarity clarity honesty [SEP]']
[ 100/2000] tot_loss=2.555 (perp=11.793, rec=0.197), tot_loss_proj:2.787 [t=0.27s]
prediction: ['[CLS] clarity clarity emotional [SEP]']
[ 150/2000] tot_loss=2.510 (perp=11.793, rec=0.152), tot_loss_proj:2.778 [t=0.26s]
prediction: ['[CLS] clarity clarity emotional [SEP]']
[ 200/2000] tot_loss=2.497 (perp=11.793, rec=0.139), tot_loss_proj:2.792 [t=0.26s]
prediction: ['[CLS] clarity clarity emotional [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.992 (perp=9.189, rec=0.154), tot_loss_proj:2.050 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 300/2000] tot_loss=1.955 (perp=9.189, rec=0.117), tot_loss_proj:2.061 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.959 (perp=9.189, rec=0.121), tot_loss_proj:2.065 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.968 (perp=9.189, rec=0.130), tot_loss_proj:2.061 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 450/2000] tot_loss=1.947 (perp=9.189, rec=0.109), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.963 (perp=9.189, rec=0.125), tot_loss_proj:2.058 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.940 (perp=9.189, rec=0.102), tot_loss_proj:2.059 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 600/2000] tot_loss=1.954 (perp=9.189, rec=0.116), tot_loss_proj:2.061 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.939 (perp=9.189, rec=0.101), tot_loss_proj:2.055 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.945 (perp=9.189, rec=0.107), tot_loss_proj:2.060 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 750/2000] tot_loss=1.940 (perp=9.189, rec=0.102), tot_loss_proj:2.059 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.943 (perp=9.189, rec=0.105), tot_loss_proj:2.062 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.938 (perp=9.189, rec=0.101), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 900/2000] tot_loss=1.949 (perp=9.189, rec=0.112), tot_loss_proj:2.061 [t=0.26s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.950 (perp=9.189, rec=0.113), tot_loss_proj:2.056 [t=0.25s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.926 (perp=9.123, rec=0.101), tot_loss_proj:2.320 [t=0.24s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[1050/2000] tot_loss=1.917 (perp=9.123, rec=0.092), tot_loss_proj:2.310 [t=0.25s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.901 (perp=9.123, rec=0.076), tot_loss_proj:2.310 [t=0.26s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.909 (perp=9.123, rec=0.084), tot_loss_proj:2.317 [t=0.26s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[1200/2000] tot_loss=1.901 (perp=9.123, rec=0.076), tot_loss_proj:2.311 [t=0.26s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=8.419, rec=0.087), tot_loss_proj:1.922 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.762 (perp=8.419, rec=0.078), tot_loss_proj:1.921 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1350/2000] tot_loss=1.767 (perp=8.419, rec=0.083), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.757 (perp=8.419, rec=0.073), tot_loss_proj:1.924 [t=0.27s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.763 (perp=8.419, rec=0.080), tot_loss_proj:1.914 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1500/2000] tot_loss=1.759 (perp=8.419, rec=0.075), tot_loss_proj:1.920 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.764 (perp=8.419, rec=0.080), tot_loss_proj:1.914 [t=0.27s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.757 (perp=8.419, rec=0.073), tot_loss_proj:1.913 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1650/2000] tot_loss=1.752 (perp=8.419, rec=0.068), tot_loss_proj:1.915 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.419, rec=0.059), tot_loss_proj:1.916 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.762 (perp=8.419, rec=0.079), tot_loss_proj:1.921 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1800/2000] tot_loss=1.757 (perp=8.419, rec=0.073), tot_loss_proj:1.912 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.754 (perp=8.419, rec=0.070), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.755 (perp=8.419, rec=0.072), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1950/2000] tot_loss=1.756 (perp=8.419, rec=0.072), tot_loss_proj:1.919 [t=0.26s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.746 (perp=8.419, rec=0.062), tot_loss_proj:1.918 [t=0.25s]
prediction: ['[CLS] emotional and clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] emotional and clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.929 | p: 86.995 | r: 89.161
rouge2     | fm: 50.582 | p: 50.153 | r: 51.088
rougeL     | fm: 76.251 | p: 75.495 | r: 77.253
rougeLsum  | fm: 76.260 | p: 75.455 | r: 77.205
r1fm+r2fm = 138.510

input #86 time: 0:10:41 | total time: 15:46:28


Running input #87 of 100.
reference: 
========================
propulsive 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8315659165382385 for ['[CLS] hybrids near [SEP]']
[Init] best rec loss: 0.7696642279624939 for ['[CLS] turn cyclists [SEP]']
[Init] best rec loss: 0.7612519860267639 for ['[CLS] outside overs [SEP]']
[Init] best rec loss: 0.6893284320831299 for ['[CLS] track ashes [SEP]']
[Init] best rec loss: 0.6828312277793884 for ['[CLS] ate chaos [SEP]']
[Init] best rec loss: 0.6523114442825317 for ['[CLS] breath hampson [SEP]']
[Init] best rec loss: 0.634991466999054 for ['[CLS]promising himself [SEP]']
[Init] best rec loss: 0.6306449174880981 for ['[CLS]oor women [SEP]']
[Init] best rec loss: 0.6244299411773682 for ['[CLS] entire rather [SEP]']
[Init] best rec loss: 0.6054010391235352 for ['[CLS] blast tend [SEP]']
[Init] best rec loss: 0.6004096865653992 for ['[CLS] or freight [SEP]']
[Init] best perm rec loss: 0.5956635475158691 for ['[CLS] freight or [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.628 (perp=7.258, rec=0.176), tot_loss_proj:1.512 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.539 (perp=7.258, rec=0.088), tot_loss_proj:1.513 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.544 (perp=7.258, rec=0.093), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.519 (perp=7.258, rec=0.067), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.508 (perp=7.258, rec=0.057), tot_loss_proj:1.508 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.508 (perp=7.258, rec=0.057), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.510 (perp=7.258, rec=0.058), tot_loss_proj:1.506 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.515 (perp=7.258, rec=0.064), tot_loss_proj:1.515 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.518 (perp=7.258, rec=0.066), tot_loss_proj:1.509 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.515 (perp=7.258, rec=0.063), tot_loss_proj:1.516 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.520 (perp=7.258, rec=0.069), tot_loss_proj:1.492 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.509 (perp=7.258, rec=0.057), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.522 (perp=7.258, rec=0.071), tot_loss_proj:1.507 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.522 (perp=7.258, rec=0.070), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.512 (perp=7.258, rec=0.060), tot_loss_proj:1.515 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.502 (perp=7.258, rec=0.051), tot_loss_proj:1.521 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.518 (perp=7.258, rec=0.066), tot_loss_proj:1.522 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.522 (perp=7.258, rec=0.070), tot_loss_proj:1.514 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.515 (perp=7.258, rec=0.064), tot_loss_proj:1.503 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.510 (perp=7.258, rec=0.059), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.526 (perp=7.258, rec=0.074), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.505 (perp=7.258, rec=0.054), tot_loss_proj:1.512 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.510 (perp=7.258, rec=0.059), tot_loss_proj:1.510 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.519 (perp=7.258, rec=0.067), tot_loss_proj:1.512 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.515 (perp=7.258, rec=0.063), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.520 (perp=7.258, rec=0.068), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.514 (perp=7.258, rec=0.062), tot_loss_proj:1.513 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.506 (perp=7.258, rec=0.055), tot_loss_proj:1.519 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.516 (perp=7.258, rec=0.065), tot_loss_proj:1.521 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.512 (perp=7.258, rec=0.061), tot_loss_proj:1.508 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.515 (perp=7.258, rec=0.063), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.503 (perp=7.258, rec=0.052), tot_loss_proj:1.519 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.513 (perp=7.258, rec=0.062), tot_loss_proj:1.517 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.513 (perp=7.258, rec=0.061), tot_loss_proj:1.510 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=7.258, rec=0.057), tot_loss_proj:1.524 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.504 (perp=7.258, rec=0.053), tot_loss_proj:1.515 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.503 (perp=7.258, rec=0.051), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.511 (perp=7.258, rec=0.060), tot_loss_proj:1.510 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.507 (perp=7.258, rec=0.056), tot_loss_proj:1.511 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.509 (perp=7.258, rec=0.057), tot_loss_proj:1.518 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.055 | p: 87.063 | r: 89.186
rouge2     | fm: 51.035 | p: 50.625 | r: 51.511
rougeL     | fm: 76.391 | p: 75.611 | r: 77.410
rougeLsum  | fm: 76.500 | p: 75.676 | r: 77.464
r1fm+r2fm = 139.090

input #87 time: 0:10:48 | total time: 15:57:16


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9136743545532227 for ['[CLS] empire flows hair release detached unit medical russian badpatient searching thumbs yin germany trial pie reliable field hugo 14 european [MASK] didulent filed bogota entirely hide straightmann professional spyrangle initial before order busy independence enough audience words hannauated [SEP]']
[Init] best rec loss: 0.9068893194198608 for ['[CLS] front comet maybe beatsign mole exclusive armstrong italian electronic resistance never corporation areatag body memories studentsik dictatorship votesbution slville spielberg montyvo lecturer semi brat the present width foster insulin called doorbell elijah team member possibleitionsit [SEP]']
[Init] best rec loss: 0.9054320454597473 for ['[CLS] payne twin somebody suggest ye stainlessnation live table cleared accomplished ، mode sales asia general bay key holding backup dioxide identify guthrie sum any 1 2015 treatment? miguelrgeon possibleurai proved approx ways season wildcats drained processlift mac only [SEP]']
[Init] best rec loss: 0.8922831416130066 for ['[CLS] these milford stenchium consisted limited amy dinner protocol : dealt japan ride general her real sinai children doll [MASK] suffering helping center hills eagle coward how academy separate poisoncier successbrand vp confronts relegated warp sync leinster luther meaning body transmission [SEP]']
[Init] best rec loss: 0.8916054964065552 for ['[CLS] by regularlydh wilson stein b volleyball rainbow hit internet projectfusion avoided most seminar formula draw radar ju command middle diamond? until workforce anyone closer correspondence potential poster nat straw with shot g mess narrator para drinking classroom programme do steve [SEP]']
[Init] best rec loss: 0.883696436882019 for ['[CLS] forced nucleus busy championships plane may if temple segments secretary dictatorwoe recover lap million dry long vols miguelfication grim 700 self over serial notre yao bengal perfectly fastest applied digital stunts six what gentlyivatingial lent story alma produce [SEP]']
[Init] best perm rec loss: 0.8820112943649292 for ['[CLS] secretary bengal may plane selfwo temple busy millionivating perfectly over digital recover dictator fastest vols grim lent alma applied yao championships notre miguelfication dry six if forcede serial lap gently story nucleus segments 700 what long stunts produceial [SEP]']
[Init] best perm rec loss: 0.8818648457527161 for ['[CLS] self miguel notre serial forced vols perfectly plane over alma 700 fastestwo may gently long digitalial six recoverivating what stunts nucleus segmentse story dry championships dictator temple bengal produce grim secretaryfication lap yao million lent if applied busy [SEP]']
[Init] best perm rec loss: 0.8791196942329407 for ['[CLS] championships gently nucleus busy notree dictator applied may serial alma digital lent fastest story produce recoverial yao temple if million miguel dry long self vols plane grim stunts six secretaryfication bengal over lap what 700 forced perfectlyivating segmentswo [SEP]']
[Init] best perm rec loss: 0.8781852722167969 for ['[CLS] segments if alma million six what may story recover lent self over lap yao 700 produce gentlywo dictatorivating secretarye stunts forced nucleusfication dry plane bengal temple notre busy long perfectly vols digital appliedial championships serial grim fastest miguel [SEP]']
[Init] best perm rec loss: 0.8780543208122253 for ['[CLS] over temple forcedwo may vols dictator recover millionial long yao secretary championships gently dry stunts notre bengalfication story digital serial lent applied grim if busy six perfectly what self segmentse fastest lap produceivating miguel 700 nucleus plane alma [SEP]']
[Init] best perm rec loss: 0.876341700553894 for ['[CLS] if long stuntse vols alma over yao lap plane applied what six championships 700 bengal fastest self miguel dictator recover nucleusfication million busy gentlyivating segments may temple story secretary perfectly lentwo serial forced dry grim notre digitalial produce [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.863 (perp=11.739, rec=0.515), tot_loss_proj:3.253 [t=0.25s]
prediction: ['[CLS]ᵈ shows vivid we nothing westernmmy basically big mo? wheregs stamford the wider sociology into the tommy derby adopted acute beard drummer sentenced melody understanding the west 《 office. silence colin love and occasional skin joy nothingutionmer [SEP]']
[ 100/2000] tot_loss=2.615 (perp=11.025, rec=0.410), tot_loss_proj:3.091 [t=0.25s]
prediction: ['[CLS]ⁿ ( vivid the ( western shit finally big in? where jay great the wider understands of which married underground would hearts lewis sighednism melody understands point beautiful understandslands. was colin battle andcm city.! end happiness [SEP]']
[ 150/2000] tot_loss=2.359 (perp=9.919, rec=0.375), tot_loss_proj:2.866 [t=0.25s]
prediction: ['[CLS]ᵈ the vivid our ( western shit finally big am? how was loved mama means understands andingly you eclectic william encounterhe whose equal melody understands the beautiful understands foreigners.. attitude. and " morning the we ourselves never [SEP]']
[ 200/2000] tot_loss=2.657 (perp=11.376, rec=0.382), tot_loss_proj:3.139 [t=0.26s]
prediction: ['[CLS] lgbt the understands our class session shit thorne hello story? how was joy average enjoys understands find if wouldstellar each our sleeper romantic equal romance understands the grand understands encyclopedia.. attitude girls and " morning\'» we 2016 [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.437 (perp=9.839, rec=0.469), tot_loss_proj:2.863 [t=0.25s]
prediction: ["[CLS]..'metric landscape history b romanticphobic ) understands super wonderful romance graduate because. michael summer and engineer. - onstage album exits 2002. star engineer episode forward. hale instrumental deeply >. the the. wonderful smiles [SEP]"]
[ 300/2000] tot_loss=2.561 (perp=11.073, rec=0.346), tot_loss_proj:3.091 [t=0.26s]
prediction: ["[CLS] features.'0lling year young romanticphobic ) understands plus super love coordinated because. michael summer and 18 • - impossible album exits wayne. star career episode forward shit hale ben deeply ª. his the.ative smiles [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.452 (perp=10.798, rec=0.292), tot_loss_proj:3.048 [t=0.25s]
prediction: ["[CLS] features.'0 robot years young romanticphobic ) understands edwards wonderful love coordinated because. michael summer and 18 • - exits chord onstage wayne. star career episode forward shit hale c deeply!. his the.ative smiles [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.764 (perp=11.450, rec=0.474), tot_loss_proj:3.161 [t=0.25s]
prediction: ['[CLS]ichi. obamaesian ; english t december [CLS] years adolescents ] understand faso wonderful love lewis.. paul summer and londonhom engineer exits values form wayne. actors state episode medical different f william edmonton up the t influences happiness [SEP]']
[ 450/2000] tot_loss=2.701 (perp=11.835, rec=0.334), tot_loss_proj:3.265 [t=0.26s]
prediction: ['[CLS] mike. obamaɨ ) englishyler emotions [CLS] years adolescents ] understand faso wonderful love lewis.. paul summer and cohom engineer exits values creativity wayne. actors states episode spiritual different f william edmonton up the & influences happiness [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.565 (perp=11.090, rec=0.347), tot_loss_proj:3.137 [t=0.26s]
prediction: ['[CLS] jack. obamaɨ the richard from emotions [CLS] years adolescents ] understands faso wonderful love lewis.. paul summer and cohom engineer exits values creativity wayne. creativity & episode spiritual different f william edmonton up ) & influences happiness [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.539 (perp=10.882, rec=0.363), tot_loss_proj:3.073 [t=0.27s]
prediction: ["[CLS] jack, obama julie the leaf adolescents ] understands faso wonderful love lewis.. paul sketch and bankshom engineer exits values creativity wayne jordan from emotions [CLS] the creativity love episode constant because f johnachal'( & influences happiness [SEP]"]
[ 600/2000] tot_loss=2.495 (perp=10.891, rec=0.317), tot_loss_proj:3.092 [t=0.27s]
prediction: ['[CLS] jack, obama oh the leaf? ] understands faso wonderful love lewis.. paul sketch and banks. hormone arch values creativity wayne jordan t emotions [CLS] the creativity love actor constant because f eventuallyachal this of & unique love [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.562 (perp=11.324, rec=0.297), tot_loss_proj:3.195 [t=0.26s]
prediction: ['[CLS] jack, obama oh the years? ] understands faso wonderful romance lewis.. paul sketch and bankshom hormone arch values face wayne jordan t emotions [CLS] the creativity origin actor comfortable because f eventuallyachal of these & unique love [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.491 (perp=11.012, rec=0.289), tot_loss_proj:3.104 [t=0.25s]
prediction: ['[CLS] jack, these oh the graves? ever understands province wonderful romance lewis.. paul sketch and bankshom hormone arch values face wayne jordan t emotions [CLS] the creativity love actor comfortable because f eventuallyachal of obama & unique love [SEP]']
[ 750/2000] tot_loss=2.493 (perp=11.116, rec=0.270), tot_loss_proj:3.121 [t=0.27s]
prediction: ['[CLS] jack, these oh the graves? ever understands province wonderful romance lewis.. paul sketch and bankshom hormone arch values face wayne jordan t emotions [CLS] the creativity love actor comfortable because f william depend of obama & unique love [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.480 (perp=11.043, rec=0.271), tot_loss_proj:3.107 [t=0.25s]
prediction: ['[CLS] jack because these oh the graves? ever understands province wonderful romance lewis.. paul sketch and bankstin hormone arch greatest reality wayne jordan t emotions [CLS] the creativity love episode comfortable, f william depend of obama & unique love [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.448 (perp=10.978, rec=0.252), tot_loss_proj:3.090 [t=0.25s]
prediction: ['[CLS] jack because these oh the graves? ever understands members wonderful romance lewis.. paul [CLS] and bankstin hormone arch greatest breakfast wayne jordan t emotions sketch the creativity love episode comfortable, f william depend of obama & unique love [SEP]']
[ 900/2000] tot_loss=2.413 (perp=10.816, rec=0.250), tot_loss_proj:3.051 [t=0.26s]
prediction: ['[CLS] jack because these oh the graves? ever understands members wonderful romance lewis.. paul [CLS] and *tin hormone arch greatest breakfast kepler jordan t emotions sketch the creativity love personality comfortable, f william depend of obama & powerful love [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.446 (perp=11.014, rec=0.243), tot_loss_proj:3.113 [t=0.26s]
prediction: ['[CLS] jack didn these oh the graves? hearts understands members wonderful romance lewis. & paul [CLS] and *tin hormone arch greatest breakfast kepler jordan t emotions sketch the achievements love personality comfortable, f william depend of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.340 (perp=10.436, rec=0.252), tot_loss_proj:2.976 [t=0.24s]
prediction: ['[CLS] jack didn these oh the graves? hearts understands members great romance lewis. & paul [CLS] f *tin hormone twin greatest breakfast helena jordan t emotions sketch the heroes love personality comfortable, and william depend of obama. powerful love [SEP]']
[1050/2000] tot_loss=2.329 (perp=10.431, rec=0.243), tot_loss_proj:2.984 [t=0.25s]
prediction: ['[CLS] jack didn these oh the graves? hearts understands members great romance lewis. & paul [CLS] f *tin hormone twin greatest breakfast helena jordan t emotions sketch the heroes love episode comfortable, and william depend of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.320 (perp=10.411, rec=0.238), tot_loss_proj:2.972 [t=0.26s]
prediction: ['[CLS] jack great these oh the graves? hearts understands members didn romance lewis. & paul [CLS] f *tin hormone twin greatest breakfast helena jordan t emotions sketch the heroes love episodeious, and william depend of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.323 (perp=10.411, rec=0.241), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS] jack great love oh the understand? hearts understands members didn romance lewis. and paul [CLS] f *tin hormone twin takes breakfast helena jordan t emotions sketch the heroes these phraseious, and william depend of obama. powerful love [SEP]']
[1200/2000] tot_loss=2.323 (perp=10.450, rec=0.232), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] dick great love oh the understand? hearts understands members didn romance lewis. and paul [CLS] f *tin hormone twin draw breakfast helena jordan t emotions sketch the heroes these phraseious, and william depend of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.275 (perp=10.215, rec=0.232), tot_loss_proj:2.953 [t=0.25s]
prediction: ['[CLS] and great love oh the understand? hearts understands members didn romance lewis. and paul [CLS] f *tin hormone twin draw breakfast helena jordan t emotions sketch the achievements these phraseious, dick william depend of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.205 (perp=9.892, rec=0.227), tot_loss_proj:2.874 [t=0.27s]
prediction: ['[CLS] and great love oh the understand? everyone understands members didn romance lewis. and paul [CLS] f *tin hormone twin draw breakfastitaire jordan t emotions sketch the depend these phraseious, dick william achievements of obama. powerful love [SEP]']
[1350/2000] tot_loss=2.184 (perp=9.775, rec=0.229), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS] and great love oh the understand? everyone understands members which romance lewis. and paul [CLS] f *tin hormone twin draw breakfastitaire jordan t emotions sketch the depend these phraseious, dick william achievements of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.169 (perp=9.639, rec=0.241), tot_loss_proj:2.834 [t=0.26s]
prediction: ['[CLS] and great love oh the understand? everyone understands members didn romance lewis sketch and paul [CLS] f * kerman hormone twin draw breakfastitaire jordan t emotions. the depend these phraseious, dick william achievements of obama. powerful love [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.069 (perp=9.151, rec=0.239), tot_loss_proj:2.741 [t=0.25s]
prediction: ['[CLS] and great love oh the understand? everyone understands members which romance emotions sketch and paul [CLS] f * kerman hormone twin draw breakfastitaire jordan t lewis. the depend these phraseious, dick william achievements of obama. wonderful love [SEP]']
[1500/2000] tot_loss=2.060 (perp=9.151, rec=0.229), tot_loss_proj:2.746 [t=0.28s]
prediction: ['[CLS] and great love oh the understand? everyone understands members which romance emotions sketch and paul [CLS] f * kerman hormone twin draw breakfastitaire jordan t lewis. the depend these phraseious, dick william achievements of obama. wonderful love [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.069 (perp=9.142, rec=0.240), tot_loss_proj:2.749 [t=0.26s]
prediction: ['[CLS] and great love oh the understand? everyone understands members which romance emotions sketch and paul [CLS] f * kerman hormone twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. wonderful love [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.044 (perp=9.086, rec=0.227), tot_loss_proj:2.741 [t=0.26s]
prediction: ['[CLS] and great love oh the understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman hormone twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. wonderful love [SEP]']
[1650/2000] tot_loss=2.047 (perp=9.086, rec=0.230), tot_loss_proj:2.741 [t=0.26s]
prediction: ['[CLS] and great love oh the understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman hormone twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. wonderful love [SEP]']
Attempt swap
[1700/2000] tot_loss=2.030 (perp=9.002, rec=0.229), tot_loss_proj:2.723 [t=0.25s]
prediction: ['[CLS] and great love oh the understand? everyone understands which romance emotions members sketch and paul [CLS] f * upon hormone twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. wonderful love [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.066 (perp=9.161, rec=0.234), tot_loss_proj:2.716 [t=0.28s]
prediction: ['[CLS] the great love oh and understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman hormone twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. grand love [SEP]']
[1800/2000] tot_loss=2.064 (perp=9.161, rec=0.232), tot_loss_proj:2.716 [t=0.25s]
prediction: ['[CLS] the great love oh and understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman hormone twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. grand love [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.057 (perp=9.108, rec=0.235), tot_loss_proj:2.685 [t=0.25s]
prediction: ['[CLS] the great love andh understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman. twin draw existenceitaire lewis t jordan. the depend these phraseious, dick william achievements of obama. grand love [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.122 (perp=9.458, rec=0.230), tot_loss_proj:2.736 [t=0.26s]
prediction: ['[CLS] the great love andh understand? everyone understands which romance emotions members sketch and paul [CLS] f * upon. twin takes williamitaire lewis t jordan. the depend these phraseious, dick existence achievements of obama. grand love [SEP]']
[1950/2000] tot_loss=2.081 (perp=9.270, rec=0.227), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] the great love andh understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman. twin takes williamitaire lewis t jordan. the depend these phraseious, dick existence achievements of obama. grand love [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.043 (perp=9.046, rec=0.234), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] the great love and achievements understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman. twin takes williamitaire lewis t jordan. the depend these phraseious, dick existenceh of ]. grand love [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] the great love andh understand? everyone understands which romance emotions members sketch and paul [CLS] f * kerman. twin takes williamitaire lewis t jordan. the depend these phraseious, dick existence achievements of obama. grand love [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 29.730 | p: 30.556 | r: 28.947
rouge2     | fm: 2.778 | p: 2.857 | r: 2.703
rougeL     | fm: 18.919 | p: 19.444 | r: 18.421
rougeLsum  | fm: 18.919 | p: 19.444 | r: 18.421
r1fm+r2fm = 32.508

[Aggregate metrics]:
rouge1     | fm: 87.450 | p: 86.509 | r: 88.589
rouge2     | fm: 50.572 | p: 50.157 | r: 51.064
rougeL     | fm: 75.863 | p: 75.091 | r: 76.807
rougeLsum  | fm: 75.761 | p: 75.033 | r: 76.766
r1fm+r2fm = 138.022

input #88 time: 0:10:52 | total time: 16:08:09


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.8829926252365112 for ['[CLS] pendleton loud over sand tel same constabularyemann arya bug j theatrewide lindseyiated completed tamil vomit sponsor rest core piece cortex [SEP] one remnants wayne him novel access internationalsome [SEP]']
[Init] best rec loss: 0.8568455576896667 for ['[CLS] op likeerved roundutive s i strangerquent dismantled wonderland irelandishly floyd visits shelter he claimed microsoft memberellant extra only matrixdog integrated exercises chat heaving sinai commons mat [SEP]']
[Init] best rec loss: 0.8497462272644043 for ['[CLS] damon combat loans undertook line del that bell cases ceo sites polish rice execution hard so sync rannrral nationtage edinburgh declan so $ory contains cooler ne lift technical maj [SEP]']
[Init] best rec loss: 0.8468186259269714 for ['[CLS] stores leaderde playing mount wantedwysca stephen damage instinct l prizedin positions energytar booth sidedhaling 100 previous administration calm originally lac god universidad citation ko kendra traveled [SEP]']
[Init] best rec loss: 0.8364530205726624 for ['[CLS] school freed latter grandfatherish opposition jagger caravan present drivers constant ; plan closurecian wishingmourip south collision pharaoh aimed traced am premiered karate when rachel minsk features l home [SEP]']
[Init] best rec loss: 0.8323886394500732 for ['[CLS] accepted hare everything marinehand hs among medical taken productions allmusic spin like cameras reaches wrath forbid reading hobby used badhort following raf minimum yen deny tackles stephen gregor graduate think [SEP]']
[Init] best rec loss: 0.8316588997840881 for ['[CLS]back carefully left amber justice notes meter f fitting animation memory balcony sister logan confirmation cloth west introduces tuitionse master⁺ springs speak feeling briefly patriarch has bill broad / hint [SEP]']
[Init] best rec loss: 0.8266626000404358 for ['[CLS] guild note codes bbc route taught seeing if asleep v ivan visibly locomotive ff vegetables billy forceili dominion impulse spencer territory injuries ~ gail east weights status ball mentioned gapur [SEP]']
[Init] best perm rec loss: 0.825794517993927 for ['[CLS] taught ball force guild ga v territory impulse vegetables asleep route bbc seeing weights ff if status injuries mentionedpur ~ spencer note eastili visibly billy dominion locomotive gail codes ivan [SEP]']
[Init] best perm rec loss: 0.8249155879020691 for ['[CLS]pur billy visibly vegetables force impulse asleep ~ mentioned spencer injuries taught weights guild ball dominion seeing v locomotive ivan if ff eastili bbc territory gail codes note route status ga [SEP]']
[Init] best perm rec loss: 0.821834146976471 for ['[CLS] locomotive taught ball status injuries weights ivanili vegetables asleep east codes gail ffpur if impulse spencer seeing bbc ~ v territory dominion force note route visibly guild mentioned billy ga [SEP]']
[Init] best perm rec loss: 0.8217531442642212 for ['[CLS] note seeing v if ~ spencer vegetables taught ivan codes route east impulse status ga visibly force bbc ff weights ball asleepili billy injuries locomotive dominion mentioned territorypur guild gail [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=11.670, rec=0.368), tot_loss_proj:2.997 [t=0.25s]
prediction: ['[CLS] drill worse activities / quantum the assault blame foundhop tactic ; tactic wendy the worse province data conduct or up none. circumstances presented ne ) unconscious one man hidingon [SEP]']
[ 100/2000] tot_loss=2.455 (perp=10.835, rec=0.288), tot_loss_proj:2.940 [t=0.24s]
prediction: ['[CLS] cover worse message worse texas the tape injury made treatment tactic ; tactic chloe the - ideas shiny from and to none - elements ir tactic - occasional mayfield off covering ideas [SEP]']
[ 150/2000] tot_loss=2.537 (perp=11.365, rec=0.264), tot_loss_proj:3.029 [t=0.26s]
prediction: ['[CLS] cover worsem worse across a wrap injury made alexis tactic ; tacticआ the - ideas bu paper, into none - elements formed） - is 場 off covering garion [SEP]']
[ 200/2000] tot_loss=2.616 (perp=11.910, rec=0.234), tot_loss_proj:3.113 [t=0.27s]
prediction: ['[CLS] cover worser worse across the jelly worse created alexis maneuver of tactic tequila theish ideas cannon,, yet none - elements formed= - is ₀ off ofsy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.377 (perp=10.757, rec=0.226), tot_loss_proj:2.793 [t=0.25s]
prediction: ['[CLS] worsem worse picture a” unrest madequisite compared of tactic question the the ideas cannon built or or none - of formed cover= - is 訁 term aroundsy [SEP]']
[ 300/2000] tot_loss=2.458 (perp=11.226, rec=0.213), tot_loss_proj:3.002 [t=0.27s]
prediction: ['[CLS] worse far worse picture a soccer existed core0sy of tactic situation the the ideas thirty built or or none - of formed cover= - [SEP]₤ yet aroundsy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.355 (perp=10.794, rec=0.197), tot_loss_proj:2.831 [t=0.27s]
prediction: ['[CLS] worse far worse picture a picture or core0 compared of tactic situation upd ideas - fl doesn - none - core constructed cover= - yetzziness yet aroundsy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.236 (perp=10.284, rec=0.179), tot_loss_proj:2.682 [t=0.25s]
prediction: ['[CLS] worseor worse picture a picture or core0sy tactic of situation factd ideas ofim doesn - none - core constructed cover= - yet yet yet aroundsy [SEP]']
[ 450/2000] tot_loss=2.246 (perp=10.365, rec=0.174), tot_loss_proj:2.711 [t=0.26s]
prediction: ['[CLS] worseor worse picture the picture or core0sy tactic of picture factd ideas ofim doesn - none - core constructed cover brute - yet yet yet aroundsy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.164 (perp=9.990, rec=0.166), tot_loss_proj:2.639 [t=0.26s]
prediction: ['[CLS] worseor core picture the picture or worse0 compared tactic picture picture facting ideas ofimsten - none - core constructed cover brute - yet yet yet aroundsy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.071 (perp=9.564, rec=0.158), tot_loss_proj:2.673 [t=0.26s]
prediction: ['[CLS] worseor core picture the picture or worse0sy tactic picture picture factd ideas ofimsten - - core constructed cover= -, yet yet none aroundsy [SEP]']
[ 600/2000] tot_loss=2.197 (perp=10.223, rec=0.152), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] worseul core picture the picture or worse0sy tactic picture picture factxi ideas ofimsten - - core constructed cover quite -, yet yet none aroundsy [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.017 (perp=9.329, rec=0.151), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS] worseor core picture the picture or worse0 compared tactic picture picture factxisten ideas ofim - - core constructed cover quite -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.961 (perp=9.033, rec=0.154), tot_loss_proj:2.579 [t=0.25s]
prediction: ['[CLS] worseer core picture the picture or flo compared tactic core picture factxisten ideas ofim - - picture constructed cover - -, yet yet none aroundsy [SEP]']
[ 750/2000] tot_loss=2.007 (perp=9.309, rec=0.145), tot_loss_proj:2.634 [t=0.27s]
prediction: ['[CLS] worseer core picture the picture or flted compared tactic core picture factxisten ideas ofim - - picture constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.035 (perp=9.458, rec=0.143), tot_loss_proj:2.660 [t=0.25s]
prediction: ['[CLS] worser ideas picture the picture or flted compared tactic core picture factxistenchment ofim - - picture constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.978 (perp=9.181, rec=0.142), tot_loss_proj:2.609 [t=0.26s]
prediction: ['[CLS] worser ideas picture a picture or flted compared tactic picture picture factxistenchment ofim - - core constructed cover - -, yet yet none aroundsy [SEP]']
[ 900/2000] tot_loss=2.147 (perp=9.763, rec=0.194), tot_loss_proj:2.761 [t=0.25s]
prediction: ['[CLS] worser ideas picture a picture or fl office honest tactic geo picture factxisten engined ofim - - core constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.149 (perp=9.942, rec=0.161), tot_loss_proj:2.826 [t=0.27s]
prediction: ['[CLS] worses ideas picture fact the a picture or fl muscle honest tactic isxisten ■ ofim - - core constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.994 (perp=9.219, rec=0.150), tot_loss_proj:2.682 [t=0.25s]
prediction: ['[CLS] worsere ideas picture fact the a picture or fl wrist core tactic isxisten core ofim - - honest constructed cover - -, yet yet none aroundsy [SEP]']
[1050/2000] tot_loss=2.037 (perp=9.503, rec=0.137), tot_loss_proj:2.733 [t=0.25s]
prediction: ['[CLS] worser ideas picture fact the a picture or fl wrist core tactic isxisten ■ ofim - - honest constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.956 (perp=9.108, rec=0.135), tot_loss_proj:2.646 [t=0.25s]
prediction: ['[CLS] worser ideas picture the fact a picture or fl wrist core tactic isxisten ■ ofim - - honest constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.951 (perp=9.055, rec=0.140), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] worser ideas picture the fact a picture or fl wrist core tactic isxisten ofctedim - - honest constructed cover - -, yet yet none aroundsy [SEP]']
[1200/2000] tot_loss=2.017 (perp=9.378, rec=0.142), tot_loss_proj:2.644 [t=0.28s]
prediction: ['[CLS] worse - ideas picture the fact a picture or fl wrist core tactic isxisten ofctedim - - honest constructed cover - -, yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.087 (perp=9.788, rec=0.129), tot_loss_proj:2.750 [t=0.28s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic isstensten ofctedim - - honest constructed cover - - the yet yet none aroundsy [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.049 (perp=9.586, rec=0.132), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic isstenstenchment ofim - - honest constructed cover - - the yet yet none aroundsy [SEP]']
[1350/2000] tot_loss=2.052 (perp=9.586, rec=0.134), tot_loss_proj:2.654 [t=0.25s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic isstenstenchment ofim - - honest constructed cover - - the yet yet none aroundsy [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.964 (perp=9.197, rec=0.124), tot_loss_proj:2.582 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic thestenstenchment ofim - - honest constructed cover - - is yet yet none aroundsy [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.951 (perp=9.112, rec=0.129), tot_loss_proj:2.492 [t=0.28s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic thestenstenchment ofim - - honest constructed cover - - is yet none yet aroundsy [SEP]']
[1500/2000] tot_loss=1.955 (perp=9.112, rec=0.132), tot_loss_proj:2.493 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic thestenstenchment ofim - - honest constructed cover - - is yet none yet aroundsy [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.930 (perp=8.994, rec=0.131), tot_loss_proj:2.650 [t=0.25s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist core tactic thestenstenchment ofim - - is honest constructed cover - - yet none yet aroundsy [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.916 (perp=8.910, rec=0.134), tot_loss_proj:2.626 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist the tactic corestenstenchment ofim - - is honest constructed cover - - yet none yet aroundsy [SEP]']
[1650/2000] tot_loss=1.910 (perp=8.910, rec=0.128), tot_loss_proj:2.628 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist the tactic corestenstenchment ofim - - is honest constructed cover - - yet none yet aroundsy [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.913 (perp=8.910, rec=0.131), tot_loss_proj:2.630 [t=0.28s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist the tactic corestenstenchment ofim - - is honest constructed cover - - yet none yet aroundsy [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.893 (perp=8.807, rec=0.132), tot_loss_proj:2.609 [t=0.25s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist the tactic corestenstenchment ofim - - is honest cover constructed - - yet none yet aroundsy [SEP]']
[1800/2000] tot_loss=1.897 (perp=8.807, rec=0.136), tot_loss_proj:2.606 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact a picture or fl wrist the tactic corestenstenchment ofim - - is honest cover constructed - - yet none yet aroundsy [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.834 (perp=8.515, rec=0.131), tot_loss_proj:2.561 [t=0.27s]
prediction: ['[CLS] worse, ideas picture the fact of a picture or fl wrist the tactic corestenstenchmentim - - is honest cover constructed - - yet none yet aroundsy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.829 (perp=8.515, rec=0.126), tot_loss_proj:2.562 [t=0.25s]
prediction: ['[CLS] worse, ideas picture the fact of a picture or fl wrist the tactic corestenstenchmentim - - is honest cover constructed - - yet none yet aroundsy [SEP]']
[1950/2000] tot_loss=1.834 (perp=8.515, rec=0.131), tot_loss_proj:2.562 [t=0.26s]
prediction: ['[CLS] worse, ideas picture the fact of a picture or fl wrist the tactic corestenstenchmentim - - is honest cover constructed - - yet none yet aroundsy [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.816 (perp=8.478, rec=0.120), tot_loss_proj:2.554 [t=0.25s]
prediction: ['[CLS] worse, ideas picture the fact of a picture or fl tactic the wrist corestenstenchmentim - - is honest cover constructed - - yet none yet aroundsy [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] worse, ideas picture the fact of a picture or fl tactic the wrist corestenstenchmentim - - is honest cover constructed - - yet none yet aroundsy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.085 | p: 66.667 | r: 69.565
rouge2     | fm: 4.444 | p: 4.348 | r: 4.545
rougeL     | fm: 34.043 | p: 33.333 | r: 34.783
rougeLsum  | fm: 34.043 | p: 33.333 | r: 34.783
r1fm+r2fm = 72.530

[Aggregate metrics]:
rouge1     | fm: 87.224 | p: 86.317 | r: 88.350
rouge2     | fm: 50.230 | p: 49.848 | r: 50.752
rougeL     | fm: 75.374 | p: 74.668 | r: 76.343
rougeLsum  | fm: 75.432 | p: 74.625 | r: 76.346
r1fm+r2fm = 137.455

input #89 time: 0:10:54 | total time: 16:19:04


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8982059955596924 for ['[CLS] somethinglusion sh suit track warwick [SEP]']
[Init] best rec loss: 0.8877499103546143 for ['[CLS]ishly prior eyes resigned e vince [SEP]']
[Init] best rec loss: 0.8778479099273682 for ['[CLS]go rebranded long rt lay player [SEP]']
[Init] best rec loss: 0.8621727824211121 for ['[CLS] city foul title story buying fill [SEP]']
[Init] best rec loss: 0.84124356508255 for ['[CLS] elk certain world shot knife barrier [SEP]']
[Init] best rec loss: 0.8383416533470154 for ['[CLS] vis numerous device easy music members [SEP]']
[Init] best rec loss: 0.8150080442428589 for ['[CLS] force of flying low photo circuit [SEP]']
[Init] best perm rec loss: 0.8123126029968262 for ['[CLS] circuit of photo flying low force [SEP]']
[Init] best perm rec loss: 0.8118799924850464 for ['[CLS] low of circuit flying photo force [SEP]']
[Init] best perm rec loss: 0.8116487860679626 for ['[CLS] flying low of photo circuit force [SEP]']
[Init] best perm rec loss: 0.8114575147628784 for ['[CLS] low circuit flying of photo force [SEP]']
[Init] best perm rec loss: 0.8105051517486572 for ['[CLS] of force low circuit photo flying [SEP]']
[Init] best perm rec loss: 0.81013423204422 for ['[CLS] low photo force flying of circuit [SEP]']
[Init] best perm rec loss: 0.8094968795776367 for ['[CLS] photo circuit of force low flying [SEP]']
[Init] best perm rec loss: 0.8077893853187561 for ['[CLS] flying of circuit force low photo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.949 (perp=8.789, rec=0.191), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] money ridiculous and how how ridiculous [SEP]']
[ 100/2000] tot_loss=2.664 (perp=12.650, rec=0.134), tot_loss_proj:2.971 [t=0.25s]
prediction: ['[CLS] money ridiculous oriented how oriented ridiculous [SEP]']
[ 150/2000] tot_loss=2.511 (perp=12.095, rec=0.091), tot_loss_proj:2.917 [t=0.27s]
prediction: ['[CLS] money ridiculous oriented how and ridiculous [SEP]']
[ 200/2000] tot_loss=2.495 (perp=12.095, rec=0.076), tot_loss_proj:2.918 [t=0.26s]
prediction: ['[CLS] money ridiculous oriented how and ridiculous [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.724 (perp=8.095, rec=0.105), tot_loss_proj:1.957 [t=0.27s]
prediction: ['[CLS] money how ridiculous oriented and ridiculous [SEP]']
[ 300/2000] tot_loss=1.701 (perp=8.095, rec=0.082), tot_loss_proj:1.956 [t=0.26s]
prediction: ['[CLS] money how ridiculous oriented and ridiculous [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.577 (perp=7.455, rec=0.086), tot_loss_proj:1.788 [t=0.27s]
prediction: ['[CLS] money how ridiculous and ridiculous oriented [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.568 (perp=7.455, rec=0.077), tot_loss_proj:1.781 [t=0.26s]
prediction: ['[CLS] money how ridiculous and ridiculous oriented [SEP]']
[ 450/2000] tot_loss=2.026 (perp=9.797, rec=0.066), tot_loss_proj:2.691 [t=0.25s]
prediction: ['[CLS] money how - and ridiculous oriented [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.741 (perp=8.355, rec=0.070), tot_loss_proj:2.129 [t=0.26s]
prediction: ['[CLS] money how ridiculous and - oriented [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.543 (perp=7.391, rec=0.065), tot_loss_proj:1.727 [t=0.27s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[ 600/2000] tot_loss=1.543 (perp=7.391, rec=0.064), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.432 (perp=6.870, rec=0.058), tot_loss_proj:1.567 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.447 (perp=6.870, rec=0.073), tot_loss_proj:1.560 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.432 (perp=6.870, rec=0.058), tot_loss_proj:1.565 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.431 (perp=6.870, rec=0.057), tot_loss_proj:1.569 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.439 (perp=6.870, rec=0.065), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.435 (perp=6.870, rec=0.061), tot_loss_proj:1.579 [t=0.29s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.424 (perp=6.870, rec=0.050), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.438 (perp=6.870, rec=0.065), tot_loss_proj:1.567 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.436 (perp=6.870, rec=0.063), tot_loss_proj:1.573 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.438 (perp=6.870, rec=0.064), tot_loss_proj:1.570 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.429 (perp=6.870, rec=0.055), tot_loss_proj:1.574 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.442 (perp=6.870, rec=0.068), tot_loss_proj:1.574 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.567 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.574 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.430 (perp=6.870, rec=0.056), tot_loss_proj:1.572 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.436 (perp=6.870, rec=0.063), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.442 (perp=6.870, rec=0.068), tot_loss_proj:1.576 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.426 (perp=6.870, rec=0.052), tot_loss_proj:1.576 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.441 (perp=6.870, rec=0.067), tot_loss_proj:1.575 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.441 (perp=6.870, rec=0.067), tot_loss_proj:1.583 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.439 (perp=6.870, rec=0.065), tot_loss_proj:1.581 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.429 (perp=6.870, rec=0.055), tot_loss_proj:1.572 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.435 (perp=6.870, rec=0.061), tot_loss_proj:1.577 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.577 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.440 (perp=6.870, rec=0.066), tot_loss_proj:1.576 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.436 (perp=6.870, rec=0.062), tot_loss_proj:1.574 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.438 (perp=6.870, rec=0.064), tot_loss_proj:1.579 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.416 | p: 86.479 | r: 88.576
rouge2     | fm: 50.682 | p: 50.251 | r: 51.175
rougeL     | fm: 75.675 | p: 74.960 | r: 76.596
rougeLsum  | fm: 75.647 | p: 74.958 | r: 76.621
r1fm+r2fm = 138.098

input #90 time: 0:10:41 | total time: 16:29:45


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.851560652256012 for ['[CLS] how yesterdayging open layton worn con teeth [SEP]']
[Init] best rec loss: 0.8007078170776367 for ['[CLS] creaturesounded points bank you samuel some uses [SEP]']
[Init] best rec loss: 0.7518479228019714 for ['[CLS] fieldwrite gretchen foundation thesis please cable waters [SEP]']
[Init] best rec loss: 0.6704030632972717 for ['[CLS] stand else ivy comedy neo whatever tiger backwards [SEP]']
[Init] best rec loss: 0.6684643626213074 for ['[CLS] whilecock mali crashed canon base red higher [SEP]']
[Init] best rec loss: 0.6595842838287354 for ['[CLS] pop feeding being. metropolitan phenomenonham sheriff [SEP]']
[Init] best perm rec loss: 0.6581763029098511 for ['[CLS]. metropolitanham pop feeding phenomenon being sheriff [SEP]']
[Init] best perm rec loss: 0.6568760275840759 for ['[CLS] feeding being metropolitanham. sheriff pop phenomenon [SEP]']
[Init] best perm rec loss: 0.6567500829696655 for ['[CLS] being popham. sheriff metropolitan phenomenon feeding [SEP]']
[Init] best perm rec loss: 0.6560449600219727 for ['[CLS] pop being. metropolitan feeding phenomenonham sheriff [SEP]']
[Init] best perm rec loss: 0.6543173789978027 for ['[CLS]. being sheriff phenomenon pop metropolitanham feeding [SEP]']
[Init] best perm rec loss: 0.6540137529373169 for ['[CLS] metropolitan phenomenon sheriff popham. being feeding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.179 (perp=9.493, rec=0.280), tot_loss_proj:2.408 [t=0.25s]
prediction: ['[CLS] loco loco, less ridiculous but less loco [SEP]']
[ 100/2000] tot_loss=2.248 (perp=10.453, rec=0.158), tot_loss_proj:2.530 [t=0.25s]
prediction: ['[CLS] loco locoy more ridiculous but more loco [SEP]']
[ 150/2000] tot_loss=2.340 (perp=11.088, rec=0.123), tot_loss_proj:2.702 [t=0.24s]
prediction: ['[CLS] mu locoyy ridiculous no more loco [SEP]']
[ 200/2000] tot_loss=2.326 (perp=11.088, rec=0.108), tot_loss_proj:2.697 [t=0.24s]
prediction: ['[CLS] mu locoyy ridiculous no more loco [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.098 (perp=10.005, rec=0.097), tot_loss_proj:2.528 [t=0.25s]
prediction: ['[CLS] mu locoy ridiculous but no more loco [SEP]']
[ 300/2000] tot_loss=2.080 (perp=10.005, rec=0.079), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] mu locoy ridiculous but no more loco [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.890 (perp=9.146, rec=0.061), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] mu,y but no more loco ridiculous [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.611 (perp=7.715, rec=0.068), tot_loss_proj:1.855 [t=0.25s]
prediction: ['[CLS] muy, but no more loco ridiculous [SEP]']
[ 450/2000] tot_loss=1.608 (perp=7.715, rec=0.065), tot_loss_proj:1.840 [t=0.26s]
prediction: ['[CLS] muy, but no more loco ridiculous [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.555 (perp=7.488, rec=0.057), tot_loss_proj:1.591 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.552 (perp=7.488, rec=0.054), tot_loss_proj:1.590 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 600/2000] tot_loss=1.569 (perp=7.488, rec=0.072), tot_loss_proj:1.592 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.549 (perp=7.488, rec=0.052), tot_loss_proj:1.587 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.558 (perp=7.488, rec=0.061), tot_loss_proj:1.588 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.555 (perp=7.488, rec=0.057), tot_loss_proj:1.581 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.543 (perp=7.488, rec=0.046), tot_loss_proj:1.580 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.549 (perp=7.488, rec=0.052), tot_loss_proj:1.584 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.564 (perp=7.488, rec=0.066), tot_loss_proj:1.590 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.558 (perp=7.488, rec=0.060), tot_loss_proj:1.585 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.551 (perp=7.488, rec=0.053), tot_loss_proj:1.574 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.551 (perp=7.488, rec=0.053), tot_loss_proj:1.585 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.562 (perp=7.488, rec=0.064), tot_loss_proj:1.582 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.562 (perp=7.488, rec=0.065), tot_loss_proj:1.585 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.566 (perp=7.488, rec=0.068), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.488, rec=0.052), tot_loss_proj:1.584 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.554 (perp=7.488, rec=0.056), tot_loss_proj:1.586 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.558 (perp=7.488, rec=0.060), tot_loss_proj:1.588 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.559 (perp=7.488, rec=0.061), tot_loss_proj:1.587 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.559 (perp=7.488, rec=0.061), tot_loss_proj:1.583 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.559 (perp=7.488, rec=0.061), tot_loss_proj:1.587 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.488, rec=0.061), tot_loss_proj:1.577 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.561 (perp=7.488, rec=0.063), tot_loss_proj:1.588 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.558 (perp=7.488, rec=0.061), tot_loss_proj:1.582 [t=0.26s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.551 (perp=7.488, rec=0.053), tot_loss_proj:1.580 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.488, rec=0.061), tot_loss_proj:1.586 [t=0.27s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.563 (perp=7.488, rec=0.065), tot_loss_proj:1.587 [t=0.35s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.560 (perp=7.488, rec=0.062), tot_loss_proj:1.586 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.560 (perp=7.488, rec=0.063), tot_loss_proj:1.576 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.488, rec=0.058), tot_loss_proj:1.581 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.553 (perp=7.488, rec=0.055), tot_loss_proj:1.577 [t=0.25s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.490 | p: 86.589 | r: 88.661
rouge2     | fm: 51.283 | p: 50.856 | r: 51.804
rougeL     | fm: 76.022 | p: 75.245 | r: 76.956
rougeLsum  | fm: 75.804 | p: 75.069 | r: 76.744
r1fm+r2fm = 138.773

input #91 time: 0:10:51 | total time: 16:40:36


Running input #92 of 100.
reference: 
========================
deceit 
========================
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 1.0091603994369507 for ['[CLS] wasp extra [SEP]']
[Init] best rec loss: 0.9201873540878296 for ['[CLS] sitative [SEP]']
[Init] best rec loss: 0.8332759141921997 for ['[CLS] torre curves [SEP]']
[Init] best rec loss: 0.7845937013626099 for ['[CLS]idotones [SEP]']
[Init] best rec loss: 0.7651355862617493 for ['[CLS]ential jonah [SEP]']
[Init] best rec loss: 0.735571563243866 for ['[CLS] punk gi [SEP]']
[Init] best rec loss: 0.7232293486595154 for ['[CLS] politiciantus [SEP]']
[Init] best rec loss: 0.7216126918792725 for ['[CLS] your anne [SEP]']
[Init] best perm rec loss: 0.7181279063224792 for ['[CLS] anne your [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.911 (perp=13.691, rec=0.173), tot_loss_proj:3.455 [t=0.25s]
prediction: ['[CLS]eiteit [SEP]']
[ 100/2000] tot_loss=1.607 (perp=7.647, rec=0.078), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.589 (perp=7.647, rec=0.060), tot_loss_proj:1.590 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.582 (perp=7.647, rec=0.053), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.583 (perp=7.647, rec=0.053), tot_loss_proj:1.603 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.601 (perp=7.647, rec=0.072), tot_loss_proj:1.586 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.598 (perp=7.647, rec=0.068), tot_loss_proj:1.592 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.593 (perp=7.647, rec=0.064), tot_loss_proj:1.601 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.598 (perp=7.647, rec=0.069), tot_loss_proj:1.587 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.585 (perp=7.647, rec=0.056), tot_loss_proj:1.594 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.647, rec=0.060), tot_loss_proj:1.596 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.647, rec=0.064), tot_loss_proj:1.600 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.589 (perp=7.647, rec=0.059), tot_loss_proj:1.598 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.602 (perp=7.647, rec=0.072), tot_loss_proj:1.601 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.592 (perp=7.647, rec=0.063), tot_loss_proj:1.596 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.647, rec=0.058), tot_loss_proj:1.599 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.599 (perp=7.647, rec=0.070), tot_loss_proj:1.592 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.588 (perp=7.647, rec=0.059), tot_loss_proj:1.595 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.592 (perp=7.647, rec=0.063), tot_loss_proj:1.591 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.598 (perp=7.647, rec=0.068), tot_loss_proj:1.602 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.647, rec=0.068), tot_loss_proj:1.597 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.580 (perp=7.647, rec=0.050), tot_loss_proj:1.581 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.598 (perp=7.647, rec=0.069), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.582 (perp=7.647, rec=0.053), tot_loss_proj:1.587 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.590 (perp=7.647, rec=0.060), tot_loss_proj:1.591 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.588 (perp=7.647, rec=0.059), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.594 (perp=7.647, rec=0.065), tot_loss_proj:1.592 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.582 (perp=7.647, rec=0.053), tot_loss_proj:1.592 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.597 (perp=7.647, rec=0.068), tot_loss_proj:1.582 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.647, rec=0.056), tot_loss_proj:1.591 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=7.647, rec=0.068), tot_loss_proj:1.589 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.647, rec=0.060), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.647, rec=0.063), tot_loss_proj:1.590 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.592 (perp=7.647, rec=0.063), tot_loss_proj:1.586 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.580 (perp=7.647, rec=0.051), tot_loss_proj:1.582 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.585 (perp=7.647, rec=0.055), tot_loss_proj:1.597 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.599 (perp=7.647, rec=0.070), tot_loss_proj:1.597 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.588 (perp=7.647, rec=0.059), tot_loss_proj:1.588 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.585 (perp=7.647, rec=0.056), tot_loss_proj:1.583 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.581 (perp=7.647, rec=0.051), tot_loss_proj:1.589 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.591 | p: 86.730 | r: 88.730
rouge2     | fm: 51.574 | p: 51.176 | r: 52.028
rougeL     | fm: 76.188 | p: 75.430 | r: 77.116
rougeLsum  | fm: 76.138 | p: 75.409 | r: 77.035
r1fm+r2fm = 139.165

input #92 time: 0:10:54 | total time: 16:51:30


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9656373262405396 for ['[CLS]hawk originally maybe classified recordedgel july [SEP]']
[Init] best rec loss: 0.9131870865821838 for ['[CLS] climb corporationfield stood teamed names center [SEP]']
[Init] best rec loss: 0.8931336998939514 for ['[CLS] orderulate racial pal chuckkowley [SEP]']
[Init] best rec loss: 0.8590894341468811 for ['[CLS] way goes every walkingceaeuca including [SEP]']
[Init] best perm rec loss: 0.8586786985397339 for ['[CLS] goes walkingceae way including everyuca [SEP]']
[Init] best perm rec loss: 0.8584739565849304 for ['[CLS] goes walking wayuca every includingceae [SEP]']
[Init] best perm rec loss: 0.8583018779754639 for ['[CLS] goes way includingceaeuca every walking [SEP]']
[Init] best perm rec loss: 0.8569874167442322 for ['[CLS] includingceae every wayuca walking goes [SEP]']
[Init] best perm rec loss: 0.8569692969322205 for ['[CLS] wayceae walking every includinguca goes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.963 (perp=11.096, rec=0.743), tot_loss_proj:3.155 [t=0.26s]
prediction: ['[CLS] for pray winning sunday • combinationsite [SEP]']
[ 100/2000] tot_loss=2.912 (perp=11.202, rec=0.671), tot_loss_proj:3.118 [t=0.26s]
prediction: ['[CLS] the subjected [SEP] when development printed license [SEP]']
[ 150/2000] tot_loss=2.895 (perp=11.054, rec=0.684), tot_loss_proj:3.112 [t=0.25s]
prediction: ['[CLS] the merely spielbergscent development propaganda prior [SEP]']
[ 200/2000] tot_loss=3.086 (perp=12.721, rec=0.541), tot_loss_proj:3.467 [t=0.28s]
prediction: ['[CLS] pines merely spielberg reception how fantasy say [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.858 (perp=11.763, rec=0.506), tot_loss_proj:3.261 [t=0.26s]
prediction: ['[CLS] zev merely how often faith propaganda way [SEP]']
[ 300/2000] tot_loss=2.940 (perp=11.419, rec=0.656), tot_loss_proj:3.331 [t=0.28s]
prediction: ['[CLS] zev attitude how often faith funny way [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.773 (perp=11.463, rec=0.481), tot_loss_proj:3.434 [t=0.25s]
prediction: ['[CLS] zev funny how often faith way sure [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.449 (perp=9.965, rec=0.456), tot_loss_proj:3.042 [t=0.25s]
prediction: ['[CLS] faith zev funny how often way funny [SEP]']
[ 450/2000] tot_loss=2.785 (perp=12.063, rec=0.372), tot_loss_proj:3.555 [t=0.25s]
prediction: ['[CLS] sometimes signature whose often often way funny [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.622 (perp=11.221, rec=0.378), tot_loss_proj:3.227 [t=0.28s]
prediction: ['[CLS] whose signature sometimes when often way sometimes [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.376 (perp=10.204, rec=0.335), tot_loss_proj:3.153 [t=0.27s]
prediction: ['[CLS] whose signature sometimes often often way funny [SEP]']
[ 600/2000] tot_loss=2.517 (perp=10.975, rec=0.322), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] whose signature sometimes far often way funny [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.370 (perp=10.271, rec=0.316), tot_loss_proj:3.205 [t=0.26s]
prediction: ['[CLS] whose signature far sometimes often way funny [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.316 (perp=10.099, rec=0.296), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] whose signature far sometimes often funny way [SEP]']
[ 750/2000] tot_loss=2.620 (perp=11.644, rec=0.291), tot_loss_proj:3.473 [t=0.27s]
prediction: ['[CLS] its signature knowledge sometimes often funny way [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.465 (perp=10.894, rec=0.287), tot_loss_proj:3.242 [t=0.25s]
prediction: ['[CLS] its signature knowledge sometimes often way funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.497 (perp=11.082, rec=0.281), tot_loss_proj:3.256 [t=0.26s]
prediction: ['[CLS] itsius knowledge sometimes often way funny [SEP]']
[ 900/2000] tot_loss=2.683 (perp=11.319, rec=0.419), tot_loss_proj:3.395 [t=0.26s]
prediction: ['[CLS] its truly knowledge▪ often way funny [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.405 (perp=10.404, rec=0.324), tot_loss_proj:3.186 [t=0.25s]
prediction: ['[CLS]▪ truly knowledge its often way funny [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.204 (perp=9.452, rec=0.313), tot_loss_proj:2.723 [t=0.27s]
prediction: ['[CLS]▪ truly understanding its often funny way [SEP]']
[1050/2000] tot_loss=2.437 (perp=10.731, rec=0.290), tot_loss_proj:3.179 [t=0.26s]
prediction: ['[CLS]▪ although understanding its often funny way [SEP]']
Attempt swap
Put prefix at the end
[1100/2000] tot_loss=2.261 (perp=9.820, rec=0.297), tot_loss_proj:2.926 [t=0.26s]
prediction: ['[CLS] although understanding its often funny way▪ [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.136 (perp=9.188, rec=0.299), tot_loss_proj:2.854 [t=0.25s]
prediction: ['[CLS] understanding its often funny way▪ ( [SEP]']
[1200/2000] tot_loss=2.281 (perp=10.005, rec=0.280), tot_loss_proj:2.982 [t=0.27s]
prediction: ['[CLS] knowledge its often funny way▪ ( [SEP]']
Attempt swap
[1250/2000] tot_loss=2.287 (perp=10.005, rec=0.287), tot_loss_proj:2.986 [t=0.25s]
prediction: ['[CLS] knowledge its often funny way▪ ( [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.284 (perp=10.051, rec=0.274), tot_loss_proj:2.982 [t=0.24s]
prediction: ['[CLS] knowledge its often▪ funny way ( [SEP]']
[1350/2000] tot_loss=2.289 (perp=10.051, rec=0.279), tot_loss_proj:2.984 [t=0.26s]
prediction: ['[CLS] knowledge its often▪ funny way ( [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.227 (perp=9.742, rec=0.278), tot_loss_proj:2.964 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1450/2000] tot_loss=2.221 (perp=9.742, rec=0.273), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
[1500/2000] tot_loss=2.217 (perp=9.742, rec=0.269), tot_loss_proj:2.965 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1550/2000] tot_loss=2.219 (perp=9.742, rec=0.270), tot_loss_proj:2.966 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1600/2000] tot_loss=2.217 (perp=9.742, rec=0.269), tot_loss_proj:2.967 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
[1650/2000] tot_loss=2.221 (perp=9.742, rec=0.273), tot_loss_proj:2.966 [t=0.26s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1700/2000] tot_loss=2.219 (perp=9.742, rec=0.270), tot_loss_proj:2.963 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1750/2000] tot_loss=2.220 (perp=9.742, rec=0.272), tot_loss_proj:2.964 [t=0.27s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
[1800/2000] tot_loss=2.213 (perp=9.742, rec=0.265), tot_loss_proj:2.969 [t=0.26s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1850/2000] tot_loss=2.210 (perp=9.742, rec=0.262), tot_loss_proj:2.968 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[1900/2000] tot_loss=2.212 (perp=9.742, rec=0.264), tot_loss_proj:2.966 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
[1950/2000] tot_loss=2.210 (perp=9.742, rec=0.262), tot_loss_proj:2.961 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Attempt swap
[2000/2000] tot_loss=2.205 (perp=9.742, rec=0.257), tot_loss_proj:2.964 [t=0.25s]
prediction: ['[CLS] knowledge▪ its often funny way ( [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] knowledge▪ its often funny way ( [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 87.598 | p: 86.734 | r: 88.631
rouge2     | fm: 51.680 | p: 51.274 | r: 52.132
rougeL     | fm: 76.227 | p: 75.543 | r: 77.040
rougeLsum  | fm: 76.182 | p: 75.491 | r: 77.009
r1fm+r2fm = 139.278

input #93 time: 0:10:49 | total time: 17:02:20


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9673216938972473 for ['[CLS] powers mixturebel meanwhile barrels affected fruit hope killard carrying [SEP]']
[Init] best rec loss: 0.9435511827468872 for ['[CLS]tifydana vibrated noise treaty acquired involved jon build meeting neck [SEP]']
[Init] best rec loss: 0.9382058382034302 for ['[CLS] intelligent considered modern story load flying always often ended champion chicago [SEP]']
[Init] best rec loss: 0.9217443466186523 for ['[CLS] alla joe collection males spring highway beaches burnsmmsu modern [SEP]']
[Init] best rec loss: 0.9186338782310486 for ['[CLS] bi os ip geo " name depression remain tree able situation [SEP]']
[Init] best rec loss: 0.9178540706634521 for ['[CLS] monastery setup agencyđ crossed jersey geoffreyova willowz laurel [SEP]']
[Init] best rec loss: 0.91544109582901 for ['[CLS] julian worth $ elena dimitriscriptfinsmith emily awards miss [SEP]']
[Init] best rec loss: 0.914986789226532 for ['[CLS] anna drew offset dale last turbinesad sports saved agatha traditionally [SEP]']
[Init] best perm rec loss: 0.9131170511245728 for ['[CLS] drew sports dale last traditionally agatha saved annaad turbines offset [SEP]']
[Init] best perm rec loss: 0.9115265607833862 for ['[CLS] dale sports offsetad turbines anna last agatha traditionally saved drew [SEP]']
[Init] best perm rec loss: 0.9111217260360718 for ['[CLS]ad anna sports agatha last traditionally turbines drew offset saved dale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.413 (perp=10.760, rec=0.261), tot_loss_proj:3.093 [t=0.26s]
prediction: ["[CLS] youngbber a cavalryed neither sir neither neither'nor [SEP]"]
[ 100/2000] tot_loss=2.463 (perp=11.465, rec=0.170), tot_loss_proj:2.668 [t=0.27s]
prediction: ['[CLS] caper a capes neither terribly neither nor original funny [SEP]']
[ 150/2000] tot_loss=2.344 (perp=11.073, rec=0.130), tot_loss_proj:2.722 [t=0.25s]
prediction: ['[CLS] caper a caper that terribly neither nor original funny [SEP]']
[ 200/2000] tot_loss=2.344 (perp=11.073, rec=0.129), tot_loss_proj:2.769 [t=0.25s]
prediction: ['[CLS] caper a caper that terribly neither nor original funny [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.793 (perp=8.252, rec=0.142), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] funny caper a caper s terribly neither nor original [SEP]']
[ 300/2000] tot_loss=1.740 (perp=8.252, rec=0.090), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] funny caper a caper s terribly neither nor original [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.893 (perp=9.040, rec=0.085), tot_loss_proj:2.626 [t=0.25s]
prediction: ['[CLS] funny caper a cape s s neither terribly nor original [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.733 (perp=8.292, rec=0.075), tot_loss_proj:2.473 [t=0.25s]
prediction: ['[CLS] funny caper s that neither a cape terribly nor original [SEP]']
[ 450/2000] tot_loss=1.737 (perp=8.292, rec=0.079), tot_loss_proj:2.474 [t=0.27s]
prediction: ['[CLS] funny caper s that neither a cape terribly nor original [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.715 (perp=8.241, rec=0.066), tot_loss_proj:2.464 [t=0.26s]
prediction: ['[CLS] funny caper that s neither a cape terribly nor original [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.635 (perp=7.826, rec=0.070), tot_loss_proj:2.362 [t=0.25s]
prediction: ["[CLS] funny caper that s neither a'nor terribly original [SEP]"]
[ 600/2000] tot_loss=1.640 (perp=7.826, rec=0.075), tot_loss_proj:2.366 [t=0.26s]
prediction: ["[CLS] funny caper that s neither a'nor terribly original [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.531 (perp=7.301, rec=0.070), tot_loss_proj:2.322 [t=0.25s]
prediction: ["[CLS] that funny caper s neither a'nor terribly original [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.351 (perp=6.365, rec=0.078), tot_loss_proj:2.106 [t=0.25s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
[ 750/2000] tot_loss=1.344 (perp=6.365, rec=0.071), tot_loss_proj:2.102 [t=0.25s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.340 (perp=6.365, rec=0.067), tot_loss_proj:2.101 [t=0.27s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.348 (perp=6.365, rec=0.075), tot_loss_proj:2.100 [t=0.26s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
[ 900/2000] tot_loss=1.344 (perp=6.365, rec=0.071), tot_loss_proj:2.106 [t=0.26s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.347 (perp=6.365, rec=0.074), tot_loss_proj:2.107 [t=0.24s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.341 (perp=6.365, rec=0.068), tot_loss_proj:2.104 [t=0.25s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
[1050/2000] tot_loss=1.337 (perp=6.365, rec=0.064), tot_loss_proj:2.107 [t=0.25s]
prediction: ["[CLS] that funny caper's neither a nor terribly original [SEP]"]
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.085 (perp=5.021, rec=0.080), tot_loss_proj:1.323 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.070 (perp=5.021, rec=0.066), tot_loss_proj:1.323 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
[1200/2000] tot_loss=1.081 (perp=5.021, rec=0.077), tot_loss_proj:1.319 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.060 (perp=5.021, rec=0.056), tot_loss_proj:1.321 [t=0.27s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.070 (perp=5.021, rec=0.066), tot_loss_proj:1.324 [t=0.27s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
[1350/2000] tot_loss=1.069 (perp=5.021, rec=0.065), tot_loss_proj:1.325 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.075 (perp=5.021, rec=0.070), tot_loss_proj:1.335 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.076 (perp=5.021, rec=0.072), tot_loss_proj:1.320 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
[1500/2000] tot_loss=1.074 (perp=5.021, rec=0.070), tot_loss_proj:1.329 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.068 (perp=5.021, rec=0.064), tot_loss_proj:1.332 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.073 (perp=5.021, rec=0.069), tot_loss_proj:1.326 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
[1650/2000] tot_loss=1.067 (perp=5.021, rec=0.063), tot_loss_proj:1.323 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.079 (perp=5.021, rec=0.075), tot_loss_proj:1.325 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.065 (perp=5.021, rec=0.061), tot_loss_proj:1.327 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
[1800/2000] tot_loss=1.070 (perp=5.021, rec=0.066), tot_loss_proj:1.323 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.073 (perp=5.021, rec=0.069), tot_loss_proj:1.322 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.065 (perp=5.021, rec=0.060), tot_loss_proj:1.324 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
[1950/2000] tot_loss=1.068 (perp=5.021, rec=0.064), tot_loss_proj:1.328 [t=0.25s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.070 (perp=5.021, rec=0.066), tot_loss_proj:1.328 [t=0.26s]
prediction: ["[CLS] that's neither a funny caper nor terribly original [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that funny caper s neither a'nor terribly original [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 120.000

[Aggregate metrics]:
rouge1     | fm: 87.698 | p: 86.905 | r: 88.707
rouge2     | fm: 51.358 | p: 51.025 | r: 51.690
rougeL     | fm: 76.119 | p: 75.503 | r: 76.880
rougeLsum  | fm: 76.095 | p: 75.431 | r: 76.957
r1fm+r2fm = 139.057

input #94 time: 0:10:42 | total time: 17:13:03


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9573214650154114 for ['[CLS] grade waters dusty one buster position blue masiva bargain wheel ca platform know much [SEP]']
[Init] best rec loss: 0.9516270160675049 for ['[CLS] due snooker juniper trick connected seem supervisors planner gig forkvo pa started ether dragon [SEP]']
[Init] best rec loss: 0.9364960193634033 for ['[CLS] galloway fr staff widely education show variety2 service jealousy onto respiratorymin requestmission [SEP]']
[Init] best rec loss: 0.9339879155158997 for ['[CLS] speed hung peter kerala enlisted data dea assent jessie cool economyiful glanced jerk lips [SEP]']
[Init] best rec loss: 0.9256618022918701 for ['[CLS] graphs roller chandler!umaticiche natasha trek departure angleː do length struck conflict [SEP]']
[Init] best rec loss: 0.9226517081260681 for ['[CLS] fc williams englandxious freedoms rush dealing charts piecesade back these mac.num [SEP]']
[Init] best perm rec loss: 0.9186740517616272 for ['[CLS]ade dealing pieces these charts williams fc freedoms. macxious rush back englandnum [SEP]']
[Init] best perm rec loss: 0.9180237650871277 for ['[CLS] england chartsxiousnum rush these back fc. williams mac pieces freedoms dealingade [SEP]']
[Init] best perm rec loss: 0.9170737862586975 for ['[CLS] rushade pieces mac charts dealingnumxious freedoms england back. williams fc these [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.103 (perp=13.050, rec=0.493), tot_loss_proj:3.413 [t=0.27s]
prediction: ['[CLS] taxi locations attraction in becomes hopeless hopeless ends hopeless becomes - worlds convention alice santa [SEP]']
[ 100/2000] tot_loss=2.958 (perp=12.607, rec=0.437), tot_loss_proj:3.209 [t=0.25s]
prediction: ['[CLS] ¿ tomb attraction ; becomes hopeless hopeless hopeless hopeless invalid - worlds story don amour [SEP]']
[ 150/2000] tot_loss=2.786 (perp=11.977, rec=0.390), tot_loss_proj:3.289 [t=0.26s]
prediction: ['[CLS] [ metaphor afterwards ( becomes hopeless hopeless hopeless hopelessbrick - worlds story johnny crying [SEP]']
[ 200/2000] tot_loss=3.281 (perp=14.642, rec=0.352), tot_loss_proj:3.801 [t=0.25s]
prediction: ['[CLS] jagger story copies ( becomes hopeless hopeless hopeless hopelessdle ( worlds story johnny dakota [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.967 (perp=12.988, rec=0.369), tot_loss_proj:3.338 [t=0.25s]
prediction: ['[CLS] hopeless story afterwards recounted becomes ⁻ hopeless hopeless hopelessgration ( worlds storybridge desperately [SEP]']
[ 300/2000] tot_loss=2.528 (perp=11.099, rec=0.309), tot_loss_proj:2.799 [t=0.27s]
prediction: ["[CLS] hopeless story copies recounted becomes'hopeless hopeless hopeless un ( : storybridge sleeper [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.694 (perp=11.980, rec=0.298), tot_loss_proj:3.187 [t=0.27s]
prediction: ['[CLS] hopeless story copies recounted becomes ( hopeless hopeless hopeless ( : story ungrowth unusually [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.590 (perp=11.474, rec=0.296), tot_loss_proj:2.981 [t=0.25s]
prediction: ['[CLS] hopeless story copieszquez becomes hopeless hopeless ( hopeless ( :dlensor grandson unusually [SEP]']
[ 450/2000] tot_loss=2.562 (perp=11.449, rec=0.272), tot_loss_proj:2.963 [t=0.25s]
prediction: ['[CLS] hopeless story copieszquez becomes hopeless hopeless ( hopeless ( :dlensor reelected unusually [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.743 (perp=12.298, rec=0.283), tot_loss_proj:3.121 [t=0.25s]
prediction: ['[CLS] hopeless story possessionszquez becomes : hopeless ( mala ( hopelessdle un reelected unusually [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.679 (perp=12.032, rec=0.272), tot_loss_proj:3.359 [t=0.26s]
prediction: ['[CLS] hopeless story afterwardsᄋ becomes ( puzzlensor mala ( hopelessdle ( reelected unusually [SEP]']
[ 600/2000] tot_loss=2.683 (perp=12.128, rec=0.257), tot_loss_proj:3.385 [t=0.26s]
prediction: ['[CLS] hopeless story afterwardsᄋ becomes ( puzzle un mala ( hopelessdle ( reelected unusually [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.622 (perp=11.850, rec=0.252), tot_loss_proj:3.319 [t=0.25s]
prediction: ['[CLS] hopeless story afterwardsᄋ becomes (fold un ( hopelessstandingdle ( reelected unusually [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.688 (perp=12.178, rec=0.253), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] hopeless story afterwardsᄋ becomes ( hopeless un, ( hopelessdle ( reelected unusually [SEP]']
[ 750/2000] tot_loss=2.783 (perp=12.644, rec=0.254), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes ( hopeless un sha ( hopelessdle ( reelected unusually [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.626 (perp=11.883, rec=0.250), tot_loss_proj:3.291 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes un hopeless ( sha ( hopelessdle ( reelected unusually [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.639 (perp=11.914, rec=0.256), tot_loss_proj:3.320 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unuttered ( ( hopelessstandingdle ( reelected unusually [SEP]']
[ 900/2000] tot_loss=2.621 (perp=11.887, rec=0.244), tot_loss_proj:3.323 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unuttered ( ( hopelessfoundeddle ( reelected unusually [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.515 (perp=11.361, rec=0.242), tot_loss_proj:3.067 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes undleuttered ( ( hopelessfounded ( reelected unusually [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.493 (perp=11.202, rec=0.253), tot_loss_proj:3.075 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes undleuttered ( hopeless (founded ( reelected unusually [SEP]']
[1050/2000] tot_loss=2.534 (perp=11.428, rec=0.249), tot_loss_proj:3.217 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes undleuttered ( taboo (founded ( reelected unusually [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.497 (perp=11.254, rec=0.247), tot_loss_proj:3.190 [t=0.27s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes undleuttered ( taboofounded ( ( reelected unusually [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.473 (perp=11.131, rec=0.247), tot_loss_proj:3.155 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatuttered ( taboodle ( ( reelected unusually [SEP]']
[1200/2000] tot_loss=2.464 (perp=11.131, rec=0.238), tot_loss_proj:3.159 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatuttered ( taboodle ( ( reelected unusually [SEP]']
Attempt swap
[1250/2000] tot_loss=2.459 (perp=11.131, rec=0.233), tot_loss_proj:3.153 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatuttered ( taboodle ( ( reelected unusually [SEP]']
Attempt swap
[1300/2000] tot_loss=2.653 (perp=12.039, rec=0.245), tot_loss_proj:3.343 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffle ( taboodle ( ( reelected unusually [SEP]']
[1350/2000] tot_loss=2.642 (perp=12.039, rec=0.234), tot_loss_proj:3.350 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffle ( taboodle ( ( reelected unusually [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.566 (perp=11.643, rec=0.237), tot_loss_proj:3.256 [t=0.27s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1450/2000] tot_loss=2.571 (perp=11.643, rec=0.242), tot_loss_proj:3.256 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
[1500/2000] tot_loss=2.561 (perp=11.643, rec=0.233), tot_loss_proj:3.265 [t=0.27s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1550/2000] tot_loss=2.557 (perp=11.643, rec=0.228), tot_loss_proj:3.258 [t=0.27s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1600/2000] tot_loss=2.568 (perp=11.643, rec=0.239), tot_loss_proj:3.266 [t=0.29s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
[1650/2000] tot_loss=2.572 (perp=11.643, rec=0.243), tot_loss_proj:3.260 [t=0.26s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1700/2000] tot_loss=2.579 (perp=11.643, rec=0.250), tot_loss_proj:3.259 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1750/2000] tot_loss=2.557 (perp=11.643, rec=0.228), tot_loss_proj:3.260 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
[1800/2000] tot_loss=2.565 (perp=11.643, rec=0.237), tot_loss_proj:3.265 [t=0.27s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1850/2000] tot_loss=2.575 (perp=11.643, rec=0.246), tot_loss_proj:3.260 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
Attempt swap
[1900/2000] tot_loss=2.564 (perp=11.643, rec=0.235), tot_loss_proj:3.262 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelected unusually [SEP]']
[1950/2000] tot_loss=2.577 (perp=11.682, rec=0.241), tot_loss_proj:3.144 [t=0.27s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelectedbasket [SEP]']
Attempt swap
[2000/2000] tot_loss=2.571 (perp=11.682, rec=0.234), tot_loss_proj:3.147 [t=0.25s]
prediction: ['[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelectedbasket [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] hopeless story arrivingᄋ becomes unsatffledle taboo ( ( ( reelectedbasket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.556 | p: 55.556 | r: 55.556
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 55.556

[Aggregate metrics]:
rouge1     | fm: 87.366 | p: 86.500 | r: 88.428
rouge2     | fm: 50.735 | p: 50.462 | r: 51.185
rougeL     | fm: 75.730 | p: 75.093 | r: 76.592
rougeLsum  | fm: 75.659 | p: 75.072 | r: 76.514
r1fm+r2fm = 138.101

input #95 time: 0:10:58 | total time: 17:24:02


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8993293642997742 for ['[CLS] jay production boxɕ native spouse addition brandingel fifaff monthly energy capable emphasis [SEP]']
[Init] best rec loss: 0.8874086737632751 for ['[CLS] evil help executive ownfusioncrat water booklet cluesaj tonight divided replacement due nap [SEP]']
[Init] best rec loss: 0.8616747260093689 for ['[CLS] turf pool marks complexbrates atomic ass suitable machinesur landmark positive gossip novel itself [SEP]']
[Init] best rec loss: 0.8219738006591797 for ['[CLS]tz crisp + surveyel convenience bob death vice left hitting whisper wimbledon with forces [SEP]']
[Init] best rec loss: 0.7874165773391724 for ['[CLS] spring saskatchewan with facilities penses o great worried mama commanded organesh meetcki [SEP]']
[Init] best rec loss: 0.7869715094566345 for ['[CLS] zackchy gas was simon shrine oaks christine sore fingertips ordeal approach missionary left zero [SEP]']
[Init] best rec loss: 0.7835100889205933 for ['[CLS] explained were doctor everyday where analogy bag fbi defeat arranged distributed accreditation which winner intent [SEP]']
[Init] best rec loss: 0.7645136117935181 for ['[CLS] austin recognize earurn conradrim. phases fuscous talbot image rough else housingmament [SEP]']
[Init] best rec loss: 0.7640089988708496 for ['[CLS] bam ba satellite shouldn constant south prominent anti uncle pointed body4 caught uncredited phd [SEP]']
[Init] best rec loss: 0.7425398826599121 for ['[CLS] englandiling frog buffaloav receptions perry havre portion reader game all atomic finland ev [SEP]']
[Init] best perm rec loss: 0.73823082447052 for ['[CLS] havre finlandav atomic reader buffalo gameiling receptions perry portion frog england all ev [SEP]']
[Init] best perm rec loss: 0.7380701303482056 for ['[CLS] readeriling receptions all havre evav game england buffalo finland portion atomic perry frog [SEP]']
[Init] best perm rec loss: 0.7379177212715149 for ['[CLS] england havre gameiling reader frog allav perry buffalo receptions ev portion atomic finland [SEP]']
[Init] best perm rec loss: 0.7331089377403259 for ['[CLS] perry finland alliling havre frog portion england atomic reader ev receptionsav game buffalo [SEP]']
[Init] best perm rec loss: 0.732092559337616 for ['[CLS] england finland havre gameilingav buffalo perry ev receptions portion frog reader all atomic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.531 (perp=11.042, rec=0.323), tot_loss_proj:2.928 [t=0.26s]
prediction: ['[CLS] force society out explosiveff people awareness become better better mainly conceived people pushed players [SEP]']
[ 100/2000] tot_loss=2.253 (perp=10.202, rec=0.213), tot_loss_proj:2.608 [t=0.27s]
prediction: ['[CLS] force on himself force few people cover into lesser lesser men outstanding people pushed people [SEP]']
[ 150/2000] tot_loss=2.092 (perp=9.708, rec=0.150), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] force on himself on situations run cover would lesser lesser men meant people on people [SEP]']
[ 200/2000] tot_loss=1.889 (perp=8.839, rec=0.121), tot_loss_proj:2.252 [t=0.27s]
prediction: ['[CLS] force on himself into situations run cover would lesser lesser men for that on people [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.003 (perp=9.396, rec=0.123), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS] force on himself into ( run lesser would cover lesser men for and on people [SEP]']
[ 300/2000] tot_loss=1.849 (perp=8.720, rec=0.105), tot_loss_proj:2.350 [t=0.26s]
prediction: ['[CLS] force on himself situations and run lesser would cover lesser men for and on people [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.893 (perp=9.000, rec=0.093), tot_loss_proj:2.352 [t=0.26s]
prediction: ['[CLS] force on himself situations into run lesser would cover lesser men on and for people [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.776 (perp=8.415, rec=0.093), tot_loss_proj:2.135 [t=0.25s]
prediction: ['[CLS] force on himself into situations run lesser would cover lesser men on and for people [SEP]']
[ 450/2000] tot_loss=1.767 (perp=8.415, rec=0.084), tot_loss_proj:2.135 [t=0.26s]
prediction: ['[CLS] force on himself into situations run lesser would cover lesser men on and for people [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.706 (perp=8.123, rec=0.082), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] force himself into situations run lesser on would cover lesser men on and for people [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.652 (perp=7.875, rec=0.077), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] force himself into situations run lesser people would cover lesser men on and for on [SEP]']
[ 600/2000] tot_loss=1.650 (perp=7.875, rec=0.075), tot_loss_proj:2.044 [t=0.25s]
prediction: ['[CLS] force himself into situations run lesser people would cover lesser men on and for on [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.638 (perp=7.760, rec=0.086), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.634 (perp=7.760, rec=0.082), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[ 750/2000] tot_loss=1.639 (perp=7.760, rec=0.087), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.635 (perp=7.760, rec=0.083), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.629 (perp=7.760, rec=0.077), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[ 900/2000] tot_loss=1.626 (perp=7.760, rec=0.074), tot_loss_proj:2.092 [t=0.27s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.630 (perp=7.760, rec=0.078), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.636 (perp=7.760, rec=0.084), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1050/2000] tot_loss=1.629 (perp=7.760, rec=0.077), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.627 (perp=7.760, rec=0.075), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.628 (perp=7.760, rec=0.076), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1200/2000] tot_loss=1.632 (perp=7.760, rec=0.080), tot_loss_proj:2.100 [t=0.27s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.639 (perp=7.760, rec=0.087), tot_loss_proj:2.095 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.630 (perp=7.760, rec=0.078), tot_loss_proj:2.088 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1350/2000] tot_loss=1.621 (perp=7.760, rec=0.069), tot_loss_proj:2.095 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.627 (perp=7.760, rec=0.075), tot_loss_proj:2.101 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.633 (perp=7.760, rec=0.081), tot_loss_proj:2.087 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1500/2000] tot_loss=1.632 (perp=7.760, rec=0.080), tot_loss_proj:2.089 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.632 (perp=7.760, rec=0.080), tot_loss_proj:2.097 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.635 (perp=7.760, rec=0.083), tot_loss_proj:2.096 [t=0.27s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1650/2000] tot_loss=1.626 (perp=7.760, rec=0.074), tot_loss_proj:2.092 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.630 (perp=7.760, rec=0.078), tot_loss_proj:2.092 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.635 (perp=7.760, rec=0.083), tot_loss_proj:2.091 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1800/2000] tot_loss=1.627 (perp=7.760, rec=0.075), tot_loss_proj:2.096 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.628 (perp=7.760, rec=0.076), tot_loss_proj:2.097 [t=0.27s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.633 (perp=7.760, rec=0.081), tot_loss_proj:2.088 [t=0.28s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
[1950/2000] tot_loss=1.636 (perp=7.760, rec=0.084), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.626 (perp=7.760, rec=0.074), tot_loss_proj:2.098 [t=0.25s]
prediction: ['[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] force himself run into situations lesser people would cover lesser men on and for on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 113.235

[Aggregate metrics]:
rouge1     | fm: 87.362 | p: 86.579 | r: 88.392
rouge2     | fm: 50.532 | p: 50.126 | r: 50.937
rougeL     | fm: 75.589 | p: 74.916 | r: 76.433
rougeLsum  | fm: 75.540 | p: 74.878 | r: 76.375
r1fm+r2fm = 137.894

input #96 time: 0:10:55 | total time: 17:34:57


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8475993871688843 for ['[CLS] right former again socks hallway force [SEP]']
[Init] best rec loss: 0.8398158550262451 for ['[CLS] standards coupe currentlyadt origin citizenship [SEP]']
[Init] best rec loss: 0.8254334330558777 for ['[CLS] ran congregation prof sake struggled discussed [SEP]']
[Init] best rec loss: 0.8129605650901794 for ['[CLS] crack jamaica flynn nonsense cast magnitude [SEP]']
[Init] best rec loss: 0.8124622106552124 for ['[CLS] gifford may according spent peter seven [SEP]']
[Init] best rec loss: 0.8030499815940857 for ['[CLS] servicelord honors evlaook [SEP]']
[Init] best rec loss: 0.7723836898803711 for ['[CLS] lost evie discipline shit band defeated [SEP]']
[Init] best rec loss: 0.765044629573822 for ['[CLS] reubeneleear claim bus freedom [SEP]']
[Init] best rec loss: 0.7608984112739563 for ['[CLS] allegedly digtituted beside colours association [SEP]']
[Init] best rec loss: 0.7591689229011536 for ['[CLS] bye when sasha compressionmel final [SEP]']
[Init] best rec loss: 0.7162978053092957 for ['[CLS] youtube undergo duncan ship eddy crane [SEP]']
[Init] best perm rec loss: 0.7158287167549133 for ['[CLS] eddy crane duncan ship undergo youtube [SEP]']
[Init] best perm rec loss: 0.7143959403038025 for ['[CLS] undergo crane eddy duncan youtube ship [SEP]']
[Init] best perm rec loss: 0.7140510678291321 for ['[CLS] youtube undergo eddy duncan crane ship [SEP]']
[Init] best perm rec loss: 0.7137810587882996 for ['[CLS] undergo ship eddy youtube duncan crane [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.259 (perp=14.629, rec=0.333), tot_loss_proj:3.659 [t=0.25s]
prediction: ['[CLS]tionsfor lou global transditional [SEP]']
[ 100/2000] tot_loss=2.959 (perp=13.798, rec=0.199), tot_loss_proj:3.610 [t=0.25s]
prediction: ['[CLS]getfor laurietableget characters [SEP]']
[ 150/2000] tot_loss=2.554 (perp=12.051, rec=0.144), tot_loss_proj:3.264 [t=0.25s]
prediction: ['[CLS]tablefor ♭tableget characters [SEP]']
[ 200/2000] tot_loss=2.748 (perp=12.814, rec=0.185), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS]tablefor johntableget characters [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.084 (perp=9.778, rec=0.129), tot_loss_proj:2.347 [t=0.24s]
prediction: ['[CLS]tableforgettable john characters [SEP]']
[ 300/2000] tot_loss=2.086 (perp=9.778, rec=0.130), tot_loss_proj:2.353 [t=0.24s]
prediction: ['[CLS]tableforgettable john characters [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.893 (perp=8.860, rec=0.121), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS]tableforgettable characters john [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.883 (perp=8.860, rec=0.111), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS]tableforgettable characters john [SEP]']
[ 450/2000] tot_loss=1.885 (perp=8.860, rec=0.113), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS]tableforgettable characters john [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=7.871, rec=0.104), tot_loss_proj:1.905 [t=0.25s]
prediction: ['[CLS]tableforgettable characters and [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.679 (perp=7.873, rec=0.104), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS]tableforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.685 (perp=7.873, rec=0.110), tot_loss_proj:1.981 [t=0.25s]
prediction: ['[CLS]tableforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.694 (perp=7.873, rec=0.119), tot_loss_proj:1.984 [t=0.25s]
prediction: ['[CLS]tableforgettable and characters [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.149 (perp=10.138, rec=0.121), tot_loss_proj:2.626 [t=0.26s]
prediction: ['[CLS]tableforgettable characters un [SEP]']
[ 750/2000] tot_loss=2.145 (perp=10.138, rec=0.117), tot_loss_proj:2.619 [t=0.27s]
prediction: ['[CLS]tableforgettable characters un [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.474 (perp=6.872, rec=0.100), tot_loss_proj:1.555 [t=0.27s]
prediction: ['[CLS] unforgettable characterstable [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.485 (perp=6.872, rec=0.110), tot_loss_proj:1.554 [t=0.25s]
prediction: ['[CLS] unforgettable characterstable [SEP]']
[ 900/2000] tot_loss=1.340 (perp=6.104, rec=0.119), tot_loss_proj:1.457 [t=0.26s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.337 (perp=6.104, rec=0.116), tot_loss_proj:1.457 [t=0.26s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.336 (perp=6.104, rec=0.115), tot_loss_proj:1.445 [t=0.26s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
[1050/2000] tot_loss=1.319 (perp=6.104, rec=0.098), tot_loss_proj:1.448 [t=0.25s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.325 (perp=6.104, rec=0.104), tot_loss_proj:1.450 [t=0.25s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.315 (perp=6.104, rec=0.094), tot_loss_proj:1.460 [t=0.26s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
[1200/2000] tot_loss=1.308 (perp=6.104, rec=0.087), tot_loss_proj:1.462 [t=0.26s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
Put prefix at the end
[1250/2000] tot_loss=1.249 (perp=5.768, rec=0.095), tot_loss_proj:1.341 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.249 (perp=5.768, rec=0.095), tot_loss_proj:1.343 [t=0.26s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1350/2000] tot_loss=1.243 (perp=5.768, rec=0.089), tot_loss_proj:1.337 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.234 (perp=5.768, rec=0.081), tot_loss_proj:1.340 [t=0.27s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.239 (perp=5.768, rec=0.086), tot_loss_proj:1.342 [t=0.26s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1500/2000] tot_loss=1.237 (perp=5.768, rec=0.083), tot_loss_proj:1.324 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.241 (perp=5.768, rec=0.087), tot_loss_proj:1.339 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.229 (perp=5.768, rec=0.075), tot_loss_proj:1.337 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1650/2000] tot_loss=1.230 (perp=5.768, rec=0.076), tot_loss_proj:1.326 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.227 (perp=5.768, rec=0.073), tot_loss_proj:1.333 [t=0.24s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.232 (perp=5.768, rec=0.078), tot_loss_proj:1.339 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1800/2000] tot_loss=1.241 (perp=5.768, rec=0.087), tot_loss_proj:1.334 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.235 (perp=5.768, rec=0.082), tot_loss_proj:1.331 [t=0.28s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.224 (perp=5.768, rec=0.070), tot_loss_proj:1.341 [t=0.26s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1950/2000] tot_loss=1.231 (perp=5.768, rec=0.077), tot_loss_proj:1.330 [t=0.26s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.239 (perp=5.768, rec=0.085), tot_loss_proj:1.329 [t=0.28s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] characters unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 87.297 | p: 86.525 | r: 88.295
rouge2     | fm: 50.653 | p: 50.258 | r: 51.063
rougeL     | fm: 75.580 | p: 74.967 | r: 76.398
rougeLsum  | fm: 75.617 | p: 75.011 | r: 76.425
r1fm+r2fm = 137.950

input #97 time: 0:10:39 | total time: 17:45:36


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.9459589719772339 for ['[CLS] marbleoint ₘ try [SEP]']
[Init] best rec loss: 0.9128426313400269 for ['[CLS] ( standards full continuing [SEP]']
[Init] best rec loss: 0.8189659714698792 for ['[CLS] thornerat doom roam [SEP]']
[Init] best rec loss: 0.8030910491943359 for ['[CLS] enter her tomorrow pic [SEP]']
[Init] best rec loss: 0.7429978847503662 for ['[CLS] beasts stevie afro tutor [SEP]']
[Init] best rec loss: 0.7326633930206299 for ['[CLS] shops situation cdp breaking [SEP]']
[Init] best rec loss: 0.7176988124847412 for ['[CLS] fuel god behind weed [SEP]']
[Init] best rec loss: 0.6893752217292786 for ['[CLS] jack v purposely cerambycidae [SEP]']
[Init] best rec loss: 0.6838822960853577 for ['[CLS] explorer cane expression sole [SEP]']
[Init] best rec loss: 0.6495212912559509 for ['[CLS] persona cheek premises tub [SEP]']
[Init] best rec loss: 0.6413914561271667 for ['[CLS] congregation external recruits slopes [SEP]']
[Init] best perm rec loss: 0.6368125081062317 for ['[CLS] recruits congregation external slopes [SEP]']
[Init] best perm rec loss: 0.6358419060707092 for ['[CLS] slopes external congregation recruits [SEP]']
[Init] best perm rec loss: 0.635684609413147 for ['[CLS] external congregation recruits slopes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.414 (perp=10.921, rec=0.230), tot_loss_proj:2.524 [t=0.31s]
prediction: ['[CLS] unfulllingful [SEP]']
[ 100/2000] tot_loss=1.080 (perp=4.947, rec=0.090), tot_loss_proj:1.061 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 150/2000] tot_loss=1.049 (perp=4.947, rec=0.060), tot_loss_proj:1.056 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 200/2000] tot_loss=1.046 (perp=4.947, rec=0.056), tot_loss_proj:1.059 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.053 (perp=4.947, rec=0.063), tot_loss_proj:1.055 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.048 (perp=4.947, rec=0.058), tot_loss_proj:1.043 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.042 (perp=4.947, rec=0.053), tot_loss_proj:1.050 [t=0.33s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.046 (perp=4.947, rec=0.057), tot_loss_proj:1.063 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.052 (perp=4.947, rec=0.063), tot_loss_proj:1.064 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.057 (perp=4.947, rec=0.068), tot_loss_proj:1.066 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.044 (perp=4.947, rec=0.055), tot_loss_proj:1.053 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.045 (perp=4.947, rec=0.055), tot_loss_proj:1.059 [t=0.33s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.053 (perp=4.947, rec=0.063), tot_loss_proj:1.065 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.043 (perp=4.947, rec=0.054), tot_loss_proj:1.056 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.046 (perp=4.947, rec=0.056), tot_loss_proj:1.048 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.043 (perp=4.947, rec=0.054), tot_loss_proj:1.053 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.041 (perp=4.947, rec=0.051), tot_loss_proj:1.043 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.051 (perp=4.947, rec=0.062), tot_loss_proj:1.055 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.057 (perp=4.947, rec=0.067), tot_loss_proj:1.054 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.042 (perp=4.947, rec=0.053), tot_loss_proj:1.054 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.050 (perp=4.947, rec=0.060), tot_loss_proj:1.059 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.036 (perp=4.947, rec=0.046), tot_loss_proj:1.045 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.051 (perp=4.947, rec=0.061), tot_loss_proj:1.048 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.047 (perp=4.947, rec=0.058), tot_loss_proj:1.057 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.043 (perp=4.947, rec=0.054), tot_loss_proj:1.065 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.051 (perp=4.947, rec=0.062), tot_loss_proj:1.047 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.055 (perp=4.947, rec=0.066), tot_loss_proj:1.046 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.063 (perp=4.947, rec=0.073), tot_loss_proj:1.052 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.055 (perp=4.947, rec=0.066), tot_loss_proj:1.059 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.044 (perp=4.947, rec=0.055), tot_loss_proj:1.049 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.057 (perp=4.947, rec=0.067), tot_loss_proj:1.050 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.041 (perp=4.947, rec=0.052), tot_loss_proj:1.047 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.044 (perp=4.947, rec=0.055), tot_loss_proj:1.048 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.045 (perp=4.947, rec=0.056), tot_loss_proj:1.052 [t=0.31s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.055 (perp=4.947, rec=0.066), tot_loss_proj:1.042 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.050 (perp=4.947, rec=0.060), tot_loss_proj:1.060 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.034 (perp=4.947, rec=0.044), tot_loss_proj:1.051 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.050 (perp=4.947, rec=0.060), tot_loss_proj:1.056 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.047 (perp=4.947, rec=0.058), tot_loss_proj:1.046 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.051 (perp=4.947, rec=0.061), tot_loss_proj:1.056 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.441 | p: 86.660 | r: 88.464
rouge2     | fm: 51.064 | p: 50.735 | r: 51.499
rougeL     | fm: 75.861 | p: 75.233 | r: 76.683
rougeLsum  | fm: 75.839 | p: 75.178 | r: 76.643
r1fm+r2fm = 138.505

input #98 time: 0:11:40 | total time: 17:57:16


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.893981397151947 for ["[CLS] hero speaking newspaper fur magistrate nsa schedulerite bury wrestlerazi cycle tree jewish gall ( expelled play pour seeing iain copper snout lone spell lower hearlter past'raise standard tom connected angeles forward [SEP]"]
[Init] best rec loss: 0.858933687210083 for ['[CLS] bomb look runningery oklahoma athena terms intailstur iron what absent shut wolf joint cross anything master balanced haven chadeck corner 部 mc appointment broad parish victoria [CLS] items tug wounded reconnaissance grid [SEP]']
[Init] best rec loss: 0.7905089259147644 for ['[CLS] limited vin castle fighter bam diego selection paul tanner moses only this thorpe run case fat answered perspective inc parish k ind signaturever simply notation senator bad us funds emeritus followed la championship those care [SEP]']
[Init] best rec loss: 0.7719022035598755 for ['[CLS] toysis created jesus message fit gemma stick claims fields daring anrea tour complete built recognized used wrestlers whatever yards wan headquartered what col uc risky [CLS] bywala supposed talk transplant mid unionist motors [SEP]']
[Init] best rec loss: 0.7553455233573914 for ['[CLS] kurt pay moe few waiting yields rangers across paterson viaivist home slight held ari metres surrender part ever 2000s fighting estimate task lone bend founding suggested me sustained bass rivals das thisyan insistence turn [SEP]']
[Init] best rec loss: 0.7529468536376953 for ['[CLS] over shotivation organic urulfð diedudge chamber atlanta fork score cowboy parked insisted harvard cincinnati collins hands minas alike bangs children stroke gossiptus cheer m gifts studies sees aided cameron blond pin [SEP]']
[Init] best rec loss: 0.7504951357841492 for ['[CLS] ortega hour damaged citadelche sha, ps minogue 4th ernst eta winbr acclaim path past / program walkzzling cave above half region war ª community amusing deviation spectators import profile allegationsffed estadio [SEP]']
[Init] best rec loss: 0.731024980545044 for ['[CLS] madetlement south sofiafoot night injection recordings guild originally goalii ryan every powers jam sunrissa offers bomb sum won rock radar sant native branch marche rates heath siege popular designerlanda order flowers [SEP]']
[Init] best perm rec loss: 0.7304300665855408 for ['[CLS] sant sun sum made designer jam flowers injection marche powers order won goal heath siege every originallyfoot guild popular night branchrissa recordings southlanda rock ryan sofia native ratestlement bomb radar offersii [SEP]']
[Init] best perm rec loss: 0.7304127812385559 for ['[CLS] sum made guild native originally powers sofia rock radar recordings jam popular ryan every flowers sun siegelanda sant night designer offers bomb south heath rates marche wonii orderfootrissatlement injection goal branch [SEP]']
[Init] best perm rec loss: 0.7286003828048706 for ['[CLS] sun radar recordings bombrissaii south rock offers rates night every popular marche order designer heath siege jam sofia sum sant guildlanda goal powers originallytlement branch ryanfoot flowers made injection native won [SEP]']
[Init] best perm rec loss: 0.727978527545929 for ['[CLS] powers guild made sunlanda radar flowerstlement night siege rockfoot bomb order originally recordings ryan sum heathrissa every designer south offers jam rates injection won goal native sofiaii sant marche popular branch [SEP]']
[Init] best perm rec loss: 0.7277243733406067 for ['[CLS] offers guild popular branch order every jamfoot powersrissa ryan south goal injection siege nighttlement made marche recordings originally sun rates bomb rock sant flowerslanda designer heath won sum radar native sofiaii [SEP]']
[Init] best perm rec loss: 0.7274906635284424 for ['[CLS] nightlanda made native bomb rates offers sofia sun sum south ryan powers won every siege marche order branch popularfootrissa originally guild jam flowers santii goal designer radar heath recordings injection rocktlement [SEP]']
[Init] best perm rec loss: 0.7269250154495239 for ['[CLS] night sun made south offers rock every guild injection won marche goalrissa branch popularfoot bombtlement recordings sofia heath sum radar designerlanda ryan rates siege order native originallyii powers sant flowers jam [SEP]']
[Init] best perm rec loss: 0.7243838906288147 for ['[CLS]foot sun wonii native bomb jam made guildrissa branch sum sofia goal offers designer santlanda injection every siege rates rock night south heath marche popular radartlement flowers recordings powers order originally ryan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.055 (perp=13.173, rec=0.420), tot_loss_proj:3.280 [t=0.29s]
prediction: ["[CLS] been monitors lasii tactical bomb failure abandoned policies backed cut encryption di facebook licensing failed version maybe'but code cursed wereming graphicsssingys history least slipped was voluntary grinned technology exchanges maintenance [SEP]"]
[ 100/2000] tot_loss=2.820 (perp=12.697, rec=0.281), tot_loss_proj:3.119 [t=0.28s]
prediction: ['[CLS]less monitorsjo terrible careful bomb failure abandoned counter backed cut topic di ) kids not version films " but issuessing dissing film film di itssing tricky [SEP] voluntary fun rate already care [SEP]']
[ 150/2000] tot_loss=2.469 (perp=11.287, rec=0.212), tot_loss_proj:2.819 [t=0.28s]
prediction: ["[CLS] been ` an horrible including ticket failure destroyed counter losing we resolution'' phil -'films had but trafficssing dissing film film di )ssing tricky so without fun cost never care [SEP]"]
[ 200/2000] tot_loss=2.711 (perp=12.187, rec=0.273), tot_loss_proj:2.977 [t=0.28s]
prediction: ['[CLS] hastily super colour box like ticket searched declined following + dropped didn\'\' q... free into had but "ssing dissing film " ` freessingt so t fun forces would oblivious [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.436 (perp=11.174, rec=0.201), tot_loss_proj:2.840 [t=0.29s]
prediction: ['[CLS] behaved super word box much ticket checks declined\'_ dropped didn\'\' they " free into had but.ssing dissing film free. `ssing you so not fun cost would oblivious [SEP]']
[ 300/2000] tot_loss=2.420 (perp=11.226, rec=0.175), tot_loss_proj:2.797 [t=0.29s]
prediction: ["[CLS] walked boo word box much ticket checks horrible'_ dropped didn'' they'free into had but (ssing dissing film ). `ssing you so felt fun cost would oblivious [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.018 (perp=9.228, rec=0.172), tot_loss_proj:2.417 [t=0.28s]
prediction: ["[CLS] walked boo word box much ticket writes terrible'{ dropped'into'they'free'had but'eyed dissing film ). ` terrible you so felt fun cost his mind [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.058 (perp=9.481, rec=0.162), tot_loss_proj:2.482 [t=0.29s]
prediction: ["[CLS] walked ` ` box much'writes terrible ticket'voice'into'they'free'had but'eyed dissing film ). ` terrible you so felt fun cost during mind [SEP]"]
[ 450/2000] tot_loss=2.059 (perp=9.568, rec=0.146), tot_loss_proj:2.502 [t=0.28s]
prediction: ["[CLS] walked ` ` box much'writes terrible ticket'voice'into'they'free'had but much eyed dissing film ). ` terrible you so felt fun cost during mind [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.868 (perp=8.643, rec=0.139), tot_loss_proj:2.349 [t=0.28s]
prediction: ["[CLS] walked ` ` much'writes terrible ticket'air'into'they'free'had but much eyed box dissing film '. ` terrible! so felt fun cost should mind [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.871 (perp=8.686, rec=0.134), tot_loss_proj:2.328 [t=0.30s]
prediction: ["[CLS] walked ` ` much'writes terrible ticket'air'into'they'free'had but much eyed box dissing film '. ` terrible! so t fun should cost mind [SEP]"]
[ 600/2000] tot_loss=1.851 (perp=8.619, rec=0.127), tot_loss_proj:2.300 [t=0.27s]
prediction: ["[CLS] walked ` ` much'muttering terrible ticket'voice'ticket'they'free'had but much wrapped box dissing film '. ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.817 (perp=8.473, rec=0.122), tot_loss_proj:2.293 [t=0.28s]
prediction: ["[CLS] walked ` ` much'muttering terrible ticket'voice box ticket'they'free'had but much including'dissing film '. ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.759 (perp=8.217, rec=0.116), tot_loss_proj:2.276 [t=0.25s]
prediction: ["[CLS] walked ` ` much'muttering terrible ticket'voice box ticket'including they'free'had but much'dissing film '. ` terrible'so t fun should cost mind [SEP]"]
[ 750/2000] tot_loss=1.816 (perp=8.487, rec=0.118), tot_loss_proj:2.356 [t=0.25s]
prediction: ['[CLS] walked ` ` much\'muttering terrible ticket\'voice box ticket\'including they\'free\'had but much\'dissing film\'" ` terrible\'so t fun should cost mind [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.761 (perp=8.234, rec=0.114), tot_loss_proj:2.280 [t=0.27s]
prediction: ["[CLS] walked ` ` much'muttering terrible ticket'voice box ticket'including they had'free'but much'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.712 (perp=7.961, rec=0.120), tot_loss_proj:2.187 [t=0.24s]
prediction: ["[CLS] walked ` ` much'terrible ticket'air box ticket'wrapped they had'free muttering'but much'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
[ 900/2000] tot_loss=1.702 (perp=7.997, rec=0.103), tot_loss_proj:2.242 [t=0.27s]
prediction: ["[CLS] walked ` ` much'terrible ticket'air box ticket'the they had'free muttering'but much'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.686 (perp=7.869, rec=0.112), tot_loss_proj:2.151 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible ticket'air box ticket'much they had'free muttering'but the'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.673 (perp=7.766, rec=0.120), tot_loss_proj:2.136 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible ticket'air box'ticket much they had'free muttering'but the'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
[1050/2000] tot_loss=1.656 (perp=7.743, rec=0.107), tot_loss_proj:2.093 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible ticket'air box'ticket much they had'em muttering'but the'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.654 (perp=7.743, rec=0.105), tot_loss_proj:2.095 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible ticket'air box'ticket much they had'em muttering'but the'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.639 (perp=7.660, rec=0.107), tot_loss_proj:2.091 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible'air box'ticket ticket much they had'em muttering'but the'dissing film'that ` terrible'so t fun should cost mind [SEP]"]
[1200/2000] tot_loss=1.642 (perp=7.716, rec=0.098), tot_loss_proj:2.108 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible'air box'ticket ticket much they had'em muttering'but the'dissing film and that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.646 (perp=7.684, rec=0.109), tot_loss_proj:2.104 [t=0.27s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but the'dissing film and that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.622 (perp=7.592, rec=0.104), tot_loss_proj:2.104 [t=0.27s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible'so t fun should cost mind [SEP]"]
[1350/2000] tot_loss=1.623 (perp=7.592, rec=0.105), tot_loss_proj:2.103 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.627 (perp=7.592, rec=0.109), tot_loss_proj:2.099 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.621 (perp=7.592, rec=0.103), tot_loss_proj:2.108 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible'so t fun should cost mind [SEP]"]
[1500/2000] tot_loss=1.621 (perp=7.592, rec=0.102), tot_loss_proj:2.103 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible'so t fun should cost mind [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.598 (perp=7.473, rec=0.103), tot_loss_proj:2.017 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.473, rec=0.099), tot_loss_proj:2.022 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible air'box'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible't so fun should cost mind [SEP]"]
[1650/2000] tot_loss=1.588 (perp=7.431, rec=0.102), tot_loss_proj:2.018 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible air'n'ticket ticket much they had'em muttering'but'the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.577 (perp=7.418, rec=0.094), tot_loss_proj:2.009 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible air much'n'ticket ticket they had'em muttering'but'the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.560 (perp=7.276, rec=0.105), tot_loss_proj:1.952 [t=0.28s]
prediction: ["[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]"]
[1800/2000] tot_loss=1.558 (perp=7.276, rec=0.103), tot_loss_proj:1.953 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.559 (perp=7.276, rec=0.104), tot_loss_proj:1.958 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.555 (perp=7.276, rec=0.100), tot_loss_proj:1.955 [t=0.25s]
prediction: ["[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]"]
[1950/2000] tot_loss=1.556 (perp=7.276, rec=0.101), tot_loss_proj:1.955 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.276, rec=0.102), tot_loss_proj:1.955 [t=0.26s]
prediction: ["[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked ` ` much'terrible'air much'n'ticket ticket they had'em muttering'but the dissing film and that ` terrible't so fun should cost mind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.472 | p: 74.074 | r: 76.923
rouge2     | fm: 3.922 | p: 3.846 | r: 4.000
rougeL     | fm: 37.736 | p: 37.037 | r: 38.462
rougeLsum  | fm: 37.736 | p: 37.037 | r: 38.462
r1fm+r2fm = 79.393

[Aggregate metrics]:
rouge1     | fm: 87.344 | p: 86.570 | r: 88.352
rouge2     | fm: 50.469 | p: 50.121 | r: 50.905
rougeL     | fm: 75.501 | p: 74.872 | r: 76.296
rougeLsum  | fm: 75.522 | p: 74.893 | r: 76.356
r1fm+r2fm = 137.813

input #99 time: 0:11:10 | total time: 18:08:26


Done with all.
