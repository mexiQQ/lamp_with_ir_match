


Command: attack2.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 2000 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
cosin similarity: -0.8934663382597008 normalized error: 1.733659495003061
cosin similarity: 0.8934663382597008 normalized error: 0.5033565318294141
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.9195889576675713 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 1.7000055914312888 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 1.6292203331030068 for ['[CLS] hybrid counter [SEP]']
[Init] best rec loss: 1.5519310411404896 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 1.3563057900385864 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.402 (perp=10.334, rec=0.335), tot_loss_proj:2.680 [t=0.30s]
prediction: ['[CLS] certainly disappointed [SEP]']
[ 100/2000] tot_loss=2.265 (perp=10.251, rec=0.215), tot_loss_proj:2.331 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.225 (perp=10.251, rec=0.175), tot_loss_proj:2.320 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.251, rec=0.165), tot_loss_proj:2.342 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.222 (perp=10.251, rec=0.172), tot_loss_proj:2.312 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.313 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.202 (perp=10.251, rec=0.151), tot_loss_proj:2.317 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.211 (perp=10.251, rec=0.161), tot_loss_proj:2.313 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.310 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.210 (perp=10.251, rec=0.160), tot_loss_proj:2.316 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.190 (perp=10.251, rec=0.139), tot_loss_proj:2.308 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.193 (perp=10.251, rec=0.143), tot_loss_proj:2.304 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.198 (perp=10.251, rec=0.148), tot_loss_proj:2.314 [t=0.32s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.196 (perp=10.251, rec=0.146), tot_loss_proj:2.320 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.203 (perp=10.251, rec=0.152), tot_loss_proj:2.317 [t=0.36s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.192 (perp=10.251, rec=0.142), tot_loss_proj:2.324 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.309 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.205 (perp=10.251, rec=0.155), tot_loss_proj:2.321 [t=0.38s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.191 (perp=10.251, rec=0.140), tot_loss_proj:2.328 [t=0.34s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.312 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.327 [t=0.34s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.307 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.317 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.191 (perp=10.251, rec=0.140), tot_loss_proj:2.312 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.194 (perp=10.251, rec=0.144), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.208 (perp=10.251, rec=0.158), tot_loss_proj:2.304 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.207 (perp=10.251, rec=0.156), tot_loss_proj:2.327 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.304 [t=0.33s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.197 (perp=10.251, rec=0.147), tot_loss_proj:2.314 [t=0.37s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.184 (perp=10.251, rec=0.134), tot_loss_proj:2.321 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.196 (perp=10.251, rec=0.146), tot_loss_proj:2.308 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.193 (perp=10.251, rec=0.143), tot_loss_proj:2.313 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.194 (perp=10.251, rec=0.144), tot_loss_proj:2.314 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.197 (perp=10.251, rec=0.147), tot_loss_proj:2.323 [t=0.41s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.193 (perp=10.251, rec=0.143), tot_loss_proj:2.311 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.204 (perp=10.251, rec=0.154), tot_loss_proj:2.325 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.208 (perp=10.251, rec=0.158), tot_loss_proj:2.322 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.208 (perp=10.251, rec=0.158), tot_loss_proj:2.316 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.320 [t=0.33s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.195 (perp=10.251, rec=0.144), tot_loss_proj:2.311 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:11:49 | total time: 0:11:49


Running input #1 of 100.
reference: 
========================
splendidly 
========================
cosin similarity: -0.9215972518936497 normalized error: 1.862747916466129
cosin similarity: 0.9215972518936498 normalized error: 0.4365905743006529
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.7844158145081626 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 1.6785674942866482 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 1.677126732716619 for ['[CLS] conducted predator [SEP]']
[Init] best rec loss: 1.5444858188097057 for ['[CLS] j native [SEP]']
[Init] best rec loss: 1.1461405497950246 for ['[CLS] finally relative [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.308 (perp=9.613, rec=0.385), tot_loss_proj:3.098 [t=0.26s]
prediction: ['[CLS] finally successfully [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.288, rec=0.317), tot_loss_proj:2.493 [t=0.28s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.302 (perp=10.288, rec=0.244), tot_loss_proj:2.492 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.289 (perp=10.288, rec=0.231), tot_loss_proj:2.498 [t=0.26s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.059 (perp=9.171, rec=0.225), tot_loss_proj:2.048 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=2.048 (perp=9.171, rec=0.213), tot_loss_proj:2.055 [t=0.40s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.047 (perp=9.171, rec=0.212), tot_loss_proj:2.045 [t=0.38s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.041 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=2.030 (perp=9.171, rec=0.196), tot_loss_proj:2.054 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.038 (perp=9.171, rec=0.203), tot_loss_proj:2.054 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.034 (perp=9.171, rec=0.200), tot_loss_proj:2.056 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.050 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.038 (perp=9.171, rec=0.204), tot_loss_proj:2.061 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.036 (perp=9.171, rec=0.202), tot_loss_proj:2.059 [t=0.30s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=2.039 (perp=9.171, rec=0.204), tot_loss_proj:2.038 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.022 (perp=9.171, rec=0.188), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.038 (perp=9.171, rec=0.203), tot_loss_proj:2.047 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=2.043 (perp=9.171, rec=0.209), tot_loss_proj:2.040 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.034 (perp=9.171, rec=0.200), tot_loss_proj:2.052 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=2.044 (perp=9.171, rec=0.210), tot_loss_proj:2.051 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=2.039 (perp=9.171, rec=0.205), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=2.033 (perp=9.171, rec=0.198), tot_loss_proj:2.062 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=2.043 (perp=9.171, rec=0.208), tot_loss_proj:2.048 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.042 (perp=9.171, rec=0.208), tot_loss_proj:2.062 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.031 (perp=9.171, rec=0.197), tot_loss_proj:2.045 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.046 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.040 (perp=9.171, rec=0.205), tot_loss_proj:2.053 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.048 (perp=9.171, rec=0.214), tot_loss_proj:2.049 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=2.043 (perp=9.171, rec=0.208), tot_loss_proj:2.051 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.034 (perp=9.171, rec=0.199), tot_loss_proj:2.055 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.039 (perp=9.171, rec=0.205), tot_loss_proj:2.057 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=2.029 (perp=9.171, rec=0.195), tot_loss_proj:2.053 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.051 (perp=9.171, rec=0.217), tot_loss_proj:2.060 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.040 (perp=9.171, rec=0.205), tot_loss_proj:2.057 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=2.042 (perp=9.171, rec=0.208), tot_loss_proj:2.053 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.043 (perp=9.171, rec=0.209), tot_loss_proj:2.052 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.037 (perp=9.171, rec=0.203), tot_loss_proj:2.055 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=2.047 (perp=9.171, rec=0.213), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.043 (perp=9.171, rec=0.209), tot_loss_proj:2.053 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:11:06 | total time: 0:22:55


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
cosin similarity: 0.9258773195154295 normalized error: 0.4567743850008564
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 1.240719218736061 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 1.2380029208513876 for ['[CLS]〜 wash at [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.695 (perp=11.388, rec=0.417), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS]ing gaining worth [SEP]']
[ 100/2000] tot_loss=2.306 (perp=10.246, rec=0.257), tot_loss_proj:2.565 [t=0.26s]
prediction: ['[CLS] bringing gaining momentum [SEP]']
[ 150/2000] tot_loss=2.387 (perp=10.861, rec=0.215), tot_loss_proj:3.406 [t=0.26s]
prediction: ['[CLS]iring gaining momentum [SEP]']
[ 200/2000] tot_loss=2.331 (perp=10.812, rec=0.169), tot_loss_proj:3.400 [t=0.27s]
prediction: ['[CLS]plify gaining momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.323 (perp=10.812, rec=0.161), tot_loss_proj:3.391 [t=0.26s]
prediction: ['[CLS]plify gaining momentum [SEP]']
[ 300/2000] tot_loss=2.318 (perp=10.812, rec=0.156), tot_loss_proj:3.385 [t=0.27s]
prediction: ['[CLS]plify gaining momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.320 (perp=10.812, rec=0.158), tot_loss_proj:3.364 [t=0.25s]
prediction: ['[CLS]plify gaining momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.328 (perp=10.795, rec=0.169), tot_loss_proj:2.978 [t=0.28s]
prediction: ['[CLS]pling gaining momentum [SEP]']
[ 450/2000] tot_loss=2.310 (perp=10.795, rec=0.151), tot_loss_proj:2.966 [t=0.25s]
prediction: ['[CLS]pling gaining momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.319 (perp=10.795, rec=0.160), tot_loss_proj:2.979 [t=0.25s]
prediction: ['[CLS]pling gaining momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.306 (perp=10.795, rec=0.147), tot_loss_proj:2.972 [t=0.25s]
prediction: ['[CLS]pling gaining momentum [SEP]']
[ 600/2000] tot_loss=2.314 (perp=10.795, rec=0.155), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS]pling gaining momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.931 (perp=8.881, rec=0.155), tot_loss_proj:2.330 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.927 (perp=8.881, rec=0.151), tot_loss_proj:2.323 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
[ 750/2000] tot_loss=1.926 (perp=8.881, rec=0.150), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.919 (perp=8.881, rec=0.143), tot_loss_proj:2.334 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.918 (perp=8.881, rec=0.142), tot_loss_proj:2.326 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
[ 900/2000] tot_loss=1.922 (perp=8.881, rec=0.146), tot_loss_proj:2.332 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.915 (perp=8.881, rec=0.138), tot_loss_proj:2.326 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.921 (perp=8.881, rec=0.145), tot_loss_proj:2.331 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1050/2000] tot_loss=1.933 (perp=8.881, rec=0.157), tot_loss_proj:2.325 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.933 (perp=8.881, rec=0.156), tot_loss_proj:2.326 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.919 (perp=8.881, rec=0.143), tot_loss_proj:2.333 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1200/2000] tot_loss=1.920 (perp=8.881, rec=0.144), tot_loss_proj:2.328 [t=0.28s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.929 (perp=8.881, rec=0.152), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.917 (perp=8.881, rec=0.141), tot_loss_proj:2.317 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1350/2000] tot_loss=1.919 (perp=8.881, rec=0.143), tot_loss_proj:2.308 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.918 (perp=8.881, rec=0.141), tot_loss_proj:2.323 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.922 (perp=8.881, rec=0.146), tot_loss_proj:2.330 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1500/2000] tot_loss=1.924 (perp=8.881, rec=0.147), tot_loss_proj:2.318 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.917 (perp=8.881, rec=0.141), tot_loss_proj:2.324 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.925 (perp=8.881, rec=0.148), tot_loss_proj:2.321 [t=0.28s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1650/2000] tot_loss=1.930 (perp=8.881, rec=0.153), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.927 (perp=8.881, rec=0.151), tot_loss_proj:2.322 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.913 (perp=8.881, rec=0.137), tot_loss_proj:2.322 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1800/2000] tot_loss=1.912 (perp=8.881, rec=0.136), tot_loss_proj:2.323 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.918 (perp=8.881, rec=0.142), tot_loss_proj:2.315 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.918 (perp=8.881, rec=0.142), tot_loss_proj:2.322 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1950/2000] tot_loss=1.920 (perp=8.881, rec=0.144), tot_loss_proj:2.321 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.911 (perp=8.881, rec=0.135), tot_loss_proj:2.314 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] many gaining momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 93.333 | p: 93.333 | r: 93.333
rougeLsum  | fm: 93.333 | p: 93.333 | r: 93.333
r1fm+r2fm = 168.333

input #2 time: 0:10:59 | total time: 0:33:55


Running input #3 of 100.
reference: 
========================
flawless film 
========================
cosin similarity: -0.7101217562261617 normalized error: 1.6831364410360434
cosin similarity: 0.7101217562261617 normalized error: 0.6049972845812499
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9855863451957703 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.7907690405845642 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.7634335160255432 for ['[CLS] anton laughed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.280 (perp=10.476, rec=0.185), tot_loss_proj:2.419 [t=0.27s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 100/2000] tot_loss=2.112 (perp=10.226, rec=0.067), tot_loss_proj:2.352 [t=0.25s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.096 (perp=10.226, rec=0.051), tot_loss_proj:2.364 [t=0.25s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.110 (perp=10.226, rec=0.065), tot_loss_proj:2.366 [t=0.24s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.763 (perp=8.385, rec=0.086), tot_loss_proj:1.767 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.746 (perp=8.385, rec=0.069), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.730 (perp=8.385, rec=0.053), tot_loss_proj:1.755 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.751 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.747 (perp=8.385, rec=0.070), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.758 (perp=8.385, rec=0.081), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.734 (perp=8.385, rec=0.057), tot_loss_proj:1.766 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.745 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.731 (perp=8.385, rec=0.054), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.748 (perp=8.385, rec=0.071), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.759 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.718 (perp=8.385, rec=0.041), tot_loss_proj:1.758 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.767 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.385, rec=0.055), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.385, rec=0.044), tot_loss_proj:1.752 [t=0.29s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.749 (perp=8.385, rec=0.072), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.748 (perp=8.385, rec=0.071), tot_loss_proj:1.752 [t=0.34s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.724 (perp=8.385, rec=0.048), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.730 (perp=8.385, rec=0.053), tot_loss_proj:1.746 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.754 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.747 (perp=8.385, rec=0.070), tot_loss_proj:1.751 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.729 (perp=8.385, rec=0.052), tot_loss_proj:1.762 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.744 (perp=8.385, rec=0.067), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.715 (perp=8.385, rec=0.038), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.737 (perp=8.385, rec=0.060), tot_loss_proj:1.762 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.748 (perp=8.385, rec=0.071), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.737 (perp=8.385, rec=0.060), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.729 (perp=8.385, rec=0.052), tot_loss_proj:1.758 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.746 (perp=8.385, rec=0.069), tot_loss_proj:1.765 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.385, rec=0.066), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.385, rec=0.059), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 81.250 | p: 81.250 | r: 81.250
rougeL     | fm: 95.000 | p: 95.000 | r: 95.000
rougeLsum  | fm: 95.000 | p: 95.000 | r: 95.000
r1fm+r2fm = 176.250

input #3 time: 0:11:01 | total time: 0:44:56


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
cosin similarity: -0.9048403215042558 normalized error: 1.78792991317121
cosin similarity: 0.9048403215042556 normalized error: 0.475176931612047
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.79504128600855 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 1.7741654840541323 for ['[CLS] watch joint weekly [SEP]']
[Init] best rec loss: 1.7312058429382033 for ['[CLS] religious tip seat [SEP]']
[Init] best rec loss: 1.729607759519339 for ['[CLS] counters ragedu [SEP]']
[Init] best rec loss: 1.4748459428734992 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 1.2364187869281222 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.289 (perp=14.362, rec=0.417), tot_loss_proj:3.528 [t=0.28s]
prediction: ['[CLS] tires uglyome [SEP]']
[ 100/2000] tot_loss=2.833 (perp=12.901, rec=0.253), tot_loss_proj:3.237 [t=0.25s]
prediction: ['[CLS] tires awfulome [SEP]']
[ 150/2000] tot_loss=2.416 (perp=11.053, rec=0.205), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] tiresomeome [SEP]']
[ 200/2000] tot_loss=2.395 (perp=11.053, rec=0.185), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] tiresomeome [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.279 (perp=9.735, rec=0.332), tot_loss_proj:2.426 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 300/2000] tot_loss=2.149 (perp=9.735, rec=0.202), tot_loss_proj:2.445 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.122 (perp=9.735, rec=0.175), tot_loss_proj:2.439 [t=0.28s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.112 (perp=9.735, rec=0.165), tot_loss_proj:2.431 [t=0.29s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 450/2000] tot_loss=2.108 (perp=9.735, rec=0.161), tot_loss_proj:2.434 [t=0.27s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.096 (perp=9.735, rec=0.149), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.092 (perp=9.735, rec=0.146), tot_loss_proj:2.443 [t=0.29s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 600/2000] tot_loss=2.093 (perp=9.735, rec=0.146), tot_loss_proj:2.440 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.086 (perp=9.680, rec=0.150), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.044 (perp=9.501, rec=0.144), tot_loss_proj:2.705 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
[ 750/2000] tot_loss=2.039 (perp=9.501, rec=0.138), tot_loss_proj:2.701 [t=0.29s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.052 (perp=9.501, rec=0.152), tot_loss_proj:2.702 [t=0.32s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.039 (perp=9.501, rec=0.139), tot_loss_proj:2.694 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
[ 900/2000] tot_loss=2.039 (perp=9.501, rec=0.139), tot_loss_proj:2.699 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.036 (perp=9.501, rec=0.136), tot_loss_proj:2.700 [t=0.30s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1000/2000] tot_loss=2.036 (perp=9.501, rec=0.136), tot_loss_proj:2.705 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
[1050/2000] tot_loss=2.038 (perp=9.501, rec=0.138), tot_loss_proj:2.700 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1100/2000] tot_loss=2.030 (perp=9.501, rec=0.130), tot_loss_proj:2.705 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1150/2000] tot_loss=2.035 (perp=9.501, rec=0.135), tot_loss_proj:2.703 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
[1200/2000] tot_loss=2.034 (perp=9.501, rec=0.134), tot_loss_proj:2.697 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1250/2000] tot_loss=2.033 (perp=9.501, rec=0.132), tot_loss_proj:2.707 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1300/2000] tot_loss=2.026 (perp=9.501, rec=0.125), tot_loss_proj:2.701 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
[1350/2000] tot_loss=2.031 (perp=9.501, rec=0.131), tot_loss_proj:2.705 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1400/2000] tot_loss=2.031 (perp=9.501, rec=0.131), tot_loss_proj:2.702 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1450/2000] tot_loss=2.038 (perp=9.501, rec=0.138), tot_loss_proj:2.706 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
[1500/2000] tot_loss=2.026 (perp=9.501, rec=0.126), tot_loss_proj:2.699 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1550/2000] tot_loss=2.024 (perp=9.501, rec=0.123), tot_loss_proj:2.701 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1600/2000] tot_loss=2.027 (perp=9.501, rec=0.127), tot_loss_proj:2.697 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
[1650/2000] tot_loss=2.026 (perp=9.501, rec=0.126), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1700/2000] tot_loss=2.031 (perp=9.501, rec=0.131), tot_loss_proj:2.708 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1750/2000] tot_loss=2.046 (perp=9.501, rec=0.146), tot_loss_proj:2.708 [t=0.21s]
prediction: ['[CLS] minds tiresome [SEP]']
[1800/2000] tot_loss=2.018 (perp=9.501, rec=0.118), tot_loss_proj:2.706 [t=0.21s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1850/2000] tot_loss=2.027 (perp=9.501, rec=0.127), tot_loss_proj:2.702 [t=0.21s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1900/2000] tot_loss=2.040 (perp=9.501, rec=0.140), tot_loss_proj:2.700 [t=0.24s]
prediction: ['[CLS] minds tiresome [SEP]']
[1950/2000] tot_loss=2.038 (perp=9.501, rec=0.138), tot_loss_proj:2.698 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[2000/2000] tot_loss=2.019 (perp=9.501, rec=0.119), tot_loss_proj:2.699 [t=0.28s]
prediction: ['[CLS] minds tiresome [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] minds tiresome [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 87.429 | p: 86.000 | r: 89.333
rouge2     | fm: 65.000 | p: 65.000 | r: 65.000
rougeL     | fm: 87.429 | p: 86.000 | r: 89.333
rougeLsum  | fm: 87.429 | p: 86.000 | r: 89.333
r1fm+r2fm = 152.429

input #4 time: 0:11:02 | total time: 0:55:59


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
cosin similarity: -0.6976662371922135 normalized error: 1.6799576310302529
cosin similarity: 0.6976662371922135 normalized error: 0.6126100487423699
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9211751222610474 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.8462492227554321 for ['[CLS] works flow [SEP]']
[Init] best rec loss: 0.8158178329467773 for ['[CLS] sur golden [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=11.854, rec=0.130), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 100/2000] tot_loss=2.427 (perp=11.854, rec=0.057), tot_loss_proj:2.593 [t=0.29s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 150/2000] tot_loss=2.441 (perp=11.854, rec=0.071), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 200/2000] tot_loss=2.439 (perp=11.854, rec=0.068), tot_loss_proj:2.598 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.440 (perp=11.854, rec=0.069), tot_loss_proj:2.587 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.437 (perp=11.854, rec=0.067), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.431 (perp=11.854, rec=0.060), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.430 (perp=11.854, rec=0.059), tot_loss_proj:2.590 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.434 (perp=11.854, rec=0.063), tot_loss_proj:2.595 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.436 (perp=11.854, rec=0.065), tot_loss_proj:2.573 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.439 (perp=11.854, rec=0.068), tot_loss_proj:2.593 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.433 (perp=11.854, rec=0.062), tot_loss_proj:2.587 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.440 (perp=11.854, rec=0.070), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.422 (perp=11.854, rec=0.051), tot_loss_proj:2.594 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.433 (perp=11.854, rec=0.062), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.437 (perp=11.854, rec=0.066), tot_loss_proj:2.600 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.428 (perp=11.854, rec=0.057), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.445 (perp=11.854, rec=0.074), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.435 (perp=11.854, rec=0.064), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.420 (perp=11.854, rec=0.049), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.435 (perp=11.854, rec=0.064), tot_loss_proj:2.590 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.439 (perp=11.854, rec=0.068), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.424 (perp=11.854, rec=0.053), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.433 (perp=11.854, rec=0.062), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.438 (perp=11.854, rec=0.067), tot_loss_proj:2.593 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.425 (perp=11.854, rec=0.054), tot_loss_proj:2.586 [t=0.29s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.438 (perp=11.854, rec=0.068), tot_loss_proj:2.592 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.427 (perp=11.854, rec=0.057), tot_loss_proj:2.580 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.434 (perp=11.854, rec=0.063), tot_loss_proj:2.592 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.431 (perp=11.854, rec=0.060), tot_loss_proj:2.589 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.423 (perp=11.854, rec=0.052), tot_loss_proj:2.585 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.448 (perp=11.854, rec=0.077), tot_loss_proj:2.587 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.430 (perp=11.854, rec=0.059), tot_loss_proj:2.585 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.425 (perp=11.854, rec=0.054), tot_loss_proj:2.594 [t=0.29s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.435 (perp=11.854, rec=0.064), tot_loss_proj:2.598 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.436 (perp=11.854, rec=0.065), tot_loss_proj:2.591 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.440 (perp=11.854, rec=0.069), tot_loss_proj:2.591 [t=0.21s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.443 (perp=11.854, rec=0.072), tot_loss_proj:2.596 [t=0.21s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.441 (perp=11.854, rec=0.071), tot_loss_proj:2.586 [t=0.21s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.424 (perp=11.854, rec=0.053), tot_loss_proj:2.595 [t=0.20s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.524 | p: 88.333 | r: 91.111
rouge2     | fm: 54.167 | p: 54.167 | r: 54.167
rougeL     | fm: 85.357 | p: 84.167 | r: 86.944
rougeLsum  | fm: 85.357 | p: 84.167 | r: 86.944
r1fm+r2fm = 143.690

input #5 time: 0:10:57 | total time: 1:06:56


Running input #6 of 100.
reference: 
========================
grayish 
========================
cosin similarity: -0.9293236555171187 normalized error: 1.7532736189764786
cosin similarity: 0.9293236555171187 normalized error: 0.4810054002498873
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 1.8880154143242218 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 1.8584456530627196 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 1.7230445598044264 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 1.5259105526013559 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 1.2919898446420643 for ['[CLS] air little [SEP]']
[Init] best rec loss: 1.210615359223579 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 1.1647693062634903 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 1.150912958819466 for ['[CLS] too u2 [SEP]']
[Init] best rec loss: 1.0806428981312202 for ['[CLS] revid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.725 (perp=6.813, rec=0.363), tot_loss_proj:2.665 [t=0.21s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.848 (perp=8.089, rec=0.230), tot_loss_proj:1.841 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.781 (perp=8.089, rec=0.163), tot_loss_proj:1.831 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.761 (perp=8.089, rec=0.143), tot_loss_proj:1.830 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.748 (perp=8.089, rec=0.130), tot_loss_proj:1.822 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.753 (perp=8.089, rec=0.135), tot_loss_proj:1.836 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.759 (perp=8.089, rec=0.142), tot_loss_proj:1.823 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.765 (perp=8.089, rec=0.147), tot_loss_proj:1.827 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.829 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.750 (perp=8.089, rec=0.132), tot_loss_proj:1.828 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.749 (perp=8.089, rec=0.132), tot_loss_proj:1.836 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.757 (perp=8.089, rec=0.139), tot_loss_proj:1.834 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.827 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.751 (perp=8.089, rec=0.133), tot_loss_proj:1.835 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.756 (perp=8.089, rec=0.138), tot_loss_proj:1.825 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.753 (perp=8.089, rec=0.136), tot_loss_proj:1.827 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.820 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.089, rec=0.138), tot_loss_proj:1.822 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.761 (perp=8.089, rec=0.143), tot_loss_proj:1.830 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.089, rec=0.120), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.744 (perp=8.089, rec=0.126), tot_loss_proj:1.824 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.837 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=8.089, rec=0.126), tot_loss_proj:1.828 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.764 (perp=8.089, rec=0.147), tot_loss_proj:1.826 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.749 (perp=8.089, rec=0.132), tot_loss_proj:1.825 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.755 (perp=8.089, rec=0.137), tot_loss_proj:1.824 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.738 (perp=8.089, rec=0.120), tot_loss_proj:1.827 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.756 (perp=8.089, rec=0.138), tot_loss_proj:1.826 [t=0.31s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.751 (perp=8.089, rec=0.133), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.815 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.750 (perp=8.089, rec=0.133), tot_loss_proj:1.836 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.752 (perp=8.089, rec=0.134), tot_loss_proj:1.820 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.089, rec=0.133), tot_loss_proj:1.836 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.763 (perp=8.089, rec=0.145), tot_loss_proj:1.820 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.759 (perp=8.089, rec=0.141), tot_loss_proj:1.835 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.752 (perp=8.089, rec=0.134), tot_loss_proj:1.817 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=8.089, rec=0.142), tot_loss_proj:1.825 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.756 (perp=8.089, rec=0.139), tot_loss_proj:1.816 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.753 (perp=8.089, rec=0.135), tot_loss_proj:1.822 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.089, rec=0.144), tot_loss_proj:1.831 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.020 | p: 90.000 | r: 92.381
rouge2     | fm: 60.714 | p: 60.714 | r: 60.714
rougeL     | fm: 87.755 | p: 86.429 | r: 88.810
rougeLsum  | fm: 87.449 | p: 86.429 | r: 88.810
r1fm+r2fm = 151.735

input #6 time: 0:09:27 | total time: 1:16:23


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
cosin similarity: -0.8826673880610065 normalized error: 1.6975368459944407
cosin similarity: 0.8826673880610065 normalized error: 0.5235793653735517
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 1.8215278228898568 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 1.535022374121544 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 1.5228614226146897 for ['[CLS]eringtracted bros ppfounded to extra billion bride collective darted doping actually riley measurement guybl news found muchox only affiliation sister times down [SEP]']
[Init] best rec loss: 1.4948979773870148 for ['[CLS] vance golf belt handyolved fl researchtium anonymousina me man murphyoof bearing zetavocationtellrti american autopsy that lie amongₑ free [SEP]']
[Init] best rec loss: 1.3951092681149906 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 1.3586777177850868 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 1.3585023317811675 for ['[CLS] # beings part hs end com baby purposepia dock median both infants flow conference sat exactly cod openpר pay grande moths most jenny [SEP]']
[Init] best perm rec loss: 1.3557871229383562 for ['[CLS] exactly part jenny conferencepia hs infants end dock satר both pay baby cod flow grande # beingsp com moths open median most purpose [SEP]']
[Init] best perm rec loss: 1.3547443298820019 for ['[CLS] part beings sat cod bothp com purpose baby hs grande jenny dockpia exactly median infants conference open flowר end moths pay # most [SEP]']
[Init] best perm rec loss: 1.354736265131166 for ['[CLS] pay babyר dock cod part most purpose median grande flow beings hs both open # infantsp conference end exactly com moths jennypia sat [SEP]']
[Init] best perm rec loss: 1.3541341246963845 for ['[CLS] median dock baby flow com pay conference purpose infants most exactly # jenny bothר part beingsppia hs sat grande end open cod moths [SEP]']
[Init] best perm rec loss: 1.3527534121050935 for ['[CLS]p flow moths end jenny openר most baby codpia infants dock beings conference hs purpose both grande part com pay exactly # median sat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.773 (perp=11.533, rec=0.466), tot_loss_proj:3.401 [t=0.21s]
prediction: ['[CLS] - meter dumb internet anybody bastard problem facelessless bad serviceins bad private problemless of died stupidbaum poor his dating poor problem [SEP]']
[ 100/2000] tot_loss=2.405 (perp=10.361, rec=0.333), tot_loss_proj:3.130 [t=0.21s]
prediction: ['[CLS] ( least dumb character seemed commune problem face an. bad punkins meet private problemless than no unlike cheek pay his $ poisoning problem [SEP]']
[ 150/2000] tot_loss=2.229 (perp=9.801, rec=0.269), tot_loss_proj:2.990 [t=0.21s]
prediction: ['[CLS] (.? characterure armed problem worst not. problem store watching meet the problem is is no unlike he poor his $. problem [SEP]']
[ 200/2000] tot_loss=2.223 (perp=9.865, rec=0.250), tot_loss_proj:2.997 [t=0.21s]
prediction: ['[CLS] (. lies character meant mind no worst not. problem warsaw or failed the problem is is no nothing he poorly his ages. problem [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.218 (perp=9.965, rec=0.225), tot_loss_proj:3.023 [t=0.22s]
prediction: ['[CLS] (. lies character meant mind no worst love. problem fledged or failed the problem is has no nothing he ages cent poorly his problem [SEP]']
[ 300/2000] tot_loss=2.207 (perp=10.025, rec=0.202), tot_loss_proj:3.266 [t=0.21s]
prediction: ['[CLS] no. words character man cute nourity love. problem fledged or failed ; problem is has no inappropriate. agesy poorly his problem [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.188 (perp=9.987, rec=0.191), tot_loss_proj:3.021 [t=0.21s]
prediction: ['[CLS] no ; mind character man dumb no nix love. problem fledged orrred ; problem is has no issue. agesied poorly his ugly [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.052 (perp=9.323, rec=0.187), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] no ; cute character man mom problem nix love. no fledged or yeah ; problem is has no issue. agesied poorly his ugly [SEP]']
[ 450/2000] tot_loss=1.863 (perp=8.446, rec=0.174), tot_loss_proj:3.198 [t=0.32s]
prediction: ['[CLS] no ; cute character man mom problem. love. no worst or yeah ; problem is has no issue. agesied / his ugly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.932 (perp=8.817, rec=0.169), tot_loss_proj:3.219 [t=0.27s]
prediction: ['[CLS] no. cute character man aged problem. love. no spawned or not ; problem is has no issue. friendshipied mom his ugly [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.641 (perp=7.317, rec=0.177), tot_loss_proj:2.460 [t=0.29s]
prediction: ['[CLS]. no cute character man / mind. love. no cute or not ; problem is has no issue. friendshipied mom his ugly [SEP]']
[ 600/2000] tot_loss=1.669 (perp=7.553, rec=0.159), tot_loss_proj:2.523 [t=0.28s]
prediction: ['[CLS]. no cute character man / mind. love. no spawned or not ; problem is has no issue. lovedied mom his ugly [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.667 (perp=7.523, rec=0.163), tot_loss_proj:2.630 [t=0.31s]
prediction: ['[CLS]. no cute character he / mind. love or no spawned or not ; problem is has no issue. cuteied his ugly mom [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.663 (perp=7.567, rec=0.149), tot_loss_proj:2.651 [t=0.29s]
prediction: ['[CLS]. no cute character he / mind. love or no here or not ; problem is has no issue. cuteied his ugly mom [SEP]']
[ 750/2000] tot_loss=1.668 (perp=7.567, rec=0.155), tot_loss_proj:2.648 [t=0.28s]
prediction: ['[CLS]. no cute character he / mind. love or no here or not ; problem is has no issue. cuteied his ugly mom [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.670 (perp=7.592, rec=0.151), tot_loss_proj:2.471 [t=0.25s]
prediction: ['[CLS]. no cute character he / mind. love or no here or not ; problem is has no no. cuteied his ugly mom [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.676 (perp=7.591, rec=0.157), tot_loss_proj:2.471 [t=0.25s]
prediction: ['[CLS]. no cute character he thugs mind. love or no no or not ; problem is has no no. cute spawned his ugly mom [SEP]']
[ 900/2000] tot_loss=1.664 (perp=7.591, rec=0.146), tot_loss_proj:2.460 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or no no or not ; problem is has no no. cute spawned his ugly mom [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.634 (perp=7.452, rec=0.144), tot_loss_proj:2.411 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or no or no not ; problem is has no no. cute here his ugly mom [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.669 (perp=7.647, rec=0.140), tot_loss_proj:2.444 [t=0.28s]
prediction: ['[CLS]. no cute character he thugs mind. love or the no or not ; problem is has no no. cute here his ugly mom [SEP]']
[1050/2000] tot_loss=1.698 (perp=7.786, rec=0.141), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or the no or not ; problem is has no no. cute here they ugly mom [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.680 (perp=7.695, rec=0.141), tot_loss_proj:2.802 [t=0.25s]
prediction: ['[CLS]. no cute character he thugs mind. love or the they or not ; problem is has no no. cute here no ugly mom [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.754 (perp=8.105, rec=0.133), tot_loss_proj:2.621 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
[1200/2000] tot_loss=1.758 (perp=8.105, rec=0.137), tot_loss_proj:2.622 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1250/2000] tot_loss=1.750 (perp=8.105, rec=0.129), tot_loss_proj:2.618 [t=0.27s]
prediction: ['[CLS]. no cute character he thugs mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1300/2000] tot_loss=1.724 (perp=7.980, rec=0.128), tot_loss_proj:2.564 [t=0.26s]
prediction: ['[CLS] here no cute character he / mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
[1350/2000] tot_loss=1.723 (perp=7.980, rec=0.127), tot_loss_proj:2.560 [t=0.27s]
prediction: ['[CLS] here no cute character he / mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=7.980, rec=0.118), tot_loss_proj:2.554 [t=0.26s]
prediction: ['[CLS] here no cute character he / mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.639 (perp=7.519, rec=0.136), tot_loss_proj:2.424 [t=0.25s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
[1500/2000] tot_loss=1.645 (perp=7.519, rec=0.141), tot_loss_proj:2.422 [t=0.25s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.519, rec=0.138), tot_loss_proj:2.423 [t=0.27s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1600/2000] tot_loss=1.632 (perp=7.519, rec=0.128), tot_loss_proj:2.427 [t=0.26s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
[1650/2000] tot_loss=1.683 (perp=7.731, rec=0.137), tot_loss_proj:2.467 [t=0.27s]
prediction: ['[CLS] here no cute character he / mind. love or they i not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=7.731, rec=0.127), tot_loss_proj:2.461 [t=0.26s]
prediction: ['[CLS] here no cute character he / mind. love or they i not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.653 (perp=7.605, rec=0.132), tot_loss_proj:2.360 [t=0.27s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
[1800/2000] tot_loss=1.653 (perp=7.605, rec=0.132), tot_loss_proj:2.361 [t=0.26s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Attempt swap
[1850/2000] tot_loss=1.642 (perp=7.605, rec=0.121), tot_loss_proj:2.364 [t=0.28s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Attempt swap
[1900/2000] tot_loss=1.648 (perp=7.605, rec=0.127), tot_loss_proj:2.359 [t=0.28s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
[1950/2000] tot_loss=1.659 (perp=7.605, rec=0.138), tot_loss_proj:2.363 [t=0.26s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.605, rec=0.126), tot_loss_proj:2.362 [t=0.27s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.767 | p: 68.182 | r: 71.429
rouge2     | fm: 14.634 | p: 14.286 | r: 15.000
rougeL     | fm: 41.860 | p: 40.909 | r: 42.857
rougeLsum  | fm: 41.860 | p: 40.909 | r: 42.857
r1fm+r2fm = 84.402

[Aggregate metrics]:
rouge1     | fm: 89.286 | p: 87.500 | r: 90.000
rouge2     | fm: 54.954 | p: 54.911 | r: 55.000
rougeL     | fm: 82.340 | p: 81.364 | r: 83.408
rougeLsum  | fm: 81.750 | p: 80.739 | r: 83.065
r1fm+r2fm = 144.240

input #7 time: 0:10:31 | total time: 1:26:55


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
cosin similarity: 0.9218859490507135 normalized error: 0.5104764842116075
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 1.2750340676286591 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best perm rec loss: 1.2738230356414995 for ['[CLS] computer cinema clubs paris fitting alloy taught passage across over luxury southern bargain gr table learning currently their band eye challenges pa those lea [SEP]']
[Init] best perm rec loss: 1.2726157089323598 for ['[CLS] paris table challenges bargain taught currently across learning clubs those band alloy fitting cinema gr southern over luxury pa eye their lea computer passage [SEP]']
[Init] best perm rec loss: 1.2726105145516666 for ['[CLS] taught learning pa bargain challenges luxury over gr across currently paris southern alloy passage cinema clubs band table lea eye their those fitting computer [SEP]']
[Init] best perm rec loss: 1.2718888606514211 for ['[CLS] pa table fitting computer lea alloy over paris their cinema challenges those luxury learning eye clubs southern currently bargain band across passage gr taught [SEP]']
[Init] best perm rec loss: 1.2703988613824198 for ['[CLS] taught learning lea gr computer cinema table their over passage band alloy pa southern bargain those fitting clubs luxury across currently paris challenges eye [SEP]']
[Init] best perm rec loss: 1.2699820162634163 for ['[CLS] eye southern bargain band paris table luxury cinema challenges currently learning passage taught over alloy computer those clubs across pa their fitting lea gr [SEP]']
[Init] best perm rec loss: 1.2684669647987539 for ['[CLS] taught cinema luxury currently clubs alloy over challenges southern computer lea gr pa paris those bargain eye table their across passage learning fitting band [SEP]']
[Init] best perm rec loss: 1.2682529522412755 for ['[CLS] challenges cinema bargain band pa across learning eye table southern currently computer luxury over those fitting gr paris passage lea alloy their clubs taught [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.122 (perp=13.465, rec=0.429), tot_loss_proj:4.354 [t=0.26s]
prediction: ['[CLS] downtown mission puzzles air dagger wherein android conspiracy minister bought athena purchase completion taxi fairly practical aircraftzziness fool louis due civilian likeathic [SEP]']
[ 100/2000] tot_loss=2.883 (perp=12.604, rec=0.363), tot_loss_proj:4.333 [t=0.28s]
prediction: ['[CLS] western thing costs cheerful warrior government android conspiracy player owned athena purchase completion debt fairly gambling episode kathy stupid with think killing conorathic [SEP]']
[ 150/2000] tot_loss=3.039 (perp=13.657, rec=0.307), tot_loss_proj:4.403 [t=0.28s]
prediction: ['[CLS] charity thing costssive reservoir film soap vanity player owned athena claim sight debt fairly fright films kathy hate - think paid vanityathic [SEP]']
[ 200/2000] tot_loss=2.850 (perp=12.839, rec=0.282), tot_loss_proj:4.120 [t=0.27s]
prediction: ['[CLS] demon film payssive reservoir filmudence vanity while ownedivation debtrting debt fairly frightmaxmax hate - felt paid vanityathic [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.921 (perp=13.040, rec=0.313), tot_loss_proj:4.135 [t=0.27s]
prediction: ["[CLS] demon film pays layne reservoir film tracy vanity while owned condoms debt doubt debt fairly vanitymaxmax vanity'felt paid vanityathic [SEP]"]
[ 300/2000] tot_loss=2.966 (perp=13.322, rec=0.301), tot_loss_proj:3.993 [t=0.25s]
prediction: ["[CLS] prophet film pays las reservoir film tracy vanity while owned similarly debt doubt what doubtmaxmaxmax vanity'felt paid vanityathic [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.710 (perp=12.395, rec=0.231), tot_loss_proj:3.927 [t=0.27s]
prediction: ["[CLS] capital that pays fright reservoir film tracy vanityed owned similarly owed feels what doubtmaxmax doubt vanity'felt owe vanity vegas [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.499 (perp=11.432, rec=0.212), tot_loss_proj:3.597 [t=0.26s]
prediction: ["[CLS] a that pays layne vanity film tracy, vanity owned similarly debt feels what doubtmaxmax doubt vanity'felt owed vanity vegas [SEP]"]
[ 450/2000] tot_loss=2.662 (perp=12.308, rec=0.201), tot_loss_proj:3.911 [t=0.28s]
prediction: ["[CLS] a that pays fright vanity film tracy, fright latitude similarly debt feels what doubtmaxmax doubt vanity'felt owed vanity baroque [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.546 (perp=11.777, rec=0.190), tot_loss_proj:3.793 [t=0.26s]
prediction: ["[CLS] a that pays fright vanity film tracy, baroque latitude similarly debt feels what doubt owedmax doubt vanity'felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.508 (perp=11.520, rec=0.204), tot_loss_proj:3.683 [t=0.26s]
prediction: ["[CLS] a that pays fright vanity film tracy, baroque latitude similarly debt feels what doubt owedmax'vanity doubt felt owed vanity fright [SEP]"]
[ 600/2000] tot_loss=2.489 (perp=11.520, rec=0.185), tot_loss_proj:3.693 [t=0.26s]
prediction: ["[CLS] a that pays fright vanity film tracy, baroque latitude similarly debt feels what doubt owedmax'vanity doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.546 (perp=11.818, rec=0.183), tot_loss_proj:3.757 [t=0.27s]
prediction: ["[CLS] a that pays vanity fright film tracy, baroque latitude similarly debt felt what doubt owedmax'vanity doubt felt owed benign fright [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.489 (perp=11.505, rec=0.188), tot_loss_proj:3.689 [t=0.29s]
prediction: ["[CLS] s that pays vanity fright film darcy, chaplin latitude similarly debt felt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
[ 750/2000] tot_loss=2.428 (perp=11.297, rec=0.169), tot_loss_proj:3.733 [t=0.27s]
prediction: ["[CLS] s that pays vanity fright film darcy, benign latitude similarly debt felt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=2.486 (perp=11.600, rec=0.166), tot_loss_proj:3.919 [t=0.26s]
prediction: ["[CLS] s that pays vanity benign film tracy, benign latitude similarly felt debt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=2.412 (perp=11.246, rec=0.163), tot_loss_proj:3.897 [t=0.28s]
prediction: ["[CLS] s that pays vanity benign, film feels benign latitude similarly felt debt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
[ 900/2000] tot_loss=2.403 (perp=11.246, rec=0.154), tot_loss_proj:3.900 [t=0.27s]
prediction: ["[CLS] s that pays vanity benign, film feels benign latitude similarly felt debt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.418 (perp=11.295, rec=0.159), tot_loss_proj:3.927 [t=0.26s]
prediction: ["[CLS] s that pays vanity benign, film feels similarly benign latitude felt debt what doubt owedmax 'fully doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.398 (perp=11.197, rec=0.159), tot_loss_proj:3.904 [t=0.30s]
prediction: ["[CLS] s that pays¥ benign felt film feels similarly benign latitude, debt what doubt owedmax 'ful doubt felt owed vanity fright [SEP]"]
[1050/2000] tot_loss=2.385 (perp=11.197, rec=0.146), tot_loss_proj:3.903 [t=0.30s]
prediction: ["[CLS] s that pays¥ benign felt film feels similarly benign latitude, debt what doubt owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.374 (perp=11.101, rec=0.154), tot_loss_proj:3.957 [t=0.25s]
prediction: ["[CLS] s that pays¥ benign felt film feels similarly benign latitude debt, what doubt owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
[1150/2000] tot_loss=2.475 (perp=11.615, rec=0.152), tot_loss_proj:4.046 [t=0.26s]
prediction: ["[CLS] s that pays¥ benign feels film precious unix benign latitude debt, what no owedmax 'ful doubt felt owed vanity fright [SEP]"]
[1200/2000] tot_loss=2.469 (perp=11.615, rec=0.146), tot_loss_proj:4.045 [t=0.29s]
prediction: ["[CLS] s that pays¥ benign feels film precious unix benign latitude debt, what no owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.420 (perp=11.363, rec=0.148), tot_loss_proj:4.017 [t=0.26s]
prediction: ["[CLS] s that pays¥ benign film feels precious unix benign latitude debt, what no owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.418 (perp=11.321, rec=0.154), tot_loss_proj:4.012 [t=0.26s]
prediction: ["[CLS] s that pays¥ benign film feels precious unix benign latitude debt, whatful abackmax'no doubt felt owed vanity fright [SEP]"]
[1350/2000] tot_loss=2.410 (perp=11.321, rec=0.146), tot_loss_proj:4.011 [t=0.27s]
prediction: ["[CLS] s that pays¥ benign film feels precious unix benign latitude debt, whatful abackmax'no doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.309 (perp=10.789, rec=0.152), tot_loss_proj:3.914 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful abackmax benign no doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.259 (perp=10.517, rec=0.156), tot_loss_proj:3.830 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful frightmax benign no doubt felt owed vanity aback [SEP]"]
[1500/2000] tot_loss=2.250 (perp=10.517, rec=0.146), tot_loss_proj:3.835 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful frightmax benign no doubt felt owed vanity aback [SEP]"]
Attempt swap
[1550/2000] tot_loss=2.249 (perp=10.517, rec=0.145), tot_loss_proj:3.829 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful frightmax benign no doubt felt owed vanity aback [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=2.221 (perp=10.405, rec=0.140), tot_loss_proj:3.762 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax benign no doubt felt owed vanity aback [SEP]"]
[1650/2000] tot_loss=2.224 (perp=10.405, rec=0.143), tot_loss_proj:3.761 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax benign no doubt felt owed vanity aback [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.196 (perp=10.273, rec=0.142), tot_loss_proj:3.756 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.199 (perp=10.273, rec=0.145), tot_loss_proj:3.755 [t=0.25s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
[1800/2000] tot_loss=2.197 (perp=10.273, rec=0.142), tot_loss_proj:3.758 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[1850/2000] tot_loss=2.154 (perp=10.036, rec=0.147), tot_loss_proj:3.692 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[1900/2000] tot_loss=2.145 (perp=10.036, rec=0.138), tot_loss_proj:3.692 [t=0.28s]
prediction: ["[CLS] s that pays¥'film feels precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
[1950/2000] tot_loss=2.149 (perp=10.036, rec=0.142), tot_loss_proj:3.694 [t=0.29s]
prediction: ["[CLS] s that pays¥'film feels precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.146 (perp=10.047, rec=0.137), tot_loss_proj:3.654 [t=0.28s]
prediction: ["[CLS] s that pays¥'film felt precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.415 | p: 61.905 | r: 65.000
rouge2     | fm: 10.256 | p: 10.000 | r: 10.526
rougeL     | fm: 39.024 | p: 38.095 | r: 40.000
rougeLsum  | fm: 39.024 | p: 38.095 | r: 40.000
r1fm+r2fm = 73.671

[Aggregate metrics]:
rouge1     | fm: 85.909 | p: 84.656 | r: 87.011
rouge2     | fm: 49.976 | p: 49.841 | r: 50.000
rougeL     | fm: 77.281 | p: 76.455 | r: 78.598
rougeLsum  | fm: 77.527 | p: 76.556 | r: 78.651
r1fm+r2fm = 135.885

input #8 time: 0:11:08 | total time: 1:38:03


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
cosin similarity: -0.9468267247362503 normalized error: 1.6636662226335797
cosin similarity: 0.9468267247362503 normalized error: 0.5190218301597448
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 1.6550674546111352 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 1.255493222442299 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 1.2165712992026636 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 1.1217013114929197 for ['[CLS] video guys glass stilldleulf explorer eva [SEP]']
[Init] best perm rec loss: 1.1158414846708098 for ['[CLS]dle glassulf explorer video eva guys still [SEP]']
[Init] best perm rec loss: 1.1137217329958664 for ['[CLS] glass video eva still explorerdle guysulf [SEP]']
[Init] best perm rec loss: 1.1125702822160046 for ['[CLS]ulfdle still eva glass video guys explorer [SEP]']
[Init] best perm rec loss: 1.1122852557154967 for ['[CLS] eva glass still explorer video guysdleulf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.145 (perp=13.749, rec=0.395), tot_loss_proj:4.170 [t=0.26s]
prediction: ['[CLS] turned part gospel core yeah replybescript [SEP]']
[ 100/2000] tot_loss=2.717 (perp=12.114, rec=0.294), tot_loss_proj:3.511 [t=0.26s]
prediction: ['[CLS] of stephen clap metaphysical clap claphead factor [SEP]']
[ 150/2000] tot_loss=2.273 (perp=10.299, rec=0.213), tot_loss_proj:3.232 [t=0.25s]
prediction: ['[CLS] of soft clap metaphysical clap claptraous [SEP]']
[ 200/2000] tot_loss=2.125 (perp=9.689, rec=0.187), tot_loss_proj:3.149 [t=0.26s]
prediction: ['[CLS] of soft clap metaphysical clap claptra tickets [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.626 (perp=7.279, rec=0.170), tot_loss_proj:2.517 [t=0.27s]
prediction: ['[CLS] of metaphysical soft clap clap claptrap [SEP]']
[ 300/2000] tot_loss=1.877 (perp=8.664, rec=0.144), tot_loss_proj:2.295 [t=0.26s]
prediction: ['[CLS] of metaphysical softhead clap claptrap [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.829 (perp=8.519, rec=0.126), tot_loss_proj:2.597 [t=0.26s]
prediction: ['[CLS] ofhead metaphysical soft clap claptrap [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.826 (perp=8.519, rec=0.123), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] ofhead metaphysical soft clap claptrap [SEP]']
[ 450/2000] tot_loss=1.819 (perp=8.519, rec=0.115), tot_loss_proj:2.588 [t=0.28s]
prediction: ['[CLS] ofhead metaphysical soft clap claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.957 (perp=9.235, rec=0.110), tot_loss_proj:2.722 [t=0.26s]
prediction: ['[CLS] ofhead metaphysical soft path claptrap [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.834 (perp=8.044, rec=0.226), tot_loss_proj:2.270 [t=0.26s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[ 600/2000] tot_loss=1.744 (perp=8.044, rec=0.135), tot_loss_proj:2.220 [t=0.26s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.736 (perp=8.044, rec=0.127), tot_loss_proj:2.231 [t=0.25s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.728 (perp=8.044, rec=0.119), tot_loss_proj:2.230 [t=0.27s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[ 750/2000] tot_loss=1.719 (perp=8.044, rec=0.110), tot_loss_proj:2.225 [t=0.27s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.717 (perp=8.044, rec=0.108), tot_loss_proj:2.225 [t=0.25s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.044, rec=0.114), tot_loss_proj:2.220 [t=0.26s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[ 900/2000] tot_loss=1.718 (perp=8.044, rec=0.110), tot_loss_proj:2.225 [t=0.26s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.745 (perp=8.212, rec=0.103), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.758 (perp=8.212, rec=0.115), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
[1050/2000] tot_loss=1.747 (perp=8.212, rec=0.105), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.753 (perp=8.212, rec=0.110), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.749 (perp=8.212, rec=0.106), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
[1200/2000] tot_loss=1.752 (perp=8.212, rec=0.109), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.746 (perp=8.212, rec=0.104), tot_loss_proj:2.112 [t=0.28s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.745 (perp=8.212, rec=0.103), tot_loss_proj:2.110 [t=0.27s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
[1350/2000] tot_loss=1.723 (perp=8.044, rec=0.114), tot_loss_proj:2.226 [t=0.28s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.717 (perp=8.044, rec=0.108), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.708 (perp=8.044, rec=0.099), tot_loss_proj:2.225 [t=0.26s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[1500/2000] tot_loss=1.707 (perp=8.044, rec=0.098), tot_loss_proj:2.229 [t=0.21s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.799 (perp=8.498, rec=0.100), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.787 (perp=8.498, rec=0.087), tot_loss_proj:2.424 [t=0.26s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
[1650/2000] tot_loss=1.801 (perp=8.498, rec=0.102), tot_loss_proj:2.423 [t=0.21s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=8.498, rec=0.102), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.801 (perp=8.498, rec=0.101), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
[1800/2000] tot_loss=1.792 (perp=8.498, rec=0.092), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.804 (perp=8.498, rec=0.104), tot_loss_proj:2.420 [t=0.21s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.788 (perp=8.498, rec=0.088), tot_loss_proj:2.426 [t=0.24s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
[1950/2000] tot_loss=1.797 (perp=8.498, rec=0.098), tot_loss_proj:2.419 [t=0.23s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.788 (perp=8.498, rec=0.089), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of nesshead metaphysical soft claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 84.747 | p: 83.333 | r: 86.726
rouge2     | fm: 48.631 | p: 48.262 | r: 49.053
rougeL     | fm: 77.075 | p: 75.650 | r: 78.786
rougeLsum  | fm: 77.509 | p: 76.141 | r: 79.333
r1fm+r2fm = 133.378

input #9 time: 0:10:26 | total time: 1:48:29


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
cosin similarity: 0.650630223734263 normalized error: 0.6565642629854562
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8756442666053772 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8336741924285889 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8261200785636902 for ['[CLS] kiran instrumental whoeverwarinae band system news victorian coalition compilation shoulderscast [SEP]']
[Init] best rec loss: 0.7976791858673096 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.7825101017951965 for ['[CLS] driving below batting israel early style isa handwriting coast sometimes about field oral [SEP]']
[Init] best rec loss: 0.7551528215408325 for ['[CLS]date hate hard older mute showednivorous starred mv quickneas worlds equal [SEP]']
[Init] best perm rec loss: 0.7465006113052368 for ['[CLS] starreddate mute hardneas equalnivorous worlds hate mv quick older showed [SEP]']
[Init] best perm rec loss: 0.7439329624176025 for ['[CLS] equaldate mv quick showed starred mute older hate worldsnivorousneas hard [SEP]']
[Init] best perm rec loss: 0.7436820864677429 for ['[CLS]date equal mute starred hard showednivorous mv worlds older quick hateneas [SEP]']
[Init] best perm rec loss: 0.7434845566749573 for ['[CLS]neas showed equal quick starred hard older hate worlds mute mvdatenivorous [SEP]']
[Init] best perm rec loss: 0.7434006333351135 for ['[CLS]date worlds showednivorous equal quick starred hate hard olderneas mute mv [SEP]']
[Init] best perm rec loss: 0.743076741695404 for ['[CLS]nivorousdateneas starred hard worlds equal hate showed quick mv older mute [SEP]']
[Init] best perm rec loss: 0.7428372502326965 for ['[CLS]dateneas showed hard starrednivorous equal worlds quick older mv hate mute [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.324 (perp=10.492, rec=0.225), tot_loss_proj:2.469 [t=0.20s]
prediction: ['[CLS] ably balance ab instrumentals real rhythms with rhythmulsiveulsive method [SEP]']
[ 100/2000] tot_loss=2.166 (perp=10.119, rec=0.142), tot_loss_proj:2.395 [t=0.20s]
prediction: ['[CLS] ably balance ab concertos real rhythms with rhythmulsiveulsive and [SEP]']
[ 150/2000] tot_loss=1.797 (perp=8.396, rec=0.118), tot_loss_proj:2.049 [t=0.21s]
prediction: ['[CLS] ably balance ab reals real rhythms with rhythm propulsive. [SEP]']
[ 200/2000] tot_loss=1.978 (perp=9.409, rec=0.096), tot_loss_proj:2.298 [t=0.20s]
prediction: ['[CLS] ably balance ab times real rhythms with incident propulsive. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.883 (perp=8.734, rec=0.136), tot_loss_proj:2.055 [t=0.20s]
prediction: ['[CLS] ably balances time ab real rhythms with incident propulsive ; [SEP]']
[ 300/2000] tot_loss=1.988 (perp=8.576, rec=0.273), tot_loss_proj:2.100 [t=0.20s]
prediction: ['[CLS] ably balances time ab real rhythms with. propulsive ; [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.715 (perp=7.721, rec=0.171), tot_loss_proj:1.913 [t=0.21s]
prediction: ['[CLS] ably. balances time ab real rhythms with propulsive. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.560 (perp=7.044, rec=0.151), tot_loss_proj:1.770 [t=0.20s]
prediction: ['[CLS] ably. balances time ab real with propulsive rhythms. [SEP]']
[ 450/2000] tot_loss=1.527 (perp=7.044, rec=0.118), tot_loss_proj:1.769 [t=0.20s]
prediction: ['[CLS] ably. balances time ab real with propulsive rhythms. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.784 (perp=8.427, rec=0.098), tot_loss_proj:2.075 [t=0.21s]
prediction: ['[CLS] ably. balances time ab real with propulsive rhythms incident [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.644 (perp=9.720, rec=0.700), tot_loss_proj:2.553 [t=0.27s]
prediction: ['[CLS] occurred ably. balances time ab real with tendencyulsive rhythms [SEP]']
[ 600/2000] tot_loss=2.418 (perp=9.720, rec=0.474), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] occurred ably. balances time ab real with tendencyulsive rhythms [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=2.202 (perp=8.970, rec=0.408), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS]ulsive rhythms occurred ably. balances time ab real with tendency [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.304 (perp=9.753, rec=0.353), tot_loss_proj:2.528 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ablytor balances time asteroids real with tendency [SEP]']
[ 750/2000] tot_loss=2.329 (perp=10.109, rec=0.307), tot_loss_proj:2.626 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ablytor balances time asteroids real with episode [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.195 (perp=9.209, rec=0.354), tot_loss_proj:2.231 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances real timeenary with hero [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.095 (perp=8.884, rec=0.318), tot_loss_proj:2.160 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances real time withenary hero [SEP]']
[ 900/2000] tot_loss=2.244 (perp=9.758, rec=0.292), tot_loss_proj:2.454 [t=0.28s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances ab time withenary hero [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.143 (perp=9.379, rec=0.267), tot_loss_proj:2.342 [t=0.27s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances abenary with time hero [SEP]']
Attempt swap
[1000/2000] tot_loss=2.160 (perp=9.477, rec=0.264), tot_loss_proj:2.423 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ablyulsive balances abenary with time hero [SEP]']
[1050/2000] tot_loss=2.154 (perp=9.477, rec=0.258), tot_loss_proj:2.409 [t=0.27s]
prediction: ['[CLS]ulsive rhythms. ablyulsive balances abenary with time hero [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.057 (perp=9.012, rec=0.254), tot_loss_proj:2.381 [t=0.27s]
prediction: ['[CLS]ulsive rhythms. abulsively balances abenary with time hero [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.002 (perp=8.796, rec=0.243), tot_loss_proj:2.423 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. abenaryly balances abulsive with time hero [SEP]']
[1200/2000] tot_loss=1.995 (perp=8.796, rec=0.236), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. abenaryly balances abulsive with time hero [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.896 (perp=8.267, rec=0.243), tot_loss_proj:2.355 [t=0.28s]
prediction: ['[CLS]ly rhythms hero abenaryly balances abulsive with time. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.769 (perp=7.624, rec=0.244), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS]ulsive rhythms hero abenaryly balances ably with time. [SEP]']
[1350/2000] tot_loss=1.754 (perp=7.624, rec=0.230), tot_loss_proj:2.042 [t=0.25s]
prediction: ['[CLS]ulsive rhythms hero abenaryly balances ably with time. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.674 (perp=7.159, rec=0.243), tot_loss_proj:2.115 [t=0.27s]
prediction: ['[CLS] rhythms hero abenaryly balances abulsively with time. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.540 (perp=6.521, rec=0.236), tot_loss_proj:2.004 [t=0.27s]
prediction: ['[CLS] characters abenaryly rhythms balances abulsively with time. [SEP]']
[1500/2000] tot_loss=1.599 (perp=6.875, rec=0.224), tot_loss_proj:2.055 [t=0.25s]
prediction: ['[CLS] multiple abenaryly rhythms balances abulsively with time. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.536 (perp=6.542, rec=0.228), tot_loss_proj:2.051 [t=0.26s]
prediction: ['[CLS] multiple rhythmsenaryly ab balances abulsively with time. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.533 (perp=6.542, rec=0.224), tot_loss_proj:2.054 [t=0.27s]
prediction: ['[CLS] multiple rhythmsenaryly ab balances abulsively with time. [SEP]']
[1650/2000] tot_loss=1.530 (perp=6.542, rec=0.222), tot_loss_proj:2.051 [t=0.26s]
prediction: ['[CLS] multiple rhythmsenaryly ab balances abulsively with time. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.511 (perp=6.438, rec=0.223), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.502 (perp=6.438, rec=0.214), tot_loss_proj:2.003 [t=0.28s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
[1800/2000] tot_loss=1.500 (perp=6.438, rec=0.212), tot_loss_proj:2.005 [t=0.27s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.501 (perp=6.438, rec=0.214), tot_loss_proj:2.006 [t=0.27s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.474 (perp=6.283, rec=0.218), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS]enaryly multiple rhythms ab balances abulsively with time. [SEP]']
[1950/2000] tot_loss=1.475 (perp=6.283, rec=0.218), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS]enaryly multiple rhythms ab balances abulsively with time. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=6.283, rec=0.211), tot_loss_proj:1.984 [t=0.25s]
prediction: ['[CLS]enaryly multiple rhythms ab balances abulsively with time. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] ably. balances time ab real with propulsive rhythms incident [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 85.751 | p: 83.985 | r: 87.933
rouge2     | fm: 48.152 | p: 47.695 | r: 48.658
rougeL     | fm: 76.932 | p: 75.228 | r: 79.091
rougeLsum  | fm: 77.222 | p: 75.535 | r: 79.351
r1fm+r2fm = 133.903

input #10 time: 0:10:11 | total time: 1:58:41


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
cosin similarity: 0.8925993019126218 normalized error: 0.48881034290755365
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 1.7771288040431488 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 1.7044502092771252 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 1.312755107589961 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 1.3122732003383797 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 1.3014458982182548 for ['[CLS] drawnture tal platform inland mileguvd familiar me [SEP]']
[Init] best perm rec loss: 1.299934598528273 for ['[CLS]ture drawn me inland mile platform talguvd familiar [SEP]']
[Init] best perm rec loss: 1.296835331198143 for ['[CLS] inland me tal mile platform familiar drawntureguvd [SEP]']
[Init] best perm rec loss: 1.2908784190158757 for ['[CLS] inland mile tal familiar me drawnguturevd platform [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.761 (perp=11.486, rec=0.463), tot_loss_proj:3.543 [t=0.27s]
prediction: ['[CLS] missing food priests refused attempted instead bypass suspiciouslyed door [SEP]']
[ 100/2000] tot_loss=3.225 (perp=14.231, rec=0.378), tot_loss_proj:4.029 [t=0.27s]
prediction: ['[CLS] missing bro priests refused gel broke heavily seemeded overall [SEP]']
[ 150/2000] tot_loss=2.782 (perp=12.487, rec=0.285), tot_loss_proj:3.944 [t=0.27s]
prediction: ['[CLS] refused wayiel refused gel refused heavily geled gel [SEP]']
[ 200/2000] tot_loss=2.279 (perp=10.141, rec=0.250), tot_loss_proj:3.247 [t=0.27s]
prediction: ['[CLS] refused was brother refused gel that stubborn gel to gel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.146 (perp=9.689, rec=0.208), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] stubborn attempted brother refused gel that refused gel to gel [SEP]']
[ 300/2000] tot_loss=2.514 (perp=11.712, rec=0.171), tot_loss_proj:3.329 [t=0.27s]
prediction: ['[CLS] stubborn attemptedanalysis refused gel that refused gel to stubborn [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.291 (perp=10.669, rec=0.157), tot_loss_proj:3.107 [t=0.27s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that refused gel to brother [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.212 (perp=10.226, rec=0.167), tot_loss_proj:3.250 [t=0.29s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to brother [SEP]']
[ 450/2000] tot_loss=2.131 (perp=9.872, rec=0.156), tot_loss_proj:3.079 [t=0.26s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to request [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.108 (perp=9.872, rec=0.133), tot_loss_proj:3.069 [t=0.30s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to request [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.207 (perp=10.342, rec=0.139), tot_loss_proj:3.128 [t=0.28s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to possibly [SEP]']
[ 600/2000] tot_loss=2.197 (perp=10.342, rec=0.128), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to possibly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.457 (perp=11.623, rec=0.132), tot_loss_proj:3.359 [t=0.25s]
prediction: ['[CLS] stubborn attempted stubborn refused attempted that gel refused to possibly [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.241 (perp=10.560, rec=0.129), tot_loss_proj:3.124 [t=0.27s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
[ 750/2000] tot_loss=2.231 (perp=10.560, rec=0.119), tot_loss_proj:3.114 [t=0.26s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.239 (perp=10.560, rec=0.127), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.239 (perp=10.560, rec=0.127), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
[ 900/2000] tot_loss=2.227 (perp=10.560, rec=0.115), tot_loss_proj:3.125 [t=0.27s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.148 (perp=10.116, rec=0.125), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] stubborn was possibly refused gel attempted that refused to stubborn [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.011 (perp=9.380, rec=0.135), tot_loss_proj:3.058 [t=0.27s]
prediction: ['[CLS] stubborn was possibly refused gelly that attempted to stubborn [SEP]']
[1050/2000] tot_loss=2.002 (perp=9.380, rec=0.126), tot_loss_proj:3.068 [t=0.26s]
prediction: ['[CLS] stubborn was possibly refused gelly that attempted to stubborn [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.948 (perp=9.133, rec=0.121), tot_loss_proj:3.112 [t=0.25s]
prediction: ['[CLS] possibly stubborn was refused gelly that attempted to stubborn [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.030 (perp=9.497, rec=0.130), tot_loss_proj:2.962 [t=0.25s]
prediction: ['[CLS] possibly stubborn was refused possiblyly that attempted to gel [SEP]']
[1200/2000] tot_loss=2.021 (perp=9.497, rec=0.122), tot_loss_proj:2.958 [t=0.27s]
prediction: ['[CLS] possibly stubborn was refused possiblyly that attempted to gel [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.806 (perp=8.456, rec=0.115), tot_loss_proj:2.899 [t=0.27s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.805 (perp=8.456, rec=0.114), tot_loss_proj:2.904 [t=0.25s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
[1350/2000] tot_loss=1.803 (perp=8.456, rec=0.111), tot_loss_proj:2.906 [t=0.25s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.811 (perp=8.456, rec=0.119), tot_loss_proj:2.904 [t=0.25s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.456, rec=0.123), tot_loss_proj:2.903 [t=0.25s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
[1500/2000] tot_loss=1.811 (perp=8.456, rec=0.120), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.811 (perp=8.456, rec=0.120), tot_loss_proj:2.902 [t=0.26s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.804 (perp=8.456, rec=0.113), tot_loss_proj:2.907 [t=0.25s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
[1650/2000] tot_loss=1.810 (perp=8.456, rec=0.119), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.804 (perp=8.456, rec=0.113), tot_loss_proj:2.903 [t=0.26s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.768 (perp=8.295, rec=0.109), tot_loss_proj:2.806 [t=0.26s]
prediction: ['[CLS] possibly possibly was stubbornly refused that attempted to gel [SEP]']
[1800/2000] tot_loss=1.787 (perp=8.295, rec=0.128), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] possibly possibly was stubbornly refused that attempted to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.774 (perp=8.295, rec=0.115), tot_loss_proj:2.810 [t=0.25s]
prediction: ['[CLS] possibly possibly was stubbornly refused that attempted to gel [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.740 (perp=8.120, rec=0.115), tot_loss_proj:2.781 [t=0.26s]
prediction: ['[CLS] possibly was possibly stubbornly refused that attempted to gel [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.120, rec=0.118), tot_loss_proj:2.785 [t=0.26s]
prediction: ['[CLS] possibly was possibly stubbornly refused that attempted to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=8.120, rec=0.107), tot_loss_proj:2.790 [t=0.25s]
prediction: ['[CLS] possibly was possibly stubbornly refused that attempted to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 101.818

[Aggregate metrics]:
rouge1     | fm: 85.465 | p: 83.764 | r: 87.493
rouge2     | fm: 45.156 | p: 44.663 | r: 45.808
rougeL     | fm: 75.045 | p: 73.387 | r: 76.907
rougeLsum  | fm: 75.460 | p: 73.866 | r: 77.107
r1fm+r2fm = 130.620

input #11 time: 0:11:05 | total time: 2:09:47


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
cosin similarity: 0.7888396314640075 normalized error: 0.6055704316055367
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8458387851715088 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.7732340693473816 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.769726037979126 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7622662782669067 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.7430709600448608 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 0.7324323058128357 for ['[CLS] vice cruiseola duces designation josh, shop program laurel at citizen formations [SEP]']
[Init] best perm rec loss: 0.7290112376213074 for ['[CLS] citizen viceces designation cruise du shop joshola formations at laurel program, [SEP]']
[Init] best perm rec loss: 0.7279205918312073 for ['[CLS] formations designation at program shopces du vice josh citizen, laurel cruiseola [SEP]']
[Init] best perm rec loss: 0.7277432680130005 for ['[CLS] cruise designation vice citizen duola josh formations, laurel shop at programces [SEP]']
[Init] best perm rec loss: 0.7272396087646484 for ['[CLS], du shop program citizen designationces josh vice formations cruise atola laurel [SEP]']
[Init] best perm rec loss: 0.7269186973571777 for ['[CLS] vice shop at citizen josh formations du, programolaces cruise laurel designation [SEP]']
[Init] best perm rec loss: 0.725749671459198 for ['[CLS] vice program du laurel designation formations citizenola cruise shop, atces josh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.435 (perp=10.860, rec=0.263), tot_loss_proj:2.698 [t=0.26s]
prediction: ['[CLS] a policy radiation cable seeing better advantage especially on any is help barely cable [SEP]']
[ 100/2000] tot_loss=1.961 (perp=8.961, rec=0.169), tot_loss_proj:2.307 [t=0.26s]
prediction: ['[CLS] that will cable cable to better advantage especially on its is help barely barely [SEP]']
[ 150/2000] tot_loss=2.050 (perp=9.626, rec=0.124), tot_loss_proj:2.410 [t=0.26s]
prediction: ['[CLS] that will either cable seen better advantage especially on on its. barely barely [SEP]']
[ 200/2000] tot_loss=2.093 (perp=9.926, rec=0.107), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] that will especially cable seen better advantage considering on on its, barely barely [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.998 (perp=9.435, rec=0.111), tot_loss_proj:2.374 [t=0.26s]
prediction: ['[CLS] that especially cable will seen better advantage considering on on its to barely barely [SEP]']
[ 300/2000] tot_loss=1.972 (perp=9.435, rec=0.085), tot_loss_proj:2.375 [t=0.25s]
prediction: ['[CLS] that especially cable will seen better advantage considering on on its to barely barely [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.896 (perp=9.110, rec=0.073), tot_loss_proj:2.320 [t=0.26s]
prediction: ['[CLS] that especially cable will seen better advantage considering on its to barely barely on [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.850 (perp=8.882, rec=0.074), tot_loss_proj:2.354 [t=0.27s]
prediction: ['[CLS] that especially on will seen better advantage considering on its to barely barely cable [SEP]']
[ 450/2000] tot_loss=1.852 (perp=8.882, rec=0.076), tot_loss_proj:2.357 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage considering on its to barely barely cable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.816 (perp=8.659, rec=0.084), tot_loss_proj:2.283 [t=0.27s]
prediction: ['[CLS] that especially on will seen better advantage considering on its cable barely barely to [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.788 (perp=8.568, rec=0.074), tot_loss_proj:2.260 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
[ 600/2000] tot_loss=1.782 (perp=8.568, rec=0.069), tot_loss_proj:2.262 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.792 (perp=8.568, rec=0.078), tot_loss_proj:2.265 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.780 (perp=8.568, rec=0.067), tot_loss_proj:2.261 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
[ 750/2000] tot_loss=1.791 (perp=8.568, rec=0.078), tot_loss_proj:2.259 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.789 (perp=8.568, rec=0.076), tot_loss_proj:2.263 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.788 (perp=8.524, rec=0.084), tot_loss_proj:2.247 [t=0.28s]
prediction: ['[CLS] that especially on will seen better advantage especially on considering its cable barely to [SEP]']
[ 900/2000] tot_loss=1.784 (perp=8.599, rec=0.064), tot_loss_proj:2.291 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=8.599, rec=0.073), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.788 (perp=8.599, rec=0.069), tot_loss_proj:2.290 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
[1050/2000] tot_loss=1.792 (perp=8.599, rec=0.073), tot_loss_proj:2.290 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.599, rec=0.073), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[1150/2000] tot_loss=1.777 (perp=8.523, rec=0.073), tot_loss_proj:2.245 [t=0.29s]
prediction: ['[CLS] that especially, will seen better advantage barely on considering its cable barely to [SEP]']
[1200/2000] tot_loss=1.779 (perp=8.523, rec=0.075), tot_loss_proj:2.245 [t=0.30s]
prediction: ['[CLS] that especially, will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.767 (perp=8.469, rec=0.074), tot_loss_proj:2.158 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1300/2000] tot_loss=1.768 (perp=8.469, rec=0.075), tot_loss_proj:2.155 [t=0.28s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1350/2000] tot_loss=1.763 (perp=8.469, rec=0.069), tot_loss_proj:2.155 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1400/2000] tot_loss=1.765 (perp=8.469, rec=0.071), tot_loss_proj:2.159 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1450/2000] tot_loss=1.771 (perp=8.469, rec=0.077), tot_loss_proj:2.160 [t=0.27s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1500/2000] tot_loss=1.768 (perp=8.469, rec=0.074), tot_loss_proj:2.156 [t=0.27s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.769 (perp=8.469, rec=0.075), tot_loss_proj:2.157 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1600/2000] tot_loss=1.770 (perp=8.469, rec=0.076), tot_loss_proj:2.155 [t=0.34s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1650/2000] tot_loss=1.759 (perp=8.469, rec=0.065), tot_loss_proj:2.159 [t=0.29s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1700/2000] tot_loss=1.760 (perp=8.469, rec=0.066), tot_loss_proj:2.157 [t=0.28s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1750/2000] tot_loss=1.761 (perp=8.469, rec=0.067), tot_loss_proj:2.160 [t=0.28s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1800/2000] tot_loss=1.763 (perp=8.469, rec=0.069), tot_loss_proj:2.158 [t=0.31s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=8.469, rec=0.066), tot_loss_proj:2.154 [t=0.27s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1900/2000] tot_loss=1.764 (perp=8.469, rec=0.071), tot_loss_proj:2.158 [t=0.27s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1950/2000] tot_loss=1.765 (perp=8.469, rec=0.071), tot_loss_proj:2.160 [t=0.34s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[2000/2000] tot_loss=1.744 (perp=8.380, rec=0.068), tot_loss_proj:2.173 [t=0.24s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely, to [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 121.905

[Aggregate metrics]:
rouge1     | fm: 86.085 | p: 84.592 | r: 87.930
rouge2     | fm: 43.646 | p: 43.361 | r: 44.100
rougeL     | fm: 75.000 | p: 73.644 | r: 76.549
rougeLsum  | fm: 75.276 | p: 73.929 | r: 76.923
r1fm+r2fm = 129.731

input #12 time: 0:11:11 | total time: 2:20:59


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
cosin similarity: -0.7751034936878405 normalized error: 1.6080171585416112
cosin similarity: 0.7751034936878405 normalized error: 0.6023913888772761
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8799152374267578 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8692481517791748 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.7824040055274963 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7573435306549072 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7498305439949036 for ['[CLS] pdf along timing started mal practical prevailed [SEP]']
[Init] best rec loss: 0.7135336399078369 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best perm rec loss: 0.7128738164901733 for ['[CLS] speakerxygled as finish do eh [SEP]']
[Init] best perm rec loss: 0.708302915096283 for ['[CLS]xy asgled finish do eh speaker [SEP]']
[Init] best perm rec loss: 0.7081822752952576 for ['[CLS]xy speaker dogled eh finish as [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.855 (perp=12.494, rec=0.357), tot_loss_proj:3.109 [t=0.29s]
prediction: ['[CLS] point. flame [SEP] [SEP] inherently bitch [SEP]']
[ 100/2000] tot_loss=2.878 (perp=12.914, rec=0.295), tot_loss_proj:3.471 [t=0.28s]
prediction: ['[CLS] point cases flame [SEP] [SEP] flame into [SEP]']
[ 150/2000] tot_loss=2.551 (perp=11.633, rec=0.225), tot_loss_proj:3.039 [t=0.28s]
prediction: ['[CLS] point cases flame [SEP]ossa explode into [SEP]']
[ 200/2000] tot_loss=2.513 (perp=11.633, rec=0.187), tot_loss_proj:3.043 [t=0.29s]
prediction: ['[CLS] point cases flame [SEP]ossa explode into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.229 (perp=10.121, rec=0.205), tot_loss_proj:2.572 [t=0.30s]
prediction: ['[CLS] point cases [SEP] mountains explode into flame [SEP]']
[ 300/2000] tot_loss=2.156 (perp=10.005, rec=0.154), tot_loss_proj:2.596 [t=0.29s]
prediction: ['[CLS] point cases [SEP]ossa explode into flame [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.154 (perp=10.005, rec=0.152), tot_loss_proj:2.602 [t=0.28s]
prediction: ['[CLS] point cases [SEP]ossa explode into flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.183 (perp=10.143, rec=0.154), tot_loss_proj:2.606 [t=0.30s]
prediction: ['[CLS] point cases [SEP] guys explode into flame [SEP]']
[ 450/2000] tot_loss=2.168 (perp=10.143, rec=0.140), tot_loss_proj:2.599 [t=0.25s]
prediction: ['[CLS] point cases [SEP] guys explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.218 (perp=10.390, rec=0.140), tot_loss_proj:2.633 [t=0.24s]
prediction: ['[CLS] point guys [SEP] things explode into flame [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.160 (perp=10.094, rec=0.141), tot_loss_proj:2.515 [t=0.25s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
[ 600/2000] tot_loss=2.149 (perp=10.094, rec=0.130), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.150 (perp=10.094, rec=0.131), tot_loss_proj:2.521 [t=0.27s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.141 (perp=10.094, rec=0.122), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
[ 750/2000] tot_loss=2.144 (perp=10.094, rec=0.125), tot_loss_proj:2.527 [t=0.24s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.841 (perp=8.540, rec=0.134), tot_loss_proj:2.212 [t=0.26s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.826 (perp=8.540, rec=0.118), tot_loss_proj:2.208 [t=0.26s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
[ 900/2000] tot_loss=1.837 (perp=8.540, rec=0.129), tot_loss_proj:2.212 [t=0.25s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.837 (perp=8.540, rec=0.129), tot_loss_proj:2.208 [t=0.25s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.830 (perp=8.540, rec=0.122), tot_loss_proj:2.206 [t=0.25s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
[1050/2000] tot_loss=1.834 (perp=8.540, rec=0.127), tot_loss_proj:2.202 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.822 (perp=8.540, rec=0.114), tot_loss_proj:2.214 [t=0.25s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.529 (perp=7.088, rec=0.112), tot_loss_proj:1.787 [t=0.27s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
[1200/2000] tot_loss=1.542 (perp=7.088, rec=0.124), tot_loss_proj:1.775 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.536 (perp=7.088, rec=0.118), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.536 (perp=7.088, rec=0.118), tot_loss_proj:1.781 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
[1350/2000] tot_loss=1.543 (perp=7.088, rec=0.125), tot_loss_proj:1.775 [t=0.24s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.545 (perp=7.088, rec=0.127), tot_loss_proj:1.777 [t=0.27s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.530 (perp=7.088, rec=0.112), tot_loss_proj:1.778 [t=0.26s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
[1500/2000] tot_loss=1.542 (perp=7.088, rec=0.124), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.525 (perp=7.088, rec=0.107), tot_loss_proj:1.778 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.893 (perp=8.873, rec=0.118), tot_loss_proj:2.220 [t=0.26s]
prediction: ['[CLS] at point ones things explode into flame [SEP]']
[1650/2000] tot_loss=1.882 (perp=8.873, rec=0.107), tot_loss_proj:2.220 [t=0.25s]
prediction: ['[CLS] at point ones things explode into flame [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.674 (perp=7.768, rec=0.121), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.677 (perp=7.768, rec=0.124), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
[1800/2000] tot_loss=1.672 (perp=7.768, rec=0.118), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.672 (perp=7.768, rec=0.118), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=7.768, rec=0.129), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
[1950/2000] tot_loss=1.660 (perp=7.768, rec=0.106), tot_loss_proj:1.959 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.680 (perp=7.768, rec=0.126), tot_loss_proj:1.962 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at ones point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 86.202 | p: 84.792 | r: 87.970
rouge2     | fm: 43.743 | p: 43.486 | r: 44.310
rougeL     | fm: 74.991 | p: 73.665 | r: 76.599
rougeLsum  | fm: 75.368 | p: 74.064 | r: 76.783
r1fm+r2fm = 129.945

input #13 time: 0:10:52 | total time: 2:31:51


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
cosin similarity: 0.9712534810517994 normalized error: 0.4024497074016018
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 1.9446767978979729 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 1.7132148887979963 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 1.673408743358911 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 1.5598440449901572 for ['[CLS] quiver federation maddie sacramentoboard [SEP]']
[Init] best rec loss: 1.5013829892984902 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best rec loss: 1.4584700254283338 for ['[CLS] magic team came directed basis [SEP]']
[Init] best perm rec loss: 1.4535703417968744 for ['[CLS] directed basis team came magic [SEP]']
[Init] best perm rec loss: 1.4511355316218377 for ['[CLS] came magic directed team basis [SEP]']
[Init] best perm rec loss: 1.4495635881015467 for ['[CLS] came basis directed team magic [SEP]']
[Init] best perm rec loss: 1.4481973697040793 for ['[CLS] came basis magic team directed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.930 (perp=12.985, rec=0.333), tot_loss_proj:3.136 [t=0.25s]
prediction: ['[CLS] developed intriguing intriguingbly intriguing [SEP]']
[ 100/2000] tot_loss=3.234 (perp=14.974, rec=0.239), tot_loss_proj:3.532 [t=0.24s]
prediction: ['[CLS] developed film intriguingenia intriguing [SEP]']
[ 150/2000] tot_loss=2.883 (perp=13.402, rec=0.202), tot_loss_proj:3.292 [t=0.25s]
prediction: ['[CLS] concern film intriguingenia intriguing [SEP]']
[ 200/2000] tot_loss=2.269 (perp=10.460, rec=0.177), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS] interest film intriguingeniably [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.235 (perp=10.301, rec=0.174), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] intriguing film attachedeniably [SEP]']
[ 300/2000] tot_loss=2.220 (perp=10.301, rec=0.160), tot_loss_proj:2.598 [t=0.25s]
prediction: ['[CLS] intriguing film attachedeniably [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.950 (perp=9.010, rec=0.148), tot_loss_proj:2.488 [t=0.27s]
prediction: ['[CLS] intriguing filmeniably attached [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.285 (perp=10.728, rec=0.139), tot_loss_proj:2.657 [t=0.27s]
prediction: ['[CLS] intriguing filmeniably prima [SEP]']
[ 450/2000] tot_loss=2.280 (perp=10.728, rec=0.135), tot_loss_proj:2.661 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably prima [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.162 (perp=10.133, rec=0.135), tot_loss_proj:2.480 [t=0.25s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.159 (perp=10.133, rec=0.132), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
[ 600/2000] tot_loss=2.163 (perp=10.133, rec=0.137), tot_loss_proj:2.475 [t=0.25s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.155 (perp=10.133, rec=0.128), tot_loss_proj:2.476 [t=0.24s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.681 (perp=7.796, rec=0.121), tot_loss_proj:1.876 [t=0.25s]
prediction: ['[CLS] intriguing undeniably film [SEP]']
[ 750/2000] tot_loss=1.695 (perp=7.796, rec=0.136), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] intriguing undeniably film [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.476 (perp=6.728, rec=0.131), tot_loss_proj:1.464 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.476 (perp=6.728, rec=0.130), tot_loss_proj:1.471 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.463 (perp=6.728, rec=0.118), tot_loss_proj:1.473 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.471 (perp=6.728, rec=0.126), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.476 (perp=6.728, rec=0.130), tot_loss_proj:1.463 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.474 (perp=6.728, rec=0.128), tot_loss_proj:1.464 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.472 (perp=6.728, rec=0.126), tot_loss_proj:1.459 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.463 (perp=6.728, rec=0.118), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.472 (perp=6.728, rec=0.127), tot_loss_proj:1.468 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.467 (perp=6.728, rec=0.122), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.457 (perp=6.728, rec=0.112), tot_loss_proj:1.457 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.469 (perp=6.728, rec=0.123), tot_loss_proj:1.478 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.479 (perp=6.728, rec=0.133), tot_loss_proj:1.468 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.472 (perp=6.728, rec=0.127), tot_loss_proj:1.470 [t=0.30s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.475 (perp=6.728, rec=0.129), tot_loss_proj:1.467 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.474 (perp=6.728, rec=0.129), tot_loss_proj:1.453 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.470 (perp=6.728, rec=0.124), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.471 (perp=6.728, rec=0.126), tot_loss_proj:1.463 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.482 (perp=6.728, rec=0.136), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.465 (perp=6.728, rec=0.119), tot_loss_proj:1.457 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.469 (perp=6.728, rec=0.123), tot_loss_proj:1.476 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.469 (perp=6.728, rec=0.123), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.465 (perp=6.728, rec=0.119), tot_loss_proj:1.465 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.469 (perp=6.728, rec=0.124), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=6.728, rec=0.119), tot_loss_proj:1.458 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.402 | p: 86.158 | r: 88.857
rouge2     | fm: 47.328 | p: 46.889 | r: 47.736
rougeL     | fm: 76.738 | p: 75.598 | r: 78.157
rougeLsum  | fm: 76.919 | p: 75.713 | r: 78.269
r1fm+r2fm = 134.729

input #14 time: 0:10:45 | total time: 2:42:37


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
cosin similarity: 0.6748695288074162 normalized error: 0.6247062170652273
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9225282073020935 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.906060516834259 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.9007771015167236 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8829787373542786 for ['[CLS] danger italiana vehicles tibet obligation ball fantastic tessa [SEP]']
[Init] best rec loss: 0.861305832862854 for ['[CLS]ₑ scouts jeffital near mills reserveignment [SEP]']
[Init] best perm rec loss: 0.8612588047981262 for ['[CLS] near reserveital jeff millsₑ scoutsignment [SEP]']
[Init] best perm rec loss: 0.8599888682365417 for ['[CLS] nearignment scouts reserveitalₑ mills jeff [SEP]']
[Init] best perm rec loss: 0.8591567277908325 for ['[CLS] jeff mills scouts nearitalₑignment reserve [SEP]']
[Init] best perm rec loss: 0.85694420337677 for ['[CLS] millsital jeff reserve nearₑ scoutsignment [SEP]']
[Init] best perm rec loss: 0.85686194896698 for ['[CLS] jeff scouts reserveital nearₑ millsignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.667 (perp=12.215, rec=0.224), tot_loss_proj:3.037 [t=0.28s]
prediction: ['[CLS] efficient efficientablyably chill anonymous, anonymous [SEP]']
[ 100/2000] tot_loss=2.293 (perp=10.729, rec=0.147), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS]ably efficientably suit chiller. anonymous [SEP]']
[ 150/2000] tot_loss=2.270 (perp=10.893, rec=0.091), tot_loss_proj:2.606 [t=0.25s]
prediction: ['[CLS]ably efficientably suit chiller, anonymous [SEP]']
[ 200/2000] tot_loss=2.266 (perp=10.893, rec=0.088), tot_loss_proj:2.609 [t=0.25s]
prediction: ['[CLS]ably efficientably suit chiller, anonymous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.722 (perp=8.122, rec=0.098), tot_loss_proj:1.934 [t=0.25s]
prediction: ['[CLS]ably suitably efficient chiller, anonymous [SEP]']
[ 300/2000] tot_loss=1.711 (perp=8.122, rec=0.086), tot_loss_proj:1.938 [t=0.25s]
prediction: ['[CLS]ably suitably efficient chiller, anonymous [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.612 (perp=7.643, rec=0.084), tot_loss_proj:1.807 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.610 (perp=7.643, rec=0.081), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 450/2000] tot_loss=1.609 (perp=7.643, rec=0.080), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.603 (perp=7.643, rec=0.075), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.602 (perp=7.643, rec=0.073), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 600/2000] tot_loss=1.603 (perp=7.643, rec=0.075), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.604 (perp=7.643, rec=0.075), tot_loss_proj:1.805 [t=0.28s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.605 (perp=7.643, rec=0.076), tot_loss_proj:1.800 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 750/2000] tot_loss=1.604 (perp=7.643, rec=0.075), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.594 (perp=7.643, rec=0.066), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.599 (perp=7.643, rec=0.070), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.609 (perp=7.643, rec=0.080), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.605 (perp=7.643, rec=0.076), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1000/2000] tot_loss=1.606 (perp=7.643, rec=0.077), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1050/2000] tot_loss=1.603 (perp=7.643, rec=0.074), tot_loss_proj:1.807 [t=0.27s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.603 (perp=7.643, rec=0.074), tot_loss_proj:1.808 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1150/2000] tot_loss=1.599 (perp=7.643, rec=0.070), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1200/2000] tot_loss=1.605 (perp=7.643, rec=0.077), tot_loss_proj:1.802 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1250/2000] tot_loss=1.607 (perp=7.643, rec=0.078), tot_loss_proj:1.797 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1300/2000] tot_loss=1.605 (perp=7.643, rec=0.076), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.643, rec=0.077), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1400/2000] tot_loss=1.606 (perp=7.643, rec=0.078), tot_loss_proj:1.800 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1450/2000] tot_loss=1.600 (perp=7.643, rec=0.071), tot_loss_proj:1.801 [t=0.27s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.643, rec=0.071), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1550/2000] tot_loss=1.943 (perp=9.324, rec=0.078), tot_loss_proj:2.165 [t=0.27s]
prediction: ['[CLS]ably suit. efficient, anonymous chiller [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.640 (perp=7.815, rec=0.077), tot_loss_proj:1.829 [t=0.25s]
prediction: ['[CLS] suitably. efficient, anonymous chiller [SEP]']
[1650/2000] tot_loss=1.630 (perp=7.815, rec=0.067), tot_loss_proj:1.831 [t=0.26s]
prediction: ['[CLS] suitably. efficient, anonymous chiller [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.405 (perp=6.697, rec=0.065), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.405 (perp=6.697, rec=0.066), tot_loss_proj:1.527 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.398 (perp=6.697, rec=0.058), tot_loss_proj:1.514 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.413 (perp=6.697, rec=0.073), tot_loss_proj:1.510 [t=0.29s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.403 (perp=6.697, rec=0.064), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.409 (perp=6.697, rec=0.070), tot_loss_proj:1.518 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.697, rec=0.062), tot_loss_proj:1.522 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 88.025 | p: 86.872 | r: 89.444
rouge2     | fm: 46.230 | p: 45.874 | r: 46.628
rougeL     | fm: 77.215 | p: 76.082 | r: 78.585
rougeLsum  | fm: 77.328 | p: 76.271 | r: 78.655
r1fm+r2fm = 134.255

input #15 time: 0:10:48 | total time: 2:53:25


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
cosin similarity: 0.8608126130577575 normalized error: 0.5227461674587929
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.9182784000561732 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 1.7721839365450194 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 1.654328542364809 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 1.5700756693749272 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 1.5311857895731213 for ['[CLS] legsyen t sharon camp ro [SEP]']
[Init] best rec loss: 1.5175395499198157 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 1.5020976554555403 for ['[CLS] hermic clement glass dig mount [SEP]']
[Init] best rec loss: 1.4031997027562024 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 1.3835596852537135 for ['[CLS] ultra backpack tallest you downstream map [SEP]']
[Init] best perm rec loss: 1.3801290946393565 for ['[CLS] ultra tallest backpack downstream you map [SEP]']
[Init] best perm rec loss: 1.3788374464161406 for ['[CLS] downstream tallest backpack ultra you map [SEP]']
[Init] best perm rec loss: 1.3783540578427966 for ['[CLS] downstream you tallest map ultra backpack [SEP]']
[Init] best perm rec loss: 1.3776690869216974 for ['[CLS] ultra you tallest map backpack downstream [SEP]']
[Init] best perm rec loss: 1.3772992617019928 for ['[CLS] ultra you tallest backpack downstream map [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=11.772, rec=0.448), tot_loss_proj:3.655 [t=0.25s]
prediction: ['[CLS] received building all cadenended of [SEP]']
[ 100/2000] tot_loss=2.373 (perp=10.200, rec=0.333), tot_loss_proj:3.963 [t=0.26s]
prediction: ['[CLS] all all this chamberended of [SEP]']
[ 150/2000] tot_loss=2.123 (perp=9.354, rec=0.252), tot_loss_proj:3.744 [t=0.25s]
prediction: ['[CLS] all more this ofended more [SEP]']
[ 200/2000] tot_loss=2.075 (perp=9.354, rec=0.204), tot_loss_proj:3.752 [t=0.26s]
prediction: ['[CLS] all more this ofended more [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.666 (perp=7.531, rec=0.160), tot_loss_proj:2.253 [t=0.24s]
prediction: ['[CLS] all of this and bartholomew more [SEP]']
[ 300/2000] tot_loss=1.593 (perp=7.262, rec=0.140), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] all of this and opportunity more [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.658 (perp=7.607, rec=0.137), tot_loss_proj:2.465 [t=0.25s]
prediction: ['[CLS] all of thispina and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.507 (perp=6.924, rec=0.123), tot_loss_proj:3.298 [t=0.27s]
prediction: ['[CLS] all of this without and more [SEP]']
[ 450/2000] tot_loss=1.509 (perp=6.924, rec=0.124), tot_loss_proj:3.296 [t=0.26s]
prediction: ['[CLS] all of this without and more [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.403 (perp=6.424, rec=0.118), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.403 (perp=6.424, rec=0.119), tot_loss_proj:3.131 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[ 600/2000] tot_loss=1.407 (perp=6.424, rec=0.122), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.398 (perp=6.424, rec=0.114), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.424, rec=0.115), tot_loss_proj:3.132 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[ 750/2000] tot_loss=1.399 (perp=6.424, rec=0.114), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.407 (perp=6.424, rec=0.122), tot_loss_proj:3.130 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.397 (perp=6.424, rec=0.112), tot_loss_proj:3.127 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
[ 900/2000] tot_loss=1.396 (perp=6.424, rec=0.111), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.405 (perp=6.424, rec=0.121), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.396 (perp=6.424, rec=0.111), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1050/2000] tot_loss=1.395 (perp=6.424, rec=0.110), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.403 (perp=6.424, rec=0.118), tot_loss_proj:3.128 [t=0.28s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.398 (perp=6.424, rec=0.113), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1200/2000] tot_loss=1.393 (perp=6.424, rec=0.109), tot_loss_proj:3.129 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.401 (perp=6.424, rec=0.117), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.386 (perp=6.424, rec=0.102), tot_loss_proj:3.127 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1350/2000] tot_loss=1.389 (perp=6.424, rec=0.105), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.424, rec=0.110), tot_loss_proj:3.125 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.394 (perp=6.424, rec=0.110), tot_loss_proj:3.124 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
[1500/2000] tot_loss=1.387 (perp=6.424, rec=0.102), tot_loss_proj:3.122 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.391 (perp=6.424, rec=0.107), tot_loss_proj:3.121 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.400 (perp=6.424, rec=0.115), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
[1650/2000] tot_loss=1.399 (perp=6.424, rec=0.114), tot_loss_proj:3.127 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.398 (perp=6.424, rec=0.113), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.397 (perp=6.424, rec=0.112), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1800/2000] tot_loss=1.393 (perp=6.424, rec=0.108), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.397 (perp=6.424, rec=0.112), tot_loss_proj:3.121 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.424, rec=0.108), tot_loss_proj:3.125 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1950/2000] tot_loss=1.393 (perp=6.424, rec=0.109), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.402 (perp=6.424, rec=0.118), tot_loss_proj:3.129 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this and without more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 88.311 | p: 86.828 | r: 90.051
rouge2     | fm: 48.787 | p: 48.218 | r: 49.630
rougeL     | fm: 78.364 | p: 76.907 | r: 80.043
rougeLsum  | fm: 78.198 | p: 76.768 | r: 79.842
r1fm+r2fm = 137.098

input #16 time: 0:10:48 | total time: 3:04:13


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
cosin similarity: 0.9037399408049033 normalized error: 0.5024741745837585
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 1.6074051919111232 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 1.5803749429665204 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 1.5803546368474701 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 1.4937723138670405 for ['[CLS] highestlt short ad relation minority black bunch marine above different [SEP]']
[Init] best rec loss: 1.411629395272497 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 1.4087598261576204 for ['[CLS] gravel divided highest accesslowe conor dir startorg timesttered [SEP]']
[Init] best rec loss: 1.3690867238837439 for ['[CLS] general sensation water consecrated affairvudran bethany then religious threatened [SEP]']
[Init] best perm rec loss: 1.3664426460821055 for ['[CLS] religiousvu consecrated bethany affair water threatened sensation then generaldran [SEP]']
[Init] best perm rec loss: 1.3600614397254753 for ['[CLS]vu consecrated water general affair sensationdran threatened then religious bethany [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.732 (perp=10.941, rec=0.543), tot_loss_proj:3.516 [t=0.25s]
prediction: ["[CLS] any think much be exploded fantasy'swimming crazy strings leaving [SEP]"]
[ 100/2000] tot_loss=2.594 (perp=10.958, rec=0.402), tot_loss_proj:3.452 [t=0.26s]
prediction: ['[CLS] too think much been stolen on too swimming plea want leaving [SEP]']
[ 150/2000] tot_loss=2.664 (perp=11.768, rec=0.310), tot_loss_proj:3.560 [t=0.26s]
prediction: ['[CLS] want think much much wrong on too about plea want leaving [SEP]']
[ 200/2000] tot_loss=2.343 (perp=10.515, rec=0.240), tot_loss_proj:3.224 [t=0.26s]
prediction: ['[CLS] want think much much too on too about much want leave [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.137 (perp=9.800, rec=0.177), tot_loss_proj:3.202 [t=0.25s]
prediction: ['[CLS] want think much much too on think about much want too [SEP]']
[ 300/2000] tot_loss=2.227 (perp=10.430, rec=0.141), tot_loss_proj:3.855 [t=0.25s]
prediction: ['[CLS] want think much much too get think about much want want [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.969 (perp=9.202, rec=0.129), tot_loss_proj:3.253 [t=0.25s]
prediction: ['[CLS] want think much too much get think about much what want [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.721 (perp=7.950, rec=0.131), tot_loss_proj:3.186 [t=0.26s]
prediction: ['[CLS] want think too much get to think about much what want [SEP]']
[ 450/2000] tot_loss=1.717 (perp=7.950, rec=0.127), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] want think too much get to think about much what want [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.550 (perp=7.216, rec=0.107), tot_loss_proj:2.777 [t=0.25s]
prediction: ['[CLS] want think too much get to think about what much want [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.534 (perp=7.089, rec=0.116), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS] want think too much want to think about what everything get [SEP]']
[ 600/2000] tot_loss=1.529 (perp=7.089, rec=0.111), tot_loss_proj:2.638 [t=0.25s]
prediction: ['[CLS] want think too much want to think about what everything get [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.530 (perp=7.102, rec=0.110), tot_loss_proj:2.541 [t=0.26s]
prediction: ['[CLS] want think too much want to think about what what get [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.626 (perp=7.631, rec=0.100), tot_loss_proj:2.405 [t=0.25s]
prediction: ['[CLS] wantsm too much want to think about what what get [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.118, rec=0.106), tot_loss_proj:2.564 [t=0.25s]
prediction: ['[CLS] wantsm too much want to think about going what get [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.663 (perp=7.798, rec=0.103), tot_loss_proj:2.469 [t=0.27s]
prediction: ['[CLS] wantsm too much want to think about going get what [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.570 (perp=7.282, rec=0.113), tot_loss_proj:2.490 [t=0.26s]
prediction: ['[CLS] want too much want excessive to think about going get what [SEP]']
[ 900/2000] tot_loss=1.643 (perp=7.706, rec=0.101), tot_loss_proj:2.500 [t=0.25s]
prediction: ['[CLS] want too much want caroline to think about going get what [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.628 (perp=7.563, rec=0.115), tot_loss_proj:2.373 [t=0.26s]
prediction: ['[CLS] want too much to want caroline think about going get what [SEP]']
Attempt swap
[1000/2000] tot_loss=1.619 (perp=7.563, rec=0.106), tot_loss_proj:2.377 [t=0.25s]
prediction: ['[CLS] want too much to want caroline think about going get what [SEP]']
[1050/2000] tot_loss=1.743 (perp=8.247, rec=0.093), tot_loss_proj:2.991 [t=0.26s]
prediction: ['[CLS] want too much to want caroline think about going lives what [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.668 (perp=7.867, rec=0.094), tot_loss_proj:2.533 [t=0.25s]
prediction: ['[CLS] want too much to want lack think about what lives going [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.576 (perp=7.375, rec=0.101), tot_loss_proj:2.591 [t=0.28s]
prediction: ['[CLS] want too much want lack to think about what get going [SEP]']
[1200/2000] tot_loss=1.537 (perp=7.188, rec=0.099), tot_loss_proj:2.295 [t=0.25s]
prediction: ['[CLS] want too much wantsm to think about what get going [SEP]']
Attempt swap
[1250/2000] tot_loss=1.624 (perp=7.617, rec=0.101), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Attempt swap
[1300/2000] tot_loss=1.632 (perp=7.617, rec=0.108), tot_loss_proj:2.475 [t=0.26s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
[1350/2000] tot_loss=1.620 (perp=7.617, rec=0.097), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Attempt swap
[1400/2000] tot_loss=1.645 (perp=7.733, rec=0.098), tot_loss_proj:2.621 [t=0.26s]
prediction: ['[CLS] want too much want lack to think about what lives going [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.566 (perp=7.318, rec=0.103), tot_loss_proj:2.477 [t=0.27s]
prediction: ['[CLS] want too much lack want to think about what lives going [SEP]']
[1500/2000] tot_loss=1.680 (perp=7.936, rec=0.093), tot_loss_proj:2.623 [t=0.26s]
prediction: ['[CLS] want too muchsm want to think about what lives going [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.643 (perp=7.733, rec=0.097), tot_loss_proj:2.624 [t=0.27s]
prediction: ['[CLS] want too much want lack to think about what lives going [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.549 (perp=7.265, rec=0.096), tot_loss_proj:2.578 [t=0.25s]
prediction: ['[CLS] want lack too much want to think about what lives going [SEP]']
[1650/2000] tot_loss=1.557 (perp=7.265, rec=0.104), tot_loss_proj:2.574 [t=0.26s]
prediction: ['[CLS] want lack too much want to think about what lives going [SEP]']
Attempt swap
[1700/2000] tot_loss=1.553 (perp=7.265, rec=0.100), tot_loss_proj:2.578 [t=0.27s]
prediction: ['[CLS] want lack too much want to think about what lives going [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=7.858, rec=0.099), tot_loss_proj:2.546 [t=0.25s]
prediction: ['[CLS] wantsm too much want to think about what lives going [SEP]']
[1800/2000] tot_loss=1.668 (perp=7.858, rec=0.096), tot_loss_proj:2.541 [t=0.25s]
prediction: ['[CLS] wantsm too much want to think about what lives going [SEP]']
Attempt swap
[1850/2000] tot_loss=1.664 (perp=7.858, rec=0.093), tot_loss_proj:2.538 [t=0.25s]
prediction: ['[CLS] wantsm too much want to think about what lives going [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.610 (perp=7.617, rec=0.087), tot_loss_proj:2.478 [t=0.26s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.617, rec=0.099), tot_loss_proj:2.478 [t=0.26s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Attempt swap
[2000/2000] tot_loss=1.614 (perp=7.617, rec=0.090), tot_loss_proj:2.478 [t=0.27s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want too muchsm want to think about what lives going [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 111.364

[Aggregate metrics]:
rouge1     | fm: 87.597 | p: 86.139 | r: 89.239
rouge2     | fm: 48.500 | p: 47.788 | r: 49.346
rougeL     | fm: 78.031 | p: 76.698 | r: 79.576
rougeLsum  | fm: 77.167 | p: 75.792 | r: 78.925
r1fm+r2fm = 136.097

input #17 time: 0:10:48 | total time: 3:15:01


Running input #18 of 100.
reference: 
========================
invigorating 
========================
cosin similarity: -0.8663931959498936 normalized error: 1.8094839224181716
cosin similarity: 0.8663931959498935 normalized error: 0.4833655777924054
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 2.0162891501258073 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 1.8783933266244992 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 1.8179616827797669 for ['[CLS] says oh dynasty watershed [SEP]']
[Init] best rec loss: 1.8119192569393463 for ['[CLS]nched jing ash face [SEP]']
[Init] best rec loss: 1.7251254339526572 for ['[CLS] disappointednce secret running [SEP]']
[Init] best rec loss: 1.7174652807963626 for ['[CLS] staten boy common diner [SEP]']
[Init] best rec loss: 1.6935080832392198 for ['[CLS] with thy commission operating [SEP]']
[Init] best rec loss: 1.672139018499803 for ['[CLS] themselvesnt lumpur rode [SEP]']
[Init] best rec loss: 1.4475356849153311 for ['[CLS] dual circle duodle [SEP]']
[Init] best rec loss: 1.442180656881522 for ['[CLS] canellant replication calm [SEP]']
[Init] best perm rec loss: 1.438380616862584 for ['[CLS] replicationellant can calm [SEP]']
[Init] best perm rec loss: 1.4359583516313148 for ['[CLS] can replicationellant calm [SEP]']
[Init] best perm rec loss: 1.4353885968659366 for ['[CLS] calm replicationellant can [SEP]']
[Init] best perm rec loss: 1.4314809151194952 for ['[CLS] replication can calmellant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.901 (perp=11.629, rec=0.575), tot_loss_proj:4.067 [t=0.20s]
prediction: ['[CLS] also newgillable [SEP]']
[ 100/2000] tot_loss=2.635 (perp=11.120, rec=0.411), tot_loss_proj:3.016 [t=0.20s]
prediction: ['[CLS] visible uniquegorating [SEP]']
[ 150/2000] tot_loss=2.607 (perp=11.392, rec=0.328), tot_loss_proj:3.550 [t=0.20s]
prediction: ['[CLS] visible!gorating [SEP]']
[ 200/2000] tot_loss=2.414 (perp=10.615, rec=0.291), tot_loss_proj:3.380 [t=0.20s]
prediction: ['[CLS] visible itsgorating [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.025 (perp=8.563, rec=0.312), tot_loss_proj:2.580 [t=0.20s]
prediction: ['[CLS] its alsogorating [SEP]']
[ 300/2000] tot_loss=2.123 (perp=9.243, rec=0.274), tot_loss_proj:2.630 [t=0.20s]
prediction: ['[CLS] its definitelygorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.979 (perp=8.563, rec=0.267), tot_loss_proj:2.580 [t=0.20s]
prediction: ['[CLS] its alsogorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.178 (perp=9.604, rec=0.257), tot_loss_proj:3.005 [t=0.20s]
prediction: ['[CLS] its availablegorating [SEP]']
[ 450/2000] tot_loss=2.170 (perp=9.604, rec=0.249), tot_loss_proj:3.004 [t=0.20s]
prediction: ['[CLS] its availablegorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.174 (perp=9.604, rec=0.254), tot_loss_proj:3.010 [t=0.20s]
prediction: ['[CLS] its availablegorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.175 (perp=9.604, rec=0.254), tot_loss_proj:3.006 [t=0.20s]
prediction: ['[CLS] its availablegorating [SEP]']
[ 600/2000] tot_loss=2.167 (perp=9.604, rec=0.246), tot_loss_proj:3.006 [t=0.20s]
prediction: ['[CLS] its availablegorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.394 (perp=10.733, rec=0.247), tot_loss_proj:3.245 [t=0.20s]
prediction: ['[CLS] its entergorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.385 (perp=10.733, rec=0.238), tot_loss_proj:3.234 [t=0.20s]
prediction: ['[CLS] its entergorating [SEP]']
[ 750/2000] tot_loss=2.392 (perp=10.733, rec=0.245), tot_loss_proj:3.237 [t=0.20s]
prediction: ['[CLS] its entergorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.382 (perp=10.702, rec=0.242), tot_loss_proj:2.868 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.377 (perp=10.702, rec=0.237), tot_loss_proj:2.868 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
[ 900/2000] tot_loss=2.371 (perp=10.702, rec=0.230), tot_loss_proj:2.879 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.367 (perp=10.702, rec=0.226), tot_loss_proj:2.867 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1000/2000] tot_loss=2.385 (perp=10.702, rec=0.244), tot_loss_proj:2.877 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
[1050/2000] tot_loss=2.374 (perp=10.702, rec=0.234), tot_loss_proj:2.866 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1100/2000] tot_loss=2.381 (perp=10.702, rec=0.240), tot_loss_proj:2.874 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1150/2000] tot_loss=2.378 (perp=10.702, rec=0.237), tot_loss_proj:2.873 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
[1200/2000] tot_loss=2.365 (perp=10.702, rec=0.224), tot_loss_proj:2.877 [t=0.21s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1250/2000] tot_loss=2.367 (perp=10.702, rec=0.227), tot_loss_proj:2.873 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1300/2000] tot_loss=2.376 (perp=10.702, rec=0.235), tot_loss_proj:2.875 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
[1350/2000] tot_loss=2.361 (perp=10.702, rec=0.221), tot_loss_proj:2.874 [t=0.20s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.892 (perp=8.319, rec=0.228), tot_loss_proj:2.359 [t=0.20s]
prediction: ['[CLS]! ingorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.888 (perp=8.319, rec=0.224), tot_loss_proj:2.365 [t=0.25s]
prediction: ['[CLS]! ingorating [SEP]']
[1500/2000] tot_loss=1.887 (perp=8.319, rec=0.223), tot_loss_proj:2.363 [t=0.25s]
prediction: ['[CLS]! ingorating [SEP]']
Attempt swap
[1550/2000] tot_loss=2.077 (perp=9.233, rec=0.230), tot_loss_proj:2.633 [t=0.24s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1600/2000] tot_loss=2.079 (perp=9.233, rec=0.232), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
[1650/2000] tot_loss=2.081 (perp=9.233, rec=0.234), tot_loss_proj:2.635 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1700/2000] tot_loss=2.074 (perp=9.233, rec=0.228), tot_loss_proj:2.634 [t=0.24s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1750/2000] tot_loss=2.086 (perp=9.233, rec=0.239), tot_loss_proj:2.629 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
[1800/2000] tot_loss=2.083 (perp=9.233, rec=0.236), tot_loss_proj:2.627 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1850/2000] tot_loss=2.074 (perp=9.233, rec=0.228), tot_loss_proj:2.633 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1900/2000] tot_loss=2.076 (perp=9.233, rec=0.230), tot_loss_proj:2.632 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
[1950/2000] tot_loss=2.084 (perp=9.233, rec=0.237), tot_loss_proj:2.637 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[2000/2000] tot_loss=2.064 (perp=9.233, rec=0.218), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS]ryl ingorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 85.815 | p: 84.127 | r: 87.928
rouge2     | fm: 45.520 | p: 44.979 | r: 46.208
rougeL     | fm: 76.862 | p: 75.203 | r: 78.898
rougeLsum  | fm: 76.224 | p: 74.531 | r: 78.397
r1fm+r2fm = 131.336

input #18 time: 0:08:49 | total time: 3:23:51


Running input #19 of 100.
reference: 
========================
to infamy 
========================
cosin similarity: 0.8340207118100215 normalized error: 0.5752933257115956
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 1.5094313931796732 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 1.4554807544511337 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 1.3433113745062517 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 1.334873426604534 for ['[CLS] human billy km² era [SEP]']
[Init] best rec loss: 1.328149610944145 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 1.2973774107200455 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 1.2937542735480927 for ['[CLS]yna reaching order pin [SEP]']
[Init] best perm rec loss: 1.2908034235951535 for ['[CLS] orderyna reaching pin [SEP]']
[Init] best perm rec loss: 1.2903990563565202 for ['[CLS] reachingyna pin order [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.424 (perp=14.757, rec=0.472), tot_loss_proj:4.384 [t=0.27s]
prediction: ['[CLS]quefirmpha situation [SEP]']
[ 100/2000] tot_loss=2.651 (perp=11.470, rec=0.357), tot_loss_proj:3.792 [t=0.25s]
prediction: ['[CLS] tofapha situation [SEP]']
[ 150/2000] tot_loss=2.515 (perp=11.006, rec=0.314), tot_loss_proj:3.776 [t=0.26s]
prediction: ['[CLS] tofamy maryland [SEP]']
[ 200/2000] tot_loss=2.087 (perp=9.226, rec=0.242), tot_loss_proj:3.433 [t=0.25s]
prediction: ['[CLS] tofamy injury [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.056 (perp=9.226, rec=0.211), tot_loss_proj:3.433 [t=0.26s]
prediction: ['[CLS] tofamy injury [SEP]']
[ 300/2000] tot_loss=2.018 (perp=9.226, rec=0.173), tot_loss_proj:3.434 [t=0.27s]
prediction: ['[CLS] tofamy injury [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.535 (perp=11.821, rec=0.171), tot_loss_proj:4.146 [t=0.25s]
prediction: ['[CLS] tofamy beat [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.312 (perp=10.538, rec=0.204), tot_loss_proj:3.754 [t=0.25s]
prediction: ['[CLS] attainfamy to [SEP]']
[ 450/2000] tot_loss=2.258 (perp=10.538, rec=0.151), tot_loss_proj:3.763 [t=0.26s]
prediction: ['[CLS] attainfamy to [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.029 (perp=9.223, rec=0.185), tot_loss_proj:3.430 [t=0.27s]
prediction: ['[CLS] to attainfamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.990 (perp=9.223, rec=0.145), tot_loss_proj:3.430 [t=0.25s]
prediction: ['[CLS] to attainfamy [SEP]']
[ 600/2000] tot_loss=1.989 (perp=9.223, rec=0.145), tot_loss_proj:3.430 [t=0.25s]
prediction: ['[CLS] to attainfamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.983 (perp=9.223, rec=0.138), tot_loss_proj:3.423 [t=0.25s]
prediction: ['[CLS] to attainfamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.968 (perp=9.223, rec=0.124), tot_loss_proj:3.432 [t=0.25s]
prediction: ['[CLS] to attainfamy [SEP]']
[ 750/2000] tot_loss=2.337 (perp=10.996, rec=0.138), tot_loss_proj:3.613 [t=0.26s]
prediction: ['[CLS] to classificationfamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.340 (perp=10.996, rec=0.141), tot_loss_proj:3.610 [t=0.26s]
prediction: ['[CLS] to classificationfamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.329 (perp=10.996, rec=0.130), tot_loss_proj:3.615 [t=0.25s]
prediction: ['[CLS] to classificationfamy [SEP]']
[ 900/2000] tot_loss=2.328 (perp=10.996, rec=0.129), tot_loss_proj:3.616 [t=0.27s]
prediction: ['[CLS] to classificationfamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.302 (perp=10.832, rec=0.135), tot_loss_proj:3.656 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1000/2000] tot_loss=2.288 (perp=10.832, rec=0.121), tot_loss_proj:3.652 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
[1050/2000] tot_loss=2.293 (perp=10.832, rec=0.126), tot_loss_proj:3.649 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1100/2000] tot_loss=2.296 (perp=10.832, rec=0.130), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.296 (perp=10.832, rec=0.130), tot_loss_proj:3.653 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
[1200/2000] tot_loss=2.290 (perp=10.832, rec=0.124), tot_loss_proj:3.645 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1250/2000] tot_loss=2.292 (perp=10.832, rec=0.125), tot_loss_proj:3.653 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1300/2000] tot_loss=2.279 (perp=10.832, rec=0.113), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
[1350/2000] tot_loss=1.921 (perp=8.949, rec=0.132), tot_loss_proj:2.777 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.916 (perp=8.949, rec=0.126), tot_loss_proj:2.772 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.921 (perp=8.949, rec=0.131), tot_loss_proj:2.787 [t=0.24s]
prediction: ['[CLS] to polyfamy [SEP]']
[1500/2000] tot_loss=1.909 (perp=8.949, rec=0.119), tot_loss_proj:2.782 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.912 (perp=8.949, rec=0.122), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.921 (perp=8.949, rec=0.132), tot_loss_proj:2.784 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
[1650/2000] tot_loss=1.917 (perp=8.949, rec=0.127), tot_loss_proj:2.773 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.914 (perp=8.949, rec=0.124), tot_loss_proj:2.783 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.898 (perp=8.949, rec=0.109), tot_loss_proj:2.778 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
[1800/2000] tot_loss=1.904 (perp=8.949, rec=0.114), tot_loss_proj:2.783 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.914 (perp=8.949, rec=0.124), tot_loss_proj:2.782 [t=0.24s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.915 (perp=8.949, rec=0.126), tot_loss_proj:2.782 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
[1950/2000] tot_loss=1.915 (perp=8.949, rec=0.126), tot_loss_proj:2.772 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.919 (perp=8.949, rec=0.129), tot_loss_proj:2.780 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to polyfamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 85.490 | p: 83.739 | r: 87.420
rouge2     | fm: 45.191 | p: 44.587 | r: 45.855
rougeL     | fm: 76.752 | p: 75.195 | r: 78.652
rougeLsum  | fm: 76.159 | p: 74.516 | r: 78.209
r1fm+r2fm = 130.682

input #19 time: 0:10:49 | total time: 3:34:41


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
cosin similarity: -0.8303731972303416 normalized error: 1.7135635582976205
cosin similarity: 0.8303731972303418 normalized error: 0.5372736947116259
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 1.7817882942253682 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 1.7579531173935001 for ['[CLS] sal focalgee weeks [SEP]']
[Init] best rec loss: 1.6723533105951658 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 1.3967802267733476 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 1.32556983564614 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 1.3157501881221847 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 1.3142276924055944 for ['[CLS] storylinenessxi [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.587 (perp=15.450, rec=0.497), tot_loss_proj:4.830 [t=0.27s]
prediction: ['[CLS] hateified socio pleasure [SEP]']
[ 100/2000] tot_loss=2.539 (perp=10.953, rec=0.349), tot_loss_proj:3.071 [t=0.26s]
prediction: ['[CLS]verseverseverse pleasure [SEP]']
[ 150/2000] tot_loss=2.121 (perp=9.188, rec=0.284), tot_loss_proj:2.890 [t=0.26s]
prediction: ['[CLS] perverseverse pleasure [SEP]']
[ 200/2000] tot_loss=2.086 (perp=9.188, rec=0.249), tot_loss_proj:2.875 [t=0.26s]
prediction: ['[CLS] perverseverse pleasure [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.295 (perp=9.920, rec=0.311), tot_loss_proj:2.746 [t=0.25s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
[ 300/2000] tot_loss=2.231 (perp=9.920, rec=0.246), tot_loss_proj:2.708 [t=0.24s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.200 (perp=9.920, rec=0.216), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.196 (perp=9.920, rec=0.212), tot_loss_proj:2.699 [t=0.25s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.740 (perp=7.708, rec=0.199), tot_loss_proj:2.260 [t=0.25s]
prediction: ['[CLS] certain perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.740 (perp=7.708, rec=0.198), tot_loss_proj:2.264 [t=0.27s]
prediction: ['[CLS] certain perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.809 (perp=8.093, rec=0.190), tot_loss_proj:3.077 [t=0.25s]
prediction: ['[CLS] suppose perverse pleasure [SEP]']
[ 600/2000] tot_loss=2.256 (perp=10.350, rec=0.186), tot_loss_proj:2.912 [t=0.29s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.267 (perp=10.350, rec=0.197), tot_loss_proj:2.910 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.251 (perp=10.350, rec=0.181), tot_loss_proj:2.911 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[ 750/2000] tot_loss=2.242 (perp=10.350, rec=0.172), tot_loss_proj:2.914 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.238 (perp=10.350, rec=0.168), tot_loss_proj:2.913 [t=0.24s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.239 (perp=10.350, rec=0.169), tot_loss_proj:2.917 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[ 900/2000] tot_loss=2.248 (perp=10.350, rec=0.178), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.908 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=2.253 (perp=10.350, rec=0.183), tot_loss_proj:2.915 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1050/2000] tot_loss=2.231 (perp=10.350, rec=0.161), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=2.244 (perp=10.350, rec=0.174), tot_loss_proj:2.906 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=2.239 (perp=10.350, rec=0.169), tot_loss_proj:2.913 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1200/2000] tot_loss=2.242 (perp=10.350, rec=0.172), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.919 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=2.249 (perp=10.350, rec=0.179), tot_loss_proj:2.909 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1350/2000] tot_loss=2.240 (perp=10.350, rec=0.170), tot_loss_proj:2.917 [t=0.24s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=2.239 (perp=10.350, rec=0.169), tot_loss_proj:2.912 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.919 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1500/2000] tot_loss=2.233 (perp=10.350, rec=0.163), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=2.235 (perp=10.350, rec=0.165), tot_loss_proj:2.919 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=2.241 (perp=10.350, rec=0.171), tot_loss_proj:2.912 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1650/2000] tot_loss=2.235 (perp=10.350, rec=0.165), tot_loss_proj:2.907 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=2.230 (perp=10.350, rec=0.160), tot_loss_proj:2.916 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.911 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1800/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.914 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.914 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=2.230 (perp=10.350, rec=0.160), tot_loss_proj:2.916 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1950/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.918 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.915 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] valle perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 85.080 | p: 83.509 | r: 86.990
rouge2     | fm: 45.279 | p: 44.705 | r: 45.871
rougeL     | fm: 76.804 | p: 75.346 | r: 78.452
rougeLsum  | fm: 76.359 | p: 74.806 | r: 78.262
r1fm+r2fm = 130.359

input #20 time: 0:10:51 | total time: 3:45:32


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
cosin similarity: -0.9150968145462328 normalized error: 1.7452712448861945
cosin similarity: 0.9150968145462328 normalized error: 0.48995361248248304
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 1.8667190857143274 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 1.6752206174896798 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 1.6601686837135479 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 1.4928408445001984 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 1.4681039903226023 for ['[CLS] bonn university on ashe shot wearing rockerlica classification speed non burning glad california againstanding colt timing mouthigo gun machinery score liked seems [SEP]']
[Init] best rec loss: 1.2771454943723175 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 1.272630955218799 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 1.2682282968996532 for ['[CLS] situationsback loan item, side rights especially pose connecticut stony there baby she general fauna size deetaking golden labor vii according bent [UNK] [SEP]']
[Init] best perm rec loss: 1.2640128982675494 for ['[CLS] pose vii size rights golden situations connecticutback stony especially labor loan there she fauna side generaltaking according, item baby [UNK] bent dee [SEP]']
[Init] best perm rec loss: 1.263095541423839 for ['[CLS] rights [UNK] item size according situationsback she golden dee baby connecticuttaking loan vii general labor bent especially pose stony there side fauna, [SEP]']
[Init] best perm rec loss: 1.2589308407412578 for ['[CLS] according baby side pose loan fauna connecticut stony situations especially general golden rights [UNK]taking labor dee item vii size she bent, thereback [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.017 (perp=12.601, rec=0.497), tot_loss_proj:3.623 [t=0.26s]
prediction: ['[CLS] according federal alleged bombing tax discrimination was on da paranoid officers worst local pope death fda tape factory failed sent america replaced become worst brain [SEP]']
[ 100/2000] tot_loss=2.898 (perp=12.529, rec=0.392), tot_loss_proj:3.612 [t=0.25s]
prediction: ['[CLS] instead issued non fixing tax discrimination were on unions worry government no local embassy prisoner fda tape foreign worst sent apple instead become worst points [SEP]']
[ 150/2000] tot_loss=2.693 (perp=11.724, rec=0.348), tot_loss_proj:3.543 [t=0.26s]
prediction: ['[CLS] instead issued non racial taxes him on cdp after absent more or embassy prison society tyres barrel mccain sent apple instead become worst affected [SEP]']
[ 200/2000] tot_loss=2.561 (perp=11.274, rec=0.307), tot_loss_proj:3.351 [t=0.25s]
prediction: ['[CLS] being athletes non military repaires all the cdp way works more or embassy prisoners society tyres hit mccain likely presented instead into worst affect [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.503 (perp=11.074, rec=0.288), tot_loss_proj:3.448 [t=0.27s]
prediction: ['[CLS] instead embassy non military repairer all the women way works instead publicly and prisoners soviet tyres iraqi mccain screens presented instead serious exception affect [SEP]']
[ 300/2000] tot_loss=2.418 (perp=10.796, rec=0.258), tot_loss_proj:3.454 [t=0.24s]
prediction: ['[CLS] way embassy non military repairer all the women way works instead wounded, athletes soviet out tits sell severe works instead serious exception everything [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.537 (perp=11.511, rec=0.235), tot_loss_proj:3.693 [t=0.25s]
prediction: ['[CLS] way embassy non racial repairer all women the way works instead teachings athletes athletes soviet outwaite sell severe works instead serious exception way [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.416 (perp=10.983, rec=0.219), tot_loss_proj:3.346 [t=0.25s]
prediction: ['[CLS] how embassy waytypical repairs more women the way works instead treatment athletes athletes teachings out message kick objects works instead serious moral way [SEP]']
[ 450/2000] tot_loss=2.379 (perp=10.938, rec=0.191), tot_loss_proj:3.261 [t=0.27s]
prediction: ['[CLS] that embassy alltypical offices more women the way works instead treatment athletes athletes distinguish outwaitec objects they instead serious caretaker way [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.383 (perp=10.939, rec=0.195), tot_loss_proj:3.342 [t=0.25s]
prediction: ['[CLS] makes embassy alltypical caretakers more women the way works instead treatment athletes athletes distinguish out alphabetig facto they instead serious repair way [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.304 (perp=10.676, rec=0.168), tot_loss_proj:3.277 [t=0.27s]
prediction: ['[CLS] makes embassy alltypical caretakers more women the way works instead treatment athletes distinguish athletes out alphabetig objects they instead serious repair way [SEP]']
[ 600/2000] tot_loss=2.258 (perp=10.490, rec=0.160), tot_loss_proj:3.261 [t=0.25s]
prediction: ['[CLS] makes embassy alltypical caretakers more women the way works instead the athletes distinguish athletes out alphabetig objects it instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.443 (perp=11.391, rec=0.165), tot_loss_proj:3.476 [t=0.29s]
prediction: ['[CLS] makes corners alltypical caretaker facto more women the way works instead this athletes teachings athletes out juicyigs it instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.262 (perp=10.560, rec=0.150), tot_loss_proj:3.166 [t=0.27s]
prediction: ['[CLS] makes corners alltypical caretaker facto more women the way works instead the.typical athletes out,igs it instead serious repair way [SEP]']
[ 750/2000] tot_loss=2.247 (perp=10.487, rec=0.149), tot_loss_proj:3.157 [t=0.25s]
prediction: ['[CLS] makes corners alltypical caretaker facto more women the way works instead the juicytypical athletes out,igs it instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.193 (perp=10.280, rec=0.137), tot_loss_proj:3.066 [t=0.25s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more women like treated works instead this waytypical athletes out,,s it instead serious repair way [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.131 (perp=9.914, rec=0.148), tot_loss_proj:2.967 [t=0.25s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more like women treated works instead this waytypical athletes out,,s it instead serious repair way [SEP]']
[ 900/2000] tot_loss=2.080 (perp=9.736, rec=0.133), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] makes every alltypical caretaker necessarily more like women treated works instead this waytypical athletes out,,s this instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.996 (perp=9.318, rec=0.133), tot_loss_proj:3.105 [t=0.27s]
prediction: ['[CLS] makes every alltypical caretaker necessarily more like women treated works instead this waytypical athletes out, repairs this instead serious, way [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.157 (perp=10.080, rec=0.141), tot_loss_proj:2.992 [t=0.26s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more like womenps works instead this athletestypical way out, puttings eruptions instead serious, way [SEP]']
[1050/2000] tot_loss=2.183 (perp=10.293, rec=0.124), tot_loss_proj:3.036 [t=0.26s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more like women coiled works instead this athletestypical way out, puttings eruptions instead serious, way [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.158 (perp=10.107, rec=0.137), tot_loss_proj:2.938 [t=0.27s]
prediction: ['[CLS] makes ( alltypical caretaker athletes more like women coiled works instead this monkstypical way out, puttings eruptions instead serious, way [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.181 (perp=10.278, rec=0.126), tot_loss_proj:3.157 [t=0.26s]
prediction: ['[CLS] makes corners alltypical caretakers more like women coiled works instead this monkstypical way out, putting athletes eruptions reputation serious and way [SEP]']
[1200/2000] tot_loss=2.029 (perp=9.527, rec=0.123), tot_loss_proj:2.995 [t=0.27s]
prediction: ['[CLS] makes ( alltypical caretakers more like women coiled works instead this monkstypical way out, putting athletes it reputation serious and way [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.959 (perp=9.157, rec=0.127), tot_loss_proj:2.833 [t=0.25s]
prediction: ['[CLS] makes ( alltypical caretakers more like women coiled works instead and monkstypical way out, putting athletes it reputation serious this way [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.946 (perp=9.053, rec=0.136), tot_loss_proj:2.874 [t=0.25s]
prediction: ['[CLS] coiled ( alltypical caretakers more like women makes works instead and monkstypical way out, putting athletes it reputation serious this way [SEP]']
[1350/2000] tot_loss=1.930 (perp=9.053, rec=0.120), tot_loss_proj:2.880 [t=0.26s]
prediction: ['[CLS] coiled ( alltypical caretakers more like women makes works instead and monkstypical way out, putting athletes it reputation serious this way [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.037 (perp=9.552, rec=0.127), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] coiled ( alltypical caretakers more like women makes works instead refers monkstypical way out, putting athletes, reputation serious this way [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.049 (perp=9.602, rec=0.129), tot_loss_proj:3.154 [t=0.29s]
prediction: ['[CLS]ological ( alltypical caretakers more like women makes works instead 止 monks coiled way out, putting athletes, reputation serious this way [SEP]']
[1500/2000] tot_loss=2.035 (perp=9.586, rec=0.118), tot_loss_proj:3.259 [t=0.25s]
prediction: ['[CLS]ological ( alltypical caretakers more like women makes works instead ի monks coiled way out, putting athletes, reputation serious this way [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.957 (perp=9.158, rec=0.125), tot_loss_proj:3.108 [t=0.28s]
prediction: ['[CLS]ological ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.857 (perp=8.650, rec=0.127), tot_loss_proj:3.039 [t=0.27s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
[1650/2000] tot_loss=1.854 (perp=8.650, rec=0.124), tot_loss_proj:3.044 [t=0.26s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.857 (perp=8.650, rec=0.127), tot_loss_proj:3.042 [t=0.25s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.798 (perp=8.367, rec=0.125), tot_loss_proj:3.098 [t=0.29s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
[1800/2000] tot_loss=1.832 (perp=8.566, rec=0.119), tot_loss_proj:3.058 [t=0.25s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.831 (perp=8.566, rec=0.117), tot_loss_proj:3.056 [t=0.26s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.830 (perp=8.566, rec=0.117), tot_loss_proj:3.051 [t=0.29s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
[1950/2000] tot_loss=1.837 (perp=8.566, rec=0.124), tot_loss_proj:3.055 [t=0.26s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.835 (perp=8.566, rec=0.121), tot_loss_proj:3.058 [t=0.28s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 63.636 | r: 60.870
rouge2     | fm: 4.651 | p: 4.762 | r: 4.545
rougeL     | fm: 26.667 | p: 27.273 | r: 26.087
rougeLsum  | fm: 26.667 | p: 27.273 | r: 26.087
r1fm+r2fm = 66.873

[Aggregate metrics]:
rouge1     | fm: 84.117 | p: 82.800 | r: 85.864
rouge2     | fm: 43.479 | p: 43.010 | r: 44.105
rougeL     | fm: 74.441 | p: 73.134 | r: 76.044
rougeLsum  | fm: 74.132 | p: 72.723 | r: 75.814
r1fm+r2fm = 127.596

input #21 time: 0:11:00 | total time: 3:56:33


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
cosin similarity: -0.9087198991097636 normalized error: 1.8245618711317035
cosin similarity: 0.9087198991097637 normalized error: 0.45808974339065517
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 1.9687011684637357 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 1.8923598639402632 for ['[CLS] shakespeare operation emerald hip year art mcdowell model apart league rate [SEP]']
[Init] best rec loss: 1.8782002101606934 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 1.8742949802815434 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 1.8167711605783965 for ['[CLS] av waitingalis reception pillar anna deal mentionedhl etc showers [SEP]']
[Init] best rec loss: 1.7648179200842402 for ['[CLS] cloud road hey wynn under diiny stalk seduce variousour [SEP]']
[Init] best rec loss: 1.728552698662686 for ['[CLS] dialectotte [MASK] type became designing aired replacing piece dear travel [SEP]']
[Init] best rec loss: 1.7253352967604632 for ['[CLS]vi dudley sponsored then background che opposition laurencefc feat double [SEP]']
[Init] best rec loss: 1.6962413440899562 for ['[CLS] immortal dos standing commentarytort placehim corporal full cruisers carrier [SEP]']
[Init] best rec loss: 1.6901170832984254 for ['[CLS] sans services downstairsgar arched take network before simply dean jurgen [SEP]']
[Init] best rec loss: 1.611336990481398 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 1.6072025469481208 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 1.6019567471392189 for ['[CLS] phoenix her laughter over function schedule chinese boarders kids set [SEP]']
[Init] best perm rec loss: 1.6008067428671753 for ['[CLS] board chinese over function kids her phoenixers schedule set laughter [SEP]']
[Init] best perm rec loss: 1.5999882609269387 for ['[CLS] board over phoenix functioners her schedule kids laughter chinese set [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.100 (perp=11.911, rec=0.718), tot_loss_proj:3.997 [t=0.26s]
prediction: ['[CLS]?. colonel earlier an hardly engine uranium pending insufficient grossed [SEP]']
[ 100/2000] tot_loss=2.979 (perp=11.748, rec=0.630), tot_loss_proj:3.909 [t=0.26s]
prediction: ['[CLS] problem. colonel earlier a hurt recording overtime minor arrest grossed [SEP]']
[ 150/2000] tot_loss=2.997 (perp=12.087, rec=0.580), tot_loss_proj:4.222 [t=0.26s]
prediction: ['[CLS] sum his colonel earlier a communist recording some until filming austrian [SEP]']
[ 200/2000] tot_loss=3.009 (perp=12.205, rec=0.568), tot_loss_proj:4.341 [t=0.26s]
prediction: ['[CLS] fifa hit colonel thriller a communist filmed overtime joyah imprisonment liability [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.752 (perp=10.994, rec=0.553), tot_loss_proj:3.718 [t=0.27s]
prediction: ['[CLS] successful adaptation adventures thriller a film film unions joyah communist recording [SEP]']
[ 300/2000] tot_loss=2.748 (perp=11.149, rec=0.518), tot_loss_proj:3.624 [t=0.26s]
prediction: ['[CLS] successful adaptation adventures serialized a film adaptation unions cooperate communist efforts [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.980 (perp=12.299, rec=0.521), tot_loss_proj:4.017 [t=0.25s]
prediction: ['[CLS] successful adaptation tolkien a serialized film adaptation unions cooperate communist spilling [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.719 (perp=11.165, rec=0.486), tot_loss_proj:3.898 [t=0.25s]
prediction: ['[CLS] successful adaptation communist an serialized film adaptation unions repair tolkien splits [SEP]']
[ 450/2000] tot_loss=2.768 (perp=11.165, rec=0.535), tot_loss_proj:3.900 [t=0.26s]
prediction: ['[CLS] successful adaptation communist an serialized film adaptation unions repair tolkien splits [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.679 (perp=10.964, rec=0.486), tot_loss_proj:3.918 [t=0.25s]
prediction: ['[CLS] successful adaptation communist serialized film an adaptation unions repair tolkien browser [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.669 (perp=11.015, rec=0.466), tot_loss_proj:3.080 [t=0.25s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation unions enjoyable tolkien splits [SEP]']
[ 600/2000] tot_loss=2.695 (perp=11.015, rec=0.492), tot_loss_proj:3.085 [t=0.25s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation unions enjoyable tolkien splits [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.848 (perp=11.855, rec=0.477), tot_loss_proj:3.193 [t=0.25s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation a enjoyable finnish splits [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.666 (perp=11.149, rec=0.436), tot_loss_proj:3.156 [t=0.26s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation a finnish enjoyable splits [SEP]']
[ 750/2000] tot_loss=2.756 (perp=11.651, rec=0.426), tot_loss_proj:3.190 [t=0.25s]
prediction: ['[CLS] successful adaptation communist quick an enjoyable adaptation a finnish enjoyable splits [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.618 (perp=10.855, rec=0.447), tot_loss_proj:2.950 [t=0.27s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.609 (perp=10.855, rec=0.438), tot_loss_proj:2.955 [t=0.26s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
[ 900/2000] tot_loss=2.619 (perp=10.855, rec=0.448), tot_loss_proj:2.945 [t=0.25s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.876 (perp=10.855, rec=0.705), tot_loss_proj:2.942 [t=0.25s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.803 (perp=11.603, rec=0.482), tot_loss_proj:3.784 [t=0.26s]
prediction: ['[CLS] successful adaptation election successful compilation successful adaptation a finnish excuse splits [SEP]']
[1050/2000] tot_loss=2.821 (perp=11.885, rec=0.444), tot_loss_proj:3.271 [t=0.27s]
prediction: ['[CLS] successful adaptation election successful enjoyable successful adaptation a finnish enjoyable splits [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.765 (perp=11.630, rec=0.439), tot_loss_proj:3.111 [t=0.25s]
prediction: ['[CLS] successful successful a successful enjoyable successful adaptation election finnish enjoyable splits [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.759 (perp=11.641, rec=0.431), tot_loss_proj:3.143 [t=0.26s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election finnish enjoyable splits [SEP]']
[1200/2000] tot_loss=2.614 (perp=11.000, rec=0.414), tot_loss_proj:3.130 [t=0.25s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1250/2000] tot_loss=2.614 (perp=11.000, rec=0.414), tot_loss_proj:3.131 [t=0.25s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1300/2000] tot_loss=2.642 (perp=11.000, rec=0.442), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
[1350/2000] tot_loss=2.601 (perp=11.000, rec=0.401), tot_loss_proj:3.130 [t=0.26s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1400/2000] tot_loss=2.604 (perp=10.956, rec=0.413), tot_loss_proj:3.061 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1450/2000] tot_loss=2.595 (perp=10.956, rec=0.404), tot_loss_proj:3.064 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
[1500/2000] tot_loss=2.589 (perp=10.956, rec=0.398), tot_loss_proj:3.060 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1550/2000] tot_loss=2.582 (perp=10.940, rec=0.394), tot_loss_proj:2.904 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1600/2000] tot_loss=2.581 (perp=10.940, rec=0.393), tot_loss_proj:2.906 [t=0.25s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
[1650/2000] tot_loss=2.572 (perp=10.940, rec=0.384), tot_loss_proj:2.898 [t=0.25s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1700/2000] tot_loss=2.579 (perp=10.940, rec=0.391), tot_loss_proj:2.909 [t=0.24s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1750/2000] tot_loss=2.580 (perp=10.940, rec=0.392), tot_loss_proj:2.903 [t=0.27s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
[1800/2000] tot_loss=2.580 (perp=10.940, rec=0.392), tot_loss_proj:2.905 [t=0.25s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1850/2000] tot_loss=2.578 (perp=10.940, rec=0.390), tot_loss_proj:2.905 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1900/2000] tot_loss=2.576 (perp=10.940, rec=0.388), tot_loss_proj:2.908 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
[1950/2000] tot_loss=2.565 (perp=10.940, rec=0.377), tot_loss_proj:2.905 [t=0.25s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[2000/2000] tot_loss=2.575 (perp=10.940, rec=0.387), tot_loss_proj:2.903 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.000 | p: 50.000 | r: 46.154
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 40.000 | p: 41.667 | r: 38.462
rougeLsum  | fm: 40.000 | p: 41.667 | r: 38.462
r1fm+r2fm = 56.696

[Aggregate metrics]:
rouge1     | fm: 82.547 | p: 81.277 | r: 84.090
rouge2     | fm: 42.040 | p: 41.498 | r: 42.631
rougeL     | fm: 72.989 | p: 71.696 | r: 74.561
rougeLsum  | fm: 72.633 | p: 71.408 | r: 74.295
r1fm+r2fm = 124.587

input #22 time: 0:10:47 | total time: 4:07:20


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
cosin similarity: 0.9513774856923713 normalized error: 0.4344634306918702
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 1.3518757628141271 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 1.3198257475467645 for ['[CLS] jumped its ion [MASK] deep spirit tracks controls spun donated tape calendar ineligible martial airport breaths complexvas net straight vs # jake featurebal each roots record death share troubles chance scores mate frank holding quest exactlyul governments win far ap gathering toysience married club [SEP]']
[Init] best rec loss: 1.30550744134911 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 1.2570864343922903 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 1.2145625932985147 for ['[CLS] talent cause skirt handled ⁴ anne pieces mine! caused safety tor goal fore 2014 residents chosen offering chiefs number sun consumergementni property riding dolphin exchequerada saw occupants trades vale course kind coronation ballroom dona village totally selena winds firstd sums manga square scholar [SEP]']
[Init] best perm rec loss: 1.2142063278498108 for ['[CLS] pieces number talent course property occupants residents ⁴ dona ballroom safety village totally manga chiefs sums valeada scholar riding!d coronation square sun handled consumer winds tor chosen saw goal offering anne mine trades first dolphin causegement caused skirt fore selena exchequer 2014 kindni [SEP]']
[Init] best perm rec loss: 1.2127282717891918 for ['[CLS] cause dolphin manga trades scholar skirt pieces tor offering occupants anne saw dona riding ⁴ chiefsni 2014 goal totally safety numberada talent sums winds village consumer mine residents! caused selena ballroom square coronationd kind first chosen sun vale property course exchequergement fore handled [SEP]']
[Init] best perm rec loss: 1.2119208803839943 for ['[CLS] number sun 2014 first coronation consumer course residents village caused totally saw selena trades dolphin exchequer propertyd chosenni manga offering square safety tor minegement fore! causeada riding chiefs handled scholar talent anne ⁴ skirt dona sums winds goal vale occupants ballroom kind pieces [SEP]']
[Init] best perm rec loss: 1.2111210877200476 for ['[CLS] 2014 sumsd skirt occupants talent pieces number sun saw consumer square totallyni first exchequer ⁴ coronation cause trades ballroom handled residents! village riding dolphin valeada dona caused offering chosen tor fore property mine course goal kind selena safety chiefs scholar mangagement winds anne [SEP]']
[Init] best perm rec loss: 1.210146347666845 for ['[CLS]d first!ada riding chiefs consumer winds selenagement exchequer mine sums 2014 caused fore number ballroom property sun saw offering village residents course talent vale pieces scholar safety ⁴ torni cause square dolphin anne occupants kind manga coronation totally handled trades goal skirt dona chosen [SEP]']
[Init] best perm rec loss: 1.2095988735355152 for ['[CLS] ⁴ tor village residents course square chosen consumer occupantsgement handled saw! ballroom sun chiefs coronation safety first kind offering selena exchequer trades mine caused pieces skirt dona riding sums caused scholar fore 2014 anne propertyni dolphin totally windsada talent vale number manga goal [SEP]']
[Init] best perm rec loss: 1.207835147944121 for ['[CLS] goal saw ridinggement chosenni tor skirtada offering pieces trades mine consumer occupants safety sums dona kind anned exchequer manga ballroom talent totally fore! village first dolphin square selena handled cause property vale sun winds coronation 2014 number caused scholar course chiefs residents ⁴ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.757 (perp=10.958, rec=0.566), tot_loss_proj:3.360 [t=0.26s]
prediction: ["[CLS] lehigh combat box media group [SEP] engineering vision 2013 patrick art vc daily environment program uk : t with lifelong goal caring visual critical vision programminging orange year josh lonely c arsre oriented movement vale best therefore visual include contents'scholar paid pinch past 35 [SEP]"]
[ 100/2000] tot_loss=2.924 (perp=12.618, rec=0.400), tot_loss_proj:3.702 [t=0.26s]
prediction: ['[CLS] ricanvich devi media group [SEP] engineering southwest deliberately × war vc compassionead ghana also : bits thisir t sustainablehyllum critical vision globalf fighting action josh frowning feeling is expression information bnched best identify visual atlanta contents co scholar paid give past 35 [SEP]']
[ 150/2000] tot_loss=2.787 (perp=12.213, rec=0.345), tot_loss_proj:3.632 [t=0.25s]
prediction: ['[CLS] your fist devi conceptual medal constitution message environmental [SEP] × soldiers vc concernedt traumatic also : soldiers this object she caring joyah frederick visual :f battle ground its objective subjects is expression information bone fe best identify gaze nc contents should helping out give mission colleges [SEP]']
[ 200/2000] tot_loss=2.641 (perp=11.738, rec=0.293), tot_loss_proj:3.417 [t=0.25s]
prediction: ['[CLS] many the " concept its constitution tone vietnam [SEP] how soldiers vc concernedt traumatic also : soldiers this object threat caring joyah₍ realm :f battle field its objective : : proportion information dress hardin otherwise theory gaze nc vast co helping made give mission missions [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.372 (perp=10.478, rec=0.276), tot_loss_proj:3.101 [t=0.25s]
prediction: ['[CLS] your the : concept its theater picture vietnam [SEP] how soldiers, conflictt also : soldiers this object completely human foundation museum vietnam realm :f strategic ground its objective : : proportion information dress stress otherwise theory looksboro an a helping made to immediate missions [SEP]']
[ 300/2000] tot_loss=2.314 (perp=10.359, rec=0.242), tot_loss_proj:3.188 [t=0.25s]
prediction: ['[CLS] many the : idea its theater picture vietnam allmusic unfamiliar soldiers, create - of : soldiers this object despite popular foundation joyah vietnam goal :h strategic ground its objective : : proportion strategic dress stress otherwise theory - montreal its a helping made to immediate missions [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.208 (perp=9.945, rec=0.219), tot_loss_proj:3.151 [t=0.27s]
prediction: ['[CLS] many unfamiliar : idea its theater picture vietnam allmusic the soldiers, create, of : soldiers also object despite popular foundation joyah vietnam goal :h strategic centre its objective : : proportion strategic the stress otherwise theory -sboro an to helping made to immediate missions [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.328 (perp=10.623, rec=0.203), tot_loss_proj:3.459 [t=0.28s]
prediction: ['[CLS] many unfamiliar : idea its theater picture vietnam quickly the soldiers, create - vietnam of soldiers ultimately ultimately despite popular charitable joyah of goal lifeh strategic genus its objective : : proportion strategic the stress otherwise theory -sboro afi the helping made to main missions [SEP]']
[ 450/2000] tot_loss=2.264 (perp=10.314, rec=0.201), tot_loss_proj:3.376 [t=0.25s]
prediction: ['[CLS] many unfamiliar : idea its theater picture vietnam achieve the soldiers, create, vietnam of soldiers ultimately ultimately despite mainstream charitable joyah of goal lifeh strategic idea its objective : : the strategic the stress so theory -sboro afi the helping made to main missions [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.247 (perp=10.288, rec=0.189), tot_loss_proj:3.377 [t=0.27s]
prediction: ['[CLS] many unfamiliar : idea its objective picture vietnam achieve a soldiers, create, vietnam of soldiers ultimately ultimately despite mainstream charitable joyah of goal lifeh strategic idea its objective : : procession relationship the stress so strategic - kaladin afi the helping made to main missions [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.252 (perp=10.362, rec=0.180), tot_loss_proj:3.152 [t=0.29s]
prediction: ['[CLS] many unfamiliar : idea its objective picture achieve a soldiers, vietnam create, vietnam of soldiers ultimately ultimately their mainstream charitable joyah of goal lifeh strategic idea main objective : : pest relationship the stress so strategic - achieved afi the helping so to main missions [SEP]']
[ 600/2000] tot_loss=2.103 (perp=9.650, rec=0.173), tot_loss_proj:3.069 [t=0.27s]
prediction: ['[CLS] manyndra : idea its objective picture achieve a soldiers, vietnam build, vietnam of soldiers ultimately ultimately despite mainstream same joyah of goal lifeh strategic idea main objective : : the relationship the stress so strategic of achievedizing the helping so to main missions [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.101 (perp=9.681, rec=0.165), tot_loss_proj:2.940 [t=0.25s]
prediction: ['[CLS] manyrnik : idea to strategic picture achieve a soldiers, vietnam create, vietnam, soldiers ultimately ultimately its mainstream same joyah of objective life ra strategic idea main objective : :zing relationship theposed. strategic of achievedizing the helping so its main missions [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.117 (perp=9.767, rec=0.163), tot_loss_proj:2.965 [t=0.25s]
prediction: ['[CLS] althoughrnik : idea to strategic picture achieve a soldiers, vietnam create, vietnam, soldiers ultimately ultimately knowles mainstream same joyah life objective a ra strategic idea main objective : :zing relationship theposed. strategic of achievedizing the helping so its main missions [SEP]']
[ 750/2000] tot_loss=2.112 (perp=9.760, rec=0.160), tot_loss_proj:2.975 [t=0.26s]
prediction: ['[CLS] althoughrnik : idea to strategic picture achieve a soldiers, vietnam create, vietnam, soldiers ultimately ultimately knowles mainstream same joyah life objective a ra strategic idea main objective : :zing relationship theeering. strategic of kaladinizing the helping so its main missions [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.130 (perp=9.892, rec=0.151), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] althoughrnik : idea to strategic picture create achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately knowles mainstream same joyah lives objective a ra strategic idea main objective : :zing relationship the ـ. strategic of kaladinizing the helping so its main missions [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.121 (perp=9.838, rec=0.154), tot_loss_proj:3.040 [t=0.26s]
prediction: ['[CLS] althoughndra : idea to strategic picture create achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately knowleseses successful joyah lives objective a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinizing the helping so its main missions [SEP]']
[ 900/2000] tot_loss=2.113 (perp=9.839, rec=0.145), tot_loss_proj:3.035 [t=0.25s]
prediction: ['[CLS] althoughndra : idea to strategic picture create achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately withouteses successful joyah lives objective a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinizing the helping so its main missions [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.050 (perp=9.500, rec=0.150), tot_loss_proj:2.975 [t=0.27s]
prediction: ['[CLS] althoughndra : idea create strategic picture to achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately knowleseses successful joyah lives objective a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinizing the helping after its main missions [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.034 (perp=9.436, rec=0.146), tot_loss_proj:2.927 [t=0.25s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately itseses what joyah lives a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinenting the helping after its main missions [SEP]']
[1050/2000] tot_loss=2.033 (perp=9.436, rec=0.145), tot_loss_proj:2.921 [t=0.26s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately itseses what joyah lives a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinenting the helping after its main missions [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.100 (perp=9.826, rec=0.135), tot_loss_proj:3.060 [t=0.25s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its ra foreign same joyah lives a strategic idea main objective : strategiczing ofh ـ. strategic relationship kaladinenting the helping after its main missions [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.995 (perp=9.286, rec=0.138), tot_loss_proj:2.937 [t=0.25s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its ra foreign what joyah lives a strategic idea main objective : dramazing of the ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
[1200/2000] tot_loss=2.032 (perp=9.492, rec=0.134), tot_loss_proj:2.951 [t=0.25s]
prediction: ['[CLS] whileching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its ra foreignzing joyah lives a strategic idea main objective : dramazing ofh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.943 (perp=9.029, rec=0.137), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] whileching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.940 (perp=8.968, rec=0.146), tot_loss_proj:2.835 [t=0.25s]
prediction: ['[CLS] whileching : strategic idea create picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
[1350/2000] tot_loss=1.934 (perp=8.968, rec=0.140), tot_loss_proj:2.830 [t=0.27s]
prediction: ['[CLS] whileching : strategic idea create picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.923 (perp=8.894, rec=0.144), tot_loss_proj:2.824 [t=0.27s]
prediction: ['[CLS] while ( : strategic idea create picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladinenting the helping. after its main missions [SEP]']
Attempt swap
[1450/2000] tot_loss=1.936 (perp=9.014, rec=0.133), tot_loss_proj:2.833 [t=0.26s]
prediction: ['[CLS] whileching : strategic idea create picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
[1500/2000] tot_loss=1.927 (perp=8.976, rec=0.132), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] while ( : strategic idea create picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.896 (perp=8.798, rec=0.137), tot_loss_proj:2.824 [t=0.26s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.843 (perp=8.570, rec=0.129), tot_loss_proj:2.791 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramazing foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
[1650/2000] tot_loss=1.842 (perp=8.570, rec=0.128), tot_loss_proj:2.787 [t=0.26s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramazing foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.820 (perp=8.466, rec=0.127), tot_loss_proj:2.804 [t=0.28s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text kaladin helping the drama. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.791 (perp=8.334, rec=0.125), tot_loss_proj:2.858 [t=0.25s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
[1800/2000] tot_loss=1.790 (perp=8.334, rec=0.124), tot_loss_proj:2.857 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.779 (perp=8.229, rec=0.133), tot_loss_proj:2.826 [t=0.25s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Attempt swap
[1900/2000] tot_loss=1.775 (perp=8.229, rec=0.129), tot_loss_proj:2.819 [t=0.26s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.229, rec=0.120), tot_loss_proj:2.829 [t=0.25s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Attempt swap
[2000/2000] tot_loss=1.765 (perp=8.146, rec=0.135), tot_loss_proj:2.803 [t=0.26s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve the soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] while ( create strategic idea : picture to achieve the soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.000 | p: 45.000 | r: 45.000
rouge2     | fm: 10.256 | p: 10.256 | r: 10.256
rougeL     | fm: 32.500 | p: 32.500 | r: 32.500
rougeLsum  | fm: 32.500 | p: 32.500 | r: 32.500
r1fm+r2fm = 55.256

[Aggregate metrics]:
rouge1     | fm: 81.041 | p: 79.916 | r: 82.575
rouge2     | fm: 40.830 | p: 40.383 | r: 41.343
rougeL     | fm: 71.309 | p: 70.147 | r: 72.819
rougeLsum  | fm: 71.023 | p: 69.806 | r: 72.478
r1fm+r2fm = 121.871

input #23 time: 0:11:02 | total time: 4:18:23


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
cosin similarity: -0.9223604647986088 normalized error: 1.7670051703009635
cosin similarity: 0.9223604647986089 normalized error: 0.47736402311244497
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 1.8235173558366566 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 1.690636250427732 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 1.6660788999609562 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 1.639423956785702 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 1.3858401992514717 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 1.1764352784900491 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 1.174503061829458 for ['[CLS] bondwyl unless county em arms damned happy suffer play attack younger ryu midaneous bush snow village no port [SEP]']
[Init] best perm rec loss: 1.1737241560296066 for ['[CLS]wyl play county ryu village arms younger port mid bond attack em bush suffer damnedaneous no snow happy unless [SEP]']
[Init] best perm rec loss: 1.1691451229159813 for ['[CLS] younger port ryu countyaneous attack arms village bushwyl bond snow unless mid em no suffer happy play damned [SEP]']
[Init] best perm rec loss: 1.1685529381675073 for ['[CLS] bond ryu port county attack play village arms happywyl snow unless bush younger mid suffer no emaneous damned [SEP]']
[Init] best perm rec loss: 1.1671323903442032 for ['[CLS] portaneous play suffer attack arms bond ryu damned county snowwyl em bush happy mid village unless younger no [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.890 (perp=12.173, rec=0.455), tot_loss_proj:3.490 [t=0.28s]
prediction: ['[CLS] bad monitoring b tamil terrorists someone drug kanye destroy terrorist drug? phone constituency tribunal [ were taken evil interpret [SEP]']
[ 100/2000] tot_loss=2.848 (perp=12.444, rec=0.359), tot_loss_proj:3.471 [t=0.30s]
prediction: ['[CLS] bad marty a plot terrorists % bomb cruz stealing terrorist drug? research constituency tribunal narrower were taken evil terrorists [SEP]']
[ 150/2000] tot_loss=2.138 (perp=9.131, rec=0.312), tot_loss_proj:2.824 [t=0.30s]
prediction: ['[CLS] context context : are terrorists any bomb! terrorists terrorist protection? political context beings outside were taken evil terrorists [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.154, rec=0.232), tot_loss_proj:2.991 [t=0.28s]
prediction: ['[CLS] context context context are terrorists else (! terrorists terrorist his? political context beings outside were taken evil terrorists [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.174 (perp=9.868, rec=0.200), tot_loss_proj:2.957 [t=0.29s]
prediction: ['[CLS] context context the are taken % (! terrorists terrorist against of bombs context! outside were terrorists evil terrorists [SEP]']
[ 300/2000] tot_loss=2.166 (perp=9.928, rec=0.181), tot_loss_proj:2.916 [t=0.30s]
prediction: ['[CLS] context ( the are taken % (! terrorists terrorist political of political context! outside stare terrorists evil terrorists [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.214 (perp=10.244, rec=0.166), tot_loss_proj:2.984 [t=0.30s]
prediction: ['[CLS] context ( the stare taken than ( see abuse terrorist political of climate context than outside are terrorists evil economically [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.230 (perp=10.370, rec=0.156), tot_loss_proj:3.015 [t=0.29s]
prediction: ['[CLS] context ( the are taken than ( see environmental terrorist political ( climate context than outside are terrorists evil economically [SEP]']
[ 450/2000] tot_loss=2.238 (perp=10.494, rec=0.139), tot_loss_proj:3.032 [t=0.29s]
prediction: ['[CLS] context ( the are taken than ( see climate terrorist political ( climate context than outside are terrorists evil economically [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.268 (perp=10.654, rec=0.138), tot_loss_proj:3.153 [t=0.29s]
prediction: ['[CLS] ( context the are taken than ( see climate allah political ( climate context than outside are terrorists evil economically [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.063 (perp=9.657, rec=0.132), tot_loss_proj:3.009 [t=0.30s]
prediction: ['[CLS] ( context the are taken than ( see climate allah political current climate context! outside terrorists are evil economically [SEP]']
[ 600/2000] tot_loss=2.132 (perp=10.039, rec=0.125), tot_loss_proj:3.020 [t=0.29s]
prediction: ['[CLS] ( context the of taken than ( see climate allah political current climate context! outside terrorists are evil economically [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.021 (perp=9.498, rec=0.121), tot_loss_proj:2.832 [t=0.29s]
prediction: ['[CLS] ( context the political taken than ( see climate allah of current climate context! outside terrorists are evil economically [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.000 (perp=9.394, rec=0.122), tot_loss_proj:2.842 [t=0.32s]
prediction: ['[CLS] ( taken the political context than ( see abuse allah of current climate context! outside terrorists more evil economically [SEP]']
[ 750/2000] tot_loss=1.992 (perp=9.394, rec=0.113), tot_loss_proj:2.845 [t=0.30s]
prediction: ['[CLS] ( taken the political context than ( see abuse allah of current climate context! outside terrorists more evil economically [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.966 (perp=9.201, rec=0.125), tot_loss_proj:2.717 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see abuse terrorists of current context context! outside terrorists more evil economically [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.940 (perp=9.107, rec=0.119), tot_loss_proj:2.792 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context terrorists of current contextout! outside terrorists more evil lebanon [SEP]']
[ 900/2000] tot_loss=1.937 (perp=9.107, rec=0.116), tot_loss_proj:2.791 [t=0.32s]
prediction: ['[CLS] ( taken the political climate than ( see context terrorists of current contextout! outside terrorists more evil lebanon [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.862 (perp=8.720, rec=0.117), tot_loss_proj:2.824 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1000/2000] tot_loss=1.850 (perp=8.720, rec=0.106), tot_loss_proj:2.825 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
[1050/2000] tot_loss=1.851 (perp=8.720, rec=0.107), tot_loss_proj:2.823 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1100/2000] tot_loss=1.857 (perp=8.720, rec=0.113), tot_loss_proj:2.827 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1150/2000] tot_loss=1.861 (perp=8.720, rec=0.117), tot_loss_proj:2.827 [t=0.31s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
[1200/2000] tot_loss=1.866 (perp=8.720, rec=0.122), tot_loss_proj:2.829 [t=0.30s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1250/2000] tot_loss=1.901 (perp=8.948, rec=0.112), tot_loss_proj:2.779 [t=0.30s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1300/2000] tot_loss=1.894 (perp=8.948, rec=0.105), tot_loss_proj:2.777 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
[1350/2000] tot_loss=1.899 (perp=8.948, rec=0.110), tot_loss_proj:2.777 [t=0.31s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1400/2000] tot_loss=1.895 (perp=8.948, rec=0.105), tot_loss_proj:2.781 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1450/2000] tot_loss=1.898 (perp=8.948, rec=0.108), tot_loss_proj:2.781 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
[1500/2000] tot_loss=1.901 (perp=8.948, rec=0.112), tot_loss_proj:2.784 [t=0.30s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1550/2000] tot_loss=1.896 (perp=8.948, rec=0.106), tot_loss_proj:2.778 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.816 (perp=8.565, rec=0.103), tot_loss_proj:2.712 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than context ( see context of current _out! outside terrorists more evil lebanon [SEP]']
[1650/2000] tot_loss=1.864 (perp=8.786, rec=0.107), tot_loss_proj:2.696 [t=0.32s]
prediction: ['[CLS] ( taken the political climate than context ( see context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1700/2000] tot_loss=1.864 (perp=8.786, rec=0.107), tot_loss_proj:2.690 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than context ( see context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.799 (perp=8.428, rec=0.113), tot_loss_proj:2.654 [t=0.26s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more evil context [SEP]']
[1800/2000] tot_loss=1.800 (perp=8.428, rec=0.114), tot_loss_proj:2.653 [t=0.31s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more evil context [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.782 (perp=8.346, rec=0.113), tot_loss_proj:2.600 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more context evil [SEP]']
Attempt swap
[1900/2000] tot_loss=1.777 (perp=8.346, rec=0.108), tot_loss_proj:2.602 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more context evil [SEP]']
[1950/2000] tot_loss=1.809 (perp=8.546, rec=0.100), tot_loss_proj:2.648 [t=0.25s]
prediction: ['[CLS] ( taken the political climate than respective ( see context of current _out! outside terrorists more context evil [SEP]']
Attempt swap
[2000/2000] tot_loss=1.805 (perp=8.546, rec=0.096), tot_loss_proj:2.648 [t=0.26s]
prediction: ['[CLS] ( taken the political climate than respective ( see context of current _out! outside terrorists more context evil [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 23.529 | p: 23.529 | r: 23.529
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 106.863

[Aggregate metrics]:
rouge1     | fm: 81.187 | p: 79.986 | r: 82.646
rouge2     | fm: 39.678 | p: 39.193 | r: 40.175
rougeL     | fm: 70.663 | p: 69.553 | r: 72.191
rougeLsum  | fm: 70.064 | p: 69.075 | r: 71.582
r1fm+r2fm = 120.866

input #24 time: 0:12:08 | total time: 4:30:32


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
cosin similarity: 0.9657079483269472 normalized error: 0.40029975426057546
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.921533046557849 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 1.8493198516179912 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 1.6627446159709092 for ['[CLS] merit delaney canoniary [SEP]']
[Init] best rec loss: 1.6268557675971966 for ['[CLS] james adding letters received [SEP]']
[Init] best rec loss: 1.4347181383026864 for ['[CLS] mention acre old headline [SEP]']
[Init] best rec loss: 1.4075943361424101 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best rec loss: 1.2928002379071515 for ['[CLS] hide a seal mess [SEP]']
[Init] best perm rec loss: 1.286761864923727 for ['[CLS] hide seal mess a [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.258, rec=0.436), tot_loss_proj:3.171 [t=0.26s]
prediction: ['[CLS] portrait striking february natural [SEP]']
[ 100/2000] tot_loss=1.899 (perp=8.063, rec=0.287), tot_loss_proj:2.198 [t=0.26s]
prediction: ['[CLS] beautiful beautiful strange beautiful [SEP]']
[ 150/2000] tot_loss=2.278 (perp=10.292, rec=0.219), tot_loss_proj:2.621 [t=0.25s]
prediction: ['[CLS] film beautiful strange beautiful [SEP]']
[ 200/2000] tot_loss=2.577 (perp=11.985, rec=0.180), tot_loss_proj:2.902 [t=0.26s]
prediction: ['[CLS] film & strange beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.876 (perp=8.556, rec=0.165), tot_loss_proj:2.195 [t=0.25s]
prediction: ['[CLS] film strange & beautiful [SEP]']
[ 300/2000] tot_loss=1.745 (perp=8.016, rec=0.142), tot_loss_proj:2.016 [t=0.26s]
prediction: ['[CLS] film strange and beautiful [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.466 (perp=6.646, rec=0.136), tot_loss_proj:1.538 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.463 (perp=6.646, rec=0.134), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.457 (perp=6.646, rec=0.128), tot_loss_proj:1.539 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.456 (perp=6.646, rec=0.126), tot_loss_proj:1.533 [t=0.30s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.523 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.452 (perp=6.646, rec=0.123), tot_loss_proj:1.530 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.446 (perp=6.646, rec=0.116), tot_loss_proj:1.528 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.460 (perp=6.646, rec=0.130), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.452 (perp=6.646, rec=0.123), tot_loss_proj:1.519 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.451 (perp=6.646, rec=0.122), tot_loss_proj:1.534 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.646, rec=0.124), tot_loss_proj:1.524 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.459 (perp=6.646, rec=0.129), tot_loss_proj:1.522 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.439 (perp=6.646, rec=0.110), tot_loss_proj:1.532 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.449 (perp=6.646, rec=0.120), tot_loss_proj:1.523 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.440 (perp=6.646, rec=0.111), tot_loss_proj:1.533 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.524 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.446 (perp=6.646, rec=0.117), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.449 (perp=6.646, rec=0.119), tot_loss_proj:1.530 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.454 (perp=6.646, rec=0.124), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.446 (perp=6.646, rec=0.117), tot_loss_proj:1.535 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.448 (perp=6.646, rec=0.118), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.466 (perp=6.646, rec=0.137), tot_loss_proj:1.519 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.646, rec=0.130), tot_loss_proj:1.519 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.453 (perp=6.646, rec=0.124), tot_loss_proj:1.522 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.646, rec=0.118), tot_loss_proj:1.538 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.443 (perp=6.646, rec=0.113), tot_loss_proj:1.523 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.453 (perp=6.646, rec=0.123), tot_loss_proj:1.529 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.531 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.436 (perp=6.646, rec=0.107), tot_loss_proj:1.531 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.454 (perp=6.646, rec=0.125), tot_loss_proj:1.536 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.448 (perp=6.646, rec=0.119), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.447 (perp=6.646, rec=0.118), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.452 (perp=6.646, rec=0.122), tot_loss_proj:1.518 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.850 | p: 80.785 | r: 83.209
rouge2     | fm: 42.040 | p: 41.692 | r: 42.578
rougeL     | fm: 71.582 | p: 70.485 | r: 72.981
rougeLsum  | fm: 71.489 | p: 70.382 | r: 72.744
r1fm+r2fm = 123.889

input #25 time: 0:10:46 | total time: 4:41:18


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
cosin similarity: -0.9021100735279437 normalized error: 1.801235038259484
cosin similarity: 0.9021100735279438 normalized error: 0.4706903940273791
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 1.8009709819325461 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 1.790939063684656 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 1.6105957617002156 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 1.5392134365327053 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 1.4764521072094978 for ['[CLS]sed benedict later housing why surroundingpinegrave nat use amount cast thy scored pattern run unknown authority travellingflict quotes guest lucan [SEP]']
[Init] best rec loss: 1.348597712309089 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 1.347903887077467 for ['[CLS] stakekar passing rides 65 turns speak mutant montrose capacity rid fur unite button riceª ak occupied cher following fully igo [SEP]']
[Init] best perm rec loss: 1.3444805281045762 for ['[CLS] rides stake occupiedª turns buttonkar capacity i following fur mutant passing speak fullygo cher rice 65 montrose ak unite rid [SEP]']
[Init] best perm rec loss: 1.32912584483422 for ['[CLS] i akgo passing 65 fur rid occupied capacity stake speak rice turns montrose unite rides button following fullyª cherkar mutant [SEP]']
[Init] best perm rec loss: 1.3274400066740004 for ['[CLS] occupied i button following akgo fur passing unite 65 rides mutant rice stake cherkar turns montrose fully speak capacity ridª [SEP]']
[Init] best perm rec loss: 1.3215558131738496 for ['[CLS] speak ak occupied capacity rid montrose i 65 fur ricego fully button passing turns rides stake cher uniteª mutantkar following [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.030 (perp=12.754, rec=0.479), tot_loss_proj:3.462 [t=0.31s]
prediction: ['[CLS] constituency national illegal money infrastructure attack stupid losing barrel guinea tape worm legislature " illegal leaders governmentgo government at dumb use scare [SEP]']
[ 100/2000] tot_loss=2.796 (perp=12.237, rec=0.349), tot_loss_proj:3.336 [t=0.30s]
prediction: ['[CLS] american national response money - attack pointless lost senate foreigners rican or canadiens in illegal farmers councilzi maybepa useless entrancegate [SEP]']
[ 150/2000] tot_loss=2.603 (perp=11.553, rec=0.292), tot_loss_proj:3.173 [t=0.31s]
prediction: ['[CLS] coming national bc network - entirely pointless shed import frenchboarding - import to youngest parties policezi maybepa pointless entrancegate [SEP]']
[ 200/2000] tot_loss=2.528 (perp=11.303, rec=0.268), tot_loss_proj:3.099 [t=0.30s]
prediction: ['[CLS] import national bc network - quite pointless shed import french importusly import totorium parties policezi importswal pointless importgate [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.514 (perp=11.354, rec=0.243), tot_loss_proj:3.130 [t=0.29s]
prediction: ['[CLS] coming national bc network - ) pointless import maybe french importusly import to age parties policeław importswal pointless importeron [SEP]']
[ 300/2000] tot_loss=2.495 (perp=11.367, rec=0.222), tot_loss_proj:3.099 [t=0.31s]
prediction: ['[CLS] coming national bc programme - ) pointless import coming import import sept import by sophie russians policeław importwal pointless importeron [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.548 (perp=11.644, rec=0.219), tot_loss_proj:3.162 [t=0.30s]
prediction: ['[CLS] coming national bc drug and ) french import coming pointless importterol import through sophie russians policeław importwal pointless importpoint [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.342 (perp=10.643, rec=0.214), tot_loss_proj:2.964 [t=0.29s]
prediction: ['[CLS] import ) bc campaign and ) french age coming pointless import sophie analysisusly import through policeław importwal pointless importpoint [SEP]']
[ 450/2000] tot_loss=2.479 (perp=11.464, rec=0.187), tot_loss_proj:3.103 [t=0.30s]
prediction: ['[CLS] this ) bc drug and ) french age coming pointless import sophie translatorusly import through policeław import ha pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.347 (perp=10.902, rec=0.167), tot_loss_proj:2.923 [t=0.29s]
prediction: ['[CLS] from )ing drug and ) french age coming pointless import sophie directorusly import through policemen this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.232 (perp=10.321, rec=0.167), tot_loss_proj:2.830 [t=0.29s]
prediction: ['[CLS] from thising drug and ) french age coming pointless import sophie importusly director through policemen this wo pointless importroller [SEP]']
[ 600/2000] tot_loss=2.287 (perp=10.685, rec=0.150), tot_loss_proj:2.922 [t=0.28s]
prediction: ['[CLS] from thising drug and ) french age coming pointless import sophie importject director through policeław this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.264 (perp=10.594, rec=0.145), tot_loss_proj:2.895 [t=0.31s]
prediction: ['[CLS] from thisingder and ) french age coming pointless import sophie importject directorław police - this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.146 (perp=10.045, rec=0.137), tot_loss_proj:2.804 [t=0.29s]
prediction: ['[CLS] from thising sophie and ) french age coming pointless importder importject directorław police - this wo pointless importroller [SEP]']
[ 750/2000] tot_loss=2.145 (perp=10.045, rec=0.136), tot_loss_proj:2.807 [t=0.28s]
prediction: ['[CLS] from thising sophie and ) french age coming pointless importder importject directorław police - this wo pointless importroller [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.065 (perp=9.679, rec=0.130), tot_loss_proj:2.739 [t=0.30s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - importject directorław director - this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.058 (perp=9.600, rec=0.138), tot_loss_proj:2.710 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - importwal directorław director - thisject pointless importroller [SEP]']
[ 900/2000] tot_loss=2.049 (perp=9.600, rec=0.129), tot_loss_proj:2.713 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - importwal directorław director - thisject pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.982 (perp=9.233, rec=0.135), tot_loss_proj:2.639 [t=0.28s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - import - directorław directorwal thisject pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.053 (perp=9.629, rec=0.127), tot_loss_proj:2.722 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless of - import - directorław directorwalject this pointless importroller [SEP]']
[1050/2000] tot_loss=2.143 (perp=10.141, rec=0.115), tot_loss_proj:2.884 [t=0.30s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless of - import - directorław director nearlyject this pointless importroller [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.044 (perp=9.599, rec=0.124), tot_loss_proj:2.781 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import of - - directorław director nearlyject this pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.022 (perp=9.441, rec=0.134), tot_loss_proj:2.752 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless importł - - director of director nearlyject this pointless importroller [SEP]']
[1200/2000] tot_loss=2.013 (perp=9.441, rec=0.125), tot_loss_proj:2.749 [t=0.25s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless importł - - director of director nearlyject this pointless importroller [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.969 (perp=9.240, rec=0.121), tot_loss_proj:2.727 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of director nearlyject this pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.943 (perp=9.074, rec=0.128), tot_loss_proj:2.652 [t=0.25s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
[1350/2000] tot_loss=1.930 (perp=9.074, rec=0.115), tot_loss_proj:2.654 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=9.074, rec=0.118), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
Attempt swap
[1450/2000] tot_loss=1.934 (perp=9.074, rec=0.119), tot_loss_proj:2.649 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
[1500/2000] tot_loss=1.967 (perp=9.262, rec=0.115), tot_loss_proj:2.711 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this congregationject director pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.932 (perp=9.075, rec=0.117), tot_loss_proj:2.669 [t=0.32s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import -growth director of this congregation - director pointless importroller [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.934 (perp=9.107, rec=0.113), tot_loss_proj:2.650 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directoros of this congregation - director pointless importroller [SEP]']
[1650/2000] tot_loss=1.916 (perp=8.957, rec=0.125), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1700/2000] tot_loss=1.912 (perp=8.957, rec=0.120), tot_loss_proj:2.614 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1750/2000] tot_loss=1.901 (perp=8.957, rec=0.110), tot_loss_proj:2.623 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
[1800/2000] tot_loss=1.908 (perp=8.957, rec=0.117), tot_loss_proj:2.616 [t=0.25s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1850/2000] tot_loss=1.909 (perp=8.957, rec=0.118), tot_loss_proj:2.622 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1900/2000] tot_loss=1.905 (perp=8.957, rec=0.113), tot_loss_proj:2.629 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
[1950/2000] tot_loss=1.904 (perp=8.957, rec=0.113), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[2000/2000] tot_loss=1.897 (perp=8.957, rec=0.105), tot_loss_proj:2.625 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.286 | p: 72.222 | r: 76.471
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 38.889 | r: 41.176
rougeLsum  | fm: 40.000 | p: 38.889 | r: 41.176
r1fm+r2fm = 74.286

[Aggregate metrics]:
rouge1     | fm: 81.534 | p: 80.383 | r: 82.979
rouge2     | fm: 40.382 | p: 40.033 | r: 40.812
rougeL     | fm: 70.545 | p: 69.407 | r: 71.890
rougeLsum  | fm: 70.282 | p: 69.088 | r: 71.655
r1fm+r2fm = 121.916

input #26 time: 0:11:41 | total time: 4:53:00


Running input #27 of 100.
reference: 
========================
are so generic 
========================
cosin similarity: 0.899414383258682 normalized error: 0.48213710503675355
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 1.8601595221254046 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 1.7924729866904148 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 1.7105311767293034 for ['[CLS] and universal universe [SEP]']
[Init] best rec loss: 1.6237242091049946 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 1.4957063567670374 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 1.366203888774431 for ['[CLS] part portion mid [SEP]']
[Init] best rec loss: 1.312832420404023 for ['[CLS] fat mattream [SEP]']
[Init] best rec loss: 1.1867137081966508 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 1.1791401490460158 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.834 (perp=11.918, rec=0.451), tot_loss_proj:3.618 [t=0.24s]
prediction: ['[CLS] hulk hated saddam [SEP]']
[ 100/2000] tot_loss=2.677 (perp=11.939, rec=0.289), tot_loss_proj:3.122 [t=0.25s]
prediction: ['[CLS] extent trap generic [SEP]']
[ 150/2000] tot_loss=1.915 (perp=8.558, rec=0.204), tot_loss_proj:2.162 [t=0.29s]
prediction: ['[CLS] most so generic [SEP]']
[ 200/2000] tot_loss=1.847 (perp=8.320, rec=0.183), tot_loss_proj:1.927 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.825 (perp=8.320, rec=0.161), tot_loss_proj:1.930 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.817 (perp=8.320, rec=0.153), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.804 (perp=8.320, rec=0.140), tot_loss_proj:1.921 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.800 (perp=8.320, rec=0.136), tot_loss_proj:1.919 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.806 (perp=8.320, rec=0.142), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.809 (perp=8.320, rec=0.145), tot_loss_proj:1.933 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.802 (perp=8.320, rec=0.138), tot_loss_proj:1.920 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.795 (perp=8.320, rec=0.131), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.807 (perp=8.320, rec=0.143), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.784 (perp=8.320, rec=0.120), tot_loss_proj:1.913 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.798 (perp=8.320, rec=0.134), tot_loss_proj:1.917 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.791 (perp=8.320, rec=0.127), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.786 (perp=8.320, rec=0.122), tot_loss_proj:1.925 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.789 (perp=8.320, rec=0.125), tot_loss_proj:1.931 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.936 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.801 (perp=8.320, rec=0.137), tot_loss_proj:1.922 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.914 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.800 (perp=8.320, rec=0.136), tot_loss_proj:1.922 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.320, rec=0.124), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.792 (perp=8.320, rec=0.128), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.793 (perp=8.320, rec=0.129), tot_loss_proj:1.935 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.801 (perp=8.320, rec=0.137), tot_loss_proj:1.925 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.798 (perp=8.320, rec=0.134), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.795 (perp=8.320, rec=0.131), tot_loss_proj:1.914 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.786 (perp=8.320, rec=0.122), tot_loss_proj:1.917 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.792 (perp=8.320, rec=0.128), tot_loss_proj:1.918 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.800 (perp=8.320, rec=0.136), tot_loss_proj:1.938 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.320, rec=0.128), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.786 (perp=8.320, rec=0.122), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.784 (perp=8.320, rec=0.120), tot_loss_proj:1.922 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=8.320, rec=0.130), tot_loss_proj:1.918 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.924 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.799 (perp=8.320, rec=0.135), tot_loss_proj:1.918 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.320, rec=0.139), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.281 | p: 81.143 | r: 83.775
rouge2     | fm: 42.393 | p: 42.108 | r: 42.722
rougeL     | fm: 71.556 | p: 70.561 | r: 72.810
rougeLsum  | fm: 71.054 | p: 70.007 | r: 72.381
r1fm+r2fm = 124.674

input #27 time: 0:10:48 | total time: 5:03:48


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
cosin similarity: -0.8963603353465541 normalized error: 1.734303904161745
cosin similarity: 0.8963603353465541 normalized error: 0.5019644046112567
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 1.7238842479734258 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 1.6400437421395921 for ['[CLS] spare blaze following tempo [SEP]']
[Init] best rec loss: 1.5779799094010394 for ['[CLS] boundaries towards lands delivery [SEP]']
[Init] best rec loss: 1.57636484969019 for ['[CLS] medalist de empress wing [SEP]']
[Init] best rec loss: 1.5325416085225378 for ['[CLS] bro asher lit majority [SEP]']
[Init] best rec loss: 1.5284168767216904 for ['[CLS] costs ev rankin airways [SEP]']
[Init] best perm rec loss: 1.5207602268517522 for ['[CLS] ev airways costs rankin [SEP]']
[Init] best perm rec loss: 1.5207221061843765 for ['[CLS] airways ev costs rankin [SEP]']
[Init] best perm rec loss: 1.5195019595003252 for ['[CLS] costs rankin ev airways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.308 (perp=9.823, rec=0.343), tot_loss_proj:2.976 [t=0.28s]
prediction: ['[CLS] only twenty amber minutes [SEP]']
[ 100/2000] tot_loss=2.205 (perp=9.964, rec=0.212), tot_loss_proj:3.064 [t=0.27s]
prediction: ['[CLS] only only amber minutes [SEP]']
[ 150/2000] tot_loss=2.364 (perp=11.000, rec=0.164), tot_loss_proj:3.246 [t=0.29s]
prediction: ['[CLS] for only inhibitor minutes [SEP]']
[ 200/2000] tot_loss=2.016 (perp=9.313, rec=0.153), tot_loss_proj:2.946 [t=0.30s]
prediction: ['[CLS] for 71 bobby minutes [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.002 (perp=9.313, rec=0.139), tot_loss_proj:2.942 [t=0.27s]
prediction: ['[CLS] for 71 bobby minutes [SEP]']
[ 300/2000] tot_loss=1.994 (perp=9.313, rec=0.132), tot_loss_proj:2.936 [t=0.29s]
prediction: ['[CLS] for 71 bobby minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.178 (perp=10.208, rec=0.137), tot_loss_proj:3.024 [t=0.25s]
prediction: ['[CLS] for 71 au minutes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.939 (perp=8.974, rec=0.144), tot_loss_proj:2.779 [t=0.26s]
prediction: ['[CLS] for 71 minutes au [SEP]']
[ 450/2000] tot_loss=2.114 (perp=9.881, rec=0.138), tot_loss_proj:2.947 [t=0.25s]
prediction: ['[CLS] for 71 minutessling [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.982 (perp=9.266, rec=0.129), tot_loss_proj:2.804 [t=0.25s]
prediction: ['[CLS]ʳ for 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.854 (perp=8.655, rec=0.123), tot_loss_proj:3.075 [t=0.25s]
prediction: ['[CLS] hans for 71 minutes [SEP]']
[ 600/2000] tot_loss=1.977 (perp=9.262, rec=0.124), tot_loss_proj:3.106 [t=0.25s]
prediction: ['[CLS]sling for 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.971 (perp=9.262, rec=0.118), tot_loss_proj:3.101 [t=0.27s]
prediction: ['[CLS]sling for 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=9.262, rec=0.116), tot_loss_proj:3.107 [t=0.27s]
prediction: ['[CLS]sling for 71 minutes [SEP]']
[ 750/2000] tot_loss=1.892 (perp=8.844, rec=0.123), tot_loss_proj:3.030 [t=0.25s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.898 (perp=8.844, rec=0.129), tot_loss_proj:3.023 [t=0.27s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=8.844, rec=0.122), tot_loss_proj:3.027 [t=0.25s]
prediction: ['[CLS] au for 71 minutes [SEP]']
[ 900/2000] tot_loss=1.891 (perp=8.844, rec=0.122), tot_loss_proj:3.031 [t=0.25s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.890 (perp=8.844, rec=0.121), tot_loss_proj:3.030 [t=0.24s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.880 (perp=8.844, rec=0.111), tot_loss_proj:3.029 [t=0.24s]
prediction: ['[CLS] au for 71 minutes [SEP]']
[1050/2000] tot_loss=1.890 (perp=8.844, rec=0.121), tot_loss_proj:3.028 [t=0.25s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.902 (perp=8.844, rec=0.133), tot_loss_proj:3.027 [t=0.26s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.893 (perp=8.844, rec=0.124), tot_loss_proj:3.032 [t=0.25s]
prediction: ['[CLS] au for 71 minutes [SEP]']
[1200/2000] tot_loss=1.962 (perp=9.171, rec=0.127), tot_loss_proj:3.023 [t=0.26s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.023 [t=0.26s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.951 (perp=9.171, rec=0.117), tot_loss_proj:3.017 [t=0.26s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1350/2000] tot_loss=1.959 (perp=9.171, rec=0.125), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.967 (perp=9.171, rec=0.132), tot_loss_proj:3.020 [t=0.24s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.964 (perp=9.171, rec=0.130), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1500/2000] tot_loss=1.956 (perp=9.171, rec=0.122), tot_loss_proj:3.016 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.015 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1650/2000] tot_loss=1.955 (perp=9.171, rec=0.121), tot_loss_proj:3.013 [t=0.26s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.949 (perp=9.171, rec=0.114), tot_loss_proj:3.014 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=9.171, rec=0.128), tot_loss_proj:3.013 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1800/2000] tot_loss=1.948 (perp=9.171, rec=0.114), tot_loss_proj:3.019 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.957 (perp=9.171, rec=0.123), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.947 (perp=9.171, rec=0.113), tot_loss_proj:3.014 [t=0.27s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1950/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.019 [t=0.25s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.956 (perp=9.171, rec=0.122), tot_loss_proj:3.016 [t=0.24s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS]sling for 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 82.291 | p: 81.249 | r: 83.680
rouge2     | fm: 42.268 | p: 41.880 | r: 42.673
rougeL     | fm: 72.014 | p: 71.011 | r: 73.328
rougeLsum  | fm: 71.496 | p: 70.435 | r: 72.768
r1fm+r2fm = 124.559

input #28 time: 0:10:56 | total time: 5:14:45


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
cosin similarity: 0.8935402273098988 normalized error: 0.5132934698956766
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 1.8951370295519259 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 1.7573377336300522 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 1.6662746918614864 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 1.6222173997270075 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 1.5402730288861677 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 1.4476836606098127 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 1.3916519224730641 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 1.3752690559401188 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 1.3590884018970015 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 1.3546598883795284 for ['[CLS] landed oil administration taste runs tvuted this envelope engagement [SEP]']
[Init] best perm rec loss: 1.3517942223727615 for ['[CLS] envelope taste landed oil tv runs engagementuted administration this [SEP]']
[Init] best perm rec loss: 1.3467121284205446 for ['[CLS] runs engagement landed tvuted this envelope oil taste administration [SEP]']
[Init] best perm rec loss: 1.3464084648223271 for ['[CLS]uted this taste landed envelope runs engagement administration oil tv [SEP]']
[Init] best perm rec loss: 1.3431373262775121 for ['[CLS] envelope oil taste engagement thisuted landed runs administration tv [SEP]']
[Init] best perm rec loss: 1.3415173260540905 for ['[CLS] taste oil runs engagement tv this envelope landeduted administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.083 (perp=12.918, rec=0.500), tot_loss_proj:4.002 [t=0.28s]
prediction: ['[CLS] popularity natural think engagement tv credits scandal hole avon government [SEP]']
[ 100/2000] tot_loss=2.571 (perp=10.897, rec=0.391), tot_loss_proj:4.058 [t=0.30s]
prediction: ['[CLS] rules natural progress engagement is picture angelica is dire not [SEP]']
[ 150/2000] tot_loss=2.387 (perp=10.162, rec=0.354), tot_loss_proj:3.344 [t=0.28s]
prediction: ['[CLS] believe natural fighting evil is picture angelica is its not [SEP]']
[ 200/2000] tot_loss=2.222 (perp=9.604, rec=0.301), tot_loss_proj:3.080 [t=0.28s]
prediction: ['[CLS] believe natural reportedly evil is it endangered is its not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.141 (perp=9.473, rec=0.247), tot_loss_proj:3.109 [t=0.28s]
prediction: ['[CLS] probably believe innocent evil is it endangered is is not [SEP]']
[ 300/2000] tot_loss=1.934 (perp=8.675, rec=0.199), tot_loss_proj:2.997 [t=0.29s]
prediction: ['[CLS] considered believe innocent evil is it evil is is not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.097 (perp=9.522, rec=0.193), tot_loss_proj:3.143 [t=0.28s]
prediction: ['[CLS] considered cold believe surface resident it resident is is not [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.147 (perp=9.869, rec=0.173), tot_loss_proj:3.127 [t=0.29s]
prediction: ['[CLS] considered cold believe abby evil is resident it is not [SEP]']
[ 450/2000] tot_loss=2.320 (perp=10.819, rec=0.156), tot_loss_proj:3.424 [t=0.28s]
prediction: ['[CLS] consider sentinel believe abby evil that resident it is not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.968 (perp=8.945, rec=0.179), tot_loss_proj:2.953 [t=0.28s]
prediction: ['[CLS] consider resident believe resident evil that surface it is not [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.752 (perp=7.944, rec=0.163), tot_loss_proj:2.621 [t=0.28s]
prediction: ['[CLS] consider resident believe resident evil that it is not surface [SEP]']
[ 600/2000] tot_loss=1.750 (perp=7.944, rec=0.161), tot_loss_proj:2.620 [t=0.29s]
prediction: ['[CLS] consider resident believe resident evil that it is not surface [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.711 (perp=7.708, rec=0.169), tot_loss_proj:2.482 [t=0.30s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.692 (perp=7.708, rec=0.150), tot_loss_proj:2.480 [t=0.29s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
[ 750/2000] tot_loss=1.698 (perp=7.708, rec=0.156), tot_loss_proj:2.478 [t=0.29s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.695 (perp=7.708, rec=0.153), tot_loss_proj:2.480 [t=0.29s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.678 (perp=7.708, rec=0.136), tot_loss_proj:2.480 [t=0.28s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
[ 900/2000] tot_loss=1.678 (perp=7.708, rec=0.136), tot_loss_proj:2.485 [t=0.29s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=7.708, rec=0.146), tot_loss_proj:2.484 [t=0.29s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=7.708, rec=0.137), tot_loss_proj:2.483 [t=0.31s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.248, rec=0.132), tot_loss_proj:2.365 [t=0.30s]
prediction: ['[CLS] i resident believe that resident evil it is not surface [SEP]']
Attempt swap
[1100/2000] tot_loss=1.584 (perp=7.248, rec=0.134), tot_loss_proj:2.366 [t=0.28s]
prediction: ['[CLS] i resident believe that resident evil it is not surface [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.508 (perp=6.815, rec=0.145), tot_loss_proj:2.245 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil it is not surface [SEP]']
[1200/2000] tot_loss=1.504 (perp=6.815, rec=0.141), tot_loss_proj:2.247 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil it is not surface [SEP]']
Attempt swap
[1250/2000] tot_loss=1.496 (perp=6.815, rec=0.133), tot_loss_proj:2.245 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil it is not surface [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.445 (perp=6.531, rec=0.139), tot_loss_proj:2.402 [t=0.31s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1350/2000] tot_loss=1.438 (perp=6.531, rec=0.132), tot_loss_proj:2.396 [t=0.30s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1400/2000] tot_loss=1.441 (perp=6.531, rec=0.135), tot_loss_proj:2.396 [t=0.28s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1450/2000] tot_loss=1.442 (perp=6.531, rec=0.136), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1500/2000] tot_loss=1.438 (perp=6.531, rec=0.131), tot_loss_proj:2.400 [t=0.30s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1550/2000] tot_loss=1.442 (perp=6.531, rec=0.136), tot_loss_proj:2.392 [t=0.30s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1600/2000] tot_loss=1.430 (perp=6.531, rec=0.124), tot_loss_proj:2.398 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1650/2000] tot_loss=1.430 (perp=6.531, rec=0.124), tot_loss_proj:2.395 [t=0.30s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1700/2000] tot_loss=1.435 (perp=6.531, rec=0.129), tot_loss_proj:2.398 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1750/2000] tot_loss=1.434 (perp=6.531, rec=0.128), tot_loss_proj:2.400 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1800/2000] tot_loss=1.440 (perp=6.531, rec=0.134), tot_loss_proj:2.395 [t=0.28s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.531, rec=0.126), tot_loss_proj:2.398 [t=0.36s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1900/2000] tot_loss=1.432 (perp=6.531, rec=0.126), tot_loss_proj:2.396 [t=0.28s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1950/2000] tot_loss=1.430 (perp=6.531, rec=0.124), tot_loss_proj:2.403 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[2000/2000] tot_loss=1.434 (perp=6.531, rec=0.128), tot_loss_proj:2.397 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe that resident resident evil is it not surface [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 134.576

[Aggregate metrics]:
rouge1     | fm: 82.472 | p: 81.314 | r: 83.979
rouge2     | fm: 42.776 | p: 42.400 | r: 43.337
rougeL     | fm: 72.311 | p: 71.208 | r: 73.600
rougeLsum  | fm: 72.024 | p: 70.859 | r: 73.404
r1fm+r2fm = 125.248

input #29 time: 0:12:13 | total time: 5:26:58


Running input #30 of 100.
reference: 
========================
fizzability 
========================
cosin similarity: -0.7819535962479063 normalized error: 1.6731907553169267
cosin similarity: 0.7819535962479063 normalized error: 0.5738673088944698
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9207770228385925 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.7793105840682983 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7627937197685242 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7625120878219604 for ['[CLS] laws gp. [SEP]']
[Init] best rec loss: 0.7374953031539917 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 0.7038500308990479 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.676681637763977 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.6746949553489685 for ['[CLS] lizard acceleration council [SEP]']
[Init] best perm rec loss: 0.6745884418487549 for ['[CLS] council lizard acceleration [SEP]']
[Init] best perm rec loss: 0.670194685459137 for ['[CLS] acceleration lizard council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.744 (perp=12.475, rec=0.249), tot_loss_proj:3.000 [t=0.28s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 100/2000] tot_loss=2.398 (perp=11.223, rec=0.154), tot_loss_proj:2.656 [t=0.31s]
prediction: ['[CLS]zzazzability [SEP]']
[ 150/2000] tot_loss=1.989 (perp=9.539, rec=0.081), tot_loss_proj:1.984 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=1.985 (perp=9.539, rec=0.077), tot_loss_proj:1.979 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.978 (perp=9.539, rec=0.070), tot_loss_proj:1.982 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.982 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.977 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.539, rec=0.060), tot_loss_proj:1.971 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.967 (perp=9.539, rec=0.059), tot_loss_proj:1.987 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.951 (perp=9.539, rec=0.043), tot_loss_proj:1.972 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.974 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.963 (perp=9.539, rec=0.055), tot_loss_proj:1.978 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.978 (perp=9.539, rec=0.071), tot_loss_proj:1.973 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=9.539, rec=0.065), tot_loss_proj:1.970 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.955 (perp=9.539, rec=0.047), tot_loss_proj:1.988 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.990 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.981 (perp=9.539, rec=0.074), tot_loss_proj:1.967 [t=0.31s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.964 (perp=9.539, rec=0.056), tot_loss_proj:1.974 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.977 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.962 (perp=9.539, rec=0.054), tot_loss_proj:1.964 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.968 (perp=9.539, rec=0.060), tot_loss_proj:1.969 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.966 (perp=9.539, rec=0.058), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.985 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.961 (perp=9.539, rec=0.053), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.962 (perp=9.539, rec=0.054), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.952 (perp=9.539, rec=0.044), tot_loss_proj:1.986 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.981 (perp=9.539, rec=0.073), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.966 (perp=9.539, rec=0.058), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.975 (perp=9.539, rec=0.068), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.976 (perp=9.539, rec=0.068), tot_loss_proj:1.987 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.976 (perp=9.539, rec=0.068), tot_loss_proj:1.985 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.977 (perp=9.539, rec=0.070), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.980 (perp=9.539, rec=0.072), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.979 (perp=9.539, rec=0.071), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.972 (perp=9.539, rec=0.064), tot_loss_proj:1.981 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.972 (perp=9.539, rec=0.064), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.963 (perp=9.539, rec=0.055), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.968 (perp=9.539, rec=0.060), tot_loss_proj:1.978 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.018 | p: 81.911 | r: 84.392
rouge2     | fm: 44.660 | p: 44.359 | r: 45.101
rougeL     | fm: 73.251 | p: 72.116 | r: 74.451
rougeLsum  | fm: 72.676 | p: 71.594 | r: 73.963
r1fm+r2fm = 127.678

input #30 time: 0:11:32 | total time: 5:38:31


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
cosin similarity: 0.8972750712825893 normalized error: 0.5145268960711955
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 1.9773721288501558 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 1.9019158403876166 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 1.8086576336662248 for ['[CLS] che episode band [SEP]']
[Init] best rec loss: 1.6337636516907696 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 1.606473108711593 for ['[CLS] seeing cat retrieved [SEP]']
[Init] best perm rec loss: 1.6009026623141054 for ['[CLS] retrieved cat seeing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.515 (perp=10.330, rec=0.449), tot_loss_proj:3.321 [t=0.28s]
prediction: ['[CLS] a truck better [SEP]']
[ 100/2000] tot_loss=2.267 (perp=9.889, rec=0.289), tot_loss_proj:2.898 [t=0.29s]
prediction: ['[CLS] a vehicle better [SEP]']
[ 150/2000] tot_loss=2.204 (perp=9.889, rec=0.226), tot_loss_proj:2.913 [t=0.28s]
prediction: ['[CLS] a vehicle better [SEP]']
[ 200/2000] tot_loss=2.195 (perp=9.889, rec=0.218), tot_loss_proj:2.910 [t=0.29s]
prediction: ['[CLS] a vehicle better [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.726 (perp=7.603, rec=0.206), tot_loss_proj:1.985 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.717 (perp=7.603, rec=0.196), tot_loss_proj:1.968 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.701 (perp=7.603, rec=0.181), tot_loss_proj:1.972 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.697 (perp=7.603, rec=0.177), tot_loss_proj:1.987 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.691 (perp=7.603, rec=0.170), tot_loss_proj:1.976 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.714 (perp=7.603, rec=0.193), tot_loss_proj:1.982 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.697 (perp=7.603, rec=0.177), tot_loss_proj:1.974 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.695 (perp=7.603, rec=0.174), tot_loss_proj:1.973 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.708 (perp=7.603, rec=0.187), tot_loss_proj:1.973 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.692 (perp=7.603, rec=0.172), tot_loss_proj:1.964 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.703 (perp=7.603, rec=0.182), tot_loss_proj:1.971 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.980 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.702 (perp=7.603, rec=0.181), tot_loss_proj:1.981 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.684 (perp=7.603, rec=0.163), tot_loss_proj:1.986 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.700 (perp=7.603, rec=0.180), tot_loss_proj:1.955 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=7.603, rec=0.180), tot_loss_proj:1.980 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.972 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.700 (perp=7.603, rec=0.179), tot_loss_proj:1.973 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.691 (perp=7.603, rec=0.171), tot_loss_proj:1.984 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.981 [t=0.31s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.687 (perp=7.603, rec=0.167), tot_loss_proj:1.978 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.683 (perp=7.603, rec=0.163), tot_loss_proj:1.967 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.686 (perp=7.603, rec=0.165), tot_loss_proj:1.967 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.690 (perp=7.603, rec=0.170), tot_loss_proj:1.978 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.691 (perp=7.603, rec=0.171), tot_loss_proj:1.975 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.694 (perp=7.603, rec=0.173), tot_loss_proj:1.990 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.686 (perp=7.603, rec=0.165), tot_loss_proj:1.977 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.695 (perp=7.603, rec=0.174), tot_loss_proj:1.975 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.694 (perp=7.603, rec=0.174), tot_loss_proj:1.984 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.687 (perp=7.603, rec=0.166), tot_loss_proj:1.979 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.694 (perp=7.603, rec=0.173), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.691 (perp=7.603, rec=0.171), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.687 (perp=7.603, rec=0.166), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.697 (perp=7.603, rec=0.176), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.688 (perp=7.603, rec=0.168), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.676 | p: 82.517 | r: 85.013
rouge2     | fm: 46.390 | p: 45.930 | r: 46.736
rougeL     | fm: 74.009 | p: 73.017 | r: 75.260
rougeLsum  | fm: 73.719 | p: 72.661 | r: 75.070
r1fm+r2fm = 130.065

input #31 time: 0:11:59 | total time: 5:50:30


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
cosin similarity: 0.9540072499327329 normalized error: 0.4076547528751486
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.9211081790519218 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 1.76629793519009 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 1.7226820069981001 for ['[CLS] everywhere commission positively galaxy wasted dish engine maine linear finn hit circulated [SEP]']
[Init] best rec loss: 1.6831346488369228 for ['[CLS] particular usual lana rid part awaitfication felt worked bolt algorithm tristan [SEP]']
[Init] best perm rec loss: 1.68248123028659 for ['[CLS] algorithm feltfication particular lana rid part await bolt worked tristan usual [SEP]']
[Init] best perm rec loss: 1.680588822278398 for ['[CLS] algorithmfication await usual tristan lana rid felt worked bolt part particular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.547 (perp=10.908, rec=0.365), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] expand photographer light narrative technology easily wise feeled a energy resource [SEP]']
[ 100/2000] tot_loss=2.664 (perp=11.853, rec=0.293), tot_loss_proj:3.706 [t=0.25s]
prediction: ['[CLS] pull rico salon stories story easily accessible feelotide prime easily available [SEP]']
[ 150/2000] tot_loss=2.682 (perp=12.318, rec=0.218), tot_loss_proj:4.283 [t=0.26s]
prediction: ['[CLS] pullund accessible stories stories easily accessibleonateulatedund easily together [SEP]']
[ 200/2000] tot_loss=2.737 (perp=12.740, rec=0.189), tot_loss_proj:4.423 [t=0.27s]
prediction: ["[CLS] pullund accessible' stories easily accessibleonateulatedund easily together [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.746 (perp=12.939, rec=0.158), tot_loss_proj:3.722 [t=0.26s]
prediction: ['[CLS] pullonate accessibleulously stories easily togetheronate prof profund that [SEP]']
[ 300/2000] tot_loss=2.781 (perp=13.162, rec=0.149), tot_loss_proj:3.727 [t=0.25s]
prediction: ['[CLS] pullonate accessiblesities stories easily togetheronate prof profund that [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.596 (perp=12.309, rec=0.134), tot_loss_proj:3.561 [t=0.26s]
prediction: ['[CLS] pullonate accessiblesities stories easily together profonate profund that [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.389 (perp=11.196, rec=0.150), tot_loss_proj:3.243 [t=0.24s]
prediction: ['[CLS] pullonate accessiblecasedonate easily together with stories profund that [SEP]']
[ 450/2000] tot_loss=2.312 (perp=10.922, rec=0.128), tot_loss_proj:3.228 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurityonate easily together with stories profund that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.105 (perp=9.901, rec=0.125), tot_loss_proj:3.002 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurityity easily together with stories that profund [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.092 (perp=9.901, rec=0.112), tot_loss_proj:3.001 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurityity easily together with stories that profund [SEP]']
[ 600/2000] tot_loss=2.098 (perp=9.901, rec=0.118), tot_loss_proj:3.002 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurityity easily together with stories that profund [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.939 (perp=9.177, rec=0.104), tot_loss_proj:2.711 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.945 (perp=9.177, rec=0.109), tot_loss_proj:2.724 [t=0.24s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
[ 750/2000] tot_loss=1.942 (perp=9.177, rec=0.106), tot_loss_proj:2.718 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.939 (perp=9.177, rec=0.104), tot_loss_proj:2.711 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.943 (perp=9.177, rec=0.107), tot_loss_proj:2.718 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
[ 900/2000] tot_loss=1.935 (perp=9.177, rec=0.100), tot_loss_proj:2.723 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.864 (perp=8.742, rec=0.115), tot_loss_proj:2.677 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.850 (perp=8.742, rec=0.101), tot_loss_proj:2.686 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1050/2000] tot_loss=1.848 (perp=8.742, rec=0.099), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.846 (perp=8.742, rec=0.098), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.857 (perp=8.742, rec=0.108), tot_loss_proj:2.671 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1200/2000] tot_loss=1.847 (perp=8.742, rec=0.099), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.847 (perp=8.742, rec=0.099), tot_loss_proj:2.674 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.839 (perp=8.742, rec=0.090), tot_loss_proj:2.682 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1350/2000] tot_loss=1.853 (perp=8.742, rec=0.104), tot_loss_proj:2.680 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.848 (perp=8.742, rec=0.099), tot_loss_proj:2.676 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.850 (perp=8.742, rec=0.102), tot_loss_proj:2.681 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1500/2000] tot_loss=1.859 (perp=8.742, rec=0.111), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.845 (perp=8.742, rec=0.097), tot_loss_proj:2.681 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.859 (perp=8.742, rec=0.111), tot_loss_proj:2.676 [t=0.24s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1650/2000] tot_loss=1.856 (perp=8.742, rec=0.108), tot_loss_proj:2.676 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.849 (perp=8.742, rec=0.101), tot_loss_proj:2.682 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.851 (perp=8.742, rec=0.103), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1800/2000] tot_loss=1.849 (perp=8.742, rec=0.101), tot_loss_proj:2.675 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.842 (perp=8.742, rec=0.093), tot_loss_proj:2.676 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.855 (perp=8.742, rec=0.107), tot_loss_proj:2.679 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1950/2000] tot_loss=1.847 (perp=8.742, rec=0.098), tot_loss_proj:2.670 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.851 (perp=8.742, rec=0.103), tot_loss_proj:2.674 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 31.579 | p: 33.333 | r: 30.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 107.769

[Aggregate metrics]:
rouge1     | fm: 83.288 | p: 82.379 | r: 84.567
rouge2     | fm: 45.763 | p: 45.421 | r: 46.267
rougeL     | fm: 73.509 | p: 72.585 | r: 74.629
rougeLsum  | fm: 73.107 | p: 72.249 | r: 74.313
r1fm+r2fm = 129.050

input #32 time: 0:10:45 | total time: 6:01:16


Running input #33 of 100.
reference: 
========================
higher 
========================
cosin similarity: 0.7986250644135383 normalized error: 0.5468308574685831
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9893083572387695 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9107549786567688 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8910643458366394 for ['[CLS] bar [SEP]']
[Init] best rec loss: 0.8839766383171082 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.8669291734695435 for ['[CLS] charged [SEP]']
[Init] best rec loss: 0.8415970206260681 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.8240987062454224 for ['[CLS] higher [SEP]']
[Init] best rec loss: 0.8214564919471741 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7940399646759033 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7562564015388489 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.7383552193641663 for ['[CLS] states [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.341 (perp=11.231, rec=0.095), tot_loss_proj:2.644 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.311 (perp=11.231, rec=0.065), tot_loss_proj:2.508 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.314 (perp=11.231, rec=0.068), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.310 (perp=11.231, rec=0.063), tot_loss_proj:2.507 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.481 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.290 (perp=11.231, rec=0.044), tot_loss_proj:2.488 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=11.231, rec=0.059), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.320 (perp=11.231, rec=0.074), tot_loss_proj:2.489 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.297 (perp=11.231, rec=0.051), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.301 (perp=11.231, rec=0.055), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.316 (perp=11.231, rec=0.069), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.314 (perp=11.231, rec=0.068), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.316 (perp=11.231, rec=0.069), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.310 (perp=11.231, rec=0.064), tot_loss_proj:2.480 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.303 (perp=11.231, rec=0.056), tot_loss_proj:2.484 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.300 (perp=11.231, rec=0.053), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.296 (perp=11.231, rec=0.050), tot_loss_proj:2.494 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.292 (perp=11.231, rec=0.046), tot_loss_proj:2.493 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.309 (perp=11.231, rec=0.063), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.290 (perp=11.231, rec=0.044), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.294 (perp=11.231, rec=0.048), tot_loss_proj:2.488 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.475 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.311 (perp=11.231, rec=0.065), tot_loss_proj:2.483 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.295 (perp=11.231, rec=0.049), tot_loss_proj:2.470 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.306 (perp=11.231, rec=0.060), tot_loss_proj:2.493 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.305 (perp=11.231, rec=0.059), tot_loss_proj:2.482 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.298 (perp=11.231, rec=0.052), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.318 (perp=11.231, rec=0.072), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.318 (perp=11.231, rec=0.072), tot_loss_proj:2.483 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.491 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.293 (perp=11.231, rec=0.047), tot_loss_proj:2.486 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.292 (perp=11.231, rec=0.046), tot_loss_proj:2.490 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.492 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.303 (perp=11.231, rec=0.057), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.485 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.319 (perp=11.231, rec=0.073), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.307 (perp=11.231, rec=0.061), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.308 (perp=11.231, rec=0.062), tot_loss_proj:2.493 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.301 (perp=11.231, rec=0.055), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.303 (perp=11.231, rec=0.057), tot_loss_proj:2.480 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.733 | p: 82.805 | r: 84.869
rouge2     | fm: 47.149 | p: 46.814 | r: 47.566
rougeL     | fm: 74.112 | p: 73.324 | r: 75.217
rougeLsum  | fm: 73.952 | p: 73.060 | r: 75.127
r1fm+r2fm = 130.882

input #33 time: 0:10:40 | total time: 6:11:57


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
cosin similarity: 0.8932598797628633 normalized error: 0.4609634765779029
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 1.8985526754050652 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 1.8872557456999548 for ['[CLS] mistress quality security throughout trunkught warning age marketing experiments despite bug travel [SEP]']
[Init] best rec loss: 1.8520096380894422 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 1.7836559245382833 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 1.758405871443009 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 1.7522172888231147 for ['[CLS] marks reflected beat projects plus respectively labradortila columbus estate customs whose marie [SEP]']
[Init] best rec loss: 1.7449057415668872 for ['[CLS] crumbling early?8 naturally episode judah financing highlight ness ford industrystorm [SEP]']
[Init] best rec loss: 1.7406904364769407 for ['[CLS] bangladesh park rival range direct alain desert early best secretsies manitical [SEP]']
[Init] best rec loss: 1.7235494299407326 for ['[CLS] laurel hung encouragement blurred quiz originally orient rather bentci sen ethiopian belmont [SEP]']
[Init] best rec loss: 1.522639053364564 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best rec loss: 1.4833163507243858 for ['[CLS] marie grammar blasted furrowed clyde splash still to caps chief failed impact level [SEP]']
[Init] best perm rec loss: 1.4696467025467284 for ['[CLS] chief caps furrowed impact still blasted grammar failed splash marie clyde to level [SEP]']
[Init] best perm rec loss: 1.4658515403071852 for ['[CLS] impact caps to marie clyde splash blasted still level grammar failed furrowed chief [SEP]']
[Init] best perm rec loss: 1.464656491326015 for ['[CLS] blasted level clyde to impact still marie splash failed grammar chief furrowed caps [SEP]']
[Init] best perm rec loss: 1.4635636998781716 for ['[CLS] still marie furrowed splash failed impact level blasted grammar chief clyde caps to [SEP]']
[Init] best perm rec loss: 1.4633178352098635 for ['[CLS] caps grammar to level furrowed impact blasted splash failed clyde chief still marie [SEP]']
[Init] best perm rec loss: 1.462763524598953 for ['[CLS] caps to grammar splash furrowed marie clyde level still blasted chief failed impact [SEP]']
[Init] best perm rec loss: 1.4619063578860712 for ['[CLS] marie to clyde still splash grammar blasted failed furrowed impact level chief caps [SEP]']
[Init] best perm rec loss: 1.4611379717454729 for ['[CLS] furrowed marie still clyde splash blasted failed level chief impact grammar caps to [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.109 (perp=13.574, rec=0.394), tot_loss_proj:3.917 [t=0.26s]
prediction: ['[CLS] domain would places urgency the audience 2002 accessible geographicage v8 gender understand [SEP]']
[ 100/2000] tot_loss=2.499 (perp=11.077, rec=0.284), tot_loss_proj:3.470 [t=0.25s]
prediction: ['[CLS] build would viewer urgency the viewersphere extreme roads immediate take. urgency [SEP]']
[ 150/2000] tot_loss=2.578 (perp=11.613, rec=0.255), tot_loss_proj:3.567 [t=0.25s]
prediction: ['[CLS] buildic population urgency the viewersphere extreme edges immediate take. urgency [SEP]']
[ 200/2000] tot_loss=2.402 (perp=11.009, rec=0.200), tot_loss_proj:3.161 [t=0.25s]
prediction: ['[CLS] build on build urgency the viewersphere extreme amazing extreme take. urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.213 (perp=10.138, rec=0.185), tot_loss_proj:2.930 [t=0.25s]
prediction: ['[CLS] build on build urgency the viewersphere extreme gems. take extreme urgency [SEP]']
[ 300/2000] tot_loss=2.331 (perp=10.868, rec=0.158), tot_loss_proj:3.006 [t=0.26s]
prediction: ['[CLS] build in synthesis urgency the viewersphere extreme gems. take extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.011 (perp=9.330, rec=0.145), tot_loss_proj:2.750 [t=0.25s]
prediction: ['[CLS] build in mind gems the viewersphere extreme urgency. take extreme urgency [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.960 (perp=8.838, rec=0.193), tot_loss_proj:2.692 [t=0.25s]
prediction: ['[CLS] build in mind gems the viewer kn urgency. take on extreme urgency [SEP]']
[ 450/2000] tot_loss=1.934 (perp=8.920, rec=0.150), tot_loss_proj:2.940 [t=0.26s]
prediction: ['[CLS] build in mind segments the viewer kn urgency. take on extreme urgency [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.911 (perp=8.838, rec=0.143), tot_loss_proj:2.692 [t=0.28s]
prediction: ['[CLS] build in mind gems the viewer kn urgency. take on extreme urgency [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.836 (perp=8.503, rec=0.135), tot_loss_proj:2.654 [t=0.28s]
prediction: ['[CLS] build in mind gems the viewer kn urgency take on extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.886 (perp=8.809, rec=0.125), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] build in mind kelly the viewer kn urgency take on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.883 (perp=8.807, rec=0.121), tot_loss_proj:2.770 [t=0.25s]
prediction: ['[CLS] build in mind and kelly viewer kn urgency take on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.803 (perp=8.392, rec=0.124), tot_loss_proj:2.677 [t=0.26s]
prediction: ['[CLS] build in mind and kn kelly viewer urgency take on extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.392, rec=0.118), tot_loss_proj:2.681 [t=0.27s]
prediction: ['[CLS] build in mind and kn kelly viewer urgency take on extreme urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.790 (perp=8.392, rec=0.111), tot_loss_proj:2.691 [t=0.26s]
prediction: ['[CLS] build in mind and kn kelly viewer urgency take on extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.725 (perp=8.054, rec=0.115), tot_loss_proj:2.525 [t=0.28s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.054, rec=0.110), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.727 (perp=8.054, rec=0.116), tot_loss_proj:2.531 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.719 (perp=8.054, rec=0.108), tot_loss_proj:2.520 [t=0.27s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.054, rec=0.091), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.719 (perp=8.054, rec=0.108), tot_loss_proj:2.528 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.717 (perp=8.054, rec=0.106), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
[1200/2000] tot_loss=1.720 (perp=8.054, rec=0.109), tot_loss_proj:2.524 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.722 (perp=8.054, rec=0.111), tot_loss_proj:2.526 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.717 (perp=8.096, rec=0.098), tot_loss_proj:2.572 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn mind take on extreme urgency. [SEP]']
[1350/2000] tot_loss=1.734 (perp=8.130, rec=0.108), tot_loss_proj:3.226 [t=0.28s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.728 (perp=8.130, rec=0.102), tot_loss_proj:3.218 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.724 (perp=8.130, rec=0.098), tot_loss_proj:3.215 [t=0.25s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1500/2000] tot_loss=1.730 (perp=8.130, rec=0.104), tot_loss_proj:3.215 [t=0.25s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=8.130, rec=0.104), tot_loss_proj:3.215 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.736 (perp=8.130, rec=0.110), tot_loss_proj:3.218 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1650/2000] tot_loss=1.725 (perp=8.130, rec=0.099), tot_loss_proj:3.222 [t=0.25s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.727 (perp=8.130, rec=0.101), tot_loss_proj:3.216 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.733 (perp=8.130, rec=0.107), tot_loss_proj:3.214 [t=0.25s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1800/2000] tot_loss=1.735 (perp=8.130, rec=0.109), tot_loss_proj:3.214 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.733 (perp=8.130, rec=0.107), tot_loss_proj:3.216 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=8.130, rec=0.109), tot_loss_proj:3.218 [t=0.25s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1950/2000] tot_loss=1.726 (perp=8.130, rec=0.100), tot_loss_proj:3.221 [t=0.24s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.729 (perp=8.130, rec=0.103), tot_loss_proj:3.216 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 53.846 | p: 53.846 | r: 53.846
rougeL     | fm: 78.571 | p: 78.571 | r: 78.571
rougeLsum  | fm: 78.571 | p: 78.571 | r: 78.571
r1fm+r2fm = 132.418

[Aggregate metrics]:
rouge1     | fm: 83.597 | p: 82.721 | r: 84.706
rouge2     | fm: 47.620 | p: 47.299 | r: 48.091
rougeL     | fm: 74.407 | p: 73.599 | r: 75.482
rougeLsum  | fm: 74.232 | p: 73.306 | r: 75.417
r1fm+r2fm = 131.216

input #34 time: 0:10:50 | total time: 6:22:47


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
cosin similarity: -0.9503733723742178 normalized error: 1.8923842993852011
cosin similarity: 0.9503733723742178 normalized error: 0.4112299561920301
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 1.9072460417616242 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 1.8966094508046802 for ['[CLS]end title seasons saysbib castle terror hand dear gu source woodland sport sheriff foughthala displacement plate wandered person spin lips constitution know tv callffed hahnply romeo automobiles door godfrey dearathi named wall why committee must efforts your [SEP]']
[Init] best rec loss: 1.852261241139072 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 1.8248313076065121 for ['[CLS] interview effectiveness hum saliva ring mao cheerleading aim respond medicine pointliftland lost happening gap placement solomon gertrude fabric four hair byte aimed ogden trains gnu beside jo tight spoke millionsᵢ folded girls halls man trail drawnvc rule authorities [SEP]']
[Init] best rec loss: 1.7643657672491058 for ["[CLS]bard boardless seed list arizona orders track be england lamb video name deep candy mont already nebraska offerings trained promise science last makeup qualifier ir lidciency about usesbrook'tag indefinitely grimes dress 2002 whether offerings design spear career [SEP]"]
[Init] best rec loss: 1.737547352247155 for ['[CLS]usionpm seeking tango casino over digital runway church radio cells an rom going endemicrted did penalty craft chance master no words [CLS] treatment bed caliphate quantum destination bladed down optical interested obvious rang recentguard hall theatre ballettt do [SEP]']
[Init] best rec loss: 1.6860270106594792 for ['[CLS] mi " therefore zev ms hays bun welles start pierce aquino interce specific causedpo normal texas often vocals secretaries themselves magic night court cesar stages achilles excellent fixed shi bertie leg rows plant alwaysch beijing futuretral young wall [SEP]']
[Init] best perm rec loss: 1.6827829914648578 for ['[CLS] future stages shi plant beijing often welles secretaries alwaysce bertie themselves excellent zev inter caused fixed achilles bun night specific mi rows hayspo aquinochtral leg normal therefore magic texas court wall ms " start young vocals cesar pierce [SEP]']
[Init] best perm rec loss: 1.6824930190927003 for ['[CLS] secretaries young fixed bun normal caused plant texaspo start excellenttral stages themselves court vocals beijing inter aquino pierce future always bertie shi night specific ms often " zev magic wallch therefore haysce rows cesar achilles mi leg welles [SEP]']
[Init] best perm rec loss: 1.681297142838472 for ['[CLS] welles court caused magic pierce mstral night vocals start therefore plant achilles shi zev specific bertie young beijing stages normalce texas wall cesar " mi legpo future fixed always interch rows themselves secretaries often hays aquino excellent bun [SEP]']
[Init] best perm rec loss: 1.6802185073922424 for ['[CLS] stages pierce often excellent ms normal specific hays fixed rows mipotral plant vocals achillesch young shi bun bertie therefore beijingce court " caused aquino magic night start inter themselves future cesar welles wall zev always texas leg secretaries [SEP]']
[Init] best perm rec loss: 1.6793486171160272 for ['[CLS] aquino excellent causedtral magicpo cesar always pierce bertie mi often start stages plantce night leg themselves specific " court secretariesch welles young zev ms inter shi texas bun hays achilles beijing fixed vocals future wall normal rows therefore [SEP]']
[Init] best perm rec loss: 1.6774741067481385 for ['[CLS] texas bertie mi stages shich often beijingce fixed bun secretaries pierce plant young specific rows aquino hays zev always cesar excellent therefore wall normal welles inter " future causedtral vocals magic night court themselves ms achilles startpo leg [SEP]']
[Init] best perm rec loss: 1.6774293348030225 for ['[CLS] wall achilles rows excellent secretariespo legch cesar hays zev fixed normalce court pierce ms bun night specific stages welles mi start beijing plant therefore inter magic vocals bertie future shi caused young oftentral texas aquino " themselves always [SEP]']
[Init] best perm rec loss: 1.6753105187579787 for ['[CLS] future hays shi cesartral specific zev start stages normal therefore fixed young themselves pierce mich caused nightce wall welles vocals secretaries excellent inter magicpo plant aquino achilles rows texas " always bertie ms beijing court often leg bun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.880 (perp=12.316, rec=0.417), tot_loss_proj:3.458 [t=0.25s]
prediction: ['[CLS] regional longest reception elevation fast roy unexpected sons wonder contemporary involved river greateyden south riley riley buddha around directors curator connection, amazing of historicalcion translated of world director necessary in 2010 firm intoivating completely taylor taylor another [SEP]']
[ 100/2000] tot_loss=2.447 (perp=10.556, rec=0.336), tot_loss_proj:3.447 [t=0.25s]
prediction: ['[CLS] personales book meaning : roy : hitleratory contemporary their river greatest roadire roy campus riley about seen, curator line, unique of greatcion translated about van daughter speak of greatest teacher care approximately really taylor taylor. [SEP]']
[ 150/2000] tot_loss=2.487 (perp=10.934, rec=0.300), tot_loss_proj:3.919 [t=0.27s]
prediction: ["[CLS] theired specialistˈ, paul or hitlertment the their lines great road ofpine previously rileynation ', director matter, good of greatest properties identity about van martyr speak from greatest teacher care approximately completely taylor taylor. [SEP]"]
[ 200/2000] tot_loss=2.299 (perp=10.116, rec=0.276), tot_loss_proj:3.192 [t=0.26s]
prediction: ["[CLS] theyed specialister which marguerite wenation discipline the their of great road but sawyer apparently (nation ', teacher matter, amazing of greatestations gift about makes rein speak from our teacher care about just teacher taylor. [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.287 (perp=9.956, rec=0.295), tot_loss_proj:3.057 [t=0.25s]
prediction: ["[CLS] we follow specialist johnson, marguerite wenation discipline the its'great road but hoffman apparently (nationbus, research in us excellent feature greatest things gift about rein rein of from your teacher care about because teacher latest. [SEP]"]
[ 300/2000] tot_loss=2.384 (perp=10.691, rec=0.246), tot_loss_proj:3.073 [t=0.26s]
prediction: ["[CLS] theed successful johnson full hire wenation discipline! its'greatest man, hoffman tampa (nationbus, teacher in us amazing visual greatest things helping about rein rein of of your teacher care about because teacher latest. [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.771 (perp=10.045, rec=0.762), tot_loss_proj:2.976 [t=0.25s]
prediction: ['[CLS] i,. feel. greg history community affair ‖ to being logan address. culture science is environmental aspects of director. us balanced discovery plant has makes about director article she [SEP] our teacher care about cedar highlighted 2011. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.512 (perp=9.109, rec=0.690), tot_loss_proj:2.821 [t=0.26s]
prediction: ['[CLS] i,. feel. greg makes communityrgeon ‖ to being award address. culture science is environmental aspects of science ) us balanced discovery plant and history about director article was the our teacher care about investments highlighted 2011. [SEP]']
[ 450/2000] tot_loss=2.468 (perp=9.119, rec=0.644), tot_loss_proj:3.013 [t=0.26s]
prediction: ['[CLS] i i. community. greg, community accessible ‖ to being award address. culture science is environmental aspects of science ) us balanced feature visual and history about director article was the our teacher care about investments highlighted 2011. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.533 (perp=9.625, rec=0.608), tot_loss_proj:3.461 [t=0.25s]
prediction: ['[CLS] we i. community. greg, community award ‖ to being picture address. hoffman science is environmental aspects of science ) us averaged feature visual and way about director directors was the our teacher care about investments highlighted director. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.524 (perp=9.641, rec=0.595), tot_loss_proj:3.550 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ to being our address. hoffman science is environmental aspects of science ) us averaged feature visual and way about article directors was the picture teacher care about investments highlighted director. [SEP]']
[ 600/2000] tot_loss=2.495 (perp=9.641, rec=0.567), tot_loss_proj:3.542 [t=0.25s]
prediction: ['[CLS] j i. noted. greg, community award ‖ to being our address. hoffman science is environmental aspects of science ) us averaged feature visual and way about article directors was the picture teacher care about investments highlighted director. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.424 (perp=9.318, rec=0.561), tot_loss_proj:3.285 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ hoffman science is to being our address. environmental aspects of science ) us averaged feature visual and way about article directors was the accessible teacher care about investments highlighted director. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.359 (perp=9.068, rec=0.545), tot_loss_proj:3.327 [t=0.25s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is to being our address. environmental aspects of science ) us averaged feature visual and director way about directors was the accessible teacher care aboutductive highlighted director. [SEP]']
[ 750/2000] tot_loss=2.341 (perp=9.038, rec=0.534), tot_loss_proj:3.299 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science ) us averaged feature visual and director way about directors was the accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.213 (perp=8.433, rec=0.526), tot_loss_proj:3.389 [t=0.27s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science. us averaged. and article way about directors was the visual accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.268 (perp=8.747, rec=0.519), tot_loss_proj:3.414 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science. us averaged and article way about directors was discovery the visual accessible teacher care aboutductive highlighted director. [SEP]']
[ 900/2000] tot_loss=2.303 (perp=8.963, rec=0.510), tot_loss_proj:3.268 [t=0.25s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science. us averaged and article history about director was discovery the visual accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.269 (perp=8.783, rec=0.513), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is science of being our address. environmental aspects of science. us averaged and article history about director was discovery the visual accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.260 (perp=8.768, rec=0.507), tot_loss_proj:3.223 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is science of being stress address. environmental aspects of science teacher us averaged and article history about director was discovery the visual accessible. care aboutductive highlighted director. [SEP]']
[1050/2000] tot_loss=2.249 (perp=8.768, rec=0.496), tot_loss_proj:3.215 [t=0.25s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is science of being stress address. environmental aspects of science teacher us averaged and article history about director was discovery the visual accessible. care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.196 (perp=8.515, rec=0.493), tot_loss_proj:3.229 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is history science of being stress address. environmental aspects of science teacher us averaged and article about director was discovery the visual accessible. care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.218 (perp=8.599, rec=0.498), tot_loss_proj:3.225 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is history science discovery of being our address. environmental aspects of science teacher us averaged and article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
[1200/2000] tot_loss=2.260 (perp=8.885, rec=0.483), tot_loss_proj:3.244 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is history science discovery of being our address. environmental aspects of science teacher us averaged arnold article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.324 (perp=9.173, rec=0.489), tot_loss_proj:3.327 [t=0.30s]
prediction: ['[CLS] noted i season j. greg, community award ‖ harris is history science discovery the being our address. environmental aspects of science teacher us averaged arnold article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.191 (perp=8.550, rec=0.481), tot_loss_proj:3.200 [t=0.25s]
prediction: ['[CLS] noted i season j. greg, community award ‖ harris is history science discovery being our address. the environmental aspects of science teacher us averaged and article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
[1350/2000] tot_loss=2.189 (perp=8.550, rec=0.479), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] noted i season j. greg, community award ‖ harris is history science discovery being our address. the environmental aspects of science teacher us averaged and article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.236 (perp=8.766, rec=0.483), tot_loss_proj:3.381 [t=0.28s]
prediction: ['[CLS] noted i season j greg, science award ‖ harris is history science discovery being our address. of environmental aspects of science teacher us averaged and article about director episode the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.212 (perp=8.662, rec=0.480), tot_loss_proj:3.358 [t=0.25s]
prediction: ['[CLS] noted i season j greg, address award ‖ harris is history science discovery being our science. of environmental aspects of science teacher us averaged and article about director episode the visual accessible. ) care aboutductive highlighted director. [SEP]']
[1500/2000] tot_loss=2.233 (perp=8.789, rec=0.475), tot_loss_proj:3.276 [t=0.28s]
prediction: ['[CLS] noted i season j greg, address award ‖ harris is history science discovery being our community. of environmental aspects of science teacher us averaged and article about director episode the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.196 (perp=8.605, rec=0.475), tot_loss_proj:3.263 [t=0.26s]
prediction: ['[CLS] noted i season j greg, address episode ‖ harris is history science discovery being our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.162 (perp=8.437, rec=0.474), tot_loss_proj:3.297 [t=0.26s]
prediction: ['[CLS] noted i season j greg, address being ‖ harris is history science discovery episode our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
[1650/2000] tot_loss=2.202 (perp=8.643, rec=0.473), tot_loss_proj:3.223 [t=0.25s]
prediction: ['[CLS] noted i season j greg, address been ‖ harris is history science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.183 (perp=8.571, rec=0.469), tot_loss_proj:3.249 [t=0.26s]
prediction: ['[CLS] noted i season j greg harris address been ‖, is history science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.200 (perp=8.637, rec=0.473), tot_loss_proj:3.185 [t=0.27s]
prediction: ['[CLS] noted irin j greg harris address been, is history ‖ science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about premio highlighted director. [SEP]']
[1800/2000] tot_loss=2.197 (perp=8.637, rec=0.470), tot_loss_proj:3.179 [t=0.26s]
prediction: ['[CLS] noted irin j greg harris address been, is history ‖ science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about premio highlighted director. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.149 (perp=8.398, rec=0.469), tot_loss_proj:3.123 [t=0.26s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.146 (perp=8.398, rec=0.466), tot_loss_proj:3.126 [t=0.26s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
[1950/2000] tot_loss=2.147 (perp=8.398, rec=0.467), tot_loss_proj:3.122 [t=0.27s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.150 (perp=8.398, rec=0.471), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] theed successful johnson full hire wenation discipline! its'greatest man, hoffman tampa (nationbus, teacher in us amazing visual greatest things helping about rein rein of of your teacher care about because teacher latest. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 31.429 | p: 31.429 | r: 31.429
rouge2     | fm: 2.941 | p: 2.941 | r: 2.941
rougeL     | fm: 20.000 | p: 20.000 | r: 20.000
rougeLsum  | fm: 20.000 | p: 20.000 | r: 20.000
r1fm+r2fm = 34.370

[Aggregate metrics]:
rouge1     | fm: 82.195 | p: 81.403 | r: 83.249
rouge2     | fm: 46.038 | p: 45.667 | r: 46.349
rougeL     | fm: 72.711 | p: 71.896 | r: 73.802
rougeLsum  | fm: 72.770 | p: 71.936 | r: 73.754
r1fm+r2fm = 128.233

input #35 time: 0:11:00 | total time: 6:33:47


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
cosin similarity: -0.9007084999897201 normalized error: 1.7564637892117434
cosin similarity: 0.9007084999897202 normalized error: 0.4904798791781636
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 1.9463439303535441 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 1.8597335676586169 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 1.6924834972748093 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 1.6912547128093005 for ['[CLS]va bonyrim seater [SEP]']
[Init] best rec loss: 1.4382111041870433 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 1.432398523081628 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 1.4317622020744187 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 1.4313524163463498 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 1.4287708516992645 for ['[CLS] ramsey harassment cornelius bates [SEP]']
[Init] best perm rec loss: 1.420618332142762 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.646 (perp=11.427, rec=0.360), tot_loss_proj:3.109 [t=0.25s]
prediction: ['[CLS] badly badly wrong wrong [SEP]']
[ 100/2000] tot_loss=2.140 (perp=9.529, rec=0.234), tot_loss_proj:2.504 [t=0.25s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=2.073 (perp=9.304, rec=0.212), tot_loss_proj:2.652 [t=0.25s]
prediction: ['[CLS] absolutely horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=2.680 (perp=12.544, rec=0.171), tot_loss_proj:3.655 [t=0.25s]
prediction: ['[CLS] damien horribly wrong wrong [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.939 (perp=8.830, rec=0.173), tot_loss_proj:2.315 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.918 (perp=8.830, rec=0.152), tot_loss_proj:2.313 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.538 (perp=12.000, rec=0.138), tot_loss_proj:3.215 [t=0.25s]
prediction: ['[CLS] s wrong horriblyoic [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.287 (perp=10.754, rec=0.136), tot_loss_proj:2.799 [t=0.25s]
prediction: ['[CLS] s horribly wrong torture [SEP]']
[ 450/2000] tot_loss=2.275 (perp=10.754, rec=0.124), tot_loss_proj:2.803 [t=0.25s]
prediction: ['[CLS] s horribly wrong torture [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.458 (perp=11.688, rec=0.120), tot_loss_proj:3.340 [t=0.25s]
prediction: ['[CLS] skovic horribly wrong [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.236 (perp=10.617, rec=0.112), tot_loss_proj:2.980 [t=0.34s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[ 600/2000] tot_loss=2.241 (perp=10.617, rec=0.118), tot_loss_proj:2.980 [t=0.28s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.237 (perp=10.617, rec=0.114), tot_loss_proj:2.980 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.237 (perp=10.617, rec=0.114), tot_loss_proj:2.980 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[ 750/2000] tot_loss=2.238 (perp=10.617, rec=0.115), tot_loss_proj:2.984 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.233 (perp=10.617, rec=0.110), tot_loss_proj:2.983 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.240 (perp=10.617, rec=0.117), tot_loss_proj:2.982 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[ 900/2000] tot_loss=2.227 (perp=10.617, rec=0.104), tot_loss_proj:2.981 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.245 (perp=10.617, rec=0.121), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.231 (perp=10.617, rec=0.107), tot_loss_proj:2.973 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1050/2000] tot_loss=2.234 (perp=10.617, rec=0.111), tot_loss_proj:2.976 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.231 (perp=10.617, rec=0.108), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.226 (perp=10.617, rec=0.103), tot_loss_proj:2.969 [t=0.24s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1200/2000] tot_loss=2.238 (perp=10.617, rec=0.114), tot_loss_proj:2.975 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.235 (perp=10.617, rec=0.112), tot_loss_proj:2.983 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.228 (perp=10.617, rec=0.104), tot_loss_proj:2.978 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1350/2000] tot_loss=2.230 (perp=10.617, rec=0.107), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.235 (perp=10.617, rec=0.112), tot_loss_proj:2.972 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.234 (perp=10.617, rec=0.110), tot_loss_proj:2.979 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1500/2000] tot_loss=2.232 (perp=10.617, rec=0.109), tot_loss_proj:2.976 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.228 (perp=10.617, rec=0.105), tot_loss_proj:2.976 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.240 (perp=10.617, rec=0.116), tot_loss_proj:2.980 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1650/2000] tot_loss=2.238 (perp=10.617, rec=0.115), tot_loss_proj:2.982 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.241 (perp=10.617, rec=0.117), tot_loss_proj:2.983 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.240 (perp=10.617, rec=0.117), tot_loss_proj:2.981 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1800/2000] tot_loss=2.233 (perp=10.617, rec=0.110), tot_loss_proj:2.979 [t=0.24s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.236 (perp=10.617, rec=0.113), tot_loss_proj:2.971 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.229 (perp=10.617, rec=0.106), tot_loss_proj:2.978 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1950/2000] tot_loss=2.228 (perp=10.617, rec=0.105), tot_loss_proj:2.977 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.237 (perp=10.617, rec=0.114), tot_loss_proj:2.975 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s horribly wrongkovic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 82.074 | p: 81.156 | r: 83.144
rouge2     | fm: 46.364 | p: 46.066 | r: 46.732
rougeL     | fm: 73.002 | p: 72.202 | r: 73.947
rougeLsum  | fm: 72.917 | p: 72.036 | r: 73.853
r1fm+r2fm = 128.438

input #36 time: 0:10:52 | total time: 6:44:39


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
cosin similarity: 0.9160557524849074 normalized error: 0.5048909406348259
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 1.5006748480817524 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 1.4465081559776138 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 1.4395158593330282 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 1.4008127448929162 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 1.2805219864328496 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 1.1848695802546465 for ['[CLS] quite sketch [SEP]']
[Init] best rec loss: 1.179312855528016 for ['[CLS] plainly holstein [SEP]']
[Init] best rec loss: 1.1543642241365162 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 1.143659906209792 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 1.1380497183729246 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 1.128497397896091 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.428 (perp=10.187, rec=0.391), tot_loss_proj:2.853 [t=0.29s]
prediction: ['[CLS] eccentric wife [SEP]']
[ 100/2000] tot_loss=2.555 (perp=11.791, rec=0.197), tot_loss_proj:3.201 [t=0.28s]
prediction: ['[CLS] eccentric indeed [SEP]']
[ 150/2000] tot_loss=2.065 (perp=9.583, rec=0.149), tot_loss_proj:2.171 [t=0.29s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=2.067 (perp=9.583, rec=0.151), tot_loss_proj:2.159 [t=0.28s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.596 (perp=11.411, rec=0.314), tot_loss_proj:2.973 [t=0.29s]
prediction: ['[CLS] therefore eccentric [SEP]']
[ 300/2000] tot_loss=2.431 (perp=11.266, rec=0.177), tot_loss_proj:2.925 [t=0.32s]
prediction: ['[CLS] indeed eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.238 (perp=10.438, rec=0.151), tot_loss_proj:2.743 [t=0.29s]
prediction: ['[CLS] besides eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.236 (perp=10.438, rec=0.148), tot_loss_proj:2.734 [t=0.29s]
prediction: ['[CLS] besides eccentric [SEP]']
[ 450/2000] tot_loss=2.231 (perp=10.438, rec=0.143), tot_loss_proj:2.728 [t=0.29s]
prediction: ['[CLS] besides eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.599 (perp=12.335, rec=0.132), tot_loss_proj:3.291 [t=0.29s]
prediction: ['[CLS] jared eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.604 (perp=12.335, rec=0.137), tot_loss_proj:3.285 [t=0.29s]
prediction: ['[CLS] jared eccentric [SEP]']
[ 600/2000] tot_loss=3.227 (perp=15.533, rec=0.120), tot_loss_proj:4.936 [t=0.29s]
prediction: ['[CLS]urity eccentric [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.665 (perp=12.620, rec=0.141), tot_loss_proj:3.483 [t=0.26s]
prediction: ['[CLS] eccentric jared [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.388 (perp=11.317, rec=0.124), tot_loss_proj:4.098 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[ 750/2000] tot_loss=2.401 (perp=11.317, rec=0.137), tot_loss_proj:4.093 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.379 (perp=11.317, rec=0.116), tot_loss_proj:4.089 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.382 (perp=11.317, rec=0.119), tot_loss_proj:4.103 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[ 900/2000] tot_loss=2.392 (perp=11.317, rec=0.129), tot_loss_proj:4.099 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.380 (perp=11.317, rec=0.117), tot_loss_proj:4.098 [t=0.24s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:4.097 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
[1050/2000] tot_loss=2.376 (perp=11.317, rec=0.112), tot_loss_proj:4.097 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.377 (perp=11.317, rec=0.114), tot_loss_proj:4.091 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.386 (perp=11.317, rec=0.123), tot_loss_proj:4.098 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1200/2000] tot_loss=2.380 (perp=11.317, rec=0.117), tot_loss_proj:4.087 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.382 (perp=11.317, rec=0.118), tot_loss_proj:4.091 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:4.094 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1350/2000] tot_loss=2.399 (perp=11.317, rec=0.136), tot_loss_proj:4.093 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.389 (perp=11.317, rec=0.126), tot_loss_proj:4.096 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.383 (perp=11.317, rec=0.120), tot_loss_proj:4.086 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1500/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:4.092 [t=0.28s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.400 (perp=11.317, rec=0.137), tot_loss_proj:4.096 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.378 (perp=11.317, rec=0.115), tot_loss_proj:4.095 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1650/2000] tot_loss=2.391 (perp=11.317, rec=0.127), tot_loss_proj:4.089 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.365 (perp=11.317, rec=0.102), tot_loss_proj:4.091 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.387 (perp=11.317, rec=0.123), tot_loss_proj:4.095 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1800/2000] tot_loss=2.383 (perp=11.317, rec=0.119), tot_loss_proj:4.087 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.384 (perp=11.317, rec=0.120), tot_loss_proj:4.088 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.382 (perp=11.317, rec=0.119), tot_loss_proj:4.093 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1950/2000] tot_loss=2.389 (perp=11.317, rec=0.125), tot_loss_proj:4.094 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.396 (perp=11.317, rec=0.133), tot_loss_proj:4.093 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentricurity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 66.667 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 66.667 | r: 50.000
rougeLsum  | fm: 57.143 | p: 66.667 | r: 50.000
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 81.514 | p: 80.892 | r: 82.264
rouge2     | fm: 45.387 | p: 45.025 | r: 45.736
rougeL     | fm: 72.496 | p: 71.963 | r: 73.252
rougeLsum  | fm: 72.639 | p: 72.057 | r: 73.427
r1fm+r2fm = 126.900

input #37 time: 0:11:18 | total time: 6:55:58


Running input #38 of 100.
reference: 
========================
scare 
========================
cosin similarity: -0.9177834580454345 normalized error: 1.7129305511605397
cosin similarity: 0.9177834580454345 normalized error: 0.5039674783213574
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 1.7734035403057808 for ['[CLS] course [SEP]']
[Init] best rec loss: 1.7676329486087006 for ['[CLS] 100 [SEP]']
[Init] best rec loss: 1.6444200642974889 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 1.492191168604056 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 1.4765153174854833 for ['[CLS] consciousness [SEP]']
[Init] best rec loss: 1.4302106789664772 for ['[CLS] private [SEP]']
[Init] best rec loss: 1.250476270925176 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.012 (perp=14.070, rec=0.198), tot_loss_proj:3.096 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.964 (perp=14.070, rec=0.150), tot_loss_proj:3.029 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.952 (perp=14.070, rec=0.137), tot_loss_proj:3.032 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.955 (perp=14.070, rec=0.141), tot_loss_proj:3.033 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.952 (perp=14.070, rec=0.138), tot_loss_proj:3.035 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.941 (perp=14.070, rec=0.127), tot_loss_proj:3.037 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.947 (perp=14.070, rec=0.133), tot_loss_proj:3.032 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.958 (perp=14.070, rec=0.144), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.944 (perp=14.070, rec=0.129), tot_loss_proj:3.024 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.938 (perp=14.070, rec=0.124), tot_loss_proj:3.030 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.945 (perp=14.070, rec=0.131), tot_loss_proj:3.047 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.955 (perp=14.070, rec=0.141), tot_loss_proj:3.045 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.943 (perp=14.070, rec=0.129), tot_loss_proj:3.039 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.933 (perp=14.070, rec=0.119), tot_loss_proj:3.027 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.949 (perp=14.070, rec=0.135), tot_loss_proj:3.032 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.938 (perp=14.070, rec=0.123), tot_loss_proj:3.034 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.954 (perp=14.070, rec=0.140), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.946 (perp=14.070, rec=0.132), tot_loss_proj:3.029 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.941 (perp=14.070, rec=0.127), tot_loss_proj:3.027 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.949 (perp=14.070, rec=0.135), tot_loss_proj:3.020 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.938 (perp=14.070, rec=0.124), tot_loss_proj:3.045 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.941 (perp=14.070, rec=0.127), tot_loss_proj:3.029 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.939 (perp=14.070, rec=0.125), tot_loss_proj:3.020 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.942 (perp=14.070, rec=0.128), tot_loss_proj:3.040 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.936 (perp=14.070, rec=0.122), tot_loss_proj:3.031 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.030 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.942 (perp=14.070, rec=0.128), tot_loss_proj:3.035 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.953 (perp=14.070, rec=0.139), tot_loss_proj:3.016 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.934 (perp=14.070, rec=0.120), tot_loss_proj:3.021 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.039 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.932 (perp=14.070, rec=0.118), tot_loss_proj:3.027 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.942 (perp=14.070, rec=0.128), tot_loss_proj:3.028 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.938 (perp=14.070, rec=0.124), tot_loss_proj:3.026 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.937 (perp=14.070, rec=0.123), tot_loss_proj:3.031 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.943 (perp=14.070, rec=0.129), tot_loss_proj:3.031 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.939 (perp=14.070, rec=0.125), tot_loss_proj:3.036 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.946 (perp=14.070, rec=0.131), tot_loss_proj:3.045 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.937 (perp=14.070, rec=0.123), tot_loss_proj:3.022 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.030 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.937 | p: 81.356 | r: 82.701
rouge2     | fm: 46.427 | p: 46.079 | r: 46.793
rougeL     | fm: 73.334 | p: 72.771 | r: 74.063
rougeLsum  | fm: 73.215 | p: 72.593 | r: 73.986
r1fm+r2fm = 128.364

input #38 time: 0:10:42 | total time: 7:06:40


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
cosin similarity: -0.7643173159809633 normalized error: 1.7333089499394547
cosin similarity: 0.7643173159809634 normalized error: 0.560839091166381
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.9521867036819458 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.9505660533905029 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9071248173713684 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.8664548397064209 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.8436209559440613 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.8375389575958252 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.8212458491325378 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best rec loss: 0.7974854111671448 for ['[CLS] laterpsy salt lieutenant natalily area mining step filmedties bad bow brownsgled phillip cousins stadium spit bat tracksce multi sy nail [SEP]']
[Init] best perm rec loss: 0.7971394062042236 for ['[CLS] bad stadium browns mining filmed area phillip lieutenant multipsy natal tracksgled nailties sy stepily cousins spit salt bat bow laterce [SEP]']
[Init] best perm rec loss: 0.7970192432403564 for ['[CLS] natal cousins mining nail stadium salt sy multi lieutenant spit bow step filmed areatiesgled phillippsy browns batce bad tracks laterily [SEP]']
[Init] best perm rec loss: 0.7966355085372925 for ['[CLS] sy cousins nail phillip stadium spit multice bad filmed bat mining browns step saltpsy area lieutenant later bow natalgled trackstiesily [SEP]']
[Init] best perm rec loss: 0.7966263294219971 for ['[CLS] spitily salt miningpsy area phillip lieutenant browns sy bow nail bat later multi tracks bad natal stadiumties step filmedgled cousinsce [SEP]']
[Init] best perm rec loss: 0.7962812781333923 for ['[CLS] browns bad tracks areaily sy salt cousins lieutenant stadium nail spit later step bow miningties natalpsy phillipce bat multigled filmed [SEP]']
[Init] best perm rec loss: 0.7956726551055908 for ['[CLS] area cousins natal bow phillip saltties browns spit stadiumce step lieutenantpsy miningily multi sy bat nail tracks later filmed badgled [SEP]']
[Init] best perm rec loss: 0.795223593711853 for ['[CLS] step natal mining later cousins badgled bow browns phillip multi stadiumily trackspsyties sy lieutenant nailce filmed bat salt area spit [SEP]']
[Init] best perm rec loss: 0.7951224446296692 for ['[CLS]ce multipsy bat saltties later area tracks cousins browns lieutenant bow sy step natal badily spit filmed nail phillip stadium mininggled [SEP]']
[Init] best perm rec loss: 0.7931864261627197 for ['[CLS] bat lieutenant area filmed bow multi miningpsyties browns spit stadium nail bad tracks phillip salt cousins laterce step sy natalilygled [SEP]']
[Init] best perm rec loss: 0.7926360964775085 for ['[CLS]psyce filmed spit nail later lieutenant bow browns cousinsily stepties bad multi tracks natal area stadium phillip bat mining sy saltgled [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.365 (perp=10.483, rec=0.269), tot_loss_proj:2.711 [t=0.25s]
prediction: ['[CLS] conservative holiday hideing primary conservative heritage. nominee, artist finds master change and, new theme traditions lived new movie 1960s found again [SEP]']
[ 100/2000] tot_loss=2.098 (perp=9.707, rec=0.157), tot_loss_proj:2.520 [t=0.27s]
prediction: ['[CLS] conservative site hidebound most conservative traditions, tanner, real identity gives it and, new texture traditions texture new movie finds one again [SEP]']
[ 150/2000] tot_loss=2.009 (perp=9.476, rec=0.114), tot_loss_proj:2.438 [t=0.25s]
prediction: ['[CLS] conservative our hidebound most conservative traditions andbound, my identity gives it and, new texture traditions relevance new movie finds - again [SEP]']
[ 200/2000] tot_loss=1.933 (perp=9.198, rec=0.094), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] our our hidebound most conservative traditions andbound, one - gives it and, new texture traditions relevance new movie finds - again [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.852 (perp=8.858, rec=0.080), tot_loss_proj:2.237 [t=0.26s]
prediction: ['[CLS] our our hidebound most conservative traditions andbound. one - gives it and traditions new texture, relevance new movie finds - again [SEP]']
[ 300/2000] tot_loss=1.848 (perp=8.858, rec=0.076), tot_loss_proj:2.240 [t=0.26s]
prediction: ['[CLS] our our hidebound most conservative traditions andbound. one - gives it and traditions new texture, relevance new movie finds - again [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.868 (perp=8.944, rec=0.080), tot_loss_proj:2.205 [t=0.26s]
prediction: ['[CLS] of our hidebound most conservative traditions andbound new one - gives it and traditions new texture, relevance. movie finds making - [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.822 (perp=8.727, rec=0.077), tot_loss_proj:2.167 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative traditions andbound new one - gives it and traditions new texture, making relevance. movie finds again [SEP]']
[ 450/2000] tot_loss=1.820 (perp=8.727, rec=0.074), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] of our hidebound most conservative traditions andbound new one - gives it and traditions new texture, making relevance. movie finds again [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.855 (perp=8.741, rec=0.107), tot_loss_proj:2.175 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative traditions and ve new one of gives it and traditions new texture, making relevance movie finds., [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.694 (perp=8.050, rec=0.084), tot_loss_proj:2.032 [t=0.26s]
prediction: ['[CLS] of our hidebound most conservative traditions andk new one of gives it new traditions and texture, making relevance movie finds., [SEP]']
[ 600/2000] tot_loss=1.747 (perp=8.344, rec=0.078), tot_loss_proj:2.078 [t=0.26s]
prediction: ['[CLS] of our hidebound most conservative traditions andves new one - gives it new traditions and texture, making relevance movie finds., [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.577 (perp=7.520, rec=0.073), tot_loss_proj:1.924 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative traditions and new one - - gives it new traditions and texture, making relevance movie finds., [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.572 (perp=7.474, rec=0.077), tot_loss_proj:1.904 [t=0.27s]
prediction: ['[CLS] of our hidebound most conservative traditions and one - - gives it new traditions and new texture, making relevance movie finds., [SEP]']
[ 750/2000] tot_loss=1.573 (perp=7.474, rec=0.078), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] of our hidebound most conservative traditions and one - - gives it new traditions and new texture, making relevance movie finds., [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.540 (perp=7.308, rec=0.078), tot_loss_proj:1.830 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative traditions and movie - - gives it new traditions and new texture, making relevance one finds., [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.467 (perp=6.915, rec=0.084), tot_loss_proj:1.749 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative, traditions and movie - - gives it new traditions and new texture, making relevance one finds. [SEP]']
[ 900/2000] tot_loss=1.454 (perp=6.915, rec=0.071), tot_loss_proj:1.743 [t=0.27s]
prediction: ['[CLS] of our hidebound most conservative, traditions and movie - - gives it new traditions and new texture, making relevance one finds. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.416 (perp=6.724, rec=0.071), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] of our hidebound most conservative, traditions and movie - - gives it new relevance and new texture, making traditions one finds. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.437 (perp=6.847, rec=0.067), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative, traditions and movie - - gives it new reality and new texture, making traditions one finds. [SEP]']
[1050/2000] tot_loss=1.447 (perp=6.847, rec=0.078), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] of our hidebound most conservative, traditions and movie - - gives it new reality and new texture, making traditions one finds. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.397 (perp=6.588, rec=0.079), tot_loss_proj:1.688 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new texture, making movie one finds. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.370 (perp=6.504, rec=0.070), tot_loss_proj:2.001 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new texture movie making, one finds. [SEP]']
[1200/2000] tot_loss=1.377 (perp=6.504, rec=0.076), tot_loss_proj:2.013 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new texture movie making, one finds. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.352 (perp=6.392, rec=0.074), tot_loss_proj:1.719 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new movie making, one finds texture. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.352 (perp=6.392, rec=0.073), tot_loss_proj:1.714 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new movie making, one finds texture. [SEP]']
[1350/2000] tot_loss=1.343 (perp=6.392, rec=0.065), tot_loss_proj:1.715 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new movie making, one finds texture. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.354 (perp=6.392, rec=0.075), tot_loss_proj:1.718 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new reality and new movie making, one finds texture. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.322 (perp=6.286, rec=0.065), tot_loss_proj:1.741 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
[1500/2000] tot_loss=1.323 (perp=6.286, rec=0.066), tot_loss_proj:1.738 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.328 (perp=6.286, rec=0.071), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.329 (perp=6.286, rec=0.072), tot_loss_proj:1.739 [t=0.28s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
[1650/2000] tot_loss=1.332 (perp=6.286, rec=0.075), tot_loss_proj:1.739 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.326 (perp=6.286, rec=0.069), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.332 (perp=6.286, rec=0.075), tot_loss_proj:1.733 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
[1800/2000] tot_loss=1.325 (perp=6.286, rec=0.068), tot_loss_proj:1.732 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.328 (perp=6.286, rec=0.071), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.320 (perp=6.286, rec=0.063), tot_loss_proj:1.731 [t=0.29s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
[1950/2000] tot_loss=1.334 (perp=6.286, rec=0.077), tot_loss_proj:1.737 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.348 (perp=6.387, rec=0.070), tot_loss_proj:1.767 [t=0.30s]
prediction: ['[CLS] of our hidebound most conservative, reality and traditions - - gives it new texture and movie making, one finds new reality. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] of our hidebound most conservative, traditions and traditions - - gives it new texture and new movie making, one finds reality. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.023 | p: 95.238 | r: 90.909
rouge2     | fm: 39.024 | p: 40.000 | r: 38.095
rougeL     | fm: 65.116 | p: 66.667 | r: 63.636
rougeLsum  | fm: 65.116 | p: 66.667 | r: 63.636
r1fm+r2fm = 132.048

[Aggregate metrics]:
rouge1     | fm: 82.239 | p: 81.752 | r: 82.944
rouge2     | fm: 46.386 | p: 46.157 | r: 46.644
rougeL     | fm: 73.098 | p: 72.652 | r: 73.756
rougeLsum  | fm: 73.018 | p: 72.480 | r: 73.695
r1fm+r2fm = 128.625

input #39 time: 0:11:25 | total time: 7:18:06


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
cosin similarity: 0.7520072193431633 normalized error: 0.5835583402914879
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9196642637252808 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.8888179063796997 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.8420372009277344 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.8310739994049072 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8144931793212891 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8134586215019226 for ['[CLS] commercial bible conjunctioney chair batman kirk box hangar [SEP]']
[Init] best rec loss: 0.795963704586029 for ['[CLS] rep survival goal coral began hoc in protection barry [SEP]']
[Init] best rec loss: 0.7766450047492981 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.7189508676528931 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.6683447957038879 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.6645317673683167 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.6588467955589294 for ['[CLS] georgian already kent abd but deciding lady° many [SEP]']
[Init] best perm rec loss: 0.6587061285972595 for ['[CLS] deciding already kent many° lady abd but georgian [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.735 (perp=12.366, rec=0.261), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] phmmel withony imageryony imagerymmelony [SEP]']
[ 100/2000] tot_loss=2.333 (perp=10.974, rec=0.139), tot_loss_proj:2.694 [t=0.27s]
prediction: ['[CLS] phmmel withony imagery or musicmmelony [SEP]']
[ 150/2000] tot_loss=2.257 (perp=10.783, rec=0.101), tot_loss_proj:2.638 [t=0.27s]
prediction: ['[CLS] phmmel withony imagery or musicmmel us [SEP]']
[ 200/2000] tot_loss=2.242 (perp=10.783, rec=0.086), tot_loss_proj:2.634 [t=0.27s]
prediction: ['[CLS] phmmel withony imagery or musicmmel us [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.079 (perp=9.899, rec=0.099), tot_loss_proj:2.634 [t=0.27s]
prediction: ['[CLS] phmmelony with imagery or musicmmel us [SEP]']
[ 300/2000] tot_loss=2.059 (perp=9.899, rec=0.079), tot_loss_proj:2.633 [t=0.27s]
prediction: ['[CLS] phmmelony with imagery or musicmmel us [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.890 (perp=8.812, rec=0.127), tot_loss_proj:2.313 [t=0.27s]
prediction: ['[CLS] phony with imagery or musicmmel usmmel [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.126 (perp=10.111, rec=0.104), tot_loss_proj:2.466 [t=0.27s]
prediction: ['[CLS] phony with imagery or musicmmel us ph [SEP]']
[ 450/2000] tot_loss=2.110 (perp=10.111, rec=0.087), tot_loss_proj:2.463 [t=0.27s]
prediction: ['[CLS] phony with imagery or musicmmel us ph [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.107 (perp=9.950, rec=0.117), tot_loss_proj:2.467 [t=0.27s]
prediction: ['[CLS] puony imagery or musicmmel us with ph [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.539 (perp=7.171, rec=0.105), tot_loss_proj:1.515 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 600/2000] tot_loss=1.522 (perp=7.171, rec=0.088), tot_loss_proj:1.514 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.512 (perp=7.171, rec=0.078), tot_loss_proj:1.513 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.496 (perp=7.171, rec=0.062), tot_loss_proj:1.511 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 750/2000] tot_loss=1.510 (perp=7.171, rec=0.075), tot_loss_proj:1.511 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.500 (perp=7.171, rec=0.066), tot_loss_proj:1.509 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.498 (perp=7.171, rec=0.064), tot_loss_proj:1.518 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 900/2000] tot_loss=1.517 (perp=7.171, rec=0.082), tot_loss_proj:1.516 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.495 (perp=7.171, rec=0.061), tot_loss_proj:1.516 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.490 (perp=7.171, rec=0.055), tot_loss_proj:1.519 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1050/2000] tot_loss=1.488 (perp=7.171, rec=0.053), tot_loss_proj:1.518 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.503 (perp=7.171, rec=0.068), tot_loss_proj:1.520 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.495 (perp=7.171, rec=0.061), tot_loss_proj:1.525 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1200/2000] tot_loss=1.503 (perp=7.171, rec=0.068), tot_loss_proj:1.513 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.502 (perp=7.171, rec=0.067), tot_loss_proj:1.516 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.501 (perp=7.171, rec=0.067), tot_loss_proj:1.508 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.171, rec=0.053), tot_loss_proj:1.510 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.508 (perp=7.171, rec=0.073), tot_loss_proj:1.507 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.502 (perp=7.171, rec=0.068), tot_loss_proj:1.512 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1500/2000] tot_loss=1.500 (perp=7.171, rec=0.066), tot_loss_proj:1.509 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.491 (perp=7.171, rec=0.057), tot_loss_proj:1.508 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.491 (perp=7.171, rec=0.057), tot_loss_proj:1.511 [t=0.30s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1650/2000] tot_loss=1.488 (perp=7.171, rec=0.053), tot_loss_proj:1.516 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.488 (perp=7.171, rec=0.053), tot_loss_proj:1.523 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.501 (perp=7.171, rec=0.067), tot_loss_proj:1.507 [t=0.32s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1800/2000] tot_loss=1.503 (perp=7.171, rec=0.069), tot_loss_proj:1.511 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.499 (perp=7.171, rec=0.065), tot_loss_proj:1.517 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=7.171, rec=0.070), tot_loss_proj:1.508 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1950/2000] tot_loss=1.507 (perp=7.171, rec=0.073), tot_loss_proj:1.523 [t=0.29s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.472 (perp=6.973, rec=0.077), tot_loss_proj:1.511 [t=0.29s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.662 | p: 82.201 | r: 83.281
rouge2     | fm: 47.733 | p: 47.414 | r: 48.080
rougeL     | fm: 73.663 | p: 73.266 | r: 74.339
rougeLsum  | fm: 73.540 | p: 73.135 | r: 74.237
r1fm+r2fm = 130.395

input #40 time: 0:11:20 | total time: 7:29:26


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
cosin similarity: -0.9586736306406645 normalized error: 1.8620978720587626
cosin similarity: 0.9586736306406645 normalized error: 0.42054102770034735
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 1.9807413656640047 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 1.8783758999600992 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 1.8258731535338106 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 1.5699197359221344 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 1.5147527971791062 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 1.4065112444869143 for ['[CLS] hauntedrily [SEP]']
[Init] best rec loss: 1.348408171800872 for ["[CLS]'classification [SEP]"]
[Init] best rec loss: 1.3380154540705231 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 1.0463319870316985 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.8872571205676811 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.300 (perp=10.212, rec=0.258), tot_loss_proj:2.190 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.202 (perp=10.212, rec=0.159), tot_loss_proj:2.183 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.180 (perp=10.212, rec=0.137), tot_loss_proj:2.185 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.181 (perp=10.212, rec=0.139), tot_loss_proj:2.197 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.173 (perp=10.212, rec=0.130), tot_loss_proj:2.197 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.165 (perp=10.212, rec=0.123), tot_loss_proj:2.176 [t=0.32s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.161 (perp=10.212, rec=0.119), tot_loss_proj:2.199 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.167 (perp=10.212, rec=0.125), tot_loss_proj:2.182 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.161 (perp=10.212, rec=0.119), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.165 (perp=10.212, rec=0.123), tot_loss_proj:2.178 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.164 (perp=10.212, rec=0.122), tot_loss_proj:2.190 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.175 (perp=10.212, rec=0.133), tot_loss_proj:2.195 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.162 (perp=10.212, rec=0.120), tot_loss_proj:2.186 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.169 (perp=10.212, rec=0.126), tot_loss_proj:2.183 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.177 (perp=10.212, rec=0.135), tot_loss_proj:2.179 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.171 (perp=10.212, rec=0.129), tot_loss_proj:2.189 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.165 (perp=10.212, rec=0.122), tot_loss_proj:2.190 [t=0.32s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.166 (perp=10.212, rec=0.123), tot_loss_proj:2.191 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.184 (perp=10.212, rec=0.141), tot_loss_proj:2.193 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.164 (perp=10.212, rec=0.122), tot_loss_proj:2.181 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.170 (perp=10.212, rec=0.127), tot_loss_proj:2.193 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.172 (perp=10.212, rec=0.129), tot_loss_proj:2.190 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.174 (perp=10.212, rec=0.132), tot_loss_proj:2.183 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.170 (perp=10.212, rec=0.127), tot_loss_proj:2.195 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.164 (perp=10.212, rec=0.122), tot_loss_proj:2.188 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.178 (perp=10.212, rec=0.136), tot_loss_proj:2.188 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.180 (perp=10.212, rec=0.137), tot_loss_proj:2.185 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.168 (perp=10.212, rec=0.125), tot_loss_proj:2.176 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.173 (perp=10.212, rec=0.131), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.162 (perp=10.212, rec=0.120), tot_loss_proj:2.180 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.172 (perp=10.212, rec=0.130), tot_loss_proj:2.196 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.169 (perp=10.212, rec=0.127), tot_loss_proj:2.173 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.175 (perp=10.212, rec=0.132), tot_loss_proj:2.176 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.173 (perp=10.212, rec=0.131), tot_loss_proj:2.179 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.176 (perp=10.212, rec=0.133), tot_loss_proj:2.202 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.173 (perp=10.212, rec=0.131), tot_loss_proj:2.183 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.169 (perp=10.212, rec=0.126), tot_loss_proj:2.182 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.174 (perp=10.212, rec=0.132), tot_loss_proj:2.200 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.175 (perp=10.212, rec=0.133), tot_loss_proj:2.192 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.167 (perp=10.212, rec=0.124), tot_loss_proj:2.185 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.103 | p: 82.645 | r: 83.789
rouge2     | fm: 48.811 | p: 48.604 | r: 49.245
rougeL     | fm: 74.408 | p: 73.951 | r: 75.029
rougeLsum  | fm: 74.360 | p: 73.849 | r: 75.047
r1fm+r2fm = 131.914

input #41 time: 0:11:43 | total time: 7:41:10


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
cosin similarity: 0.7515790452467637 normalized error: 0.6030919457721563
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9316263198852539 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8086886405944824 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8003501892089844 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.796410858631134 for ['[CLS] speakers merize branch morning switzerland pedal dublinaker mar lamar introduced air sweet bowling promoter latter is cannon als how romney rhythm damolvedhedral [SEP]']
[Init] best rec loss: 0.7477632164955139 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7464561462402344 for ['[CLS] internationalgible ever wish superseded cutbe stages ran attracted darectric bandars treaty maple offended assignmentures kitchentakingpling scale lifted larger enough [SEP]']
[Init] best perm rec loss: 0.7452285885810852 for ['[CLS]gible superseded cut ran assignmentrs stages wishtaking liftedctricures treaty kitchen maple international scalebe attractedpling enough offended ever larger banda dare [SEP]']
[Init] best perm rec loss: 0.744653582572937 for ['[CLS]pling treaty banda kitchen assignment scalegible attracted largerctric stages wishbe superseded darers maple international offended everures lifted ran enoughtaking cut [SEP]']
[Init] best perm rec loss: 0.7431253790855408 for ['[CLS] larger treaty banda dareures enough stages superseded offended everplinggiblebe lifted international assignmenttaking cut scale attracted kitchen ran maple wishctricrs [SEP]']
[Init] best perm rec loss: 0.7422858476638794 for ['[CLS] enough banda attracted dare maplebe lifted assignment ran superseded larger kitchenctric wishrs scale offended cut treatygibleures stagestaking everpling international [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.692 (perp=11.940, rec=0.304), tot_loss_proj:2.944 [t=0.29s]
prediction: ['[CLS] less sc hopkins metaphor during app aggressive boyle colonial troopers poorly officers poorly poorly to poorly poorly date election guys bad for reported personnel complained broke [SEP]']
[ 100/2000] tot_loss=2.709 (perp=12.445, rec=0.220), tot_loss_proj:3.004 [t=0.38s]
prediction: ["[CLS] forgot recio forgot into filmmaker anything schools scary creators poorly'poorly poorly re poorly poorly talk vampire re forgot to reported background complained broke [SEP]"]
[ 150/2000] tot_loss=2.549 (perp=11.904, rec=0.168), tot_loss_proj:2.871 [t=0.30s]
prediction: ["[CLS] forgot re anything forgot into filmmaker anything school scary filmmakers poorly'poorly poorly re poorly poorlygger constructed re forgot to scary production restaurant location [SEP]"]
[ 200/2000] tot_loss=2.660 (perp=12.591, rec=0.142), tot_loss_proj:3.015 [t=0.29s]
prediction: ['[CLS] forgot re project scary halfway filmmaker anything schools scary they poorly the poorly poorlygger poorly poorlygger into re forgot to scary setting setting setting [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.787 (perp=12.651, rec=0.256), tot_loss_proj:3.034 [t=0.28s]
prediction: ['[CLS] forgot re project include even filmmakers anything ள school scary asoa poorly poorlyggerille poorlygger into s forgot to scary film setting into [SEP]']
[ 300/2000] tot_loss=2.428 (perp=11.351, rec=0.158), tot_loss_proj:2.773 [t=0.30s]
prediction: ['[CLS] forgot the project include even filmmakers anything ள school scary asna they poorlyggerille poorlygger into filmmakers forgot to scary film setting setting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.368 (perp=11.134, rec=0.141), tot_loss_proj:2.831 [t=0.30s]
prediction: ['[CLS] the forgot project include even filmmakers anything ள school scary as restroom they poorlygger re poorlygger into filmmakers forgot to scary film setting setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.213 (perp=10.404, rec=0.132), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] the forgot project include even filmmakers anything ள school scary aslaze they poorly regger poorlygger into filmmakers forgot to scary film setting setting [SEP]']
[ 450/2000] tot_loss=2.331 (perp=11.093, rec=0.113), tot_loss_proj:2.819 [t=0.27s]
prediction: ['[CLS] the forgot project include even filmmakers anything《 school scary as ashe they poorly regger poorlygger into filmmakers forgot to halfway film setting setting [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.390 (perp=11.417, rec=0.107), tot_loss_proj:2.844 [t=0.25s]
prediction: ['[CLS] re forgot project include even scary anything《 school filmmakers as halfway they poorly regger poorlygger into filmmakers forgot to halfway film attraction setting [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.309 (perp=10.831, rec=0.143), tot_loss_proj:2.717 [t=0.25s]
prediction: ['[CLS] the forgot project include even scary anything《 school filmmakers as they poorly halfway regger poorlygger into filmmakers forgot to halfway film fatal setting [SEP]']
[ 600/2000] tot_loss=2.224 (perp=10.588, rec=0.107), tot_loss_proj:2.662 [t=0.26s]
prediction: ['[CLS] the forgot project include even scary anything《 school filmmakers as they poorly halfway regger poorlygger into filmmakers forgot to halfway film attraction setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.177 (perp=10.337, rec=0.109), tot_loss_proj:2.624 [t=0.26s]
prediction: ['[CLS] the forgot project include even scary anything《 attraction filmmakers as they poorly halfway regger poorlygger into filmmakers forgot to halfway film school setting [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.152 (perp=10.237, rec=0.105), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] the s even include project scary anything《 attraction filmmakers as they poorly halfway regger poorlygger into filmmakers forgot to halfway film school setting [SEP]']
[ 750/2000] tot_loss=2.150 (perp=10.237, rec=0.103), tot_loss_proj:2.606 [t=0.25s]
prediction: ['[CLS] the s even include project scary anything《 attraction filmmakers as they poorly halfway regger poorlygger into filmmakers forgot to halfway film school setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.131 (perp=10.202, rec=0.090), tot_loss_proj:2.544 [t=0.26s]
prediction: ['[CLS] the s even include project scary anything《gger filmmakers as they poorlylaze regger poorly attraction into filmmakers forgot to halfway film school setting [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.123 (perp=10.202, rec=0.083), tot_loss_proj:2.547 [t=0.26s]
prediction: ['[CLS] the s even include project scary anything《gger filmmakers as they poorlylaze regger poorly attraction into filmmakers forgot to halfway film school setting [SEP]']
[ 900/2000] tot_loss=2.137 (perp=10.202, rec=0.097), tot_loss_proj:2.554 [t=0.26s]
prediction: ['[CLS] the s even include project scary anything《gger filmmakers as they poorlylaze regger poorly attraction into filmmakers forgot to halfway film school setting [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.094 (perp=10.026, rec=0.088), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] the s even include project scary anything《gger filmmakers as they poorly regger poorly attraction into filmmakerslaze forgot to halfway film school setting [SEP]']
Attempt swap
[1000/2000] tot_loss=2.098 (perp=10.026, rec=0.092), tot_loss_proj:2.518 [t=0.25s]
prediction: ['[CLS] the s even include project scary anything《gger filmmakers as they poorly regger poorly attraction into filmmakerslaze forgot to halfway film school setting [SEP]']
[1050/2000] tot_loss=2.166 (perp=10.359, rec=0.094), tot_loss_proj:2.601 [t=0.25s]
prediction: ['[CLS] the s even include project scary anything《gger filmmakers as they poorlyjigger poorly fatal into filmmakers fatal forgot to halfway film school setting [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.155 (perp=10.295, rec=0.096), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] the sgger include project scary anything《 even filmmakers as they poorlyjigger poorly fatal into filmmakers fatal forgot to halfway film school setting [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.105 (perp=10.055, rec=0.094), tot_loss_proj:2.557 [t=0.27s]
prediction: ['[CLS] the sgger include project scary anything《 even filmmakers as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
[1200/2000] tot_loss=2.101 (perp=10.055, rec=0.090), tot_loss_proj:2.560 [t=0.25s]
prediction: ['[CLS] the sgger include project scary anything《 even filmmakers as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.075 (perp=9.917, rec=0.092), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
[1300/2000] tot_loss=2.074 (perp=9.917, rec=0.091), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
[1350/2000] tot_loss=2.073 (perp=9.917, rec=0.089), tot_loss_proj:2.605 [t=0.26s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
[1400/2000] tot_loss=2.059 (perp=9.917, rec=0.076), tot_loss_proj:2.608 [t=0.25s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
[1450/2000] tot_loss=2.068 (perp=9.917, rec=0.084), tot_loss_proj:2.606 [t=0.26s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
[1500/2000] tot_loss=2.069 (perp=9.917, rec=0.085), tot_loss_proj:2.607 [t=0.28s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
[1550/2000] tot_loss=2.066 (perp=9.917, rec=0.082), tot_loss_proj:2.606 [t=0.26s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
[1600/2000] tot_loss=2.069 (perp=9.917, rec=0.086), tot_loss_proj:2.606 [t=0.27s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
[1650/2000] tot_loss=2.060 (perp=9.917, rec=0.077), tot_loss_proj:2.609 [t=0.27s]
prediction: ['[CLS] the sgger include project scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.057 (perp=9.887, rec=0.080), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] the sgger project include scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
[1750/2000] tot_loss=2.056 (perp=9.887, rec=0.079), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] the sgger project include scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
[1800/2000] tot_loss=2.063 (perp=9.887, rec=0.086), tot_loss_proj:2.585 [t=0.25s]
prediction: ['[CLS] the sgger project include scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.035 (perp=9.728, rec=0.090), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] the sgger project include fatal anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway scary film school setting [SEP]']
Attempt swap
[1900/2000] tot_loss=2.023 (perp=9.728, rec=0.077), tot_loss_proj:2.481 [t=0.27s]
prediction: ['[CLS] the sgger project include fatal anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway scary film school setting [SEP]']
[1950/2000] tot_loss=2.033 (perp=9.728, rec=0.087), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] the sgger project include fatal anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway scary film school setting [SEP]']
Attempt swap
[2000/2000] tot_loss=2.029 (perp=9.728, rec=0.083), tot_loss_proj:2.474 [t=0.26s]
prediction: ['[CLS] the sgger project include fatal anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway scary film school setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] the sgger project include scary anything《 filmmakers even as they poorlyjigger poorly fatal into filmmakers forgot to halfway fatal film school setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 79.167 | p: 79.167 | r: 79.167
rouge2     | fm: 26.087 | p: 26.087 | r: 26.087
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 105.254

[Aggregate metrics]:
rouge1     | fm: 82.813 | p: 82.382 | r: 83.493
rouge2     | fm: 48.647 | p: 48.415 | r: 48.990
rougeL     | fm: 73.985 | p: 73.454 | r: 74.669
rougeLsum  | fm: 73.862 | p: 73.417 | r: 74.526
r1fm+r2fm = 131.459

input #42 time: 0:11:08 | total time: 7:52:19


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
cosin similarity: -0.8206536545363274 normalized error: 1.7208620839187307
cosin similarity: 0.8206536545363273 normalized error: 0.5385766653645379
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 1.930642349247132 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 1.7851881997727803 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 1.6401963674852145 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 1.5806250046029051 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 1.4549208238461195 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 1.4183159966364798 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 1.2795261404886538 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 1.2649144397639163 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 1.1797931903189784 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 1.1795728389063767 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 1.1789216065817092 for ['[CLS] oxidation council enrollment deserved [SEP]']
[Init] best perm rec loss: 1.17678087706032 for ['[CLS] council oxidation deserved enrollment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.313 (perp=14.014, rec=0.510), tot_loss_proj:4.350 [t=0.25s]
prediction: ['[CLS]ountless qualify racial [SEP]']
[ 100/2000] tot_loss=2.988 (perp=13.182, rec=0.352), tot_loss_proj:4.374 [t=0.24s]
prediction: ['[CLS]ountlessptiveistic [SEP]']
[ 150/2000] tot_loss=3.036 (perp=13.726, rec=0.291), tot_loss_proj:4.701 [t=0.25s]
prediction: ['[CLS]ouse armycifulistic [SEP]']
[ 200/2000] tot_loss=2.407 (perp=10.763, rec=0.255), tot_loss_proj:2.931 [t=0.25s]
prediction: ['[CLS]ition naissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.376 (perp=10.766, rec=0.223), tot_loss_proj:2.934 [t=0.25s]
prediction: ['[CLS]iss naissistic [SEP]']
[ 300/2000] tot_loss=2.348 (perp=10.766, rec=0.195), tot_loss_proj:2.947 [t=0.25s]
prediction: ['[CLS]iss naissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.319 (perp=10.766, rec=0.166), tot_loss_proj:2.943 [t=0.25s]
prediction: ['[CLS]iss naissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.386 (perp=11.133, rec=0.159), tot_loss_proj:3.101 [t=0.27s]
prediction: ['[CLS] ec naissistic [SEP]']
[ 450/2000] tot_loss=2.378 (perp=11.133, rec=0.151), tot_loss_proj:3.081 [t=0.25s]
prediction: ['[CLS] ec naissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.381 (perp=11.133, rec=0.154), tot_loss_proj:3.092 [t=0.28s]
prediction: ['[CLS] ec naissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.369 (perp=11.133, rec=0.143), tot_loss_proj:3.100 [t=0.26s]
prediction: ['[CLS] ec naissistic [SEP]']
[ 600/2000] tot_loss=2.369 (perp=11.133, rec=0.143), tot_loss_proj:3.091 [t=0.26s]
prediction: ['[CLS] ec naissistic [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.108 (perp=9.766, rec=0.155), tot_loss_proj:3.221 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.103 (perp=9.766, rec=0.150), tot_loss_proj:3.235 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[ 750/2000] tot_loss=2.089 (perp=9.766, rec=0.136), tot_loss_proj:3.234 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.075 (perp=9.766, rec=0.122), tot_loss_proj:3.230 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.094 (perp=9.766, rec=0.141), tot_loss_proj:3.240 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[ 900/2000] tot_loss=2.095 (perp=9.766, rec=0.142), tot_loss_proj:3.237 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.091 (perp=9.766, rec=0.137), tot_loss_proj:3.241 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1000/2000] tot_loss=2.078 (perp=9.766, rec=0.125), tot_loss_proj:3.232 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
[1050/2000] tot_loss=2.092 (perp=9.766, rec=0.139), tot_loss_proj:3.236 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1100/2000] tot_loss=2.090 (perp=9.766, rec=0.137), tot_loss_proj:3.239 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1150/2000] tot_loss=2.080 (perp=9.766, rec=0.127), tot_loss_proj:3.244 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1200/2000] tot_loss=2.086 (perp=9.766, rec=0.133), tot_loss_proj:3.243 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1250/2000] tot_loss=2.084 (perp=9.766, rec=0.131), tot_loss_proj:3.235 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1300/2000] tot_loss=2.088 (perp=9.766, rec=0.135), tot_loss_proj:3.240 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
[1350/2000] tot_loss=2.094 (perp=9.766, rec=0.141), tot_loss_proj:3.245 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1400/2000] tot_loss=2.084 (perp=9.766, rec=0.131), tot_loss_proj:3.243 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1450/2000] tot_loss=2.089 (perp=9.766, rec=0.136), tot_loss_proj:3.247 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
[1500/2000] tot_loss=2.081 (perp=9.766, rec=0.128), tot_loss_proj:3.237 [t=0.29s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1550/2000] tot_loss=2.080 (perp=9.766, rec=0.127), tot_loss_proj:3.247 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1600/2000] tot_loss=2.077 (perp=9.766, rec=0.124), tot_loss_proj:3.236 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1650/2000] tot_loss=2.078 (perp=9.766, rec=0.125), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1700/2000] tot_loss=2.092 (perp=9.766, rec=0.138), tot_loss_proj:3.242 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1750/2000] tot_loss=2.091 (perp=9.766, rec=0.138), tot_loss_proj:3.240 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
[1800/2000] tot_loss=2.076 (perp=9.766, rec=0.123), tot_loss_proj:3.242 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1850/2000] tot_loss=2.076 (perp=9.766, rec=0.122), tot_loss_proj:3.244 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1900/2000] tot_loss=2.098 (perp=9.766, rec=0.145), tot_loss_proj:3.242 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1950/2000] tot_loss=2.072 (perp=9.766, rec=0.118), tot_loss_proj:3.250 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[2000/2000] tot_loss=2.088 (perp=9.766, rec=0.135), tot_loss_proj:3.243 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] ecissistic na [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 82.366 | p: 81.773 | r: 83.245
rouge2     | fm: 47.389 | p: 47.129 | r: 47.686
rougeL     | fm: 73.629 | p: 72.973 | r: 74.410
rougeLsum  | fm: 73.547 | p: 72.887 | r: 74.384
r1fm+r2fm = 129.755

input #43 time: 0:10:50 | total time: 8:03:09


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
cosin similarity: -0.8568554930972359 normalized error: 1.74531016791114
cosin similarity: 0.856855493097236 normalized error: 0.5131648958461217
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.8408239056825355 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.5962682946128663 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 1.5329986037727885 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 1.532608173477598 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best rec loss: 1.5271526875466608 for ['[CLS] program jurisdiction earlier mistakes through learning near termhen death blank christianity skeleton besides merton son bikinittle ) eyebrows previous hamption civil antony seed architectural remained lie [SEP]']
[Init] best rec loss: 1.495407174316337 for ['[CLS] reservesdicated friendly sole rurallda counselan signals spec jamie americas foot emigrated tied [MASK] dex comfortdating artillery meditation joinednard readings eve solo ukraine why offspring [SEP]']
[Init] best perm rec loss: 1.4914100898253133 for ['[CLS] artillery [MASK] ukrainedatingnard signals joined sole friendly readings why counsel jamiedicated spec reserves offspring tied dex solo americaslda meditationan foot eve emigrated rural comfort [SEP]']
[Init] best perm rec loss: 1.4901355102475167 for ['[CLS] friendly dexlda signals solo tieddicated offspring ukraine reserves eve footnard meditation rural emigrated americas jamiedating spec readings comfort counsel artillery [MASK]an why sole joined [SEP]']
[Init] best perm rec loss: 1.4877398101619763 for ['[CLS] ukraine jamie friendlydicated readings spec eve tied rural footan dex signals emigrated comfort americas artillery meditation sole joined counsel [MASK] offspringnard reserves sololdadating why [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.650 (perp=11.323, rec=0.385), tot_loss_proj:3.176 [t=0.26s]
prediction: ['[CLS] lost loses editorial text screaming routine fled print rigged shell? apparently dumb mug design commercial coke false verdict paper and planned an allegedly damage ¨ category assignment jerked [SEP]']
[ 100/2000] tot_loss=2.590 (perp=11.440, rec=0.302), tot_loss_proj:3.156 [t=0.27s]
prediction: ['[CLS] lost lost published text screaming routine fled print rigged shelles routine dumb hollywood design routine coke false bowler chronology nor translation an allegedly damage another welles translation paused [SEP]']
[ 150/2000] tot_loss=2.694 (perp=12.074, rec=0.279), tot_loss_proj:3.258 [t=0.26s]
prediction: ['[CLS] was lost routine text gambling routine losttest rigged. is routine dumb hollywood performer routineos false bowler province nor translation the allegedlyort another objective translation afghanistan [SEP]']
[ 200/2000] tot_loss=2.540 (perp=11.587, rec=0.223), tot_loss_proj:3.320 [t=0.25s]
prediction: ['[CLS] is lost routine afterwardsₕ continuous lost it rigged.. routine. hollywood performer routinegos slack bowler. nor translation the palermoort another finals translation disbanded [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.477 (perp=11.420, rec=0.194), tot_loss_proj:3.232 [t=0.26s]
prediction: ['[CLS] been lost routine slackₕ continuous lostification rigged. in routine routine hollywoodfest.gos slack bowler. nor translation the palermoort another張 translationizes [SEP]']
[ 300/2000] tot_loss=2.333 (perp=10.811, rec=0.171), tot_loss_proj:3.133 [t=0.25s]
prediction: ['[CLS] been lost routine slackburgh continuous. ; rigged. in routine routine hollywoodfest. jed slack bowler. nor procedure the palermoort anotherfest translationizes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.204 (perp=10.188, rec=0.167), tot_loss_proj:3.062 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. ; rigged slack in routine routine hollywoodfest.kar. bowler. nor procedure the palermoort another″ translationizes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.173 (perp=10.111, rec=0.151), tot_loss_proj:3.041 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest.kar. bowlerizes thereforealic the palermoort another execution translation. [SEP]']
[ 450/2000] tot_loss=2.172 (perp=10.128, rec=0.147), tot_loss_proj:3.015 [t=0.25s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest.kar. doughizes thereforealic the palermoort another execution translation. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.271 (perp=10.593, rec=0.152), tot_loss_proj:3.206 [t=0.25s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkaralic doughizes therefore. the arabianort another execution translation. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.131 (perp=9.990, rec=0.133), tot_loss_proj:3.044 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkar doughalicizes therefore. the arabianort another execution translation. [SEP]']
[ 600/2000] tot_loss=2.132 (perp=9.990, rec=0.134), tot_loss_proj:3.047 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkar doughalicizes therefore. the arabianort another execution translation. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.075 (perp=9.742, rec=0.127), tot_loss_proj:2.908 [t=0.27s]
prediction: ['[CLS] has lost execution slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkar doughalicizes therefore. the arabianort another routine translation. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.112 (perp=9.918, rec=0.128), tot_loss_proj:2.959 [t=0.26s]
prediction: ['[CLS] has lost execution slack ₍ excessive. the significance slack in routine routine hollywoodfest slackkarartyalicizes therefore. the routine arabianort another translation. [SEP]']
[ 750/2000] tot_loss=2.099 (perp=9.848, rec=0.129), tot_loss_proj:2.967 [t=0.25s]
prediction: ['[CLS] has lost execution slack ₍ excessive. the significance slack in routine routine hollywoodfest slackkarartyalicizes therefore. the routine itsort another translation. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.021 (perp=9.429, rec=0.135), tot_loss_proj:3.011 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ excessive. the significance slack in routine routine hollywoodfest slack couldartyalicizes therefore. the routine its seat another translation. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.216 (perp=10.434, rec=0.130), tot_loss_proj:3.031 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ excessivealic the significance skirt in routine routine hollywoodfest slack couldartyalicizes therefore. the routine slack seat another translation. [SEP]']
[ 900/2000] tot_loss=2.271 (perp=10.755, rec=0.120), tot_loss_proj:3.161 [t=0.27s]
prediction: ['[CLS] has lost slack execution hysteria excessivealic the significance skirt in routine routine hollywoodfest slack couldartyalicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.324 (perp=11.015, rec=0.121), tot_loss_proj:3.188 [t=0.26s]
prediction: ['[CLS] has lost slack execution hysteria excessivealic the significance skirt in routine routine hollywoodfest slack prophetkaralicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.226 (perp=10.474, rec=0.131), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] has lost slack execution hysteria the significance excessivealic skirt in routine routine hollywoodfest slackartykaralicizes therefore. the routine slack seat another translation. [SEP]']
[1050/2000] tot_loss=2.184 (perp=10.320, rec=0.120), tot_loss_proj:2.997 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the significance excessivealic skirt in routine routine hollywoodfest slackartykaralicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.144 (perp=10.121, rec=0.120), tot_loss_proj:2.936 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic skirt in excessive routine routine hollywoodfest slackartykaralicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.209 (perp=10.438, rec=0.121), tot_loss_proj:3.015 [t=0.27s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic excessive in skirt routine routine hollywoodfest slack prophetkaralicizes therefore. the routine slack seat another translation. [SEP]']
[1200/2000] tot_loss=2.155 (perp=10.190, rec=0.117), tot_loss_proj:2.918 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic excessive in skirt routine routine hollywoodfest slack prophet fairlyalicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.106 (perp=9.965, rec=0.113), tot_loss_proj:2.849 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic. in skirt routine routine hollywoodfest slack prophet fairlyalicizes therefore excessive the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.088 (perp=9.902, rec=0.108), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic. in skirt routine routine hollywoodfest routine prophet fairlyalicizes therefore excessive the slack slack seat another translation. [SEP]']
[1350/2000] tot_loss=2.192 (perp=10.350, rec=0.122), tot_loss_proj:2.917 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in tinted routine routine hollywoodfest routine prophet fairlyalicizes therefore excessive the slack slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.022 (perp=9.560, rec=0.110), tot_loss_proj:2.799 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the routine routine hollywoodfest routine prophet fairlyalicizes therefore excessive skirt slack slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.134 (perp=10.052, rec=0.124), tot_loss_proj:2.902 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine prophet racialalicizes therefore excessive another slack slack seat detectives translation. [SEP]']
[1500/2000] tot_loss=2.095 (perp=9.890, rec=0.117), tot_loss_proj:2.850 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine prophet racialalicizes therefore excessive another slack slack seat tinted translation. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.083 (perp=9.828, rec=0.117), tot_loss_proj:2.839 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine racial prophetalicizes therefore excessive another slack slack seat kensington translation. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.086 (perp=9.828, rec=0.120), tot_loss_proj:2.847 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine racial prophetalicizes therefore excessive another slack slack seat kensington translation. [SEP]']
[1650/2000] tot_loss=2.079 (perp=9.828, rec=0.113), tot_loss_proj:2.840 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine racial prophetalicizes therefore excessive another slack slack seat kensington translation. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.071 (perp=9.757, rec=0.120), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophetalicizes therefore excessive another slack slack seat racial translation. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.050 (perp=9.667, rec=0.116), tot_loss_proj:2.788 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore excessive another slack slack seatalic translation. [SEP]']
[1800/2000] tot_loss=2.057 (perp=9.667, rec=0.124), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore excessive another slack slack seatalic translation. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.031 (perp=9.569, rec=0.118), tot_loss_proj:2.760 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore another excessive slack slack seatalic translation. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.012 (perp=9.487, rec=0.115), tot_loss_proj:2.752 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes another therefore excessive slack slack seatalic translation. [SEP]']
[1950/2000] tot_loss=2.008 (perp=9.487, rec=0.110), tot_loss_proj:2.748 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes another therefore excessive slack slack seatalic translation. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.013 (perp=9.475, rec=0.118), tot_loss_proj:2.776 [t=0.29s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the routine which hollywoodfest routine kensington prophet racializes another therefore excessive slack slack seatalic translation. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore another excessive slack slack seatalic translation. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.319 | p: 54.167 | r: 56.522
rouge2     | fm: 13.333 | p: 13.043 | r: 13.636
rougeL     | fm: 34.043 | p: 33.333 | r: 34.783
rougeLsum  | fm: 34.043 | p: 33.333 | r: 34.783
r1fm+r2fm = 68.652

[Aggregate metrics]:
rouge1     | fm: 81.693 | p: 81.080 | r: 82.590
rouge2     | fm: 46.688 | p: 46.464 | r: 46.963
rougeL     | fm: 72.646 | p: 71.986 | r: 73.540
rougeLsum  | fm: 72.659 | p: 72.027 | r: 73.559
r1fm+r2fm = 128.381

input #44 time: 0:11:03 | total time: 8:14:12


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
cosin similarity: -0.8624079044552135 normalized error: 1.7449468372151096
cosin similarity: 0.8624079044552135 normalized error: 0.5109698971810958
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 1.9146515847063736 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 1.6332375251840188 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 1.500359427995984 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 1.2939814832067222 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 1.1644757465174165 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 1.1641417101783367 for ['[CLS] status football whoa joan tree enclosed entrance curtis gentry around few ( military skinlanda single bore v five special letter ku via taste operated2tiv murmured [SEP]']
[Init] best perm rec loss: 1.1631431773277008 for ['[CLS] single gentry tastelanda ( via tree bore few football special entrance status joan murmured whoa letter around v operated enclosed ku fivetiv2 skin curtis military [SEP]']
[Init] best perm rec loss: 1.1629994392654714 for ['[CLS] whoa entrance taste five around letter footballtiv single ku operated2 status skin joan enclosed military tree murmured gentrylanda v ( few bore via curtis special [SEP]']
[Init] best perm rec loss: 1.160602955912381 for ['[CLS] single gentry taste skin status via ku football tree special operated enclosed joantiv2 curtis whoa ( letterlanda military five murmured few around bore entrance v [SEP]']
[Init] best perm rec loss: 1.1604427087402178 for ['[CLS] taste ( gentry special skin tree statuslanda single operated joan whoa aroundtiv football curtis bore few five letter v military2 enclosed ku entrance via murmured [SEP]']
[Init] best perm rec loss: 1.1546550746046425 for ['[CLS] football around v2 murmured special vialanda enclosed skin joan entrance boretiv military letter whoa operated five few gentry single status tree ku taste curtis ( [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.859 (perp=12.294, rec=0.401), tot_loss_proj:3.360 [t=0.28s]
prediction: ["[CLS] ship demoted flipped post overseaser wiring in fifeit australian'trade at mob application an compared - passed display double block grade expogm pamphlet tonight [SEP]"]
[ 100/2000] tot_loss=2.593 (perp=11.321, rec=0.329), tot_loss_proj:3.132 [t=0.28s]
prediction: ["[CLS] trade funin post acte talking infu warlord -'trade than - application an operated - passed airing character block deck expogm agitation tonight [SEP]"]
[ 150/2000] tot_loss=2.544 (perp=11.219, rec=0.300), tot_loss_proj:3.157 [t=0.27s]
prediction: ["[CLS] move funin aspen acte movements infu exercise -'shelf than - on an bought - pass thus character exercise shootboardgp exercise tonight [SEP]"]
[ 200/2000] tot_loss=2.582 (perp=11.608, rec=0.261), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] shelf funin aspen act - movements -fu exercise - - shelf than - - - shelf - otherwise thus character exercisemm exercise than exercise than [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.266 (perp=10.193, rec=0.228), tot_loss_proj:3.046 [t=0.27s]
prediction: ['[CLS] shelf fornin aspen bow - movements -mm bow - - shelf than this - - shelf - otherwise - character exercisemm exercisegp exercise pursuing [SEP]']
[ 300/2000] tot_loss=2.238 (perp=10.241, rec=0.190), tot_loss_proj:3.104 [t=0.25s]
prediction: ['[CLS] shelf fornin aspen bow - movements -mm bow - - shelf than this - - shelf - usually - character exercisemm exercisegp exercise pursuing [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.232 (perp=10.240, rec=0.184), tot_loss_proj:3.096 [t=0.25s]
prediction: ['[CLS] this innin aspen bow - movements -mm bow - - shelf than shelf - - shelf -ick - crime exercisemm exercisegp exercise pursuing [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.310 (perp=10.458, rec=0.218), tot_loss_proj:2.898 [t=0.26s]
prediction: ['[CLS] this funin - bow - movementselmm bow - / shelf than shelf - the shelf -ick - crime shootmm exercisegp exercise pursuing [SEP]']
[ 450/2000] tot_loss=2.445 (perp=11.339, rec=0.177), tot_loss_proj:3.257 [t=0.26s]
prediction: ['[CLS] this ginin - bow - movementselmm bow - / shelf than crime - on shelf -ick - crime shootmm exercisegp exercise pursued [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.204 (perp=10.180, rec=0.168), tot_loss_proj:3.093 [t=0.25s]
prediction: ['[CLS] this gi turning - bow - movements exercisemm bow - / shelf than crime - on shelf -ick - crime dramamm - connolly exercise pursued [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.149 (perp=9.974, rec=0.154), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS] this gi snapping - bow - movements exercisemm bow - than shelf / drama long on shelf -ick - crime dramamm - connolly exercise pursued [SEP]']
[ 600/2000] tot_loss=2.170 (perp=10.122, rec=0.146), tot_loss_proj:2.938 [t=0.26s]
prediction: ['[CLS] this gi snapping - bow - movements exercisemm bow - than shelf / drama long on shelf -ick - crime gimm - connolly exercise pursue [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.091 (perp=9.729, rec=0.146), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / drama long snapping shelf -ick - crime gimm - connolly exercise pursue [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.039 (perp=9.509, rec=0.137), tot_loss_proj:2.873 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / exercise long snapping shelf -ick - crime gimm - connolly drama pursuing [SEP]']
[ 750/2000] tot_loss=2.037 (perp=9.509, rec=0.135), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / exercise long snapping shelf -ick - crime gimm - connolly drama pursuing [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.999 (perp=9.317, rec=0.135), tot_loss_proj:2.826 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / exercise long shelf snapping -ick - crime gimm - connolly drama dramas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.952 (perp=9.076, rec=0.137), tot_loss_proj:2.653 [t=0.25s]
prediction: ['[CLS] this gi on - bow - movements exercise shelf bow - than shelf ( exercise longmm snapping -ick - crime gimmick connolly drama dramas [SEP]']
[ 900/2000] tot_loss=1.960 (perp=9.141, rec=0.131), tot_loss_proj:2.672 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercise shelf bow - than shelf ( exercise longmm snapping -ick - crime gimmick connolly drama pursuing [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.860 (perp=8.654, rec=0.129), tot_loss_proj:2.583 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf connolly exercise longmm snapping -ick - crime gimmick / drama pursuing [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.852 (perp=8.600, rec=0.132), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf dramas exercise longmm snapping -ick - crime gimmick / drama connolly [SEP]']
[1050/2000] tot_loss=1.843 (perp=8.562, rec=0.131), tot_loss_proj:2.545 [t=0.25s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ exercise longmm snapping -ick - crime gimmick / drama connolly [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.821 (perp=8.492, rec=0.122), tot_loss_proj:2.566 [t=0.25s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ shoot longmmick - snapping - crime gimmick / drama connolly [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.780 (perp=8.251, rec=0.130), tot_loss_proj:2.584 [t=0.25s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ shoot longmmick - - snapping crime gimmick / drama connolly [SEP]']
[1200/2000] tot_loss=1.775 (perp=8.251, rec=0.125), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ shoot longmmick - - snapping crime gimmick / drama connolly [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.684 (perp=7.787, rec=0.126), tot_loss_proj:2.404 [t=0.26s]
prediction: ['[CLS] this long on - bow - movements exercise, bow - than shelf½ shoot gimmick - - snapping crime gimmick / drama connolly [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.675 (perp=7.714, rec=0.132), tot_loss_proj:2.337 [t=0.25s]
prediction: ['[CLS] this long on - bow - movements exercise, bow - than shelf½ - shoot gimmick - hear crime gimmick / drama connolly [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.673, rec=0.127), tot_loss_proj:2.303 [t=0.28s]
prediction: ['[CLS] this long on - bow - movements exercise, bow - than shelf½ - shoot gimmick - hear crime gimmick / drama villiers [SEP]']
Attempt swap
[1400/2000] tot_loss=1.715 (perp=7.966, rec=0.121), tot_loss_proj:2.378 [t=0.25s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick / drama villiers [SEP]']
Attempt swap
[1450/2000] tot_loss=1.670 (perp=7.762, rec=0.117), tot_loss_proj:2.348 [t=0.26s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
[1500/2000] tot_loss=1.674 (perp=7.762, rec=0.122), tot_loss_proj:2.348 [t=0.26s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.762, rec=0.119), tot_loss_proj:2.350 [t=0.26s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.637 (perp=7.551, rec=0.127), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
[1650/2000] tot_loss=1.633 (perp=7.551, rec=0.123), tot_loss_proj:2.339 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
[1700/2000] tot_loss=1.633 (perp=7.551, rec=0.123), tot_loss_proj:2.340 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
[1750/2000] tot_loss=1.662 (perp=7.700, rec=0.122), tot_loss_proj:2.318 [t=0.28s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]']
[1800/2000] tot_loss=1.660 (perp=7.700, rec=0.121), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]']
Attempt swap
[1850/2000] tot_loss=1.657 (perp=7.700, rec=0.117), tot_loss_proj:2.322 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.626 (perp=7.522, rec=0.122), tot_loss_proj:2.279 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise, crime - than shelf long - shoot gimmick - hearel gimmick - dramatock [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.522, rec=0.118), tot_loss_proj:2.271 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise, crime - than shelf long - shoot gimmick - hearel gimmick - dramatock [SEP]']
Attempt swap
[2000/2000] tot_loss=1.627 (perp=7.522, rec=0.122), tot_loss_proj:2.274 [t=0.25s]
prediction: ['[CLS] this½ on - bow - movements exercise, crime - than shelf long - shoot gimmick - hearel gimmick - dramatock [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.857 | p: 64.706 | r: 61.111
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 41.176 | r: 38.889
rougeLsum  | fm: 40.000 | p: 41.176 | r: 38.889
r1fm+r2fm = 62.857

[Aggregate metrics]:
rouge1     | fm: 81.285 | p: 80.674 | r: 82.092
rouge2     | fm: 45.639 | p: 45.324 | r: 45.899
rougeL     | fm: 72.074 | p: 71.433 | r: 72.863
rougeLsum  | fm: 71.980 | p: 71.317 | r: 72.836
r1fm+r2fm = 126.924

input #45 time: 0:10:59 | total time: 8:25:12


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
cosin similarity: -0.6528367566872437 normalized error: 1.646257550301846
cosin similarity: 0.6528367566872438 normalized error: 0.6467475105930727
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9287487864494324 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9002854824066162 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.8919875025749207 for ['[CLS] worldwide fork packaging touched might fantastic [SEP]']
[Init] best rec loss: 0.8221158385276794 for ['[CLS] sank including privately heritage surfaced falcon [SEP]']
[Init] best rec loss: 0.808422327041626 for ['[CLS] ga system cody because stove democratic [SEP]']
[Init] best perm rec loss: 0.8050276041030884 for ['[CLS] ga cody because stove system democratic [SEP]']
[Init] best perm rec loss: 0.8041706681251526 for ['[CLS] system ga cody stove because democratic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.360 (perp=10.829, rec=0.195), tot_loss_proj:2.531 [t=0.27s]
prediction: ['[CLS] slick visually visually slick slick striking [SEP]']
[ 100/2000] tot_loss=2.436 (perp=11.512, rec=0.134), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] slick visually visually slick staged striking [SEP]']
[ 150/2000] tot_loss=2.404 (perp=11.524, rec=0.099), tot_loss_proj:2.572 [t=0.26s]
prediction: ['[CLS]ly visually and slick staged striking [SEP]']
[ 200/2000] tot_loss=2.378 (perp=11.524, rec=0.073), tot_loss_proj:2.572 [t=0.25s]
prediction: ['[CLS]ly visually and slick staged striking [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.710 (perp=8.154, rec=0.079), tot_loss_proj:1.870 [t=0.25s]
prediction: ['[CLS]ly staged and slick visually striking [SEP]']
[ 300/2000] tot_loss=1.698 (perp=8.154, rec=0.067), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS]ly staged and slick visually striking [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.387 (perp=6.580, rec=0.071), tot_loss_proj:1.459 [t=0.28s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.374 (perp=6.580, rec=0.058), tot_loss_proj:1.467 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 450/2000] tot_loss=1.386 (perp=6.580, rec=0.070), tot_loss_proj:1.474 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.379 (perp=6.580, rec=0.063), tot_loss_proj:1.466 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.379 (perp=6.580, rec=0.063), tot_loss_proj:1.469 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 600/2000] tot_loss=1.379 (perp=6.580, rec=0.063), tot_loss_proj:1.463 [t=0.29s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.375 (perp=6.580, rec=0.059), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.391 (perp=6.580, rec=0.075), tot_loss_proj:1.468 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 750/2000] tot_loss=1.383 (perp=6.580, rec=0.067), tot_loss_proj:1.458 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.385 (perp=6.580, rec=0.069), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.385 (perp=6.580, rec=0.069), tot_loss_proj:1.460 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 900/2000] tot_loss=1.391 (perp=6.580, rec=0.075), tot_loss_proj:1.474 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.381 (perp=6.580, rec=0.065), tot_loss_proj:1.456 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1000/2000] tot_loss=1.379 (perp=6.580, rec=0.063), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1050/2000] tot_loss=1.385 (perp=6.580, rec=0.069), tot_loss_proj:1.476 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1100/2000] tot_loss=1.372 (perp=6.580, rec=0.056), tot_loss_proj:1.466 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.383 (perp=6.580, rec=0.067), tot_loss_proj:1.475 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1200/2000] tot_loss=1.367 (perp=6.580, rec=0.051), tot_loss_proj:1.463 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1250/2000] tot_loss=1.385 (perp=6.580, rec=0.069), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.377 (perp=6.580, rec=0.061), tot_loss_proj:1.463 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1350/2000] tot_loss=1.380 (perp=6.580, rec=0.064), tot_loss_proj:1.462 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.383 (perp=6.580, rec=0.067), tot_loss_proj:1.463 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.383 (perp=6.580, rec=0.067), tot_loss_proj:1.465 [t=0.27s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1500/2000] tot_loss=1.385 (perp=6.580, rec=0.069), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.373 (perp=6.580, rec=0.057), tot_loss_proj:1.459 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1600/2000] tot_loss=1.380 (perp=6.580, rec=0.064), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1650/2000] tot_loss=1.386 (perp=6.580, rec=0.070), tot_loss_proj:1.472 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.376 (perp=6.580, rec=0.060), tot_loss_proj:1.463 [t=0.26s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.369 (perp=6.580, rec=0.053), tot_loss_proj:1.466 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1800/2000] tot_loss=1.367 (perp=6.580, rec=0.051), tot_loss_proj:1.467 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.378 (perp=6.580, rec=0.062), tot_loss_proj:1.468 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.378 (perp=6.580, rec=0.062), tot_loss_proj:1.459 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1950/2000] tot_loss=1.373 (perp=6.580, rec=0.057), tot_loss_proj:1.472 [t=0.24s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.375 (perp=6.580, rec=0.059), tot_loss_proj:1.468 [t=0.25s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] slickly staged and visually striking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 81.688 | p: 81.138 | r: 82.491
rouge2     | fm: 45.442 | p: 45.267 | r: 45.737
rougeL     | fm: 71.661 | p: 71.139 | r: 72.498
rougeLsum  | fm: 71.603 | p: 71.018 | r: 72.341
r1fm+r2fm = 127.129

input #46 time: 0:10:49 | total time: 8:36:02


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
cosin similarity: -0.878594209824801 normalized error: 1.6392166029226003
cosin similarity: 0.878594209824801 normalized error: 0.552143322537014
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 1.3327846124508835 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 1.3039728765500995 for ['[CLS] bass settlement elder [SEP]']
[Init] best rec loss: 1.2958279178759948 for ['[CLS]zong ruiz its [SEP]']
[Init] best perm rec loss: 1.2917188398867314 for ['[CLS] itszong ruiz [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.988 (perp=12.798, rec=0.429), tot_loss_proj:3.833 [t=0.25s]
prediction: ['[CLS] transparent chargetropical [SEP]']
[ 100/2000] tot_loss=2.853 (perp=12.775, rec=0.298), tot_loss_proj:3.578 [t=0.26s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 150/2000] tot_loss=2.796 (perp=12.775, rec=0.241), tot_loss_proj:3.573 [t=0.26s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 200/2000] tot_loss=2.762 (perp=12.775, rec=0.207), tot_loss_proj:3.567 [t=0.25s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.734 (perp=12.775, rec=0.179), tot_loss_proj:3.565 [t=0.27s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 300/2000] tot_loss=2.731 (perp=12.775, rec=0.175), tot_loss_proj:3.568 [t=0.26s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.705 (perp=12.775, rec=0.150), tot_loss_proj:3.571 [t=0.26s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.693 (perp=12.775, rec=0.138), tot_loss_proj:3.574 [t=0.25s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 450/2000] tot_loss=2.618 (perp=12.355, rec=0.147), tot_loss_proj:3.492 [t=0.25s]
prediction: ['[CLS]らright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.605 (perp=12.355, rec=0.134), tot_loss_proj:3.489 [t=0.25s]
prediction: ['[CLS]らright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.563 (perp=12.153, rec=0.133), tot_loss_proj:3.254 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[ 600/2000] tot_loss=2.569 (perp=12.153, rec=0.139), tot_loss_proj:3.255 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.560 (perp=12.153, rec=0.130), tot_loss_proj:3.254 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.561 (perp=12.153, rec=0.130), tot_loss_proj:3.258 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[ 750/2000] tot_loss=2.547 (perp=12.153, rec=0.116), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.549 (perp=12.153, rec=0.118), tot_loss_proj:3.263 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.557 (perp=12.153, rec=0.126), tot_loss_proj:3.260 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[ 900/2000] tot_loss=2.560 (perp=12.153, rec=0.129), tot_loss_proj:3.264 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.552 (perp=12.153, rec=0.122), tot_loss_proj:3.264 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=2.555 (perp=12.153, rec=0.125), tot_loss_proj:3.263 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1050/2000] tot_loss=2.556 (perp=12.153, rec=0.126), tot_loss_proj:3.257 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.554 (perp=12.153, rec=0.123), tot_loss_proj:3.252 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.552 (perp=12.153, rec=0.121), tot_loss_proj:3.268 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1200/2000] tot_loss=2.552 (perp=12.153, rec=0.122), tot_loss_proj:3.263 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.553 (perp=12.153, rec=0.123), tot_loss_proj:3.257 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.557 (perp=12.153, rec=0.126), tot_loss_proj:3.259 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1350/2000] tot_loss=2.537 (perp=12.153, rec=0.107), tot_loss_proj:3.260 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.543 (perp=12.153, rec=0.112), tot_loss_proj:3.263 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.550 (perp=12.153, rec=0.120), tot_loss_proj:3.260 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1500/2000] tot_loss=2.547 (perp=12.153, rec=0.117), tot_loss_proj:3.259 [t=0.27s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.550 (perp=12.153, rec=0.120), tot_loss_proj:3.256 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.547 (perp=12.153, rec=0.116), tot_loss_proj:3.261 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1650/2000] tot_loss=2.546 (perp=12.153, rec=0.115), tot_loss_proj:3.262 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.554 (perp=12.153, rec=0.124), tot_loss_proj:3.264 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=2.546 (perp=12.153, rec=0.116), tot_loss_proj:3.262 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1800/2000] tot_loss=2.551 (perp=12.153, rec=0.120), tot_loss_proj:3.264 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.546 (perp=12.153, rec=0.116), tot_loss_proj:3.252 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.554 (perp=12.153, rec=0.124), tot_loss_proj:3.259 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1950/2000] tot_loss=2.551 (perp=12.153, rec=0.121), tot_loss_proj:3.261 [t=0.26s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=2.544 (perp=12.153, rec=0.113), tot_loss_proj:3.257 [t=0.25s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] cunninghamright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 81.523 | p: 81.024 | r: 82.362
rouge2     | fm: 45.140 | p: 44.881 | r: 45.342
rougeL     | fm: 71.827 | p: 71.343 | r: 72.654
rougeLsum  | fm: 71.600 | p: 71.183 | r: 72.421
r1fm+r2fm = 126.664

input #47 time: 0:10:48 | total time: 8:46:51


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
cosin similarity: -0.6309706475604857 normalized error: 1.5825054937679657
cosin similarity: 0.6309706475604856 normalized error: 0.6756827814320959
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8032118678092957 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8015367984771729 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.7995321750640869 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.7967418432235718 for ['[CLS] don link wb sounding [SEP]']
[Init] best rec loss: 0.7277597784996033 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.6839700937271118 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.682114839553833 for ['[CLS]dinetute runs graveyard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.661 (perp=12.137, rec=0.234), tot_loss_proj:2.872 [t=0.25s]
prediction: ['[CLS] rotting rottingbell rotting [SEP]']
[ 100/2000] tot_loss=2.973 (perp=14.357, rec=0.102), tot_loss_proj:3.124 [t=0.27s]
prediction: ['[CLS] rotting underbell under [SEP]']
[ 150/2000] tot_loss=1.491 (perp=7.108, rec=0.069), tot_loss_proj:1.493 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 200/2000] tot_loss=1.479 (perp=7.108, rec=0.058), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.488 (perp=7.108, rec=0.066), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.488 (perp=7.108, rec=0.067), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.468 (perp=7.108, rec=0.046), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.483 (perp=7.108, rec=0.061), tot_loss_proj:1.494 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.474 (perp=7.108, rec=0.052), tot_loss_proj:1.489 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.488 (perp=7.108, rec=0.066), tot_loss_proj:1.483 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.480 (perp=7.108, rec=0.059), tot_loss_proj:1.483 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.484 (perp=7.108, rec=0.062), tot_loss_proj:1.484 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.485 (perp=7.108, rec=0.063), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.475 (perp=7.108, rec=0.053), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.495 (perp=7.108, rec=0.074), tot_loss_proj:1.477 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.485 (perp=7.108, rec=0.064), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.480 (perp=7.108, rec=0.058), tot_loss_proj:1.484 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.475 (perp=7.108, rec=0.053), tot_loss_proj:1.497 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.481 (perp=7.108, rec=0.060), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.481 (perp=7.108, rec=0.059), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.474 (perp=7.108, rec=0.052), tot_loss_proj:1.489 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.482 (perp=7.108, rec=0.060), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.498 (perp=7.108, rec=0.076), tot_loss_proj:1.484 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.483 (perp=7.108, rec=0.061), tot_loss_proj:1.483 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.479 (perp=7.108, rec=0.057), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.480 (perp=7.108, rec=0.058), tot_loss_proj:1.481 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.476 (perp=7.108, rec=0.054), tot_loss_proj:1.482 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.488 (perp=7.108, rec=0.066), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.470 (perp=7.108, rec=0.049), tot_loss_proj:1.477 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.479 (perp=7.108, rec=0.057), tot_loss_proj:1.478 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.477 (perp=7.108, rec=0.055), tot_loss_proj:1.490 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.489 (perp=7.108, rec=0.067), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.485 (perp=7.108, rec=0.063), tot_loss_proj:1.481 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.476 (perp=7.108, rec=0.054), tot_loss_proj:1.484 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.479 (perp=7.108, rec=0.058), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.485 (perp=7.108, rec=0.063), tot_loss_proj:1.494 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.482 (perp=7.108, rec=0.061), tot_loss_proj:1.494 [t=0.27s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.480 (perp=7.108, rec=0.059), tot_loss_proj:1.474 [t=0.28s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.483 (perp=7.108, rec=0.061), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=7.108, rec=0.055), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.961 | p: 81.494 | r: 82.761
rouge2     | fm: 45.967 | p: 45.779 | r: 46.292
rougeL     | fm: 72.236 | p: 71.754 | r: 73.039
rougeLsum  | fm: 72.298 | p: 71.737 | r: 73.038
r1fm+r2fm = 127.928

input #48 time: 0:10:44 | total time: 8:57:35


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
cosin similarity: 0.9683217036303956 normalized error: 0.4534142344774211
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 1.4778312589764235 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 1.4136233842593589 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 1.3607508643839044 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 1.297533454500428 for ['[CLS] chair assured dick fine chance household every expect boat couple freestyleerly [SEP]']
[Init] best perm rec loss: 1.2957378183063728 for ['[CLS] fine assured chair every freestyle dick boat couple chanceerly expect household [SEP]']
[Init] best perm rec loss: 1.2940180804195136 for ['[CLS] couple expect dick boat fine assured household chairerly chance every freestyle [SEP]']
[Init] best perm rec loss: 1.2878868872315852 for ['[CLS] expect household couple boat dickerly assured fine chair every freestyle chance [SEP]']
[Init] best perm rec loss: 1.2867992763169107 for ['[CLS] boat household chair dick couple fine chance freestyleerly expect every assured [SEP]']
[Init] best perm rec loss: 1.2865862604053442 for ['[CLS] chance every couple dick expect boaterly household freestyle chair assured fine [SEP]']
[Init] best perm rec loss: 1.2860970655053672 for ['[CLS] assured couple dick expecterly every household freestyle chair chance fine boat [SEP]']
[Init] best perm rec loss: 1.285564383519302 for ['[CLS] dick chance freestyle everyerly couple boat household fine expect chair assured [SEP]']
[Init] best perm rec loss: 1.2848470383984811 for ['[CLS] fine chair household assured boat expect every freestyleerly chance dick couple [SEP]']
[Init] best perm rec loss: 1.2833863283344924 for ['[CLS] chair dick household assured chance every boat freestyleerly expect fine couple [SEP]']
[Init] best perm rec loss: 1.278603297321006 for ['[CLS] chair assured freestyle boat expecterly every household couple dick fine chance [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.814 (perp=12.076, rec=0.398), tot_loss_proj:3.451 [t=0.28s]
prediction: ['[CLS] should clarksonold knew than blacks females be reduced suspect single care [SEP]']
[ 100/2000] tot_loss=2.589 (perp=11.443, rec=0.300), tot_loss_proj:3.345 [t=0.28s]
prediction: ['[CLS] could femaleold less contemptgging female be species be single instance [SEP]']
[ 150/2000] tot_loss=2.538 (perp=11.437, rec=0.250), tot_loss_proj:3.232 [t=0.28s]
prediction: ['[CLS] could female fitzgerald more contemptuous female be species be single contempt [SEP]']
[ 200/2000] tot_loss=2.480 (perp=11.293, rec=0.221), tot_loss_proj:3.158 [t=0.29s]
prediction: ['[CLS] could population fitzgerald more contemptuous female be least be single contempt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.155 (perp=9.911, rec=0.173), tot_loss_proj:3.010 [t=0.29s]
prediction: ['[CLS] possibly population. more contemptuous single female least be single contempt [SEP]']
[ 300/2000] tot_loss=2.225 (perp=10.351, rec=0.154), tot_loss_proj:3.118 [t=0.29s]
prediction: ['[CLS] possibly population. more contemptuous single female mira be single contempt [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.134 (perp=9.904, rec=0.154), tot_loss_proj:2.962 [t=0.25s]
prediction: ['[CLS] possiblyive. more contemptuous single female daughter be single population [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.040 (perp=9.445, rec=0.151), tot_loss_proj:2.804 [t=0.25s]
prediction: ['[CLS] possiblyive be. more contemptuous single female newly single population [SEP]']
[ 450/2000] tot_loss=2.011 (perp=9.329, rec=0.146), tot_loss_proj:2.851 [t=0.25s]
prediction: ['[CLS] possibly contempt be. more contemptuous single female newly single population [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.929 (perp=8.968, rec=0.136), tot_loss_proj:2.817 [t=0.25s]
prediction: ['[CLS] possibly be be. more contemptuous single female newly single population [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.886 (perp=8.722, rec=0.142), tot_loss_proj:2.612 [t=0.27s]
prediction: ['[CLS] possibly be be more contemptuous. single female newly disappearance population [SEP]']
[ 600/2000] tot_loss=1.878 (perp=8.713, rec=0.135), tot_loss_proj:2.637 [t=0.25s]
prediction: ['[CLS] possibly be be more contemptuous. single female daughter disappearance population [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.872 (perp=8.713, rec=0.130), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS] possibly be be more contemptuous. single female daughter disappearance population [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.849 (perp=8.584, rec=0.132), tot_loss_proj:2.699 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughter disappearance population [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.402, rec=0.116), tot_loss_proj:2.547 [t=0.24s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.802 (perp=8.402, rec=0.121), tot_loss_proj:2.545 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.804 (perp=8.402, rec=0.123), tot_loss_proj:2.550 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[ 900/2000] tot_loss=1.803 (perp=8.402, rec=0.122), tot_loss_proj:2.547 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.786 (perp=8.402, rec=0.106), tot_loss_proj:2.546 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.792 (perp=8.402, rec=0.111), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1050/2000] tot_loss=1.795 (perp=8.402, rec=0.114), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.402, rec=0.113), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.790 (perp=8.402, rec=0.109), tot_loss_proj:2.545 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1200/2000] tot_loss=1.792 (perp=8.402, rec=0.112), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.791 (perp=8.402, rec=0.110), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1300/2000] tot_loss=1.791 (perp=8.402, rec=0.111), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1350/2000] tot_loss=1.788 (perp=8.402, rec=0.107), tot_loss_proj:2.551 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.789 (perp=8.402, rec=0.109), tot_loss_proj:2.543 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.794 (perp=8.402, rec=0.114), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.402, rec=0.114), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.872 (perp=8.772, rec=0.118), tot_loss_proj:2.607 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. single female newlyworm population [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.756 (perp=8.249, rec=0.106), tot_loss_proj:2.506 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
[1650/2000] tot_loss=1.762 (perp=8.249, rec=0.112), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.757 (perp=8.249, rec=0.107), tot_loss_proj:2.510 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.767 (perp=8.249, rec=0.117), tot_loss_proj:2.502 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
[1800/2000] tot_loss=1.757 (perp=8.249, rec=0.108), tot_loss_proj:2.507 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=8.249, rec=0.109), tot_loss_proj:2.505 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=8.249, rec=0.110), tot_loss_proj:2.509 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.249, rec=0.121), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.755 (perp=8.249, rec=0.105), tot_loss_proj:2.508 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] be possibly be more contemptuous. single female newlyworm population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 81.818 | r: 75.000
rouge2     | fm: 47.619 | p: 50.000 | r: 45.455
rougeL     | fm: 78.261 | p: 81.818 | r: 75.000
rougeLsum  | fm: 78.261 | p: 81.818 | r: 75.000
r1fm+r2fm = 125.880

[Aggregate metrics]:
rouge1     | fm: 81.890 | p: 81.455 | r: 82.569
rouge2     | fm: 46.221 | p: 46.046 | r: 46.422
rougeL     | fm: 72.321 | p: 71.868 | r: 73.058
rougeLsum  | fm: 72.470 | p: 71.964 | r: 73.102
r1fm+r2fm = 128.111

input #49 time: 0:11:05 | total time: 9:08:41


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
cosin similarity: 0.9451105335183868 normalized error: 0.508965433353086
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 1.7447391229628995 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 1.5633844270276005 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 1.5250435738473378 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 1.4189065270930936 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best perm rec loss: 1.4185997024513828 for ['[CLS] associated fueled trustok rama sq napkin gall unit [SEP]']
[Init] best perm rec loss: 1.412301089326974 for ['[CLS]ok gall napkin associated fueled sq trust unit rama [SEP]']
[Init] best perm rec loss: 1.4095784306625545 for ['[CLS] gall sq napkin trust fueled unit ramaok associated [SEP]']
[Init] best perm rec loss: 1.4041040650997367 for ['[CLS] napkinok trust unit gall fueled rama sq associated [SEP]']
[Init] best perm rec loss: 1.4040456915436497 for ['[CLS] trustok fueled napkin gall sq unit rama associated [SEP]']
[Init] best perm rec loss: 1.4037055539535581 for ['[CLS] associated sq trust napkinok unit rama gall fueled [SEP]']
[Init] best perm rec loss: 1.4017938043464744 for ['[CLS] napkin trust sq gallok associated unit rama fueled [SEP]']
[Init] best perm rec loss: 1.3994468356968173 for ['[CLS] associated trust unit gall fueled napkinok sq rama [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.035 (perp=12.753, rec=0.484), tot_loss_proj:4.249 [t=0.25s]
prediction: ['[CLS] ` disdain palmer = beside among marie wonderful stupid [SEP]']
[ 100/2000] tot_loss=3.053 (perp=13.233, rec=0.407), tot_loss_proj:4.076 [t=0.27s]
prediction: ['[CLS] ` as upper twice switch merely isabelle clever confused [SEP]']
[ 150/2000] tot_loss=3.166 (perp=13.961, rec=0.374), tot_loss_proj:4.027 [t=0.25s]
prediction: ['[CLS] ` as upper byeer already remy clever voluntary [SEP]']
[ 200/2000] tot_loss=2.590 (perp=11.385, rec=0.313), tot_loss_proj:3.379 [t=0.25s]
prediction: ['[CLS] ` as english byieg almost remy clever half [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.388 (perp=10.497, rec=0.288), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] ` asˈ by english almost andre clever half [SEP]']
[ 300/2000] tot_loss=2.734 (perp=12.226, rec=0.289), tot_loss_proj:3.591 [t=0.25s]
prediction: ['[CLS] ` (asurable by english almost andre clever half [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.152 (perp=9.424, rec=0.267), tot_loss_proj:2.954 [t=0.26s]
prediction: ['[CLS] ` call by clever what by english almost half [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.997 (perp=8.774, rec=0.242), tot_loss_proj:3.293 [t=0.25s]
prediction: ['[CLS] ` what by clever call by english almost half [SEP]']
[ 450/2000] tot_loss=1.970 (perp=8.774, rec=0.215), tot_loss_proj:3.295 [t=0.25s]
prediction: ['[CLS] ` what by clever call by english almost half [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.898 (perp=8.414, rec=0.215), tot_loss_proj:3.192 [t=0.27s]
prediction: ['[CLS] ` by what clever call by english almost half [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.860 (perp=8.414, rec=0.177), tot_loss_proj:3.195 [t=0.25s]
prediction: ['[CLS] ` by what clever call by english almost half [SEP]']
[ 600/2000] tot_loss=1.844 (perp=8.414, rec=0.161), tot_loss_proj:3.197 [t=0.25s]
prediction: ['[CLS] ` by what clever call by english almost half [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.967 (perp=9.061, rec=0.155), tot_loss_proj:3.240 [t=0.26s]
prediction: ['[CLS] ` by what clever call by english do half [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.057 (perp=9.524, rec=0.152), tot_loss_proj:3.290 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[ 750/2000] tot_loss=2.030 (perp=9.524, rec=0.125), tot_loss_proj:3.282 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.022 (perp=9.524, rec=0.117), tot_loss_proj:3.282 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.014 (perp=9.524, rec=0.109), tot_loss_proj:3.285 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[ 900/2000] tot_loss=2.014 (perp=9.524, rec=0.110), tot_loss_proj:3.279 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.010 (perp=9.524, rec=0.105), tot_loss_proj:3.282 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1000/2000] tot_loss=2.008 (perp=9.524, rec=0.103), tot_loss_proj:3.285 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1050/2000] tot_loss=2.010 (perp=9.524, rec=0.105), tot_loss_proj:3.279 [t=0.29s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1100/2000] tot_loss=2.002 (perp=9.524, rec=0.097), tot_loss_proj:3.282 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1150/2000] tot_loss=2.000 (perp=9.524, rec=0.095), tot_loss_proj:3.281 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1200/2000] tot_loss=2.009 (perp=9.524, rec=0.104), tot_loss_proj:3.281 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1250/2000] tot_loss=2.000 (perp=9.524, rec=0.095), tot_loss_proj:3.275 [t=0.27s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1300/2000] tot_loss=2.000 (perp=9.524, rec=0.096), tot_loss_proj:3.281 [t=0.24s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1350/2000] tot_loss=2.002 (perp=9.524, rec=0.097), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1400/2000] tot_loss=2.001 (perp=9.524, rec=0.096), tot_loss_proj:3.283 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1450/2000] tot_loss=2.001 (perp=9.524, rec=0.096), tot_loss_proj:3.279 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1500/2000] tot_loss=1.994 (perp=9.524, rec=0.090), tot_loss_proj:3.281 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.983 (perp=9.524, rec=0.078), tot_loss_proj:3.283 [t=0.27s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.998 (perp=9.524, rec=0.094), tot_loss_proj:3.275 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1650/2000] tot_loss=2.000 (perp=9.524, rec=0.095), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.991 (perp=9.524, rec=0.087), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.991 (perp=9.524, rec=0.086), tot_loss_proj:3.280 [t=0.24s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1800/2000] tot_loss=1.990 (perp=9.524, rec=0.085), tot_loss_proj:3.273 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.991 (perp=9.524, rec=0.086), tot_loss_proj:3.280 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.998 (perp=9.524, rec=0.094), tot_loss_proj:3.282 [t=0.28s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1950/2000] tot_loss=1.993 (perp=9.524, rec=0.088), tot_loss_proj:3.278 [t=0.25s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=9.524, rec=0.086), tot_loss_proj:3.279 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] too ` what clever call by english do half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 101.111

[Aggregate metrics]:
rouge1     | fm: 82.057 | p: 81.680 | r: 82.758
rouge2     | fm: 45.523 | p: 45.319 | r: 45.727
rougeL     | fm: 72.138 | p: 71.681 | r: 72.771
rougeLsum  | fm: 72.163 | p: 71.664 | r: 72.817
r1fm+r2fm = 127.580

input #50 time: 0:10:50 | total time: 9:19:32


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
cosin similarity: -0.9214147204321703 normalized error: 1.6234518397518047
cosin similarity: 0.9214147204321702 normalized error: 0.5471154596691675
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 1.6132520794545706 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 1.3670916137976665 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 1.3646106984125925 for ['[CLS] openmes sections shakespeare power? host cuba bonn depends [SEP]']
[Init] best rec loss: 1.3611530242162084 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 1.338883572473704 for ['[CLS] nationals offense - vaguely world justine domesticished majorage [SEP]']
[Init] best rec loss: 1.3212501357510134 for ['[CLS] termination musical guardaur chief electric oxford compilationrch sensor [SEP]']
[Init] best rec loss: 1.3056688377467667 for ['[CLS] political breadction sydney less nothin rican roll color classified [SEP]']
[Init] best rec loss: 1.3029854955057565 for ['[CLS]! marathi cot a wipe ski seniorstered studiolizer [SEP]']
[Init] best rec loss: 1.2765522592121463 for ['[CLS] of deal formula without replace demonstration green driver practice edition [SEP]']
[Init] best rec loss: 1.252414587965134 for ['[CLS] include plants hole abuse especially multiple fingers & since accepting [SEP]']
[Init] best perm rec loss: 1.2465105555631277 for ['[CLS] accepting hole multiple since abuse especially plants & include fingers [SEP]']
[Init] best perm rec loss: 1.246167531158738 for ['[CLS] multiple hole accepting & especially since fingers abuse plants include [SEP]']
[Init] best perm rec loss: 1.2458765469618287 for ['[CLS] since & hole plants especially abuse multiple include fingers accepting [SEP]']
[Init] best perm rec loss: 1.2451012068796579 for ['[CLS] since plants especially abuse & hole multiple fingers include accepting [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.585 (perp=12.701, rec=1.044), tot_loss_proj:4.225 [t=0.25s]
prediction: ['[CLS] luke praise finally combination nascar gable healing. stood... [SEP]']
[ 100/2000] tot_loss=3.202 (perp=11.875, rec=0.827), tot_loss_proj:3.903 [t=0.26s]
prediction: ['[CLS] matter commentary arguably feel zombie augustus wisdom. stood good [SEP]']
[ 150/2000] tot_loss=3.102 (perp=11.894, rec=0.724), tot_loss_proj:4.075 [t=0.26s]
prediction: ['[CLS] written say arguably points zombie gram wisdom. stood brave [SEP]']
[ 200/2000] tot_loss=3.288 (perp=13.077, rec=0.673), tot_loss_proj:4.118 [t=0.26s]
prediction: ['[CLS] funny initial albeit points unless gram wisdom. considered brave [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.794 (perp=10.536, rec=0.686), tot_loss_proj:3.919 [t=0.27s]
prediction: ['[CLS] funny a gram ) boom zombie wisdom. considered brave [SEP]']
[ 300/2000] tot_loss=2.816 (perp=10.732, rec=0.670), tot_loss_proj:4.041 [t=0.27s]
prediction: ['[CLS] funny a funny in points zombie wisdom. considered brave [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.944 (perp=11.525, rec=0.639), tot_loss_proj:3.384 [t=0.25s]
prediction: ['[CLS] funny a sucks zombie ) points wisdom. review sucks [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.956 (perp=11.377, rec=0.681), tot_loss_proj:3.490 [t=0.25s]
prediction: ['[CLS] funny reaction sucks unless ) points review good wisdom. [SEP]']
[ 450/2000] tot_loss=2.761 (perp=9.990, rec=0.763), tot_loss_proj:3.656 [t=0.25s]
prediction: ['[CLS] great reaction sucks apocalypse scorer reviews review brave wisdom. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.809 (perp=9.981, rec=0.813), tot_loss_proj:3.594 [t=0.25s]
prediction: ['[CLS] great reaction sucks ) points review apocalypse good wisdom, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.712 (perp=10.203, rec=0.671), tot_loss_proj:3.181 [t=0.25s]
prediction: ['[CLS] great reaction sucks multi knowledge review unless good points. [SEP]']
[ 600/2000] tot_loss=2.614 (perp=9.632, rec=0.687), tot_loss_proj:3.006 [t=0.26s]
prediction: ['[CLS] great reaction sucks. wisdom review unless good boom. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.869 (perp=10.489, rec=0.771), tot_loss_proj:3.486 [t=0.24s]
prediction: ['[CLS] great reaction sucks fledged sucks review unless knowledge points. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.312 (perp=8.505, rec=0.611), tot_loss_proj:3.018 [t=0.25s]
prediction: ['[CLS] great reaction sucks. unless review sucks knowledge points. [SEP]']
[ 750/2000] tot_loss=2.510 (perp=9.283, rec=0.653), tot_loss_proj:3.034 [t=0.25s]
prediction: ['[CLS] great reaction sucks. unless review good knowledge boom. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.802 (perp=9.223, rec=0.957), tot_loss_proj:3.306 [t=0.24s]
prediction: ['[CLS] eminent reaction sucks. sucks review unless knowledge points. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.516 (perp=9.417, rec=0.633), tot_loss_proj:3.286 [t=0.25s]
prediction: ['[CLS] eminent reaction sucks. sucks unless got knowledge boom. [SEP]']
[ 900/2000] tot_loss=2.774 (perp=9.596, rec=0.855), tot_loss_proj:3.353 [t=0.25s]
prediction: ['[CLS] eminent reaction sucks. sucks unless yeah knowledge points. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.494 (perp=9.325, rec=0.629), tot_loss_proj:3.063 [t=0.27s]
prediction: ['[CLS] funny reaction sucks. sucks unless got wisdom points. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.792 (perp=9.333, rec=0.925), tot_loss_proj:3.269 [t=0.27s]
prediction: ['[CLS] eminent reaction sucks. sucks unless got likes points. [SEP]']
[1050/2000] tot_loss=2.528 (perp=9.486, rec=0.631), tot_loss_proj:3.099 [t=0.26s]
prediction: ['[CLS] funny reaction sucks. sucks unless got knowledge points. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.329 (perp=8.739, rec=0.581), tot_loss_proj:2.744 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got knowledge points. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.448 (perp=9.211, rec=0.606), tot_loss_proj:2.815 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1200/2000] tot_loss=2.353 (perp=9.211, rec=0.511), tot_loss_proj:2.814 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.398 (perp=9.211, rec=0.555), tot_loss_proj:2.814 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.375 (perp=9.211, rec=0.533), tot_loss_proj:2.815 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1350/2000] tot_loss=2.362 (perp=9.211, rec=0.520), tot_loss_proj:2.812 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.347 (perp=9.211, rec=0.505), tot_loss_proj:2.817 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.335 (perp=9.211, rec=0.493), tot_loss_proj:2.816 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1500/2000] tot_loss=2.333 (perp=9.211, rec=0.491), tot_loss_proj:2.809 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.331 (perp=9.211, rec=0.489), tot_loss_proj:2.812 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.331 (perp=9.211, rec=0.489), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1650/2000] tot_loss=2.329 (perp=9.211, rec=0.486), tot_loss_proj:2.810 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.327 (perp=9.211, rec=0.485), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.323 (perp=9.211, rec=0.481), tot_loss_proj:2.808 [t=0.27s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1800/2000] tot_loss=2.324 (perp=9.211, rec=0.482), tot_loss_proj:2.808 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.325 (perp=9.211, rec=0.483), tot_loss_proj:2.816 [t=0.25s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.319 (perp=9.211, rec=0.477), tot_loss_proj:2.817 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1950/2000] tot_loss=2.322 (perp=9.211, rec=0.480), tot_loss_proj:2.813 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.320 (perp=9.211, rec=0.478), tot_loss_proj:2.818 [t=0.26s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] reaction funny sucks. sucks unless got likes points. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 40.000 | r: 40.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.000 | p: 30.000 | r: 30.000
rougeLsum  | fm: 30.000 | p: 30.000 | r: 30.000
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 81.230 | p: 80.790 | r: 81.941
rouge2     | fm: 44.550 | p: 44.441 | r: 44.820
rougeL     | fm: 71.348 | p: 70.886 | r: 72.022
rougeLsum  | fm: 71.331 | p: 70.919 | r: 72.055
r1fm+r2fm = 125.780

input #51 time: 0:10:48 | total time: 9:30:20


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
cosin similarity: -0.913830416657226 normalized error: 1.7702200963928998
cosin similarity: 0.9138304166572259 normalized error: 0.47924693221818315
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 1.8918972745288198 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 1.7367219556579863 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 1.6020888656688619 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 1.5186443878427849 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 1.4754864182597114 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 1.021767545651363 for ['[CLS] token ghetto tree [SEP]']
[Init] best perm rec loss: 1.0208957600591795 for ['[CLS] tree ghetto token [SEP]']
[Init] best perm rec loss: 1.0200359378925175 for ['[CLS] token tree ghetto [SEP]']
[Init] best perm rec loss: 1.01193992970521 for ['[CLS] tree token ghetto [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.673 (perp=11.737, rec=0.326), tot_loss_proj:2.837 [t=0.27s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.564 (perp=11.737, rec=0.217), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.507 (perp=11.737, rec=0.159), tot_loss_proj:2.848 [t=0.25s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 200/2000] tot_loss=2.495 (perp=11.737, rec=0.147), tot_loss_proj:2.846 [t=0.26s]
prediction: ['[CLS] trailer trash trash [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.295 (perp=10.789, rec=0.137), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] trash trailer trash [SEP]']
[ 300/2000] tot_loss=2.281 (perp=10.789, rec=0.123), tot_loss_proj:2.787 [t=0.25s]
prediction: ['[CLS] trash trailer trash [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.358 (perp=11.127, rec=0.133), tot_loss_proj:2.920 [t=0.25s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.357 (perp=11.127, rec=0.132), tot_loss_proj:2.911 [t=0.27s]
prediction: ['[CLS]frey trailer trash [SEP]']
[ 450/2000] tot_loss=2.355 (perp=11.127, rec=0.130), tot_loss_proj:2.911 [t=0.25s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.339 (perp=11.127, rec=0.114), tot_loss_proj:2.915 [t=0.26s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.342 (perp=11.127, rec=0.116), tot_loss_proj:2.910 [t=0.25s]
prediction: ['[CLS]frey trailer trash [SEP]']
[ 600/2000] tot_loss=2.330 (perp=11.127, rec=0.104), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.360 (perp=11.184, rec=0.124), tot_loss_proj:2.857 [t=0.25s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.342 (perp=11.184, rec=0.106), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS]nagar trailer trash [SEP]']
[ 750/2000] tot_loss=2.355 (perp=11.184, rec=0.119), tot_loss_proj:2.854 [t=0.25s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.351 (perp=11.184, rec=0.115), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.357 (perp=11.184, rec=0.120), tot_loss_proj:2.846 [t=0.26s]
prediction: ['[CLS]nagar trailer trash [SEP]']
[ 900/2000] tot_loss=2.359 (perp=11.184, rec=0.122), tot_loss_proj:2.850 [t=0.25s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.233 (perp=10.609, rec=0.111), tot_loss_proj:2.571 [t=0.27s]
prediction: ['[CLS] - trailer trash [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.462 (perp=11.688, rec=0.125), tot_loss_proj:2.985 [t=0.27s]
prediction: ['[CLS] trash trailernagar [SEP]']
[1050/2000] tot_loss=2.459 (perp=11.688, rec=0.121), tot_loss_proj:2.991 [t=0.26s]
prediction: ['[CLS] trash trailernagar [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.321 (perp=10.986, rec=0.124), tot_loss_proj:2.912 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1150/2000] tot_loss=2.322 (perp=10.986, rec=0.125), tot_loss_proj:2.917 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1200/2000] tot_loss=2.313 (perp=10.986, rec=0.116), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1250/2000] tot_loss=2.300 (perp=10.986, rec=0.103), tot_loss_proj:2.911 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1300/2000] tot_loss=2.326 (perp=10.986, rec=0.128), tot_loss_proj:2.915 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1350/2000] tot_loss=2.321 (perp=10.986, rec=0.123), tot_loss_proj:2.916 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1400/2000] tot_loss=2.310 (perp=10.986, rec=0.113), tot_loss_proj:2.916 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1450/2000] tot_loss=2.310 (perp=10.986, rec=0.113), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1500/2000] tot_loss=2.319 (perp=10.986, rec=0.122), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1550/2000] tot_loss=2.315 (perp=10.986, rec=0.117), tot_loss_proj:2.920 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1600/2000] tot_loss=2.309 (perp=10.986, rec=0.112), tot_loss_proj:2.909 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1650/2000] tot_loss=2.318 (perp=10.986, rec=0.121), tot_loss_proj:2.911 [t=0.24s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1700/2000] tot_loss=2.317 (perp=10.986, rec=0.120), tot_loss_proj:2.915 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1750/2000] tot_loss=2.303 (perp=10.986, rec=0.105), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1800/2000] tot_loss=2.320 (perp=10.986, rec=0.123), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1850/2000] tot_loss=2.301 (perp=10.986, rec=0.104), tot_loss_proj:2.919 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1900/2000] tot_loss=2.304 (perp=10.986, rec=0.107), tot_loss_proj:2.912 [t=0.26s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1950/2000] tot_loss=2.313 (perp=10.986, rec=0.115), tot_loss_proj:2.912 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[2000/2000] tot_loss=2.304 (perp=10.986, rec=0.107), tot_loss_proj:2.910 [t=0.25s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] - trailer trash [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.530 | p: 81.126 | r: 82.169
rouge2     | fm: 45.515 | p: 45.414 | r: 45.702
rougeL     | fm: 71.866 | p: 71.515 | r: 72.532
rougeLsum  | fm: 71.923 | p: 71.396 | r: 72.584
r1fm+r2fm = 127.046

input #52 time: 0:10:46 | total time: 9:41:06


Running input #53 of 100.
reference: 
========================
flinching 
========================
cosin similarity: 0.8177057447280546 normalized error: 0.5949757513681382
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 1.860857468996012 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 1.8326884834881505 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 1.78793463003454 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 1.7694669264075686 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 1.7461980450754935 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 1.6822965134714465 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 1.3790848816458245 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 1.3746548415711082 for ['[CLS] ralph not [SEP]']
[Init] best rec loss: 1.3267703807258537 for ['[CLS] praising won [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.827 (perp=12.384, rec=0.350), tot_loss_proj:3.613 [t=0.25s]
prediction: ['[CLS] flinch flinched [SEP]']
[ 100/2000] tot_loss=2.751 (perp=12.492, rec=0.253), tot_loss_proj:3.638 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.700 (perp=12.492, rec=0.201), tot_loss_proj:3.645 [t=0.24s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.696 (perp=12.492, rec=0.198), tot_loss_proj:3.655 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.675 (perp=12.492, rec=0.177), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.676 (perp=12.492, rec=0.177), tot_loss_proj:3.641 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.669 (perp=12.492, rec=0.171), tot_loss_proj:3.639 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.663 (perp=12.492, rec=0.164), tot_loss_proj:3.643 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 450/2000] tot_loss=2.659 (perp=12.472, rec=0.165), tot_loss_proj:3.654 [t=0.27s]
prediction: ['[CLS] kayla flinch [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.417 (perp=11.225, rec=0.172), tot_loss_proj:3.291 [t=0.27s]
prediction: ['[CLS] flinch kayla [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.398 (perp=11.225, rec=0.153), tot_loss_proj:3.276 [t=0.25s]
prediction: ['[CLS] flinch kayla [SEP]']
[ 600/2000] tot_loss=2.390 (perp=11.225, rec=0.145), tot_loss_proj:3.288 [t=0.26s]
prediction: ['[CLS] flinch kayla [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.400 (perp=11.225, rec=0.155), tot_loss_proj:3.287 [t=0.27s]
prediction: ['[CLS] flinch kayla [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.785 (perp=8.090, rec=0.167), tot_loss_proj:2.031 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.767 (perp=8.090, rec=0.149), tot_loss_proj:2.037 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.781 (perp=8.090, rec=0.163), tot_loss_proj:2.037 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.769 (perp=8.090, rec=0.151), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.781 (perp=8.090, rec=0.163), tot_loss_proj:2.037 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.780 (perp=8.090, rec=0.162), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.769 (perp=8.090, rec=0.151), tot_loss_proj:2.036 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.778 (perp=8.090, rec=0.160), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.766 (perp=8.090, rec=0.148), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.776 (perp=8.090, rec=0.158), tot_loss_proj:2.029 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.761 (perp=8.090, rec=0.143), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.766 (perp=8.090, rec=0.149), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.766 (perp=8.090, rec=0.148), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.775 (perp=8.090, rec=0.157), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.774 (perp=8.090, rec=0.156), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.765 (perp=8.090, rec=0.147), tot_loss_proj:2.031 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.772 (perp=8.090, rec=0.154), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.756 (perp=8.090, rec=0.139), tot_loss_proj:2.027 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.757 (perp=8.090, rec=0.139), tot_loss_proj:2.029 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.757 (perp=8.090, rec=0.139), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.758 (perp=8.090, rec=0.140), tot_loss_proj:2.038 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.777 (perp=8.090, rec=0.159), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.788 (perp=8.090, rec=0.170), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.768 (perp=8.090, rec=0.150), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.773 (perp=8.090, rec=0.155), tot_loss_proj:2.031 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.090, rec=0.152), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.764 (perp=8.090, rec=0.146), tot_loss_proj:2.027 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.928 | p: 81.467 | r: 82.588
rouge2     | fm: 46.542 | p: 46.346 | r: 46.745
rougeL     | fm: 72.430 | p: 72.012 | r: 73.052
rougeLsum  | fm: 72.468 | p: 72.000 | r: 73.169
r1fm+r2fm = 128.469

input #53 time: 0:10:45 | total time: 9:51:52


Running input #54 of 100.
reference: 
========================
hot topics 
========================
cosin similarity: -0.8756915472916371 normalized error: 1.7683841257581865
cosin similarity: 0.875691547291637 normalized error: 0.49565989248160147
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 1.6227908775326791 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 1.5987542074693561 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 1.5767884679215545 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 1.5682671519385059 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 1.5260936180324371 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 1.306422755073867 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 1.2822390957943035 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 1.261873184519111 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 1.1590576490000863 for ['[CLS] wild exercised [SEP]']
[Init] best rec loss: 1.152734810718929 for ['[CLS] shining blaine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.063 (perp=8.086, rec=0.446), tot_loss_proj:2.763 [t=0.26s]
prediction: ['[CLS] topic topics [SEP]']
[ 100/2000] tot_loss=2.626 (perp=11.553, rec=0.315), tot_loss_proj:2.957 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.579 (perp=11.553, rec=0.268), tot_loss_proj:2.968 [t=0.25s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.552 (perp=11.553, rec=0.242), tot_loss_proj:2.957 [t=0.25s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.890 (perp=8.198, rec=0.251), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.835 (perp=8.198, rec=0.195), tot_loss_proj:1.949 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.821 (perp=8.198, rec=0.182), tot_loss_proj:1.952 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.822 (perp=8.198, rec=0.182), tot_loss_proj:1.947 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.806 (perp=8.198, rec=0.166), tot_loss_proj:1.954 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.810 (perp=8.198, rec=0.171), tot_loss_proj:1.946 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.803 (perp=8.198, rec=0.164), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.801 (perp=8.198, rec=0.161), tot_loss_proj:1.955 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.814 (perp=8.198, rec=0.175), tot_loss_proj:1.951 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.803 (perp=8.198, rec=0.163), tot_loss_proj:1.953 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.799 (perp=8.198, rec=0.160), tot_loss_proj:1.960 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.800 (perp=8.198, rec=0.161), tot_loss_proj:1.951 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.796 (perp=8.198, rec=0.156), tot_loss_proj:1.944 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.805 (perp=8.198, rec=0.165), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.198, rec=0.159), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=8.198, rec=0.164), tot_loss_proj:1.943 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.806 (perp=8.198, rec=0.166), tot_loss_proj:1.942 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.804 (perp=8.198, rec=0.165), tot_loss_proj:1.948 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.800 (perp=8.198, rec=0.161), tot_loss_proj:1.948 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.798 (perp=8.198, rec=0.159), tot_loss_proj:1.953 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.809 (perp=8.198, rec=0.169), tot_loss_proj:1.955 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.805 (perp=8.198, rec=0.166), tot_loss_proj:1.954 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.792 (perp=8.198, rec=0.152), tot_loss_proj:1.947 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.792 (perp=8.198, rec=0.153), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.803 (perp=8.198, rec=0.163), tot_loss_proj:1.950 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.798 (perp=8.198, rec=0.158), tot_loss_proj:1.947 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.794 (perp=8.198, rec=0.155), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.805 (perp=8.198, rec=0.165), tot_loss_proj:1.953 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.794 (perp=8.198, rec=0.155), tot_loss_proj:1.948 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.806 (perp=8.198, rec=0.166), tot_loss_proj:1.948 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.798 (perp=8.198, rec=0.159), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.799 (perp=8.198, rec=0.159), tot_loss_proj:1.947 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.799 (perp=8.198, rec=0.160), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.198, rec=0.157), tot_loss_proj:1.954 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.798 (perp=8.198, rec=0.159), tot_loss_proj:1.946 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.792 (perp=8.198, rec=0.152), tot_loss_proj:1.958 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.236 | p: 81.863 | r: 82.843
rouge2     | fm: 47.744 | p: 47.622 | r: 47.940
rougeL     | fm: 72.791 | p: 72.415 | r: 73.474
rougeLsum  | fm: 72.902 | p: 72.517 | r: 73.581
r1fm+r2fm = 129.980

input #54 time: 0:10:42 | total time: 10:02:35


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
cosin similarity: -0.9432948797398057 normalized error: 1.6850677566109011
cosin similarity: 0.9432948797398059 normalized error: 0.5091769049280793
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 1.8132597928905372 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 1.520339640262229 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 1.4178397981846766 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 1.364029795873306 for ['[CLS] leaflets highlighted the [SEP]']
[Init] best rec loss: 1.3321413016333503 for ['[CLS] precipitation written mounted [SEP]']
[Init] best perm rec loss: 1.3286311339900267 for ['[CLS] written precipitation mounted [SEP]']
[Init] best perm rec loss: 1.3279397570065152 for ['[CLS] written mounted precipitation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.721 (perp=10.755, rec=0.570), tot_loss_proj:3.443 [t=0.26s]
prediction: ['[CLS] problems recoverednsis [SEP]']
[ 100/2000] tot_loss=3.014 (perp=12.871, rec=0.439), tot_loss_proj:3.936 [t=0.26s]
prediction: ['[CLS]omi settle detect [SEP]']
[ 150/2000] tot_loss=2.665 (perp=11.449, rec=0.376), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] down settle detect [SEP]']
[ 200/2000] tot_loss=2.807 (perp=12.286, rec=0.350), tot_loss_proj:3.720 [t=0.25s]
prediction: ['[CLS] down settle settles [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.454 (perp=10.337, rec=0.387), tot_loss_proj:3.052 [t=0.26s]
prediction: ['[CLS] down easily settle [SEP]']
[ 300/2000] tot_loss=1.918 (perp=8.185, rec=0.281), tot_loss_proj:2.353 [t=0.24s]
prediction: ['[CLS] too easily settle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.959 (perp=8.688, rec=0.221), tot_loss_proj:2.425 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.902 (perp=8.688, rec=0.164), tot_loss_proj:2.428 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.876 (perp=8.688, rec=0.139), tot_loss_proj:2.432 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.873 (perp=8.688, rec=0.135), tot_loss_proj:2.433 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.865 (perp=8.688, rec=0.127), tot_loss_proj:2.428 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.868 (perp=8.688, rec=0.131), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.857 (perp=8.688, rec=0.120), tot_loss_proj:2.432 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.853 (perp=8.688, rec=0.116), tot_loss_proj:2.428 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.856 (perp=8.688, rec=0.118), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.846 (perp=8.688, rec=0.108), tot_loss_proj:2.436 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.858 (perp=8.688, rec=0.120), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.850 (perp=8.688, rec=0.113), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.841 (perp=8.688, rec=0.103), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.843 (perp=8.688, rec=0.105), tot_loss_proj:2.433 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.845 (perp=8.688, rec=0.107), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.853 (perp=8.688, rec=0.115), tot_loss_proj:2.426 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.854 (perp=8.688, rec=0.117), tot_loss_proj:2.438 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.847 (perp=8.688, rec=0.109), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.849 (perp=8.688, rec=0.112), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=8.688, rec=0.105), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.846 (perp=8.688, rec=0.108), tot_loss_proj:2.440 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.853 (perp=8.688, rec=0.116), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=8.688, rec=0.110), tot_loss_proj:2.429 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.844 (perp=8.688, rec=0.106), tot_loss_proj:2.438 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.853 (perp=8.688, rec=0.115), tot_loss_proj:2.424 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.846 (perp=8.688, rec=0.109), tot_loss_proj:2.438 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.847 (perp=8.688, rec=0.109), tot_loss_proj:2.435 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.843 (perp=8.688, rec=0.105), tot_loss_proj:2.427 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.841 (perp=8.688, rec=0.104), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.848 (perp=8.688, rec=0.110), tot_loss_proj:2.426 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.845 (perp=8.688, rec=0.108), tot_loss_proj:2.437 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.844 (perp=8.688, rec=0.107), tot_loss_proj:2.440 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.846 (perp=8.688, rec=0.109), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.839 (perp=8.688, rec=0.102), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 82.615 | p: 82.212 | r: 83.240
rouge2     | fm: 47.338 | p: 47.157 | r: 47.491
rougeL     | fm: 73.029 | p: 72.601 | r: 73.588
rougeLsum  | fm: 73.112 | p: 72.652 | r: 73.767
r1fm+r2fm = 129.954

input #55 time: 0:10:43 | total time: 10:13:18


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
cosin similarity: -0.9308917516775046 normalized error: 1.780329755081986
cosin similarity: 0.9308917516775045 normalized error: 0.4680700509046626
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 1.657949479590898 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 1.5972682180982085 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 1.5830251744808155 for ['[CLS] gu listgnant brave xavier jenna lady behalf file productions experienced charmvah everything law commander shorts inner matchesonal boot [SEP]']
[Init] best rec loss: 1.5256889901627173 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 1.478327425027009 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 1.4694687572998928 for ['[CLS] sense en depression avid laid ironured bear k strike blame reflection technique determined backed unfortunately ; sympathy charter code tis [SEP]']
[Init] best perm rec loss: 1.4612084267702257 for ['[CLS] strike charter unfortunately en backed reflection code laid tis blame k determined depression technique sense bear sympathy ironured ; avid [SEP]']
[Init] best perm rec loss: 1.4561146937008274 for ['[CLS] strike reflection ; tisured determined sympathy backed k sense en unfortunately depression iron technique laid blame code avid charter bear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.715 (perp=11.675, rec=0.380), tot_loss_proj:3.307 [t=0.25s]
prediction: ['[CLS] forced phone barack paulo repair tape badly our days not worst unfortunately of crore provincial damage crude toilet if of caused [SEP]']
[ 100/2000] tot_loss=2.726 (perp=12.100, rec=0.306), tot_loss_proj:3.534 [t=0.25s]
prediction: ['[CLS] forcedcy afbphate repair raceway damageible am not damn unfortunately of centuries provincial damage country costly if of caused [SEP]']
[ 150/2000] tot_loss=2.529 (perp=11.336, rec=0.262), tot_loss_proj:3.255 [t=0.25s]
prediction: ['[CLS] yearscy filmsphate damage raceway damage that we not might unfortunately of centuries autopsy damage ty costly fix of caused [SEP]']
[ 200/2000] tot_loss=2.616 (perp=11.988, rec=0.218), tot_loss_proj:3.881 [t=0.27s]
prediction: ['[CLS] yearscy filmsphate analysis films damage that hours cause will unfortunately of centuries autopsy damage strained costly fix never unnecessary [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.443 (perp=11.150, rec=0.213), tot_loss_proj:3.871 [t=0.25s]
prediction: ['[CLS] yearscy filmsphate analysis films damage that hours cause of years autopsy damage strained costly fix will unfortunately never unnecessary [SEP]']
[ 300/2000] tot_loss=2.360 (perp=10.888, rec=0.182), tot_loss_proj:3.907 [t=0.26s]
prediction: ['[CLS] yearscy filmsphate analysis films damage that years cause of years autopsy damage of costly fix will unfortunately never unnecessary [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.228 (perp=10.340, rec=0.160), tot_loss_proj:3.425 [t=0.25s]
prediction: ['[CLS] yearscy films allah analysis films autopsy damage that years cause of years damage of costly fix will unfortunately never prohibit [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.152 (perp=10.055, rec=0.141), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] yearscy films allah analysis films ir damage that years cause of damage years of costly fix will unfortunately never prohibit [SEP]']
[ 450/2000] tot_loss=2.304 (perp=10.801, rec=0.143), tot_loss_proj:3.531 [t=0.25s]
prediction: ['[CLS] years { films allah analysis films ir damage that years cause of damage years of costly fix will dangerous never prohibit [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.269 (perp=10.668, rec=0.135), tot_loss_proj:3.319 [t=0.25s]
prediction: ['[CLS] years of films allah analysis which ir damage that years cause of damage yearsqua dangerous costly fix will never loads [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.323 (perp=10.976, rec=0.127), tot_loss_proj:3.485 [t=0.24s]
prediction: ['[CLS] years films allah analysis which ir trunk damage that years cause of damage yearsqua dangerous costly fix will never loads [SEP]']
[ 600/2000] tot_loss=2.321 (perp=10.976, rec=0.125), tot_loss_proj:3.485 [t=0.26s]
prediction: ['[CLS] years films allah analysis which ir trunk damage that years cause of damage yearsqua dangerous costly fix will never loads [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.108 (perp=9.915, rec=0.125), tot_loss_proj:3.300 [t=0.26s]
prediction: ['[CLS] of films allah analysis which irnce damage that years cause of damage years of costly dangerous fix will never loads [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.172 (perp=10.241, rec=0.124), tot_loss_proj:3.225 [t=0.25s]
prediction: ['[CLS] analysis of filmsbella which irired damage that years cause of damage years of costly dangerous fix will never loads [SEP]']
[ 750/2000] tot_loss=2.160 (perp=10.241, rec=0.112), tot_loss_proj:3.228 [t=0.26s]
prediction: ['[CLS] analysis of filmsbella which irired damage that years cause of damage years of costly dangerous fix will never loads [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.055 (perp=9.714, rec=0.113), tot_loss_proj:3.225 [t=0.26s]
prediction: ['[CLS] analysis of films which irbellaired damage that years cause of damage years of costly spectacular fix will never loads [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.996 (perp=9.424, rec=0.111), tot_loss_proj:3.144 [t=0.25s]
prediction: ['[CLS] analysis of films which irbellaired damage that years cause of spectacular years of costly damage fix will never loads [SEP]']
[ 900/2000] tot_loss=1.991 (perp=9.371, rec=0.117), tot_loss_proj:3.122 [t=0.25s]
prediction: ['[CLS] analysis of films whichparabellaired damage that years cause of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.838 (perp=8.623, rec=0.113), tot_loss_proj:2.852 [t=0.25s]
prediction: ['[CLS] analysis of films which causeparabellaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
[1000/2000] tot_loss=1.836 (perp=8.623, rec=0.111), tot_loss_proj:2.859 [t=0.26s]
prediction: ['[CLS] analysis of films which causeparabellaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
[1050/2000] tot_loss=1.838 (perp=8.623, rec=0.113), tot_loss_proj:2.854 [t=0.25s]
prediction: ['[CLS] analysis of films which causeparabellaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.828 (perp=8.596, rec=0.109), tot_loss_proj:2.815 [t=0.26s]
prediction: ['[CLS] analysis of films which causebellaparaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.895 (perp=8.963, rec=0.102), tot_loss_proj:2.751 [t=0.26s]
prediction: ['[CLS] analysis of which films causebellaparaulsive damage that years of spectacular years of costly damage fix will never loads [SEP]']
[1200/2000] tot_loss=1.894 (perp=8.963, rec=0.102), tot_loss_proj:2.749 [t=0.26s]
prediction: ['[CLS] analysis of which films causebellaparaulsive damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.855 (perp=8.739, rec=0.108), tot_loss_proj:2.744 [t=0.28s]
prediction: ['[CLS] analysis of which films causeulsiveparabella damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.815 (perp=8.547, rec=0.105), tot_loss_proj:2.632 [t=0.25s]
prediction: ['[CLS] analysis of which films cause loadsparabella damage that years of spectacular years of costly damage fix will neverulsive [SEP]']
[1350/2000] tot_loss=1.820 (perp=8.547, rec=0.110), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS] analysis of which films cause loadsparabella damage that years of spectacular years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.816 (perp=8.547, rec=0.107), tot_loss_proj:2.628 [t=0.27s]
prediction: ['[CLS] analysis of which films cause loadsparabella damage that years of spectacular years of costly damage fix will neverulsive [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.790 (perp=8.404, rec=0.109), tot_loss_proj:2.538 [t=0.25s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
[1500/2000] tot_loss=1.787 (perp=8.404, rec=0.106), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.783 (perp=8.404, rec=0.102), tot_loss_proj:2.533 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.781 (perp=8.404, rec=0.100), tot_loss_proj:2.530 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
[1650/2000] tot_loss=1.803 (perp=8.508, rec=0.101), tot_loss_proj:2.764 [t=0.25s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.807 (perp=8.508, rec=0.106), tot_loss_proj:2.763 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.808 (perp=8.508, rec=0.106), tot_loss_proj:2.764 [t=0.28s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
[1800/2000] tot_loss=1.808 (perp=8.508, rec=0.106), tot_loss_proj:2.766 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.749 (perp=8.233, rec=0.102), tot_loss_proj:2.665 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of years of less costly damage fix will neverulsive [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.778 (perp=8.271, rec=0.124), tot_loss_proj:2.558 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads of periods ofparabella damage that years of dangerous costly damage fix will neverulsive [SEP]']
[1950/2000] tot_loss=1.760 (perp=8.271, rec=0.106), tot_loss_proj:2.562 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads of periods ofparabella damage that years of dangerous costly damage fix will neverulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.271, rec=0.108), tot_loss_proj:2.563 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads of periods ofparabella damage that years of dangerous costly damage fix will neverulsive [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 26.316 | p: 26.316 | r: 26.316
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 106.316

[Aggregate metrics]:
rouge1     | fm: 82.563 | p: 82.195 | r: 83.214
rouge2     | fm: 46.990 | p: 46.836 | r: 47.225
rougeL     | fm: 72.871 | p: 72.476 | r: 73.527
rougeLsum  | fm: 72.847 | p: 72.399 | r: 73.481
r1fm+r2fm = 129.553

input #56 time: 0:10:59 | total time: 10:24:18


Running input #57 of 100.
reference: 
========================
wears 
========================
cosin similarity: -0.9322696138597257 normalized error: 1.6892108661716054
cosin similarity: 0.9322696138597257 normalized error: 0.510582375861863
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 1.7576340849318535 for ['[CLS]ne [SEP]']
[Init] best rec loss: 1.716505687086117 for ['[CLS] their [SEP]']
[Init] best rec loss: 1.6640945856224452 for ['[CLS] software [SEP]']
[Init] best rec loss: 1.6096875667724126 for ['[CLS] passed [SEP]']
[Init] best rec loss: 1.5187619586044785 for ['[CLS]cta [SEP]']
[Init] best rec loss: 1.501980876382866 for ['[CLS] darren [SEP]']
[Init] best rec loss: 1.4348307468367545 for ['[CLS] decision [SEP]']
[Init] best rec loss: 1.3838976232790914 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.926 (perp=12.705, rec=0.385), tot_loss_proj:3.345 [t=0.25s]
prediction: ['[CLS] wore [SEP]']
[ 100/2000] tot_loss=2.640 (perp=12.283, rec=0.183), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.626 (perp=12.283, rec=0.169), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.596 (perp=12.283, rec=0.139), tot_loss_proj:2.648 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.582 (perp=12.283, rec=0.125), tot_loss_proj:2.658 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.571 (perp=12.283, rec=0.114), tot_loss_proj:2.658 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.565 (perp=12.283, rec=0.108), tot_loss_proj:2.647 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.587 (perp=12.283, rec=0.130), tot_loss_proj:2.643 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.568 (perp=12.283, rec=0.111), tot_loss_proj:2.656 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.572 (perp=12.283, rec=0.115), tot_loss_proj:2.653 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.562 (perp=12.283, rec=0.106), tot_loss_proj:2.655 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.582 (perp=12.283, rec=0.125), tot_loss_proj:2.655 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.567 (perp=12.283, rec=0.110), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.575 (perp=12.283, rec=0.118), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.575 (perp=12.283, rec=0.118), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.582 (perp=12.283, rec=0.126), tot_loss_proj:2.655 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.566 (perp=12.283, rec=0.110), tot_loss_proj:2.653 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.577 (perp=12.283, rec=0.120), tot_loss_proj:2.633 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.562 (perp=12.283, rec=0.106), tot_loss_proj:2.650 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.572 (perp=12.283, rec=0.116), tot_loss_proj:2.645 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.566 (perp=12.283, rec=0.110), tot_loss_proj:2.647 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.567 (perp=12.283, rec=0.110), tot_loss_proj:2.642 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.561 (perp=12.283, rec=0.105), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.571 (perp=12.283, rec=0.114), tot_loss_proj:2.655 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.562 (perp=12.283, rec=0.106), tot_loss_proj:2.646 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.574 (perp=12.283, rec=0.118), tot_loss_proj:2.643 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.581 (perp=12.283, rec=0.125), tot_loss_proj:2.653 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.573 (perp=12.283, rec=0.116), tot_loss_proj:2.649 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.562 (perp=12.283, rec=0.105), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.585 (perp=12.283, rec=0.128), tot_loss_proj:2.648 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.574 (perp=12.283, rec=0.118), tot_loss_proj:2.647 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.565 (perp=12.283, rec=0.108), tot_loss_proj:2.645 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.574 (perp=12.283, rec=0.117), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.565 (perp=12.283, rec=0.108), tot_loss_proj:2.659 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.581 (perp=12.283, rec=0.124), tot_loss_proj:2.651 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.565 (perp=12.283, rec=0.109), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.577 (perp=12.283, rec=0.120), tot_loss_proj:2.662 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.561 (perp=12.283, rec=0.104), tot_loss_proj:2.628 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.563 (perp=12.283, rec=0.106), tot_loss_proj:2.664 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.578 (perp=12.283, rec=0.121), tot_loss_proj:2.662 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.788 | p: 82.433 | r: 83.385
rouge2     | fm: 47.942 | p: 47.785 | r: 48.144
rougeL     | fm: 73.404 | p: 73.007 | r: 73.953
rougeLsum  | fm: 73.311 | p: 72.894 | r: 73.953
r1fm+r2fm = 130.730

input #57 time: 0:10:45 | total time: 10:35:03


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
cosin similarity: 0.74009822539267 normalized error: 0.5757614783650968
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9722450971603394 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9545842409133911 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9472771883010864 for ['[CLS] talking honorary llc gray account feed very / cover robotics from which kin safe type tanks [SEP]']
[Init] best rec loss: 0.9237793684005737 for ['[CLS]ety spider gmina hypothesisjali brett endorsedhof avoid " joinsop programme friends designated looks [SEP]']
[Init] best rec loss: 0.9158854484558105 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9065104722976685 for ['[CLS] beth early fred zealand puppy sherwood ancient snap artwork page non group paying kan mile marked [SEP]']
[Init] best rec loss: 0.8996490836143494 for ['[CLS] roundsus public sacred shutter pure father succession seasonal grace youtube priest candi alpine mane elgin [SEP]']
[Init] best rec loss: 0.895362913608551 for ['[CLS] forest transportlight chloride protein rocker challenge academy are juliet partner party say castle berg microscope [SEP]']
[Init] best rec loss: 0.8887709379196167 for ['[CLS] carbonate nate loveorus coming debating cup arena stairs died closer threwsceau parents longer [SEP]']
[Init] best rec loss: 0.8770865201950073 for ['[CLS] personal duet hurt music due bilateral myself studyiniaailed said iron welfare ribbonscut oil [SEP]']
[Init] best rec loss: 0.8715378642082214 for ['[CLS] headingmo billionο wits tasting gravitational boundero togetherdion aim uefa with angrydilly [SEP]']
[Init] best rec loss: 0.8568609952926636 for ['[CLS] opener cards lasting forwards champion gone 11 programmeoe celaena siberia caine mason classscope own [SEP]']
[Init] best perm rec loss: 0.8506932854652405 for ['[CLS]scope forwardsoe mason cards opener programme class celaena caine lasting 11 champion siberia gone own [SEP]']
[Init] best perm rec loss: 0.8497921824455261 for ['[CLS] siberia cards caine 11oe class programme champion mason celaena ownscope gone lasting opener forwards [SEP]']
[Init] best perm rec loss: 0.8482516407966614 for ['[CLS] class celaenaoe gone 11 caine programme lasting own openerscope mason forwards siberia cards champion [SEP]']
[Init] best perm rec loss: 0.8459879159927368 for ['[CLS]oe cards mason 11 lasting forwards celaena classscope caine siberia programme own champion opener gone [SEP]']
[Init] best perm rec loss: 0.8458184599876404 for ['[CLS] 11 forwards champion mason lasting classoescope cards gone programme own siberia opener caine celaena [SEP]']
[Init] best perm rec loss: 0.8437963128089905 for ['[CLS] gone celaena caine siberia mason cardsscopeoe lasting opener forwards 11 class own programme champion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.526 (perp=11.559, rec=0.215), tot_loss_proj:2.941 [t=0.26s]
prediction: ['[CLS] is inspirational acted inspirational inspirational kissingkey mountain story early characters either report love the innocence [SEP]']
[ 100/2000] tot_loss=2.109 (perp=9.803, rec=0.149), tot_loss_proj:2.474 [t=0.26s]
prediction: ['[CLS] is inspirational love inspirational inspirational encounterre ideal story, romantic encounter encounter capturing first innocence [SEP]']
[ 150/2000] tot_loss=2.163 (perp=10.225, rec=0.118), tot_loss_proj:2.602 [t=0.27s]
prediction: ['[CLS] is inspirational love inspirational inspirational encounterre ideal story, ideal encounter encounter capturing first innocence [SEP]']
[ 200/2000] tot_loss=2.280 (perp=10.870, rec=0.106), tot_loss_proj:2.678 [t=0.25s]
prediction: ['[CLS] is inspirational love inspirational an encounterre ideal story that ideal encounter encounter capturing first innocence [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.030 (perp=9.608, rec=0.108), tot_loss_proj:2.462 [t=0.27s]
prediction: ['[CLS] is inspirational love inspirational an encounteri ideal story capturing that ideal encounter encounter first innocence [SEP]']
[ 300/2000] tot_loss=2.071 (perp=9.913, rec=0.088), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] is inspirational love ideal an encounteri ideal story capturing that the encounter encounter first innocence [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.919 (perp=9.169, rec=0.085), tot_loss_proj:2.314 [t=0.25s]
prediction: ['[CLS] is inspirational love ideal an ideal story capturing that the of encounter first encounteri innocence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.740 (perp=8.293, rec=0.081), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] is inspirational love ideal an ideal story capturing that the encounter of first encounteri innocence [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.293, rec=0.078), tot_loss_proj:2.113 [t=0.28s]
prediction: ['[CLS] is inspirational love ideal an ideal story capturing that the encounter of first encounteri innocence [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.660 (perp=7.936, rec=0.072), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing ideal the encounter of first encounteri innocence [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.651 (perp=7.881, rec=0.075), tot_loss_proj:2.024 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing encounter the ideal of first encounteri innocence [SEP]']
[ 600/2000] tot_loss=1.654 (perp=7.881, rec=0.077), tot_loss_proj:2.026 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing encounter the ideal of first encounteri innocence [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.620 (perp=7.739, rec=0.072), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturingism the ideal of first encounter innocencei [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.544 (perp=7.329, rec=0.078), tot_loss_proj:1.882 [t=0.26s]
prediction: ['[CLS] is inspirational love that an idealism story capturing the ideal of first encounter innocencei [SEP]']
[ 750/2000] tot_loss=1.545 (perp=7.329, rec=0.080), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] is inspirational love that an idealism story capturing the ideal of first encounter innocencei [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.458 (perp=6.926, rec=0.073), tot_loss_proj:1.746 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.466 (perp=6.926, rec=0.081), tot_loss_proj:1.753 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[ 900/2000] tot_loss=1.462 (perp=6.926, rec=0.077), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.459 (perp=6.926, rec=0.074), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1000/2000] tot_loss=1.463 (perp=6.926, rec=0.078), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1050/2000] tot_loss=1.459 (perp=6.926, rec=0.074), tot_loss_proj:1.757 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1100/2000] tot_loss=1.460 (perp=6.926, rec=0.075), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1150/2000] tot_loss=1.453 (perp=6.926, rec=0.068), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1200/2000] tot_loss=1.455 (perp=6.926, rec=0.070), tot_loss_proj:1.757 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1250/2000] tot_loss=1.456 (perp=6.926, rec=0.071), tot_loss_proj:1.751 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1300/2000] tot_loss=1.456 (perp=6.926, rec=0.071), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1350/2000] tot_loss=1.457 (perp=6.926, rec=0.072), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1400/2000] tot_loss=1.462 (perp=6.926, rec=0.077), tot_loss_proj:1.751 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1450/2000] tot_loss=1.460 (perp=6.926, rec=0.075), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1500/2000] tot_loss=1.452 (perp=6.926, rec=0.067), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1550/2000] tot_loss=1.454 (perp=6.926, rec=0.069), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1600/2000] tot_loss=1.462 (perp=6.926, rec=0.077), tot_loss_proj:1.750 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1650/2000] tot_loss=1.455 (perp=6.926, rec=0.070), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1700/2000] tot_loss=1.461 (perp=6.926, rec=0.076), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1750/2000] tot_loss=1.451 (perp=6.926, rec=0.066), tot_loss_proj:1.756 [t=0.28s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1800/2000] tot_loss=1.453 (perp=6.926, rec=0.068), tot_loss_proj:1.756 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1850/2000] tot_loss=1.457 (perp=6.926, rec=0.072), tot_loss_proj:1.752 [t=0.26s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
[1900/2000] tot_loss=1.458 (perp=6.926, rec=0.073), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
[1950/2000] tot_loss=1.454 (perp=6.926, rec=0.069), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.439 (perp=6.841, rec=0.071), tot_loss_proj:1.732 [t=0.30s]
prediction: ['[CLS] is inspirational love that an ideal story capturing the idealism of innocence first encounteri [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] is inspirational love that an ideal story capturing the idealism of first encounter innocencei [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 127.500

[Aggregate metrics]:
rouge1     | fm: 82.938 | p: 82.532 | r: 83.489
rouge2     | fm: 47.738 | p: 47.581 | r: 47.946
rougeL     | fm: 73.303 | p: 72.904 | r: 73.944
rougeLsum  | fm: 73.240 | p: 72.843 | r: 73.889
r1fm+r2fm = 130.676

input #58 time: 0:11:01 | total time: 10:46:04


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
cosin similarity: -0.9816993464484325 normalized error: 1.900850405425909
cosin similarity: 0.9816993464484326 normalized error: 0.3937520154390487
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 1.9352468220595735 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 1.924344726965796 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 1.9235641936941186 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 1.9057989966081574 for ['[CLS] shares josephine settled commerce refrain bulletsgi moved plot awaitanies roger console fergusotidew [SEP]']
[Init] best rec loss: 1.8261733513192162 for ['[CLS] meetings primarily afar vietnamille sound explaining bun ii powerped able speaking [SEP] brow illumination [SEP]']
[Init] best rec loss: 1.8195959440220848 for ['[CLS]her mutual so furrowed biggest new and \\ mag ac infantry portuguesecturing honor st thunder [SEP]']
[Init] best rec loss: 1.7829898906195414 for ['[CLS] trollsity underoh othersrion vault sorry days premiereend wivesjit reachedhold motorway [SEP]']
[Init] best rec loss: 1.7449995235109532 for ['[CLS] approaches dumb accept households frame relation sport replymis logan surrounding dutch dragon different com discipline [SEP]']
[Init] best rec loss: 1.7358503800545138 for ['[CLS]manship channels finishing organized black og getting last education plant mad thisor swiss penalties milton [SEP]']
[Init] best rec loss: 1.731510353822376 for ['[CLS] return knows french describeza r steer tatum bowler park valve form & where digitft [SEP]']
[Init] best rec loss: 1.721799546019262 for ['[CLS] effects one marxist southeastcarbon first rural relations breast tony threatened ran rose dodgers temptation josie [SEP]']
[Init] best rec loss: 1.6841728449184612 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best rec loss: 1.4963156858759479 for ['[CLS] organic passengers heroic wall duty change surgery drag kay statesflower hadn retirement cross will money [SEP]']
[Init] best perm rec loss: 1.4889789914032447 for ['[CLS] states organic passengers dragflower retirement kay will cross heroic change money surgery duty hadn wall [SEP]']
[Init] best perm rec loss: 1.4856175553972626 for ['[CLS] cross passengers money change organic hadn retirement heroic will kay surgery wall states dutyflower drag [SEP]']
[Init] best perm rec loss: 1.4851606582037857 for ['[CLS] organic kay change hadn cross moneyflower states retirement wall drag heroic surgery duty will passengers [SEP]']
[Init] best perm rec loss: 1.4814596546115226 for ['[CLS] cross organic states change kay money heroicflower duty wall hadn drag surgery retirement will passengers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.842 (perp=12.154, rec=0.412), tot_loss_proj:4.218 [t=0.26s]
prediction: ['[CLS] elvis wanted batsman theater catchther (yo borneptive lady of " quinn managed little [SEP]']
[ 100/2000] tot_loss=2.870 (perp=12.805, rec=0.309), tot_loss_proj:4.088 [t=0.26s]
prediction: ['[CLS] has wanted child theatre woman screen (yo style sha woman who ability karen an young [SEP]']
[ 150/2000] tot_loss=2.531 (perp=11.128, rec=0.305), tot_loss_proj:3.733 [t=0.26s]
prediction: ['[CLS] has the womantta woman screen (li woman female woman who ability wife hold young [SEP]']
[ 200/2000] tot_loss=2.685 (perp=12.221, rec=0.241), tot_loss_proj:3.975 [t=0.27s]
prediction: ['[CLS] has has womantta woman screen (li who female screen who char wife hold young [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.351 (perp=10.624, rec=0.226), tot_loss_proj:3.744 [t=0.27s]
prediction: ['[CLS]ism has womanism where screen has a who how screen who char wife hold young [SEP]']
[ 300/2000] tot_loss=2.242 (perp=10.244, rec=0.193), tot_loss_proj:3.537 [t=0.25s]
prediction: ['[CLS]ism has woman of who screen has a who how screen who char wife hold young [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.032 (perp=9.343, rec=0.163), tot_loss_proj:3.196 [t=0.26s]
prediction: ['[CLS]ism has woman of who screen has a who screen who char wife hold the young [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.994 (perp=9.221, rec=0.150), tot_loss_proj:2.933 [t=0.27s]
prediction: ['[CLS]ism has woman of who screen has a screen who knows char wife hold the young [SEP]']
[ 450/2000] tot_loss=1.867 (perp=8.641, rec=0.139), tot_loss_proj:2.726 [t=0.27s]
prediction: ['[CLS]ism has woman of a screen has a screen who knows char wife hold the young [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.973 (perp=9.178, rec=0.137), tot_loss_proj:3.159 [t=0.26s]
prediction: ['[CLS]ism has woman of the screen hasised screen who knows char wife hold the young [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.864 (perp=8.721, rec=0.120), tot_loss_proj:2.794 [t=0.25s]
prediction: ['[CLS]ism has woman of the screen husbandism screen who knows char has hold the young [SEP]']
[ 600/2000] tot_loss=2.006 (perp=9.417, rec=0.123), tot_loss_proj:2.896 [t=0.25s]
prediction: ['[CLS]ism has woman of the screen knowsism screen who knows char has hold the young [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.899 (perp=8.926, rec=0.114), tot_loss_proj:2.825 [t=0.26s]
prediction: ['[CLS]ism has woman of the screenism screen knows who knows char has hold the young [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.863 (perp=8.691, rec=0.125), tot_loss_proj:2.777 [t=0.27s]
prediction: ['[CLS]ism has woman of the screen char screen knows who knowsism has hold the young [SEP]']
[ 750/2000] tot_loss=1.948 (perp=9.192, rec=0.110), tot_loss_proj:2.769 [t=0.26s]
prediction: ['[CLS]ism has woman of theism char screen knows who knowsism has hold the young [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.891 (perp=8.938, rec=0.103), tot_loss_proj:2.559 [t=0.26s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=8.938, rec=0.102), tot_loss_proj:2.553 [t=0.26s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
[ 900/2000] tot_loss=1.890 (perp=8.938, rec=0.102), tot_loss_proj:2.557 [t=0.26s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.893 (perp=8.938, rec=0.106), tot_loss_proj:2.560 [t=0.28s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.870 (perp=8.798, rec=0.111), tot_loss_proj:2.486 [t=0.26s]
prediction: ['[CLS]ism hasism of the charism screen knows who knows woman has hold the young [SEP]']
[1050/2000] tot_loss=1.864 (perp=8.798, rec=0.105), tot_loss_proj:2.487 [t=0.25s]
prediction: ['[CLS]ism hasism of the charism screen knows who knows woman has hold the young [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.829 (perp=8.685, rec=0.092), tot_loss_proj:2.466 [t=0.25s]
prediction: ['[CLS]ismism has of the charism screen knows who knows woman has hold the young [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.818 (perp=8.572, rec=0.104), tot_loss_proj:2.559 [t=0.27s]
prediction: ['[CLS]ismism has of the charism screen knows who knows hold the young woman having [SEP]']
[1200/2000] tot_loss=1.817 (perp=8.572, rec=0.102), tot_loss_proj:2.560 [t=0.28s]
prediction: ['[CLS]ismism has of the charism screen knows who knows hold the young woman having [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.731 (perp=8.138, rec=0.104), tot_loss_proj:2.470 [t=0.26s]
prediction: ['[CLS]ismism has of the charism screen knows who knows having hold the young woman [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.631 (perp=7.652, rec=0.100), tot_loss_proj:2.244 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1350/2000] tot_loss=1.624 (perp=7.652, rec=0.093), tot_loss_proj:2.247 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.631 (perp=7.652, rec=0.100), tot_loss_proj:2.232 [t=0.25s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1450/2000] tot_loss=1.628 (perp=7.652, rec=0.097), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1500/2000] tot_loss=1.632 (perp=7.652, rec=0.101), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1550/2000] tot_loss=1.629 (perp=7.652, rec=0.099), tot_loss_proj:2.230 [t=0.25s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1600/2000] tot_loss=1.639 (perp=7.652, rec=0.109), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1650/2000] tot_loss=1.635 (perp=7.652, rec=0.104), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1700/2000] tot_loss=1.628 (perp=7.652, rec=0.098), tot_loss_proj:2.233 [t=0.27s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1750/2000] tot_loss=1.626 (perp=7.652, rec=0.095), tot_loss_proj:2.237 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1800/2000] tot_loss=1.629 (perp=7.652, rec=0.098), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1850/2000] tot_loss=1.632 (perp=7.652, rec=0.102), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1900/2000] tot_loss=1.628 (perp=7.652, rec=0.098), tot_loss_proj:2.234 [t=0.28s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1950/2000] tot_loss=1.625 (perp=7.652, rec=0.094), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[2000/2000] tot_loss=1.631 (perp=7.652, rec=0.100), tot_loss_proj:2.235 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 101.667

[Aggregate metrics]:
rouge1     | fm: 82.739 | p: 82.341 | r: 83.389
rouge2     | fm: 47.181 | p: 46.995 | r: 47.311
rougeL     | fm: 72.983 | p: 72.646 | r: 73.547
rougeLsum  | fm: 73.168 | p: 72.786 | r: 73.776
r1fm+r2fm = 129.920

input #59 time: 0:11:03 | total time: 10:57:08


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
cosin similarity: 0.7253921869358013 normalized error: 0.6182812032239168
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.8672913908958435 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.7851632237434387 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.7791898846626282 for ['[CLS] desk nick campaign mrs poison operation arabiaq black nearly plant cain [SEP]']
[Init] best rec loss: 0.7726471424102783 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.7517830729484558 for ['[CLS] width stranger sector loyalist soundtrack opposition beside position didn eligible grants peter [SEP]']
[Init] best rec loss: 0.7371909022331238 for ['[CLS] rico shave overcomensor 1st opus introduced knockout currency area statewide whispered [SEP]']
[Init] best perm rec loss: 0.7334657311439514 for ['[CLS] introduced shave area whispered 1st statewide rico currencynsor overcome knockout opus [SEP]']
[Init] best perm rec loss: 0.7313056588172913 for ['[CLS] 1stnsor knockout statewide introduced area rico opus whispered currency shave overcome [SEP]']
[Init] best perm rec loss: 0.7281737923622131 for ['[CLS] 1st introduced statewide rico opus whispered overcome area currency shavensor knockout [SEP]']
[Init] best perm rec loss: 0.7271633744239807 for ['[CLS] statewide overcome knockout shave rico opus 1st currency whisperednsor introduced area [SEP]']
[Init] best perm rec loss: 0.726322591304779 for ['[CLS] area opusnsor statewide shave knockout 1st introduced whispered overcome currency rico [SEP]']
[Init] best perm rec loss: 0.7256045937538147 for ['[CLS] statewide area shave 1st knockout opus whispered currencynsor overcome introduced rico [SEP]']
[Init] best perm rec loss: 0.7245604395866394 for ['[CLS] rico opus knockout shave whispered currency overcome introduced 1st statewide areansor [SEP]']
[Init] best perm rec loss: 0.7241901755332947 for ['[CLS] 1st area introduced knockout opus statewide whispered currency riconsor overcome shave [SEP]']
[Init] best perm rec loss: 0.7236802577972412 for ['[CLS] statewide rico opus shave area 1st knockout overcome currencynsor introduced whispered [SEP]']
[Init] best perm rec loss: 0.7218004465103149 for ['[CLS] statewidensor shave 1st whispered rico knockout introduced opus overcome currency area [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.396 (perp=10.738, rec=0.249), tot_loss_proj:2.626 [t=0.25s]
prediction: ['[CLS] awkwardly awkwardly was the awkwardly circuit par barracks is a awkwardly cable [SEP]']
[ 100/2000] tot_loss=2.565 (perp=12.002, rec=0.165), tot_loss_proj:2.878 [t=0.25s]
prediction: ['[CLS] awkwardly awkwardly was is soap circuit characters circuit paced is awkwardly story [SEP]']
[ 150/2000] tot_loss=2.478 (perp=11.797, rec=0.118), tot_loss_proj:2.780 [t=0.25s]
prediction: ['[CLS] awkwardly awkwardly is is soap soap characters circuit paced theh story [SEP]']
[ 200/2000] tot_loss=2.188 (perp=10.434, rec=0.102), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] awkwardly awkwardly is is soap opera − circuit paced theh story [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.935 (perp=9.224, rec=0.090), tot_loss_proj:2.248 [t=0.25s]
prediction: ['[CLS] awkwardly awkwardly is soap opera. circuit paced is theh story [SEP]']
[ 300/2000] tot_loss=1.958 (perp=9.437, rec=0.071), tot_loss_proj:2.297 [t=0.26s]
prediction: ['[CLS] awkwardly awkwardly is soap opera is circuit paced is theh story [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.779 (perp=8.281, rec=0.123), tot_loss_proj:1.995 [t=0.28s]
prediction: ['[CLS]. awkwardly is soap opera circuit paced - the ish story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.856 (perp=8.765, rec=0.103), tot_loss_proj:2.159 [t=0.26s]
prediction: ['[CLS]. awkwardly is soap opera circuit. - the pacedh story [SEP]']
[ 450/2000] tot_loss=1.864 (perp=8.814, rec=0.101), tot_loss_proj:2.162 [t=0.25s]
prediction: ['[CLS] is awkwardly is soap opera circuit. - the pacedh story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.653 (perp=7.698, rec=0.113), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] is awkwardly paced soap opera circuit is - the ish story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.584 (perp=7.478, rec=0.088), tot_loss_proj:1.792 [t=0.27s]
prediction: ['[CLS] is awkwardly paced circuit soap opera is - the ish story [SEP]']
[ 600/2000] tot_loss=1.580 (perp=7.488, rec=0.083), tot_loss_proj:1.767 [t=0.27s]
prediction: ['[CLS] is awkwardly paced circuit soap opera. - the ish story [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.499 (perp=7.144, rec=0.070), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera. - the ish story [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.353 (perp=6.365, rec=0.080), tot_loss_proj:1.565 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[ 750/2000] tot_loss=1.350 (perp=6.365, rec=0.077), tot_loss_proj:1.555 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.349 (perp=6.365, rec=0.076), tot_loss_proj:1.571 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.341 (perp=6.365, rec=0.068), tot_loss_proj:1.565 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[ 900/2000] tot_loss=1.347 (perp=6.365, rec=0.074), tot_loss_proj:1.558 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.340 (perp=6.365, rec=0.067), tot_loss_proj:1.555 [t=0.27s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.349 (perp=6.365, rec=0.076), tot_loss_proj:1.567 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1050/2000] tot_loss=1.348 (perp=6.365, rec=0.075), tot_loss_proj:1.566 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.344 (perp=6.365, rec=0.071), tot_loss_proj:1.567 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.340 (perp=6.365, rec=0.067), tot_loss_proj:1.561 [t=0.26s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1200/2000] tot_loss=1.355 (perp=6.365, rec=0.082), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.348 (perp=6.365, rec=0.075), tot_loss_proj:1.558 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.345 (perp=6.365, rec=0.072), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1350/2000] tot_loss=1.351 (perp=6.365, rec=0.078), tot_loss_proj:1.562 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.340 (perp=6.365, rec=0.067), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.338 (perp=6.365, rec=0.065), tot_loss_proj:1.565 [t=0.24s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1500/2000] tot_loss=1.351 (perp=6.365, rec=0.078), tot_loss_proj:1.558 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.337 (perp=6.365, rec=0.064), tot_loss_proj:1.558 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.349 (perp=6.365, rec=0.076), tot_loss_proj:1.565 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1650/2000] tot_loss=1.340 (perp=6.365, rec=0.067), tot_loss_proj:1.555 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.341 (perp=6.365, rec=0.068), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.349 (perp=6.365, rec=0.076), tot_loss_proj:1.571 [t=0.24s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1800/2000] tot_loss=1.344 (perp=6.365, rec=0.071), tot_loss_proj:1.566 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.338 (perp=6.365, rec=0.065), tot_loss_proj:1.566 [t=0.27s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.345 (perp=6.365, rec=0.072), tot_loss_proj:1.562 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
[1950/2000] tot_loss=1.333 (perp=6.365, rec=0.060), tot_loss_proj:1.556 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.351 (perp=6.365, rec=0.078), tot_loss_proj:1.554 [t=0.25s]
prediction: ['[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] awkwardly paced circuit is soap opera - the ish story. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 83.024 | p: 82.695 | r: 83.689
rouge2     | fm: 47.323 | p: 47.204 | r: 47.530
rougeL     | fm: 73.019 | p: 72.629 | r: 73.636
rougeLsum  | fm: 73.053 | p: 72.692 | r: 73.661
r1fm+r2fm = 130.347

input #60 time: 0:10:47 | total time: 11:07:56


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
cosin similarity: -0.8662755347520332 normalized error: 1.839448386591049
cosin similarity: 0.8662755347520332 normalized error: 0.4720166028736299
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 1.8395388486350686 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 1.7747550251026512 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 1.627125089526111 for ['[CLS] age bad link [SEP]']
[Init] best rec loss: 1.6162559336635822 for ['[CLS] maximus broken initiative [SEP]']
[Init] best rec loss: 1.3438386127527544 for ['[CLS] request lets mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.016 (perp=7.753, rec=0.465), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.934 (perp=8.033, rec=0.327), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 150/2000] tot_loss=1.909 (perp=8.033, rec=0.302), tot_loss_proj:1.950 [t=0.24s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 200/2000] tot_loss=1.896 (perp=8.033, rec=0.289), tot_loss_proj:1.950 [t=0.25s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.728 (perp=7.102, rec=0.308), tot_loss_proj:1.905 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.714 (perp=7.102, rec=0.294), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.715 (perp=7.102, rec=0.294), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.707 (perp=7.102, rec=0.287), tot_loss_proj:1.900 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.718 (perp=7.102, rec=0.298), tot_loss_proj:1.910 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.707 (perp=7.102, rec=0.287), tot_loss_proj:1.908 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=7.102, rec=0.260), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.666 (perp=7.102, rec=0.246), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.675 (perp=7.102, rec=0.255), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=7.102, rec=0.255), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.669 (perp=7.102, rec=0.249), tot_loss_proj:1.908 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.668 (perp=7.102, rec=0.248), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.671 (perp=7.102, rec=0.251), tot_loss_proj:1.908 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.672 (perp=7.102, rec=0.252), tot_loss_proj:1.911 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.667 (perp=7.102, rec=0.247), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.667 (perp=7.102, rec=0.247), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.659 (perp=7.102, rec=0.239), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.661 (perp=7.102, rec=0.241), tot_loss_proj:1.906 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.664 (perp=7.102, rec=0.244), tot_loss_proj:1.897 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.671 (perp=7.102, rec=0.251), tot_loss_proj:1.911 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.102, rec=0.248), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.661 (perp=7.102, rec=0.241), tot_loss_proj:1.915 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.669 (perp=7.102, rec=0.249), tot_loss_proj:1.905 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.672 (perp=7.102, rec=0.252), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.663 (perp=7.102, rec=0.243), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.102, rec=0.247), tot_loss_proj:1.894 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.661 (perp=7.102, rec=0.241), tot_loss_proj:1.912 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=7.102, rec=0.254), tot_loss_proj:1.893 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.663 (perp=7.102, rec=0.243), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.655 (perp=7.102, rec=0.234), tot_loss_proj:1.896 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.662 (perp=7.102, rec=0.242), tot_loss_proj:1.908 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.664 (perp=7.102, rec=0.244), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.666 (perp=7.102, rec=0.246), tot_loss_proj:1.906 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.664 (perp=7.102, rec=0.244), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.663 (perp=7.102, rec=0.243), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.654 (perp=7.102, rec=0.234), tot_loss_proj:1.909 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.299 | p: 82.970 | r: 83.873
rouge2     | fm: 48.288 | p: 48.124 | r: 48.516
rougeL     | fm: 73.446 | p: 73.145 | r: 74.034
rougeLsum  | fm: 73.408 | p: 73.038 | r: 74.041
r1fm+r2fm = 131.587

input #61 time: 0:10:50 | total time: 11:18:47


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
cosin similarity: 0.9025832287894447 normalized error: 0.4617084804268676
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 1.9297349250196945 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 1.8903897177075442 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 1.844699101257625 for ['[CLS] young dance sacrifice cross regular drove huffington trip client gloss chosen butte actually t running buywide sms custom floating mug [SEP]']
[Init] best rec loss: 1.7349761959658436 for ['[CLS] help rarely extensionbreaker local sea team mom beacon tear wax chairmanphstatic mum new osman intervention [CLS] attentionius [SEP]']
[Init] best rec loss: 1.7294749743744964 for ['[CLS]ftbytry unit bulls ibnuit graf model annabelle finhop type municipalityusing blooded prank ms advantage if stone [SEP]']
[Init] best rec loss: 1.7171115198947655 for ['[CLS] think jacented pac serial hardcover mini showcase commissioned they familiar cho tire buildings hands commerce indoor muscle funding best sac [SEP]']
[Init] best rec loss: 1.7157574469863874 for ['[CLS] such duo demand appeared being pv status stereotypes superlary eight song signage thing conform take pup i planetary feed free [SEP]']
[Init] best rec loss: 1.6609326681959053 for ['[CLS] ammunition nowheregut opinion deemed romansdong was mattered al body mono turkish abet main alone stations bag lead facebook [SEP]']
[Init] best perm rec loss: 1.6607041937562856 for ['[CLS] romans body opinion al lead abegut nowhere bag mattered deemedt turkishdong was alone ammunition mono stations main facebook [SEP]']
[Init] best perm rec loss: 1.6603711363279208 for ['[CLS] body romans mono main al was facebook abegutdong turkish stations opiniont nowhere bag lead ammunition mattered alone deemed [SEP]']
[Init] best perm rec loss: 1.6599393968141325 for ['[CLS] ammunitiontdong abe stations mattered mono alone turkish body facebook deemed opiniongut bag romans lead main nowhere was al [SEP]']
[Init] best perm rec loss: 1.6582424510254032 for ['[CLS] mono lead body main facebook stations alone bagt nowhere romans mattered deemed ammunition wasgut abedong turkish opinion al [SEP]']
[Init] best perm rec loss: 1.657107630088984 for ['[CLS] bag nowhere lead opinion mono romans turkish deemed matteredgut bodydong abe alone main stationst was ammunition al facebook [SEP]']
[Init] best perm rec loss: 1.6554196095583933 for ['[CLS] ammunition mono maint turkish abedong leadgut opinion mattered body bag nowhere facebook alone deemed stations romans al was [SEP]']
[Init] best perm rec loss: 1.654280861231804 for ['[CLS]dong stations mattered opinion deemed abe body turkish facebook romans mono ammunition alone nowheret al maingut was lead bag [SEP]']
[Init] best perm rec loss: 1.654129012955191 for ['[CLS] nowhere mono bagt abe mattereddong stations alonegut deemed body ammunition al lead turkish facebook opinion main romans was [SEP]']
[Init] best perm rec loss: 1.6539011960149457 for ['[CLS] nowhere body alonet mattered turkishdong facebook romans stations bag ammunition deemedgut al mono main lead abe opinion was [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.946 (perp=11.424, rec=0.661), tot_loss_proj:3.798 [t=0.26s]
prediction: ['[CLS] nothing empty lost dating gaulle national inappropriate discrimination tv. waste ammunition worse fiat. forced via so equipment experienced letters [SEP]']
[ 100/2000] tot_loss=2.881 (perp=11.493, rec=0.582), tot_loss_proj:3.953 [t=0.25s]
prediction: ['[CLS] seem barely lost dating gaulle to inappropriate discrimination sometimes catholic waste which worse outcome rarely any to hero camera concentration letters [SEP]']
[ 150/2000] tot_loss=3.491 (perp=13.407, rec=0.809), tot_loss_proj:4.385 [t=0.25s]
prediction: ['[CLS] brazilian barely lost rick gaulle behind uncomfortableoulos journalism catholic say there worse victory called anyque films camera gillespie anything [SEP]']
[ 200/2000] tot_loss=2.882 (perp=11.460, rec=0.590), tot_loss_proj:3.838 [t=0.26s]
prediction: ['[CLS] lie barely lost call goddamn to uncomfortable waste. ordained claim nothing neverho called treasure with so eating liquor food [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.628 (perp=10.440, rec=0.540), tot_loss_proj:3.646 [t=0.26s]
prediction: ['[CLS] lie barely was scheduled goddamn to uncomfortable waste. war say nothing only mara called any peace with so eating percentage [SEP]']
[ 300/2000] tot_loss=2.662 (perp=10.506, rec=0.560), tot_loss_proj:3.765 [t=0.25s]
prediction: ['[CLS] seem barely of to goddamn shooting classified waste, war prevent nothing only mara called any best with movies about percentage [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.473 (perp=9.819, rec=0.509), tot_loss_proj:3.774 [t=0.28s]
prediction: ['[CLS] seemhole of to prevent finest to classified waste, war nothing better mara called the best with movies about percentage [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.552 (perp=10.331, rec=0.486), tot_loss_proj:3.976 [t=0.24s]
prediction: ['[CLS] seem beside of to prevent finest to classified waste, war any nothing only mara and best with movies about legislation [SEP]']
[ 450/2000] tot_loss=2.486 (perp=9.939, rec=0.499), tot_loss_proj:3.703 [t=0.26s]
prediction: ['[CLS] seem barely of to prevent finest to classified waste, war riches criticism better mara and best with movies about legislation [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.367 (perp=9.368, rec=0.493), tot_loss_proj:3.655 [t=0.26s]
prediction: ['[CLS] grace barely of want to prevent best to classified coincidence lifestyle movies before better mara and best with movies about legislation [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.491 (perp=10.146, rec=0.462), tot_loss_proj:3.897 [t=0.26s]
prediction: ['[CLS] gracepromising of want to prevent best classified coincidence, movies beforeudence better mara up best with movies does legislation [SEP]']
[ 600/2000] tot_loss=2.357 (perp=9.477, rec=0.461), tot_loss_proj:3.817 [t=0.25s]
prediction: ['[CLS] gracepromising of want to than best classified coincidence, movies before to better mara and best with movies does legislation [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.438 (perp=9.950, rec=0.448), tot_loss_proj:3.873 [t=0.27s]
prediction: ['[CLS] gracepromising of want to best classified coincidence, war before to better prevent maraify best with movies ever legislation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.339 (perp=9.405, rec=0.458), tot_loss_proj:3.805 [t=0.25s]
prediction: ['[CLS] grace mara of want to best classified coincidence, movies before to better preventpromisingify best with movies ever legislation [SEP]']
[ 750/2000] tot_loss=2.445 (perp=9.790, rec=0.487), tot_loss_proj:3.876 [t=0.25s]
prediction: ['[CLS] grace mara of want to best classified coincidence, war before to better preventpromising be best with movies ever legislation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.277 (perp=9.241, rec=0.429), tot_loss_proj:3.738 [t=0.25s]
prediction: ['[CLS] grace mara of want to best classified coincidence, war before to better than highly best be with movies ever legislation [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.392 (perp=9.659, rec=0.461), tot_loss_proj:3.847 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best characterized coincidence, prevention before to better prevent highly best with movies ever legislation [SEP]']
[ 900/2000] tot_loss=2.231 (perp=8.998, rec=0.432), tot_loss_proj:3.597 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.226 (perp=8.998, rec=0.427), tot_loss_proj:3.598 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
[1000/2000] tot_loss=2.236 (perp=8.998, rec=0.437), tot_loss_proj:3.600 [t=0.25s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
[1050/2000] tot_loss=2.215 (perp=8.998, rec=0.415), tot_loss_proj:3.595 [t=0.25s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.199 (perp=8.964, rec=0.406), tot_loss_proj:3.545 [t=0.29s]
prediction: ['[CLS] grace mara of want to be best classified, coincidence war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.234 (perp=9.080, rec=0.418), tot_loss_proj:3.694 [t=0.25s]
prediction: ['[CLS] grace mara of want to be best classified before coincidence war, to better prevent highly best with movies ever legislation [SEP]']
[1200/2000] tot_loss=2.303 (perp=9.080, rec=0.487), tot_loss_proj:3.692 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified before coincidence war, to better prevent highly best with movies ever legislation [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.223 (perp=9.048, rec=0.414), tot_loss_proj:3.702 [t=0.28s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, to better prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1300/2000] tot_loss=2.270 (perp=9.319, rec=0.406), tot_loss_proj:3.811 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1350/2000] tot_loss=2.279 (perp=9.319, rec=0.415), tot_loss_proj:3.813 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1400/2000] tot_loss=2.263 (perp=9.319, rec=0.399), tot_loss_proj:3.814 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1450/2000] tot_loss=2.270 (perp=9.319, rec=0.406), tot_loss_proj:3.808 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1500/2000] tot_loss=2.263 (perp=9.319, rec=0.399), tot_loss_proj:3.812 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1550/2000] tot_loss=2.256 (perp=9.319, rec=0.392), tot_loss_proj:3.810 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1600/2000] tot_loss=2.328 (perp=9.336, rec=0.461), tot_loss_proj:3.797 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into better prevent highly best with movies ever legislation [SEP]']
[1650/2000] tot_loss=2.314 (perp=9.524, rec=0.409), tot_loss_proj:3.834 [t=0.25s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1700/2000] tot_loss=2.312 (perp=9.524, rec=0.407), tot_loss_proj:3.834 [t=0.29s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1750/2000] tot_loss=2.302 (perp=9.524, rec=0.397), tot_loss_proj:3.834 [t=0.26s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1800/2000] tot_loss=2.301 (perp=9.524, rec=0.396), tot_loss_proj:3.834 [t=0.27s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1850/2000] tot_loss=2.297 (perp=9.524, rec=0.392), tot_loss_proj:3.833 [t=0.27s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1900/2000] tot_loss=2.293 (perp=9.524, rec=0.388), tot_loss_proj:3.836 [t=0.26s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1950/2000] tot_loss=2.293 (perp=9.524, rec=0.388), tot_loss_proj:3.837 [t=0.26s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[2000/2000] tot_loss=2.299 (perp=9.524, rec=0.394), tot_loss_proj:3.836 [t=0.25s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 37.209 | p: 38.095 | r: 36.364
rouge2     | fm: 4.878 | p: 5.000 | r: 4.762
rougeL     | fm: 32.558 | p: 33.333 | r: 31.818
rougeLsum  | fm: 32.558 | p: 33.333 | r: 31.818
r1fm+r2fm = 42.087

[Aggregate metrics]:
rouge1     | fm: 82.599 | p: 82.323 | r: 83.168
rouge2     | fm: 47.466 | p: 47.365 | r: 47.668
rougeL     | fm: 72.897 | p: 72.544 | r: 73.453
rougeLsum  | fm: 72.876 | p: 72.550 | r: 73.405
r1fm+r2fm = 130.066

input #62 time: 0:10:58 | total time: 11:29:45


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
cosin similarity: 0.888152152709799 normalized error: 0.5233351577081562
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 1.7797503937975239 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 1.3290306339774856 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 1.291038887418315 for ['[CLS] builder jumping timber nasal grant [SEP]']
[Init] best perm rec loss: 1.2905503176438675 for ['[CLS] jumping grant timber builder nasal [SEP]']
[Init] best perm rec loss: 1.2892315809817956 for ['[CLS] builder jumping nasal grant timber [SEP]']
[Init] best perm rec loss: 1.2890984321985854 for ['[CLS] nasal grant jumping timber builder [SEP]']
[Init] best perm rec loss: 1.2890506922916605 for ['[CLS] builder jumping grant timber nasal [SEP]']
[Init] best perm rec loss: 1.2881710746637853 for ['[CLS] grant builder jumping timber nasal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.945 (perp=12.652, rec=0.415), tot_loss_proj:3.775 [t=0.27s]
prediction: ['[CLS] return return ticket coward drug [SEP]']
[ 100/2000] tot_loss=2.650 (perp=12.060, rec=0.237), tot_loss_proj:3.386 [t=0.28s]
prediction: ['[CLS] return return ticket cr looking [SEP]']
[ 150/2000] tot_loss=2.562 (perp=11.972, rec=0.168), tot_loss_proj:3.755 [t=0.25s]
prediction: ['[CLS] pardon return ticket convey looking [SEP]']
[ 200/2000] tot_loss=2.405 (perp=11.318, rec=0.141), tot_loss_proj:3.688 [t=0.25s]
prediction: ['[CLS] upon return ticket cr looking [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.507 (perp=11.774, rec=0.152), tot_loss_proj:4.043 [t=0.25s]
prediction: ['[CLS] upon convey ticket return looking [SEP]']
[ 300/2000] tot_loss=2.492 (perp=11.774, rec=0.137), tot_loss_proj:4.045 [t=0.25s]
prediction: ['[CLS] upon convey ticket return looking [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.337 (perp=11.039, rec=0.129), tot_loss_proj:3.972 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.964 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 450/2000] tot_loss=2.331 (perp=11.039, rec=0.124), tot_loss_proj:3.969 [t=0.27s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.332 (perp=11.039, rec=0.124), tot_loss_proj:3.968 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.326 (perp=11.039, rec=0.118), tot_loss_proj:3.972 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 600/2000] tot_loss=2.327 (perp=11.039, rec=0.119), tot_loss_proj:3.974 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.328 (perp=11.039, rec=0.121), tot_loss_proj:3.977 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.329 (perp=11.039, rec=0.122), tot_loss_proj:3.979 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 750/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.982 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.326 (perp=11.039, rec=0.118), tot_loss_proj:3.981 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.327 (perp=11.039, rec=0.120), tot_loss_proj:3.980 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 900/2000] tot_loss=2.309 (perp=11.039, rec=0.101), tot_loss_proj:3.976 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.318 (perp=11.039, rec=0.111), tot_loss_proj:3.987 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.322 (perp=11.039, rec=0.115), tot_loss_proj:3.979 [t=0.27s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[1050/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.980 [t=0.27s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.980 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.055 (perp=9.624, rec=0.130), tot_loss_proj:2.670 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1200/2000] tot_loss=2.030 (perp=9.624, rec=0.105), tot_loss_proj:2.671 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=2.027 (perp=9.624, rec=0.102), tot_loss_proj:2.680 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=2.035 (perp=9.624, rec=0.110), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1350/2000] tot_loss=2.042 (perp=9.624, rec=0.117), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=2.024 (perp=9.624, rec=0.099), tot_loss_proj:2.677 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=2.025 (perp=9.624, rec=0.100), tot_loss_proj:2.676 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1500/2000] tot_loss=2.035 (perp=9.624, rec=0.111), tot_loss_proj:2.681 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=2.034 (perp=9.624, rec=0.109), tot_loss_proj:2.674 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=2.033 (perp=9.624, rec=0.108), tot_loss_proj:2.678 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1650/2000] tot_loss=2.041 (perp=9.624, rec=0.116), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=2.031 (perp=9.624, rec=0.106), tot_loss_proj:2.673 [t=0.24s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=2.031 (perp=9.624, rec=0.107), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1800/2000] tot_loss=2.046 (perp=9.624, rec=0.121), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=2.028 (perp=9.624, rec=0.104), tot_loss_proj:2.677 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=2.046 (perp=9.624, rec=0.122), tot_loss_proj:2.685 [t=0.24s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1950/2000] tot_loss=2.043 (perp=9.624, rec=0.118), tot_loss_proj:2.680 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=2.031 (perp=9.624, rec=0.106), tot_loss_proj:2.671 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] gi looking for return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 82.616 | p: 82.285 | r: 83.156
rouge2     | fm: 47.580 | p: 47.438 | r: 47.816
rougeL     | fm: 72.948 | p: 72.648 | r: 73.514
rougeLsum  | fm: 73.148 | p: 72.838 | r: 73.683
r1fm+r2fm = 130.197

input #63 time: 0:10:48 | total time: 11:40:34


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
cosin similarity: 0.8897437545542236 normalized error: 0.4919963179002097
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 1.874859259969168 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 1.8443270537702192 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 1.8210097990032375 for ['[CLS]bled independence clearing [SEP]']
[Init] best rec loss: 1.5310293456421353 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 1.494383521887698 for ['[CLS] spends adrian mating [SEP]']
[Init] best rec loss: 1.3013654423332823 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 1.2933210474211365 for ['[CLS] water visionsonale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.034 (perp=8.505, rec=0.333), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] horror horror horror [SEP]']
[ 100/2000] tot_loss=1.953 (perp=8.653, rec=0.223), tot_loss_proj:2.226 [t=0.27s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.928 (perp=8.653, rec=0.198), tot_loss_proj:2.219 [t=0.30s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.910 (perp=8.653, rec=0.179), tot_loss_proj:2.222 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.281 (perp=10.235, rec=0.234), tot_loss_proj:2.907 [t=0.25s]
prediction: ['[CLS] strange covent horror [SEP]']
[ 300/2000] tot_loss=2.331 (perp=10.705, rec=0.190), tot_loss_proj:3.125 [t=0.25s]
prediction: ['[CLS] strange allegro horror [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.200 (perp=10.131, rec=0.174), tot_loss_proj:3.362 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.188 (perp=10.131, rec=0.162), tot_loss_proj:3.362 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 450/2000] tot_loss=2.190 (perp=10.131, rec=0.164), tot_loss_proj:3.374 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.179 (perp=10.131, rec=0.153), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.185 (perp=10.131, rec=0.158), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 600/2000] tot_loss=2.172 (perp=10.131, rec=0.146), tot_loss_proj:3.361 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.175 (perp=10.131, rec=0.149), tot_loss_proj:3.360 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.168 (perp=10.131, rec=0.141), tot_loss_proj:3.355 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 750/2000] tot_loss=2.183 (perp=10.131, rec=0.157), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.169 (perp=10.131, rec=0.142), tot_loss_proj:3.360 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.167 (perp=10.131, rec=0.141), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 900/2000] tot_loss=2.172 (perp=10.131, rec=0.146), tot_loss_proj:3.363 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.177 (perp=10.131, rec=0.151), tot_loss_proj:3.354 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1000/2000] tot_loss=2.168 (perp=10.131, rec=0.142), tot_loss_proj:3.359 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1050/2000] tot_loss=2.177 (perp=10.131, rec=0.150), tot_loss_proj:3.357 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1100/2000] tot_loss=2.159 (perp=10.131, rec=0.132), tot_loss_proj:3.358 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1150/2000] tot_loss=2.169 (perp=10.131, rec=0.143), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1200/2000] tot_loss=2.165 (perp=10.131, rec=0.138), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1250/2000] tot_loss=2.168 (perp=10.131, rec=0.142), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1300/2000] tot_loss=2.162 (perp=10.131, rec=0.136), tot_loss_proj:3.352 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1350/2000] tot_loss=2.159 (perp=10.131, rec=0.132), tot_loss_proj:3.360 [t=0.29s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1400/2000] tot_loss=2.171 (perp=10.131, rec=0.145), tot_loss_proj:3.359 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1450/2000] tot_loss=2.163 (perp=10.131, rec=0.136), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1500/2000] tot_loss=2.176 (perp=10.131, rec=0.150), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1550/2000] tot_loss=2.163 (perp=10.131, rec=0.137), tot_loss_proj:3.349 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1600/2000] tot_loss=2.169 (perp=10.131, rec=0.143), tot_loss_proj:3.355 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1650/2000] tot_loss=2.166 (perp=10.131, rec=0.140), tot_loss_proj:3.357 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1700/2000] tot_loss=2.172 (perp=10.131, rec=0.146), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1750/2000] tot_loss=2.167 (perp=10.131, rec=0.141), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1800/2000] tot_loss=2.160 (perp=10.131, rec=0.134), tot_loss_proj:3.356 [t=0.24s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1850/2000] tot_loss=2.164 (perp=10.131, rec=0.138), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1900/2000] tot_loss=2.171 (perp=10.131, rec=0.145), tot_loss_proj:3.351 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1950/2000] tot_loss=2.167 (perp=10.131, rec=0.141), tot_loss_proj:3.357 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[2000/2000] tot_loss=2.180 (perp=10.131, rec=0.154), tot_loss_proj:3.354 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] strange horror allegro [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 82.639 | p: 82.295 | r: 83.194
rouge2     | fm: 47.395 | p: 47.254 | r: 47.592
rougeL     | fm: 73.244 | p: 72.964 | r: 73.782
rougeLsum  | fm: 73.288 | p: 72.872 | r: 73.781
r1fm+r2fm = 130.034

input #64 time: 0:10:53 | total time: 11:51:27


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
cosin similarity: -0.7178626049650516 normalized error: 1.7401795652390009
cosin similarity: 0.7178626049650515 normalized error: 0.5840441504396936
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.0036271810531616 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9474172592163086 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9103438258171082 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.9087744951248169 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.9074904322624207 for ['[CLS] raids yo pot madam harm even https all face [SEP]']
[Init] best rec loss: 0.8844785690307617 for ['[CLS] strategic cylinder tar rebeccaraphy below had causeway committee [SEP]']
[Init] best rec loss: 0.8800411224365234 for ['[CLS] forth drag roger choice rival familiar howellacingbies [SEP]']
[Init] best rec loss: 0.8734747767448425 for ['[CLS] list royal highlybury poor cords purbed may [SEP]']
[Init] best rec loss: 0.8596139550209045 for ['[CLS] accredited crowded shape lo straw out examined more cloud [SEP]']
[Init] best rec loss: 0.8291407823562622 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8241493701934814 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8233164548873901 for ['[CLS] evenhoff general news pu someday overs funmament [SEP]']
[Init] best perm rec loss: 0.82155442237854 for ['[CLS] fun someday overs newsmamenthoff pu general even [SEP]']
[Init] best perm rec loss: 0.8208556175231934 for ['[CLS] fun someday oversmament generalhoff news even pu [SEP]']
[Init] best perm rec loss: 0.8184975981712341 for ['[CLS] news pu general somedaymamenthoff overs even fun [SEP]']
[Init] best perm rec loss: 0.8163646459579468 for ['[CLS] news someday general evenmament overshoff fun pu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.119 (perp=9.649, rec=0.189), tot_loss_proj:2.473 [t=0.27s]
prediction: ['[CLS]ous joy joy joy joyous film joy film [SEP]']
[ 100/2000] tot_loss=2.051 (perp=9.498, rec=0.151), tot_loss_proj:2.396 [t=0.24s]
prediction: ['[CLS], film rom joy joyous film of of [SEP]']
[ 150/2000] tot_loss=1.887 (perp=8.907, rec=0.106), tot_loss_proj:2.266 [t=0.25s]
prediction: ['[CLS], film rom joy joyous film. of [SEP]']
[ 200/2000] tot_loss=1.876 (perp=8.907, rec=0.094), tot_loss_proj:2.264 [t=0.25s]
prediction: ['[CLS], film rom joy joyous film. of [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.139 (perp=9.874, rec=0.164), tot_loss_proj:2.514 [t=0.32s]
prediction: ['[CLS], film rom personal of joyous film weapon [SEP]']
[ 300/2000] tot_loss=1.753 (perp=8.249, rec=0.103), tot_loss_proj:2.139 [t=0.27s]
prediction: ['[CLS], film rom sexual of joyous film. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.602 (perp=7.554, rec=0.091), tot_loss_proj:1.946 [t=0.25s]
prediction: ['[CLS], film rom individual joyous of film. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.374 (perp=6.409, rec=0.092), tot_loss_proj:1.718 [t=0.28s]
prediction: ['[CLS] film rom, the joyous of film. [SEP]']
[ 450/2000] tot_loss=1.484 (perp=6.960, rec=0.092), tot_loss_proj:1.900 [t=0.25s]
prediction: ['[CLS]p rom, the joyous of film. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.383 (perp=6.504, rec=0.082), tot_loss_proj:1.722 [t=0.24s]
prediction: ['[CLS]p rom, joyous of a film. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.271 (perp=5.940, rec=0.083), tot_loss_proj:1.454 [t=0.25s]
prediction: ['[CLS] romp, joyous of a film. [SEP]']
[ 600/2000] tot_loss=1.266 (perp=5.940, rec=0.078), tot_loss_proj:1.458 [t=0.27s]
prediction: ['[CLS] romp, joyous of a film. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.097 (perp=5.097, rec=0.078), tot_loss_proj:1.245 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.101 (perp=5.097, rec=0.081), tot_loss_proj:1.254 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[ 750/2000] tot_loss=1.091 (perp=5.097, rec=0.072), tot_loss_proj:1.236 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.090 (perp=5.097, rec=0.071), tot_loss_proj:1.249 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.087 (perp=5.097, rec=0.067), tot_loss_proj:1.244 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[ 900/2000] tot_loss=1.086 (perp=5.097, rec=0.067), tot_loss_proj:1.241 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.086 (perp=5.097, rec=0.067), tot_loss_proj:1.241 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.088 (perp=5.097, rec=0.069), tot_loss_proj:1.246 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1050/2000] tot_loss=1.098 (perp=5.097, rec=0.079), tot_loss_proj:1.245 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.093 (perp=5.097, rec=0.074), tot_loss_proj:1.240 [t=0.27s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.103 (perp=5.097, rec=0.084), tot_loss_proj:1.246 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1200/2000] tot_loss=1.096 (perp=5.097, rec=0.076), tot_loss_proj:1.246 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.092 (perp=5.097, rec=0.072), tot_loss_proj:1.244 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.083 (perp=5.097, rec=0.064), tot_loss_proj:1.247 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1350/2000] tot_loss=1.097 (perp=5.097, rec=0.077), tot_loss_proj:1.251 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.088 (perp=5.097, rec=0.069), tot_loss_proj:1.245 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.098 (perp=5.097, rec=0.079), tot_loss_proj:1.249 [t=0.24s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1500/2000] tot_loss=1.091 (perp=5.097, rec=0.072), tot_loss_proj:1.246 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.098 (perp=5.097, rec=0.078), tot_loss_proj:1.244 [t=0.27s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.100 (perp=5.097, rec=0.081), tot_loss_proj:1.242 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1650/2000] tot_loss=1.095 (perp=5.097, rec=0.076), tot_loss_proj:1.247 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.091 (perp=5.097, rec=0.072), tot_loss_proj:1.242 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.102 (perp=5.097, rec=0.082), tot_loss_proj:1.255 [t=0.27s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1800/2000] tot_loss=1.090 (perp=5.097, rec=0.070), tot_loss_proj:1.255 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.090 (perp=5.097, rec=0.070), tot_loss_proj:1.240 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.088 (perp=5.097, rec=0.068), tot_loss_proj:1.247 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1950/2000] tot_loss=1.088 (perp=5.097, rec=0.069), tot_loss_proj:1.255 [t=0.26s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.092 (perp=5.097, rec=0.072), tot_loss_proj:1.247 [t=0.25s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous romp, of a film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.836 | p: 82.447 | r: 83.329
rouge2     | fm: 48.055 | p: 47.973 | r: 48.193
rougeL     | fm: 73.672 | p: 73.400 | r: 74.173
rougeLsum  | fm: 73.717 | p: 73.344 | r: 74.245
r1fm+r2fm = 130.892

input #65 time: 0:10:45 | total time: 12:02:12


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
cosin similarity: -0.9602693402946472 normalized error: 1.8654588241675922
cosin similarity: 0.9602693402946472 normalized error: 0.41839710947482045
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 1.9293739671387775 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 1.8552600330721851 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 1.830793744364479 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 1.761128777721764 for ['[CLS] school divisional labor liberals [SEP]']
[Init] best rec loss: 1.7438727355052204 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 1.5280836521470906 for ['[CLS] space leader screen [CLS] [SEP]']
[Init] best rec loss: 1.4192977185046012 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 1.2415355689949863 for ['[CLS] finish eachensis clark [SEP]']
[Init] best perm rec loss: 1.2339681075273201 for ['[CLS] each clarkensis finish [SEP]']
[Init] best perm rec loss: 1.2306118275322921 for ['[CLS]ensis clark each finish [SEP]']
[Init] best perm rec loss: 1.2279674772229399 for ['[CLS] eachensis clark finish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.069 (perp=13.377, rec=0.393), tot_loss_proj:3.406 [t=0.26s]
prediction: ['[CLS] firmly fan tolkien loved [SEP]']
[ 100/2000] tot_loss=2.056 (perp=9.181, rec=0.220), tot_loss_proj:2.444 [t=0.28s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 150/2000] tot_loss=2.008 (perp=9.181, rec=0.172), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 200/2000] tot_loss=1.997 (perp=9.181, rec=0.161), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.975 (perp=9.181, rec=0.139), tot_loss_proj:2.456 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 300/2000] tot_loss=1.986 (perp=9.181, rec=0.150), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.982 (perp=9.181, rec=0.146), tot_loss_proj:2.462 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.181, rec=0.130), tot_loss_proj:2.442 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 450/2000] tot_loss=1.981 (perp=9.181, rec=0.145), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.181, rec=0.135), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.966 (perp=9.181, rec=0.130), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.181, rec=0.139), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.963 (perp=9.181, rec=0.126), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.973 (perp=9.181, rec=0.137), tot_loss_proj:2.442 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 750/2000] tot_loss=1.971 (perp=9.181, rec=0.135), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.955 (perp=9.181, rec=0.119), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.973 (perp=9.181, rec=0.137), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 900/2000] tot_loss=1.968 (perp=9.181, rec=0.131), tot_loss_proj:2.448 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.973 (perp=9.181, rec=0.137), tot_loss_proj:2.457 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.967 (perp=9.181, rec=0.131), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1050/2000] tot_loss=1.962 (perp=9.181, rec=0.126), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.957 (perp=9.181, rec=0.121), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.977 (perp=9.181, rec=0.140), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1200/2000] tot_loss=1.957 (perp=9.181, rec=0.121), tot_loss_proj:2.449 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.970 (perp=9.181, rec=0.134), tot_loss_proj:2.451 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.970 (perp=9.181, rec=0.134), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1350/2000] tot_loss=1.961 (perp=9.181, rec=0.125), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.957 (perp=9.181, rec=0.121), tot_loss_proj:2.447 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.963 (perp=9.181, rec=0.126), tot_loss_proj:2.448 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1500/2000] tot_loss=1.980 (perp=9.181, rec=0.144), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=9.181, rec=0.125), tot_loss_proj:2.450 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.963 (perp=9.181, rec=0.127), tot_loss_proj:2.452 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1650/2000] tot_loss=1.952 (perp=9.181, rec=0.116), tot_loss_proj:2.451 [t=0.28s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.961 (perp=9.181, rec=0.125), tot_loss_proj:2.456 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.964 (perp=9.181, rec=0.128), tot_loss_proj:2.453 [t=0.28s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1800/2000] tot_loss=1.968 (perp=9.181, rec=0.131), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.965 (perp=9.181, rec=0.128), tot_loss_proj:2.449 [t=0.28s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.972 (perp=9.181, rec=0.136), tot_loss_proj:2.447 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1950/2000] tot_loss=1.967 (perp=9.181, rec=0.131), tot_loss_proj:2.445 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.964 (perp=9.181, rec=0.128), tot_loss_proj:2.450 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] longtime tolkien tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 143.333

[Aggregate metrics]:
rouge1     | fm: 82.833 | p: 82.593 | r: 83.363
rouge2     | fm: 48.289 | p: 48.215 | r: 48.412
rougeL     | fm: 73.826 | p: 73.546 | r: 74.313
rougeLsum  | fm: 73.803 | p: 73.464 | r: 74.312
r1fm+r2fm = 131.122

input #66 time: 0:10:46 | total time: 12:12:59


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
cosin similarity: 0.7089905831605775 normalized error: 0.5944421463060496
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9364231824874878 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9243518114089966 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9219090342521667 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9012067914009094 for ['[CLS] gilbert bid released wonder needmeral historic comes repeatedly judgement [SEP]']
[Init] best rec loss: 0.8842928409576416 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.8547902703285217 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.8520013093948364 for ['[CLS] flag fig before gordon quinlantop now seryu power [SEP]']
[Init] best rec loss: 0.8488348722457886 for ['[CLS]bling trade mc fitzgerald find cape wave razor anti us [SEP]']
[Init] best rec loss: 0.8310950398445129 for ['[CLS] dams zeroently all committed oftenу platelich duke [SEP]']
[Init] best perm rec loss: 0.8303163051605225 for ['[CLS] often committed duke all zerolichу dams plateently [SEP]']
[Init] best perm rec loss: 0.8294693827629089 for ['[CLS]lichently duke committed dams often plate zeroу all [SEP]']
[Init] best perm rec loss: 0.8290266394615173 for ['[CLS] plate zero often committedlichу all damsently duke [SEP]']
[Init] best perm rec loss: 0.827275276184082 for ['[CLS] dukeently committed often alllich plateу dams zero [SEP]']
[Init] best perm rec loss: 0.8260548710823059 for ['[CLS]уentlylich plate duke zero often committed all dams [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.411 (perp=10.741, rec=0.263), tot_loss_proj:2.779 [t=0.25s]
prediction: ['[CLS] heart kind away amp academy,warmingvinsky kind [SEP]']
[ 100/2000] tot_loss=2.412 (perp=11.333, rec=0.145), tot_loss_proj:2.954 [t=0.25s]
prediction: ['[CLS] heart kind additionwarental,warming nonental [SEP]']
[ 150/2000] tot_loss=2.327 (perp=11.116, rec=0.104), tot_loss_proj:3.032 [t=0.25s]
prediction: ['[CLS] heart kindcutwarental,warming nonental [SEP]']
[ 200/2000] tot_loss=2.253 (perp=10.755, rec=0.102), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] heart kindgmgmental,warming nonental [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.106 (perp=9.485, rec=0.209), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] heart kindjuental,warming nongmental [SEP]']
[ 300/2000] tot_loss=2.070 (perp=9.209, rec=0.228), tot_loss_proj:2.412 [t=0.26s]
prediction: ['[CLS] heart kind氷 ;,warming nongmental [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.098 (perp=9.270, rec=0.244), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS], kindipental heartwarming non kindental [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.988 (perp=8.915, rec=0.205), tot_loss_proj:2.337 [t=0.25s]
prediction: ['[CLS] kindipental heartwarming, non kindental [SEP]']
[ 450/2000] tot_loss=1.950 (perp=8.915, rec=0.167), tot_loss_proj:2.338 [t=0.26s]
prediction: ['[CLS] kindipental heartwarming, non kindental [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.671 (perp=7.589, rec=0.153), tot_loss_proj:1.991 [t=0.25s]
prediction: ['[CLS] kind heartwarming,gmental non kindental [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.482 (perp=6.747, rec=0.132), tot_loss_proj:1.721 [t=0.25s]
prediction: ['[CLS] kind heartwarming, kindental nongmental [SEP]']
[ 600/2000] tot_loss=1.467 (perp=6.747, rec=0.118), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] kind heartwarming, kindental nongmental [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.620 (perp=7.531, rec=0.114), tot_loss_proj:1.932 [t=0.26s]
prediction: ['[CLS] kind heartwarming, kindgm nongmental [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.616 (perp=7.531, rec=0.110), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] kind heartwarming, kindgm nongmental [SEP]']
[ 750/2000] tot_loss=1.555 (perp=7.254, rec=0.104), tot_loss_proj:1.880 [t=0.26s]
prediction: ['[CLS] kind heartwarming, kindju nongmental [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.681 (perp=7.882, rec=0.105), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS]ming heartwarming, kind nonjugmental [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.677 (perp=7.882, rec=0.101), tot_loss_proj:1.899 [t=0.25s]
prediction: ['[CLS]ming heartwarming, kind nonjugmental [SEP]']
[ 900/2000] tot_loss=1.680 (perp=7.882, rec=0.104), tot_loss_proj:1.907 [t=0.25s]
prediction: ['[CLS]ming heartwarming, kind nonjugmental [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.544 (perp=7.222, rec=0.100), tot_loss_proj:1.771 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1000/2000] tot_loss=1.535 (perp=7.222, rec=0.091), tot_loss_proj:1.775 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1050/2000] tot_loss=1.531 (perp=7.222, rec=0.087), tot_loss_proj:1.772 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1100/2000] tot_loss=1.529 (perp=7.222, rec=0.084), tot_loss_proj:1.774 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1150/2000] tot_loss=1.529 (perp=7.222, rec=0.085), tot_loss_proj:1.769 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1200/2000] tot_loss=1.535 (perp=7.222, rec=0.091), tot_loss_proj:1.766 [t=0.27s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1250/2000] tot_loss=1.525 (perp=7.222, rec=0.081), tot_loss_proj:1.760 [t=0.28s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1300/2000] tot_loss=1.530 (perp=7.222, rec=0.086), tot_loss_proj:1.764 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1350/2000] tot_loss=1.527 (perp=7.222, rec=0.082), tot_loss_proj:1.767 [t=0.29s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1400/2000] tot_loss=1.526 (perp=7.222, rec=0.082), tot_loss_proj:1.770 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1450/2000] tot_loss=1.529 (perp=7.222, rec=0.085), tot_loss_proj:1.770 [t=0.28s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1500/2000] tot_loss=1.522 (perp=7.222, rec=0.077), tot_loss_proj:1.770 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=7.222, rec=0.080), tot_loss_proj:1.765 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.533 (perp=7.222, rec=0.089), tot_loss_proj:1.765 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1650/2000] tot_loss=1.525 (perp=7.222, rec=0.081), tot_loss_proj:1.767 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.532 (perp=7.222, rec=0.088), tot_loss_proj:1.770 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.529 (perp=7.222, rec=0.085), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1800/2000] tot_loss=1.524 (perp=7.222, rec=0.079), tot_loss_proj:1.768 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.529 (perp=7.222, rec=0.085), tot_loss_proj:1.772 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.517 (perp=7.222, rec=0.072), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
[1950/2000] tot_loss=1.520 (perp=7.222, rec=0.076), tot_loss_proj:1.765 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.516 (perp=7.222, rec=0.072), tot_loss_proj:1.764 [t=0.26s]
prediction: ['[CLS] heartwarming, kind nonmingjugmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming, kind nonmingjugmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 82.851 | p: 82.502 | r: 83.369
rouge2     | fm: 47.981 | p: 47.915 | r: 48.076
rougeL     | fm: 73.786 | p: 73.535 | r: 74.270
rougeLsum  | fm: 73.914 | p: 73.627 | r: 74.420
r1fm+r2fm = 130.832

input #67 time: 0:10:47 | total time: 12:23:47


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
cosin similarity: 0.7579495317309078 normalized error: 0.5776880740757563
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9666261672973633 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9524903893470764 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.821449339389801 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.7973076701164246 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.7666670680046082 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 0.7659441232681274 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.6998501420021057 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.6918004751205444 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.6903947591781616 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.6883867383003235 for ['[CLS]yn comfort floor possibly died beth. form councils medal viewiferous riding [SEP]']
[Init] best perm rec loss: 0.6881512403488159 for ['[CLS] medal. beth possibly floor councils form diedyn riding viewiferous comfort [SEP]']
[Init] best perm rec loss: 0.6881235241889954 for ['[CLS] form diedyn floor councils possibly riding. view medaliferous beth comfort [SEP]']
[Init] best perm rec loss: 0.6854112148284912 for ['[CLS]yn beth form.iferous died comfort possibly riding floor councils medal view [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.170 (perp=9.953, rec=0.179), tot_loss_proj:2.355 [t=0.26s]
prediction: ["[CLS] un absurd'absurd rehention and guinea very vicious, absurd [SEP]"]
[ 100/2000] tot_loss=2.199 (perp=10.433, rec=0.112), tot_loss_proj:2.461 [t=0.26s]
prediction: ['[CLS] un absurduthuth reomption andomp very vicious, absurd [SEP]']
[ 150/2000] tot_loss=1.939 (perp=9.240, rec=0.091), tot_loss_proj:2.168 [t=0.25s]
prediction: ['[CLS] uncouthsible reompsible andomp very vicious, absurd [SEP]']
[ 200/2000] tot_loss=1.876 (perp=8.949, rec=0.086), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] uncouthsibleompompsible andomp very vicious, absurd [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.832 (perp=8.497, rec=0.133), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] uncouthsible inchensibleomp and severe vicious, absurd [SEP]']
[ 300/2000] tot_loss=1.763 (perp=8.370, rec=0.089), tot_loss_proj:1.951 [t=0.26s]
prediction: ['[CLS] uncouthsible inchensibleomp and vicious vicious, absurd [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.767 (perp=8.370, rec=0.093), tot_loss_proj:1.952 [t=0.26s]
prediction: ['[CLS] uncouthsible inchensibleomp and vicious vicious, absurd [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.729 (perp=8.213, rec=0.086), tot_loss_proj:1.940 [t=0.25s]
prediction: ['[CLS] uncouthsible inchensibleomp and vicious, vicious absurd [SEP]']
[ 450/2000] tot_loss=1.635 (perp=7.771, rec=0.081), tot_loss_proj:1.866 [t=0.26s]
prediction: ['[CLS] uncouthsibleomphensibleomp and vicious, vicious absurd [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.565 (perp=7.475, rec=0.070), tot_loss_proj:1.784 [t=0.24s]
prediction: ['[CLS] uncouthsibleomphensibleomp, vicious and vicious absurd [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.578 (perp=7.475, rec=0.083), tot_loss_proj:1.802 [t=0.25s]
prediction: ['[CLS] uncouthsibleomphensibleomp, vicious and vicious absurd [SEP]']
[ 600/2000] tot_loss=1.576 (perp=7.475, rec=0.081), tot_loss_proj:1.797 [t=0.26s]
prediction: ['[CLS] uncouthsibleomphensibleomp, vicious and vicious absurd [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.745 (perp=8.334, rec=0.078), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS] uncouthsibleomphensibleomp,inge and vicious absurd [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.814 (perp=8.696, rec=0.075), tot_loss_proj:2.057 [t=0.25s]
prediction: ['[CLS] uncouthromsibleomphensibleomp, and vicious absurd [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.559, rec=0.082), tot_loss_proj:1.844 [t=0.27s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, and vicious absurd [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.525 (perp=7.303, rec=0.065), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, vicious and absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.534 (perp=7.303, rec=0.074), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, vicious and absurd [SEP]']
[ 900/2000] tot_loss=1.535 (perp=7.303, rec=0.074), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, vicious and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.538 (perp=7.303, rec=0.077), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, vicious and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.533 (perp=7.303, rec=0.072), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, vicious and absurd [SEP]']
[1050/2000] tot_loss=1.530 (perp=7.303, rec=0.069), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS] uncouthocsibleomphensibleomp, vicious and absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.593 (perp=7.627, rec=0.067), tot_loss_proj:1.772 [t=0.26s]
prediction: ['[CLS] uncouthresibleomphensibleomp, vicious and absurd [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.501 (perp=7.132, rec=0.075), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] uncouthsibleomphensibleompre, vicious and absurd [SEP]']
[1200/2000] tot_loss=1.485 (perp=7.132, rec=0.059), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] uncouthsibleomphensibleompre, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.350 (perp=6.334, rec=0.083), tot_loss_proj:1.461 [t=0.27s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=1.332 (perp=6.334, rec=0.065), tot_loss_proj:1.469 [t=0.26s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
[1350/2000] tot_loss=1.336 (perp=6.334, rec=0.069), tot_loss_proj:1.470 [t=0.26s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=1.345 (perp=6.334, rec=0.078), tot_loss_proj:1.462 [t=0.25s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=1.342 (perp=6.334, rec=0.076), tot_loss_proj:1.471 [t=0.27s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
[1500/2000] tot_loss=1.341 (perp=6.334, rec=0.075), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.348 (perp=6.334, rec=0.081), tot_loss_proj:1.470 [t=0.27s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.346 (perp=6.334, rec=0.079), tot_loss_proj:1.475 [t=0.27s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
[1650/2000] tot_loss=1.340 (perp=6.334, rec=0.073), tot_loss_proj:1.467 [t=0.25s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.330 (perp=6.334, rec=0.063), tot_loss_proj:1.466 [t=0.24s]
prediction: ['[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.294 (perp=6.075, rec=0.079), tot_loss_proj:1.429 [t=0.25s]
prediction: ['[CLS] uncouthresibleomprehensible, vicious and absurd [SEP]']
[1800/2000] tot_loss=1.284 (perp=6.075, rec=0.069), tot_loss_proj:1.431 [t=0.25s]
prediction: ['[CLS] uncouthresibleomprehensible, vicious and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.282 (perp=6.075, rec=0.067), tot_loss_proj:1.427 [t=0.25s]
prediction: ['[CLS] uncouthresibleomprehensible, vicious and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.291 (perp=6.075, rec=0.076), tot_loss_proj:1.439 [t=0.26s]
prediction: ['[CLS] uncouthresibleomprehensible, vicious and absurd [SEP]']
[1950/2000] tot_loss=1.287 (perp=6.075, rec=0.072), tot_loss_proj:1.439 [t=0.26s]
prediction: ['[CLS] uncouthresibleomprehensible, vicious and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.288 (perp=6.075, rec=0.073), tot_loss_proj:1.427 [t=0.28s]
prediction: ['[CLS] uncouthresibleomprehensible, vicious and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouthsibleompomprehensible, vicious and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 54.545 | p: 60.000 | r: 50.000
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 131.469

[Aggregate metrics]:
rouge1     | fm: 82.798 | p: 82.573 | r: 83.210
rouge2     | fm: 48.041 | p: 48.029 | r: 48.178
rougeL     | fm: 73.806 | p: 73.654 | r: 74.162
rougeLsum  | fm: 73.982 | p: 73.737 | r: 74.452
r1fm+r2fm = 130.839

input #68 time: 0:10:50 | total time: 12:34:37


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
cosin similarity: -0.7112078402311113 normalized error: 1.7043868488471028
cosin similarity: 0.7112078402311114 normalized error: 0.5980756544836167
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.947589635848999 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9100350737571716 for ['[CLS] ii formpoint visual frozenception abc sa circuit achievement answered muslim sinkmable closer standings [SEP]']
[Init] best rec loss: 0.9054116606712341 for ['[CLS] graceful additional notes lease gotphone word staff open telling sad corporation inquisition damage special coast [SEP]']
[Init] best rec loss: 0.9035710692405701 for ['[CLS] it dressednysies salvation go fault pierre decidedoit whilecamp drowning tellingitic peninsula [SEP]']
[Init] best rec loss: 0.8936435580253601 for ['[CLS] happy winter conference mortallybara shiva passing phase izzyrak home seville lynn grounds immortals which [SEP]']
[Init] best rec loss: 0.8820329308509827 for ['[CLS] nan control breathui mines lane choice base ridgepped eve lattergrantusion! inside [SEP]']
[Init] best rec loss: 0.8818706274032593 for ['[CLS] appointed long vice racingnio centre 1890s nan elder mix nose early gamma indeed underground minds [SEP]']
[Init] best perm rec loss: 0.8773277997970581 for ['[CLS] early vice long nose elder appointednio gamma centre mix indeed nan 1890s minds racing underground [SEP]']
[Init] best perm rec loss: 0.8766458034515381 for ['[CLS] racing appointed earlynio elder underground vice centre mix indeed nose gamma 1890s long minds nan [SEP]']
[Init] best perm rec loss: 0.8761093020439148 for ['[CLS] elder underground vice centre gamma minds indeed early nose 1890snio appointed racing nan long mix [SEP]']
[Init] best perm rec loss: 0.8753983378410339 for ['[CLS] 1890s vice eldernio early centre mix long indeed appointed racing gamma underground nan nose minds [SEP]']
[Init] best perm rec loss: 0.8737422823905945 for ['[CLS] appointed underground nan centre elder vice nose long 1890s mix gamma racing earlynio indeed minds [SEP]']
[Init] best perm rec loss: 0.8720600605010986 for ['[CLS] long 1890s centre indeed underground early nosenio appointed gamma racing nan mix minds elder vice [SEP]']
[Init] best perm rec loss: 0.8719090819358826 for ['[CLS] appointed centre underground vice indeed 1890s long gamma elder nan nose early racingnio mix minds [SEP]']
[Init] best perm rec loss: 0.8715306520462036 for ['[CLS] elder indeed underground minds early appointednio nose long gamma 1890s nan racing vice mix centre [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.448 (perp=11.078, rec=0.232), tot_loss_proj:2.646 [t=0.28s]
prediction: ['[CLS] real smart - funny winner smart distinctly funny funny subtlee ; [SEP], radiantdable [SEP]']
[ 100/2000] tot_loss=1.892 (perp=8.745, rec=0.143), tot_loss_proj:2.233 [t=0.26s]
prediction: ['[CLS] real winner - funny winner smart, subtle subtle subtlene. winner,onant [SEP]']
[ 150/2000] tot_loss=1.558 (perp=7.203, rec=0.118), tot_loss_proj:1.844 [t=0.26s]
prediction: ['[CLS] real winner - funny winner smart, funny, subtle, and -,onant [SEP]']
[ 200/2000] tot_loss=1.749 (perp=8.189, rec=0.112), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] real winner - funny winner smart, funny, subtle res and res,onant [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.375 (perp=5.881, rec=0.199), tot_loss_proj:1.454 [t=0.25s]
prediction: ['[CLS] real winner - smart winner, smart, funny, subtle, and resonant [SEP]']
[ 300/2000] tot_loss=1.346 (perp=5.881, rec=0.170), tot_loss_proj:1.441 [t=0.24s]
prediction: ['[CLS] real winner - smart winner, smart, funny, subtle, and resonant [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.637 (perp=6.109, rec=0.415), tot_loss_proj:1.570 [t=0.26s]
prediction: ['[CLS] real winner - winner smart, smart, subtle. subtle, and resonant [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.701 (perp=7.138, rec=0.274), tot_loss_proj:2.148 [t=0.26s]
prediction: ['[CLS] real says - winner. smart, smart, subtle subtle, and neveronant [SEP]']
[ 450/2000] tot_loss=1.611 (perp=6.956, rec=0.219), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] real parramatta - winner. smart, smart, characters subtle, and resonant [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.763 (perp=7.667, rec=0.229), tot_loss_proj:1.930 [t=0.25s]
prediction: ['[CLS] real rated - winner. smart, smart, characters, subtle and zooonant [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.439 (perp=6.112, rec=0.217), tot_loss_proj:1.591 [t=0.27s]
prediction: ['[CLS] real rated - winner smart, smart, characters, subtle and resonant. [SEP]']
[ 600/2000] tot_loss=1.422 (perp=6.112, rec=0.200), tot_loss_proj:1.588 [t=0.26s]
prediction: ['[CLS] real rated - winner smart, smart, characters, subtle and resonant. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.366 (perp=5.895, rec=0.187), tot_loss_proj:1.532 [t=0.27s]
prediction: ['[CLS] real rated - winner characters, smart, smart, subtle and resonant. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.316 (perp=5.644, rec=0.187), tot_loss_proj:1.452 [t=0.25s]
prediction: ['[CLS] real rated characters - winner, smart, smart, subtle and resonant. [SEP]']
[ 750/2000] tot_loss=1.294 (perp=5.644, rec=0.165), tot_loss_proj:1.456 [t=0.26s]
prediction: ['[CLS] real rated characters - winner, smart, smart, subtle and resonant. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.373 (perp=5.981, rec=0.177), tot_loss_proj:1.540 [t=0.26s]
prediction: ['[CLS] real rated subtle - winner, smart, smart, subtle and resonant. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.276 (perp=5.518, rec=0.173), tot_loss_proj:1.446 [t=0.27s]
prediction: ['[CLS] real and subtle - winner, smart, smart, subtle - resonant. [SEP]']
[ 900/2000] tot_loss=1.275 (perp=5.518, rec=0.172), tot_loss_proj:1.445 [t=0.25s]
prediction: ['[CLS] real and subtle - winner, smart, smart, subtle - resonant. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.215 (perp=5.290, rec=0.157), tot_loss_proj:1.399 [t=0.25s]
prediction: ['[CLS] real, subtle - winner - smart, smart, subtle, resonant. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.198 (perp=5.125, rec=0.173), tot_loss_proj:1.341 [t=0.27s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1050/2000] tot_loss=1.179 (perp=5.125, rec=0.154), tot_loss_proj:1.343 [t=0.25s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.188 (perp=5.125, rec=0.163), tot_loss_proj:1.346 [t=0.26s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.186 (perp=5.157, rec=0.155), tot_loss_proj:1.342 [t=0.25s]
prediction: ['[CLS] real and subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1200/2000] tot_loss=1.185 (perp=5.157, rec=0.154), tot_loss_proj:1.344 [t=0.26s]
prediction: ['[CLS] real and subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.185 (perp=5.157, rec=0.154), tot_loss_proj:1.346 [t=0.25s]
prediction: ['[CLS] real and subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.170 (perp=5.157, rec=0.139), tot_loss_proj:1.343 [t=0.25s]
prediction: ['[CLS] real and subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1350/2000] tot_loss=1.171 (perp=5.125, rec=0.146), tot_loss_proj:1.352 [t=0.26s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.173 (perp=5.125, rec=0.148), tot_loss_proj:1.347 [t=0.27s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.171 (perp=5.125, rec=0.146), tot_loss_proj:1.342 [t=0.24s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1500/2000] tot_loss=1.169 (perp=5.125, rec=0.144), tot_loss_proj:1.346 [t=0.26s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.170 (perp=5.125, rec=0.145), tot_loss_proj:1.342 [t=0.26s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.169 (perp=5.125, rec=0.144), tot_loss_proj:1.345 [t=0.25s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1650/2000] tot_loss=1.169 (perp=5.125, rec=0.144), tot_loss_proj:1.335 [t=0.27s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.162 (perp=5.125, rec=0.137), tot_loss_proj:1.342 [t=0.25s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.176 (perp=5.125, rec=0.151), tot_loss_proj:1.341 [t=0.24s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1800/2000] tot_loss=1.161 (perp=5.125, rec=0.136), tot_loss_proj:1.345 [t=0.27s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.171 (perp=5.125, rec=0.146), tot_loss_proj:1.349 [t=0.26s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.155 (perp=5.125, rec=0.130), tot_loss_proj:1.345 [t=0.26s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
[1950/2000] tot_loss=1.160 (perp=5.125, rec=0.135), tot_loss_proj:1.350 [t=0.27s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.169 (perp=5.125, rec=0.144), tot_loss_proj:1.343 [t=0.25s]
prediction: ['[CLS] real, subtle winner - - smart, smart, subtle, resonant. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] real winner - smart winner smart, funny, subtle res and res,onant [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 61.538 | r: 80.000
rouge2     | fm: 38.095 | p: 33.333 | r: 44.444
rougeL     | fm: 69.565 | p: 61.538 | r: 80.000
rougeLsum  | fm: 69.565 | p: 61.538 | r: 80.000
r1fm+r2fm = 107.660

[Aggregate metrics]:
rouge1     | fm: 82.597 | p: 82.271 | r: 83.128
rouge2     | fm: 47.887 | p: 47.788 | r: 48.019
rougeL     | fm: 73.854 | p: 73.546 | r: 74.381
rougeLsum  | fm: 73.928 | p: 73.592 | r: 74.424
r1fm+r2fm = 130.484

input #69 time: 0:11:01 | total time: 12:45:38


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
cosin similarity: 0.8917103407547794 normalized error: 0.5638843529053624
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 1.7970043049026638 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 1.5994827807789185 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 1.4548180353512685 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 1.4481823068865651 for ['[CLS] piano myth casualty immediately vocal right bottle [SEP]']
[Init] best rec loss: 1.328233292199492 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 1.1803363520140064 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 1.1794856280623118 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 1.1764670266942903 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 1.176198336517593 for ['[CLS] muscle guybution party bob modern ি [SEP]']
[Init] best perm rec loss: 1.175268694659985 for ['[CLS] muscle modernbution party ি guy bob [SEP]']
[Init] best perm rec loss: 1.1728360348227085 for ['[CLS] guy modern musclebution ি party bob [SEP]']
[Init] best perm rec loss: 1.17282422239566 for ['[CLS] িbution muscle guy party modern bob [SEP]']
[Init] best perm rec loss: 1.1726098840835648 for ['[CLS] muscle bob modernbution ি guy party [SEP]']
[Init] best perm rec loss: 1.1690425348442939 for ['[CLS] guy িbution modern muscle party bob [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.874 (perp=12.307, rec=0.413), tot_loss_proj:4.327 [t=0.25s]
prediction: ['[CLS] storm sometimes public.bn after through [SEP]']
[ 100/2000] tot_loss=2.312 (perp=9.940, rec=0.324), tot_loss_proj:3.399 [t=0.25s]
prediction: ['[CLS] storm hardly institution clunky through [SEP]']
[ 150/2000] tot_loss=1.967 (perp=8.580, rec=0.251), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] cong clunk clunky through [SEP]']
[ 200/2000] tot_loss=1.741 (perp=7.645, rec=0.212), tot_loss_proj:2.652 [t=0.25s]
prediction: ['[CLS] cl clunk clunky on [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.638 (perp=11.847, rec=0.269), tot_loss_proj:3.643 [t=0.25s]
prediction: ['[CLS] brooke clips cl opponent getsunky [SEP]']
[ 300/2000] tot_loss=2.298 (perp=10.493, rec=0.200), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS] brooke screen cl opponent clunky [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.082 (perp=9.437, rec=0.194), tot_loss_proj:2.888 [t=0.27s]
prediction: ['[CLS] screen screen cl brooke clunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.049 (perp=9.437, rec=0.161), tot_loss_proj:2.883 [t=0.25s]
prediction: ['[CLS] screen screen cl brooke clunky [SEP]']
[ 450/2000] tot_loss=1.559 (perp=7.054, rec=0.148), tot_loss_proj:2.169 [t=0.26s]
prediction: ['[CLS] screen screen clunk clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.561 (perp=7.054, rec=0.150), tot_loss_proj:2.174 [t=0.25s]
prediction: ['[CLS] screen screen clunk clunky [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.880 (perp=8.587, rec=0.163), tot_loss_proj:2.332 [t=0.25s]
prediction: ['[CLS] screen screenunk gets clunky [SEP]']
[ 600/2000] tot_loss=1.926 (perp=8.928, rec=0.140), tot_loss_proj:2.373 [t=0.25s]
prediction: ['[CLS] screen screenhorpe gets clunky [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.948 (perp=9.026, rec=0.143), tot_loss_proj:2.424 [t=0.25s]
prediction: ['[CLS] screen screen gets clunky piece [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.754 (perp=8.090, rec=0.136), tot_loss_proj:2.185 [t=0.24s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.748 (perp=8.090, rec=0.130), tot_loss_proj:2.190 [t=0.24s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.746 (perp=8.090, rec=0.128), tot_loss_proj:2.186 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.742 (perp=8.090, rec=0.124), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.733 (perp=8.090, rec=0.116), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.730 (perp=8.090, rec=0.112), tot_loss_proj:2.186 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.731 (perp=8.090, rec=0.113), tot_loss_proj:2.186 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1050/2000] tot_loss=1.731 (perp=8.090, rec=0.114), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.741 (perp=8.090, rec=0.123), tot_loss_proj:2.189 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.738 (perp=8.090, rec=0.120), tot_loss_proj:2.184 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1200/2000] tot_loss=1.738 (perp=8.090, rec=0.120), tot_loss_proj:2.191 [t=0.24s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.739 (perp=8.090, rec=0.121), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.736 (perp=8.090, rec=0.118), tot_loss_proj:2.188 [t=0.24s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1350/2000] tot_loss=1.731 (perp=8.090, rec=0.113), tot_loss_proj:2.178 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.090, rec=0.119), tot_loss_proj:2.181 [t=0.27s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.729 (perp=8.090, rec=0.111), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1500/2000] tot_loss=1.732 (perp=8.090, rec=0.114), tot_loss_proj:2.177 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.723 (perp=8.090, rec=0.105), tot_loss_proj:2.180 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.737 (perp=8.090, rec=0.119), tot_loss_proj:2.183 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1650/2000] tot_loss=1.731 (perp=8.090, rec=0.114), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.090, rec=0.124), tot_loss_proj:2.182 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.730 (perp=8.090, rec=0.112), tot_loss_proj:2.186 [t=0.27s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1800/2000] tot_loss=1.734 (perp=8.090, rec=0.116), tot_loss_proj:2.184 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=8.090, rec=0.118), tot_loss_proj:2.190 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=8.090, rec=0.110), tot_loss_proj:2.186 [t=0.26s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1950/2000] tot_loss=1.727 (perp=8.090, rec=0.109), tot_loss_proj:2.186 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.734 (perp=8.090, rec=0.116), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] screen piece screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 88.095

[Aggregate metrics]:
rouge1     | fm: 82.411 | p: 82.070 | r: 82.945
rouge2     | fm: 47.574 | p: 47.482 | r: 47.729
rougeL     | fm: 73.596 | p: 73.344 | r: 74.104
rougeLsum  | fm: 73.674 | p: 73.346 | r: 74.222
r1fm+r2fm = 129.985

input #70 time: 0:10:49 | total time: 12:56:27


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
cosin similarity: -0.773327853527467 normalized error: 1.6542214243473703
cosin similarity: 0.7733278535274671 normalized error: 0.5848165919813948
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8921006321907043 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8828422427177429 for ['[CLS] originally oldestfold columns double end shelby strict bass hp rainbow lucy anthem strykerciation [SEP]']
[Init] best rec loss: 0.8440277576446533 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8415377736091614 for ['[CLS]od production romatose smith bloody joker chapter trains via returning question tempoq cholera [SEP]']
[Init] best rec loss: 0.8376414775848389 for ['[CLS] downructuredst once emile eye bill edison judicial joininghil sister wheels saint drove [SEP]']
[Init] best rec loss: 0.8339051604270935 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.828903317451477 for ['[CLS] clips theory social chains landing ignorance mother game experience point ser [MASK] less whatever other [SEP]']
[Init] best rec loss: 0.8116455674171448 for ['[CLS]lon dictionary short prairie mayatypic conditioning flyingto etc men provided star cassidy gems [SEP]']
[Init] best perm rec loss: 0.8079438805580139 for ['[CLS] star short etctypic gems cassidy prairie provided conditioning men flyinglon maya dictionaryto [SEP]']
[Init] best perm rec loss: 0.8078082799911499 for ['[CLS] menlon etc prairie maya conditioning provided cassidy shortto gems star flyingtypic dictionary [SEP]']
[Init] best perm rec loss: 0.8055443167686462 for ['[CLS] gems prairie mayato short star flyingtypiclon cassidy men dictionary provided etc conditioning [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.843 (perp=8.083, rec=0.227), tot_loss_proj:2.169 [t=0.26s]
prediction: ['[CLS] not single my moment jump - - moment jump second no moment status moment moment [SEP]']
[ 100/2000] tot_loss=2.067 (perp=9.512, rec=0.164), tot_loss_proj:2.409 [t=0.26s]
prediction: ['[CLS] not single there a jump - jump moment -ith - seat seat moment seat [SEP]']
[ 150/2000] tot_loss=1.682 (perp=7.818, rec=0.118), tot_loss_proj:2.037 [t=0.26s]
prediction: ['[CLS] not single there a jump - in moment - a - your - moment seat [SEP]']
[ 200/2000] tot_loss=1.700 (perp=8.064, rec=0.087), tot_loss_proj:2.419 [t=0.24s]
prediction: ['[CLS] not single there a jump and in moment - a - your - moment seat [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.651 (perp=7.865, rec=0.078), tot_loss_proj:2.244 [t=0.27s]
prediction: ['[CLS] not single there a and jump in moment - a - your - moment seat [SEP]']
[ 300/2000] tot_loss=1.658 (perp=7.865, rec=0.085), tot_loss_proj:2.236 [t=0.25s]
prediction: ['[CLS] not single there a and jump in moment - a - your - moment seat [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.546 (perp=7.351, rec=0.076), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] not a single there and jump in moment - a - your - moment seat [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.488 (perp=7.048, rec=0.078), tot_loss_proj:2.276 [t=0.25s]
prediction: ["[CLS] not a single moment and jump in there -'- your - moment seat [SEP]"]
[ 450/2000] tot_loss=1.478 (perp=7.048, rec=0.069), tot_loss_proj:2.278 [t=0.25s]
prediction: ["[CLS] not a single moment and jump in there -'- your - moment seat [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.381 (perp=6.441, rec=0.093), tot_loss_proj:2.117 [t=0.26s]
prediction: ["[CLS] not a single moment and jump in there - - your'- moment seat [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.336 (perp=6.136, rec=0.109), tot_loss_proj:2.187 [t=0.26s]
prediction: ["[CLS] not a single moment and jump in there is - -'your moment seat [SEP]"]
[ 600/2000] tot_loss=1.434 (perp=6.768, rec=0.080), tot_loss_proj:2.265 [t=0.27s]
prediction: ["[CLS] not a single moment and jump in there s - -'your moment seat [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.361 (perp=6.387, rec=0.084), tot_loss_proj:2.135 [t=0.25s]
prediction: ["[CLS] not a single moment and jump in there s - -'moment your seat [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.362 (perp=6.387, rec=0.084), tot_loss_proj:2.134 [t=0.25s]
prediction: ["[CLS] not a single moment and jump in there s - -'moment your seat [SEP]"]
[ 750/2000] tot_loss=1.343 (perp=6.387, rec=0.065), tot_loss_proj:2.133 [t=0.26s]
prediction: ["[CLS] not a single moment and jump in there s - -'moment your seat [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.273 (perp=6.033, rec=0.067), tot_loss_proj:2.085 [t=0.25s]
prediction: ["[CLS] s not a single moment and jump in there - -'moment your seat [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.322 (perp=6.272, rec=0.068), tot_loss_proj:1.903 [t=0.26s]
prediction: ["[CLS] s not a single - and jump in there - -'moment your seat [SEP]"]
[ 900/2000] tot_loss=1.329 (perp=6.272, rec=0.074), tot_loss_proj:1.897 [t=0.27s]
prediction: ["[CLS] s not a single - and jump in there - -'moment your seat [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.233 (perp=5.813, rec=0.071), tot_loss_proj:1.771 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - -'moment your seat [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.216 (perp=5.714, rec=0.073), tot_loss_proj:1.711 [t=0.26s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1050/2000] tot_loss=1.216 (perp=5.714, rec=0.074), tot_loss_proj:1.714 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.209 (perp=5.714, rec=0.067), tot_loss_proj:1.715 [t=0.27s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.210 (perp=5.714, rec=0.068), tot_loss_proj:1.725 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1200/2000] tot_loss=1.209 (perp=5.714, rec=0.066), tot_loss_proj:1.711 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.218 (perp=5.714, rec=0.076), tot_loss_proj:1.719 [t=0.27s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.219 (perp=5.714, rec=0.076), tot_loss_proj:1.718 [t=0.27s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1350/2000] tot_loss=1.216 (perp=5.714, rec=0.073), tot_loss_proj:1.725 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.214 (perp=5.714, rec=0.071), tot_loss_proj:1.724 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.210 (perp=5.714, rec=0.068), tot_loss_proj:1.722 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1500/2000] tot_loss=1.202 (perp=5.714, rec=0.060), tot_loss_proj:1.721 [t=0.26s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.212 (perp=5.714, rec=0.069), tot_loss_proj:1.723 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.218 (perp=5.714, rec=0.075), tot_loss_proj:1.717 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1650/2000] tot_loss=1.212 (perp=5.714, rec=0.069), tot_loss_proj:1.720 [t=0.26s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.205 (perp=5.714, rec=0.063), tot_loss_proj:1.721 [t=0.26s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.214 (perp=5.714, rec=0.071), tot_loss_proj:1.717 [t=0.28s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1800/2000] tot_loss=1.218 (perp=5.714, rec=0.075), tot_loss_proj:1.718 [t=0.26s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.215 (perp=5.714, rec=0.073), tot_loss_proj:1.721 [t=0.24s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.215 (perp=5.714, rec=0.072), tot_loss_proj:1.721 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
[1950/2000] tot_loss=1.205 (perp=5.714, rec=0.063), tot_loss_proj:1.720 [t=0.25s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.208 (perp=5.714, rec=0.065), tot_loss_proj:1.720 [t=0.35s]
prediction: ["[CLS] not a single s - and jump in there - - moment'your seat [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] not a single s - and jump in there - - moment'your seat [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 82.650 | p: 82.333 | r: 83.235
rouge2     | fm: 47.278 | p: 47.131 | r: 47.419
rougeL     | fm: 73.586 | p: 73.309 | r: 74.109
rougeLsum  | fm: 73.634 | p: 73.330 | r: 74.124
r1fm+r2fm = 129.928

input #71 time: 0:10:59 | total time: 13:07:27


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
cosin similarity: 0.8619169926329063 normalized error: 0.5020466964876452
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 1.752843905665214 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 1.6520627574430182 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 1.5570253903808349 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 1.5363156906424398 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 1.4755265598408513 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 1.395293902324087 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 1.3948383014151817 for ['[CLS] anne proud walked originally navigation blame spurs junior eastbery and located part swiss [SEP] [SEP]']
[Init] best rec loss: 1.3907338648757994 for ['[CLS] trophy exit ) hear stuffture prey gaytering opera progress spec companyheater broadcasts [SEP]']
[Init] best rec loss: 1.3516572504891111 for ['[CLS] things substitute air favors bishop defined werewolf anywaylusion ghana tonnesboard favorfin cy [SEP]']
[Init] best perm rec loss: 1.350628190650515 for ['[CLS] defined ghana things favorslusionfin werewolf anyway bishopboard favor air tonnes substitute cy [SEP]']
[Init] best perm rec loss: 1.3464317534270858 for ['[CLS] favor defined favors substitute bishop air things anywaylusionboardfin werewolf cy ghana tonnes [SEP]']
[Init] best perm rec loss: 1.3452217314798915 for ['[CLS] ghana anyway air cy things bishop substitutefin werewolf tonnes favor definedboardlusion favors [SEP]']
[Init] best perm rec loss: 1.3448562551891643 for ['[CLS] favor werewolfboard things bishop anyway air cyfin ghana defined favors substitutelusion tonnes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.066 (perp=13.218, rec=0.422), tot_loss_proj:3.771 [t=0.27s]
prediction: ['[CLS] thin agenda itsachal territoryency hard cop transition insisted pick something room. differential [SEP]']
[ 100/2000] tot_loss=2.797 (perp=12.481, rec=0.301), tot_loss_proj:3.656 [t=0.25s]
prediction: ['[CLS] tough resources specific upper time has tough toughac insistedogical something room ( when [SEP]']
[ 150/2000] tot_loss=2.365 (perp=10.690, rec=0.227), tot_loss_proj:3.619 [t=0.25s]
prediction: ['[CLS] tough resourceser more time has tough tough predecessors roogical its time housemates presidential [SEP]']
[ 200/2000] tot_loss=2.369 (perp=10.900, rec=0.189), tot_loss_proj:3.967 [t=0.27s]
prediction: ['[CLS] tough violenceer more time has tough tough print balancing inspired its timeˈ presidential [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.384 (perp=11.106, rec=0.162), tot_loss_proj:3.742 [t=0.26s]
prediction: ['[CLS] violenceer tougher time has tough tough mistake balancing inspired its timeˈ presidential [SEP]']
[ 300/2000] tot_loss=2.525 (perp=11.861, rec=0.153), tot_loss_proj:4.280 [t=0.25s]
prediction: ['[CLS] syndromeer tougher time has tough a simply balancing inspired its time grewenburg [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.252 (perp=10.572, rec=0.138), tot_loss_proj:3.699 [t=0.25s]
prediction: ['[CLS] timeer tougher time has tough a simply balancing inspired violence violence grewenburg [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.159 (perp=10.096, rec=0.139), tot_loss_proj:3.255 [t=0.26s]
prediction: ['[CLS] timeer tougher time has tough a simply balancing philosophy its housematesenburg philosophy [SEP]']
[ 450/2000] tot_loss=2.257 (perp=10.728, rec=0.111), tot_loss_proj:3.291 [t=0.27s]
prediction: ['[CLS] timeer tougher time has tough a simply balancing philosophy violence housematesenburg philosophy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.147 (perp=10.126, rec=0.121), tot_loss_proj:3.144 [t=0.26s]
prediction: ['[CLS] timeer tougher time has tough philosophy simply balancing with violence housematesenburg philosophy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.076 (perp=9.775, rec=0.121), tot_loss_proj:3.226 [t=0.26s]
prediction: ['[CLS] timeer tougher time has tough philosophy balancing simply with violence housematesenburg philosophy [SEP]']
[ 600/2000] tot_loss=2.044 (perp=9.682, rec=0.107), tot_loss_proj:3.332 [t=0.27s]
prediction: ['[CLS] timeer tougher time has tough philosophy balancing simply with violence accompaniedenburg philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.916 (perp=9.006, rec=0.115), tot_loss_proj:2.976 [t=0.26s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing simply with its accompanied philosophy philosophy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.914 (perp=9.006, rec=0.113), tot_loss_proj:2.970 [t=0.26s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing simply with its accompanied philosophy philosophy [SEP]']
[ 750/2000] tot_loss=1.935 (perp=9.112, rec=0.112), tot_loss_proj:3.110 [t=0.26s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing material with its accompanied philosophy philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.138 (perp=10.131, rec=0.112), tot_loss_proj:3.389 [t=0.26s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing philosophy simply a its accompanied philosophy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.866 (perp=8.773, rec=0.111), tot_loss_proj:3.146 [t=0.25s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing philosophy with its simply accompanied philosophy [SEP]']
[ 900/2000] tot_loss=1.974 (perp=9.267, rec=0.120), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing philosophy with its material accompanied philosophy [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.847 (perp=8.643, rec=0.118), tot_loss_proj:2.972 [t=0.26s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing its material philosophy with accompanied philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.829 (perp=8.643, rec=0.101), tot_loss_proj:2.978 [t=0.25s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing its material philosophy with accompanied philosophy [SEP]']
[1050/2000] tot_loss=2.026 (perp=9.603, rec=0.105), tot_loss_proj:3.322 [t=0.26s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy with accompanied philosophy [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.016 (perp=9.549, rec=0.106), tot_loss_proj:3.240 [t=0.27s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.018 (perp=9.549, rec=0.109), tot_loss_proj:3.237 [t=0.27s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
[1200/2000] tot_loss=2.019 (perp=9.549, rec=0.110), tot_loss_proj:3.239 [t=0.26s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.998 (perp=9.441, rec=0.110), tot_loss_proj:3.235 [t=0.26s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=2.001 (perp=9.441, rec=0.113), tot_loss_proj:3.232 [t=0.26s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
[1350/2000] tot_loss=1.994 (perp=9.441, rec=0.105), tot_loss_proj:3.240 [t=0.28s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.992 (perp=9.441, rec=0.104), tot_loss_proj:3.231 [t=0.25s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.981 (perp=9.441, rec=0.093), tot_loss_proj:3.236 [t=0.25s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
[1500/2000] tot_loss=1.997 (perp=9.441, rec=0.109), tot_loss_proj:3.236 [t=0.25s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.100 (perp=9.965, rec=0.107), tot_loss_proj:2.832 [t=0.26s]
prediction: ['[CLS] violenceerenburger time has tough time balancing its material philosophy finch with philosophy [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.907 (perp=9.004, rec=0.106), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
[1650/2000] tot_loss=1.913 (perp=9.004, rec=0.112), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.905 (perp=9.004, rec=0.104), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.004, rec=0.104), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
[1800/2000] tot_loss=1.918 (perp=9.004, rec=0.117), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.897 (perp=9.004, rec=0.096), tot_loss_proj:2.632 [t=0.25s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.897 (perp=9.004, rec=0.096), tot_loss_proj:2.634 [t=0.25s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
[1950/2000] tot_loss=1.909 (perp=9.004, rec=0.108), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[2000/2000] tot_loss=2.071 (perp=9.805, rec=0.110), tot_loss_proj:2.809 [t=0.26s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy finch with philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 53.333 | r: 61.538
rouge2     | fm: 23.077 | p: 21.429 | r: 25.000
rougeL     | fm: 57.143 | p: 53.333 | r: 61.538
rougeLsum  | fm: 57.143 | p: 53.333 | r: 61.538
r1fm+r2fm = 80.220

[Aggregate metrics]:
rouge1     | fm: 82.296 | p: 81.887 | r: 82.984
rouge2     | fm: 46.986 | p: 46.880 | r: 47.168
rougeL     | fm: 73.389 | p: 73.043 | r: 73.909
rougeLsum  | fm: 73.330 | p: 72.980 | r: 73.952
r1fm+r2fm = 129.282

input #72 time: 0:11:00 | total time: 13:18:27


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
cosin similarity: -0.7651320934251609 normalized error: 1.7071232564366776
cosin similarity: 0.7651320934251608 normalized error: 0.5693052337592939
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9642160534858704 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9623100161552429 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9298595786094666 for ['[CLS] bitch natasha [SEP]']
[Init] best rec loss: 0.9027500748634338 for ['[CLS] action founded [SEP]']
[Init] best perm rec loss: 0.8974323868751526 for ['[CLS] founded action [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.785 (perp=10.252, rec=0.735), tot_loss_proj:3.000 [t=0.26s]
prediction: ['[CLS] spin ideas [SEP]']
[ 100/2000] tot_loss=2.522 (perp=9.467, rec=0.628), tot_loss_proj:2.804 [t=0.25s]
prediction: ['[CLS] international filmmaking [SEP]']
[ 150/2000] tot_loss=2.974 (perp=13.257, rec=0.323), tot_loss_proj:3.290 [t=0.25s]
prediction: ['[CLS] burkina bad [SEP]']
[ 200/2000] tot_loss=2.242 (perp=9.832, rec=0.275), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] [SEP] bad [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.204 (perp=9.832, rec=0.237), tot_loss_proj:2.617 [t=0.25s]
prediction: ['[CLS] [SEP] bad [SEP]']
[ 300/2000] tot_loss=2.830 (perp=13.015, rec=0.227), tot_loss_proj:3.003 [t=0.25s]
prediction: ['[CLS] filmmaking bad [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.162 (perp=9.724, rec=0.218), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.157 (perp=9.724, rec=0.212), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.146 (perp=9.724, rec=0.202), tot_loss_proj:2.047 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.135 (perp=9.724, rec=0.191), tot_loss_proj:2.028 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.141 (perp=9.724, rec=0.196), tot_loss_proj:2.031 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.127 (perp=9.724, rec=0.182), tot_loss_proj:2.034 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.144 (perp=9.724, rec=0.199), tot_loss_proj:2.024 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.110 (perp=9.724, rec=0.166), tot_loss_proj:2.027 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.094 (perp=9.724, rec=0.149), tot_loss_proj:2.028 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.153 (perp=9.724, rec=0.208), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.138 (perp=9.724, rec=0.193), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.126 (perp=9.724, rec=0.181), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.134 (perp=9.724, rec=0.189), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.126 (perp=9.724, rec=0.181), tot_loss_proj:2.019 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.118 (perp=9.724, rec=0.173), tot_loss_proj:2.025 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.108 (perp=9.724, rec=0.163), tot_loss_proj:2.005 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.090 (perp=9.724, rec=0.146), tot_loss_proj:1.998 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.111 (perp=9.724, rec=0.166), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.091 (perp=9.724, rec=0.146), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.153 (perp=9.724, rec=0.208), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.125 (perp=9.724, rec=0.181), tot_loss_proj:2.011 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.103 (perp=9.724, rec=0.158), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.083 (perp=9.724, rec=0.138), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.086 (perp=9.724, rec=0.141), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.093 (perp=9.724, rec=0.148), tot_loss_proj:2.000 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.076 (perp=9.724, rec=0.131), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.071 (perp=9.724, rec=0.126), tot_loss_proj:2.021 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.066 (perp=9.724, rec=0.121), tot_loss_proj:2.023 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.072 (perp=9.724, rec=0.127), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.084 (perp=9.724, rec=0.140), tot_loss_proj:2.010 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.075 (perp=9.724, rec=0.130), tot_loss_proj:2.024 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.079 (perp=9.724, rec=0.134), tot_loss_proj:2.004 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.087 (perp=9.724, rec=0.142), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.078 (perp=9.724, rec=0.133), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.654 | p: 82.332 | r: 83.175
rouge2     | fm: 47.773 | p: 47.605 | r: 47.973
rougeL     | fm: 73.671 | p: 73.362 | r: 74.288
rougeLsum  | fm: 73.659 | p: 73.354 | r: 74.259
r1fm+r2fm = 130.427

input #73 time: 0:10:44 | total time: 13:29:12


Running input #74 of 100.
reference: 
========================
share 
========================
cosin similarity: 0.5745548755000613 normalized error: 0.7164188335902618
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8526026606559753 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.732341468334198 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.7091285586357117 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.958 (perp=8.178, rec=0.323), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.855 (perp=8.178, rec=0.219), tot_loss_proj:1.857 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.794 (perp=8.178, rec=0.158), tot_loss_proj:1.901 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.794 (perp=8.178, rec=0.159), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.787 (perp=8.178, rec=0.151), tot_loss_proj:1.892 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.779 (perp=8.178, rec=0.143), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.782 (perp=8.178, rec=0.146), tot_loss_proj:1.753 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.784 (perp=8.178, rec=0.148), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.791 (perp=8.178, rec=0.156), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.770 (perp=8.178, rec=0.134), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.774 (perp=8.178, rec=0.139), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.767 (perp=8.178, rec=0.131), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.782 (perp=8.178, rec=0.147), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.777 (perp=8.178, rec=0.142), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.772 (perp=8.178, rec=0.137), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.767 (perp=8.178, rec=0.131), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.782 (perp=8.178, rec=0.146), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.178, rec=0.136), tot_loss_proj:1.745 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.773 (perp=8.178, rec=0.138), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.762 (perp=8.178, rec=0.126), tot_loss_proj:1.739 [t=0.24s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.776 (perp=8.178, rec=0.141), tot_loss_proj:1.730 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.773 (perp=8.178, rec=0.138), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.777 (perp=8.178, rec=0.142), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.770 (perp=8.178, rec=0.135), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.755 (perp=8.178, rec=0.120), tot_loss_proj:1.746 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.771 (perp=8.178, rec=0.136), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.178, rec=0.138), tot_loss_proj:1.748 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.757 (perp=8.178, rec=0.121), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.782 (perp=8.178, rec=0.147), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.773 (perp=8.178, rec=0.137), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.178, rec=0.133), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.759 (perp=8.178, rec=0.124), tot_loss_proj:1.715 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.775 (perp=8.178, rec=0.140), tot_loss_proj:1.749 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.773 (perp=8.178, rec=0.137), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.780 (perp=8.178, rec=0.145), tot_loss_proj:1.746 [t=0.33s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.773 (perp=8.178, rec=0.138), tot_loss_proj:1.751 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.774 (perp=8.178, rec=0.138), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.789 (perp=8.178, rec=0.154), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.772 (perp=8.178, rec=0.137), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.778 (perp=8.178, rec=0.142), tot_loss_proj:1.743 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.855 | p: 82.476 | r: 83.417
rouge2     | fm: 48.424 | p: 48.295 | r: 48.550
rougeL     | fm: 73.976 | p: 73.642 | r: 74.493
rougeLsum  | fm: 74.005 | p: 73.695 | r: 74.604
r1fm+r2fm = 131.279

input #74 time: 0:10:40 | total time: 13:39:53


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
cosin similarity: 0.8721797930098243 normalized error: 0.5185604172624592
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 1.8861748611996618 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 1.8705921993801187 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 1.8253952638064617 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 1.7451496849903472 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 1.7248061963322525 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 1.7089033866910621 for ['[CLS] surrounding imlence health flow mecklenburg dining twins execution plannercott by yes guy rattle senior batch 社 earth [SEP]']
[Init] best rec loss: 1.7052668652087082 for ['[CLS] cabin titled feedbi humble wbning translation chance tempo area true trailing legislative be yellowish popular granite midwest [SEP]']
[Init] best perm rec loss: 1.7052304604017312 for ['[CLS] be legislative yellowish chance humblebi cabin midwest tempo true titled area translation granitening trailing popular wb feed [SEP]']
[Init] best perm rec loss: 1.7046288236619875 for ['[CLS] granitening humble be translation tempo popular cabin legislativebi titled trailing true chance area feed yellowish wb midwest [SEP]']
[Init] best perm rec loss: 1.704073331904696 for ['[CLS] legislative midwest be trailing yellowish granite titled tempo true cabin humble feed area translationningbi popular wb chance [SEP]']
[Init] best perm rec loss: 1.702376819265071 for ['[CLS] granite tempo yellowish feed wb titledning cabin areabi midwest popular legislative translation humble chance be true trailing [SEP]']
[Init] best perm rec loss: 1.7013103710980708 for ['[CLS]bi true trailing translation humble legislative tempo yellowishning area chance cabin be granite feed midwest titled wb popular [SEP]']
[Init] best perm rec loss: 1.6972391532988222 for ['[CLS]ning humble be titled feed chance cabin legislative area tempobi true trailing yellowish popular granite wb midwest translation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.074 (perp=13.027, rec=0.469), tot_loss_proj:3.805 [t=0.27s]
prediction: ['[CLS] fashion good appreciated ni look of settle ivan emphasispor studied universidad gu officer, noble meyer inter mark [SEP]']
[ 100/2000] tot_loss=3.032 (perp=13.356, rec=0.361), tot_loss_proj:4.316 [t=0.28s]
prediction: ['[CLS] fashion perfect expected into diplomatic of retired allows emphasiseterchule wicket besides envy, dismissed ignored crossed commemorate [SEP]']
[ 150/2000] tot_loss=3.130 (perp=14.115, rec=0.307), tot_loss_proj:4.587 [t=0.26s]
prediction: ['[CLS] smashwords tested expected upon diplomatic beast retired allows savannah mathias universidad isn awardederic not dismissed easily passes dismissed [SEP]']
[ 200/2000] tot_loss=2.824 (perp=12.886, rec=0.247), tot_loss_proj:4.325 [t=0.26s]
prediction: ['[CLS] smashwords silk expected libertadoresative into retired 発 opportunity mathias derek isn.eric not dismissed easily easily dismissed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.550 (perp=11.588, rec=0.233), tot_loss_proj:3.857 [t=0.25s]
prediction: ['[CLS] finish silk expected el instability into mhz instability joey mathias iseric. isn not dismissed easily easily dismissed [SEP]']
[ 300/2000] tot_loss=2.561 (perp=11.731, rec=0.215), tot_loss_proj:3.963 [t=0.25s]
prediction: ['[CLS] finish demonstrated expected el instability into mhz instability joey mathias is expensive. isn not dismissed easily easily dismissed [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.588 (perp=11.832, rec=0.221), tot_loss_proj:3.992 [t=0.26s]
prediction: ['[CLS] this demonstrated expected el instability into mhz joeyeded isxxciful instability never not dismissed easily easily dismissed [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.658 (perp=12.120, rec=0.234), tot_loss_proj:3.899 [t=0.26s]
prediction: ['[CLS] this this available el instability excursionciful joeyeded isxx mhz instability never not dismissed easily easily dismissed [SEP]']
[ 450/2000] tot_loss=2.565 (perp=11.884, rec=0.189), tot_loss_proj:3.654 [t=0.26s]
prediction: ['[CLS] this this available el instability excursionciful joeyeded is sophie mhz instability not not dismissed easily easily dismissed [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.537 (perp=11.749, rec=0.187), tot_loss_proj:4.204 [t=0.26s]
prediction: ['[CLS] this this available eleit instability excursion joey instability is sophie mhz instability not not dismissed easilyasurable dismissed [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.568 (perp=11.899, rec=0.188), tot_loss_proj:4.018 [t=0.25s]
prediction: ['[CLS] this this available eleit is excursion opportunity instability instabilitympt mhz instability isn not dismissed easily although dismissed [SEP]']
[ 600/2000] tot_loss=2.520 (perp=11.713, rec=0.177), tot_loss_proj:3.706 [t=0.29s]
prediction: ['[CLS] this this available eleit is excursion opportunity instability instability brooklyn mhz instability wasn not dismissed easily or dismissed [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.409 (perp=11.214, rec=0.166), tot_loss_proj:3.600 [t=0.27s]
prediction: ['[CLS] this this available 主. is excursion opportunity renumbered mhz instability instability instability wasn not dismissed easily or dismissed [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.302 (perp=10.620, rec=0.178), tot_loss_proj:3.594 [t=0.26s]
prediction: ['[CLS] this this available 主 is excursion opportunity renumbered mhz instability instability instability. wasn not dismissed easily or dismissed [SEP]']
[ 750/2000] tot_loss=2.272 (perp=10.530, rec=0.166), tot_loss_proj:3.784 [t=0.25s]
prediction: ['[CLS] this this templar 主 is excursion joey renumbered mhz instability instability instability.enter not dismissed easily or dismissed [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.238 (perp=10.320, rec=0.174), tot_loss_proj:3.362 [t=0.25s]
prediction: ['[CLS] this this templar el is excursion joey renumberedএ instability instability instability.enter not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.159 (perp=9.980, rec=0.163), tot_loss_proj:3.321 [t=0.26s]
prediction: ['[CLS] this this templar 主 is excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
[ 900/2000] tot_loss=2.112 (perp=9.757, rec=0.161), tot_loss_proj:3.317 [t=0.26s]
prediction: ['[CLS] this this equally 主 is excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.025 (perp=9.332, rec=0.159), tot_loss_proj:3.221 [t=0.27s]
prediction: ['[CLS] this is equally 主 this excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.063 (perp=9.511, rec=0.161), tot_loss_proj:3.609 [t=0.25s]
prediction: ['[CLS] this is this forget 主 excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
[1050/2000] tot_loss=2.016 (perp=9.306, rec=0.155), tot_loss_proj:3.599 [t=0.25s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=9.306, rec=0.162), tot_loss_proj:3.604 [t=0.26s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.017 (perp=9.306, rec=0.156), tot_loss_proj:3.599 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
[1200/2000] tot_loss=2.019 (perp=9.306, rec=0.158), tot_loss_proj:3.601 [t=0.25s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.979 (perp=9.105, rec=0.158), tot_loss_proj:3.570 [t=0.25s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
[1300/2000] tot_loss=1.979 (perp=9.105, rec=0.158), tot_loss_proj:3.571 [t=0.25s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.105, rec=0.149), tot_loss_proj:3.577 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
[1400/2000] tot_loss=1.982 (perp=9.105, rec=0.161), tot_loss_proj:3.571 [t=0.26s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
[1450/2000] tot_loss=1.936 (perp=8.904, rec=0.155), tot_loss_proj:3.231 [t=0.25s]
prediction: ['[CLS] this is thisable 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
[1500/2000] tot_loss=1.934 (perp=8.904, rec=0.153), tot_loss_proj:3.231 [t=0.25s]
prediction: ['[CLS] this is thisable 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.013 (perp=9.318, rec=0.150), tot_loss_proj:3.608 [t=0.27s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.012 (perp=9.318, rec=0.148), tot_loss_proj:3.608 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
[1650/2000] tot_loss=2.014 (perp=9.318, rec=0.150), tot_loss_proj:3.607 [t=0.26s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.008 (perp=9.318, rec=0.144), tot_loss_proj:3.610 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.012 (perp=9.318, rec=0.149), tot_loss_proj:3.605 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
[1800/2000] tot_loss=2.017 (perp=9.318, rec=0.154), tot_loss_proj:3.611 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.032 (perp=9.431, rec=0.146), tot_loss_proj:3.699 [t=0.28s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.039 (perp=9.431, rec=0.152), tot_loss_proj:3.699 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
[1950/2000] tot_loss=2.039 (perp=9.431, rec=0.153), tot_loss_proj:3.693 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.038 (perp=9.431, rec=0.152), tot_loss_proj:3.699 [t=0.26s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 73.333 | r: 64.706
rouge2     | fm: 26.667 | p: 28.571 | r: 25.000
rougeL     | fm: 56.250 | p: 60.000 | r: 52.941
rougeLsum  | fm: 56.250 | p: 60.000 | r: 52.941
r1fm+r2fm = 95.417

[Aggregate metrics]:
rouge1     | fm: 82.622 | p: 82.319 | r: 83.129
rouge2     | fm: 47.941 | p: 47.866 | r: 48.128
rougeL     | fm: 73.715 | p: 73.440 | r: 74.151
rougeLsum  | fm: 73.928 | p: 73.610 | r: 74.440
r1fm+r2fm = 130.563

input #75 time: 0:11:01 | total time: 13:50:55


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
cosin similarity: 0.8993835694058105 normalized error: 0.4740738023882021
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 1.7927852314865809 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 1.7453874883585057 for ['[CLS] vimes spread stanford telescope formed neighbourhood wire chang miniseries farmers kyle having bend attempt [SEP]']
[Init] best rec loss: 1.7336280263095611 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 1.704004183913559 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 1.547392456147973 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 1.478506002806667 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 1.4752863838910206 for ['[CLS] pushed ( purse onwards lefthaw tautoning surreal hard ab backwardˣ mango [SEP]']
[Init] best perm rec loss: 1.4748151393159554 for ['[CLS]ˣ mango taut purse backward onwards left surreal hardoning ab ( pushedhaw [SEP]']
[Init] best perm rec loss: 1.4740360588253913 for ['[CLS] tautˣoninghaw mango surreal left onwards hard backward pushed purse ( ab [SEP]']
[Init] best perm rec loss: 1.4725668657707782 for ['[CLS]oning onwards abhaw ( pushed backwardˣ hard left surreal purse taut mango [SEP]']
[Init] best perm rec loss: 1.4708118839200626 for ['[CLS] abˣ purse surrealoning left hard taut ( backward onwards pushedhaw mango [SEP]']
[Init] best perm rec loss: 1.4704620886867759 for ['[CLS] onwards pushed ab hard surrealoning lefthaw taut purseˣ ( mango backward [SEP]']
[Init] best perm rec loss: 1.4674005283156941 for ['[CLS] tautˣ backward hard (oning left onwards purse mangohaw pushed ab surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.675 (perp=11.320, rec=0.411), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] british barrel software forgotten from family packet closed career felt companies finally stopped qualifying [SEP]']
[ 100/2000] tot_loss=2.580 (perp=10.931, rec=0.394), tot_loss_proj:3.457 [t=0.25s]
prediction: ['[CLS] gr heat attack stopped off. metal oil only seemed challenge afterwards stopped challenging [SEP]']
[ 150/2000] tot_loss=2.696 (perp=12.151, rec=0.266), tot_loss_proj:4.043 [t=0.25s]
prediction: ['[CLS] of weeks war stopped great. silver industries when feels challenge culminated stopped challenging [SEP]']
[ 200/2000] tot_loss=2.431 (perp=11.045, rec=0.223), tot_loss_proj:3.946 [t=0.27s]
prediction: ['[CLS] of barack war stopped great. silver industry when feels challenging has stopped challenging [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.342 (perp=10.662, rec=0.210), tot_loss_proj:3.324 [t=0.27s]
prediction: ['[CLS] he barack when 16 stopped great. silver industries seems challenging has stopped challenging [SEP]']
[ 300/2000] tot_loss=2.473 (perp=11.452, rec=0.183), tot_loss_proj:3.358 [t=0.25s]
prediction: ['[CLS] when kilometers when 16 stopped great. silver industries seems himself has stopped challenging [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.308 (perp=10.682, rec=0.172), tot_loss_proj:3.212 [t=0.26s]
prediction: ['[CLS] when kilometers when 66 stopped. silver industries great seems himself has stopped challenging [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.209 (perp=10.251, rec=0.159), tot_loss_proj:3.249 [t=0.25s]
prediction: ['[CLS] when kerman if when 66 stopped. silver industries great himself has stopped challenging [SEP]']
[ 450/2000] tot_loss=2.195 (perp=10.251, rec=0.145), tot_loss_proj:3.250 [t=0.25s]
prediction: ['[CLS] when kerman if when 66 stopped. silver industries great himself has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.177 (perp=10.185, rec=0.139), tot_loss_proj:3.384 [t=0.25s]
prediction: ['[CLS] when kerman when if 66 stopped. silver oil great himself has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.117 (perp=9.932, rec=0.131), tot_loss_proj:3.014 [t=0.26s]
prediction: ['[CLS] when kerman when if 66 ended, great oil silver himself has stopped challenging [SEP]']
[ 600/2000] tot_loss=2.112 (perp=9.932, rec=0.126), tot_loss_proj:3.008 [t=0.25s]
prediction: ['[CLS] when kerman when if 66 ended, great oil silver himself has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.136 (perp=10.061, rec=0.124), tot_loss_proj:3.023 [t=0.26s]
prediction: ['[CLS] when silveryman when if 66 leaves, very oil himself has stopped challenging [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.078 (perp=9.753, rec=0.127), tot_loss_proj:3.160 [t=0.26s]
prediction: ['[CLS] when silveryman when if 66 leaves at at oil has stopped challenging himself [SEP]']
[ 750/2000] tot_loss=2.110 (perp=9.966, rec=0.117), tot_loss_proj:3.200 [t=0.26s]
prediction: ['[CLS] when silver kerman when if 66 leaves at at oil has stopped challenging himself [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.024 (perp=9.516, rec=0.121), tot_loss_proj:3.180 [t=0.28s]
prediction: ['[CLS] when silver kerman when if at 66 leaves very oil has stopped challenging himself [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.949 (perp=9.139, rec=0.122), tot_loss_proj:3.150 [t=0.27s]
prediction: ['[CLS] when silver kerman when if at 66 leaves oil has stopped very challenging himself [SEP]']
[ 900/2000] tot_loss=1.909 (perp=8.937, rec=0.122), tot_loss_proj:2.903 [t=0.27s]
prediction: ['[CLS] when ur kerman when if at 66 leaves - has stopped very challenging himself [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.914 (perp=8.937, rec=0.127), tot_loss_proj:2.905 [t=0.25s]
prediction: ['[CLS] when ur kerman when if at 66 leaves - has stopped very challenging himself [SEP]']
Attempt swap
[1000/2000] tot_loss=1.892 (perp=8.887, rec=0.114), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] when ur allen when if at 66 leaves - has stopped very challenging himself [SEP]']
[1050/2000] tot_loss=1.887 (perp=8.887, rec=0.110), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS] when ur allen when if at 66 leaves - has stopped very challenging himself [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.836 (perp=8.638, rec=0.108), tot_loss_proj:2.752 [t=0.25s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]']
Attempt swap
[1150/2000] tot_loss=1.842 (perp=8.638, rec=0.115), tot_loss_proj:2.750 [t=0.28s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]']
[1200/2000] tot_loss=1.841 (perp=8.638, rec=0.113), tot_loss_proj:2.755 [t=0.25s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]']
Attempt swap
[1250/2000] tot_loss=1.879 (perp=8.818, rec=0.116), tot_loss_proj:2.799 [t=0.25s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
[1300/2000] tot_loss=1.877 (perp=8.818, rec=0.113), tot_loss_proj:2.803 [t=0.24s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
[1350/2000] tot_loss=1.879 (perp=8.818, rec=0.116), tot_loss_proj:2.802 [t=0.25s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
[1400/2000] tot_loss=1.875 (perp=8.818, rec=0.111), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
[1450/2000] tot_loss=1.870 (perp=8.818, rec=0.107), tot_loss_proj:2.802 [t=0.26s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
[1500/2000] tot_loss=1.879 (perp=8.818, rec=0.115), tot_loss_proj:2.803 [t=0.26s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.834 (perp=8.592, rec=0.115), tot_loss_proj:2.775 [t=0.27s]
prediction: ['[CLS] when ( when if at 66 leaves - allen has stopped ur challenging himself [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.880 (perp=8.892, rec=0.102), tot_loss_proj:3.413 [t=0.26s]
prediction: ['[CLS] when ( - if at 66 proper when allen has stopped ur challenging himself [SEP]']
[1650/2000] tot_loss=1.890 (perp=8.892, rec=0.111), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] when ( - if at 66 proper when allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.815 (perp=8.558, rec=0.103), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS] when if ( - at 66 proper when allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.793 (perp=8.415, rec=0.110), tot_loss_proj:3.194 [t=0.25s]
prediction: ['[CLS] when if ( - at 66 when leaves allen has stopped ur challenging himself [SEP]']
[1800/2000] tot_loss=1.798 (perp=8.415, rec=0.115), tot_loss_proj:3.190 [t=0.25s]
prediction: ['[CLS] when if ( - at 66 when leaves allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.754 (perp=8.211, rec=0.111), tot_loss_proj:3.293 [t=0.27s]
prediction: ['[CLS] when if - ( at 66 when proper allen has stopped ur challenging himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.753 (perp=8.211, rec=0.111), tot_loss_proj:3.294 [t=0.27s]
prediction: ['[CLS] when if - ( at 66 when proper allen has stopped ur challenging himself [SEP]']
[1950/2000] tot_loss=1.822 (perp=8.515, rec=0.119), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] when as - ( at 66 when proper allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.743 (perp=8.148, rec=0.113), tot_loss_proj:3.287 [t=0.25s]
prediction: ['[CLS] when as ( at 66 - when proper allen has stopped ur challenging himself [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 66.667 | r: 83.333
rouge2     | fm: 32.000 | p: 28.571 | r: 36.364
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 106.074

[Aggregate metrics]:
rouge1     | fm: 82.490 | p: 82.053 | r: 83.101
rouge2     | fm: 47.882 | p: 47.753 | r: 48.110
rougeL     | fm: 73.742 | p: 73.347 | r: 74.394
rougeLsum  | fm: 73.755 | p: 73.376 | r: 74.395
r1fm+r2fm = 130.372

input #76 time: 0:10:51 | total time: 14:01:46


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
cosin similarity: -0.96511151779788 normalized error: 1.8886612138874637
cosin similarity: 0.9651115177978798 normalized error: 0.40625056343347843
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 1.666193725103536 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 1.6577978970606757 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 1.6427321829678994 for ['[CLS]cing conducted core worship often scientific rama riding clubs kira furrowed ta stack phenomenon leigh [SEP]']
[Init] best rec loss: 1.3998614203474378 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 1.3943678329145157 for ['[CLS] where medium limeraphicno ways ole sheep sometime purple outside win most gray park [SEP]']
[Init] best perm rec loss: 1.3934208400648185 for ['[CLS] medium outside purple gray ways sheep ole lime most park win sometime whereraphicno [SEP]']
[Init] best perm rec loss: 1.3891200283681246 for ['[CLS] whereno parkraphic sheep ways sometime gray most ole lime purple outside win medium [SEP]']
[Init] best perm rec loss: 1.3853828023597805 for ['[CLS] park medium where sheep purple grayraphic ole sometime winno outside lime ways most [SEP]']
[Init] best perm rec loss: 1.38414973943817 for ['[CLS] park lime where sheep gray ways sometime most oleraphic outsideno win purple medium [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.484, rec=0.413), tot_loss_proj:3.370 [t=0.26s]
prediction: ['[CLS]ه jean blue life capitalfy could its experience above brand be legend jacksonville sweet [SEP]']
[ 100/2000] tot_loss=2.684 (perp=11.807, rec=0.323), tot_loss_proj:3.528 [t=0.27s]
prediction: ['[CLS] its jean blue life life ka ins its experience above made be waterwski promised [SEP]']
[ 150/2000] tot_loss=2.592 (perp=11.522, rec=0.288), tot_loss_proj:3.429 [t=0.28s]
prediction: ['[CLS] its you love life life ka ins its position above promise above mythwski promised [SEP]']
[ 200/2000] tot_loss=2.520 (perp=11.429, rec=0.234), tot_loss_proj:3.476 [t=0.27s]
prediction: ['[CLS] is its feel life life pro ins its assets above make above mythstellar promised [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.396 (perp=10.864, rec=0.223), tot_loss_proj:3.452 [t=0.27s]
prediction: ['[CLS] is its believe life fly life insars promise above make above realmstellar composed [SEP]']
[ 300/2000] tot_loss=2.542 (perp=11.680, rec=0.206), tot_loss_proj:3.443 [t=0.25s]
prediction: ['[CLS] is its make lifeg believe thinkars promise above make above realm consideredars [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.345 (perp=10.799, rec=0.185), tot_loss_proj:3.390 [t=0.26s]
prediction: ['[CLS] is its make lifeg believe thinkars promise above promise above realm believears [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.163 (perp=9.937, rec=0.176), tot_loss_proj:3.170 [t=0.27s]
prediction: ['[CLS] is its make lifears believe thinkars promise above promise above material believeg [SEP]']
[ 450/2000] tot_loss=2.091 (perp=9.612, rec=0.169), tot_loss_proj:3.029 [t=0.25s]
prediction: ['[CLS] is its make lifears believe thinkars promise above that above material believeg [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.983 (perp=9.103, rec=0.162), tot_loss_proj:2.980 [t=0.28s]
prediction: ['[CLS] is its make believe lifears thinkars promise above that above material believeg [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.977 (perp=9.103, rec=0.156), tot_loss_proj:2.911 [t=0.25s]
prediction: ['[CLS] is its make believears life thinkars promise above that above material believeat [SEP]']
[ 600/2000] tot_loss=2.231 (perp=10.387, rec=0.154), tot_loss_proj:3.095 [t=0.26s]
prediction: ['[CLS] is its make makesars life thinkars promise above that above material believe crow [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.092 (perp=9.720, rec=0.148), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] is its make makes rely life thinkars promise above that the material believears [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.895 (perp=8.683, rec=0.159), tot_loss_proj:2.953 [t=0.26s]
prediction: ['[CLS] is its material makes rely life thinkars promise above that the make believears [SEP]']
[ 750/2000] tot_loss=1.866 (perp=8.647, rec=0.137), tot_loss_proj:2.914 [t=0.26s]
prediction: ['[CLS] is its material makes rely life thinkars promise above that the make believe so [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.830 (perp=8.420, rec=0.146), tot_loss_proj:2.871 [t=0.27s]
prediction: ['[CLS] is its material makes rely life thinkars above promise that the make believe so [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.767 (perp=8.162, rec=0.135), tot_loss_proj:2.806 [t=0.26s]
prediction: ['[CLS] is its material rely make life thinkars above promise that the make believe so [SEP]']
[ 900/2000] tot_loss=1.769 (perp=8.162, rec=0.136), tot_loss_proj:2.816 [t=0.25s]
prediction: ['[CLS] is its material rely make life thinkars above promise that the make believe so [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.916 (perp=8.955, rec=0.125), tot_loss_proj:2.918 [t=0.25s]
prediction: ['[CLS] is its material rely make life thinkars above promise that the believe believe so [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.799 (perp=8.317, rec=0.135), tot_loss_proj:2.319 [t=0.27s]
prediction: ['[CLS] is its material rely make life think promise that the believe realm soars above [SEP]']
[1050/2000] tot_loss=1.781 (perp=8.317, rec=0.118), tot_loss_proj:2.318 [t=0.26s]
prediction: ['[CLS] is its material rely make life think promise that the believe realm soars above [SEP]']
Attempt swap
[1100/2000] tot_loss=1.777 (perp=8.317, rec=0.114), tot_loss_proj:2.320 [t=0.26s]
prediction: ['[CLS] is its material rely make life think promise that the believe realm soars above [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.882 (perp=8.825, rec=0.117), tot_loss_proj:2.510 [t=0.25s]
prediction: ['[CLS] is its material rely make life sh promise believe that the realm soars above [SEP]']
[1200/2000] tot_loss=1.927 (perp=9.069, rec=0.113), tot_loss_proj:2.470 [t=0.25s]
prediction: ['[CLS] is its materialll make life sh promise believe that the realm soars above [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.679 (perp=7.845, rec=0.110), tot_loss_proj:2.187 [t=0.26s]
prediction: ['[CLS] is its material keeps entirely make life promise believe that the realm soars above [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.737 (perp=8.139, rec=0.110), tot_loss_proj:2.206 [t=0.25s]
prediction: ['[CLS] is its material keeps make life cube promise believe that the realm soars above [SEP]']
[1350/2000] tot_loss=1.738 (perp=8.139, rec=0.111), tot_loss_proj:2.211 [t=0.26s]
prediction: ['[CLS] is its material keeps make life cube promise believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.686 (perp=7.921, rec=0.102), tot_loss_proj:2.177 [t=0.25s]
prediction: ['[CLS] is its material keeps make life promise cube believe that the realm soars above [SEP]']
Attempt swap
[1450/2000] tot_loss=1.695 (perp=7.921, rec=0.110), tot_loss_proj:2.169 [t=0.26s]
prediction: ['[CLS] is its material keeps make life promise cube believe that the realm soars above [SEP]']
[1500/2000] tot_loss=1.822 (perp=8.601, rec=0.101), tot_loss_proj:2.402 [t=0.26s]
prediction: ['[CLS] is its materiallyn make life promise cube believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.811 (perp=8.535, rec=0.104), tot_loss_proj:2.329 [t=0.26s]
prediction: ['[CLS] is its make keeps material life promise cube believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.798 (perp=8.430, rec=0.112), tot_loss_proj:2.271 [t=0.26s]
prediction: ['[CLS] is its keeps make material life promise cube believe that the realm soars above [SEP]']
[1650/2000] tot_loss=1.790 (perp=8.430, rec=0.104), tot_loss_proj:2.274 [t=0.25s]
prediction: ['[CLS] is its keeps make material life promise cube believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.764 (perp=8.285, rec=0.107), tot_loss_proj:2.236 [t=0.27s]
prediction: ['[CLS] is its keeps make cube life promise material believe that the realm soars above [SEP]']
Attempt swap
[1750/2000] tot_loss=1.936 (perp=9.171, rec=0.101), tot_loss_proj:2.513 [t=0.27s]
prediction: ['[CLS] is itslyn make cube life promise material believe that the realm soars above [SEP]']
[1800/2000] tot_loss=1.939 (perp=9.171, rec=0.105), tot_loss_proj:2.506 [t=0.26s]
prediction: ['[CLS] is itslyn make cube life promise material believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.802 (perp=8.480, rec=0.106), tot_loss_proj:2.288 [t=0.26s]
prediction: ['[CLS] is its make keeps cube life promise material believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.777 (perp=8.349, rec=0.107), tot_loss_proj:2.271 [t=0.25s]
prediction: ['[CLS] is its make believe cube life promise material keeps that the realm soars above [SEP]']
[1950/2000] tot_loss=1.808 (perp=8.514, rec=0.105), tot_loss_proj:2.305 [t=0.26s]
prediction: ['[CLS] is its make believe cube life promise materiallyn that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.766 (perp=8.306, rec=0.105), tot_loss_proj:2.289 [t=0.26s]
prediction: ['[CLS] is its make believe life cube promise materiallyn that the realm soars above [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is its make believe cube life promise materiallyn that the realm soars above [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 122.381

[Aggregate metrics]:
rouge1     | fm: 82.541 | p: 82.167 | r: 83.162
rouge2     | fm: 47.523 | p: 47.361 | r: 47.777
rougeL     | fm: 73.679 | p: 73.252 | r: 74.229
rougeLsum  | fm: 73.663 | p: 73.256 | r: 74.257
r1fm+r2fm = 130.064

input #77 time: 0:11:01 | total time: 14:12:48


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
cosin similarity: 0.9052137094556744 normalized error: 0.5044539339140962
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 1.9062914134112117 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 1.8520335989306531 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 1.498924850161912 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 1.4925886357125542 for ['[CLS] v focus wang [SEP]']
[Init] best rec loss: 1.3836849457314573 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 1.3773987256555427 for ['[CLS] le grant screens [SEP]']
[Init] best perm rec loss: 1.3753151746446246 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 1.373104293474772 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.269 (perp=9.321, rec=0.405), tot_loss_proj:2.920 [t=0.27s]
prediction: ['[CLS] exit pack exit [SEP]']
[ 100/2000] tot_loss=2.022 (perp=8.971, rec=0.228), tot_loss_proj:2.701 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.979 (perp=8.971, rec=0.184), tot_loss_proj:2.701 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.959 (perp=8.971, rec=0.165), tot_loss_proj:2.697 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.959 (perp=8.971, rec=0.164), tot_loss_proj:2.702 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 300/2000] tot_loss=1.963 (perp=8.971, rec=0.168), tot_loss_proj:2.709 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.950 (perp=8.971, rec=0.156), tot_loss_proj:2.701 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.948 (perp=8.971, rec=0.154), tot_loss_proj:2.702 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 450/2000] tot_loss=1.943 (perp=8.971, rec=0.149), tot_loss_proj:2.706 [t=0.24s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.935 (perp=8.971, rec=0.140), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.949 (perp=8.971, rec=0.155), tot_loss_proj:2.707 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 600/2000] tot_loss=1.939 (perp=8.971, rec=0.144), tot_loss_proj:2.707 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.943 (perp=8.971, rec=0.149), tot_loss_proj:2.706 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.943 (perp=8.971, rec=0.149), tot_loss_proj:2.704 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 750/2000] tot_loss=1.934 (perp=8.971, rec=0.140), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.929 (perp=8.971, rec=0.135), tot_loss_proj:2.708 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.940 (perp=8.971, rec=0.146), tot_loss_proj:2.712 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 900/2000] tot_loss=1.941 (perp=8.971, rec=0.147), tot_loss_proj:2.711 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.932 (perp=8.971, rec=0.137), tot_loss_proj:2.707 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.938 (perp=8.971, rec=0.143), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[1050/2000] tot_loss=1.930 (perp=8.971, rec=0.135), tot_loss_proj:2.705 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.929 (perp=8.971, rec=0.135), tot_loss_proj:2.704 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.935 (perp=8.971, rec=0.141), tot_loss_proj:2.709 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
[1200/2000] tot_loss=1.921 (perp=8.971, rec=0.127), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.929 (perp=8.971, rec=0.134), tot_loss_proj:2.709 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.924 (perp=8.971, rec=0.129), tot_loss_proj:2.707 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[1350/2000] tot_loss=1.933 (perp=8.971, rec=0.139), tot_loss_proj:2.707 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=8.971, rec=0.137), tot_loss_proj:2.704 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.924 (perp=8.971, rec=0.130), tot_loss_proj:2.703 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[1500/2000] tot_loss=1.927 (perp=8.971, rec=0.132), tot_loss_proj:2.701 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.926 (perp=8.971, rec=0.132), tot_loss_proj:2.704 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.924 (perp=8.971, rec=0.129), tot_loss_proj:2.704 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[1650/2000] tot_loss=1.927 (perp=8.971, rec=0.133), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.927 (perp=8.971, rec=0.132), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.928 (perp=8.971, rec=0.134), tot_loss_proj:2.704 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[1800/2000] tot_loss=1.929 (perp=8.971, rec=0.135), tot_loss_proj:2.706 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.928 (perp=8.971, rec=0.134), tot_loss_proj:2.699 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.920 (perp=8.971, rec=0.126), tot_loss_proj:2.702 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[1950/2000] tot_loss=1.919 (perp=8.971, rec=0.125), tot_loss_proj:2.705 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=2.449 (perp=11.605, rec=0.128), tot_loss_proj:3.329 [t=0.27s]
prediction: ['[CLS] exit theater tamara [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 82.471 | p: 82.067 | r: 83.102
rouge2     | fm: 47.282 | p: 47.189 | r: 47.491
rougeL     | fm: 73.699 | p: 73.331 | r: 74.313
rougeLsum  | fm: 73.795 | p: 73.405 | r: 74.430
r1fm+r2fm = 129.754

input #78 time: 0:10:51 | total time: 14:23:39


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
cosin similarity: -0.9542445893279807 normalized error: 1.8914472775898075
cosin similarity: 0.9542445893279807 normalized error: 0.4098774975167472
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 1.92151040770786 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 1.916817931985512 for ['[CLS] scoutsᴵ [SEP]']
[Init] best rec loss: 1.896975546355378 for ['[CLS] chicago militia [SEP]']
[Init] best rec loss: 1.8672783061280573 for ['[CLS] notation nu [SEP]']
[Init] best rec loss: 1.608048471705002 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 1.4920240202236046 for ['[CLS] combined quickly [SEP]']
[Init] best rec loss: 1.4482479800464858 for ['[CLS]wl patrol [SEP]']
[Init] best rec loss: 1.2479964178600431 for ['[CLS] texas qualified [SEP]']
[Init] best rec loss: 1.0314914604474852 for ['[CLS] own terrain [SEP]']
[Init] best perm rec loss: 1.0254998278411258 for ['[CLS] terrain own [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.565 (perp=11.427, rec=0.279), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.535 (perp=11.427, rec=0.250), tot_loss_proj:2.703 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.489 (perp=11.427, rec=0.204), tot_loss_proj:2.713 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=1.881 (perp=8.695, rec=0.142), tot_loss_proj:2.082 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.078 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.078 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.891 (perp=8.695, rec=0.152), tot_loss_proj:2.069 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.887 (perp=8.695, rec=0.148), tot_loss_proj:2.086 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.894 (perp=8.695, rec=0.155), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.892 (perp=8.695, rec=0.153), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.881 (perp=8.695, rec=0.142), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.882 (perp=8.695, rec=0.143), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.896 (perp=8.695, rec=0.157), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=8.695, rec=0.151), tot_loss_proj:2.079 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.887 (perp=8.695, rec=0.148), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.894 (perp=8.695, rec=0.155), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.874 (perp=8.695, rec=0.135), tot_loss_proj:2.077 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.894 (perp=8.695, rec=0.155), tot_loss_proj:2.083 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.873 (perp=8.695, rec=0.135), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=8.695, rec=0.149), tot_loss_proj:2.078 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.891 (perp=8.695, rec=0.152), tot_loss_proj:2.080 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.878 (perp=8.695, rec=0.139), tot_loss_proj:2.078 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.892 (perp=8.695, rec=0.153), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.887 (perp=8.695, rec=0.148), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.875 (perp=8.695, rec=0.136), tot_loss_proj:2.079 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.892 (perp=8.695, rec=0.153), tot_loss_proj:2.078 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.081 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.077 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.078 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.890 (perp=8.695, rec=0.151), tot_loss_proj:2.067 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.891 (perp=8.695, rec=0.152), tot_loss_proj:2.071 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.880 (perp=8.695, rec=0.141), tot_loss_proj:2.079 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.885 (perp=8.695, rec=0.146), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.883 (perp=8.695, rec=0.144), tot_loss_proj:2.083 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.890 (perp=8.695, rec=0.151), tot_loss_proj:2.083 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.883 (perp=8.695, rec=0.144), tot_loss_proj:2.067 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 82.738 | p: 82.346 | r: 83.370
rouge2     | fm: 46.691 | p: 46.555 | r: 46.975
rougeL     | fm: 73.707 | p: 73.418 | r: 74.292
rougeLsum  | fm: 73.760 | p: 73.406 | r: 74.414
r1fm+r2fm = 129.429

input #79 time: 0:10:50 | total time: 14:34:30


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
cosin similarity: 0.9707110677809513 normalized error: 0.39211658681230543
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 1.8992503833461423 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 1.746037412600804 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 1.7210905498079565 for ['[CLS] we message phantom sir carpathian [SEP]']
[Init] best rec loss: 1.6528549078043888 for ['[CLS] here lecture mid [MASK]kko [SEP]']
[Init] best rec loss: 1.5989477478729168 for ['[CLS]ghtlving dried days dressing [SEP]']
[Init] best perm rec loss: 1.5970663445019415 for ['[CLS] dried daysghtlving dressing [SEP]']
[Init] best perm rec loss: 1.593624974902322 for ['[CLS] dried days dressingghtlving [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.554 (perp=14.140, rec=0.726), tot_loss_proj:4.722 [t=0.25s]
prediction: ['[CLS] inuit eyebrows fine oppositionop [SEP]']
[ 100/2000] tot_loss=3.365 (perp=13.650, rec=0.636), tot_loss_proj:4.216 [t=0.25s]
prediction: ['[CLS] stupid overs finezenski [SEP]']
[ 150/2000] tot_loss=3.309 (perp=12.855, rec=0.738), tot_loss_proj:4.049 [t=0.26s]
prediction: ['[CLS] stupiddate blank ltnor [SEP]']
[ 200/2000] tot_loss=3.315 (perp=13.355, rec=0.644), tot_loss_proj:4.428 [t=0.25s]
prediction: ['[CLS] candidate tech ash lt diet [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.252 (perp=13.439, rec=0.564), tot_loss_proj:4.620 [t=0.24s]
prediction: ['[CLS] ucinniszen offera [SEP]']
[ 300/2000] tot_loss=2.592 (perp=10.285, rec=0.535), tot_loss_proj:3.987 [t=0.27s]
prediction: ['[CLS]ernniszen niera [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.767 (perp=10.699, rec=0.627), tot_loss_proj:4.091 [t=0.27s]
prediction: ['[CLS] ninniszen candidatezen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.417 (perp=9.455, rec=0.526), tot_loss_proj:3.805 [t=0.25s]
prediction: ['[CLS] ninniszenzenves [SEP]']
[ 450/2000] tot_loss=3.345 (perp=14.143, rec=0.516), tot_loss_proj:3.992 [t=0.25s]
prediction: ['[CLS] ni learnzenzen wise [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.886 (perp=11.958, rec=0.495), tot_loss_proj:3.421 [t=0.24s]
prediction: ['[CLS] nizenzen learn wise [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.658 (perp=15.108, rec=0.636), tot_loss_proj:4.969 [t=0.28s]
prediction: ['[CLS] issnveszen learnae [SEP]']
[ 600/2000] tot_loss=3.465 (perp=14.565, rec=0.552), tot_loss_proj:4.866 [t=0.26s]
prediction: ['[CLS] linedveszen learnius [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.113 (perp=12.969, rec=0.520), tot_loss_proj:4.322 [t=0.25s]
prediction: ['[CLS] lined wisezenzen learn [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.948 (perp=12.159, rec=0.516), tot_loss_proj:3.077 [t=0.25s]
prediction: ['[CLS] wise wizenzen learn [SEP]']
[ 750/2000] tot_loss=2.918 (perp=12.159, rec=0.486), tot_loss_proj:3.083 [t=0.26s]
prediction: ['[CLS] wise wizenzen learn [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.031 (perp=12.624, rec=0.506), tot_loss_proj:3.461 [t=0.27s]
prediction: ['[CLS] wise wizen palmer learn [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.955 (perp=12.356, rec=0.484), tot_loss_proj:3.444 [t=0.28s]
prediction: ['[CLS] wise wizen petersen learn [SEP]']
[ 900/2000] tot_loss=2.980 (perp=12.356, rec=0.508), tot_loss_proj:3.449 [t=0.25s]
prediction: ['[CLS] wise wizen petersen learn [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.952 (perp=12.356, rec=0.481), tot_loss_proj:3.453 [t=0.25s]
prediction: ['[CLS] wise wizen petersen learn [SEP]']
Attempt swap
[1000/2000] tot_loss=2.883 (perp=12.088, rec=0.465), tot_loss_proj:3.575 [t=0.27s]
prediction: ['[CLS] wise wizenaur learn [SEP]']
[1050/2000] tot_loss=2.783 (perp=11.644, rec=0.454), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1100/2000] tot_loss=2.801 (perp=11.644, rec=0.472), tot_loss_proj:3.274 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1150/2000] tot_loss=2.775 (perp=11.644, rec=0.446), tot_loss_proj:3.282 [t=0.29s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1200/2000] tot_loss=2.774 (perp=11.644, rec=0.445), tot_loss_proj:3.270 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1250/2000] tot_loss=2.773 (perp=11.644, rec=0.445), tot_loss_proj:3.276 [t=0.27s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1300/2000] tot_loss=2.782 (perp=11.644, rec=0.453), tot_loss_proj:3.273 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1350/2000] tot_loss=2.769 (perp=11.644, rec=0.440), tot_loss_proj:3.278 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1400/2000] tot_loss=2.763 (perp=11.644, rec=0.435), tot_loss_proj:3.274 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1450/2000] tot_loss=2.765 (perp=11.644, rec=0.437), tot_loss_proj:3.275 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1500/2000] tot_loss=2.768 (perp=11.644, rec=0.439), tot_loss_proj:3.277 [t=0.28s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1550/2000] tot_loss=2.763 (perp=11.644, rec=0.434), tot_loss_proj:3.271 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1600/2000] tot_loss=2.757 (perp=11.644, rec=0.428), tot_loss_proj:3.272 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1650/2000] tot_loss=2.759 (perp=11.644, rec=0.430), tot_loss_proj:3.273 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1700/2000] tot_loss=2.764 (perp=11.644, rec=0.435), tot_loss_proj:3.272 [t=0.28s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1750/2000] tot_loss=2.759 (perp=11.644, rec=0.430), tot_loss_proj:3.272 [t=0.24s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1800/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1850/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1900/2000] tot_loss=2.752 (perp=11.644, rec=0.424), tot_loss_proj:3.274 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1950/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.278 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[2000/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.272 [t=0.27s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise wizenius learn [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 82.564 | p: 82.098 | r: 83.240
rouge2     | fm: 46.595 | p: 46.364 | r: 46.894
rougeL     | fm: 73.600 | p: 73.220 | r: 74.237
rougeLsum  | fm: 73.685 | p: 73.208 | r: 74.403
r1fm+r2fm = 129.159

input #80 time: 0:10:50 | total time: 14:45:20


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
cosin similarity: -0.9108721734199294 normalized error: 1.741715381589591
cosin similarity: 0.9108721734199295 normalized error: 0.4931494713940682
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 1.8293099945045699 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 1.5943592952630858 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 1.5742121294350335 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 1.4662792401728457 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 1.4483613597750806 for ['[CLS] mass seeneer off joe đ [SEP]']
[Init] best rec loss: 1.4483097384213772 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 1.4027965780698894 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 1.3837556186032505 for ['[CLS] eligibilityetched folk ava list cfl [SEP]']
[Init] best rec loss: 1.3711582294895788 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 1.3680713291447872 for ['[CLS] donaldson ivyvikplatedown proceeded [SEP]']
[Init] best perm rec loss: 1.367640960015664 for ['[CLS]vikdown donaldson proceeded ivyplate [SEP]']
[Init] best perm rec loss: 1.362997111250602 for ['[CLS]vik proceededdown donaldsonplate ivy [SEP]']
[Init] best perm rec loss: 1.3623241379086424 for ['[CLS]vikdown ivy donaldson proceededplate [SEP]']
[Init] best perm rec loss: 1.362096490695115 for ['[CLS] ivyvik proceededdown donaldsonplate [SEP]']
[Init] best perm rec loss: 1.3593138508527556 for ['[CLS] donaldsondown proceededvik ivyplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.100 (perp=13.053, rec=0.489), tot_loss_proj:3.822 [t=0.24s]
prediction: ['[CLS] poorly stage military nobody oricon contested [SEP]']
[ 100/2000] tot_loss=2.597 (perp=11.191, rec=0.359), tot_loss_proj:3.217 [t=0.25s]
prediction: ['[CLS] not meeting nonetheless never impressive藤 [SEP]']
[ 150/2000] tot_loss=2.545 (perp=11.326, rec=0.280), tot_loss_proj:3.303 [t=0.26s]
prediction: ['[CLS] not prospect most not impressive藤 [SEP]']
[ 200/2000] tot_loss=2.543 (perp=11.513, rec=0.240), tot_loss_proj:3.074 [t=0.26s]
prediction: ['[CLS] not being mostlat impressive players [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.215 (perp=9.966, rec=0.222), tot_loss_proj:3.788 [t=0.25s]
prediction: ['[CLS] not is most impressive shoulder player [SEP]']
[ 300/2000] tot_loss=2.173 (perp=9.966, rec=0.180), tot_loss_proj:3.914 [t=0.25s]
prediction: ['[CLS] not is most impressive shoulder player [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.946 (perp=8.923, rec=0.161), tot_loss_proj:2.414 [t=0.25s]
prediction: ['[CLS] is not most impressive shoulder player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.925 (perp=8.923, rec=0.141), tot_loss_proj:2.413 [t=0.24s]
prediction: ['[CLS] is not most impressive shoulder player [SEP]']
[ 450/2000] tot_loss=1.940 (perp=8.944, rec=0.151), tot_loss_proj:2.561 [t=0.24s]
prediction: ['[CLS] is not most impressive been player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.939 (perp=8.944, rec=0.151), tot_loss_proj:2.570 [t=0.25s]
prediction: ['[CLS] is not most impressive been player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.915 (perp=8.944, rec=0.127), tot_loss_proj:2.564 [t=0.26s]
prediction: ['[CLS] is not most impressive been player [SEP]']
[ 600/2000] tot_loss=1.930 (perp=8.945, rec=0.141), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.931 (perp=8.945, rec=0.142), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.915 (perp=8.945, rec=0.126), tot_loss_proj:2.458 [t=0.25s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
[ 750/2000] tot_loss=1.919 (perp=8.945, rec=0.130), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.908 (perp=8.945, rec=0.119), tot_loss_proj:2.465 [t=0.26s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.910 (perp=8.945, rec=0.121), tot_loss_proj:2.456 [t=0.24s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
[ 900/2000] tot_loss=1.940 (perp=9.038, rec=0.132), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] is not most impressive absolutely player [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.004 (perp=9.288, rec=0.147), tot_loss_proj:3.038 [t=0.25s]
prediction: ['[CLS] is not most condensed impressive player [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.977 (perp=9.107, rec=0.156), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1050/2000] tot_loss=1.971 (perp=9.107, rec=0.150), tot_loss_proj:2.586 [t=0.27s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.965 (perp=9.107, rec=0.144), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.964 (perp=9.107, rec=0.143), tot_loss_proj:2.585 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1200/2000] tot_loss=1.963 (perp=9.107, rec=0.142), tot_loss_proj:2.589 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.975 (perp=9.107, rec=0.154), tot_loss_proj:2.585 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=9.107, rec=0.143), tot_loss_proj:2.593 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.107, rec=0.149), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.959 (perp=9.107, rec=0.137), tot_loss_proj:2.594 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.965 (perp=9.107, rec=0.143), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1500/2000] tot_loss=1.965 (perp=9.107, rec=0.143), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.973 (perp=9.107, rec=0.152), tot_loss_proj:2.594 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.974 (perp=9.107, rec=0.152), tot_loss_proj:2.589 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1650/2000] tot_loss=1.960 (perp=9.107, rec=0.138), tot_loss_proj:2.590 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.966 (perp=9.107, rec=0.145), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.969 (perp=9.107, rec=0.147), tot_loss_proj:2.595 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1800/2000] tot_loss=1.961 (perp=9.107, rec=0.140), tot_loss_proj:2.595 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.961 (perp=9.107, rec=0.139), tot_loss_proj:2.598 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.965 (perp=9.107, rec=0.144), tot_loss_proj:2.589 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1950/2000] tot_loss=1.961 (perp=9.107, rec=0.139), tot_loss_proj:2.591 [t=0.27s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.959 (perp=9.107, rec=0.138), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not most impressivecus player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 82.472 | p: 82.090 | r: 83.123
rouge2     | fm: 46.499 | p: 46.322 | r: 46.725
rougeL     | fm: 73.698 | p: 73.368 | r: 74.287
rougeLsum  | fm: 73.793 | p: 73.471 | r: 74.450
r1fm+r2fm = 128.971

input #81 time: 0:10:45 | total time: 14:56:05


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
cosin similarity: 0.8627532589286222 normalized error: 0.5239208010726941
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 1.9232511060650235 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 1.7593884380864369 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 1.7294200531575432 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 1.6955706906365182 for ['[CLS] maltaierif ace players reserve hmm rpm [SEP]']
[Init] best rec loss: 1.6565519157416173 for ['[CLS] worse terms everyday down sandsbed supporting due [SEP]']
[Init] best rec loss: 1.6488327845043949 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 1.530765826551578 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 1.5301077648105523 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best rec loss: 1.5291422418169685 for ['[CLS] allegations bloodles noctuidae kappa before version where [SEP]']
[Init] best rec loss: 1.449259868093832 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 1.432699200229046 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 1.432098731195023 for ['[CLS]basket rolefurach whoever plumage respective record [SEP]']
[Init] best perm rec loss: 1.4316574518747034 for ['[CLS]furbasket role whoeverach respective record plumage [SEP]']
[Init] best perm rec loss: 1.429876031148659 for ['[CLS]basketfur role whoeverach plumage record respective [SEP]']
[Init] best perm rec loss: 1.429873857376806 for ['[CLS]basket whoeverach respective recordfur plumage role [SEP]']
[Init] best perm rec loss: 1.4272721424733839 for ['[CLS]basketfur respective whoever role plumage recordach [SEP]']
[Init] best perm rec loss: 1.42690239852947 for ['[CLS]basket whoever roleachfur respective plumage record [SEP]']
[Init] best perm rec loss: 1.4254638558439783 for ['[CLS]basketfur role respective recordach plumage whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.001 (perp=13.064, rec=0.388), tot_loss_proj:3.742 [t=0.26s]
prediction: ['[CLS] undone undone process lithuanian tradition shows undone hadley [SEP]']
[ 100/2000] tot_loss=2.616 (perp=11.813, rec=0.253), tot_loss_proj:3.472 [t=0.25s]
prediction: ["[CLS] undone undone 'keeping script script undone saetan [SEP]"]
[ 150/2000] tot_loss=2.452 (perp=11.356, rec=0.181), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] undone undone is hemisphere by script undone institutions [SEP]']
[ 200/2000] tot_loss=2.764 (perp=13.126, rec=0.139), tot_loss_proj:3.537 [t=0.26s]
prediction: ['[CLS] sloppy undone s suppose by script undone bandage [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.535 (perp=12.034, rec=0.128), tot_loss_proj:3.278 [t=0.26s]
prediction: ['[CLS] undone sstellar by sloppy script undone bandage [SEP]']
[ 300/2000] tot_loss=2.396 (perp=11.353, rec=0.125), tot_loss_proj:3.101 [t=0.25s]
prediction: ['[CLS] undone s pomeranian by sloppy script undone bandage [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.472 (perp=10.179, rec=0.436), tot_loss_proj:2.659 [t=0.25s]
prediction: ['[CLS] undone is undone by sloppy script half item [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.531 (perp=10.953, rec=0.341), tot_loss_proj:3.000 [t=0.25s]
prediction: ['[CLS] undone centenary it undone by sloppy script item [SEP]']
[ 450/2000] tot_loss=2.486 (perp=10.978, rec=0.290), tot_loss_proj:2.948 [t=0.25s]
prediction: ['[CLS] undone sideways itllen by sloppy script item [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.525 (perp=11.295, rec=0.266), tot_loss_proj:2.977 [t=0.25s]
prediction: ['[CLS] undone item isllen by sloppy script sideways [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.233 (perp=9.976, rec=0.237), tot_loss_proj:2.628 [t=0.26s]
prediction: ['[CLS]llen item is undone by sloppy script sideways [SEP]']
[ 600/2000] tot_loss=2.215 (perp=9.976, rec=0.219), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS]llen item is undone by sloppy script sideways [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.212 (perp=9.976, rec=0.217), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS]llen item is undone by sloppy script sideways [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.314 (perp=10.583, rec=0.197), tot_loss_proj:2.716 [t=0.25s]
prediction: ['[CLS] itemllen is undone by sloppy script entrusted [SEP]']
[ 750/2000] tot_loss=2.312 (perp=10.583, rec=0.195), tot_loss_proj:2.717 [t=0.25s]
prediction: ['[CLS] itemllen is undone by sloppy script entrusted [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=2.246 (perp=10.283, rec=0.189), tot_loss_proj:2.615 [t=0.29s]
prediction: ['[CLS] entrusted itemllen is undone by sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.296 (perp=10.631, rec=0.169), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] entrusted packagellen is undone by sloppy script [SEP]']
[ 900/2000] tot_loss=2.567 (perp=12.023, rec=0.163), tot_loss_proj:2.951 [t=0.26s]
prediction: ['[CLS] entrusted packagellen s undone by sloppy script [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.783 (perp=13.082, rec=0.167), tot_loss_proj:3.288 [t=0.26s]
prediction: ['[CLS] packagellen instrumental s undone by sloppy script [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=2.328 (perp=10.722, rec=0.183), tot_loss_proj:2.937 [t=0.25s]
prediction: ['[CLS] s undone by sloppy script packagellen instrumental [SEP]']
[1050/2000] tot_loss=2.389 (perp=11.064, rec=0.176), tot_loss_proj:3.004 [t=0.27s]
prediction: ['[CLS] s undone by sloppy script itemllen instrumental [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.177 (perp=10.074, rec=0.162), tot_loss_proj:2.669 [t=0.28s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1150/2000] tot_loss=2.236 (perp=10.379, rec=0.160), tot_loss_proj:2.821 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental outcome [SEP]']
[1200/2000] tot_loss=2.235 (perp=10.379, rec=0.160), tot_loss_proj:2.826 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental outcome [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.489 (perp=11.653, rec=0.159), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS] s instrumental item undone by sloppy scriptllen [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.169 (perp=10.074, rec=0.154), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1350/2000] tot_loss=2.180 (perp=10.074, rec=0.165), tot_loss_proj:2.669 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1400/2000] tot_loss=2.173 (perp=10.074, rec=0.159), tot_loss_proj:2.678 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1450/2000] tot_loss=2.160 (perp=10.074, rec=0.145), tot_loss_proj:2.667 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1500/2000] tot_loss=2.164 (perp=10.074, rec=0.149), tot_loss_proj:2.676 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1550/2000] tot_loss=2.163 (perp=10.074, rec=0.148), tot_loss_proj:2.669 [t=0.24s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1600/2000] tot_loss=2.163 (perp=10.074, rec=0.148), tot_loss_proj:2.671 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1650/2000] tot_loss=2.158 (perp=10.074, rec=0.143), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1700/2000] tot_loss=2.155 (perp=10.074, rec=0.140), tot_loss_proj:2.679 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1750/2000] tot_loss=2.169 (perp=10.074, rec=0.154), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1800/2000] tot_loss=2.157 (perp=10.074, rec=0.143), tot_loss_proj:2.678 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1850/2000] tot_loss=2.173 (perp=10.074, rec=0.158), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1900/2000] tot_loss=2.161 (perp=10.074, rec=0.146), tot_loss_proj:2.673 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1950/2000] tot_loss=2.152 (perp=10.074, rec=0.138), tot_loss_proj:2.677 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[2000/2000] tot_loss=2.153 (perp=10.074, rec=0.139), tot_loss_proj:2.677 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] undone s pomeranian by sloppy script undone bandage [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 82.429 | p: 82.000 | r: 83.132
rouge2     | fm: 46.160 | p: 46.003 | r: 46.440
rougeL     | fm: 73.574 | p: 73.202 | r: 74.219
rougeLsum  | fm: 73.626 | p: 73.207 | r: 74.307
r1fm+r2fm = 128.589

input #82 time: 0:10:45 | total time: 15:06:50


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
cosin similarity: 0.926325547377931 normalized error: 0.4375947399134601
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 1.8595740001953698 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 1.843287356173501 for ['[CLS] expressing congratulations butch evacuate copyright grenadasome snow paid confidence [SEP]']
[Init] best rec loss: 1.820005483585518 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 1.7389689969756927 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 1.7380943515029363 for ['[CLS]ki car sebastian positions directed gleam here visiting scope easier [SEP]']
[Init] best rec loss: 1.6253996902143903 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 1.555076169647435 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best perm rec loss: 1.5486948480774083 for ['[CLS] hit already use £ benji runaway mercy wild publishing someone [SEP]']
[Init] best perm rec loss: 1.547261495508724 for ['[CLS] already £ publishing use hit mercy someone wild benji runaway [SEP]']
[Init] best perm rec loss: 1.5465915335737765 for ['[CLS] benji already someone £ use mercy wild publishing runaway hit [SEP]']
[Init] best perm rec loss: 1.5465131298345318 for ['[CLS] mercy already publishing use £ hit wild benji runaway someone [SEP]']
[Init] best perm rec loss: 1.5418853219075874 for ['[CLS] benji publishing £ already use runaway hit mercy wild someone [SEP]']
[Init] best perm rec loss: 1.5413632965528183 for ['[CLS] publishing £ already benji runaway use hit someone mercy wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.975 (perp=12.176, rec=0.540), tot_loss_proj:3.590 [t=0.25s]
prediction: ['[CLS] really makesness austrian inaiest to something powerness [SEP]']
[ 100/2000] tot_loss=2.835 (perp=12.351, rec=0.365), tot_loss_proj:3.431 [t=0.25s]
prediction: ['[CLS] know gives environment early growsful how something powerity [SEP]']
[ 150/2000] tot_loss=2.690 (perp=11.998, rec=0.290), tot_loss_proj:3.676 [t=0.28s]
prediction: ['[CLS] know grows environment came growsfulhesion what power when [SEP]']
[ 200/2000] tot_loss=2.709 (perp=12.249, rec=0.259), tot_loss_proj:3.831 [t=0.26s]
prediction: ['[CLS] know wants up coming growsfulhesion what power when [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.800 (perp=12.505, rec=0.299), tot_loss_proj:4.028 [t=0.27s]
prediction: ['[CLS] know here... coming growsful peel what original when [SEP]']
[ 300/2000] tot_loss=2.603 (perp=11.821, rec=0.239), tot_loss_proj:4.245 [t=0.25s]
prediction: ['[CLS] know when up become grows when peel wants original when [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.233 (perp=10.059, rec=0.222), tot_loss_proj:3.698 [t=0.25s]
prediction: ['[CLS] know when original your grows to peel wants up when [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.029 (perp=9.109, rec=0.207), tot_loss_proj:3.001 [t=0.25s]
prediction: ['[CLS] know when energy your wants when peel grows up when [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.004, rec=0.187), tot_loss_proj:2.784 [t=0.25s]
prediction: ['[CLS] know what energy your wants to peel be grows when [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.043 (perp=9.363, rec=0.170), tot_loss_proj:3.432 [t=0.25s]
prediction: ['[CLS] know what several energy wants to peel be grows when [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.028 (perp=9.348, rec=0.158), tot_loss_proj:2.809 [t=0.25s]
prediction: ['[CLS] know what it energy wants what besee grows when [SEP]']
[ 600/2000] tot_loss=2.071 (perp=9.600, rec=0.151), tot_loss_proj:2.963 [t=0.26s]
prediction: ['[CLS] know what it primary wants what besee grows when [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.973 (perp=9.093, rec=0.155), tot_loss_proj:2.963 [t=0.27s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.953 (perp=9.093, rec=0.134), tot_loss_proj:2.955 [t=0.25s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
[ 750/2000] tot_loss=1.939 (perp=9.093, rec=0.121), tot_loss_proj:2.962 [t=0.25s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.942 (perp=9.093, rec=0.124), tot_loss_proj:2.955 [t=0.25s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.941 (perp=9.093, rec=0.122), tot_loss_proj:2.962 [t=0.27s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
[ 900/2000] tot_loss=2.238 (perp=10.600, rec=0.118), tot_loss_proj:3.539 [t=0.26s]
prediction: ['[CLS] know let it wants what primary besee grows when [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.930 (perp=9.093, rec=0.111), tot_loss_proj:2.963 [t=0.26s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[1000/2000] tot_loss=1.932 (perp=9.093, rec=0.113), tot_loss_proj:2.964 [t=0.26s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
[1050/2000] tot_loss=1.881 (perp=8.864, rec=0.108), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1100/2000] tot_loss=1.883 (perp=8.864, rec=0.110), tot_loss_proj:2.877 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=8.864, rec=0.115), tot_loss_proj:2.882 [t=0.25s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
[1200/2000] tot_loss=1.888 (perp=8.864, rec=0.115), tot_loss_proj:2.883 [t=0.27s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1250/2000] tot_loss=1.885 (perp=8.864, rec=0.112), tot_loss_proj:2.875 [t=0.25s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1300/2000] tot_loss=1.873 (perp=8.864, rec=0.100), tot_loss_proj:2.876 [t=0.25s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
[1350/2000] tot_loss=1.876 (perp=8.864, rec=0.103), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1400/2000] tot_loss=1.949 (perp=9.184, rec=0.112), tot_loss_proj:2.965 [t=0.25s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
Attempt swap
[1450/2000] tot_loss=1.940 (perp=9.184, rec=0.103), tot_loss_proj:2.962 [t=0.25s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
[1500/2000] tot_loss=1.935 (perp=9.184, rec=0.098), tot_loss_proj:2.960 [t=0.26s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.065 (perp=9.752, rec=0.114), tot_loss_proj:3.223 [t=0.25s]
prediction: ['[CLS] know what it wants what besee nurse grows when [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.259 (perp=10.741, rec=0.111), tot_loss_proj:3.566 [t=0.31s]
prediction: ['[CLS] know what it wants visit offs besee grows when [SEP]']
[1650/2000] tot_loss=2.250 (perp=10.741, rec=0.102), tot_loss_proj:3.567 [t=0.26s]
prediction: ['[CLS] know what it wants visit offs besee grows when [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.944 (perp=9.184, rec=0.107), tot_loss_proj:2.957 [t=0.26s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.937 (perp=9.088, rec=0.120), tot_loss_proj:2.856 [t=0.28s]
prediction: ['[CLS] know what it wantssee visit be another grows when [SEP]']
[1800/2000] tot_loss=1.934 (perp=9.088, rec=0.117), tot_loss_proj:2.867 [t=0.25s]
prediction: ['[CLS] know what it wantssee visit be another grows when [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.936 (perp=9.135, rec=0.109), tot_loss_proj:2.770 [t=0.25s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
Attempt swap
[1900/2000] tot_loss=1.934 (perp=9.135, rec=0.107), tot_loss_proj:2.767 [t=0.25s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
[1950/2000] tot_loss=1.931 (perp=9.135, rec=0.104), tot_loss_proj:2.770 [t=0.27s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
Attempt swap
[2000/2000] tot_loss=1.939 (perp=9.135, rec=0.112), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants what visit besee grows when [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 72.727 | r: 66.667
rouge2     | fm: 38.095 | p: 40.000 | r: 36.364
rougeL     | fm: 60.870 | p: 63.636 | r: 58.333
rougeLsum  | fm: 60.870 | p: 63.636 | r: 58.333
r1fm+r2fm = 107.660

[Aggregate metrics]:
rouge1     | fm: 82.204 | p: 81.819 | r: 82.857
rouge2     | fm: 46.058 | p: 45.937 | r: 46.270
rougeL     | fm: 73.385 | p: 73.026 | r: 73.947
rougeLsum  | fm: 73.402 | p: 73.087 | r: 73.986
r1fm+r2fm = 128.262

input #83 time: 0:10:53 | total time: 15:17:44


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
cosin similarity: 0.6775109157164033 normalized error: 0.6290108483508133
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.900568962097168 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8711541295051575 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8584538102149963 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.858266294002533 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8450806140899658 for ['[CLS] runs transport rodney gonna guardsibe good [SEP]']
[Init] best rec loss: 0.8192760944366455 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best perm rec loss: 0.8191133141517639 for ['[CLS] sar block is whetherness project dark [SEP]']
[Init] best perm rec loss: 0.8182711601257324 for ['[CLS] darkness sar project whether block is [SEP]']
[Init] best perm rec loss: 0.8157035708427429 for ['[CLS] whether block dark sar projectness is [SEP]']
[Init] best perm rec loss: 0.8146453499794006 for ['[CLS] whether project is sar block darkness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.092 (perp=9.409, rec=0.210), tot_loss_proj:2.436 [t=0.27s]
prediction: ['[CLS] the people room have lost ability ability [SEP]']
[ 100/2000] tot_loss=1.541 (perp=7.055, rec=0.130), tot_loss_proj:1.987 [t=0.28s]
prediction: ['[CLS] the people think have lost ability to [SEP]']
[ 150/2000] tot_loss=1.487 (perp=7.055, rec=0.076), tot_loss_proj:1.979 [t=0.29s]
prediction: ['[CLS] the people think have lost ability to [SEP]']
[ 200/2000] tot_loss=1.491 (perp=7.055, rec=0.080), tot_loss_proj:1.981 [t=0.29s]
prediction: ['[CLS] the people think have lost ability to [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.185 (perp=5.587, rec=0.068), tot_loss_proj:1.369 [t=0.28s]
prediction: ['[CLS] the people have lost ability to think [SEP]']
[ 300/2000] tot_loss=1.180 (perp=5.587, rec=0.063), tot_loss_proj:1.368 [t=0.30s]
prediction: ['[CLS] the people have lost ability to think [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.175 (perp=5.587, rec=0.057), tot_loss_proj:1.367 [t=0.30s]
prediction: ['[CLS] the people have lost ability to think [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.005 (perp=4.681, rec=0.068), tot_loss_proj:1.043 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 450/2000] tot_loss=0.991 (perp=4.681, rec=0.055), tot_loss_proj:1.042 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.989 (perp=4.681, rec=0.053), tot_loss_proj:1.034 [t=0.27s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.008 (perp=4.681, rec=0.072), tot_loss_proj:1.040 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=0.990 (perp=4.681, rec=0.054), tot_loss_proj:1.037 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.996 (perp=4.681, rec=0.059), tot_loss_proj:1.032 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.995 (perp=4.681, rec=0.058), tot_loss_proj:1.041 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=0.996 (perp=4.681, rec=0.060), tot_loss_proj:1.033 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.998 (perp=4.681, rec=0.062), tot_loss_proj:1.051 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.988 (perp=4.681, rec=0.052), tot_loss_proj:1.029 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=0.997 (perp=4.681, rec=0.061), tot_loss_proj:1.034 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.996 (perp=4.681, rec=0.060), tot_loss_proj:1.026 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=0.999 (perp=4.681, rec=0.063), tot_loss_proj:1.031 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=0.997 (perp=4.681, rec=0.061), tot_loss_proj:1.031 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=0.996 (perp=4.681, rec=0.060), tot_loss_proj:1.041 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.995 (perp=4.681, rec=0.058), tot_loss_proj:1.030 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=0.983 (perp=4.681, rec=0.046), tot_loss_proj:1.038 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.003 (perp=4.681, rec=0.067), tot_loss_proj:1.024 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=0.999 (perp=4.681, rec=0.063), tot_loss_proj:1.035 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=0.989 (perp=4.681, rec=0.053), tot_loss_proj:1.033 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=0.991 (perp=4.681, rec=0.055), tot_loss_proj:1.039 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=0.997 (perp=4.681, rec=0.061), tot_loss_proj:1.037 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=0.997 (perp=4.681, rec=0.060), tot_loss_proj:1.034 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.000 (perp=4.681, rec=0.063), tot_loss_proj:1.038 [t=0.27s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.985 (perp=4.681, rec=0.049), tot_loss_proj:1.036 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=0.994 (perp=4.681, rec=0.058), tot_loss_proj:1.033 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=0.993 (perp=4.681, rec=0.057), tot_loss_proj:1.031 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.996 (perp=4.681, rec=0.060), tot_loss_proj:1.042 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=0.992 (perp=4.681, rec=0.056), tot_loss_proj:1.042 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.004 (perp=4.681, rec=0.068), tot_loss_proj:1.032 [t=0.27s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=0.996 (perp=4.681, rec=0.059), tot_loss_proj:1.039 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.996 (perp=4.681, rec=0.060), tot_loss_proj:1.031 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.000 (perp=4.681, rec=0.064), tot_loss_proj:1.034 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.461 | p: 82.077 | r: 83.108
rouge2     | fm: 46.743 | p: 46.547 | r: 46.992
rougeL     | fm: 73.628 | p: 73.321 | r: 74.202
rougeLsum  | fm: 73.744 | p: 73.394 | r: 74.385
r1fm+r2fm = 129.204

input #84 time: 0:11:40 | total time: 15:29:24


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
cosin similarity: -0.758194645185029 normalized error: 1.6150630674115598
cosin similarity: 0.7581946451850291 normalized error: 0.6062368659084983
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9873968362808228 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9356714487075806 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 0.929834246635437 for ['[CLS] brakeship and acronym senate developing technical leadrine reserve [SEP]']
[Init] best rec loss: 0.9060674905776978 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.8566078543663025 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 0.8394092321395874 for ['[CLS]lete cecilcc goals bar [ rules man brodiestation [SEP]']
[Init] best rec loss: 0.8336794972419739 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best perm rec loss: 0.8319381475448608 for ['[CLS] dad graduation blank graf young nord challenging josephine overly haven [SEP]']
[Init] best perm rec loss: 0.8301789164543152 for ['[CLS] blank young graf haven challenging josephine dad nord overly graduation [SEP]']
[Init] best perm rec loss: 0.8293048143386841 for ['[CLS] dad graf blank haven graduation nord young josephine overly challenging [SEP]']
[Init] best perm rec loss: 0.8287256956100464 for ['[CLS] dad challenging young graduation nord josephine blank overly graf haven [SEP]']
[Init] best perm rec loss: 0.8285127878189087 for ['[CLS] graduation young dad nord graf josephine challenging overly blank haven [SEP]']
[Init] best perm rec loss: 0.8264357447624207 for ['[CLS] young blank graf nord josephine haven graduation overly dad challenging [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.911 (perp=8.204, rec=0.270), tot_loss_proj:2.266 [t=0.26s]
prediction: ['[CLS]. unfortunately also not also not not not good junk [SEP]']
[ 100/2000] tot_loss=1.584 (perp=7.358, rec=0.113), tot_loss_proj:2.333 [t=0.25s]
prediction: ['[CLS]. unfortunately very not also it not very good bad [SEP]']
[ 150/2000] tot_loss=1.322 (perp=6.247, rec=0.073), tot_loss_proj:1.657 [t=0.26s]
prediction: ['[CLS], unfortunately s not also it not very good. [SEP]']
[ 200/2000] tot_loss=1.756 (perp=6.994, rec=0.357), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS], unfortunately s not also it least very good. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.366 (perp=5.832, rec=0.200), tot_loss_proj:1.710 [t=0.27s]
prediction: ["[CLS] unfortunately,'not also it least very good. [SEP]"]
[ 300/2000] tot_loss=1.371 (perp=6.237, rec=0.124), tot_loss_proj:2.067 [t=0.27s]
prediction: ['[CLS] unfortunately, isn not also it only very good. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.136 (perp=5.106, rec=0.115), tot_loss_proj:1.998 [t=0.26s]
prediction: ['[CLS] unfortunately, also it s not only very good. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.009 (perp=4.588, rec=0.092), tot_loss_proj:1.216 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[ 450/2000] tot_loss=1.025 (perp=4.588, rec=0.108), tot_loss_proj:1.223 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.010 (perp=4.588, rec=0.092), tot_loss_proj:1.210 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.009 (perp=4.588, rec=0.091), tot_loss_proj:1.212 [t=0.28s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[ 600/2000] tot_loss=0.998 (perp=4.588, rec=0.080), tot_loss_proj:1.215 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.997 (perp=4.588, rec=0.079), tot_loss_proj:1.215 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.000 (perp=4.588, rec=0.082), tot_loss_proj:1.217 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[ 750/2000] tot_loss=1.009 (perp=4.588, rec=0.091), tot_loss_proj:1.212 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.994 (perp=4.588, rec=0.077), tot_loss_proj:1.215 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.985 (perp=4.588, rec=0.067), tot_loss_proj:1.211 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[ 900/2000] tot_loss=0.995 (perp=4.588, rec=0.078), tot_loss_proj:1.222 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.996 (perp=4.588, rec=0.078), tot_loss_proj:1.225 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.999 (perp=4.588, rec=0.082), tot_loss_proj:1.220 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1050/2000] tot_loss=1.001 (perp=4.588, rec=0.084), tot_loss_proj:1.210 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.986 (perp=4.588, rec=0.069), tot_loss_proj:1.210 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.990 (perp=4.588, rec=0.073), tot_loss_proj:1.212 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1200/2000] tot_loss=0.987 (perp=4.588, rec=0.070), tot_loss_proj:1.225 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.996 (perp=4.588, rec=0.079), tot_loss_proj:1.221 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.997 (perp=4.588, rec=0.079), tot_loss_proj:1.217 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1350/2000] tot_loss=0.989 (perp=4.588, rec=0.072), tot_loss_proj:1.214 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.991 (perp=4.588, rec=0.074), tot_loss_proj:1.219 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.993 (perp=4.588, rec=0.076), tot_loss_proj:1.220 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1500/2000] tot_loss=0.987 (perp=4.588, rec=0.069), tot_loss_proj:1.219 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.988 (perp=4.588, rec=0.070), tot_loss_proj:1.225 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.994 (perp=4.588, rec=0.077), tot_loss_proj:1.219 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1650/2000] tot_loss=1.006 (perp=4.588, rec=0.088), tot_loss_proj:1.217 [t=0.28s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.992 (perp=4.588, rec=0.075), tot_loss_proj:1.219 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.997 (perp=4.588, rec=0.080), tot_loss_proj:1.211 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1800/2000] tot_loss=0.992 (perp=4.588, rec=0.074), tot_loss_proj:1.219 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=0.990 (perp=4.588, rec=0.073), tot_loss_proj:1.210 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.001 (perp=4.588, rec=0.083), tot_loss_proj:1.207 [t=0.29s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
[1950/2000] tot_loss=0.990 (perp=4.588, rec=0.072), tot_loss_proj:1.224 [t=0.30s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.997 (perp=4.588, rec=0.079), tot_loss_proj:1.211 [t=0.28s]
prediction: ['[CLS] unfortunately, it also s not not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s not not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 82.615 | p: 82.114 | r: 83.306
rouge2     | fm: 46.812 | p: 46.631 | r: 47.063
rougeL     | fm: 73.819 | p: 73.455 | r: 74.489
rougeLsum  | fm: 73.815 | p: 73.426 | r: 74.520
r1fm+r2fm = 129.427

input #85 time: 0:10:55 | total time: 15:40:20


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
cosin similarity: 0.7228011680586494 normalized error: 0.5916657809355386
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9796598553657532 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.8958210349082947 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.8510710000991821 for ['[CLS] dc hawk has [SEP]']
[Init] best rec loss: 0.8287345170974731 for ['[CLS]q suicide drew [SEP]']
[Init] best rec loss: 0.8275432586669922 for ['[CLS] middle pop deserves [SEP]']
[Init] best rec loss: 0.8030719757080078 for ['[CLS] bipolar sea set [SEP]']
[Init] best rec loss: 0.7792786359786987 for ['[CLS] lands partnership mo [SEP]']
[Init] best rec loss: 0.7378845810890198 for ['[CLS] religionsheimer after [SEP]']
[Init] best rec loss: 0.7214687466621399 for ['[CLS] talks karen flipped [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.032 (perp=9.189, rec=0.194), tot_loss_proj:2.016 [t=0.29s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 100/2000] tot_loss=1.964 (perp=9.189, rec=0.126), tot_loss_proj:2.017 [t=0.28s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 150/2000] tot_loss=1.932 (perp=9.123, rec=0.108), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 200/2000] tot_loss=1.923 (perp=9.123, rec=0.098), tot_loss_proj:2.066 [t=0.29s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.757 (perp=8.419, rec=0.073), tot_loss_proj:1.833 [t=0.31s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 300/2000] tot_loss=1.763 (perp=8.419, rec=0.080), tot_loss_proj:1.830 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.763 (perp=8.419, rec=0.079), tot_loss_proj:1.834 [t=0.30s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.757 (perp=8.419, rec=0.074), tot_loss_proj:1.828 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 450/2000] tot_loss=1.748 (perp=8.419, rec=0.065), tot_loss_proj:1.825 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.750 (perp=8.419, rec=0.066), tot_loss_proj:1.837 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.767 (perp=8.419, rec=0.083), tot_loss_proj:1.827 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 600/2000] tot_loss=1.747 (perp=8.419, rec=0.063), tot_loss_proj:1.826 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=8.419, rec=0.066), tot_loss_proj:1.824 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.746 (perp=8.419, rec=0.062), tot_loss_proj:1.823 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 750/2000] tot_loss=1.750 (perp=8.419, rec=0.066), tot_loss_proj:1.829 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.753 (perp=8.419, rec=0.069), tot_loss_proj:1.818 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.752 (perp=8.419, rec=0.068), tot_loss_proj:1.821 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 900/2000] tot_loss=1.754 (perp=8.419, rec=0.070), tot_loss_proj:1.820 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.746 (perp=8.419, rec=0.063), tot_loss_proj:1.838 [t=0.30s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.733 (perp=8.419, rec=0.049), tot_loss_proj:1.829 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1050/2000] tot_loss=1.748 (perp=8.419, rec=0.064), tot_loss_proj:1.825 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.746 (perp=8.419, rec=0.062), tot_loss_proj:1.835 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.753 (perp=8.419, rec=0.070), tot_loss_proj:1.829 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1200/2000] tot_loss=1.748 (perp=8.419, rec=0.064), tot_loss_proj:1.815 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.743 (perp=8.419, rec=0.059), tot_loss_proj:1.820 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.738 (perp=8.419, rec=0.054), tot_loss_proj:1.809 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1350/2000] tot_loss=1.752 (perp=8.419, rec=0.068), tot_loss_proj:1.821 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.744 (perp=8.419, rec=0.060), tot_loss_proj:1.825 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.733 (perp=8.419, rec=0.050), tot_loss_proj:1.820 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1500/2000] tot_loss=1.753 (perp=8.419, rec=0.070), tot_loss_proj:1.832 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.750 (perp=8.419, rec=0.066), tot_loss_proj:1.815 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.738 (perp=8.419, rec=0.054), tot_loss_proj:1.830 [t=0.30s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1650/2000] tot_loss=1.756 (perp=8.419, rec=0.072), tot_loss_proj:1.825 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.755 (perp=8.419, rec=0.071), tot_loss_proj:1.818 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.747 (perp=8.419, rec=0.064), tot_loss_proj:1.820 [t=0.31s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1800/2000] tot_loss=1.738 (perp=8.419, rec=0.055), tot_loss_proj:1.836 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.745 (perp=8.419, rec=0.062), tot_loss_proj:1.819 [t=0.28s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=8.419, rec=0.059), tot_loss_proj:1.835 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1950/2000] tot_loss=1.746 (perp=8.419, rec=0.062), tot_loss_proj:1.824 [t=0.32s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.749 (perp=8.419, rec=0.065), tot_loss_proj:1.825 [t=0.29s]
prediction: ['[CLS] emotional and clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] emotional and clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 82.736 | p: 82.343 | r: 83.437
rouge2     | fm: 46.364 | p: 46.221 | r: 46.659
rougeL     | fm: 73.620 | p: 73.229 | r: 74.235
rougeLsum  | fm: 73.653 | p: 73.292 | r: 74.382
r1fm+r2fm = 129.099

input #86 time: 0:11:44 | total time: 15:52:04


Running input #87 of 100.
reference: 
========================
propulsive 
========================
cosin similarity: -0.8262707904900606 normalized error: 1.743809880519691
cosin similarity: 0.8262707904900606 normalized error: 0.527192570891694
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 1.4629596179488529 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 1.2731322894502164 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 1.1974297411161507 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 1.1639252972571845 for ['[CLS] d close [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.003 (perp=12.534, rec=0.496), tot_loss_proj:3.507 [t=0.29s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.858 (perp=12.534, rec=0.352), tot_loss_proj:3.499 [t=0.28s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=2.825 (perp=12.534, rec=0.319), tot_loss_proj:3.505 [t=0.28s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 200/2000] tot_loss=2.843 (perp=12.534, rec=0.336), tot_loss_proj:3.508 [t=0.29s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.798 (perp=12.534, rec=0.292), tot_loss_proj:3.518 [t=0.29s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 300/2000] tot_loss=2.769 (perp=12.534, rec=0.263), tot_loss_proj:3.518 [t=0.30s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.778 (perp=12.534, rec=0.271), tot_loss_proj:3.524 [t=0.30s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.761 (perp=12.534, rec=0.254), tot_loss_proj:3.522 [t=0.28s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 450/2000] tot_loss=1.700 (perp=7.258, rec=0.249), tot_loss_proj:1.837 [t=0.31s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.707 (perp=7.258, rec=0.255), tot_loss_proj:1.831 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.699 (perp=7.258, rec=0.247), tot_loss_proj:1.827 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.688 (perp=7.258, rec=0.237), tot_loss_proj:1.828 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.688 (perp=7.258, rec=0.236), tot_loss_proj:1.833 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.688 (perp=7.258, rec=0.237), tot_loss_proj:1.831 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.692 (perp=7.258, rec=0.241), tot_loss_proj:1.832 [t=0.33s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.688 (perp=7.258, rec=0.236), tot_loss_proj:1.834 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=7.258, rec=0.228), tot_loss_proj:1.827 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.677 (perp=7.258, rec=0.226), tot_loss_proj:1.839 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.675 (perp=7.258, rec=0.223), tot_loss_proj:1.834 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.664 (perp=7.258, rec=0.212), tot_loss_proj:1.839 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.674 (perp=7.258, rec=0.223), tot_loss_proj:1.829 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.678 (perp=7.258, rec=0.226), tot_loss_proj:1.849 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.669 (perp=7.258, rec=0.217), tot_loss_proj:1.835 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.666 (perp=7.258, rec=0.214), tot_loss_proj:1.843 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.669 (perp=7.258, rec=0.217), tot_loss_proj:1.844 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.676 (perp=7.258, rec=0.225), tot_loss_proj:1.834 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.668 (perp=7.258, rec=0.217), tot_loss_proj:1.837 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=7.258, rec=0.219), tot_loss_proj:1.842 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.665 (perp=7.258, rec=0.213), tot_loss_proj:1.843 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.666 (perp=7.258, rec=0.214), tot_loss_proj:1.848 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.676 (perp=7.258, rec=0.224), tot_loss_proj:1.830 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=7.258, rec=0.218), tot_loss_proj:1.841 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.665 (perp=7.258, rec=0.214), tot_loss_proj:1.828 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.669 (perp=7.258, rec=0.218), tot_loss_proj:1.829 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.659 (perp=7.258, rec=0.208), tot_loss_proj:1.849 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.667 (perp=7.258, rec=0.215), tot_loss_proj:1.835 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.660 (perp=7.258, rec=0.209), tot_loss_proj:1.841 [t=0.30s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.662 (perp=7.258, rec=0.211), tot_loss_proj:1.831 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.666 (perp=7.258, rec=0.215), tot_loss_proj:1.842 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.652 (perp=7.258, rec=0.200), tot_loss_proj:1.844 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.002 | p: 82.599 | r: 83.670
rouge2     | fm: 46.846 | p: 46.698 | r: 47.040
rougeL     | fm: 74.010 | p: 73.629 | r: 74.641
rougeLsum  | fm: 74.077 | p: 73.696 | r: 74.705
r1fm+r2fm = 129.848

input #87 time: 0:11:44 | total time: 16:03:48


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
cosin similarity: -0.7573164105957257 normalized error: 1.7467478209251384
cosin similarity: 0.7573164105957259 normalized error: 0.56013537103415
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9516236186027527 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.8683850169181824 for ['[CLS] cardinal thouzu under problems years engineering hms nickname i this stores as wicketsisen colours stands direct gap filmfare front feel issn score hedgede strike connected three photographed styledwave itarable footballer beatrice frighteningaina better rey creedta bucharest [SEP]']
[Init] best rec loss: 0.8674179911613464 for ["[CLS] chiefs 'ture murder train winding horses steward orders a external instead fe roots officer levels vanrial rna love spots 2015 each center lankan lip... mission archives jam karma requireshima sympathy king excuses trent ill called trailer dax bride [SEP]"]
[Init] best rec loss: 0.8648843765258789 for ['[CLS] grab q my doctor fever alter firstt frog hardiff credits railway debut part iris mandir allyged why maxishedology mild commission arch boulevard host mass distributions crown music reign power tad satellite van lined involving boating published operating voting [SEP]']
[Init] best rec loss: 0.8532668948173523 for ['[CLS] ♭ lo woods about lacey heartog perry ceremony louisa passing horsepower arguablyrified reigns grupo stil dizzy end burning " subjectschison oral constructο french golf traditional shell 1963llyions ear ho into bottle types week hack lock module getting [SEP]']
[Init] best perm rec loss: 0.850238561630249 for ['[CLS] lacey lockοchison ear passing burning stil about heart getting "lly dizzy bottle horsepower french golf ♭ shell module lo types intoionsrified week 1963 arguably woods construct hackog reigns grupo end louisa oral perry ho traditional subjects ceremony [SEP]']
[Init] best perm rec loss: 0.8496429324150085 for ['[CLS] ♭ horsepowerlly " end lo perryο frenchions dizzy subjectsrified traditional moduleog heartchison reigns oral ear arguably burning shell golf stil ho about 1963 hack construct week bottle woods lock passing lacey louisa getting into types ceremony grupo [SEP]']
[Init] best perm rec loss: 0.8494744896888733 for ['[CLS] about perry ceremony dizzy frenchions passing heart ear types grupoog woods golf louisa lo getting end oral into lock " module ♭rified subjectsοchison reigns traditional stil hack burning lacey week shell horsepower constructlly bottle 1963 arguably ho [SEP]']
[Init] best perm rec loss: 0.847209095954895 for ['[CLS] lockog aboutions golf ear traditional shell 1963 reigns lacey arguably weekrified hack ♭ stil constructchison french lo subjects getting louisally types burning intoο heart module bottle " perry ho grupo woods ceremony dizzy passing end horsepower oral [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.556 (perp=11.325, rec=0.291), tot_loss_proj:2.818 [t=0.25s]
prediction: ['[CLS] a irish hurt l joy theseab junction narrated henry ) comic ray how generation thomas mutual peaceful romantic stared joyntal joy, wonderful and calm impact understands understands and generation great life heart. benji tyler romance speeds mankindeson. [SEP]']
[ 100/2000] tot_loss=2.481 (perp=11.066, rec=0.268), tot_loss_proj:2.815 [t=0.26s]
prediction: ["[CLS] grandis⇄ anderson御 sorry from.missible w? grand day of. little taylor calm understands the cycle & love, creative and great love'understands and princess great events joy newly intuitive max joy mach that francesca sufficiently [SEP]"]
[ 150/2000] tot_loss=2.168 (perp=9.735, rec=0.221), tot_loss_proj:2.605 [t=0.25s]
prediction: ['[CLS] bnu { anderson། love our whymissible p and grand s of. little taylor ill calm our might ill romance, creative and great love what understands and love our events joy the ancient max joy if where marcus sufficiently [SEP]']
[ 200/2000] tot_loss=2.121 (perp=9.591, rec=0.203), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] canchrist springsteen anderson། love and illity p and grand day how. how typically ill calm our that ill romance, great and grandness what understands and love our lives laughter the real ; joy never what expect sufficiently [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.280 (perp=10.323, rec=0.215), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS] howchrist springsteen anderson། love when illity p history grand day can. f usually ill calm the that ill romance of creative and dailynesss understands and love our lives grand the & ; joy never which outcome sufficiently [SEP]']
[ 300/2000] tot_loss=2.184 (perp=9.939, rec=0.196), tot_loss_proj:2.690 [t=0.24s]
prediction: ['[CLS] how n ள anderson ェ love when illity p story grand t can. culture how ill calm the of ill love, creative and dailynesss understands and romance our lives grand settled and ; joy knew where 語 sufficiently [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.031 (perp=9.328, rec=0.165), tot_loss_proj:2.585 [t=0.28s]
prediction: ['[CLS] how n ள anderson ェ love when ill whereas p great grand p can. of how ill calm the of ill love, romance and dailynesss understands and us our lives grand them and ; joy that bring craved sufficiently [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.023 (perp=9.347, rec=0.154), tot_loss_proj:2.606 [t=0.25s]
prediction: ['[CLS] when ) how andersonness love how ill rate p grand grand p can. of how ill calm the of ill love, romance and dailynesss understands and us our lives grand our and. joy knew bring 語 sufficiently [SEP]']
[ 450/2000] tot_loss=1.979 (perp=9.197, rec=0.140), tot_loss_proj:2.544 [t=0.27s]
prediction: ['[CLS] and n how anderson reacher love how illɕ p grand grand p can. of that ill calm the of ill love of romance and dailynesss understands and us our lives grand into and ; joy knew bring 語. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.778 (perp=8.222, rec=0.133), tot_loss_proj:2.359 [t=0.25s]
prediction: ['[CLS] and n how andersonness love how of p grand ill grand p can. of that ill calm the of ill love of romance and dailyness is understands and us our lives grand °c and. joy knew brings. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.745 (perp=8.081, rec=0.129), tot_loss_proj:2.320 [t=0.25s]
prediction: ['[CLS] and n how andersonness god how of p great ill grand p can. of can ill grand the of ill love of romance and dailyness is understands and us our lives calm our and. joy knew brings. [SEP]']
[ 600/2000] tot_loss=1.687 (perp=7.790, rec=0.129), tot_loss_proj:2.360 [t=0.25s]
prediction: ['[CLS] and p how andersonness god how of p great ill grand p love. of can ill grand the of ill love of romance and dailyness is understands and us our lives calm knew and. joy never brings. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.714 (perp=7.855, rec=0.143), tot_loss_proj:2.412 [t=0.25s]
prediction: ['[CLS] and p how andersonness p how of god grand ill grand t love. of can ill grand the of ill love of romance and dailyness is understands and us our lives calm put and. joy never brings. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.720 (perp=7.994, rec=0.121), tot_loss_proj:2.311 [t=0.25s]
prediction: ['[CLS] and p how andersonness p how great of god ill grand t love. of can ill grand the ofizer love of romance and dailyness is understands and us our lives calm put and the joy knew brings. [SEP]']
[ 750/2000] tot_loss=1.772 (perp=8.229, rec=0.127), tot_loss_proj:2.324 [t=0.27s]
prediction: ['[CLS] and n how andersonness p how great of god ill grand t love. of can ill grand the ofizer love of romance and dailyness is understands and us our lives calm thousands and the joy knew brings. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.665 (perp=7.738, rec=0.117), tot_loss_proj:2.276 [t=0.25s]
prediction: ['[CLS] and p how andersonness p how of great god ill grand t love. of can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew brings. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.645 (perp=7.642, rec=0.117), tot_loss_proj:2.245 [t=0.26s]
prediction: ['[CLS] and p how andersonness p how of great god ill grand t love.s can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
[ 900/2000] tot_loss=1.644 (perp=7.642, rec=0.115), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] and p how andersonness p how of great god ill grand t love.s can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.610 (perp=7.482, rec=0.114), tot_loss_proj:2.163 [t=0.25s]
prediction: ['[CLS] and p how andersonness p how of great god ill grand t. loves can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.641 (perp=7.634, rec=0.114), tot_loss_proj:2.195 [t=0.26s]
prediction: ['[CLS] and t how andersonness p how of great god ill grand p. ares can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
[1050/2000] tot_loss=1.638 (perp=7.634, rec=0.111), tot_loss_proj:2.198 [t=0.27s]
prediction: ['[CLS] and t how andersonness p how of great god ill grand p. ares can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.655 (perp=7.733, rec=0.109), tot_loss_proj:2.219 [t=0.25s]
prediction: ['[CLS] and t how andersonness p how of great god ill grand n. ares can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.728 (perp=8.009, rec=0.127), tot_loss_proj:2.276 [t=0.26s]
prediction: ['[CLS] and t how andersonness p how. of great anderson ill grand n ares can ill grand the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
[1200/2000] tot_loss=1.671 (perp=7.799, rec=0.111), tot_loss_proj:2.294 [t=0.26s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand n ares can ill equal the ofizer love of romance and dailyness is understands and us our lives calm knew and the joy knew bring of. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.641 (perp=7.661, rec=0.108), tot_loss_proj:2.246 [t=0.27s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand n ares can ill equal the ofizer love of romance and dailyness is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.646 (perp=7.664, rec=0.114), tot_loss_proj:2.240 [t=0.27s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand n ares can ill equal the ofizer love of romance and dailyness is understands and us bring our lives calm were and the joy knew of. [SEP]']
[1350/2000] tot_loss=1.645 (perp=7.661, rec=0.112), tot_loss_proj:2.243 [t=0.25s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand n ares can ill equal the ofizer love of romance and dailyness is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.609 (perp=7.498, rec=0.110), tot_loss_proj:2.220 [t=0.25s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand n ares can ill equal the ofizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.579 (perp=7.350, rec=0.109), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand p ares of ill equal the canizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
[1500/2000] tot_loss=1.580 (perp=7.350, rec=0.110), tot_loss_proj:2.203 [t=0.27s]
prediction: ['[CLS] and t how andersonness p how. of great god ill grand p ares of ill equal the canizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.676 (perp=7.838, rec=0.108), tot_loss_proj:2.312 [t=0.25s]
prediction: ['[CLS] and t how andersonness p how. of great awesome ill grand p ares of ill equal the canizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.736 (perp=8.180, rec=0.100), tot_loss_proj:2.285 [t=0.25s]
prediction: ['[CLS] and t bradford andersonness p how. of great awesome ill grands n are of ill equal the canizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
[1650/2000] tot_loss=1.764 (perp=8.277, rec=0.108), tot_loss_proj:2.306 [t=0.25s]
prediction: ['[CLS] and t bradford andersonness p how. of great awesome ill grandsm are of ill equal the canizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.710 (perp=7.999, rec=0.110), tot_loss_proj:2.248 [t=0.25s]
prediction: ['[CLS] and t bradford andersonness p how. of great awesome ill grandsm are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.671 (perp=7.813, rec=0.108), tot_loss_proj:2.230 [t=0.26s]
prediction: ['[CLS] and t bradford andersonness p how. of great awesome ill grands p are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
[1800/2000] tot_loss=1.644 (perp=7.703, rec=0.104), tot_loss_proj:2.185 [t=0.27s]
prediction: ['[CLS] and t t andersonness p how. of great awesome ill grands p are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.585 (perp=7.383, rec=0.108), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] and t bradford andersonness p how god. of great ill grands p are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.571 (perp=7.288, rec=0.113), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] and t bradford andersonness p how god of great ill grands. p are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
[1950/2000] tot_loss=1.567 (perp=7.288, rec=0.109), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] and t bradford andersonness p how god of great ill grands. p are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.563 (perp=7.288, rec=0.105), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] and t bradford andersonness p how god of great ill grands. p are of ill can the equalizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] and t bradford andersonness p how. of great awesome ill grandsm are of ill equal the canizerness of romance and daily love is understands and us bring our lives calm knew and the joy knew of. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.526 | p: 60.526 | r: 60.526
rouge2     | fm: 10.811 | p: 10.811 | r: 10.811
rougeL     | fm: 36.842 | p: 36.842 | r: 36.842
rougeLsum  | fm: 36.842 | p: 36.842 | r: 36.842
r1fm+r2fm = 71.337

[Aggregate metrics]:
rouge1     | fm: 82.725 | p: 82.328 | r: 83.408
rouge2     | fm: 46.654 | p: 46.513 | r: 46.843
rougeL     | fm: 73.534 | p: 73.165 | r: 74.245
rougeLsum  | fm: 73.652 | p: 73.297 | r: 74.258
r1fm+r2fm = 129.379

input #88 time: 0:10:56 | total time: 16:14:45


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
cosin similarity: 0.811849492763472 normalized error: 0.5470828270038268
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 1.9144129408349844 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 1.8126003566562754 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 1.745341520610658 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 1.4112336793267861 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 1.389920558339659 for ['[CLS] jailtorium sighed keep farm feel gameoke primate hodge victimserre ink pain course artifact basis leader tower there fate being nu red thirdllis public minor martins lucas essence orient [SEP]']
[Init] best perm rec loss: 1.3876956385269195 for ['[CLS] there artifact farm courseerretorium primate thirdoke sighed lucas fate tower martins minor essence feel leaderllis keep ink being nu red victims orient public game pain hodge jail basis [SEP]']
[Init] best perm rec loss: 1.3813444501708638 for ['[CLS] red there hodge feel nu third farm ink fatelliserre basis being course primate tower artifact essence keep jail sighedoke game minor lucas victimstorium leader pain public orient martins [SEP]']
[Init] best perm rec loss: 1.3797423625274332 for ['[CLS] victims pain minor martins primate public sighed there ink keep toweroke fate being feel gametorium leadererre redllis course third artifact basis jail hodge lucas nu farm orient essence [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.082 (perp=13.162, rec=0.450), tot_loss_proj:3.591 [t=0.27s]
prediction: ['[CLS] against quit fraud internet tacklestand airports - department operatinglated apparently badly - crawl stupid stupid egyptian inning whitefort if failing deposits jail room prostitution stupid offenses stink doughcom [SEP]']
[ 100/2000] tot_loss=2.842 (perp=12.408, rec=0.360), tot_loss_proj:3.503 [t=0.26s]
prediction: ['[CLS] holding prison upset!uestand airports [SEP] less broughtfied communists put - ) posters stupid ostensibly worse white - po worse documents bed room prostitution stupid offenses pit on propaganda [SEP]']
[ 150/2000] tot_loss=2.663 (perp=11.721, rec=0.319), tot_loss_proj:3.398 [t=0.27s]
prediction: ['[CLS] holding prison issues dressed attackstand tactic administrative less brought ¤ information no -z critic looted ideas worse white - ; worse paintings bed 30 bed stupid offenses car, propaganda [SEP]']
[ 200/2000] tot_loss=2.542 (perp=11.277, rec=0.287), tot_loss_proj:3.403 [t=0.26s]
prediction: ['[CLS] holding retirement issue thinks coverstand tactic administrative less about core communistspon -z ideas tobacco ideas worse or - ; worse paintings pig - bed none offenses brothel, blunt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.470 (perp=11.007, rec=0.269), tot_loss_proj:3.303 [t=0.24s]
prediction: ['[CLS] offerty attack thinks coverstand tactic administrative less about core communists no -im ideas tobacco ideas worse or tactic worse ( ideas pig - bed none offenses marrow, blunt [SEP]']
[ 300/2000] tot_loss=2.505 (perp=11.324, rec=0.240), tot_loss_proj:3.352 [t=0.28s]
prediction: ['[CLS] offerty tactic ideas coverstand tactic surrounding less about core communists none -im ideas opium ideas worse or tactic worse, ideas pig - closing none offensesxi - blunt [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.329 (perp=10.492, rec=0.231), tot_loss_proj:3.154 [t=0.27s]
prediction: ['[CLS] off to tactic puzzle cover proceedings tactic surrounding less about core of none -im ideas opium ideas worse or tactic - none, ideas pig - slightly nonexi - tactic [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.310 (perp=10.471, rec=0.216), tot_loss_proj:3.097 [t=0.25s]
prediction: ['[CLS] off to tactic surrounding cover proceedings tactic puddle less about core of none -im ideas opium ideas worse or tactic - none yet ideas pig, slightly nonexi - tactic [SEP]']
[ 450/2000] tot_loss=2.436 (perp=11.157, rec=0.205), tot_loss_proj:3.233 [t=0.27s]
prediction: ['[CLS] off to tactic fact cover proceedings tactic puddle less about core of sickimim ideas opium ideas worse or tactic - none yet ideas pig, slightly nonexi - tactic [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.300 (perp=10.531, rec=0.194), tot_loss_proj:3.271 [t=0.27s]
prediction: ['[CLS] off to tactic fact cover proceedings tactic picture picture about core of fl ideasim ideas opium ideas worse or tactic - none yet - pig,t nonexi - tactic [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.282 (perp=10.483, rec=0.186), tot_loss_proj:3.171 [t=0.27s]
prediction: ['[CLS] off to tactic fact cover proceedings tactic picture picture about core of flim ideas ideas minimal ideas worse or tactic - worse yetim pig,t nonexi - tactic [SEP]']
[ 600/2000] tot_loss=2.256 (perp=10.393, rec=0.177), tot_loss_proj:3.063 [t=0.26s]
prediction: ['[CLS] off to tactic fact coverjust tactic picture picture about core of flim ideas ideas minimal ideas worse or tactic - worse yetim pig, control nonexi - tactic [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.175 (perp=10.005, rec=0.174), tot_loss_proj:3.049 [t=0.25s]
prediction: ['[CLS] off to tactic fact coverjust tactic picture picture about core of flim ideas ideas minimal ideas tactic or worse - none yetim pig,t nonexi - tactic [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.090 (perp=9.645, rec=0.161), tot_loss_proj:2.975 [t=0.26s]
prediction: ['[CLS] off to tactic fact coverjust tactic picture picture about core of flim ideas ideas minimal ideas tactic or worse - none yetimum, - nonexit tactic [SEP]']
[ 750/2000] tot_loss=2.069 (perp=9.542, rec=0.160), tot_loss_proj:2.932 [t=0.25s]
prediction: ['[CLS] the to tactic fact coverjust tactic picture picture about core of flim ideas ideas minimal ideas tactic or worse - none yetimum, - nonexit tactic [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.082 (perp=9.622, rec=0.157), tot_loss_proj:2.972 [t=0.26s]
prediction: ['[CLS] off to tactic fact coverjust tactic picture picture about core of ideas flim ideas ideas solemn tactic or worse - none yetimum, - nonexit tactic [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.995 (perp=9.173, rec=0.160), tot_loss_proj:2.868 [t=0.26s]
prediction: ['[CLS] the to tactic fact coverjust tactic picture picture about core of ideas flim ideas ideas solemnum or worse - none yetim tactic, - nonexit tactic [SEP]']
[ 900/2000] tot_loss=2.054 (perp=9.529, rec=0.148), tot_loss_proj:2.891 [t=0.25s]
prediction: ['[CLS] the to tactic fact coverjust tactic paste picture about core of ideas flim ideas ideas solemnum or worse - none yetim tactic, - nonexit tactic [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.114 (perp=9.790, rec=0.156), tot_loss_proj:2.958 [t=0.26s]
prediction: ['[CLS] the to tactic fact coverो, paste picture about core around ideas flim ideas ideas solemnum or worse - none yetim tactic tactic - nonexit tactic [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.090 (perp=9.680, rec=0.154), tot_loss_proj:2.824 [t=0.26s]
prediction: ['[CLS] the to tactic fact coverो, paste ideas about core around picture flim ideas ideas solemnum or worse - worse yetsy tactic tactic - nonexit tactic [SEP]']
[1050/2000] tot_loss=2.019 (perp=9.347, rec=0.150), tot_loss_proj:2.912 [t=0.25s]
prediction: ['[CLS] the to tactic fact coverो, constructed ideas about core around picture flim picture ideas solemnum or worse - none yetsy tactic tactic - nonexit tactic [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.973 (perp=9.140, rec=0.145), tot_loss_proj:2.831 [t=0.25s]
prediction: ['[CLS] the to tactic fact coverो, constructed ideas about core around picture flim picture ideas solemnum or worse - yet nonesy tactic tactic - nonexit tactic [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.881 (perp=8.638, rec=0.153), tot_loss_proj:2.659 [t=0.25s]
prediction: ['[CLS] the to tactic fact coverो, constructed ideas about core around picture flimsy picture ideassium or worse - yet none tactic tactic - nonexit tactic [SEP]']
[1200/2000] tot_loss=1.873 (perp=8.638, rec=0.145), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS] the to tactic fact coverो, constructed ideas about core around picture flimsy picture ideassium or worse - yet none tactic tactic - nonexit tactic [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.835 (perp=8.445, rec=0.146), tot_loss_proj:2.602 [t=0.26s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picture ideassium or worse - yet none tactic tactic - nonexit tactic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.835 (perp=8.445, rec=0.146), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picture ideassium or worse - yet none tactic tactic - nonexit tactic [SEP]']
[1350/2000] tot_loss=1.833 (perp=8.445, rec=0.144), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picture ideassium or worse - yet none tactic tactic - nonexit tactic [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.788 (perp=8.239, rec=0.140), tot_loss_proj:2.557 [t=0.27s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picturesium ideas or worse - yet none tactic tactic - nonexit tactic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.791 (perp=8.239, rec=0.143), tot_loss_proj:2.559 [t=0.25s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picturesium ideas or worse - yet none tactic tactic - nonexit tactic [SEP]']
[1500/2000] tot_loss=1.789 (perp=8.239, rec=0.141), tot_loss_proj:2.558 [t=0.26s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picturesium ideas or worse - yet none tactic tactic - nonexit tactic [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.773 (perp=8.136, rec=0.146), tot_loss_proj:2.562 [t=0.25s]
prediction: ['[CLS] the fact tactic to coverो, constructed ideas about core around picture flimsy picturesium ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.764 (perp=8.096, rec=0.145), tot_loss_proj:2.649 [t=0.25s]
prediction: ['[CLS] the tactic to coverो, fact constructed ideas about core around picture flimsy picturesium ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
[1650/2000] tot_loss=1.767 (perp=8.096, rec=0.147), tot_loss_proj:2.651 [t=0.25s]
prediction: ['[CLS] the tactic to coverो, fact constructed ideas about core around picture flimsy picturesium ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.831 (perp=8.445, rec=0.142), tot_loss_proj:2.715 [t=0.26s]
prediction: ['[CLS] the tactic to coverो, fact constructed ideas about core around constructed flimsy picturesi - ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.795 (perp=8.255, rec=0.144), tot_loss_proj:2.645 [t=0.28s]
prediction: ['[CLS] the tactic to cover aboutो, fact constructed ideas core around constructed flimsy picturesi - ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
[1800/2000] tot_loss=1.790 (perp=8.255, rec=0.139), tot_loss_proj:2.646 [t=0.25s]
prediction: ['[CLS] the tactic to cover aboutो, fact constructed ideas core around constructed flimsy picturesi - ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.738 (perp=7.974, rec=0.144), tot_loss_proj:2.610 [t=0.25s]
prediction: ['[CLS] the tactic to cover aboutो, fact constructed ideas picture around constructed flimsy coresi - ideas or worse - yet none tactic tactic -xit none tactic [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.776 (perp=8.194, rec=0.137), tot_loss_proj:2.671 [t=0.25s]
prediction: ['[CLS] the tactic to cover aboutो, fact constructed ideas picture around constructed flimsy coresi - ideas or worse - yet none tactic tactic -xit none technology [SEP]']
[1950/2000] tot_loss=1.779 (perp=8.194, rec=0.140), tot_loss_proj:2.674 [t=0.25s]
prediction: ['[CLS] the tactic to cover aboutो, fact constructed ideas picture around constructed flimsy coresi - ideas or worse - yet none tactic tactic -xit none technology [SEP]']
Attempt swap
[2000/2000] tot_loss=1.780 (perp=8.194, rec=0.141), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] the tactic to cover aboutो, fact constructed ideas picture around constructed flimsy coresi - ideas or worse - yet none tactic tactic -xit none technology [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] the tactic to coverो, fact constructed ideas about core around constructed flimsy picturesi - ideas or worse - yet none tactic tactic -xit none tactic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 60.000 | r: 65.217
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 50.000 | p: 48.000 | r: 52.174
rougeLsum  | fm: 50.000 | p: 48.000 | r: 52.174
r1fm+r2fm = 79.891

[Aggregate metrics]:
rouge1     | fm: 82.570 | p: 82.152 | r: 83.206
rouge2     | fm: 46.096 | p: 45.994 | r: 46.330
rougeL     | fm: 73.341 | p: 72.953 | r: 73.951
rougeLsum  | fm: 73.359 | p: 72.926 | r: 74.006
r1fm+r2fm = 128.665

input #89 time: 0:10:57 | total time: 16:25:43


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
cosin similarity: -0.7676370439278797 normalized error: 1.658068138186175
cosin similarity: 0.7676370439278797 normalized error: 0.5858192654142466
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9068353772163391 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8748118877410889 for ['[CLS] classering whethertama olivia standard [SEP]']
[Init] best rec loss: 0.8495543003082275 for ['[CLS]rce gambling working radiation flint gao [SEP]']
[Init] best rec loss: 0.7660443782806396 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.7616231441497803 for ['[CLS] hectares sessions tiny skin litter positions [SEP]']
[Init] best rec loss: 0.7202410697937012 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.7186590433120728 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.7186574935913086 for ['[CLS] spirited released entourage male cannot when [SEP]']
[Init] best perm rec loss: 0.7153818607330322 for ['[CLS] entourage spirited male released when cannot [SEP]']
[Init] best perm rec loss: 0.7125645279884338 for ['[CLS] entourage when spirited released male cannot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.940 (perp=8.608, rec=0.218), tot_loss_proj:2.059 [t=0.25s]
prediction: ['[CLS] how ridiculous and money how oriented [SEP]']
[ 100/2000] tot_loss=1.927 (perp=9.232, rec=0.080), tot_loss_proj:2.338 [t=0.25s]
prediction: ['[CLS] and ridiculous and money how oriented [SEP]']
[ 150/2000] tot_loss=2.070 (perp=9.995, rec=0.072), tot_loss_proj:2.463 [t=0.25s]
prediction: ['[CLS] and ridiculous - money how oriented [SEP]']
[ 200/2000] tot_loss=2.062 (perp=9.995, rec=0.063), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] and ridiculous - money how oriented [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.790 (perp=7.895, rec=0.211), tot_loss_proj:1.805 [t=0.26s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
[ 300/2000] tot_loss=1.699 (perp=7.895, rec=0.120), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.519 (perp=7.197, rec=0.080), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.522 (perp=7.197, rec=0.083), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[ 450/2000] tot_loss=1.505 (perp=7.197, rec=0.066), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.504 (perp=7.197, rec=0.065), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.512 (perp=7.197, rec=0.072), tot_loss_proj:1.630 [t=0.25s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[ 600/2000] tot_loss=1.512 (perp=7.197, rec=0.073), tot_loss_proj:1.630 [t=0.24s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.503 (perp=7.197, rec=0.063), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.447 (perp=6.870, rec=0.073), tot_loss_proj:1.535 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.450 (perp=6.870, rec=0.076), tot_loss_proj:1.532 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.440 (perp=6.870, rec=0.066), tot_loss_proj:1.538 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.437 (perp=6.870, rec=0.063), tot_loss_proj:1.532 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.438 (perp=6.870, rec=0.064), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.446 (perp=6.870, rec=0.072), tot_loss_proj:1.534 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.427 (perp=6.870, rec=0.053), tot_loss_proj:1.542 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.435 (perp=6.870, rec=0.061), tot_loss_proj:1.523 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.447 (perp=6.870, rec=0.073), tot_loss_proj:1.528 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.433 (perp=6.870, rec=0.059), tot_loss_proj:1.532 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.435 (perp=6.870, rec=0.061), tot_loss_proj:1.535 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.437 (perp=6.870, rec=0.063), tot_loss_proj:1.528 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.428 (perp=6.870, rec=0.054), tot_loss_proj:1.531 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.531 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.439 (perp=6.870, rec=0.065), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.439 (perp=6.870, rec=0.065), tot_loss_proj:1.531 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.538 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.424 (perp=6.870, rec=0.050), tot_loss_proj:1.530 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.441 (perp=6.870, rec=0.067), tot_loss_proj:1.533 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.441 (perp=6.870, rec=0.067), tot_loss_proj:1.534 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.438 (perp=6.870, rec=0.064), tot_loss_proj:1.531 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.432 (perp=6.870, rec=0.058), tot_loss_proj:1.538 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.436 (perp=6.870, rec=0.062), tot_loss_proj:1.533 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.870, rec=0.060), tot_loss_proj:1.528 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.870, rec=0.059), tot_loss_proj:1.536 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.431 (perp=6.870, rec=0.057), tot_loss_proj:1.537 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.441 (perp=6.870, rec=0.067), tot_loss_proj:1.530 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.742 | p: 82.292 | r: 83.416
rouge2     | fm: 46.708 | p: 46.566 | r: 46.942
rougeL     | fm: 73.512 | p: 73.167 | r: 74.100
rougeLsum  | fm: 73.678 | p: 73.295 | r: 74.313
r1fm+r2fm = 129.450

input #90 time: 0:10:42 | total time: 16:36:25


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
cosin similarity: 0.8990136992785539 normalized error: 0.5188314572632723
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 1.9041250003514372 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 1.8999366091857504 for ['[CLS]underscribe canton below messenger speaking been does [SEP]']
[Init] best rec loss: 1.5954688821981988 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 1.5917624947086813 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 1.3482904642193045 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 1.2967210809857457 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 1.2298997879524856 for ['[CLS] apollo lucia umpire skip gentleman grandmothergna line [SEP]']
[Init] best rec loss: 1.2210402727290313 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 1.1719690706085633 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 1.1711326342838921 for ['[CLS] unknown shelterpmentlipdern hard revolution pony [SEP]']
[Init] best perm rec loss: 1.169978699475498 for ['[CLS] shelterlip hardpment revolutiondern unknown pony [SEP]']
[Init] best perm rec loss: 1.169567129760284 for ['[CLS] hard unknown revolutionlip pony shelterdernpment [SEP]']
[Init] best perm rec loss: 1.1691435741392886 for ['[CLS]dern unknownpment shelter revolutionlip hard pony [SEP]']
[Init] best perm rec loss: 1.169060127300047 for ['[CLS] hard revolutionpment unknowndern shelter ponylip [SEP]']
[Init] best perm rec loss: 1.1668254708532384 for ['[CLS] hard unknown revolutionpment ponydernlip shelter [SEP]']
[Init] best perm rec loss: 1.166256492975525 for ['[CLS] unknowndernpment hardlip revolution shelter pony [SEP]']
[Init] best perm rec loss: 1.1646383607534663 for ['[CLS] hard revolutionpment unknowndern shelterlip pony [SEP]']
[Init] best perm rec loss: 1.1642952621803928 for ['[CLS]pment revolution hardlip shelter ponydern unknown [SEP]']
[Init] best perm rec loss: 1.163902118002278 for ['[CLS]dern revolutionlippment pony hard shelter unknown [SEP]']
[Init] best perm rec loss: 1.161932394655686 for ['[CLS]pmentlip revolution pony shelter harddern unknown [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.311 (perp=14.642, rec=0.383), tot_loss_proj:3.924 [t=0.25s]
prediction: ['[CLS] using ricky contrary colious oricondown ridiculous [SEP]']
[ 100/2000] tot_loss=2.757 (perp=12.313, rec=0.295), tot_loss_proj:3.339 [t=0.25s]
prediction: ['[CLS]il johnny ridiculous loco loco moredown ridiculous [SEP]']
[ 150/2000] tot_loss=2.219 (perp=9.807, rec=0.257), tot_loss_proj:3.291 [t=0.26s]
prediction: ['[CLS] but none loco loco loco no shit ridiculous [SEP]']
[ 200/2000] tot_loss=1.796 (perp=7.973, rec=0.201), tot_loss_proj:2.306 [t=0.25s]
prediction: ['[CLS] but no loco loco loco no more ridiculous [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.914 (perp=8.828, rec=0.148), tot_loss_proj:2.617 [t=0.26s]
prediction: ['[CLS] but no loco mu loco no more ridiculous [SEP]']
[ 300/2000] tot_loss=1.885 (perp=8.828, rec=0.120), tot_loss_proj:2.608 [t=0.25s]
prediction: ['[CLS] but no loco mu loco no more ridiculous [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.840 (perp=8.591, rec=0.122), tot_loss_proj:2.487 [t=0.25s]
prediction: ['[CLS] but no loco mu no loco more ridiculous [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.838 (perp=8.591, rec=0.119), tot_loss_proj:2.499 [t=0.26s]
prediction: ['[CLS] but no loco mu no loco more ridiculous [SEP]']
[ 450/2000] tot_loss=1.673 (perp=7.818, rec=0.110), tot_loss_proj:2.250 [t=0.24s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=7.818, rec=0.116), tot_loss_proj:2.257 [t=0.27s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=7.818, rec=0.112), tot_loss_proj:2.250 [t=0.25s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
[ 600/2000] tot_loss=1.668 (perp=7.818, rec=0.104), tot_loss_proj:2.255 [t=0.26s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.656 (perp=7.818, rec=0.092), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.664 (perp=7.818, rec=0.100), tot_loss_proj:2.253 [t=0.31s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
[ 750/2000] tot_loss=1.673 (perp=7.818, rec=0.109), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.660 (perp=7.818, rec=0.096), tot_loss_proj:2.249 [t=0.25s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.666 (perp=7.818, rec=0.103), tot_loss_proj:2.249 [t=0.27s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
[ 900/2000] tot_loss=1.675 (perp=7.818, rec=0.111), tot_loss_proj:2.248 [t=0.25s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.656 (perp=7.818, rec=0.092), tot_loss_proj:2.252 [t=0.24s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.661 (perp=7.818, rec=0.098), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
[1050/2000] tot_loss=1.655 (perp=7.818, rec=0.091), tot_loss_proj:2.250 [t=0.26s]
prediction: ['[CLS] but no locoy no loco more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.993 (perp=9.407, rec=0.111), tot_loss_proj:2.533 [t=0.25s]
prediction: ['[CLS] but no locoy geo loco more ridiculous [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.861 (perp=8.823, rec=0.096), tot_loss_proj:2.469 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
[1200/2000] tot_loss=1.864 (perp=8.823, rec=0.099), tot_loss_proj:2.458 [t=0.26s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=8.823, rec=0.094), tot_loss_proj:2.465 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.861 (perp=8.823, rec=0.096), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
[1350/2000] tot_loss=1.856 (perp=8.823, rec=0.092), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.868 (perp=8.823, rec=0.104), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.852 (perp=8.823, rec=0.087), tot_loss_proj:2.467 [t=0.24s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
[1500/2000] tot_loss=1.859 (perp=8.823, rec=0.094), tot_loss_proj:2.457 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.863 (perp=8.823, rec=0.098), tot_loss_proj:2.462 [t=0.29s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.854 (perp=8.823, rec=0.090), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
[1650/2000] tot_loss=1.860 (perp=8.823, rec=0.096), tot_loss_proj:2.464 [t=0.27s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.864 (perp=8.823, rec=0.099), tot_loss_proj:2.468 [t=0.24s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.860 (perp=8.823, rec=0.095), tot_loss_proj:2.466 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
[1800/2000] tot_loss=1.858 (perp=8.823, rec=0.093), tot_loss_proj:2.465 [t=0.26s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.862 (perp=8.823, rec=0.098), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.864 (perp=8.823, rec=0.100), tot_loss_proj:2.463 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
[1950/2000] tot_loss=1.875 (perp=8.823, rec=0.111), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.865 (perp=8.823, rec=0.100), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] but no locoy loco geo more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] but no locoy loco geo more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 82.688 | p: 82.180 | r: 83.416
rouge2     | fm: 46.725 | p: 46.598 | r: 47.008
rougeL     | fm: 73.608 | p: 73.144 | r: 74.237
rougeLsum  | fm: 73.593 | p: 73.218 | r: 74.278
r1fm+r2fm = 129.414

input #91 time: 0:10:44 | total time: 16:47:10


Running input #92 of 100.
reference: 
========================
deceit 
========================
cosin similarity: -0.8620338859357262 normalized error: 1.7638292571068026
cosin similarity: 0.8620338859357262 normalized error: 0.5034061874714496
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 1.8337715611711476 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 1.730499774578491 for ['[CLS]orus lead [SEP]']
[Init] best rec loss: 1.5963739168440254 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 1.4626473030630893 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 1.3495660407719359 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 1.3472513818375165 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.837 (perp=12.265, rec=0.384), tot_loss_proj:3.380 [t=0.24s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=2.994 (perp=13.691, rec=0.256), tot_loss_proj:4.377 [t=0.25s]
prediction: ['[CLS]eiteit [SEP]']
[ 150/2000] tot_loss=2.959 (perp=13.691, rec=0.221), tot_loss_proj:4.371 [t=0.26s]
prediction: ['[CLS]eiteit [SEP]']
[ 200/2000] tot_loss=2.926 (perp=13.691, rec=0.188), tot_loss_proj:4.355 [t=0.25s]
prediction: ['[CLS]eiteit [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.258 (perp=15.501, rec=0.158), tot_loss_proj:3.738 [t=0.25s]
prediction: ['[CLS]eit dec [SEP]']
[ 300/2000] tot_loss=3.267 (perp=15.501, rec=0.167), tot_loss_proj:3.738 [t=0.28s]
prediction: ['[CLS]eit dec [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.667 (perp=7.647, rec=0.137), tot_loss_proj:1.860 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.676 (perp=7.647, rec=0.146), tot_loss_proj:1.852 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.683 (perp=7.647, rec=0.153), tot_loss_proj:1.851 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.670 (perp=7.647, rec=0.140), tot_loss_proj:1.854 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.663 (perp=7.647, rec=0.134), tot_loss_proj:1.849 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.674 (perp=7.647, rec=0.145), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.681 (perp=7.647, rec=0.152), tot_loss_proj:1.864 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.673 (perp=7.647, rec=0.143), tot_loss_proj:1.861 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.686 (perp=7.647, rec=0.156), tot_loss_proj:1.852 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.675 (perp=7.647, rec=0.146), tot_loss_proj:1.862 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=7.647, rec=0.157), tot_loss_proj:1.849 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.673 (perp=7.647, rec=0.144), tot_loss_proj:1.868 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.683 (perp=7.647, rec=0.154), tot_loss_proj:1.865 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.659 (perp=7.647, rec=0.130), tot_loss_proj:1.857 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.675 (perp=7.647, rec=0.146), tot_loss_proj:1.840 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.679 (perp=7.647, rec=0.149), tot_loss_proj:1.850 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.673 (perp=7.647, rec=0.143), tot_loss_proj:1.864 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.669 (perp=7.647, rec=0.139), tot_loss_proj:1.853 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.676 (perp=7.647, rec=0.146), tot_loss_proj:1.854 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=7.647, rec=0.149), tot_loss_proj:1.851 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.683 (perp=7.647, rec=0.154), tot_loss_proj:1.848 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=7.647, rec=0.141), tot_loss_proj:1.860 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.667 (perp=7.647, rec=0.138), tot_loss_proj:1.860 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.668 (perp=7.647, rec=0.139), tot_loss_proj:1.853 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.675 (perp=7.647, rec=0.145), tot_loss_proj:1.846 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=7.647, rec=0.140), tot_loss_proj:1.856 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.669 (perp=7.647, rec=0.139), tot_loss_proj:1.864 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.670 (perp=7.647, rec=0.141), tot_loss_proj:1.854 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.677 (perp=7.647, rec=0.148), tot_loss_proj:1.854 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.677 (perp=7.647, rec=0.148), tot_loss_proj:1.844 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.669 (perp=7.647, rec=0.139), tot_loss_proj:1.868 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.670 (perp=7.647, rec=0.141), tot_loss_proj:1.847 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.657 (perp=7.647, rec=0.128), tot_loss_proj:1.874 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.674 (perp=7.647, rec=0.144), tot_loss_proj:1.861 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.895 | p: 82.411 | r: 83.678
rouge2     | fm: 47.183 | p: 47.025 | r: 47.486
rougeL     | fm: 73.871 | p: 73.466 | r: 74.592
rougeLsum  | fm: 73.969 | p: 73.466 | r: 74.637
r1fm+r2fm = 130.077

input #92 time: 0:09:13 | total time: 16:56:23


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
cosin similarity: 0.9530630718900329 normalized error: 0.41506647791207635
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.901175936331111 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 1.8608722882340878 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 1.7548238433512717 for ['[CLS] move needing checkpoint into " brothers bag [SEP]']
[Init] best rec loss: 1.7053383520282717 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 1.6883677178197145 for ['[CLS] move parade platform playable want strong capital [SEP]']
[Init] best rec loss: 1.3498080882819985 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 1.3246318518823095 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 1.3176015690731018 for ['[CLS] furtherrac premiership colby madonna jeremy [CLS] [SEP]']
[Init] best perm rec loss: 1.3062984369355521 for ['[CLS] further madonnarac colby jeremy premiership [CLS] [SEP]']
[Init] best perm rec loss: 1.3061504548056482 for ['[CLS]rac colby madonna further jeremy premiership [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.002 (perp=12.968, rec=0.409), tot_loss_proj:3.205 [t=0.20s]
prediction: ['[CLS] funnyly success understanding rural musical funny [SEP]']
[ 100/2000] tot_loss=2.689 (perp=11.902, rec=0.308), tot_loss_proj:2.886 [t=0.20s]
prediction: ['[CLS] often understanding way understanding often musical funny [SEP]']
[ 150/2000] tot_loss=2.436 (perp=10.868, rec=0.263), tot_loss_proj:2.685 [t=0.20s]
prediction: ['[CLS] often understanding way understanding often ( funny [SEP]']
[ 200/2000] tot_loss=2.406 (perp=10.868, rec=0.233), tot_loss_proj:2.676 [t=0.20s]
prediction: ['[CLS] often understanding way understanding often ( funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.135 (perp=9.560, rec=0.223), tot_loss_proj:2.424 [t=0.20s]
prediction: ['[CLS] often understanding way ( often understanding funny [SEP]']
[ 300/2000] tot_loss=2.105 (perp=9.560, rec=0.193), tot_loss_proj:2.428 [t=0.20s]
prediction: ['[CLS] often understanding way ( often understanding funny [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.301 (perp=10.598, rec=0.182), tot_loss_proj:2.607 [t=0.20s]
prediction: ['[CLS] understanding understanding way its often often funny [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.383 (perp=11.085, rec=0.166), tot_loss_proj:2.912 [t=0.20s]
prediction: ['[CLS] understanding its way its often phylogenetic funny [SEP]']
[ 450/2000] tot_loss=2.373 (perp=11.085, rec=0.156), tot_loss_proj:2.915 [t=0.20s]
prediction: ['[CLS] understanding its way its often phylogenetic funny [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.122 (perp=9.841, rec=0.154), tot_loss_proj:2.660 [t=0.20s]
prediction: ['[CLS] understanding its way its often funny phylogenetic [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.919 (perp=8.793, rec=0.160), tot_loss_proj:2.322 [t=0.20s]
prediction: ['[CLS] understanding its often funnytypic way, [SEP]']
[ 600/2000] tot_loss=1.902 (perp=8.793, rec=0.144), tot_loss_proj:2.326 [t=0.20s]
prediction: ['[CLS] understanding its often funnytypic way, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.827 (perp=8.394, rec=0.148), tot_loss_proj:2.296 [t=0.20s]
prediction: ['[CLS] understanding its often funny waytypic, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.811 (perp=8.394, rec=0.132), tot_loss_proj:2.295 [t=0.20s]
prediction: ['[CLS] understanding its often funny waytypic, [SEP]']
[ 750/2000] tot_loss=1.835 (perp=8.522, rec=0.131), tot_loss_proj:2.268 [t=0.20s]
prediction: ['[CLS] understanding its often funny way considerable, [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.712 (perp=7.879, rec=0.136), tot_loss_proj:2.105 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, considerable [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.815 (perp=8.394, rec=0.137), tot_loss_proj:2.298 [t=0.20s]
prediction: ['[CLS] understanding its often funny waytypic, [SEP]']
[ 900/2000] tot_loss=1.819 (perp=8.394, rec=0.140), tot_loss_proj:2.297 [t=0.20s]
prediction: ['[CLS] understanding its often funny waytypic, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.821 (perp=8.394, rec=0.142), tot_loss_proj:2.304 [t=0.20s]
prediction: ['[CLS] understanding its often funny waytypic, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.904 (perp=8.879, rec=0.128), tot_loss_proj:2.403 [t=0.20s]
prediction: ['[CLS] understanding its often funny way carly, [SEP]']
[1050/2000] tot_loss=1.902 (perp=8.879, rec=0.126), tot_loss_proj:2.413 [t=0.20s]
prediction: ['[CLS] understanding its often funny way carly, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.738 (perp=8.054, rec=0.127), tot_loss_proj:2.216 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.739 (perp=8.054, rec=0.129), tot_loss_proj:2.221 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
[1200/2000] tot_loss=1.740 (perp=8.054, rec=0.130), tot_loss_proj:2.226 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.737 (perp=8.054, rec=0.127), tot_loss_proj:2.225 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.741 (perp=8.054, rec=0.130), tot_loss_proj:2.217 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
[1350/2000] tot_loss=1.746 (perp=8.054, rec=0.135), tot_loss_proj:2.226 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.735 (perp=8.054, rec=0.125), tot_loss_proj:2.224 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.744 (perp=8.054, rec=0.133), tot_loss_proj:2.224 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
[1500/2000] tot_loss=1.745 (perp=8.054, rec=0.134), tot_loss_proj:2.220 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=8.054, rec=0.119), tot_loss_proj:2.219 [t=0.20s]
prediction: ['[CLS] understanding its often funny way, carly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.824 (perp=8.461, rec=0.131), tot_loss_proj:2.337 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
[1650/2000] tot_loss=1.823 (perp=8.461, rec=0.131), tot_loss_proj:2.341 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
Attempt swap
[1700/2000] tot_loss=1.818 (perp=8.461, rec=0.126), tot_loss_proj:2.335 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
Attempt swap
[1750/2000] tot_loss=1.820 (perp=8.461, rec=0.128), tot_loss_proj:2.335 [t=0.21s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
[1800/2000] tot_loss=1.810 (perp=8.461, rec=0.118), tot_loss_proj:2.334 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
Attempt swap
[1850/2000] tot_loss=1.823 (perp=8.461, rec=0.131), tot_loss_proj:2.338 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
Attempt swap
[1900/2000] tot_loss=1.816 (perp=8.461, rec=0.124), tot_loss_proj:2.334 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
[1950/2000] tot_loss=1.815 (perp=8.461, rec=0.123), tot_loss_proj:2.335 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
Attempt swap
[2000/2000] tot_loss=1.820 (perp=8.461, rec=0.127), tot_loss_proj:2.336 [t=0.20s]
prediction: ['[CLS] understanding its often funny way,₊ [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding its often funny way,₊ [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 100.000 | r: 87.500
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 83.062 | p: 82.654 | r: 83.671
rouge2     | fm: 47.286 | p: 47.046 | r: 47.492
rougeL     | fm: 73.828 | p: 73.527 | r: 74.494
rougeLsum  | fm: 73.972 | p: 73.547 | r: 74.595
r1fm+r2fm = 130.348

input #93 time: 0:08:03 | total time: 17:04:26


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
cosin similarity: -0.9384349337768554 normalized error: 1.8320128368282338
cosin similarity: 0.9384349337768555 normalized error: 0.44216675279548323
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 1.8953639150566466 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 1.880547770755494 for ['[CLS] of pro wanted scientists rayon housing chart close earlier anniversary ni [SEP]']
[Init] best rec loss: 1.8007740421943854 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 1.780231116984333 for ['[CLS]ser straight alligator inches subject never splashed pony des withancy [SEP]']
[Init] best rec loss: 1.5176775456038603 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 1.4407265283193462 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best perm rec loss: 1.4401216839258015 for ['[CLS] slowed spirit mirpour bow badercedebleiter matters [SEP]']
[Init] best perm rec loss: 1.4392160267462948 for ['[CLS]pourercede baditerble bow slowed spirit mir matters [SEP]']
[Init] best perm rec loss: 1.436423397548413 for ['[CLS] slowed bad bowiter matters mirblepourcede spiriter [SEP]']
[Init] best perm rec loss: 1.429745352740744 for ['[CLS]iter slowed bowerpour mir bad mattersblecede spirit [SEP]']
[Init] best perm rec loss: 1.4291336165603195 for ['[CLS]cede boweriterble mir spirit matters slowed badpour [SEP]']
[Init] best perm rec loss: 1.4274322572955003 for ['[CLS] spirit matterscede bower slowed mirbleiter badpour [SEP]']
[Init] best perm rec loss: 1.4269980803312623 for ['[CLS]iter spiritcedeer slowedpour mattersble mir bow bad [SEP]']
[Init] best perm rec loss: 1.4190153138167863 for ['[CLS]iterer matters bowcedeble mirpour bad spirit slowed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.917 (perp=12.265, rec=0.464), tot_loss_proj:3.658 [t=0.20s]
prediction: ["[CLS] find neither as neithersome about'dominican poll turned washed [SEP]"]
[ 100/2000] tot_loss=2.507 (perp=10.845, rec=0.338), tot_loss_proj:3.688 [t=0.20s]
prediction: ["[CLS] times neither'neither home particularly'aground voters turnedsław [SEP]"]
[ 150/2000] tot_loss=2.784 (perp=12.439, rec=0.297), tot_loss_proj:3.140 [t=0.20s]
prediction: ["[CLS] cape nor'neitherp particularly a funny nor norsław [SEP]"]
[ 200/2000] tot_loss=2.270 (perp=10.131, rec=0.244), tot_loss_proj:2.795 [t=0.20s]
prediction: ["[CLS] cape nor'neither past terribly nor funny nor nor tired [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.144 (perp=9.575, rec=0.229), tot_loss_proj:2.579 [t=0.20s]
prediction: ["[CLS] cape terribly'neither past nor a funny prospect nor terribly [SEP]"]
[ 300/2000] tot_loss=2.153 (perp=9.798, rec=0.193), tot_loss_proj:2.764 [t=0.20s]
prediction: ["[CLS] cape terribly'neither up nor a funnyr nor terribly [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.960 (perp=8.867, rec=0.187), tot_loss_proj:2.569 [t=0.21s]
prediction: ["[CLS] terribly'neither up cape nor a funnyr nor terribly [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.797 (perp=7.879, rec=0.221), tot_loss_proj:2.179 [t=0.20s]
prediction: ["[CLS] terribly'neither up caper nor a funny nor terribly [SEP]"]
[ 450/2000] tot_loss=1.752 (perp=7.952, rec=0.162), tot_loss_proj:2.230 [t=0.20s]
prediction: ["[CLS] terribly'neither my caper nor a funny nor terribly [SEP]"]
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.643 (perp=7.436, rec=0.156), tot_loss_proj:2.105 [t=0.20s]
prediction: ["[CLS] terribly'neither my a caper nor funny nor terribly [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.768 (perp=8.062, rec=0.156), tot_loss_proj:2.321 [t=0.20s]
prediction: ['[CLS] s neither rhyme a caper nor terribly funny nor terribly [SEP]']
[ 600/2000] tot_loss=1.749 (perp=8.062, rec=0.136), tot_loss_proj:2.328 [t=0.20s]
prediction: ['[CLS] s neither rhyme a caper nor terribly funny nor terribly [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.634 (perp=7.446, rec=0.145), tot_loss_proj:2.209 [t=0.20s]
prediction: ['[CLS] s neither rhyme a caper nor terribly nor terribly funny [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.742 (perp=8.060, rec=0.130), tot_loss_proj:2.299 [t=0.20s]
prediction: ['[CLS] s neither a rhyme caper that extremely nor terribly funny [SEP]']
[ 750/2000] tot_loss=1.744 (perp=8.060, rec=0.132), tot_loss_proj:2.289 [t=0.20s]
prediction: ['[CLS] s neither a rhyme caper that extremely nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.627 (perp=7.491, rec=0.128), tot_loss_proj:2.017 [t=0.20s]
prediction: ['[CLS] s that a rhyme caper neither extremely nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.609 (perp=7.412, rec=0.127), tot_loss_proj:2.052 [t=0.20s]
prediction: ['[CLS] s that rhyme a caper neither extremely nor terribly funny [SEP]']
[ 900/2000] tot_loss=1.612 (perp=7.412, rec=0.130), tot_loss_proj:2.038 [t=0.20s]
prediction: ['[CLS] s that rhyme a caper neither extremely nor terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=7.295, rec=0.117), tot_loss_proj:2.062 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither extremely nor terribly funny [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.577 (perp=7.268, rec=0.123), tot_loss_proj:2.013 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither extremely nor terribly funny [SEP]']
[1050/2000] tot_loss=1.569 (perp=7.268, rec=0.116), tot_loss_proj:2.027 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither extremely nor terribly funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.573 (perp=7.268, rec=0.119), tot_loss_proj:2.021 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither extremely nor terribly funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.573 (perp=7.268, rec=0.119), tot_loss_proj:2.025 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither extremely nor terribly funny [SEP]']
[1200/2000] tot_loss=1.643 (perp=7.616, rec=0.120), tot_loss_proj:2.047 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.642 (perp=7.616, rec=0.119), tot_loss_proj:2.040 [t=0.21s]
prediction: ['[CLS] that s shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.642 (perp=7.616, rec=0.119), tot_loss_proj:2.050 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither original nor terribly funny [SEP]']
[1350/2000] tot_loss=1.641 (perp=7.616, rec=0.118), tot_loss_proj:2.048 [t=0.20s]
prediction: ['[CLS] that s shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.627 (perp=7.546, rec=0.118), tot_loss_proj:2.068 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.625 (perp=7.546, rec=0.115), tot_loss_proj:2.071 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
[1500/2000] tot_loss=1.618 (perp=7.546, rec=0.109), tot_loss_proj:2.067 [t=0.21s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.620 (perp=7.546, rec=0.111), tot_loss_proj:2.063 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.619 (perp=7.546, rec=0.110), tot_loss_proj:2.070 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
[1650/2000] tot_loss=1.625 (perp=7.546, rec=0.116), tot_loss_proj:2.066 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.619 (perp=7.546, rec=0.110), tot_loss_proj:2.067 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.618 (perp=7.546, rec=0.109), tot_loss_proj:2.070 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
[1800/2000] tot_loss=1.611 (perp=7.546, rec=0.102), tot_loss_proj:2.062 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.627 (perp=7.546, rec=0.118), tot_loss_proj:2.068 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.622 (perp=7.546, rec=0.112), tot_loss_proj:2.064 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
[1950/2000] tot_loss=1.619 (perp=7.546, rec=0.110), tot_loss_proj:2.060 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.622 (perp=7.546, rec=0.113), tot_loss_proj:2.065 [t=0.20s]
prediction: ['[CLS] s that shoe a caper neither original nor terribly funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that s shoe a caper neither original nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 66.667 | p: 63.636 | r: 70.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 162.319

[Aggregate metrics]:
rouge1     | fm: 83.098 | p: 82.682 | r: 83.838
rouge2     | fm: 47.526 | p: 47.344 | r: 47.781
rougeL     | fm: 73.919 | p: 73.500 | r: 74.523
rougeLsum  | fm: 73.980 | p: 73.593 | r: 74.698
r1fm+r2fm = 130.624

input #94 time: 0:08:03 | total time: 17:12:29


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
cosin similarity: -0.8715510290048321 normalized error: 1.802807382070858
cosin similarity: 0.871551029004832 normalized error: 0.48358451395924695
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.893139441373553 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.891437821788051 for ['[CLS] bree theological teaching maybe backed past starvinglusion pigs twitcharable badic flower able [SEP]']
[Init] best rec loss: 1.8120346494190627 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 1.7168066056322306 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 1.6755339575279669 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 1.6092498138679499 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 1.595403331924985 for ['[CLS] fire some phillip margin khz number grace discipline formula plains when secretarygrave duke hell [SEP]']
[Init] best rec loss: 1.5221146913554877 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 1.3258105114943526 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 1.3213218630734704 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 1.3201221454876384 for ['[CLS] cut pressure ]ے wire complete sister block monty hanging damp tech trailer privatenne [SEP]']
[Init] best perm rec loss: 1.3155356412399923 for ['[CLS] wire hanging damp pressure trailer block private sisterےnne tech complete ] cut monty [SEP]']
[Init] best perm rec loss: 1.315242588001302 for ['[CLS] cut block private tech wire hanging pressure trailer completenne monty damp ] sisterے [SEP]']
[Init] best perm rec loss: 1.3149565322513064 for ['[CLS] ] tech damp private cut completenneے trailer wire hanging block monty sister pressure [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.053 (perp=13.394, rec=0.375), tot_loss_proj:3.712 [t=0.20s]
prediction: ['[CLS] aground suspiciously an closet dump - bid potentially unsuccessful operated mud such gone internal convention [SEP]']
[ 100/2000] tot_loss=3.056 (perp=13.838, rec=0.288), tot_loss_proj:3.551 [t=0.21s]
prediction: ['[CLS] hopeless mysteriously an middle housing - passwordsi hopeless operated mudis hopelessdle decree [SEP]']
[ 150/2000] tot_loss=2.794 (perp=12.796, rec=0.235), tot_loss_proj:3.346 [t=0.21s]
prediction: ['[CLS] hopeless mysteriously an middledle becamedled becomes hopeless coat muddle hopelessdle cbs [SEP]']
[ 200/2000] tot_loss=2.528 (perp=11.622, rec=0.204), tot_loss_proj:3.076 [t=0.21s]
prediction: ['[CLS] hopeless ( a industrialdle becamedled becomes hopeless clothing muddle hopelessdle story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.929 (perp=13.674, rec=0.194), tot_loss_proj:3.457 [t=0.21s]
prediction: ['[CLS] hopelesscourt adleddlecky industrial becomes hopeless clothing muddlefying coat story [SEP]']
[ 300/2000] tot_loss=2.416 (perp=11.191, rec=0.178), tot_loss_proj:3.021 [t=0.21s]
prediction: ['[CLS] becomes ( adleddle became regions becomes hopeless clothing muddlefying coat story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.417 (perp=11.246, rec=0.168), tot_loss_proj:3.029 [t=0.21s]
prediction: ["[CLS] ( becomes adleddle'sat becomes hopeless story muddlefying coat story [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.442 (perp=11.401, rec=0.162), tot_loss_proj:3.109 [t=0.21s]
prediction: ["[CLS] ( becomes adleddle 'udeau becomes hopeless story muddlefyingsat story [SEP]"]
[ 450/2000] tot_loss=2.359 (perp=11.037, rec=0.152), tot_loss_proj:3.022 [t=0.21s]
prediction: ["[CLS] ( aftermath a becomesdle'coat becomes hopeless story muddlefyingsat story [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.992 (perp=9.249, rec=0.143), tot_loss_proj:2.655 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) coat becomes hopeless a muddlefyingsat story [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.907 (perp=8.859, rec=0.136), tot_loss_proj:2.686 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes a muddlefyingsat story [SEP]']
[ 600/2000] tot_loss=1.899 (perp=8.859, rec=0.127), tot_loss_proj:2.682 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes a muddlefyingsat story [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.027 (perp=9.513, rec=0.125), tot_loss_proj:2.745 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes a mudissatfying story [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.895 (perp=8.927, rec=0.110), tot_loss_proj:2.740 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes asatis mudfying story [SEP]']
[ 750/2000] tot_loss=1.903 (perp=8.927, rec=0.118), tot_loss_proj:2.741 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes asatis mudfying story [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.804 (perp=8.405, rec=0.123), tot_loss_proj:2.632 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes asatisfying mud story [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.801 (perp=8.405, rec=0.120), tot_loss_proj:2.631 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes asatisfying mud story [SEP]']
[ 900/2000] tot_loss=1.811 (perp=8.405, rec=0.130), tot_loss_proj:2.626 [t=0.21s]
prediction: ['[CLS] ( aftermath story (dle ) hopeless coat becomes asatisfying mud story [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.644 (perp=7.627, rec=0.118), tot_loss_proj:2.201 [t=0.23s]
prediction: ['[CLS] ( aftermath story ( story ) hopeless coat becomes asatisfying muddle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.731 (perp=8.043, rec=0.123), tot_loss_proj:2.249 [t=0.27s]
prediction: ['[CLS] ( possibly story ( story ) hopeless coat becomes asatisfying muddle [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.043, rec=0.114), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] ( possibly story ( story ) hopeless coat becomes asatisfying muddle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.723 (perp=8.043, rec=0.115), tot_loss_proj:2.241 [t=0.27s]
prediction: ['[CLS] ( possibly story ( story ) hopeless coat becomes asatisfying muddle [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.669 (perp=7.773, rec=0.114), tot_loss_proj:2.207 [t=0.25s]
prediction: ['[CLS] ( coat story ( story ) hopeless aftermath becomes asatisfying muddle [SEP]']
[1200/2000] tot_loss=1.658 (perp=7.684, rec=0.122), tot_loss_proj:2.302 [t=0.29s]
prediction: ['[CLS] ( coat story ( story ) hopeless possibly becomes asatisfying muddle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.650 (perp=7.684, rec=0.114), tot_loss_proj:2.293 [t=0.25s]
prediction: ['[CLS] ( coat story ( story ) hopeless possibly becomes asatisfying muddle [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.758 (perp=8.163, rec=0.126), tot_loss_proj:2.310 [t=0.25s]
prediction: ['[CLS] ( coat story ( story ) hopeless becomes a aftermathsatisfying muddle [SEP]']
[1350/2000] tot_loss=1.907 (perp=8.985, rec=0.110), tot_loss_proj:2.472 [t=0.27s]
prediction: ['[CLS] ( coat denis ( story ) hopeless becomes, possiblysatisfying muddle [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.864 (perp=8.674, rec=0.129), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS] ( coat becomes story ( story ( hopeless, possiblysatisfying muddle [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.823 (perp=8.474, rec=0.128), tot_loss_proj:2.418 [t=0.25s]
prediction: ['[CLS] ( coat ( story ( story becomes hopeless, possiblysatisfying muddle [SEP]']
[1500/2000] tot_loss=1.768 (perp=8.268, rec=0.114), tot_loss_proj:2.385 [t=0.25s]
prediction: ['[CLS] (八 ( story ( story becomes hopeless, possiblysatisfying muddle [SEP]']
Attempt swap
Put prefix at the end
[1550/2000] tot_loss=1.729 (perp=8.023, rec=0.125), tot_loss_proj:2.357 [t=0.28s]
prediction: ['[CLS]八 ) denis ( story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.670 (perp=7.724, rec=0.125), tot_loss_proj:2.131 [t=0.25s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
[1650/2000] tot_loss=1.657 (perp=7.724, rec=0.113), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Attempt swap
[1700/2000] tot_loss=1.656 (perp=7.724, rec=0.112), tot_loss_proj:2.129 [t=0.27s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Attempt swap
[1750/2000] tot_loss=1.667 (perp=7.724, rec=0.122), tot_loss_proj:2.121 [t=0.29s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
[1800/2000] tot_loss=1.660 (perp=7.724, rec=0.116), tot_loss_proj:2.125 [t=0.27s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Attempt swap
[1850/2000] tot_loss=1.663 (perp=7.724, rec=0.118), tot_loss_proj:2.131 [t=0.26s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Attempt swap
[1900/2000] tot_loss=1.657 (perp=7.724, rec=0.113), tot_loss_proj:2.127 [t=0.25s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
[1950/2000] tot_loss=1.668 (perp=7.724, rec=0.123), tot_loss_proj:2.135 [t=0.27s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Attempt swap
[2000/2000] tot_loss=1.658 (perp=7.724, rec=0.114), tot_loss_proj:2.126 [t=0.26s]
prediction: ['[CLS] coat ( denis ) story becomes hopeless, possiblysatisfying muddle ( [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( possibly story ( story ) hopeless coat becomes asatisfying muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.158 | p: 60.000 | r: 66.667
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 74.923

[Aggregate metrics]:
rouge1     | fm: 82.940 | p: 82.412 | r: 83.590
rouge2     | fm: 47.140 | p: 47.016 | r: 47.422
rougeL     | fm: 73.798 | p: 73.352 | r: 74.432
rougeLsum  | fm: 73.748 | p: 73.279 | r: 74.459
r1fm+r2fm = 130.080

input #95 time: 0:09:37 | total time: 17:22:07


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
cosin similarity: -0.873860002866591 normalized error: 1.7535049075060742
cosin similarity: 0.8738600028665912 normalized error: 0.5026238399237948
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 1.7973857156996118 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 1.7651670449262973 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 1.723171672980326 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 1.7181945172971402 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 1.70851450757539 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 1.6553843450314083 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 1.6504389791125684 for ['[CLS] viva promise [ fear caution locked pity between pathhing hour small reasoning blur mixture [SEP]']
[Init] best rec loss: 1.6180148976905318 for ['[CLS] daughter fivb harlow district idea momentum absislavuve achievement motorcycle views quietdiment from [SEP]']
[Init] best rec loss: 1.5396640918804037 for ['[CLS] hand hopefullysas super profit laundry readings context places liaison mollusk talents rest feature date [SEP]']
[Init] best perm rec loss: 1.5325270123320154 for ['[CLS] profitsas hand rest hopefully places laundry mollusk date liaison feature talents readings context super [SEP]']
[Init] best perm rec loss: 1.5297288388170243 for ['[CLS] contextsas talents places readings liaison profit laundry rest date hand super feature hopefully mollusk [SEP]']
[Init] best perm rec loss: 1.5292351661407426 for ['[CLS] profit rest super date hand liaison places feature talents laundry context hopefully mollusk readingssas [SEP]']
[Init] best perm rec loss: 1.5250981335494473 for ['[CLS] context date laundry rest profit places super mollusk feature handsas readings hopefully liaison talents [SEP]']
[Init] best perm rec loss: 1.5242015997932004 for ['[CLS] hopefully date feature mollusk context places liaison profit super rest laundry talents readings handsas [SEP]']
[Init] best perm rec loss: 1.523749350572039 for ['[CLS] liaison profit laundry hand places rest context feature date supersas mollusk hopefully talents readings [SEP]']
[Init] best perm rec loss: 1.5208485550828756 for ['[CLS] context readings mollusk hand super rest date feature profit places laundry hopefully liaisonsas talents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.181 (perp=13.491, rec=0.483), tot_loss_proj:4.197 [t=0.28s]
prediction: ['[CLS]ion canton expanse province growth keith althoughport aroundisation peninsula demand touch sophia humanitarian [SEP]']
[ 100/2000] tot_loss=2.781 (perp=12.023, rec=0.376), tot_loss_proj:3.856 [t=0.25s]
prediction: ['[CLS] tropical... force immediately himselfaq although her intoitarian shorter people crowd into humanitarian [SEP]']
[ 150/2000] tot_loss=2.470 (perp=10.841, rec=0.302), tot_loss_proj:3.200 [t=0.26s]
prediction: ['[CLS] something... force situations himself from for her into onto lesser women worth into character [SEP]']
[ 200/2000] tot_loss=2.466 (perp=10.928, rec=0.280), tot_loss_proj:3.729 [t=0.27s]
prediction: ['[CLS] something... force situations himselfease into her into someone lesser women things into carmine [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.472 (perp=10.923, rec=0.287), tot_loss_proj:3.740 [t=0.25s]
prediction: ['[CLS] something sprint force situations himselfease into her into someone lesser for people men situations [SEP]']
[ 300/2000] tot_loss=2.300 (perp=10.329, rec=0.234), tot_loss_proj:3.394 [t=0.25s]
prediction: ['[CLS] something those force situations himself which into her into someone lesser make people men cover [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.250 (perp=10.147, rec=0.221), tot_loss_proj:3.202 [t=0.27s]
prediction: ['[CLS] something himself william force situations himself into and into someone lesser make people men cover [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.914 (perp=8.529, rec=0.209), tot_loss_proj:2.776 [t=0.26s]
prediction: ['[CLS] himself himself soon force situations himself into and into make lesser men make for cover [SEP]']
[ 450/2000] tot_loss=2.001 (perp=9.066, rec=0.188), tot_loss_proj:3.020 [t=0.25s]
prediction: ['[CLS] himself himself soon force situations on into and on for lesser men make run cover [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.089 (perp=9.578, rec=0.174), tot_loss_proj:3.389 [t=0.27s]
prediction: ['[CLS] himself situations soon force initially on into and on for lesser men make run cover [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.909 (perp=8.652, rec=0.179), tot_loss_proj:3.007 [t=0.26s]
prediction: ['[CLS] himself situations soon force himself on into and on for lesser men make run cover [SEP]']
[ 600/2000] tot_loss=1.874 (perp=8.532, rec=0.168), tot_loss_proj:2.978 [t=0.26s]
prediction: ['[CLS] now situations soon force himself on into and on for lesser men make run cover [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.735 (perp=7.874, rec=0.161), tot_loss_proj:2.902 [t=0.25s]
prediction: ['[CLS] now situations soon force himself on for and on for lesser make men run cover [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.087 (perp=9.670, rec=0.153), tot_loss_proj:3.241 [t=0.25s]
prediction: ['[CLS] emotions situations soon force himself onpro and on for lesser make men run cover [SEP]']
[ 750/2000] tot_loss=2.247 (perp=10.482, rec=0.151), tot_loss_proj:3.593 [t=0.27s]
prediction: ['[CLS] them situations trees force himself onpro and on for lesser make men run cover [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.157 (perp=9.928, rec=0.172), tot_loss_proj:3.433 [t=0.25s]
prediction: ['[CLS] science situations for force himself on soon for on toward lesser make men run cover [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.983 (perp=9.135, rec=0.156), tot_loss_proj:3.132 [t=0.26s]
prediction: ['[CLS] emotion situations for force himself on for soon on which lesser make men run cover [SEP]']
[ 900/2000] tot_loss=1.831 (perp=8.404, rec=0.150), tot_loss_proj:3.118 [t=0.25s]
prediction: ['[CLS] emotion situations for force himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.811 (perp=8.311, rec=0.149), tot_loss_proj:2.791 [t=0.27s]
prediction: ['[CLS] emotion situations force for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.748 (perp=7.981, rec=0.152), tot_loss_proj:2.884 [t=0.27s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
[1050/2000] tot_loss=1.741 (perp=7.981, rec=0.144), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1100/2000] tot_loss=1.740 (perp=7.981, rec=0.144), tot_loss_proj:2.888 [t=0.27s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1150/2000] tot_loss=1.747 (perp=7.981, rec=0.151), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
[1200/2000] tot_loss=1.742 (perp=7.981, rec=0.146), tot_loss_proj:2.880 [t=0.27s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1250/2000] tot_loss=1.741 (perp=7.981, rec=0.145), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1300/2000] tot_loss=1.737 (perp=7.981, rec=0.140), tot_loss_proj:2.883 [t=0.27s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
[1350/2000] tot_loss=1.738 (perp=7.981, rec=0.142), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1400/2000] tot_loss=1.739 (perp=7.981, rec=0.143), tot_loss_proj:2.880 [t=0.26s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1450/2000] tot_loss=1.735 (perp=7.981, rec=0.139), tot_loss_proj:2.883 [t=0.25s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
[1500/2000] tot_loss=1.743 (perp=7.981, rec=0.146), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=7.981, rec=0.134), tot_loss_proj:2.881 [t=0.27s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1600/2000] tot_loss=1.738 (perp=7.981, rec=0.142), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] emotion force situations for himself on and soon on which lesser make men run cover [SEP]']
[1650/2000] tot_loss=1.787 (perp=8.197, rec=0.148), tot_loss_proj:2.710 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1700/2000] tot_loss=1.786 (perp=8.197, rec=0.147), tot_loss_proj:2.715 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1750/2000] tot_loss=1.781 (perp=8.197, rec=0.142), tot_loss_proj:2.710 [t=0.25s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
[1800/2000] tot_loss=1.783 (perp=8.197, rec=0.144), tot_loss_proj:2.715 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1850/2000] tot_loss=1.788 (perp=8.197, rec=0.148), tot_loss_proj:2.708 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[1900/2000] tot_loss=1.785 (perp=8.197, rec=0.146), tot_loss_proj:2.708 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
[1950/2000] tot_loss=1.778 (perp=8.197, rec=0.139), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
Attempt swap
[2000/2000] tot_loss=1.771 (perp=8.197, rec=0.132), tot_loss_proj:2.715 [t=0.26s]
prediction: ['[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] emotions force situations for himself on and soon on which lesser make men run cover [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 95.221

[Aggregate metrics]:
rouge1     | fm: 82.804 | p: 82.358 | r: 83.515
rouge2     | fm: 46.804 | p: 46.647 | r: 47.089
rougeL     | fm: 73.588 | p: 73.204 | r: 74.320
rougeLsum  | fm: 73.636 | p: 73.223 | r: 74.309
r1fm+r2fm = 129.608

input #96 time: 0:10:59 | total time: 17:33:07


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
cosin similarity: 0.8744239937557571 normalized error: 0.48336424841774195
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 1.355539800008093 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 1.2167402573675692 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 1.2159137672750187 for ['[CLS] rory blood we mazercle brig [SEP]']
[Init] best perm rec loss: 1.215286310368375 for ['[CLS] maze rory brigrcle we blood [SEP]']
[Init] best perm rec loss: 1.2150252722565353 for ['[CLS]rcle brig rory blood we maze [SEP]']
[Init] best perm rec loss: 1.2077014016771346 for ['[CLS] brig rory bloodrcle we maze [SEP]']
[Init] best perm rec loss: 1.2076583575990258 for ['[CLS] brig rory maze bloodrcle we [SEP]']
[Init] best perm rec loss: 1.2061606716133877 for ['[CLS] rory blood brig mazercle we [SEP]']
[Init] best perm rec loss: 1.2015563533595108 for ['[CLS] we rory blood maze brigrcle [SEP]']
[Init] best perm rec loss: 1.200916108695932 for ['[CLS] blood rory maze we brigrcle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.006 (perp=12.521, rec=0.502), tot_loss_proj:4.037 [t=0.28s]
prediction: ['[CLS] genes oflingsmith leveled bronze [SEP]']
[ 100/2000] tot_loss=2.829 (perp=12.443, rec=0.340), tot_loss_proj:4.352 [t=0.28s]
prediction: ['[CLS]est confirmed supportedget compounds bye [SEP]']
[ 150/2000] tot_loss=2.891 (perp=13.034, rec=0.284), tot_loss_proj:4.439 [t=0.28s]
prediction: ['[CLS] andtablelsonget characters bye [SEP]']
[ 200/2000] tot_loss=2.860 (perp=13.034, rec=0.254), tot_loss_proj:4.446 [t=0.29s]
prediction: ['[CLS] andtablelsonget characters bye [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.659 (perp=11.403, rec=0.378), tot_loss_proj:4.063 [t=0.29s]
prediction: ['[CLS] andtable simmonsget richie latter [SEP]']
[ 300/2000] tot_loss=2.734 (perp=12.260, rec=0.282), tot_loss_proj:4.252 [t=0.27s]
prediction: ['[CLS] etctableadayget richie antagonist [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.515 (perp=11.350, rec=0.246), tot_loss_proj:3.392 [t=0.29s]
prediction: ['[CLS]riverrilygettable elite characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.487 (perp=11.270, rec=0.233), tot_loss_proj:3.507 [t=0.28s]
prediction: ['[CLS]riverrilygettabletable characters [SEP]']
[ 450/2000] tot_loss=2.537 (perp=11.571, rec=0.223), tot_loss_proj:3.854 [t=0.29s]
prediction: ['[CLS]river bertiegettabletable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.537 (perp=11.571, rec=0.223), tot_loss_proj:3.863 [t=0.28s]
prediction: ['[CLS]river bertiegettabletable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.507 (perp=11.434, rec=0.220), tot_loss_proj:4.096 [t=0.29s]
prediction: ['[CLS]river bertiegettable shirt characters [SEP]']
[ 600/2000] tot_loss=2.502 (perp=11.434, rec=0.215), tot_loss_proj:4.090 [t=0.28s]
prediction: ['[CLS]river bertiegettable shirt characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.506 (perp=11.474, rec=0.211), tot_loss_proj:3.991 [t=0.29s]
prediction: ['[CLS]river bertiegettable entirely characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.473 (perp=11.328, rec=0.207), tot_loss_proj:3.879 [t=0.29s]
prediction: ['[CLS] characters bertiegettable entirely characters [SEP]']
[ 750/2000] tot_loss=2.199 (perp=9.984, rec=0.202), tot_loss_proj:3.428 [t=0.29s]
prediction: ['[CLS] and bertiegettable entirely characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.194 (perp=9.984, rec=0.197), tot_loss_proj:3.430 [t=0.28s]
prediction: ['[CLS] and bertiegettable entirely characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.200 (perp=9.984, rec=0.203), tot_loss_proj:3.440 [t=0.29s]
prediction: ['[CLS] and bertiegettable entirely characters [SEP]']
[ 900/2000] tot_loss=2.476 (perp=11.349, rec=0.207), tot_loss_proj:4.076 [t=0.28s]
prediction: ['[CLS] andrnedgettable entirely characters [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.973 (perp=8.915, rec=0.190), tot_loss_proj:2.887 [t=0.27s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1000/2000] tot_loss=1.971 (perp=8.915, rec=0.188), tot_loss_proj:2.885 [t=0.28s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
[1050/2000] tot_loss=1.969 (perp=8.915, rec=0.186), tot_loss_proj:2.880 [t=0.28s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1100/2000] tot_loss=1.981 (perp=8.915, rec=0.198), tot_loss_proj:2.882 [t=0.30s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1150/2000] tot_loss=1.975 (perp=8.915, rec=0.192), tot_loss_proj:2.890 [t=0.28s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
[1200/2000] tot_loss=1.965 (perp=8.915, rec=0.182), tot_loss_proj:2.884 [t=0.30s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1250/2000] tot_loss=1.965 (perp=8.915, rec=0.182), tot_loss_proj:2.892 [t=0.30s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1300/2000] tot_loss=1.972 (perp=8.915, rec=0.189), tot_loss_proj:2.888 [t=0.28s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
[1350/2000] tot_loss=1.974 (perp=8.915, rec=0.191), tot_loss_proj:2.882 [t=0.29s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1400/2000] tot_loss=1.970 (perp=8.915, rec=0.187), tot_loss_proj:2.890 [t=0.24s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1450/2000] tot_loss=1.968 (perp=8.915, rec=0.185), tot_loss_proj:2.893 [t=0.25s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
[1500/2000] tot_loss=1.976 (perp=8.915, rec=0.193), tot_loss_proj:2.894 [t=0.26s]
prediction: ['[CLS] andrilygettable characters ¹ [SEP]']
Attempt swap
[1550/2000] tot_loss=1.982 (perp=9.061, rec=0.170), tot_loss_proj:2.685 [t=0.24s]
prediction: ['[CLS] andrilygettable characters entirely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.993 (perp=9.061, rec=0.181), tot_loss_proj:2.698 [t=0.27s]
prediction: ['[CLS] andrilygettable characters entirely [SEP]']
[1650/2000] tot_loss=1.995 (perp=9.061, rec=0.183), tot_loss_proj:2.690 [t=0.25s]
prediction: ['[CLS] andrilygettable characters entirely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.993 (perp=9.061, rec=0.181), tot_loss_proj:2.684 [t=0.26s]
prediction: ['[CLS] andrilygettable characters entirely [SEP]']
Attempt swap
[1750/2000] tot_loss=2.000 (perp=9.061, rec=0.188), tot_loss_proj:2.685 [t=0.26s]
prediction: ['[CLS] andrilygettable characters entirely [SEP]']
[1800/2000] tot_loss=1.989 (perp=9.061, rec=0.176), tot_loss_proj:2.697 [t=0.27s]
prediction: ['[CLS] andrilygettable characters entirely [SEP]']
Attempt swap
[1850/2000] tot_loss=2.220 (perp=10.214, rec=0.177), tot_loss_proj:3.177 [t=0.25s]
prediction: ['[CLS] andrilygettable charactersfor [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.009 (perp=8.956, rec=0.218), tot_loss_proj:2.624 [t=0.25s]
prediction: ['[CLS] andforgettable charactersrily [SEP]']
[1950/2000] tot_loss=2.058 (perp=9.306, rec=0.196), tot_loss_proj:3.237 [t=0.24s]
prediction: ['[CLS] andforgettable charactersrned [SEP]']
Attempt swap
[2000/2000] tot_loss=2.062 (perp=9.306, rec=0.201), tot_loss_proj:3.234 [t=0.25s]
prediction: ['[CLS] andforgettable charactersrned [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] andrilygettable characters entirely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 82.677 | p: 82.211 | r: 83.362
rouge2     | fm: 46.505 | p: 46.259 | r: 46.840
rougeL     | fm: 73.506 | p: 73.076 | r: 74.150
rougeLsum  | fm: 73.525 | p: 73.029 | r: 74.202
r1fm+r2fm = 129.182

input #97 time: 0:11:46 | total time: 17:44:53


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
cosin similarity: 0.7748733410326958 normalized error: 0.5782735414220924
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6695665717124939 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6694188714027405 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.6672139763832092 for ['[CLS] ada prohibited nos jed [SEP]']
[Init] best perm rec loss: 0.6666910648345947 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.6660864949226379 for ['[CLS] jed ada prohibited nos [SEP]']
[Init] best perm rec loss: 0.6644374132156372 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.6631656289100647 for ['[CLS] ada nos jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.628 (perp=11.846, rec=0.259), tot_loss_proj:2.848 [t=0.25s]
prediction: ['[CLS] un unful selling [SEP]']
[ 100/2000] tot_loss=2.245 (perp=10.618, rec=0.122), tot_loss_proj:2.403 [t=0.27s]
prediction: ['[CLS] unfulfullling [SEP]']
[ 150/2000] tot_loss=2.183 (perp=10.509, rec=0.081), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] unfifullling [SEP]']
[ 200/2000] tot_loss=2.166 (perp=10.509, rec=0.064), tot_loss_proj:2.429 [t=0.25s]
prediction: ['[CLS] unfifullling [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.046 (perp=4.947, rec=0.057), tot_loss_proj:1.071 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.056 (perp=4.947, rec=0.066), tot_loss_proj:1.058 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.042 (perp=4.947, rec=0.053), tot_loss_proj:1.053 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.046 (perp=4.947, rec=0.057), tot_loss_proj:1.057 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.047 (perp=4.947, rec=0.057), tot_loss_proj:1.068 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.047 (perp=4.947, rec=0.058), tot_loss_proj:1.062 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.054 (perp=4.947, rec=0.065), tot_loss_proj:1.063 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.041 (perp=4.947, rec=0.051), tot_loss_proj:1.063 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.045 (perp=4.947, rec=0.055), tot_loss_proj:1.069 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.046 (perp=4.947, rec=0.057), tot_loss_proj:1.060 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.052 (perp=4.947, rec=0.063), tot_loss_proj:1.061 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.041 (perp=4.947, rec=0.052), tot_loss_proj:1.073 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.051 (perp=4.947, rec=0.062), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.045 (perp=4.947, rec=0.056), tot_loss_proj:1.062 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.056 (perp=4.947, rec=0.066), tot_loss_proj:1.056 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.050 (perp=4.947, rec=0.061), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.053 (perp=4.947, rec=0.064), tot_loss_proj:1.054 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.043 (perp=4.947, rec=0.054), tot_loss_proj:1.051 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.061 (perp=4.947, rec=0.071), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.046 (perp=4.947, rec=0.057), tot_loss_proj:1.048 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.042 (perp=4.947, rec=0.053), tot_loss_proj:1.059 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.058 (perp=4.947, rec=0.069), tot_loss_proj:1.061 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.053 (perp=4.947, rec=0.063), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.044 (perp=4.947, rec=0.055), tot_loss_proj:1.053 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.057 (perp=4.947, rec=0.068), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.045 (perp=4.947, rec=0.055), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.042 (perp=4.947, rec=0.052), tot_loss_proj:1.052 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.048 (perp=4.947, rec=0.058), tot_loss_proj:1.044 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.052 (perp=4.947, rec=0.063), tot_loss_proj:1.054 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.048 (perp=4.947, rec=0.059), tot_loss_proj:1.053 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.043 (perp=4.947, rec=0.054), tot_loss_proj:1.057 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.053 (perp=4.947, rec=0.063), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.043 (perp=4.947, rec=0.054), tot_loss_proj:1.056 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.040 (perp=4.947, rec=0.051), tot_loss_proj:1.059 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.054 (perp=4.947, rec=0.065), tot_loss_proj:1.060 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.058 (perp=4.947, rec=0.068), tot_loss_proj:1.056 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.870 | p: 82.438 | r: 83.556
rouge2     | fm: 46.748 | p: 46.668 | r: 47.054
rougeL     | fm: 73.679 | p: 73.338 | r: 74.297
rougeLsum  | fm: 73.674 | p: 73.266 | r: 74.307
r1fm+r2fm = 129.619

input #98 time: 0:10:46 | total time: 17:55:39


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
cosin similarity: -0.8000383537769618 normalized error: 1.6702722636147556
cosin similarity: 0.8000383537769618 normalized error: 0.5673083383087922
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 1.6018527413418453 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 1.5608383158796688 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 1.4919029338445122 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 1.487766937924715 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 1.4827190712277205 for ['[CLS] supply adviceoh evenlands married anthology shoulder memories mal kilometre againsteil into working artemis shotgun en stillran definite directed full mobility massage apparent zodiac many functioning cd walk upstairs circular time setting rid [SEP]']
[Init] best rec loss: 1.4794247222215047 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 1.4744697776047475 for ['[CLS] nominations versa cm ¨ camp is spend oh stayst derelict try pictured isbn no arms grey ticked meeting but aug diseasefold errors removalheart authorised album lip marketing skatray wreck considered accreditation barry [SEP]']
[Init] best rec loss: 1.4665281286945167 for ['[CLS] football trust o guide every into integral? maybe200nington just layne what alaska priory incidentffled gymnastics manufactured lines kim survived told particularlygui discipline lonely # level pointsuna loves leaving it providence [SEP]']
[Init] best rec loss: 1.428502115366636 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 1.4187426817429025 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 1.3446356520986282 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 1.3429657726248148 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 1.3423724159354955 for ['[CLS] tasteaging distance thunder earliest services orientts temps currently barbie cushion ratings when te dental opposed bearing actually slight [MASK] knowledge screens still garcia harper right re bet synonymˈ forced claire fernste himself [SEP]']
[Init] best perm rec loss: 1.34031357433401 for ['[CLS] orient slight garcia tasteaging currently services earliest [MASK] still bearing dental harper cushion forced actually synonym claire tempsts ratings te right opposedte ferns when distance bet knowledge himself screens reˈ barbie thunder [SEP]']
[Init] best perm rec loss: 1.3371351875917943 for ['[CLS] screens ratings forced cushionˈtsaging opposed still when himself right harper orient ferns [MASK] thunder bearing tete distance re synonym taste temps currently actually dental slight earliest services bet knowledge barbie garcia claire [SEP]']
[Init] best perm rec loss: 1.3337213200439066 for ['[CLS] slight dental te earliest thunder orient re harper right still bet garcia ferns distance himself cushion forcedts knowledge tempste currently bearing services opposed screensaging whenˈ actually [MASK] synonym barbie ratings claire taste [SEP]']
[Init] best perm rec loss: 1.3307326544661549 for ['[CLS] forced services slight betaging synonym bearing orient te currently taste ferns clairete [MASK] distance opposed harperˈ himself still earliest ratings knowledge garcia actually temps cushionts screens right re barbie thunder when dental [SEP]']
[Init] best perm rec loss: 1.3298860167884436 for ['[CLS] harper garcia te right orient taste slight claire earliest still barbie [MASK] re thunder services distance actually cushionts forcedˈ temps himself when ferns ratings synonym knowledge dental bearingaging bet screens currently opposedte [SEP]']
[Init] best perm rec loss: 1.3278684589206107 for ['[CLS] opposed temps thunder ratings cushion services knowledge te bearing screens dental harper slight orientts earliest barbie tastete when forcedˈ re bet [MASK] synonym distance actually himselfaging garcia currently ferns claire right still [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.962 (perp=12.662, rec=0.429), tot_loss_proj:3.600 [t=0.25s]
prediction: ["[CLS] orerty bomber section inmate terminal 2 alleged dopingno mouth dismissed loser dal'earliest stupid threatening off organ repairsing mess check were criminal anyway officer enforcement apparent foreign eventually got worst security tape [SEP]"]
[ 100/2000] tot_loss=3.040 (perp=13.430, rec=0.354), tot_loss_proj:4.072 [t=0.25s]
prediction: ['[CLS] stupidting miami section inmate airport got province countriesno chemical minority wal government generally countries pig worstzationtra teethssingclass or a bit reason officer broadcasts certainly foreign still took the fun cooperation [SEP]']
[ 150/2000] tot_loss=2.547 (perp=11.330, rec=0.281), tot_loss_proj:3.753 [t=0.25s]
prediction: ["[CLS] diized nfl section inmate airport con province countries - chemical.ssing `? ones monsters horriblezationlain paymentsssing'' the many this situation film much gender still took the fun fun [SEP]"]
[ 200/2000] tot_loss=2.541 (perp=11.454, rec=0.250), tot_loss_proj:3.752 [t=0.27s]
prediction: ["[CLS] diized voivodeship section inmate airport con alleged endemic ` tubes andssing `? award ` horriblezationlainadayssing'' the several this which film very newspaper but took the fun fun [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.502 (perp=11.306, rec=0.241), tot_loss_proj:3.571 [t=0.25s]
prediction: ["[CLS] di airport voivodeship terrible 'ized di declared legislature - infected andssing `? award ` horrible lawsonlain expensesssing'' the significant that which film much ` but mind the fun fun [SEP]"]
[ 300/2000] tot_loss=2.392 (perp=10.909, rec=0.210), tot_loss_proj:3.666 [t=0.26s]
prediction: ["[CLS] di airport voivodeship terrible `ized di declared legislature'` andssing '? award ` horrible lawsonlain brainssing'' the significant that which film much ` but mind the fun fun [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.240 (perp=10.207, rec=0.199), tot_loss_proj:3.889 [t=0.25s]
prediction: ["[CLS] di ticket caracas terrible 'ized di stated mind'` have horrible `? award ` horrible $lain moneyssing'' the mind that so film much ` but significant the fun feedback [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.182 (perp=9.996, rec=0.182), tot_loss_proj:3.894 [t=0.26s]
prediction: ["[CLS] di airports caracas terrible `ized di stated saying'` have horrible `? award ` horrible lawson arsenal brainssing'' the mind that film so much ` but significant the fun feedback [SEP]"]
[ 450/2000] tot_loss=2.235 (perp=10.261, rec=0.183), tot_loss_proj:3.968 [t=0.26s]
prediction: ["[CLS] di ticket caracas terrible `ized di had saying'` walked horrible `'award ` horrible $ arsenal moneyssing'' the mind that film so much ` but significant the fun feedback [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.210 (perp=10.226, rec=0.165), tot_loss_proj:3.946 [t=0.26s]
prediction: ["[CLS] di ticket caracas terrible `ized di had `'` walked horrible'' award mind horrible lawson arsenal moneyssing'' the mind that film so much ` but significant the fun feedback [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.112 (perp=9.731, rec=0.166), tot_loss_proj:3.829 [t=0.26s]
prediction: ["[CLS] di ticket caracas terribleized ` di had `'` walked horrible'' award mind horrible shillings arsenal brainssing'' the mind that film so much ` but significant the fun feedback [SEP]"]
[ 600/2000] tot_loss=2.204 (perp=10.258, rec=0.152), tot_loss_proj:3.038 [t=0.28s]
prediction: ["[CLS] di ticket caracas terribleized ` di had ` they ` walked horrible'' award mind muttering shillings arsenaladayssing'' the mind that film so much ticket but significant not fun ᶜ [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.057 (perp=9.526, rec=0.151), tot_loss_proj:2.900 [t=0.28s]
prediction: ["[CLS] di ticket caracas terribleized ` di had ` they ` walked horrible shillings'award mind muttering'ticketadayssing'' the mind that film so much ticket but terrible not fun ᶜ [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=2.045 (perp=9.534, rec=0.138), tot_loss_proj:3.000 [t=0.25s]
prediction: ["[CLS] di ticket caracas terribleized ` di had ` they ` walked horrible shillings'cost nor muttering'ticketadayssing much'the mind that film so much ticket but not terrible fun ᵍ [SEP]"]
[ 750/2000] tot_loss=2.117 (perp=9.894, rec=0.138), tot_loss_proj:3.053 [t=0.26s]
prediction: ["[CLS] di ticket caracas terribleized ` di had ` they ` walked horrible shillings'cost nor muttering'ticketadayssing much'the mind that film un much ticket but not terrible fun tickets [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.027 (perp=9.455, rec=0.136), tot_loss_proj:2.922 [t=0.26s]
prediction: ["[CLS] di ticket caracas terribleized ` di'` they ` walked horrible dreamed'cost n muttering'ticketadayssing much'the mind that film had much ticket but not terrible fun tickets [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.062 (perp=9.631, rec=0.136), tot_loss_proj:2.962 [t=0.27s]
prediction: ["[CLS] di ticket caracas terribleized ` di'` they walked ` horrible dreamed'cost n muttering'ticketadayssing much'the mind that film had much ticket but t terrible fun tickets [SEP]"]
[ 900/2000] tot_loss=2.042 (perp=9.536, rec=0.135), tot_loss_proj:2.922 [t=0.26s]
prediction: ["[CLS] di ticket correction terribleized ` di'` they walked ` horrible dreamed'cost n muttering'ticketadayssing much'the mind that film had much ticket but t terrible fun tickets [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.013 (perp=9.388, rec=0.135), tot_loss_proj:2.917 [t=0.25s]
prediction: ["[CLS] di ticket correction terribleized di'` ` they walked ` horrible dreamed'cost n muttering'ticketadayssing much'the mind that film had much ticket but t terrible fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.981 (perp=9.266, rec=0.127), tot_loss_proj:3.039 [t=0.25s]
prediction: ["[CLS] di ticket correction terribleized di'` horrible they walked ` horrible dreamed'cost n muttering'ticketadayssing t'the mind that film had much ticket but much terrible fun tickets [SEP]"]
[1050/2000] tot_loss=1.977 (perp=9.266, rec=0.124), tot_loss_proj:3.035 [t=0.25s]
prediction: ["[CLS] di ticket correction terribleized di'` horrible they walked ` horrible dreamed'cost n muttering'ticketadayssing t'the mind that film had much ticket but much terrible fun tickets [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=2.028 (perp=9.501, rec=0.128), tot_loss_proj:3.119 [t=0.25s]
prediction: ["[CLS] di ticket correction horribleized'` horrible they walked ` di horrible dreamed'cost n muttering'ticketadayssing t'the mind that film had much ticket but much kept fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.009 (perp=9.424, rec=0.124), tot_loss_proj:3.076 [t=0.25s]
prediction: ["[CLS] di ticket disturbing horribleized'` horrible they walked ` di horrible dreamed'cost n muttering'ticketadayssing t'the mind that film had kept ticket but much much fun tickets [SEP]"]
[1200/2000] tot_loss=2.006 (perp=9.424, rec=0.122), tot_loss_proj:3.073 [t=0.33s]
prediction: ["[CLS] di ticket disturbing horribleized'` horrible they walked ` di horrible dreamed'cost n muttering'ticketadayssing t'the mind that film had kept ticket but much much fun tickets [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.988 (perp=9.290, rec=0.130), tot_loss_proj:3.010 [t=0.25s]
prediction: ["[CLS] di disturbing ticket horribleized'` horrible they walked ` di out dreamed'cost n muttering'ticketadayssing t'the mind that film had kept ticket but much much fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.909 (perp=8.918, rec=0.125), tot_loss_proj:3.452 [t=0.26s]
prediction: ["[CLS] di disturbing ticket horribleized'` horrible they walked ` di out dreamed'cost n muttering'ticketadayssing't the mind that film had no ticket but much much fun tickets [SEP]"]
[1350/2000] tot_loss=1.911 (perp=8.918, rec=0.128), tot_loss_proj:3.452 [t=0.26s]
prediction: ["[CLS] di disturbing ticket horribleized'` horrible they walked ` di out dreamed'cost n muttering'ticketadayssing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.861 (perp=8.690, rec=0.123), tot_loss_proj:3.193 [t=0.26s]
prediction: ["[CLS] di conjecture ticket horribleized'` horrible they walked ` out dreamed'cost n muttering'ticketaday dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.823 (perp=8.482, rec=0.127), tot_loss_proj:3.141 [t=0.25s]
prediction: ["[CLS] di disturbing ticket horribleized ` ` horrible they walked'out dreamed'cost n muttering'ticket else dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
[1500/2000] tot_loss=1.822 (perp=8.482, rec=0.126), tot_loss_proj:3.140 [t=0.26s]
prediction: ["[CLS] di disturbing ticket horribleized ` ` horrible they walked'out dreamed'cost n muttering'ticket else dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.783 (perp=8.277, rec=0.128), tot_loss_proj:3.135 [t=0.27s]
prediction: ["[CLS] di disturbing ticket horribleized ` ` out they walked'horrible dreamed'cost n muttering'ticket else dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.815 (perp=8.438, rec=0.127), tot_loss_proj:3.088 [t=0.26s]
prediction: ["[CLS] di conjecture ticket horribleized ` `'they walked out horrible dreamed'cost n muttering'ticket else dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
[1650/2000] tot_loss=1.810 (perp=8.438, rec=0.122), tot_loss_proj:3.087 [t=0.25s]
prediction: ["[CLS] di conjecture ticket horribleized ` `'they walked out horrible dreamed'cost n muttering'ticket else dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.838 (perp=8.552, rec=0.127), tot_loss_proj:3.071 [t=0.26s]
prediction: ["[CLS] di conjecture ticket horribleized ` `'they walked out cost dreamed'terrible n muttering'ticketaday dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.829 (perp=8.552, rec=0.119), tot_loss_proj:3.071 [t=0.28s]
prediction: ["[CLS] di conjecture ticket horribleized ` `'they walked out cost dreamed'terrible n muttering'ticketaday dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
[1800/2000] tot_loss=1.833 (perp=8.552, rec=0.122), tot_loss_proj:3.072 [t=0.26s]
prediction: ["[CLS] di conjecture ticket horribleized ` `'they walked out cost dreamed'terrible n muttering'ticketaday dissing't the mind that film had no ticket but much much fun tickets [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.848 (perp=8.611, rec=0.126), tot_loss_proj:3.031 [t=0.25s]
prediction: ["[CLS] di disturbing'ticket horribleized ` `'they walked out cost dreamed terrible n muttering'ticketaday dissing't the mind that film had several ticket but much much fun tickets [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.830 (perp=8.535, rec=0.123), tot_loss_proj:2.797 [t=0.26s]
prediction: ["[CLS] di conjecture'ticket horribleized ` `'they walked out cost dreamed much n muttering'ticketaday dissing't the mind that film had several ticket but much terrible fun tickets [SEP]"]
[1950/2000] tot_loss=1.830 (perp=8.535, rec=0.123), tot_loss_proj:2.792 [t=0.25s]
prediction: ["[CLS] di conjecture'ticket horribleized ` `'they walked out cost dreamed much n muttering'ticketaday dissing't the mind that film had several ticket but much terrible fun tickets [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.810 (perp=8.454, rec=0.119), tot_loss_proj:2.759 [t=0.27s]
prediction: ["[CLS] di conjecture'ticket horribleized ` `'they dreamed walked out cost much n muttering'ticketaday dissing't the mind that film had several ticket but much terrible fun tickets [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] di conjecture ticket horribleized ` `'they walked out cost dreamed'terrible n muttering'ticketaday dissing't the mind that film had no ticket but much much fun tickets [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.091 | p: 65.517 | r: 73.077
rouge2     | fm: 7.547 | p: 7.143 | r: 8.000
rougeL     | fm: 32.727 | p: 31.034 | r: 34.615
rougeLsum  | fm: 32.727 | p: 31.034 | r: 34.615
r1fm+r2fm = 76.638

[Aggregate metrics]:
rouge1     | fm: 82.714 | p: 82.174 | r: 83.447
rouge2     | fm: 46.511 | p: 46.331 | r: 46.765
rougeL     | fm: 73.355 | p: 72.869 | r: 73.998
rougeLsum  | fm: 73.337 | p: 72.897 | r: 74.005
r1fm+r2fm = 129.225

input #99 time: 0:11:00 | total time: 18:06:40


Done with all.
