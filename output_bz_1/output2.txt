


Command: attack2.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 2000 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
cosin similarity: -0.8934663382597008 normalized error: 1.733659495003061
cosin similarity: 0.8934663382597008 normalized error: 0.5033565318294141
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.9195889576675713 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 1.7000055914312888 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 1.6292203331030068 for ['[CLS] hybrid counter [SEP]']
[Init] best rec loss: 1.5519310411404896 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 1.3563057900385864 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.402 (perp=10.334, rec=0.335), tot_loss_proj:2.680 [t=0.28s]
prediction: ['[CLS] certainly disappointed [SEP]']
[ 100/2000] tot_loss=2.265 (perp=10.251, rec=0.215), tot_loss_proj:2.331 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.225 (perp=10.251, rec=0.175), tot_loss_proj:2.320 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.251, rec=0.165), tot_loss_proj:2.342 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.222 (perp=10.251, rec=0.172), tot_loss_proj:2.312 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.313 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.202 (perp=10.251, rec=0.151), tot_loss_proj:2.317 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.211 (perp=10.251, rec=0.161), tot_loss_proj:2.313 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.310 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.210 (perp=10.251, rec=0.160), tot_loss_proj:2.316 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.190 (perp=10.251, rec=0.139), tot_loss_proj:2.308 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.193 (perp=10.251, rec=0.143), tot_loss_proj:2.304 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.198 (perp=10.251, rec=0.148), tot_loss_proj:2.314 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.196 (perp=10.251, rec=0.146), tot_loss_proj:2.320 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.203 (perp=10.251, rec=0.152), tot_loss_proj:2.317 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.192 (perp=10.251, rec=0.142), tot_loss_proj:2.324 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.205 (perp=10.251, rec=0.155), tot_loss_proj:2.321 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.191 (perp=10.251, rec=0.140), tot_loss_proj:2.328 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.312 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.307 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.317 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.191 (perp=10.251, rec=0.140), tot_loss_proj:2.312 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.194 (perp=10.251, rec=0.144), tot_loss_proj:2.330 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.208 (perp=10.251, rec=0.158), tot_loss_proj:2.304 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.207 (perp=10.251, rec=0.156), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.201 (perp=10.251, rec=0.151), tot_loss_proj:2.304 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.197 (perp=10.251, rec=0.147), tot_loss_proj:2.314 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.184 (perp=10.251, rec=0.134), tot_loss_proj:2.321 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.196 (perp=10.251, rec=0.146), tot_loss_proj:2.308 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.193 (perp=10.251, rec=0.143), tot_loss_proj:2.313 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.194 (perp=10.251, rec=0.144), tot_loss_proj:2.314 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.197 (perp=10.251, rec=0.147), tot_loss_proj:2.323 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.193 (perp=10.251, rec=0.143), tot_loss_proj:2.311 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.204 (perp=10.251, rec=0.154), tot_loss_proj:2.325 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.208 (perp=10.251, rec=0.158), tot_loss_proj:2.322 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.208 (perp=10.251, rec=0.158), tot_loss_proj:2.316 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.200 (perp=10.251, rec=0.150), tot_loss_proj:2.320 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.195 (perp=10.251, rec=0.144), tot_loss_proj:2.311 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:11:28 | total time: 0:11:28


Running input #1 of 100.
reference: 
========================
splendidly 
========================
cosin similarity: -0.9215972518936497 normalized error: 1.862747916466129
cosin similarity: 0.9215972518936498 normalized error: 0.4365905743006529
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.7844158145081626 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 1.6785674942866482 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 1.677126732716619 for ['[CLS] conducted predator [SEP]']
[Init] best rec loss: 1.5444858188097057 for ['[CLS] j native [SEP]']
[Init] best rec loss: 1.1461405497950246 for ['[CLS] finally relative [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.308 (perp=9.613, rec=0.385), tot_loss_proj:3.098 [t=0.20s]
prediction: ['[CLS] finally successfully [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.288, rec=0.317), tot_loss_proj:2.493 [t=0.20s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.302 (perp=10.288, rec=0.244), tot_loss_proj:2.492 [t=0.20s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.289 (perp=10.288, rec=0.231), tot_loss_proj:2.498 [t=0.20s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.059 (perp=9.171, rec=0.225), tot_loss_proj:2.048 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=2.048 (perp=9.171, rec=0.213), tot_loss_proj:2.055 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.047 (perp=9.171, rec=0.212), tot_loss_proj:2.045 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.041 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=2.030 (perp=9.171, rec=0.196), tot_loss_proj:2.054 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.038 (perp=9.171, rec=0.203), tot_loss_proj:2.054 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.034 (perp=9.171, rec=0.200), tot_loss_proj:2.056 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.038 (perp=9.171, rec=0.204), tot_loss_proj:2.061 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.036 (perp=9.171, rec=0.202), tot_loss_proj:2.059 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=2.039 (perp=9.171, rec=0.204), tot_loss_proj:2.038 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.022 (perp=9.171, rec=0.188), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.038 (perp=9.171, rec=0.203), tot_loss_proj:2.047 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=2.043 (perp=9.171, rec=0.209), tot_loss_proj:2.040 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.034 (perp=9.171, rec=0.200), tot_loss_proj:2.052 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=2.044 (perp=9.171, rec=0.210), tot_loss_proj:2.051 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=2.039 (perp=9.171, rec=0.205), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=2.033 (perp=9.171, rec=0.198), tot_loss_proj:2.062 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.053 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=2.043 (perp=9.171, rec=0.208), tot_loss_proj:2.048 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.042 (perp=9.171, rec=0.208), tot_loss_proj:2.062 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.031 (perp=9.171, rec=0.197), tot_loss_proj:2.045 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=2.035 (perp=9.171, rec=0.201), tot_loss_proj:2.046 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.040 (perp=9.171, rec=0.205), tot_loss_proj:2.053 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.048 (perp=9.171, rec=0.214), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=2.043 (perp=9.171, rec=0.208), tot_loss_proj:2.051 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.034 (perp=9.171, rec=0.199), tot_loss_proj:2.055 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.039 (perp=9.171, rec=0.205), tot_loss_proj:2.057 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=2.029 (perp=9.171, rec=0.195), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.051 (perp=9.171, rec=0.217), tot_loss_proj:2.060 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.040 (perp=9.171, rec=0.205), tot_loss_proj:2.057 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=2.042 (perp=9.171, rec=0.208), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.043 (perp=9.171, rec=0.209), tot_loss_proj:2.052 [t=0.31s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.037 (perp=9.171, rec=0.203), tot_loss_proj:2.055 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=2.047 (perp=9.171, rec=0.213), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.043 (perp=9.171, rec=0.209), tot_loss_proj:2.053 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:10:07 | total time: 0:21:36


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
cosin similarity: 0.9258773195154295 normalized error: 0.4567743850008564
cosin similarity: -0.9258773195154295 normalized error: 1.8104055459475727
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 1.240719218736061 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 1.2380029208513876 for ['[CLS]〜 wash at [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.695 (perp=11.388, rec=0.417), tot_loss_proj:2.980 [t=0.28s]
prediction: ['[CLS]ing gaining worth [SEP]']
[ 100/2000] tot_loss=2.306 (perp=10.246, rec=0.257), tot_loss_proj:2.565 [t=0.25s]
prediction: ['[CLS] bringing gaining momentum [SEP]']
[ 150/2000] tot_loss=2.387 (perp=10.861, rec=0.215), tot_loss_proj:3.406 [t=0.27s]
prediction: ['[CLS]iring gaining momentum [SEP]']
[ 200/2000] tot_loss=2.331 (perp=10.812, rec=0.169), tot_loss_proj:3.400 [t=0.26s]
prediction: ['[CLS]plify gaining momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.323 (perp=10.812, rec=0.161), tot_loss_proj:3.391 [t=0.26s]
prediction: ['[CLS]plify gaining momentum [SEP]']
[ 300/2000] tot_loss=2.318 (perp=10.812, rec=0.156), tot_loss_proj:3.385 [t=0.27s]
prediction: ['[CLS]plify gaining momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.320 (perp=10.812, rec=0.158), tot_loss_proj:3.364 [t=0.27s]
prediction: ['[CLS]plify gaining momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.328 (perp=10.795, rec=0.169), tot_loss_proj:2.978 [t=0.26s]
prediction: ['[CLS]pling gaining momentum [SEP]']
[ 450/2000] tot_loss=2.310 (perp=10.795, rec=0.151), tot_loss_proj:2.966 [t=0.26s]
prediction: ['[CLS]pling gaining momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.319 (perp=10.795, rec=0.160), tot_loss_proj:2.979 [t=0.27s]
prediction: ['[CLS]pling gaining momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.306 (perp=10.795, rec=0.147), tot_loss_proj:2.972 [t=0.25s]
prediction: ['[CLS]pling gaining momentum [SEP]']
[ 600/2000] tot_loss=2.314 (perp=10.795, rec=0.155), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS]pling gaining momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.931 (perp=8.881, rec=0.155), tot_loss_proj:2.330 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.927 (perp=8.881, rec=0.151), tot_loss_proj:2.323 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
[ 750/2000] tot_loss=1.926 (perp=8.881, rec=0.150), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.919 (perp=8.881, rec=0.143), tot_loss_proj:2.334 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.918 (perp=8.881, rec=0.142), tot_loss_proj:2.326 [t=0.30s]
prediction: ['[CLS] many gaining momentum [SEP]']
[ 900/2000] tot_loss=1.922 (perp=8.881, rec=0.146), tot_loss_proj:2.332 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.915 (perp=8.881, rec=0.138), tot_loss_proj:2.326 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.921 (perp=8.881, rec=0.145), tot_loss_proj:2.331 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1050/2000] tot_loss=1.933 (perp=8.881, rec=0.157), tot_loss_proj:2.325 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.933 (perp=8.881, rec=0.156), tot_loss_proj:2.326 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.919 (perp=8.881, rec=0.143), tot_loss_proj:2.333 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1200/2000] tot_loss=1.920 (perp=8.881, rec=0.144), tot_loss_proj:2.328 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.929 (perp=8.881, rec=0.152), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.917 (perp=8.881, rec=0.141), tot_loss_proj:2.317 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1350/2000] tot_loss=1.919 (perp=8.881, rec=0.143), tot_loss_proj:2.308 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.918 (perp=8.881, rec=0.141), tot_loss_proj:2.323 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.922 (perp=8.881, rec=0.146), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1500/2000] tot_loss=1.924 (perp=8.881, rec=0.147), tot_loss_proj:2.318 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.917 (perp=8.881, rec=0.141), tot_loss_proj:2.324 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.925 (perp=8.881, rec=0.148), tot_loss_proj:2.321 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1650/2000] tot_loss=1.930 (perp=8.881, rec=0.153), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.927 (perp=8.881, rec=0.151), tot_loss_proj:2.322 [t=0.28s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.913 (perp=8.881, rec=0.137), tot_loss_proj:2.322 [t=0.25s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1800/2000] tot_loss=1.912 (perp=8.881, rec=0.136), tot_loss_proj:2.323 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.918 (perp=8.881, rec=0.142), tot_loss_proj:2.315 [t=0.28s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.918 (perp=8.881, rec=0.142), tot_loss_proj:2.322 [t=0.27s]
prediction: ['[CLS] many gaining momentum [SEP]']
[1950/2000] tot_loss=1.920 (perp=8.881, rec=0.144), tot_loss_proj:2.321 [t=0.28s]
prediction: ['[CLS] many gaining momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.911 (perp=8.881, rec=0.135), tot_loss_proj:2.314 [t=0.26s]
prediction: ['[CLS] many gaining momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] many gaining momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 93.333 | p: 93.333 | r: 93.333
rougeLsum  | fm: 93.333 | p: 93.333 | r: 93.333
r1fm+r2fm = 168.333

input #2 time: 0:11:04 | total time: 0:32:40


Running input #3 of 100.
reference: 
========================
flawless film 
========================
cosin similarity: -0.7101217562261617 normalized error: 1.6831364410360434
cosin similarity: 0.7101217562261617 normalized error: 0.6049972845812499
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.8771149043397706 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 1.5753492513139955 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 1.428541961569726 for ['[CLS] anton laughed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=10.247, rec=0.703), tot_loss_proj:2.985 [t=0.27s]
prediction: ['[CLS] flawless perfectly [SEP]']
[ 100/2000] tot_loss=2.565 (perp=10.476, rec=0.470), tot_loss_proj:2.935 [t=0.25s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 150/2000] tot_loss=2.424 (perp=10.226, rec=0.379), tot_loss_proj:2.848 [t=0.28s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.478 (perp=10.226, rec=0.433), tot_loss_proj:2.834 [t=0.26s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.106 (perp=8.385, rec=0.429), tot_loss_proj:2.317 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=2.055 (perp=8.385, rec=0.378), tot_loss_proj:2.331 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.053 (perp=8.385, rec=0.376), tot_loss_proj:2.332 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.015 (perp=8.385, rec=0.338), tot_loss_proj:2.322 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=2.032 (perp=8.385, rec=0.355), tot_loss_proj:2.311 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.004 (perp=8.385, rec=0.327), tot_loss_proj:2.310 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=8.385, rec=0.324), tot_loss_proj:2.304 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=2.003 (perp=8.385, rec=0.326), tot_loss_proj:2.310 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.317 (perp=9.960, rec=0.324), tot_loss_proj:3.023 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.311 (perp=9.960, rec=0.319), tot_loss_proj:3.023 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
[ 750/2000] tot_loss=2.314 (perp=9.960, rec=0.321), tot_loss_proj:3.022 [t=0.25s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.307 (perp=9.960, rec=0.315), tot_loss_proj:3.031 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.310 (perp=9.960, rec=0.318), tot_loss_proj:3.018 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
[ 900/2000] tot_loss=2.305 (perp=9.960, rec=0.313), tot_loss_proj:3.014 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.316 (perp=9.960, rec=0.324), tot_loss_proj:3.025 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1000/2000] tot_loss=2.304 (perp=9.960, rec=0.312), tot_loss_proj:3.018 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1050/2000] tot_loss=2.306 (perp=9.960, rec=0.314), tot_loss_proj:3.023 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1100/2000] tot_loss=2.305 (perp=9.960, rec=0.313), tot_loss_proj:3.034 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1150/2000] tot_loss=2.314 (perp=9.960, rec=0.322), tot_loss_proj:3.026 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1200/2000] tot_loss=2.305 (perp=9.960, rec=0.313), tot_loss_proj:3.032 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1250/2000] tot_loss=2.295 (perp=9.960, rec=0.303), tot_loss_proj:3.035 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1300/2000] tot_loss=2.301 (perp=9.960, rec=0.308), tot_loss_proj:3.019 [t=0.28s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1350/2000] tot_loss=2.293 (perp=9.960, rec=0.301), tot_loss_proj:3.028 [t=0.25s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1400/2000] tot_loss=2.304 (perp=9.960, rec=0.312), tot_loss_proj:3.025 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1450/2000] tot_loss=2.298 (perp=9.960, rec=0.306), tot_loss_proj:3.033 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1500/2000] tot_loss=2.290 (perp=9.960, rec=0.298), tot_loss_proj:3.027 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1550/2000] tot_loss=2.301 (perp=9.960, rec=0.309), tot_loss_proj:3.019 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1600/2000] tot_loss=2.286 (perp=9.960, rec=0.294), tot_loss_proj:3.024 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1650/2000] tot_loss=2.303 (perp=9.960, rec=0.311), tot_loss_proj:3.023 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1700/2000] tot_loss=2.290 (perp=9.960, rec=0.298), tot_loss_proj:3.027 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1750/2000] tot_loss=2.301 (perp=9.960, rec=0.308), tot_loss_proj:3.029 [t=0.28s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1800/2000] tot_loss=2.311 (perp=9.960, rec=0.319), tot_loss_proj:3.028 [t=0.27s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1850/2000] tot_loss=2.299 (perp=9.960, rec=0.307), tot_loss_proj:3.020 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[1900/2000] tot_loss=2.299 (perp=9.960, rec=0.307), tot_loss_proj:3.040 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
[1950/2000] tot_loss=2.299 (perp=9.960, rec=0.307), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Attempt swap
[2000/2000] tot_loss=2.297 (perp=9.960, rec=0.305), tot_loss_proj:3.031 [t=0.26s]
prediction: ['[CLS] flawless vuelta [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless vuelta [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 88.750 | p: 88.750 | r: 88.750
rouge2     | fm: 64.583 | p: 64.583 | r: 64.583
rougeL     | fm: 88.750 | p: 88.750 | r: 88.750
rougeLsum  | fm: 88.750 | p: 88.750 | r: 88.750
r1fm+r2fm = 153.333

input #3 time: 0:11:04 | total time: 0:43:45


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
cosin similarity: -0.9048403215042558 normalized error: 1.78792991317121
cosin similarity: 0.9048403215042556 normalized error: 0.475176931612047
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.79504128600855 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 1.7741654840541323 for ['[CLS] watch joint weekly [SEP]']
[Init] best rec loss: 1.7312058429382033 for ['[CLS] religious tip seat [SEP]']
[Init] best rec loss: 1.729607759519339 for ['[CLS] counters ragedu [SEP]']
[Init] best rec loss: 1.4748459428734992 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 1.2364187869281222 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.289 (perp=14.362, rec=0.417), tot_loss_proj:3.528 [t=0.26s]
prediction: ['[CLS] tires uglyome [SEP]']
[ 100/2000] tot_loss=2.833 (perp=12.901, rec=0.253), tot_loss_proj:3.237 [t=0.26s]
prediction: ['[CLS] tires awfulome [SEP]']
[ 150/2000] tot_loss=2.416 (perp=11.053, rec=0.205), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] tiresomeome [SEP]']
[ 200/2000] tot_loss=2.395 (perp=11.053, rec=0.185), tot_loss_proj:2.579 [t=0.27s]
prediction: ['[CLS] tiresomeome [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.279 (perp=9.735, rec=0.332), tot_loss_proj:2.426 [t=0.25s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 300/2000] tot_loss=2.149 (perp=9.735, rec=0.202), tot_loss_proj:2.445 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.122 (perp=9.735, rec=0.175), tot_loss_proj:2.439 [t=0.27s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.112 (perp=9.735, rec=0.165), tot_loss_proj:2.431 [t=0.25s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 450/2000] tot_loss=2.108 (perp=9.735, rec=0.161), tot_loss_proj:2.434 [t=0.25s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.096 (perp=9.735, rec=0.149), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.092 (perp=9.735, rec=0.146), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 600/2000] tot_loss=2.093 (perp=9.735, rec=0.146), tot_loss_proj:2.440 [t=0.27s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.086 (perp=9.680, rec=0.150), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.044 (perp=9.501, rec=0.144), tot_loss_proj:2.705 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
[ 750/2000] tot_loss=2.039 (perp=9.501, rec=0.138), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.052 (perp=9.501, rec=0.152), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.039 (perp=9.501, rec=0.139), tot_loss_proj:2.694 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
[ 900/2000] tot_loss=2.039 (perp=9.501, rec=0.139), tot_loss_proj:2.699 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.036 (perp=9.501, rec=0.136), tot_loss_proj:2.700 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1000/2000] tot_loss=2.036 (perp=9.501, rec=0.136), tot_loss_proj:2.705 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
[1050/2000] tot_loss=2.038 (perp=9.501, rec=0.138), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1100/2000] tot_loss=2.030 (perp=9.501, rec=0.130), tot_loss_proj:2.705 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1150/2000] tot_loss=2.035 (perp=9.501, rec=0.135), tot_loss_proj:2.703 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
[1200/2000] tot_loss=2.034 (perp=9.501, rec=0.134), tot_loss_proj:2.697 [t=0.29s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1250/2000] tot_loss=2.033 (perp=9.501, rec=0.132), tot_loss_proj:2.707 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1300/2000] tot_loss=2.026 (perp=9.501, rec=0.125), tot_loss_proj:2.701 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
[1350/2000] tot_loss=2.031 (perp=9.501, rec=0.131), tot_loss_proj:2.705 [t=0.29s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1400/2000] tot_loss=2.031 (perp=9.501, rec=0.131), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1450/2000] tot_loss=2.038 (perp=9.501, rec=0.138), tot_loss_proj:2.706 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
[1500/2000] tot_loss=2.026 (perp=9.501, rec=0.126), tot_loss_proj:2.699 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1550/2000] tot_loss=2.024 (perp=9.501, rec=0.123), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1600/2000] tot_loss=2.027 (perp=9.501, rec=0.127), tot_loss_proj:2.697 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
[1650/2000] tot_loss=2.026 (perp=9.501, rec=0.126), tot_loss_proj:2.702 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1700/2000] tot_loss=2.031 (perp=9.501, rec=0.131), tot_loss_proj:2.708 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1750/2000] tot_loss=2.046 (perp=9.501, rec=0.146), tot_loss_proj:2.708 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
[1800/2000] tot_loss=2.018 (perp=9.501, rec=0.118), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1850/2000] tot_loss=2.027 (perp=9.501, rec=0.127), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[1900/2000] tot_loss=2.040 (perp=9.501, rec=0.140), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
[1950/2000] tot_loss=2.038 (perp=9.501, rec=0.138), tot_loss_proj:2.698 [t=0.27s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
[2000/2000] tot_loss=2.019 (perp=9.501, rec=0.119), tot_loss_proj:2.699 [t=0.29s]
prediction: ['[CLS] minds tiresome [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] minds tiresome [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 82.429 | p: 81.000 | r: 84.333
rouge2     | fm: 51.667 | p: 51.667 | r: 51.667
rougeL     | fm: 82.429 | p: 81.000 | r: 84.333
rougeLsum  | fm: 82.429 | p: 81.000 | r: 84.333
r1fm+r2fm = 134.095

input #4 time: 0:11:04 | total time: 0:54:49


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
cosin similarity: -0.6976662371922135 normalized error: 1.6799576310302529
cosin similarity: 0.6976662371922135 normalized error: 0.6126100487423699
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 1.7698692559443443 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 1.668958904616424 for ['[CLS] works flow [SEP]']
[Init] best rec loss: 1.544181172559094 for ['[CLS] eye central [SEP]']
[Init] best perm rec loss: 1.5374453344314825 for ['[CLS] central eye [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.373 (perp=8.395, rec=0.694), tot_loss_proj:2.795 [t=0.20s]
prediction: ['[CLS] feeling comfortable [SEP]']
[ 100/2000] tot_loss=2.883 (perp=11.370, rec=0.609), tot_loss_proj:3.599 [t=0.20s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=2.838 (perp=11.370, rec=0.564), tot_loss_proj:3.601 [t=0.20s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=3.153 (perp=13.679, rec=0.417), tot_loss_proj:4.164 [t=0.20s]
prediction: ['[CLS]plify ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.101 (perp=13.679, rec=0.366), tot_loss_proj:4.171 [t=0.20s]
prediction: ['[CLS]plify ease [SEP]']
[ 300/2000] tot_loss=3.082 (perp=13.679, rec=0.346), tot_loss_proj:4.174 [t=0.20s]
prediction: ['[CLS]plify ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.619 (perp=11.339, rec=0.351), tot_loss_proj:3.486 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.626 (perp=11.339, rec=0.358), tot_loss_proj:3.471 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[ 450/2000] tot_loss=2.581 (perp=11.339, rec=0.313), tot_loss_proj:3.474 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.577 (perp=11.339, rec=0.309), tot_loss_proj:3.464 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.590 (perp=11.339, rec=0.322), tot_loss_proj:3.481 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[ 600/2000] tot_loss=2.573 (perp=11.339, rec=0.305), tot_loss_proj:3.460 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.580 (perp=11.339, rec=0.312), tot_loss_proj:3.469 [t=0.21s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.568 (perp=11.339, rec=0.300), tot_loss_proj:3.463 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[ 750/2000] tot_loss=2.575 (perp=11.339, rec=0.308), tot_loss_proj:3.460 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.573 (perp=11.339, rec=0.306), tot_loss_proj:3.465 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.573 (perp=11.339, rec=0.306), tot_loss_proj:3.464 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[ 900/2000] tot_loss=2.572 (perp=11.339, rec=0.304), tot_loss_proj:3.462 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.560 (perp=11.339, rec=0.292), tot_loss_proj:3.461 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1000/2000] tot_loss=2.563 (perp=11.339, rec=0.295), tot_loss_proj:3.464 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[1050/2000] tot_loss=2.569 (perp=11.339, rec=0.302), tot_loss_proj:3.468 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1100/2000] tot_loss=2.566 (perp=11.339, rec=0.299), tot_loss_proj:3.462 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1150/2000] tot_loss=2.568 (perp=11.339, rec=0.301), tot_loss_proj:3.470 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[1200/2000] tot_loss=2.556 (perp=11.339, rec=0.289), tot_loss_proj:3.466 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1250/2000] tot_loss=2.555 (perp=11.339, rec=0.287), tot_loss_proj:3.471 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1300/2000] tot_loss=2.568 (perp=11.339, rec=0.300), tot_loss_proj:3.464 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[1350/2000] tot_loss=2.567 (perp=11.339, rec=0.299), tot_loss_proj:3.470 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1400/2000] tot_loss=2.562 (perp=11.339, rec=0.294), tot_loss_proj:3.471 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1450/2000] tot_loss=2.556 (perp=11.339, rec=0.288), tot_loss_proj:3.466 [t=0.21s]
prediction: ['[CLS]ulent ease [SEP]']
[1500/2000] tot_loss=2.560 (perp=11.339, rec=0.292), tot_loss_proj:3.464 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1550/2000] tot_loss=2.563 (perp=11.339, rec=0.295), tot_loss_proj:3.468 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1600/2000] tot_loss=2.561 (perp=11.339, rec=0.293), tot_loss_proj:3.466 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[1650/2000] tot_loss=2.563 (perp=11.339, rec=0.295), tot_loss_proj:3.471 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1700/2000] tot_loss=2.566 (perp=11.339, rec=0.299), tot_loss_proj:3.465 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1750/2000] tot_loss=2.562 (perp=11.339, rec=0.294), tot_loss_proj:3.468 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
[1800/2000] tot_loss=2.560 (perp=11.339, rec=0.292), tot_loss_proj:3.468 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1850/2000] tot_loss=2.561 (perp=11.339, rec=0.293), tot_loss_proj:3.466 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[1900/2000] tot_loss=2.566 (perp=11.339, rec=0.299), tot_loss_proj:3.463 [t=0.21s]
prediction: ['[CLS]ulent ease [SEP]']
[1950/2000] tot_loss=2.572 (perp=11.339, rec=0.304), tot_loss_proj:3.472 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Attempt swap
[2000/2000] tot_loss=2.555 (perp=11.339, rec=0.287), tot_loss_proj:3.468 [t=0.20s]
prediction: ['[CLS]ulent ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS]ulent ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 81.190 | p: 80.000 | r: 82.778
rouge2     | fm: 47.222 | p: 47.222 | r: 47.222
rougeL     | fm: 81.190 | p: 80.000 | r: 82.778
rougeLsum  | fm: 81.190 | p: 80.000 | r: 82.778
r1fm+r2fm = 128.413

input #5 time: 0:08:04 | total time: 1:02:54


Running input #6 of 100.
reference: 
========================
grayish 
========================
cosin similarity: -0.9293236555171187 normalized error: 1.7532736189764786
cosin similarity: 0.9293236555171187 normalized error: 0.4810054002498873
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 1.8880154143242218 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 1.8584456530627196 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 1.7230445598044264 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 1.5259105526013559 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 1.2919898446420643 for ['[CLS] air little [SEP]']
[Init] best rec loss: 1.210615359223579 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 1.1647693062634903 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 1.150912958819466 for ['[CLS] too u2 [SEP]']
[Init] best rec loss: 1.0806428981312202 for ['[CLS] revid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.725 (perp=6.813, rec=0.363), tot_loss_proj:2.665 [t=0.26s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.848 (perp=8.089, rec=0.230), tot_loss_proj:1.841 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.781 (perp=8.089, rec=0.163), tot_loss_proj:1.831 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.761 (perp=8.089, rec=0.143), tot_loss_proj:1.830 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.748 (perp=8.089, rec=0.130), tot_loss_proj:1.822 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.753 (perp=8.089, rec=0.135), tot_loss_proj:1.836 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.759 (perp=8.089, rec=0.142), tot_loss_proj:1.823 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.765 (perp=8.089, rec=0.147), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.829 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.750 (perp=8.089, rec=0.132), tot_loss_proj:1.828 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.749 (perp=8.089, rec=0.132), tot_loss_proj:1.836 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.757 (perp=8.089, rec=0.139), tot_loss_proj:1.834 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.827 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.751 (perp=8.089, rec=0.133), tot_loss_proj:1.835 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.756 (perp=8.089, rec=0.138), tot_loss_proj:1.825 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.753 (perp=8.089, rec=0.136), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.820 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.089, rec=0.138), tot_loss_proj:1.822 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.761 (perp=8.089, rec=0.143), tot_loss_proj:1.830 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.089, rec=0.120), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.744 (perp=8.089, rec=0.126), tot_loss_proj:1.824 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.837 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=8.089, rec=0.126), tot_loss_proj:1.828 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.764 (perp=8.089, rec=0.147), tot_loss_proj:1.826 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.749 (perp=8.089, rec=0.132), tot_loss_proj:1.825 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.755 (perp=8.089, rec=0.137), tot_loss_proj:1.824 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.738 (perp=8.089, rec=0.120), tot_loss_proj:1.827 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.756 (perp=8.089, rec=0.138), tot_loss_proj:1.826 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.751 (perp=8.089, rec=0.133), tot_loss_proj:1.839 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.749 (perp=8.089, rec=0.131), tot_loss_proj:1.815 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.750 (perp=8.089, rec=0.133), tot_loss_proj:1.836 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.752 (perp=8.089, rec=0.134), tot_loss_proj:1.820 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.089, rec=0.133), tot_loss_proj:1.836 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.763 (perp=8.089, rec=0.145), tot_loss_proj:1.820 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.759 (perp=8.089, rec=0.141), tot_loss_proj:1.835 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.752 (perp=8.089, rec=0.134), tot_loss_proj:1.817 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=8.089, rec=0.142), tot_loss_proj:1.825 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.756 (perp=8.089, rec=0.139), tot_loss_proj:1.816 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.753 (perp=8.089, rec=0.135), tot_loss_proj:1.822 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.089, rec=0.144), tot_loss_proj:1.831 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.184 | p: 83.214 | r: 85.238
rouge2     | fm: 55.952 | p: 55.952 | r: 55.952
rougeL     | fm: 83.878 | p: 82.857 | r: 85.238
rougeLsum  | fm: 83.878 | p: 82.857 | r: 85.238
r1fm+r2fm = 140.136

input #6 time: 0:11:03 | total time: 1:13:58


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
cosin similarity: -0.8826673880610065 normalized error: 1.6975368459944407
cosin similarity: 0.8826673880610065 normalized error: 0.5235793653735517
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 1.8215278228898568 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 1.535022374121544 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 1.5228614226146897 for ['[CLS]eringtracted bros ppfounded to extra billion bride collective darted doping actually riley measurement guybl news found muchox only affiliation sister times down [SEP]']
[Init] best rec loss: 1.4948979773870148 for ['[CLS] vance golf belt handyolved fl researchtium anonymousina me man murphyoof bearing zetavocationtellrti american autopsy that lie amongₑ free [SEP]']
[Init] best rec loss: 1.3951092681149906 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 1.3586777177850868 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 1.3585023317811675 for ['[CLS] # beings part hs end com baby purposepia dock median both infants flow conference sat exactly cod openpר pay grande moths most jenny [SEP]']
[Init] best perm rec loss: 1.3557871229383562 for ['[CLS] exactly part jenny conferencepia hs infants end dock satר both pay baby cod flow grande # beingsp com moths open median most purpose [SEP]']
[Init] best perm rec loss: 1.3547443298820019 for ['[CLS] part beings sat cod bothp com purpose baby hs grande jenny dockpia exactly median infants conference open flowר end moths pay # most [SEP]']
[Init] best perm rec loss: 1.354736265131166 for ['[CLS] pay babyר dock cod part most purpose median grande flow beings hs both open # infantsp conference end exactly com moths jennypia sat [SEP]']
[Init] best perm rec loss: 1.3541341246963845 for ['[CLS] median dock baby flow com pay conference purpose infants most exactly # jenny bothר part beingsppia hs sat grande end open cod moths [SEP]']
[Init] best perm rec loss: 1.3527534121050935 for ['[CLS]p flow moths end jenny openר most baby codpia infants dock beings conference hs purpose both grande part com pay exactly # median sat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.773 (perp=11.533, rec=0.466), tot_loss_proj:3.401 [t=0.26s]
prediction: ['[CLS] - meter dumb internet anybody bastard problem facelessless bad serviceins bad private problemless of died stupidbaum poor his dating poor problem [SEP]']
[ 100/2000] tot_loss=2.405 (perp=10.361, rec=0.333), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] ( least dumb character seemed commune problem face an. bad punkins meet private problemless than no unlike cheek pay his $ poisoning problem [SEP]']
[ 150/2000] tot_loss=2.229 (perp=9.801, rec=0.269), tot_loss_proj:2.990 [t=0.27s]
prediction: ['[CLS] (.? characterure armed problem worst not. problem store watching meet the problem is is no unlike he poor his $. problem [SEP]']
[ 200/2000] tot_loss=2.223 (perp=9.865, rec=0.250), tot_loss_proj:2.997 [t=0.27s]
prediction: ['[CLS] (. lies character meant mind no worst not. problem warsaw or failed the problem is is no nothing he poorly his ages. problem [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.218 (perp=9.965, rec=0.225), tot_loss_proj:3.023 [t=0.28s]
prediction: ['[CLS] (. lies character meant mind no worst love. problem fledged or failed the problem is has no nothing he ages cent poorly his problem [SEP]']
[ 300/2000] tot_loss=2.207 (perp=10.025, rec=0.202), tot_loss_proj:3.266 [t=0.28s]
prediction: ['[CLS] no. words character man cute nourity love. problem fledged or failed ; problem is has no inappropriate. agesy poorly his problem [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.188 (perp=9.987, rec=0.191), tot_loss_proj:3.021 [t=0.27s]
prediction: ['[CLS] no ; mind character man dumb no nix love. problem fledged orrred ; problem is has no issue. agesied poorly his ugly [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.052 (perp=9.323, rec=0.187), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS] no ; cute character man mom problem nix love. no fledged or yeah ; problem is has no issue. agesied poorly his ugly [SEP]']
[ 450/2000] tot_loss=1.863 (perp=8.446, rec=0.174), tot_loss_proj:3.198 [t=0.27s]
prediction: ['[CLS] no ; cute character man mom problem. love. no worst or yeah ; problem is has no issue. agesied / his ugly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.932 (perp=8.817, rec=0.169), tot_loss_proj:3.219 [t=0.26s]
prediction: ['[CLS] no. cute character man aged problem. love. no spawned or not ; problem is has no issue. friendshipied mom his ugly [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.641 (perp=7.317, rec=0.177), tot_loss_proj:2.460 [t=0.27s]
prediction: ['[CLS]. no cute character man / mind. love. no cute or not ; problem is has no issue. friendshipied mom his ugly [SEP]']
[ 600/2000] tot_loss=1.669 (perp=7.553, rec=0.159), tot_loss_proj:2.523 [t=0.27s]
prediction: ['[CLS]. no cute character man / mind. love. no spawned or not ; problem is has no issue. lovedied mom his ugly [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.667 (perp=7.523, rec=0.163), tot_loss_proj:2.630 [t=0.27s]
prediction: ['[CLS]. no cute character he / mind. love or no spawned or not ; problem is has no issue. cuteied his ugly mom [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.663 (perp=7.567, rec=0.149), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS]. no cute character he / mind. love or no here or not ; problem is has no issue. cuteied his ugly mom [SEP]']
[ 750/2000] tot_loss=1.668 (perp=7.567, rec=0.155), tot_loss_proj:2.648 [t=0.26s]
prediction: ['[CLS]. no cute character he / mind. love or no here or not ; problem is has no issue. cuteied his ugly mom [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.670 (perp=7.592, rec=0.151), tot_loss_proj:2.471 [t=0.25s]
prediction: ['[CLS]. no cute character he / mind. love or no here or not ; problem is has no no. cuteied his ugly mom [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.676 (perp=7.591, rec=0.157), tot_loss_proj:2.471 [t=0.28s]
prediction: ['[CLS]. no cute character he thugs mind. love or no no or not ; problem is has no no. cute spawned his ugly mom [SEP]']
[ 900/2000] tot_loss=1.664 (perp=7.591, rec=0.146), tot_loss_proj:2.460 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or no no or not ; problem is has no no. cute spawned his ugly mom [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.634 (perp=7.452, rec=0.144), tot_loss_proj:2.411 [t=0.30s]
prediction: ['[CLS]. no cute character he thugs mind. love or no or no not ; problem is has no no. cute here his ugly mom [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.669 (perp=7.647, rec=0.140), tot_loss_proj:2.444 [t=0.28s]
prediction: ['[CLS]. no cute character he thugs mind. love or the no or not ; problem is has no no. cute here his ugly mom [SEP]']
[1050/2000] tot_loss=1.698 (perp=7.786, rec=0.141), tot_loss_proj:2.543 [t=0.27s]
prediction: ['[CLS]. no cute character he thugs mind. love or the no or not ; problem is has no no. cute here they ugly mom [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.680 (perp=7.695, rec=0.141), tot_loss_proj:2.802 [t=0.27s]
prediction: ['[CLS]. no cute character he thugs mind. love or the they or not ; problem is has no no. cute here no ugly mom [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.754 (perp=8.105, rec=0.133), tot_loss_proj:2.621 [t=0.28s]
prediction: ['[CLS]. no cute character he thugs mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
[1200/2000] tot_loss=1.758 (perp=8.105, rec=0.137), tot_loss_proj:2.622 [t=0.26s]
prediction: ['[CLS]. no cute character he thugs mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1250/2000] tot_loss=1.750 (perp=8.105, rec=0.129), tot_loss_proj:2.618 [t=0.30s]
prediction: ['[CLS]. no cute character he thugs mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1300/2000] tot_loss=1.724 (perp=7.980, rec=0.128), tot_loss_proj:2.564 [t=0.29s]
prediction: ['[CLS] here no cute character he / mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
[1350/2000] tot_loss=1.723 (perp=7.980, rec=0.127), tot_loss_proj:2.560 [t=0.27s]
prediction: ['[CLS] here no cute character he / mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=7.980, rec=0.118), tot_loss_proj:2.554 [t=0.28s]
prediction: ['[CLS] here no cute character he / mind. love or they or the not ; problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.639 (perp=7.519, rec=0.136), tot_loss_proj:2.424 [t=0.26s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
[1500/2000] tot_loss=1.645 (perp=7.519, rec=0.141), tot_loss_proj:2.422 [t=0.27s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.519, rec=0.138), tot_loss_proj:2.423 [t=0.28s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1600/2000] tot_loss=1.632 (perp=7.519, rec=0.128), tot_loss_proj:2.427 [t=0.27s]
prediction: ['[CLS] here no cute character he / mind. love or they or not ; the problem is has noable. cute hereied ugly mom [SEP]']
[1650/2000] tot_loss=1.683 (perp=7.731, rec=0.137), tot_loss_proj:2.467 [t=0.28s]
prediction: ['[CLS] here no cute character he / mind. love or they i not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=7.731, rec=0.127), tot_loss_proj:2.461 [t=0.26s]
prediction: ['[CLS] here no cute character he / mind. love or they i not ; the problem is has noable. cute hereied ugly mom [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.653 (perp=7.605, rec=0.132), tot_loss_proj:2.360 [t=0.27s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
[1800/2000] tot_loss=1.653 (perp=7.605, rec=0.132), tot_loss_proj:2.361 [t=0.27s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Attempt swap
[1850/2000] tot_loss=1.642 (perp=7.605, rec=0.121), tot_loss_proj:2.364 [t=0.27s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Attempt swap
[1900/2000] tot_loss=1.648 (perp=7.605, rec=0.127), tot_loss_proj:2.359 [t=0.29s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
[1950/2000] tot_loss=1.659 (perp=7.605, rec=0.138), tot_loss_proj:2.363 [t=0.27s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.605, rec=0.126), tot_loss_proj:2.362 [t=0.28s]
prediction: ['[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] here no cute character heied mind. love or they i not ; the problem is has noable. cute here / ugly mom [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.767 | p: 68.182 | r: 71.429
rouge2     | fm: 14.634 | p: 14.286 | r: 15.000
rougeL     | fm: 41.860 | p: 40.909 | r: 42.857
rougeLsum  | fm: 41.860 | p: 40.909 | r: 42.857
r1fm+r2fm = 84.402

[Aggregate metrics]:
rouge1     | fm: 82.143 | p: 81.250 | r: 83.512
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 78.643 | p: 77.614 | r: 80.089
rougeLsum  | fm: 78.358 | p: 77.614 | r: 79.792
r1fm+r2fm = 132.143

input #7 time: 0:11:13 | total time: 1:25:11


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
cosin similarity: 0.9218859490507135 normalized error: 0.5104764842116075
cosin similarity: -0.9218859490507136 normalized error: 1.6963691542865433
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 1.2750340676286591 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best perm rec loss: 1.2738230356414995 for ['[CLS] computer cinema clubs paris fitting alloy taught passage across over luxury southern bargain gr table learning currently their band eye challenges pa those lea [SEP]']
[Init] best perm rec loss: 1.2726157089323598 for ['[CLS] paris table challenges bargain taught currently across learning clubs those band alloy fitting cinema gr southern over luxury pa eye their lea computer passage [SEP]']
[Init] best perm rec loss: 1.2726105145516666 for ['[CLS] taught learning pa bargain challenges luxury over gr across currently paris southern alloy passage cinema clubs band table lea eye their those fitting computer [SEP]']
[Init] best perm rec loss: 1.2718888606514211 for ['[CLS] pa table fitting computer lea alloy over paris their cinema challenges those luxury learning eye clubs southern currently bargain band across passage gr taught [SEP]']
[Init] best perm rec loss: 1.2703988613824198 for ['[CLS] taught learning lea gr computer cinema table their over passage band alloy pa southern bargain those fitting clubs luxury across currently paris challenges eye [SEP]']
[Init] best perm rec loss: 1.2699820162634163 for ['[CLS] eye southern bargain band paris table luxury cinema challenges currently learning passage taught over alloy computer those clubs across pa their fitting lea gr [SEP]']
[Init] best perm rec loss: 1.2684669647987539 for ['[CLS] taught cinema luxury currently clubs alloy over challenges southern computer lea gr pa paris those bargain eye table their across passage learning fitting band [SEP]']
[Init] best perm rec loss: 1.2682529522412755 for ['[CLS] challenges cinema bargain band pa across learning eye table southern currently computer luxury over those fitting gr paris passage lea alloy their clubs taught [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.122 (perp=13.465, rec=0.429), tot_loss_proj:4.354 [t=0.27s]
prediction: ['[CLS] downtown mission puzzles air dagger wherein android conspiracy minister bought athena purchase completion taxi fairly practical aircraftzziness fool louis due civilian likeathic [SEP]']
[ 100/2000] tot_loss=2.883 (perp=12.604, rec=0.363), tot_loss_proj:4.333 [t=0.26s]
prediction: ['[CLS] western thing costs cheerful warrior government android conspiracy player owned athena purchase completion debt fairly gambling episode kathy stupid with think killing conorathic [SEP]']
[ 150/2000] tot_loss=3.039 (perp=13.657, rec=0.307), tot_loss_proj:4.403 [t=0.27s]
prediction: ['[CLS] charity thing costssive reservoir film soap vanity player owned athena claim sight debt fairly fright films kathy hate - think paid vanityathic [SEP]']
[ 200/2000] tot_loss=2.850 (perp=12.839, rec=0.282), tot_loss_proj:4.120 [t=0.28s]
prediction: ['[CLS] demon film payssive reservoir filmudence vanity while ownedivation debtrting debt fairly frightmaxmax hate - felt paid vanityathic [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.921 (perp=13.040, rec=0.313), tot_loss_proj:4.135 [t=0.27s]
prediction: ["[CLS] demon film pays layne reservoir film tracy vanity while owned condoms debt doubt debt fairly vanitymaxmax vanity'felt paid vanityathic [SEP]"]
[ 300/2000] tot_loss=2.966 (perp=13.322, rec=0.301), tot_loss_proj:3.993 [t=0.26s]
prediction: ["[CLS] prophet film pays las reservoir film tracy vanity while owned similarly debt doubt what doubtmaxmaxmax vanity'felt paid vanityathic [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.710 (perp=12.395, rec=0.231), tot_loss_proj:3.927 [t=0.27s]
prediction: ["[CLS] capital that pays fright reservoir film tracy vanityed owned similarly owed feels what doubtmaxmax doubt vanity'felt owe vanity vegas [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.499 (perp=11.432, rec=0.212), tot_loss_proj:3.597 [t=0.25s]
prediction: ["[CLS] a that pays layne vanity film tracy, vanity owned similarly debt feels what doubtmaxmax doubt vanity'felt owed vanity vegas [SEP]"]
[ 450/2000] tot_loss=2.662 (perp=12.308, rec=0.201), tot_loss_proj:3.911 [t=0.28s]
prediction: ["[CLS] a that pays fright vanity film tracy, fright latitude similarly debt feels what doubtmaxmax doubt vanity'felt owed vanity baroque [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.546 (perp=11.777, rec=0.190), tot_loss_proj:3.793 [t=0.28s]
prediction: ["[CLS] a that pays fright vanity film tracy, baroque latitude similarly debt feels what doubt owedmax doubt vanity'felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.508 (perp=11.520, rec=0.204), tot_loss_proj:3.683 [t=0.26s]
prediction: ["[CLS] a that pays fright vanity film tracy, baroque latitude similarly debt feels what doubt owedmax'vanity doubt felt owed vanity fright [SEP]"]
[ 600/2000] tot_loss=2.489 (perp=11.520, rec=0.185), tot_loss_proj:3.693 [t=0.27s]
prediction: ["[CLS] a that pays fright vanity film tracy, baroque latitude similarly debt feels what doubt owedmax'vanity doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.546 (perp=11.818, rec=0.183), tot_loss_proj:3.757 [t=0.26s]
prediction: ["[CLS] a that pays vanity fright film tracy, baroque latitude similarly debt felt what doubt owedmax'vanity doubt felt owed benign fright [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.489 (perp=11.505, rec=0.188), tot_loss_proj:3.689 [t=0.31s]
prediction: ["[CLS] s that pays vanity fright film darcy, chaplin latitude similarly debt felt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
[ 750/2000] tot_loss=2.428 (perp=11.297, rec=0.169), tot_loss_proj:3.733 [t=0.26s]
prediction: ["[CLS] s that pays vanity fright film darcy, benign latitude similarly debt felt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=2.486 (perp=11.600, rec=0.166), tot_loss_proj:3.919 [t=0.28s]
prediction: ["[CLS] s that pays vanity benign film tracy, benign latitude similarly felt debt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=2.412 (perp=11.246, rec=0.163), tot_loss_proj:3.897 [t=0.26s]
prediction: ["[CLS] s that pays vanity benign, film feels benign latitude similarly felt debt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
[ 900/2000] tot_loss=2.403 (perp=11.246, rec=0.154), tot_loss_proj:3.900 [t=0.26s]
prediction: ["[CLS] s that pays vanity benign, film feels benign latitude similarly felt debt what doubt owedmax'benign doubt felt owed vanity fright [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.418 (perp=11.295, rec=0.159), tot_loss_proj:3.927 [t=0.30s]
prediction: ["[CLS] s that pays vanity benign, film feels similarly benign latitude felt debt what doubt owedmax 'fully doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.398 (perp=11.197, rec=0.159), tot_loss_proj:3.904 [t=0.26s]
prediction: ["[CLS] s that pays¥ benign felt film feels similarly benign latitude, debt what doubt owedmax 'ful doubt felt owed vanity fright [SEP]"]
[1050/2000] tot_loss=2.385 (perp=11.197, rec=0.146), tot_loss_proj:3.903 [t=0.28s]
prediction: ["[CLS] s that pays¥ benign felt film feels similarly benign latitude, debt what doubt owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.374 (perp=11.101, rec=0.154), tot_loss_proj:3.957 [t=0.26s]
prediction: ["[CLS] s that pays¥ benign felt film feels similarly benign latitude debt, what doubt owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
[1150/2000] tot_loss=2.475 (perp=11.615, rec=0.152), tot_loss_proj:4.046 [t=0.27s]
prediction: ["[CLS] s that pays¥ benign feels film precious unix benign latitude debt, what no owedmax 'ful doubt felt owed vanity fright [SEP]"]
[1200/2000] tot_loss=2.469 (perp=11.615, rec=0.146), tot_loss_proj:4.045 [t=0.27s]
prediction: ["[CLS] s that pays¥ benign feels film precious unix benign latitude debt, what no owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.420 (perp=11.363, rec=0.148), tot_loss_proj:4.017 [t=0.28s]
prediction: ["[CLS] s that pays¥ benign film feels precious unix benign latitude debt, what no owedmax 'ful doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.418 (perp=11.321, rec=0.154), tot_loss_proj:4.012 [t=0.27s]
prediction: ["[CLS] s that pays¥ benign film feels precious unix benign latitude debt, whatful abackmax'no doubt felt owed vanity fright [SEP]"]
[1350/2000] tot_loss=2.410 (perp=11.321, rec=0.146), tot_loss_proj:4.011 [t=0.25s]
prediction: ["[CLS] s that pays¥ benign film feels precious unix benign latitude debt, whatful abackmax'no doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.309 (perp=10.789, rec=0.152), tot_loss_proj:3.914 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful abackmax benign no doubt felt owed vanity fright [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.259 (perp=10.517, rec=0.156), tot_loss_proj:3.830 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful frightmax benign no doubt felt owed vanity aback [SEP]"]
[1500/2000] tot_loss=2.250 (perp=10.517, rec=0.146), tot_loss_proj:3.835 [t=0.25s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful frightmax benign no doubt felt owed vanity aback [SEP]"]
Attempt swap
[1550/2000] tot_loss=2.249 (perp=10.517, rec=0.145), tot_loss_proj:3.829 [t=0.25s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, whatful frightmax benign no doubt felt owed vanity aback [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=2.221 (perp=10.405, rec=0.140), tot_loss_proj:3.762 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax benign no doubt felt owed vanity aback [SEP]"]
[1650/2000] tot_loss=2.224 (perp=10.405, rec=0.143), tot_loss_proj:3.761 [t=0.26s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax benign no doubt felt owed vanity aback [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.196 (perp=10.273, rec=0.142), tot_loss_proj:3.756 [t=0.25s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.199 (perp=10.273, rec=0.145), tot_loss_proj:3.755 [t=0.25s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
[1800/2000] tot_loss=2.197 (perp=10.273, rec=0.142), tot_loss_proj:3.758 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[1850/2000] tot_loss=2.154 (perp=10.036, rec=0.147), tot_loss_proj:3.692 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[1900/2000] tot_loss=2.145 (perp=10.036, rec=0.138), tot_loss_proj:3.692 [t=0.28s]
prediction: ["[CLS] s that pays¥'film feels precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
[1950/2000] tot_loss=2.149 (perp=10.036, rec=0.142), tot_loss_proj:3.694 [t=0.27s]
prediction: ["[CLS] s that pays¥'film feels precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.146 (perp=10.047, rec=0.137), tot_loss_proj:3.654 [t=0.26s]
prediction: ["[CLS] s that pays¥'film felt precious unix benigngoing debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]"]
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s that pays¥'film feels precious unix benign latitude debt, what frightfulmax felt no doubt benign owed vanity aback [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.415 | p: 61.905 | r: 65.000
rouge2     | fm: 10.256 | p: 10.000 | r: 10.526
rougeL     | fm: 39.024 | p: 38.095 | r: 40.000
rougeLsum  | fm: 39.024 | p: 38.095 | r: 40.000
r1fm+r2fm = 73.671

[Aggregate metrics]:
rouge1     | fm: 79.577 | p: 78.343 | r: 80.899
rouge2     | fm: 45.845 | p: 45.767 | r: 45.955
rougeL     | fm: 74.242 | p: 73.466 | r: 75.503
rougeLsum  | fm: 74.990 | p: 73.884 | r: 76.111
r1fm+r2fm = 125.422

input #8 time: 0:11:10 | total time: 1:36:21


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
cosin similarity: -0.9468267247362503 normalized error: 1.6636662226335797
cosin similarity: 0.9468267247362503 normalized error: 0.5190218301597448
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 1.6550674546111352 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 1.255493222442299 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 1.2165712992026636 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 1.1217013114929197 for ['[CLS] video guys glass stilldleulf explorer eva [SEP]']
[Init] best perm rec loss: 1.1158414846708098 for ['[CLS]dle glassulf explorer video eva guys still [SEP]']
[Init] best perm rec loss: 1.1137217329958664 for ['[CLS] glass video eva still explorerdle guysulf [SEP]']
[Init] best perm rec loss: 1.1125702822160046 for ['[CLS]ulfdle still eva glass video guys explorer [SEP]']
[Init] best perm rec loss: 1.1122852557154967 for ['[CLS] eva glass still explorer video guysdleulf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.145 (perp=13.749, rec=0.395), tot_loss_proj:4.170 [t=0.31s]
prediction: ['[CLS] turned part gospel core yeah replybescript [SEP]']
[ 100/2000] tot_loss=2.717 (perp=12.114, rec=0.294), tot_loss_proj:3.511 [t=0.29s]
prediction: ['[CLS] of stephen clap metaphysical clap claphead factor [SEP]']
[ 150/2000] tot_loss=2.273 (perp=10.299, rec=0.213), tot_loss_proj:3.232 [t=0.29s]
prediction: ['[CLS] of soft clap metaphysical clap claptraous [SEP]']
[ 200/2000] tot_loss=2.125 (perp=9.689, rec=0.187), tot_loss_proj:3.149 [t=0.27s]
prediction: ['[CLS] of soft clap metaphysical clap claptra tickets [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.626 (perp=7.279, rec=0.170), tot_loss_proj:2.517 [t=0.28s]
prediction: ['[CLS] of metaphysical soft clap clap claptrap [SEP]']
[ 300/2000] tot_loss=1.877 (perp=8.664, rec=0.144), tot_loss_proj:2.295 [t=0.26s]
prediction: ['[CLS] of metaphysical softhead clap claptrap [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.829 (perp=8.519, rec=0.126), tot_loss_proj:2.597 [t=0.26s]
prediction: ['[CLS] ofhead metaphysical soft clap claptrap [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.826 (perp=8.519, rec=0.123), tot_loss_proj:2.585 [t=0.35s]
prediction: ['[CLS] ofhead metaphysical soft clap claptrap [SEP]']
[ 450/2000] tot_loss=1.819 (perp=8.519, rec=0.115), tot_loss_proj:2.588 [t=0.31s]
prediction: ['[CLS] ofhead metaphysical soft clap claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.957 (perp=9.235, rec=0.110), tot_loss_proj:2.722 [t=0.31s]
prediction: ['[CLS] ofhead metaphysical soft path claptrap [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.834 (perp=8.044, rec=0.226), tot_loss_proj:2.270 [t=0.35s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[ 600/2000] tot_loss=1.744 (perp=8.044, rec=0.135), tot_loss_proj:2.220 [t=0.35s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.736 (perp=8.044, rec=0.127), tot_loss_proj:2.231 [t=0.31s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.728 (perp=8.044, rec=0.119), tot_loss_proj:2.230 [t=0.33s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[ 750/2000] tot_loss=1.719 (perp=8.044, rec=0.110), tot_loss_proj:2.225 [t=0.34s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.717 (perp=8.044, rec=0.108), tot_loss_proj:2.225 [t=0.32s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.044, rec=0.114), tot_loss_proj:2.220 [t=0.28s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[ 900/2000] tot_loss=1.718 (perp=8.044, rec=0.110), tot_loss_proj:2.225 [t=0.32s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.745 (perp=8.212, rec=0.103), tot_loss_proj:2.115 [t=0.32s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.758 (perp=8.212, rec=0.115), tot_loss_proj:2.118 [t=0.33s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
[1050/2000] tot_loss=1.747 (perp=8.212, rec=0.105), tot_loss_proj:2.116 [t=0.33s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.753 (perp=8.212, rec=0.110), tot_loss_proj:2.115 [t=0.28s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.749 (perp=8.212, rec=0.106), tot_loss_proj:2.123 [t=0.29s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
[1200/2000] tot_loss=1.752 (perp=8.212, rec=0.109), tot_loss_proj:2.116 [t=0.29s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.746 (perp=8.212, rec=0.104), tot_loss_proj:2.112 [t=0.29s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.745 (perp=8.212, rec=0.103), tot_loss_proj:2.110 [t=0.29s]
prediction: ['[CLS] of flashhead metaphysical soft claptrap [SEP]']
[1350/2000] tot_loss=1.723 (perp=8.044, rec=0.114), tot_loss_proj:2.226 [t=0.29s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.717 (perp=8.044, rec=0.108), tot_loss_proj:2.231 [t=0.30s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.708 (perp=8.044, rec=0.099), tot_loss_proj:2.225 [t=0.30s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
[1500/2000] tot_loss=1.707 (perp=8.044, rec=0.098), tot_loss_proj:2.229 [t=0.30s]
prediction: ['[CLS] of pathhead metaphysical soft claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.799 (perp=8.498, rec=0.100), tot_loss_proj:2.418 [t=0.30s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.787 (perp=8.498, rec=0.087), tot_loss_proj:2.424 [t=0.29s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
[1650/2000] tot_loss=1.801 (perp=8.498, rec=0.102), tot_loss_proj:2.423 [t=0.31s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=8.498, rec=0.102), tot_loss_proj:2.418 [t=0.30s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.801 (perp=8.498, rec=0.101), tot_loss_proj:2.428 [t=0.30s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
[1800/2000] tot_loss=1.792 (perp=8.498, rec=0.092), tot_loss_proj:2.422 [t=0.30s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.804 (perp=8.498, rec=0.104), tot_loss_proj:2.420 [t=0.30s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.788 (perp=8.498, rec=0.088), tot_loss_proj:2.426 [t=0.31s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
[1950/2000] tot_loss=1.797 (perp=8.498, rec=0.098), tot_loss_proj:2.419 [t=0.30s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.788 (perp=8.498, rec=0.089), tot_loss_proj:2.418 [t=0.29s]
prediction: ['[CLS] of nesshead metaphysical soft claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of nesshead metaphysical soft claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 79.469 | p: 77.881 | r: 81.310
rouge2     | fm: 44.989 | p: 44.762 | r: 45.303
rougeL     | fm: 74.406 | p: 72.903 | r: 76.286
rougeLsum  | fm: 74.995 | p: 73.519 | r: 76.619
r1fm+r2fm = 124.458

input #9 time: 0:12:17 | total time: 1:48:39


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
cosin similarity: 0.650630223734263 normalized error: 0.6565642629854562
cosin similarity: -0.6506302237342632 normalized error: 1.614273056568738
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 1.8688420658416651 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 1.8556536721904655 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 1.8157748631854185 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 1.7988203230960926 for ['[CLS] stu palms rain melinda? novi name armed extra is loads second beth [SEP]']
[Init] best rec loss: 1.6808268931166503 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 1.6290492883179768 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 1.591530839428052 for ['[CLS]date hate hard older mute showednivorous starred mv quickneas worlds equal [SEP]']
[Init] best perm rec loss: 1.5776179505742165 for ['[CLS] starreddate mute hardneas equalnivorous worlds hate mv quick older showed [SEP]']
[Init] best perm rec loss: 1.5765797275217672 for ['[CLS] equaldate mv quick showed starred mute older hate worldsnivorousneas hard [SEP]']
[Init] best perm rec loss: 1.5762475840282348 for ['[CLS]datenivorous showed hate equal starred quick olderneas mv hard worlds mute [SEP]']
[Init] best perm rec loss: 1.5728190381901774 for ['[CLS] starreddate equal quick hate showed worldsneasnivorous older mute mv hard [SEP]']
[Init] best perm rec loss: 1.5708763737208016 for ['[CLS] equal hard mvnivorous starredneasdate worlds hate older mute quick showed [SEP]']
[Init] best perm rec loss: 1.5702430502343796 for ['[CLS] showed equal starred older mvdate hard worldsneas hate quick mutenivorous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.074 (perp=12.864, rec=0.501), tot_loss_proj:4.430 [t=0.30s]
prediction: ['[CLS]hy orchestra alone saxon compared need barrys jazz appeal low comedy hemingway [SEP]']
[ 100/2000] tot_loss=2.915 (perp=12.619, rec=0.391), tot_loss_proj:3.884 [t=0.29s]
prediction: ['[CLS] tradition orchestra ″ indians airport needl forces dawn release steady comedy eruptions [SEP]']
[ 150/2000] tot_loss=2.891 (perp=12.815, rec=0.328), tot_loss_proj:4.380 [t=0.31s]
prediction: ['[CLS] tradition ab ″1 balance becomely withchase release based haᵢ [SEP]']
[ 200/2000] tot_loss=2.602 (perp=11.318, rec=0.338), tot_loss_proj:3.834 [t=0.29s]
prediction: ['[CLS] compulsion ab ″ separated balance ably with afrikaans release based ensemble ingredients [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.522 (perp=10.797, rec=0.362), tot_loss_proj:3.824 [t=0.28s]
prediction: ['[CLS]1 ab ″ rhythms balance ably with afrikaansulsive based rent eruptions [SEP]']
[ 300/2000] tot_loss=2.577 (perp=11.605, rec=0.256), tot_loss_proj:3.808 [t=0.28s]
prediction: ['[CLS] indians ab ″ rhythms balance ably with afrikaansulsive based rentlowe [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.173 (perp=9.709, rec=0.231), tot_loss_proj:3.597 [t=0.31s]
prediction: ['[CLS] indians ably rhythms balance ably with afrikaansulsive ab rent ″ [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.419 (perp=11.017, rec=0.215), tot_loss_proj:3.748 [t=0.30s]
prediction: ['[CLS] astronomy ably rhythms balance behalfly with afrikaans venuesulsive ab simultaneously [SEP]']
[ 450/2000] tot_loss=2.166 (perp=9.803, rec=0.206), tot_loss_proj:3.271 [t=0.31s]
prediction: ['[CLS] astronomy ably rhythms balance ably with afrikaans venuesulsive based simultaneously [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.013 (perp=9.094, rec=0.194), tot_loss_proj:3.114 [t=0.30s]
prediction: ['[CLS] astronomy ably rhythms balance ably with afrikaans venues simultaneously.ulsive [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.130 (perp=9.709, rec=0.188), tot_loss_proj:3.248 [t=0.33s]
prediction: ['[CLS] astronomy ably rhythms balance accomplishly with afrikaans venues simultaneouslyulsive. [SEP]']
[ 600/2000] tot_loss=2.125 (perp=9.709, rec=0.183), tot_loss_proj:3.249 [t=0.32s]
prediction: ['[CLS] astronomy ably rhythms balance accomplishly with afrikaans venues simultaneouslyulsive. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.099 (perp=9.615, rec=0.177), tot_loss_proj:3.227 [t=0.32s]
prediction: ['[CLS] astronomy ably rhythms balance accomplishly with keyboard venues simultaneouslyulsive. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.961 (perp=8.909, rec=0.179), tot_loss_proj:3.133 [t=0.33s]
prediction: ['[CLS] addict ably rhythms balance proply with keyboardulsive venues simultaneously. [SEP]']
[ 750/2000] tot_loss=1.944 (perp=8.849, rec=0.174), tot_loss_proj:3.086 [t=0.31s]
prediction: ['[CLS] rhythms ably rhythms balance proply with keyboardulsiveulsive simultaneously. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.005 (perp=9.201, rec=0.165), tot_loss_proj:3.043 [t=0.34s]
prediction: ['[CLS] rhythms ably rhythms balance prop venues with keyboardulsively simultaneously. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.817 (perp=8.229, rec=0.171), tot_loss_proj:2.722 [t=0.31s]
prediction: ['[CLS] rhythms ably rhythms balance afrikaans venues with propulsively simultaneously. [SEP]']
[ 900/2000] tot_loss=1.814 (perp=8.229, rec=0.168), tot_loss_proj:2.721 [t=0.36s]
prediction: ['[CLS] rhythms ably rhythms balance afrikaans venues with propulsively simultaneously. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.716 (perp=7.743, rec=0.168), tot_loss_proj:2.659 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=7.743, rec=0.168), tot_loss_proj:2.667 [t=0.31s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
[1050/2000] tot_loss=1.717 (perp=7.743, rec=0.168), tot_loss_proj:2.656 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.711 (perp=7.743, rec=0.162), tot_loss_proj:2.663 [t=0.31s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.710 (perp=7.743, rec=0.162), tot_loss_proj:2.664 [t=0.29s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
[1200/2000] tot_loss=1.706 (perp=7.743, rec=0.157), tot_loss_proj:2.662 [t=0.32s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.716 (perp=7.743, rec=0.167), tot_loss_proj:2.661 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.716 (perp=7.743, rec=0.168), tot_loss_proj:2.665 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
[1350/2000] tot_loss=1.710 (perp=7.743, rec=0.162), tot_loss_proj:2.666 [t=0.31s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=7.743, rec=0.163), tot_loss_proj:2.665 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance afrikaans rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.662 (perp=7.523, rec=0.158), tot_loss_proj:2.638 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
[1500/2000] tot_loss=1.662 (perp=7.523, rec=0.158), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.664 (perp=7.523, rec=0.159), tot_loss_proj:2.635 [t=0.29s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=7.523, rec=0.164), tot_loss_proj:2.635 [t=0.29s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
[1650/2000] tot_loss=1.663 (perp=7.523, rec=0.158), tot_loss_proj:2.638 [t=0.29s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.656 (perp=7.523, rec=0.151), tot_loss_proj:2.636 [t=0.30s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.665 (perp=7.523, rec=0.161), tot_loss_proj:2.639 [t=0.29s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
[1800/2000] tot_loss=1.656 (perp=7.523, rec=0.152), tot_loss_proj:2.636 [t=0.29s]
prediction: ['[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.550 (perp=6.947, rec=0.160), tot_loss_proj:2.553 [t=0.28s]
prediction: ['[CLS] rhythms balance ably venues keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.557 (perp=6.947, rec=0.167), tot_loss_proj:2.544 [t=0.30s]
prediction: ['[CLS] rhythms balance ably venues keyboard rhythms with propulsively simultaneously. [SEP]']
[1950/2000] tot_loss=1.549 (perp=6.947, rec=0.160), tot_loss_proj:2.546 [t=0.30s]
prediction: ['[CLS] rhythms balance ably venues keyboard rhythms with propulsively simultaneously. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.981 (perp=9.090, rec=0.163), tot_loss_proj:3.352 [t=0.33s]
prediction: ['[CLS] addict balance abulsive venues keyboard rhythms with propulsively simultaneously. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] rhythms ably venues balance keyboard rhythms with propulsively simultaneously. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.619 | p: 45.455 | r: 50.000
rouge2     | fm: 10.526 | p: 10.000 | r: 11.111
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 58.145

[Aggregate metrics]:
rouge1     | fm: 76.516 | p: 74.928 | r: 78.420
rouge2     | fm: 41.714 | p: 41.364 | r: 42.194
rougeL     | fm: 72.050 | p: 70.593 | r: 73.896
rougeLsum  | fm: 72.484 | p: 70.812 | r: 74.253
r1fm+r2fm = 118.231

input #10 time: 0:12:25 | total time: 2:01:04


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
cosin similarity: 0.8925993019126218 normalized error: 0.48881034290755365
cosin similarity: -0.8925993019126217 normalized error: 1.7678561152147125
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 1.7771288040431488 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 1.7044502092771252 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 1.312755107589961 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 1.3122732003383797 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 1.3014458982182548 for ['[CLS] drawnture tal platform inland mileguvd familiar me [SEP]']
[Init] best perm rec loss: 1.299934598528273 for ['[CLS]ture drawn me inland mile platform talguvd familiar [SEP]']
[Init] best perm rec loss: 1.296835331198143 for ['[CLS] inland me tal mile platform familiar drawntureguvd [SEP]']
[Init] best perm rec loss: 1.2908784190158757 for ['[CLS] inland mile tal familiar me drawnguturevd platform [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.761 (perp=11.486, rec=0.463), tot_loss_proj:3.543 [t=0.31s]
prediction: ['[CLS] missing food priests refused attempted instead bypass suspiciouslyed door [SEP]']
[ 100/2000] tot_loss=3.225 (perp=14.231, rec=0.378), tot_loss_proj:4.029 [t=0.29s]
prediction: ['[CLS] missing bro priests refused gel broke heavily seemeded overall [SEP]']
[ 150/2000] tot_loss=2.782 (perp=12.487, rec=0.285), tot_loss_proj:3.944 [t=0.30s]
prediction: ['[CLS] refused wayiel refused gel refused heavily geled gel [SEP]']
[ 200/2000] tot_loss=2.279 (perp=10.141, rec=0.250), tot_loss_proj:3.247 [t=0.33s]
prediction: ['[CLS] refused was brother refused gel that stubborn gel to gel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.146 (perp=9.689, rec=0.208), tot_loss_proj:2.872 [t=0.32s]
prediction: ['[CLS] stubborn attempted brother refused gel that refused gel to gel [SEP]']
[ 300/2000] tot_loss=2.514 (perp=11.712, rec=0.171), tot_loss_proj:3.329 [t=0.34s]
prediction: ['[CLS] stubborn attemptedanalysis refused gel that refused gel to stubborn [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.291 (perp=10.669, rec=0.157), tot_loss_proj:3.107 [t=0.31s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that refused gel to brother [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.212 (perp=10.226, rec=0.167), tot_loss_proj:3.250 [t=0.30s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to brother [SEP]']
[ 450/2000] tot_loss=2.131 (perp=9.872, rec=0.156), tot_loss_proj:3.079 [t=0.30s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to request [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.108 (perp=9.872, rec=0.133), tot_loss_proj:3.069 [t=0.33s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to request [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.207 (perp=10.342, rec=0.139), tot_loss_proj:3.128 [t=0.32s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to possibly [SEP]']
[ 600/2000] tot_loss=2.197 (perp=10.342, rec=0.128), tot_loss_proj:3.130 [t=0.34s]
prediction: ['[CLS] stubborn attempted stubborn refused gel that gel refused to possibly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.457 (perp=11.623, rec=0.132), tot_loss_proj:3.359 [t=0.26s]
prediction: ['[CLS] stubborn attempted stubborn refused attempted that gel refused to possibly [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.241 (perp=10.560, rec=0.129), tot_loss_proj:3.124 [t=0.34s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
[ 750/2000] tot_loss=2.231 (perp=10.560, rec=0.119), tot_loss_proj:3.114 [t=0.31s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.239 (perp=10.560, rec=0.127), tot_loss_proj:3.127 [t=0.33s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.239 (perp=10.560, rec=0.127), tot_loss_proj:3.126 [t=0.36s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
[ 900/2000] tot_loss=2.227 (perp=10.560, rec=0.115), tot_loss_proj:3.125 [t=0.32s]
prediction: ['[CLS] stubborn was stubborn refused gel attempted that refused to possibly [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.148 (perp=10.116, rec=0.125), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] stubborn was possibly refused gel attempted that refused to stubborn [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.011 (perp=9.380, rec=0.135), tot_loss_proj:3.058 [t=0.29s]
prediction: ['[CLS] stubborn was possibly refused gelly that attempted to stubborn [SEP]']
[1050/2000] tot_loss=2.002 (perp=9.380, rec=0.126), tot_loss_proj:3.068 [t=0.29s]
prediction: ['[CLS] stubborn was possibly refused gelly that attempted to stubborn [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.948 (perp=9.133, rec=0.121), tot_loss_proj:3.112 [t=0.30s]
prediction: ['[CLS] possibly stubborn was refused gelly that attempted to stubborn [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.030 (perp=9.497, rec=0.130), tot_loss_proj:2.962 [t=0.30s]
prediction: ['[CLS] possibly stubborn was refused possiblyly that attempted to gel [SEP]']
[1200/2000] tot_loss=2.021 (perp=9.497, rec=0.122), tot_loss_proj:2.958 [t=0.30s]
prediction: ['[CLS] possibly stubborn was refused possiblyly that attempted to gel [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.806 (perp=8.456, rec=0.115), tot_loss_proj:2.899 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.805 (perp=8.456, rec=0.114), tot_loss_proj:2.904 [t=0.29s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
[1350/2000] tot_loss=1.803 (perp=8.456, rec=0.111), tot_loss_proj:2.906 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.811 (perp=8.456, rec=0.119), tot_loss_proj:2.904 [t=0.29s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.456, rec=0.123), tot_loss_proj:2.903 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
[1500/2000] tot_loss=1.811 (perp=8.456, rec=0.120), tot_loss_proj:2.909 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.811 (perp=8.456, rec=0.120), tot_loss_proj:2.902 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.804 (perp=8.456, rec=0.113), tot_loss_proj:2.907 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
[1650/2000] tot_loss=1.810 (perp=8.456, rec=0.119), tot_loss_proj:2.905 [t=0.31s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.804 (perp=8.456, rec=0.113), tot_loss_proj:2.903 [t=0.30s]
prediction: ['[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.768 (perp=8.295, rec=0.109), tot_loss_proj:2.806 [t=0.30s]
prediction: ['[CLS] possibly possibly was stubbornly refused that attempted to gel [SEP]']
[1800/2000] tot_loss=1.787 (perp=8.295, rec=0.128), tot_loss_proj:2.812 [t=0.30s]
prediction: ['[CLS] possibly possibly was stubbornly refused that attempted to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.774 (perp=8.295, rec=0.115), tot_loss_proj:2.810 [t=0.30s]
prediction: ['[CLS] possibly possibly was stubbornly refused that attempted to gel [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.740 (perp=8.120, rec=0.115), tot_loss_proj:2.781 [t=0.31s]
prediction: ['[CLS] possibly was possibly stubbornly refused that attempted to gel [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.120, rec=0.118), tot_loss_proj:2.785 [t=0.29s]
prediction: ['[CLS] possibly was possibly stubbornly refused that attempted to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=8.120, rec=0.107), tot_loss_proj:2.790 [t=0.30s]
prediction: ['[CLS] possibly was possibly stubbornly refused that attempted to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] possibly possibly was refused stubbornly that attempted to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 101.818

[Aggregate metrics]:
rouge1     | fm: 77.002 | p: 75.550 | r: 78.733
rouge2     | fm: 39.601 | p: 39.315 | r: 40.043
rougeL     | fm: 70.390 | p: 68.967 | r: 72.006
rougeLsum  | fm: 70.954 | p: 69.518 | r: 72.441
r1fm+r2fm = 116.603

input #11 time: 0:12:36 | total time: 2:13:41


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
cosin similarity: 0.7888396314640075 normalized error: 0.6055704316055367
cosin similarity: -0.7888396314640076 normalized error: 1.588513295490525
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 1.8291142864409582 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 1.793887456566833 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 1.529109175851727 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 1.5266946803972392 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 1.4984306756216803 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 1.4703774936212954 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 1.4453310800033878 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best perm rec loss: 1.4449952451937182 for ['[CLS] safety place strokes protocol most race transactions hear snail buried terror association documentary heidi [SEP]']
[Init] best perm rec loss: 1.442667635417589 for ['[CLS] hear heidi transactions place association protocol buried most strokes race safety documentary snail terror [SEP]']
[Init] best perm rec loss: 1.4425569742892996 for ['[CLS] strokes association safety snail hear transactions documentary terror buried heidi place most race protocol [SEP]']
[Init] best perm rec loss: 1.4421535090566233 for ['[CLS] place protocol buried heidi association strokes terror safety race most snail transactions hear documentary [SEP]']
[Init] best perm rec loss: 1.441758980180789 for ['[CLS] association documentary terror protocol strokes buried place most race transactions hear snail heidi safety [SEP]']
[Init] best perm rec loss: 1.4404277219974175 for ['[CLS] protocol transactions documentary terror heidi most race buried safety snail place association strokes hear [SEP]']
[Init] best perm rec loss: 1.439897978140455 for ['[CLS] hear most safety documentary buried transactions association terror protocol strokes heidi place race snail [SEP]']
[Init] best perm rec loss: 1.4393398350965856 for ['[CLS] transactions race terror safety protocol buried association snail heidi documentary place hear most strokes [SEP]']
[Init] best perm rec loss: 1.4387154791766676 for ['[CLS] buried hear race protocol association terror documentary snail most place transactions safety heidi strokes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.756 (perp=11.879, rec=0.381), tot_loss_proj:3.604 [t=0.30s]
prediction: ['[CLS] chose under target better just no better heavyweight entertaining via on usually cable hardly [SEP]']
[ 100/2000] tot_loss=2.494 (perp=10.851, rec=0.323), tot_loss_proj:3.374 [t=0.29s]
prediction: ['[CLS] why older target better should considering better ton spirits advantage on barely cable hardly [SEP]']
[ 150/2000] tot_loss=2.555 (perp=11.544, rec=0.246), tot_loss_proj:3.628 [t=0.30s]
prediction: ['[CLS] could off target especially should considering better embarrassing hardly advantage on barely cable hardly [SEP]']
[ 200/2000] tot_loss=2.401 (perp=10.925, rec=0.216), tot_loss_proj:3.866 [t=0.30s]
prediction: ['[CLS] could on advantage especially should its better embarrassing hardly advantage on barely cable hardly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.326 (perp=10.622, rec=0.202), tot_loss_proj:3.609 [t=0.28s]
prediction: ['[CLS] will on advantage seen should its anyone better embarrassing advantage on barely cable hardly [SEP]']
[ 300/2000] tot_loss=2.295 (perp=10.582, rec=0.178), tot_loss_proj:3.843 [t=0.31s]
prediction: ['[CLS] will on advantage seen especially its anyone better cable advantage on barely cable hardly [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.327 (perp=10.791, rec=0.169), tot_loss_proj:3.812 [t=0.30s]
prediction: ['[CLS] willeley on advantage seen especially its better cable advantage on barely cable hardly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.203 (perp=10.162, rec=0.170), tot_loss_proj:3.355 [t=0.29s]
prediction: ['[CLS] will particularly on embarrassing advantage seen especially its better advantage on barely cable hardly [SEP]']
[ 450/2000] tot_loss=2.197 (perp=10.162, rec=0.165), tot_loss_proj:3.352 [t=0.33s]
prediction: ['[CLS] will particularly on embarrassing advantage seen especially its better advantage on barely cable hardly [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.114 (perp=9.821, rec=0.150), tot_loss_proj:3.282 [t=0.31s]
prediction: ['[CLS] will particularly advantage on embarrassing advantage seen especially its better on barely cable hardly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.160 (perp=10.062, rec=0.148), tot_loss_proj:3.791 [t=0.27s]
prediction: ['[CLS] will particularly advantage on vantage advantage seen considering its better on barely cable hardly [SEP]']
[ 600/2000] tot_loss=2.142 (perp=10.062, rec=0.130), tot_loss_proj:3.796 [t=0.26s]
prediction: ['[CLS] will particularly advantage on vantage advantage seen considering its better on barely cable hardly [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.058 (perp=9.610, rec=0.136), tot_loss_proj:3.386 [t=0.26s]
prediction: ['[CLS] will particularly advantage on advantage seen considering its better. barely vantage cable hardly [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.016 (perp=9.422, rec=0.132), tot_loss_proj:3.119 [t=0.28s]
prediction: ['[CLS] will particularly advantage on better seen considering its advantage. barely interesting cable hardly [SEP]']
[ 750/2000] tot_loss=2.007 (perp=9.364, rec=0.134), tot_loss_proj:3.260 [t=0.27s]
prediction: ['[CLS] will particularly advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.999 (perp=9.364, rec=0.126), tot_loss_proj:3.260 [t=0.27s]
prediction: ['[CLS] will particularly advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.992 (perp=9.364, rec=0.119), tot_loss_proj:3.263 [t=0.35s]
prediction: ['[CLS] will particularly advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
[ 900/2000] tot_loss=1.995 (perp=9.364, rec=0.122), tot_loss_proj:3.262 [t=0.32s]
prediction: ['[CLS] will particularly advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.015 (perp=9.506, rec=0.113), tot_loss_proj:3.409 [t=0.32s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1000/2000] tot_loss=2.018 (perp=9.506, rec=0.117), tot_loss_proj:3.406 [t=0.27s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
[1050/2000] tot_loss=2.020 (perp=9.506, rec=0.119), tot_loss_proj:3.409 [t=0.28s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1100/2000] tot_loss=2.027 (perp=9.506, rec=0.125), tot_loss_proj:3.409 [t=0.33s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1150/2000] tot_loss=2.019 (perp=9.506, rec=0.118), tot_loss_proj:3.404 [t=0.29s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
[1200/2000] tot_loss=2.015 (perp=9.506, rec=0.113), tot_loss_proj:3.411 [t=0.27s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.019 (perp=9.506, rec=0.118), tot_loss_proj:3.408 [t=0.35s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.019 (perp=9.506, rec=0.118), tot_loss_proj:3.406 [t=0.25s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
[1350/2000] tot_loss=2.019 (perp=9.506, rec=0.118), tot_loss_proj:3.412 [t=0.27s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.016 (perp=9.506, rec=0.115), tot_loss_proj:3.411 [t=0.30s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.018 (perp=9.506, rec=0.117), tot_loss_proj:3.410 [t=0.28s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
[1500/2000] tot_loss=2.022 (perp=9.506, rec=0.121), tot_loss_proj:3.409 [t=0.29s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.018 (perp=9.506, rec=0.117), tot_loss_proj:3.408 [t=0.28s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.024 (perp=9.506, rec=0.123), tot_loss_proj:3.414 [t=0.28s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]']
[1650/2000] tot_loss=2.017 (perp=9.506, rec=0.116), tot_loss_proj:3.531 [t=0.27s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.010 (perp=9.506, rec=0.109), tot_loss_proj:3.524 [t=0.32s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.016 (perp=9.506, rec=0.115), tot_loss_proj:3.531 [t=0.37s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
[1800/2000] tot_loss=2.015 (perp=9.506, rec=0.114), tot_loss_proj:3.528 [t=0.26s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.015 (perp=9.506, rec=0.113), tot_loss_proj:3.535 [t=0.28s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.023 (perp=9.506, rec=0.121), tot_loss_proj:3.533 [t=0.36s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
[1950/2000] tot_loss=2.014 (perp=9.506, rec=0.113), tot_loss_proj:3.527 [t=0.37s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.010 (perp=9.506, rec=0.109), tot_loss_proj:3.532 [t=0.58s]
prediction: ['[CLS] will especially advantage on better seen considering its advantage, barely vantage cable hardly [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] will especially advantage on better seen considering its advantage. barely vantage cable hardly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 53.333 | p: 53.333 | r: 53.333
rougeLsum  | fm: 53.333 | p: 53.333 | r: 53.333
r1fm+r2fm = 94.286

[Aggregate metrics]:
rouge1     | fm: 77.190 | p: 75.834 | r: 78.846
rouge2     | fm: 37.519 | p: 37.198 | r: 37.853
rougeL     | fm: 69.184 | p: 67.860 | r: 70.788
rougeLsum  | fm: 69.278 | p: 67.916 | r: 70.861
r1fm+r2fm = 114.708

input #12 time: 0:12:34 | total time: 2:26:15


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
cosin similarity: -0.7751034936878405 normalized error: 1.6080171585416112
cosin similarity: 0.7751034936878405 normalized error: 0.6023913888772761
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 1.601804460461702 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 1.543296117559898 for ['[CLS] pdf along timing started mal practical prevailed [SEP]']
[Init] best rec loss: 1.450966042226235 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 1.4292533869870074 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best rec loss: 1.4254359912639574 for ['[CLS] from gave some resistanceffed broadcast d [SEP]']
[Init] best perm rec loss: 1.4234536125356028 for ['[CLS] d gaveffed some broadcast resistance from [SEP]']
[Init] best perm rec loss: 1.4207700326825705 for ['[CLS] gave d from broadcast resistanceffed some [SEP]']
[Init] best perm rec loss: 1.4181523092725374 for ['[CLS] d broadcast gave resistance someffed from [SEP]']
[Init] best perm rec loss: 1.4160163910816634 for ['[CLS] d gave resistance broadcastffed some from [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.876 (perp=11.877, rec=0.501), tot_loss_proj:3.570 [t=0.28s]
prediction: ['[CLS] flame wars suffereduising violent kanye caused [SEP]']
[ 100/2000] tot_loss=3.098 (perp=13.614, rec=0.375), tot_loss_proj:4.121 [t=0.25s]
prediction: ['[CLS] flame explode flames digits drink kanye caused [SEP]']
[ 150/2000] tot_loss=2.440 (perp=10.712, rec=0.298), tot_loss_proj:3.829 [t=0.26s]
prediction: ['[CLS] flame flame flame target dose into into [SEP]']
[ 200/2000] tot_loss=2.431 (perp=10.712, rec=0.289), tot_loss_proj:3.817 [t=0.27s]
prediction: ['[CLS] flame flame flame target dose into into [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.476 (perp=10.950, rec=0.286), tot_loss_proj:3.635 [t=0.26s]
prediction: ['[CLS] point flame flame into dose into using [SEP]']
[ 300/2000] tot_loss=2.456 (perp=11.020, rec=0.252), tot_loss_proj:3.748 [t=0.25s]
prediction: ['[CLS] point flame flame into drawer into skin [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.398 (perp=10.960, rec=0.206), tot_loss_proj:3.299 [t=0.27s]
prediction: ['[CLS] point flame into explode things into using [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.173 (perp=9.828, rec=0.207), tot_loss_proj:3.198 [t=0.26s]
prediction: ['[CLS] point things flame into explode into using [SEP]']
[ 450/2000] tot_loss=2.135 (perp=9.747, rec=0.186), tot_loss_proj:3.429 [t=0.26s]
prediction: ['[CLS] point things flame into explode into skin [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.117 (perp=9.747, rec=0.168), tot_loss_proj:3.422 [t=0.26s]
prediction: ['[CLS] point things flame into explode into skin [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.941 (perp=8.856, rec=0.170), tot_loss_proj:3.202 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[ 600/2000] tot_loss=1.921 (perp=8.856, rec=0.150), tot_loss_proj:3.196 [t=0.27s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.927 (perp=8.856, rec=0.155), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.923 (perp=8.856, rec=0.152), tot_loss_proj:3.199 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[ 750/2000] tot_loss=1.930 (perp=8.856, rec=0.158), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.920 (perp=8.856, rec=0.149), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.921 (perp=8.856, rec=0.150), tot_loss_proj:3.207 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[ 900/2000] tot_loss=1.923 (perp=8.856, rec=0.151), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.915 (perp=8.856, rec=0.144), tot_loss_proj:3.203 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1000/2000] tot_loss=1.911 (perp=8.856, rec=0.140), tot_loss_proj:3.202 [t=0.25s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1050/2000] tot_loss=1.920 (perp=8.856, rec=0.148), tot_loss_proj:3.203 [t=0.28s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1100/2000] tot_loss=1.915 (perp=8.856, rec=0.144), tot_loss_proj:3.199 [t=0.29s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1150/2000] tot_loss=1.908 (perp=8.856, rec=0.137), tot_loss_proj:3.201 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1200/2000] tot_loss=1.908 (perp=8.856, rec=0.137), tot_loss_proj:3.195 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1250/2000] tot_loss=1.903 (perp=8.856, rec=0.132), tot_loss_proj:3.197 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1300/2000] tot_loss=1.913 (perp=8.856, rec=0.142), tot_loss_proj:3.203 [t=0.27s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1350/2000] tot_loss=1.903 (perp=8.856, rec=0.132), tot_loss_proj:3.200 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1400/2000] tot_loss=1.907 (perp=8.856, rec=0.136), tot_loss_proj:3.205 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1450/2000] tot_loss=1.912 (perp=8.856, rec=0.140), tot_loss_proj:3.194 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1500/2000] tot_loss=1.906 (perp=8.856, rec=0.135), tot_loss_proj:3.196 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1550/2000] tot_loss=1.903 (perp=8.856, rec=0.132), tot_loss_proj:3.198 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1600/2000] tot_loss=1.904 (perp=8.856, rec=0.132), tot_loss_proj:3.201 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1650/2000] tot_loss=1.914 (perp=8.856, rec=0.143), tot_loss_proj:3.197 [t=0.27s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1700/2000] tot_loss=1.915 (perp=8.856, rec=0.144), tot_loss_proj:3.203 [t=0.27s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1750/2000] tot_loss=1.901 (perp=8.856, rec=0.130), tot_loss_proj:3.199 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1800/2000] tot_loss=1.905 (perp=8.856, rec=0.134), tot_loss_proj:3.207 [t=0.28s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1850/2000] tot_loss=1.905 (perp=8.856, rec=0.133), tot_loss_proj:3.200 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[1900/2000] tot_loss=1.907 (perp=8.856, rec=0.136), tot_loss_proj:3.198 [t=0.26s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
[1950/2000] tot_loss=1.924 (perp=8.856, rec=0.152), tot_loss_proj:3.201 [t=0.28s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Attempt swap
[2000/2000] tot_loss=1.910 (perp=8.856, rec=0.139), tot_loss_proj:3.201 [t=0.27s]
prediction: ['[CLS] point things flame that explode into skin [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point things flame that explode into skin [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 78.143 | p: 76.782 | r: 79.666
rouge2     | fm: 37.798 | p: 37.517 | r: 38.109
rougeL     | fm: 69.621 | p: 68.487 | r: 71.213
rougeLsum  | fm: 69.855 | p: 68.692 | r: 71.280
r1fm+r2fm = 115.941

input #13 time: 0:11:04 | total time: 2:37:20


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
cosin similarity: 0.9712534810517994 normalized error: 0.4024497074016018
cosin similarity: -0.9712534810517994 normalized error: 1.891265860553726
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 1.9446767978979729 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 1.7132148887979963 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 1.673408743358911 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 1.5598440449901572 for ['[CLS] quiver federation maddie sacramentoboard [SEP]']
[Init] best rec loss: 1.5013829892984902 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best rec loss: 1.4584700254283338 for ['[CLS] magic team came directed basis [SEP]']
[Init] best perm rec loss: 1.4535703417968744 for ['[CLS] directed basis team came magic [SEP]']
[Init] best perm rec loss: 1.4511355316218377 for ['[CLS] came magic directed team basis [SEP]']
[Init] best perm rec loss: 1.4495635881015467 for ['[CLS] came basis directed team magic [SEP]']
[Init] best perm rec loss: 1.4481973697040793 for ['[CLS] came basis magic team directed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.930 (perp=12.985, rec=0.333), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] developed intriguing intriguingbly intriguing [SEP]']
[ 100/2000] tot_loss=3.234 (perp=14.974, rec=0.239), tot_loss_proj:3.532 [t=0.26s]
prediction: ['[CLS] developed film intriguingenia intriguing [SEP]']
[ 150/2000] tot_loss=2.883 (perp=13.402, rec=0.202), tot_loss_proj:3.292 [t=0.25s]
prediction: ['[CLS] concern film intriguingenia intriguing [SEP]']
[ 200/2000] tot_loss=2.269 (perp=10.460, rec=0.177), tot_loss_proj:2.846 [t=0.26s]
prediction: ['[CLS] interest film intriguingeniably [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.235 (perp=10.301, rec=0.174), tot_loss_proj:2.602 [t=0.27s]
prediction: ['[CLS] intriguing film attachedeniably [SEP]']
[ 300/2000] tot_loss=2.220 (perp=10.301, rec=0.160), tot_loss_proj:2.598 [t=0.25s]
prediction: ['[CLS] intriguing film attachedeniably [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.950 (perp=9.010, rec=0.148), tot_loss_proj:2.488 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably attached [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.285 (perp=10.728, rec=0.139), tot_loss_proj:2.657 [t=0.27s]
prediction: ['[CLS] intriguing filmeniably prima [SEP]']
[ 450/2000] tot_loss=2.280 (perp=10.728, rec=0.135), tot_loss_proj:2.661 [t=0.27s]
prediction: ['[CLS] intriguing filmeniably prima [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.162 (perp=10.133, rec=0.135), tot_loss_proj:2.480 [t=0.25s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.159 (perp=10.133, rec=0.132), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
[ 600/2000] tot_loss=2.163 (perp=10.133, rec=0.137), tot_loss_proj:2.475 [t=0.26s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.155 (perp=10.133, rec=0.128), tot_loss_proj:2.476 [t=0.25s]
prediction: ['[CLS] intriguing primaeniably film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.681 (perp=7.796, rec=0.121), tot_loss_proj:1.876 [t=0.27s]
prediction: ['[CLS] intriguing undeniably film [SEP]']
[ 750/2000] tot_loss=1.695 (perp=7.796, rec=0.136), tot_loss_proj:1.882 [t=0.27s]
prediction: ['[CLS] intriguing undeniably film [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.476 (perp=6.728, rec=0.131), tot_loss_proj:1.464 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.476 (perp=6.728, rec=0.130), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.463 (perp=6.728, rec=0.118), tot_loss_proj:1.473 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.471 (perp=6.728, rec=0.126), tot_loss_proj:1.471 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.476 (perp=6.728, rec=0.130), tot_loss_proj:1.463 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.474 (perp=6.728, rec=0.128), tot_loss_proj:1.464 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.472 (perp=6.728, rec=0.126), tot_loss_proj:1.459 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.463 (perp=6.728, rec=0.118), tot_loss_proj:1.464 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.472 (perp=6.728, rec=0.127), tot_loss_proj:1.468 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.467 (perp=6.728, rec=0.122), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.457 (perp=6.728, rec=0.112), tot_loss_proj:1.457 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.469 (perp=6.728, rec=0.123), tot_loss_proj:1.478 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.479 (perp=6.728, rec=0.133), tot_loss_proj:1.468 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.472 (perp=6.728, rec=0.127), tot_loss_proj:1.470 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.475 (perp=6.728, rec=0.129), tot_loss_proj:1.467 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.474 (perp=6.728, rec=0.129), tot_loss_proj:1.453 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.470 (perp=6.728, rec=0.124), tot_loss_proj:1.471 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.471 (perp=6.728, rec=0.126), tot_loss_proj:1.463 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.482 (perp=6.728, rec=0.136), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.465 (perp=6.728, rec=0.119), tot_loss_proj:1.457 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.469 (perp=6.728, rec=0.123), tot_loss_proj:1.476 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.469 (perp=6.728, rec=0.123), tot_loss_proj:1.464 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.465 (perp=6.728, rec=0.119), tot_loss_proj:1.465 [t=0.29s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.469 (perp=6.728, rec=0.124), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=6.728, rec=0.119), tot_loss_proj:1.458 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.546 | p: 78.347 | r: 81.005
rouge2     | fm: 42.016 | p: 41.738 | r: 42.239
rougeL     | fm: 71.887 | p: 70.723 | r: 73.195
rougeLsum  | fm: 71.713 | p: 70.639 | r: 72.904
r1fm+r2fm = 121.562

input #14 time: 0:11:02 | total time: 2:48:22


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
cosin similarity: 0.6748695288074162 normalized error: 0.6247062170652273
cosin similarity: -0.6748695288074162 normalized error: 1.6822343017748727
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 1.8970370209850902 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 1.8300392041643305 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 1.7513569220039324 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 1.737308721226646 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 1.7311888822016992 for ['[CLS]ₑ scouts jeffital near mills reserveignment [SEP]']
[Init] best rec loss: 1.6392896973664168 for ['[CLS] winner french badminton harperrdial missed ex fond [SEP]']
[Init] best perm rec loss: 1.6384854116454244 for ['[CLS] harper badminton frenchrdial missed fond ex winner [SEP]']
[Init] best perm rec loss: 1.6370199819809566 for ['[CLS] french ex fond missedrdial badminton winner harper [SEP]']
[Init] best perm rec loss: 1.6355880723650063 for ['[CLS] harper winner fond frenchrdial badminton ex missed [SEP]']
[Init] best perm rec loss: 1.6344319928426385 for ['[CLS]rdial french harper ex winner fond missed badminton [SEP]']
[Init] best perm rec loss: 1.6326826439126438 for ['[CLS] fond winnerrdial french harper missed ex badminton [SEP]']
[Init] best perm rec loss: 1.6309022190689135 for ['[CLS] ex harperrdial winner french fond missed badminton [SEP]']
[Init] best perm rec loss: 1.630848530440952 for ['[CLS] ex harper winnerrdial missed french fond badminton [SEP]']
[Init] best perm rec loss: 1.6299066048861643 for ['[CLS] winner harperrdial missed ex fond french badminton [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.166 (perp=13.156, rec=0.535), tot_loss_proj:3.897 [t=0.25s]
prediction: ['[CLS]ctus macdonald efficientablydies generation efficient clarkson [SEP]']
[ 100/2000] tot_loss=2.990 (perp=12.898, rec=0.410), tot_loss_proj:3.808 [t=0.25s]
prediction: ['[CLS] season macdonald suitsably kaladin unanimously efficient efficient [SEP]']
[ 150/2000] tot_loss=3.002 (perp=13.353, rec=0.331), tot_loss_proj:4.103 [t=0.27s]
prediction: ['[CLS] season macdonald suitsablyer suit efficient clarkson [SEP]']
[ 200/2000] tot_loss=2.813 (perp=12.431, rec=0.327), tot_loss_proj:4.371 [t=0.25s]
prediction: ['[CLS] chill lack suitably beads favor efficientarable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.521 (perp=11.149, rec=0.291), tot_loss_proj:3.843 [t=0.25s]
prediction: ['[CLS] chill rate suitably chill efficientrued anonymous [SEP]']
[ 300/2000] tot_loss=2.505 (perp=11.149, rec=0.275), tot_loss_proj:3.843 [t=0.27s]
prediction: ['[CLS] chill rate suitably chill efficientrued anonymous [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.536 (perp=11.427, rec=0.251), tot_loss_proj:3.883 [t=0.26s]
prediction: ['[CLS] chill rate suitably chill efficientrueder [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.357 (perp=10.497, rec=0.258), tot_loss_proj:3.484 [t=0.26s]
prediction: ['[CLS] chill rates suitably efficientrued chiller [SEP]']
[ 450/2000] tot_loss=2.311 (perp=10.345, rec=0.242), tot_loss_proj:3.339 [t=0.27s]
prediction: ['[CLS] chill rate suitably efficientrued chiller [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.459 (perp=11.102, rec=0.238), tot_loss_proj:3.444 [t=0.27s]
prediction: ['[CLS] chill tortricidaerued suitably efficient chiller [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.459 (perp=11.075, rec=0.244), tot_loss_proj:3.527 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficientrued chiller [SEP]']
[ 600/2000] tot_loss=2.309 (perp=10.407, rec=0.228), tot_loss_proj:3.306 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.312 (perp=10.407, rec=0.231), tot_loss_proj:3.301 [t=0.29s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.307 (perp=10.407, rec=0.225), tot_loss_proj:3.305 [t=0.28s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[ 750/2000] tot_loss=2.294 (perp=10.407, rec=0.213), tot_loss_proj:3.305 [t=0.28s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.300 (perp=10.407, rec=0.218), tot_loss_proj:3.303 [t=0.25s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.304 (perp=10.407, rec=0.223), tot_loss_proj:3.308 [t=0.27s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[ 900/2000] tot_loss=2.301 (perp=10.407, rec=0.219), tot_loss_proj:3.303 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.288 (perp=10.407, rec=0.206), tot_loss_proj:3.303 [t=0.25s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1000/2000] tot_loss=2.296 (perp=10.407, rec=0.215), tot_loss_proj:3.310 [t=0.27s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1050/2000] tot_loss=2.298 (perp=10.407, rec=0.216), tot_loss_proj:3.309 [t=0.27s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=2.298 (perp=10.407, rec=0.217), tot_loss_proj:3.308 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1150/2000] tot_loss=2.289 (perp=10.407, rec=0.207), tot_loss_proj:3.300 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1200/2000] tot_loss=2.290 (perp=10.407, rec=0.209), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1250/2000] tot_loss=2.300 (perp=10.407, rec=0.218), tot_loss_proj:3.303 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1300/2000] tot_loss=2.286 (perp=10.407, rec=0.205), tot_loss_proj:3.305 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1350/2000] tot_loss=2.290 (perp=10.407, rec=0.209), tot_loss_proj:3.310 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1400/2000] tot_loss=2.289 (perp=10.407, rec=0.207), tot_loss_proj:3.308 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1450/2000] tot_loss=2.282 (perp=10.407, rec=0.201), tot_loss_proj:3.303 [t=0.26s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1500/2000] tot_loss=2.295 (perp=10.407, rec=0.214), tot_loss_proj:3.306 [t=0.28s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1550/2000] tot_loss=2.292 (perp=10.407, rec=0.210), tot_loss_proj:3.301 [t=0.25s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1600/2000] tot_loss=2.293 (perp=10.407, rec=0.212), tot_loss_proj:3.306 [t=0.28s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1650/2000] tot_loss=2.289 (perp=10.407, rec=0.207), tot_loss_proj:3.306 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1700/2000] tot_loss=2.288 (perp=10.407, rec=0.206), tot_loss_proj:3.309 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1750/2000] tot_loss=2.296 (perp=10.407, rec=0.214), tot_loss_proj:3.304 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1800/2000] tot_loss=2.289 (perp=10.407, rec=0.207), tot_loss_proj:3.308 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1850/2000] tot_loss=2.288 (perp=10.407, rec=0.206), tot_loss_proj:3.308 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[1900/2000] tot_loss=2.295 (perp=10.407, rec=0.214), tot_loss_proj:3.308 [t=0.22s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
[1950/2000] tot_loss=2.287 (perp=10.407, rec=0.206), tot_loss_proj:3.307 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Attempt swap
[2000/2000] tot_loss=2.287 (perp=10.407, rec=0.206), tot_loss_proj:3.305 [t=0.21s]
prediction: ['[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] chill tortricidae suitably efficient anonymous chiller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 75.000 | r: 100.000
rouge2     | fm: 33.333 | p: 28.571 | r: 40.000
rougeL     | fm: 71.429 | p: 62.500 | r: 83.333
rougeLsum  | fm: 71.429 | p: 62.500 | r: 83.333
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 80.151 | p: 78.293 | r: 82.252
rouge2     | fm: 41.003 | p: 40.499 | r: 41.658
rougeL     | fm: 71.807 | p: 70.118 | r: 73.764
rougeLsum  | fm: 71.896 | p: 70.455 | r: 73.802
r1fm+r2fm = 121.154

input #15 time: 0:10:31 | total time: 2:58:54


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
cosin similarity: 0.8608126130577575 normalized error: 0.5227461674587929
cosin similarity: -0.8608126130577576 normalized error: 1.718421683305823
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.9182784000561732 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 1.7721839365450194 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 1.654328542364809 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 1.5700756693749272 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 1.5311857895731213 for ['[CLS] legsyen t sharon camp ro [SEP]']
[Init] best rec loss: 1.5175395499198157 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 1.5020976554555403 for ['[CLS] hermic clement glass dig mount [SEP]']
[Init] best rec loss: 1.4031997027562024 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 1.3835596852537135 for ['[CLS] ultra backpack tallest you downstream map [SEP]']
[Init] best perm rec loss: 1.3801290946393565 for ['[CLS] ultra tallest backpack downstream you map [SEP]']
[Init] best perm rec loss: 1.3788374464161406 for ['[CLS] downstream tallest backpack ultra you map [SEP]']
[Init] best perm rec loss: 1.3783540578427966 for ['[CLS] downstream you tallest map ultra backpack [SEP]']
[Init] best perm rec loss: 1.3776690869216974 for ['[CLS] ultra you tallest map backpack downstream [SEP]']
[Init] best perm rec loss: 1.3772992617019928 for ['[CLS] ultra you tallest backpack downstream map [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=11.772, rec=0.448), tot_loss_proj:3.655 [t=0.20s]
prediction: ['[CLS] received building all cadenended of [SEP]']
[ 100/2000] tot_loss=2.373 (perp=10.200, rec=0.333), tot_loss_proj:3.963 [t=0.21s]
prediction: ['[CLS] all all this chamberended of [SEP]']
[ 150/2000] tot_loss=2.123 (perp=9.354, rec=0.252), tot_loss_proj:3.744 [t=0.21s]
prediction: ['[CLS] all more this ofended more [SEP]']
[ 200/2000] tot_loss=2.075 (perp=9.354, rec=0.204), tot_loss_proj:3.752 [t=0.21s]
prediction: ['[CLS] all more this ofended more [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.666 (perp=7.531, rec=0.160), tot_loss_proj:2.253 [t=0.21s]
prediction: ['[CLS] all of this and bartholomew more [SEP]']
[ 300/2000] tot_loss=1.593 (perp=7.262, rec=0.140), tot_loss_proj:2.393 [t=0.21s]
prediction: ['[CLS] all of this and opportunity more [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.658 (perp=7.607, rec=0.137), tot_loss_proj:2.465 [t=0.21s]
prediction: ['[CLS] all of thispina and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.507 (perp=6.924, rec=0.123), tot_loss_proj:3.298 [t=0.26s]
prediction: ['[CLS] all of this without and more [SEP]']
[ 450/2000] tot_loss=1.509 (perp=6.924, rec=0.124), tot_loss_proj:3.296 [t=0.27s]
prediction: ['[CLS] all of this without and more [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.403 (perp=6.424, rec=0.118), tot_loss_proj:3.128 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.403 (perp=6.424, rec=0.119), tot_loss_proj:3.131 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[ 600/2000] tot_loss=1.407 (perp=6.424, rec=0.122), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.398 (perp=6.424, rec=0.114), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.424, rec=0.115), tot_loss_proj:3.132 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
[ 750/2000] tot_loss=1.399 (perp=6.424, rec=0.114), tot_loss_proj:3.130 [t=0.28s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.407 (perp=6.424, rec=0.122), tot_loss_proj:3.130 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.397 (perp=6.424, rec=0.112), tot_loss_proj:3.127 [t=0.28s]
prediction: ['[CLS] all of this and without more [SEP]']
[ 900/2000] tot_loss=1.396 (perp=6.424, rec=0.111), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.405 (perp=6.424, rec=0.121), tot_loss_proj:3.128 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.396 (perp=6.424, rec=0.111), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1050/2000] tot_loss=1.395 (perp=6.424, rec=0.110), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.403 (perp=6.424, rec=0.118), tot_loss_proj:3.128 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.398 (perp=6.424, rec=0.113), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1200/2000] tot_loss=1.393 (perp=6.424, rec=0.109), tot_loss_proj:3.129 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.401 (perp=6.424, rec=0.117), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.386 (perp=6.424, rec=0.102), tot_loss_proj:3.127 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
[1350/2000] tot_loss=1.389 (perp=6.424, rec=0.105), tot_loss_proj:3.126 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.424, rec=0.110), tot_loss_proj:3.125 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.394 (perp=6.424, rec=0.110), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS] all of this and without more [SEP]']
[1500/2000] tot_loss=1.387 (perp=6.424, rec=0.102), tot_loss_proj:3.122 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.391 (perp=6.424, rec=0.107), tot_loss_proj:3.121 [t=0.28s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.400 (perp=6.424, rec=0.115), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
[1650/2000] tot_loss=1.399 (perp=6.424, rec=0.114), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.398 (perp=6.424, rec=0.113), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.397 (perp=6.424, rec=0.112), tot_loss_proj:3.126 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
[1800/2000] tot_loss=1.393 (perp=6.424, rec=0.108), tot_loss_proj:3.126 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.397 (perp=6.424, rec=0.112), tot_loss_proj:3.121 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.424, rec=0.108), tot_loss_proj:3.125 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
[1950/2000] tot_loss=1.393 (perp=6.424, rec=0.109), tot_loss_proj:3.130 [t=0.28s]
prediction: ['[CLS] all of this and without more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.402 (perp=6.424, rec=0.118), tot_loss_proj:3.129 [t=0.27s]
prediction: ['[CLS] all of this and without more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this and without more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 80.591 | p: 78.533 | r: 83.106
rouge2     | fm: 43.729 | p: 42.735 | r: 44.793
rougeL     | fm: 73.339 | p: 71.426 | r: 75.563
rougeLsum  | fm: 72.890 | p: 71.083 | r: 75.171
r1fm+r2fm = 124.321

input #16 time: 0:10:26 | total time: 3:09:20


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
cosin similarity: 0.9037399408049033 normalized error: 0.5024741745837585
cosin similarity: -0.9037399408049032 normalized error: 1.727021223700542
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 1.6074051919111232 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 1.5803749429665204 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 1.5803546368474701 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 1.4937723138670405 for ['[CLS] highestlt short ad relation minority black bunch marine above different [SEP]']
[Init] best rec loss: 1.411629395272497 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 1.4087598261576204 for ['[CLS] gravel divided highest accesslowe conor dir startorg timesttered [SEP]']
[Init] best rec loss: 1.3690867238837439 for ['[CLS] general sensation water consecrated affairvudran bethany then religious threatened [SEP]']
[Init] best perm rec loss: 1.3664426460821055 for ['[CLS] religiousvu consecrated bethany affair water threatened sensation then generaldran [SEP]']
[Init] best perm rec loss: 1.3600614397254753 for ['[CLS]vu consecrated water general affair sensationdran threatened then religious bethany [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.732 (perp=10.941, rec=0.543), tot_loss_proj:3.516 [t=0.27s]
prediction: ["[CLS] any think much be exploded fantasy'swimming crazy strings leaving [SEP]"]
[ 100/2000] tot_loss=2.594 (perp=10.958, rec=0.402), tot_loss_proj:3.452 [t=0.25s]
prediction: ['[CLS] too think much been stolen on too swimming plea want leaving [SEP]']
[ 150/2000] tot_loss=2.664 (perp=11.768, rec=0.310), tot_loss_proj:3.560 [t=0.26s]
prediction: ['[CLS] want think much much wrong on too about plea want leaving [SEP]']
[ 200/2000] tot_loss=2.343 (perp=10.515, rec=0.240), tot_loss_proj:3.224 [t=0.27s]
prediction: ['[CLS] want think much much too on too about much want leave [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.137 (perp=9.800, rec=0.177), tot_loss_proj:3.202 [t=0.27s]
prediction: ['[CLS] want think much much too on think about much want too [SEP]']
[ 300/2000] tot_loss=2.227 (perp=10.430, rec=0.141), tot_loss_proj:3.855 [t=0.27s]
prediction: ['[CLS] want think much much too get think about much want want [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.969 (perp=9.202, rec=0.129), tot_loss_proj:3.253 [t=0.27s]
prediction: ['[CLS] want think much too much get think about much what want [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.721 (perp=7.950, rec=0.131), tot_loss_proj:3.186 [t=0.28s]
prediction: ['[CLS] want think too much get to think about much what want [SEP]']
[ 450/2000] tot_loss=1.717 (perp=7.950, rec=0.127), tot_loss_proj:3.192 [t=0.28s]
prediction: ['[CLS] want think too much get to think about much what want [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.550 (perp=7.216, rec=0.107), tot_loss_proj:2.777 [t=0.27s]
prediction: ['[CLS] want think too much get to think about what much want [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.534 (perp=7.089, rec=0.116), tot_loss_proj:2.640 [t=0.27s]
prediction: ['[CLS] want think too much want to think about what everything get [SEP]']
[ 600/2000] tot_loss=1.529 (perp=7.089, rec=0.111), tot_loss_proj:2.638 [t=0.28s]
prediction: ['[CLS] want think too much want to think about what everything get [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.530 (perp=7.102, rec=0.110), tot_loss_proj:2.541 [t=0.26s]
prediction: ['[CLS] want think too much want to think about what what get [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.626 (perp=7.631, rec=0.100), tot_loss_proj:2.405 [t=0.32s]
prediction: ['[CLS] wantsm too much want to think about what what get [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.118, rec=0.106), tot_loss_proj:2.564 [t=0.27s]
prediction: ['[CLS] wantsm too much want to think about going what get [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.663 (perp=7.798, rec=0.103), tot_loss_proj:2.469 [t=0.27s]
prediction: ['[CLS] wantsm too much want to think about going get what [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.570 (perp=7.282, rec=0.113), tot_loss_proj:2.490 [t=0.28s]
prediction: ['[CLS] want too much want excessive to think about going get what [SEP]']
[ 900/2000] tot_loss=1.643 (perp=7.706, rec=0.101), tot_loss_proj:2.500 [t=0.25s]
prediction: ['[CLS] want too much want caroline to think about going get what [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.628 (perp=7.563, rec=0.115), tot_loss_proj:2.373 [t=0.27s]
prediction: ['[CLS] want too much to want caroline think about going get what [SEP]']
Attempt swap
[1000/2000] tot_loss=1.619 (perp=7.563, rec=0.106), tot_loss_proj:2.377 [t=0.25s]
prediction: ['[CLS] want too much to want caroline think about going get what [SEP]']
[1050/2000] tot_loss=1.743 (perp=8.247, rec=0.093), tot_loss_proj:2.991 [t=0.27s]
prediction: ['[CLS] want too much to want caroline think about going lives what [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.668 (perp=7.867, rec=0.094), tot_loss_proj:2.533 [t=0.25s]
prediction: ['[CLS] want too much to want lack think about what lives going [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.576 (perp=7.375, rec=0.101), tot_loss_proj:2.591 [t=0.25s]
prediction: ['[CLS] want too much want lack to think about what get going [SEP]']
[1200/2000] tot_loss=1.537 (perp=7.188, rec=0.099), tot_loss_proj:2.295 [t=0.27s]
prediction: ['[CLS] want too much wantsm to think about what get going [SEP]']
Attempt swap
[1250/2000] tot_loss=1.624 (perp=7.617, rec=0.101), tot_loss_proj:2.481 [t=0.27s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Attempt swap
[1300/2000] tot_loss=1.632 (perp=7.617, rec=0.108), tot_loss_proj:2.475 [t=0.25s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
[1350/2000] tot_loss=1.620 (perp=7.617, rec=0.097), tot_loss_proj:2.474 [t=0.25s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Attempt swap
[1400/2000] tot_loss=1.645 (perp=7.733, rec=0.098), tot_loss_proj:2.621 [t=0.26s]
prediction: ['[CLS] want too much want lack to think about what lives going [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.566 (perp=7.318, rec=0.103), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] want too much lack want to think about what lives going [SEP]']
[1500/2000] tot_loss=1.680 (perp=7.936, rec=0.093), tot_loss_proj:2.623 [t=0.26s]
prediction: ['[CLS] want too muchsm want to think about what lives going [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.643 (perp=7.733, rec=0.097), tot_loss_proj:2.624 [t=0.26s]
prediction: ['[CLS] want too much want lack to think about what lives going [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.549 (perp=7.265, rec=0.096), tot_loss_proj:2.578 [t=0.27s]
prediction: ['[CLS] want lack too much want to think about what lives going [SEP]']
[1650/2000] tot_loss=1.557 (perp=7.265, rec=0.104), tot_loss_proj:2.574 [t=0.28s]
prediction: ['[CLS] want lack too much want to think about what lives going [SEP]']
Attempt swap
[1700/2000] tot_loss=1.553 (perp=7.265, rec=0.100), tot_loss_proj:2.578 [t=0.25s]
prediction: ['[CLS] want lack too much want to think about what lives going [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=7.858, rec=0.099), tot_loss_proj:2.546 [t=0.31s]
prediction: ['[CLS] wantsm too much want to think about what lives going [SEP]']
[1800/2000] tot_loss=1.668 (perp=7.858, rec=0.096), tot_loss_proj:2.541 [t=0.28s]
prediction: ['[CLS] wantsm too much want to think about what lives going [SEP]']
Attempt swap
[1850/2000] tot_loss=1.664 (perp=7.858, rec=0.093), tot_loss_proj:2.538 [t=0.28s]
prediction: ['[CLS] wantsm too much want to think about what lives going [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.610 (perp=7.617, rec=0.087), tot_loss_proj:2.478 [t=0.26s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.617, rec=0.099), tot_loss_proj:2.478 [t=0.26s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Attempt swap
[2000/2000] tot_loss=1.614 (perp=7.617, rec=0.090), tot_loss_proj:2.478 [t=0.25s]
prediction: ['[CLS] want too much wantsm to think about what lives going [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want too muchsm want to think about what lives going [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 111.364

[Aggregate metrics]:
rouge1     | fm: 80.332 | p: 78.411 | r: 82.687
rouge2     | fm: 43.329 | p: 42.529 | r: 44.470
rougeL     | fm: 73.032 | p: 71.284 | r: 75.125
rougeLsum  | fm: 72.360 | p: 70.558 | r: 74.825
r1fm+r2fm = 123.661

input #17 time: 0:11:04 | total time: 3:20:25


Running input #18 of 100.
reference: 
========================
invigorating 
========================
cosin similarity: -0.8663931959498936 normalized error: 1.8094839224181716
cosin similarity: 0.8663931959498935 normalized error: 0.4833655777924054
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 2.0162891501258073 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 1.8783933266244992 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 1.8179616827797669 for ['[CLS] says oh dynasty watershed [SEP]']
[Init] best rec loss: 1.8119192569393463 for ['[CLS]nched jing ash face [SEP]']
[Init] best rec loss: 1.7251254339526572 for ['[CLS] disappointednce secret running [SEP]']
[Init] best rec loss: 1.7174652807963626 for ['[CLS] staten boy common diner [SEP]']
[Init] best rec loss: 1.6935080832392198 for ['[CLS] with thy commission operating [SEP]']
[Init] best rec loss: 1.672139018499803 for ['[CLS] themselvesnt lumpur rode [SEP]']
[Init] best rec loss: 1.4475356849153311 for ['[CLS] dual circle duodle [SEP]']
[Init] best rec loss: 1.442180656881522 for ['[CLS] canellant replication calm [SEP]']
[Init] best perm rec loss: 1.438380616862584 for ['[CLS] replicationellant can calm [SEP]']
[Init] best perm rec loss: 1.4359583516313148 for ['[CLS] can replicationellant calm [SEP]']
[Init] best perm rec loss: 1.4353885968659366 for ['[CLS] calm replicationellant can [SEP]']
[Init] best perm rec loss: 1.4314809151194952 for ['[CLS] replication can calmellant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.901 (perp=11.629, rec=0.575), tot_loss_proj:4.067 [t=0.26s]
prediction: ['[CLS] also newgillable [SEP]']
[ 100/2000] tot_loss=2.635 (perp=11.120, rec=0.411), tot_loss_proj:3.016 [t=0.27s]
prediction: ['[CLS] visible uniquegorating [SEP]']
[ 150/2000] tot_loss=2.607 (perp=11.392, rec=0.328), tot_loss_proj:3.550 [t=0.26s]
prediction: ['[CLS] visible!gorating [SEP]']
[ 200/2000] tot_loss=2.414 (perp=10.615, rec=0.291), tot_loss_proj:3.380 [t=0.26s]
prediction: ['[CLS] visible itsgorating [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.025 (perp=8.563, rec=0.312), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] its alsogorating [SEP]']
[ 300/2000] tot_loss=2.123 (perp=9.243, rec=0.274), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] its definitelygorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.979 (perp=8.563, rec=0.267), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] its alsogorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.178 (perp=9.604, rec=0.257), tot_loss_proj:3.005 [t=0.26s]
prediction: ['[CLS] its availablegorating [SEP]']
[ 450/2000] tot_loss=2.170 (perp=9.604, rec=0.249), tot_loss_proj:3.004 [t=0.27s]
prediction: ['[CLS] its availablegorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.174 (perp=9.604, rec=0.254), tot_loss_proj:3.010 [t=0.27s]
prediction: ['[CLS] its availablegorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.175 (perp=9.604, rec=0.254), tot_loss_proj:3.006 [t=0.25s]
prediction: ['[CLS] its availablegorating [SEP]']
[ 600/2000] tot_loss=2.167 (perp=9.604, rec=0.246), tot_loss_proj:3.006 [t=0.26s]
prediction: ['[CLS] its availablegorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.394 (perp=10.733, rec=0.247), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] its entergorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.385 (perp=10.733, rec=0.238), tot_loss_proj:3.234 [t=0.25s]
prediction: ['[CLS] its entergorating [SEP]']
[ 750/2000] tot_loss=2.392 (perp=10.733, rec=0.245), tot_loss_proj:3.237 [t=0.26s]
prediction: ['[CLS] its entergorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.382 (perp=10.702, rec=0.242), tot_loss_proj:2.868 [t=0.25s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.377 (perp=10.702, rec=0.237), tot_loss_proj:2.868 [t=0.26s]
prediction: ['[CLS]! entergorating [SEP]']
[ 900/2000] tot_loss=2.371 (perp=10.702, rec=0.230), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.367 (perp=10.702, rec=0.226), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1000/2000] tot_loss=2.385 (perp=10.702, rec=0.244), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS]! entergorating [SEP]']
[1050/2000] tot_loss=2.374 (perp=10.702, rec=0.234), tot_loss_proj:2.866 [t=0.26s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1100/2000] tot_loss=2.381 (perp=10.702, rec=0.240), tot_loss_proj:2.874 [t=0.27s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1150/2000] tot_loss=2.378 (perp=10.702, rec=0.237), tot_loss_proj:2.873 [t=0.28s]
prediction: ['[CLS]! entergorating [SEP]']
[1200/2000] tot_loss=2.365 (perp=10.702, rec=0.224), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1250/2000] tot_loss=2.367 (perp=10.702, rec=0.227), tot_loss_proj:2.873 [t=0.26s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1300/2000] tot_loss=2.376 (perp=10.702, rec=0.235), tot_loss_proj:2.875 [t=0.27s]
prediction: ['[CLS]! entergorating [SEP]']
[1350/2000] tot_loss=2.361 (perp=10.702, rec=0.221), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS]! entergorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.892 (perp=8.319, rec=0.228), tot_loss_proj:2.359 [t=0.26s]
prediction: ['[CLS]! ingorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.888 (perp=8.319, rec=0.224), tot_loss_proj:2.365 [t=0.25s]
prediction: ['[CLS]! ingorating [SEP]']
[1500/2000] tot_loss=1.887 (perp=8.319, rec=0.223), tot_loss_proj:2.363 [t=0.26s]
prediction: ['[CLS]! ingorating [SEP]']
Attempt swap
[1550/2000] tot_loss=2.077 (perp=9.233, rec=0.230), tot_loss_proj:2.633 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1600/2000] tot_loss=2.079 (perp=9.233, rec=0.232), tot_loss_proj:2.631 [t=0.27s]
prediction: ['[CLS]ryl ingorating [SEP]']
[1650/2000] tot_loss=2.081 (perp=9.233, rec=0.234), tot_loss_proj:2.635 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1700/2000] tot_loss=2.074 (perp=9.233, rec=0.228), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1750/2000] tot_loss=2.086 (perp=9.233, rec=0.239), tot_loss_proj:2.629 [t=0.25s]
prediction: ['[CLS]ryl ingorating [SEP]']
[1800/2000] tot_loss=2.083 (perp=9.233, rec=0.236), tot_loss_proj:2.627 [t=0.29s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1850/2000] tot_loss=2.074 (perp=9.233, rec=0.228), tot_loss_proj:2.633 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[1900/2000] tot_loss=2.076 (perp=9.233, rec=0.230), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
[1950/2000] tot_loss=2.084 (perp=9.233, rec=0.237), tot_loss_proj:2.637 [t=0.27s]
prediction: ['[CLS]ryl ingorating [SEP]']
Attempt swap
[2000/2000] tot_loss=2.064 (perp=9.233, rec=0.218), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS]ryl ingorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS]ryl ingorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 79.250 | p: 77.063 | r: 81.946
rouge2     | fm: 41.178 | p: 40.490 | r: 42.163
rougeL     | fm: 72.362 | p: 70.233 | r: 74.995
rougeLsum  | fm: 71.826 | p: 69.609 | r: 74.361
r1fm+r2fm = 120.429

input #18 time: 0:11:02 | total time: 3:31:28


Running input #19 of 100.
reference: 
========================
to infamy 
========================
cosin similarity: 0.8340207118100215 normalized error: 0.5752933257115956
cosin similarity: -0.8340207118100214 normalized error: 1.6213409820620608
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 1.5094313931796732 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 1.4554807544511337 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 1.3433113745062517 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 1.334873426604534 for ['[CLS] human billy km² era [SEP]']
[Init] best rec loss: 1.328149610944145 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 1.2973774107200455 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 1.2937542735480927 for ['[CLS]yna reaching order pin [SEP]']
[Init] best perm rec loss: 1.2908034235951535 for ['[CLS] orderyna reaching pin [SEP]']
[Init] best perm rec loss: 1.2903990563565202 for ['[CLS] reachingyna pin order [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.424 (perp=14.757, rec=0.472), tot_loss_proj:4.384 [t=0.26s]
prediction: ['[CLS]quefirmpha situation [SEP]']
[ 100/2000] tot_loss=2.651 (perp=11.470, rec=0.357), tot_loss_proj:3.792 [t=0.27s]
prediction: ['[CLS] tofapha situation [SEP]']
[ 150/2000] tot_loss=2.515 (perp=11.006, rec=0.314), tot_loss_proj:3.776 [t=0.26s]
prediction: ['[CLS] tofamy maryland [SEP]']
[ 200/2000] tot_loss=2.087 (perp=9.226, rec=0.242), tot_loss_proj:3.433 [t=0.25s]
prediction: ['[CLS] tofamy injury [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.056 (perp=9.226, rec=0.211), tot_loss_proj:3.433 [t=0.26s]
prediction: ['[CLS] tofamy injury [SEP]']
[ 300/2000] tot_loss=2.018 (perp=9.226, rec=0.173), tot_loss_proj:3.434 [t=0.26s]
prediction: ['[CLS] tofamy injury [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.535 (perp=11.821, rec=0.171), tot_loss_proj:4.146 [t=0.27s]
prediction: ['[CLS] tofamy beat [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.312 (perp=10.538, rec=0.204), tot_loss_proj:3.754 [t=0.25s]
prediction: ['[CLS] attainfamy to [SEP]']
[ 450/2000] tot_loss=2.258 (perp=10.538, rec=0.151), tot_loss_proj:3.763 [t=0.26s]
prediction: ['[CLS] attainfamy to [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.029 (perp=9.223, rec=0.185), tot_loss_proj:3.430 [t=0.28s]
prediction: ['[CLS] to attainfamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.990 (perp=9.223, rec=0.145), tot_loss_proj:3.430 [t=0.26s]
prediction: ['[CLS] to attainfamy [SEP]']
[ 600/2000] tot_loss=1.989 (perp=9.223, rec=0.145), tot_loss_proj:3.430 [t=0.25s]
prediction: ['[CLS] to attainfamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.983 (perp=9.223, rec=0.138), tot_loss_proj:3.423 [t=0.26s]
prediction: ['[CLS] to attainfamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.968 (perp=9.223, rec=0.124), tot_loss_proj:3.432 [t=0.26s]
prediction: ['[CLS] to attainfamy [SEP]']
[ 750/2000] tot_loss=2.337 (perp=10.996, rec=0.138), tot_loss_proj:3.613 [t=0.27s]
prediction: ['[CLS] to classificationfamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.340 (perp=10.996, rec=0.141), tot_loss_proj:3.610 [t=0.26s]
prediction: ['[CLS] to classificationfamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.329 (perp=10.996, rec=0.130), tot_loss_proj:3.615 [t=0.28s]
prediction: ['[CLS] to classificationfamy [SEP]']
[ 900/2000] tot_loss=2.328 (perp=10.996, rec=0.129), tot_loss_proj:3.616 [t=0.25s]
prediction: ['[CLS] to classificationfamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.302 (perp=10.832, rec=0.135), tot_loss_proj:3.656 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1000/2000] tot_loss=2.288 (perp=10.832, rec=0.121), tot_loss_proj:3.652 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
[1050/2000] tot_loss=2.293 (perp=10.832, rec=0.126), tot_loss_proj:3.649 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1100/2000] tot_loss=2.296 (perp=10.832, rec=0.130), tot_loss_proj:3.648 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.296 (perp=10.832, rec=0.130), tot_loss_proj:3.653 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
[1200/2000] tot_loss=2.290 (perp=10.832, rec=0.124), tot_loss_proj:3.645 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1250/2000] tot_loss=2.292 (perp=10.832, rec=0.125), tot_loss_proj:3.653 [t=0.26s]
prediction: ['[CLS] to completedfamy [SEP]']
Attempt swap
[1300/2000] tot_loss=2.279 (perp=10.832, rec=0.113), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] to completedfamy [SEP]']
[1350/2000] tot_loss=1.921 (perp=8.949, rec=0.132), tot_loss_proj:2.777 [t=0.27s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.916 (perp=8.949, rec=0.126), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.921 (perp=8.949, rec=0.131), tot_loss_proj:2.787 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
[1500/2000] tot_loss=1.909 (perp=8.949, rec=0.119), tot_loss_proj:2.782 [t=0.28s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.912 (perp=8.949, rec=0.122), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.921 (perp=8.949, rec=0.132), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
[1650/2000] tot_loss=1.917 (perp=8.949, rec=0.127), tot_loss_proj:2.773 [t=0.27s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.914 (perp=8.949, rec=0.124), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.898 (perp=8.949, rec=0.109), tot_loss_proj:2.778 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
[1800/2000] tot_loss=1.904 (perp=8.949, rec=0.114), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.914 (perp=8.949, rec=0.124), tot_loss_proj:2.782 [t=0.27s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.915 (perp=8.949, rec=0.126), tot_loss_proj:2.782 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
[1950/2000] tot_loss=1.915 (perp=8.949, rec=0.126), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] to polyfamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.919 (perp=8.949, rec=0.129), tot_loss_proj:2.780 [t=0.25s]
prediction: ['[CLS] to polyfamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to polyfamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 79.049 | p: 77.022 | r: 81.583
rouge2     | fm: 40.639 | p: 39.711 | r: 41.516
rougeL     | fm: 72.436 | p: 70.563 | r: 74.729
rougeLsum  | fm: 71.867 | p: 70.025 | r: 74.250
r1fm+r2fm = 119.688

input #19 time: 0:11:03 | total time: 3:42:32


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
cosin similarity: -0.8303731972303416 normalized error: 1.7135635582976205
cosin similarity: 0.8303731972303418 normalized error: 0.5372736947116259
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 1.7817882942253682 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 1.7579531173935001 for ['[CLS] sal focalgee weeks [SEP]']
[Init] best rec loss: 1.6723533105951658 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 1.3967802267733476 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 1.32556983564614 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 1.3157501881221847 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 1.3142276924055944 for ['[CLS] storylinenessxi [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.587 (perp=15.450, rec=0.497), tot_loss_proj:4.830 [t=0.26s]
prediction: ['[CLS] hateified socio pleasure [SEP]']
[ 100/2000] tot_loss=2.539 (perp=10.953, rec=0.349), tot_loss_proj:3.071 [t=0.25s]
prediction: ['[CLS]verseverseverse pleasure [SEP]']
[ 150/2000] tot_loss=2.121 (perp=9.188, rec=0.284), tot_loss_proj:2.890 [t=0.28s]
prediction: ['[CLS] perverseverse pleasure [SEP]']
[ 200/2000] tot_loss=2.086 (perp=9.188, rec=0.249), tot_loss_proj:2.875 [t=0.27s]
prediction: ['[CLS] perverseverse pleasure [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.295 (perp=9.920, rec=0.311), tot_loss_proj:2.746 [t=0.27s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
[ 300/2000] tot_loss=2.231 (perp=9.920, rec=0.246), tot_loss_proj:2.708 [t=0.26s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.200 (perp=9.920, rec=0.216), tot_loss_proj:2.702 [t=0.27s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.196 (perp=9.920, rec=0.212), tot_loss_proj:2.699 [t=0.27s]
prediction: ['[CLS] uber perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.740 (perp=7.708, rec=0.199), tot_loss_proj:2.260 [t=0.26s]
prediction: ['[CLS] certain perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.740 (perp=7.708, rec=0.198), tot_loss_proj:2.264 [t=0.26s]
prediction: ['[CLS] certain perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.809 (perp=8.093, rec=0.190), tot_loss_proj:3.077 [t=0.26s]
prediction: ['[CLS] suppose perverse pleasure [SEP]']
[ 600/2000] tot_loss=2.256 (perp=10.350, rec=0.186), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.267 (perp=10.350, rec=0.197), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.251 (perp=10.350, rec=0.181), tot_loss_proj:2.911 [t=0.29s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[ 750/2000] tot_loss=2.242 (perp=10.350, rec=0.172), tot_loss_proj:2.914 [t=0.28s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.238 (perp=10.350, rec=0.168), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.239 (perp=10.350, rec=0.169), tot_loss_proj:2.917 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[ 900/2000] tot_loss=2.248 (perp=10.350, rec=0.178), tot_loss_proj:2.909 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.908 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=2.253 (perp=10.350, rec=0.183), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1050/2000] tot_loss=2.231 (perp=10.350, rec=0.161), tot_loss_proj:2.907 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=2.244 (perp=10.350, rec=0.174), tot_loss_proj:2.906 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=2.239 (perp=10.350, rec=0.169), tot_loss_proj:2.913 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1200/2000] tot_loss=2.242 (perp=10.350, rec=0.172), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.919 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=2.249 (perp=10.350, rec=0.179), tot_loss_proj:2.909 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1350/2000] tot_loss=2.240 (perp=10.350, rec=0.170), tot_loss_proj:2.917 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=2.239 (perp=10.350, rec=0.169), tot_loss_proj:2.912 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.919 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1500/2000] tot_loss=2.233 (perp=10.350, rec=0.163), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=2.235 (perp=10.350, rec=0.165), tot_loss_proj:2.919 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=2.241 (perp=10.350, rec=0.171), tot_loss_proj:2.912 [t=0.29s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1650/2000] tot_loss=2.235 (perp=10.350, rec=0.165), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=2.230 (perp=10.350, rec=0.160), tot_loss_proj:2.916 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.911 [t=0.26s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1800/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.914 [t=0.25s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.914 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=2.230 (perp=10.350, rec=0.160), tot_loss_proj:2.916 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
[1950/2000] tot_loss=2.237 (perp=10.350, rec=0.167), tot_loss_proj:2.918 [t=0.27s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=2.232 (perp=10.350, rec=0.162), tot_loss_proj:2.915 [t=0.28s]
prediction: ['[CLS] valle perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] valle perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 79.049 | p: 77.063 | r: 81.505
rouge2     | fm: 41.119 | p: 40.294 | r: 41.937
rougeL     | fm: 72.657 | p: 70.854 | r: 74.957
rougeLsum  | fm: 72.081 | p: 70.104 | r: 74.550
r1fm+r2fm = 120.167

input #20 time: 0:11:03 | total time: 3:53:35


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
cosin similarity: -0.9150968145462328 normalized error: 1.7452712448861945
cosin similarity: 0.9150968145462328 normalized error: 0.48995361248248304
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 1.8667190857143274 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 1.6752206174896798 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 1.6601686837135479 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 1.4928408445001984 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 1.4681039903226023 for ['[CLS] bonn university on ashe shot wearing rockerlica classification speed non burning glad california againstanding colt timing mouthigo gun machinery score liked seems [SEP]']
[Init] best rec loss: 1.2771454943723175 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 1.272630955218799 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 1.2682282968996532 for ['[CLS] situationsback loan item, side rights especially pose connecticut stony there baby she general fauna size deetaking golden labor vii according bent [UNK] [SEP]']
[Init] best perm rec loss: 1.2640128982675494 for ['[CLS] pose vii size rights golden situations connecticutback stony especially labor loan there she fauna side generaltaking according, item baby [UNK] bent dee [SEP]']
[Init] best perm rec loss: 1.263095541423839 for ['[CLS] rights [UNK] item size according situationsback she golden dee baby connecticuttaking loan vii general labor bent especially pose stony there side fauna, [SEP]']
[Init] best perm rec loss: 1.2589308407412578 for ['[CLS] according baby side pose loan fauna connecticut stony situations especially general golden rights [UNK]taking labor dee item vii size she bent, thereback [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.017 (perp=12.601, rec=0.497), tot_loss_proj:3.623 [t=0.26s]
prediction: ['[CLS] according federal alleged bombing tax discrimination was on da paranoid officers worst local pope death fda tape factory failed sent america replaced become worst brain [SEP]']
[ 100/2000] tot_loss=2.898 (perp=12.529, rec=0.392), tot_loss_proj:3.612 [t=0.26s]
prediction: ['[CLS] instead issued non fixing tax discrimination were on unions worry government no local embassy prisoner fda tape foreign worst sent apple instead become worst points [SEP]']
[ 150/2000] tot_loss=2.693 (perp=11.724, rec=0.348), tot_loss_proj:3.543 [t=0.31s]
prediction: ['[CLS] instead issued non racial taxes him on cdp after absent more or embassy prison society tyres barrel mccain sent apple instead become worst affected [SEP]']
[ 200/2000] tot_loss=2.561 (perp=11.274, rec=0.307), tot_loss_proj:3.351 [t=0.27s]
prediction: ['[CLS] being athletes non military repaires all the cdp way works more or embassy prisoners society tyres hit mccain likely presented instead into worst affect [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.503 (perp=11.074, rec=0.288), tot_loss_proj:3.448 [t=0.27s]
prediction: ['[CLS] instead embassy non military repairer all the women way works instead publicly and prisoners soviet tyres iraqi mccain screens presented instead serious exception affect [SEP]']
[ 300/2000] tot_loss=2.418 (perp=10.796, rec=0.258), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS] way embassy non military repairer all the women way works instead wounded, athletes soviet out tits sell severe works instead serious exception everything [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.537 (perp=11.511, rec=0.235), tot_loss_proj:3.693 [t=0.28s]
prediction: ['[CLS] way embassy non racial repairer all women the way works instead teachings athletes athletes soviet outwaite sell severe works instead serious exception way [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.416 (perp=10.983, rec=0.219), tot_loss_proj:3.346 [t=0.26s]
prediction: ['[CLS] how embassy waytypical repairs more women the way works instead treatment athletes athletes teachings out message kick objects works instead serious moral way [SEP]']
[ 450/2000] tot_loss=2.379 (perp=10.938, rec=0.191), tot_loss_proj:3.261 [t=0.26s]
prediction: ['[CLS] that embassy alltypical offices more women the way works instead treatment athletes athletes distinguish outwaitec objects they instead serious caretaker way [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.383 (perp=10.939, rec=0.195), tot_loss_proj:3.342 [t=0.28s]
prediction: ['[CLS] makes embassy alltypical caretakers more women the way works instead treatment athletes athletes distinguish out alphabetig facto they instead serious repair way [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.304 (perp=10.676, rec=0.168), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] makes embassy alltypical caretakers more women the way works instead treatment athletes distinguish athletes out alphabetig objects they instead serious repair way [SEP]']
[ 600/2000] tot_loss=2.258 (perp=10.490, rec=0.160), tot_loss_proj:3.261 [t=0.29s]
prediction: ['[CLS] makes embassy alltypical caretakers more women the way works instead the athletes distinguish athletes out alphabetig objects it instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.443 (perp=11.391, rec=0.165), tot_loss_proj:3.476 [t=0.26s]
prediction: ['[CLS] makes corners alltypical caretaker facto more women the way works instead this athletes teachings athletes out juicyigs it instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.262 (perp=10.560, rec=0.150), tot_loss_proj:3.166 [t=0.28s]
prediction: ['[CLS] makes corners alltypical caretaker facto more women the way works instead the.typical athletes out,igs it instead serious repair way [SEP]']
[ 750/2000] tot_loss=2.247 (perp=10.487, rec=0.149), tot_loss_proj:3.157 [t=0.27s]
prediction: ['[CLS] makes corners alltypical caretaker facto more women the way works instead the juicytypical athletes out,igs it instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.193 (perp=10.280, rec=0.137), tot_loss_proj:3.066 [t=0.27s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more women like treated works instead this waytypical athletes out,,s it instead serious repair way [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.131 (perp=9.914, rec=0.148), tot_loss_proj:2.967 [t=0.28s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more like women treated works instead this waytypical athletes out,,s it instead serious repair way [SEP]']
[ 900/2000] tot_loss=2.080 (perp=9.736, rec=0.133), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] makes every alltypical caretaker necessarily more like women treated works instead this waytypical athletes out,,s this instead serious repair way [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.996 (perp=9.318, rec=0.133), tot_loss_proj:3.105 [t=0.28s]
prediction: ['[CLS] makes every alltypical caretaker necessarily more like women treated works instead this waytypical athletes out, repairs this instead serious, way [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.157 (perp=10.080, rec=0.141), tot_loss_proj:2.992 [t=0.27s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more like womenps works instead this athletestypical way out, puttings eruptions instead serious, way [SEP]']
[1050/2000] tot_loss=2.183 (perp=10.293, rec=0.124), tot_loss_proj:3.036 [t=0.26s]
prediction: ['[CLS] makes corners alltypical caretaker necessarily more like women coiled works instead this athletestypical way out, puttings eruptions instead serious, way [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.158 (perp=10.107, rec=0.137), tot_loss_proj:2.938 [t=0.27s]
prediction: ['[CLS] makes ( alltypical caretaker athletes more like women coiled works instead this monkstypical way out, puttings eruptions instead serious, way [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.181 (perp=10.278, rec=0.126), tot_loss_proj:3.157 [t=0.27s]
prediction: ['[CLS] makes corners alltypical caretakers more like women coiled works instead this monkstypical way out, putting athletes eruptions reputation serious and way [SEP]']
[1200/2000] tot_loss=2.029 (perp=9.527, rec=0.123), tot_loss_proj:2.995 [t=0.25s]
prediction: ['[CLS] makes ( alltypical caretakers more like women coiled works instead this monkstypical way out, putting athletes it reputation serious and way [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.959 (perp=9.157, rec=0.127), tot_loss_proj:2.833 [t=0.27s]
prediction: ['[CLS] makes ( alltypical caretakers more like women coiled works instead and monkstypical way out, putting athletes it reputation serious this way [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.946 (perp=9.053, rec=0.136), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] coiled ( alltypical caretakers more like women makes works instead and monkstypical way out, putting athletes it reputation serious this way [SEP]']
[1350/2000] tot_loss=1.930 (perp=9.053, rec=0.120), tot_loss_proj:2.880 [t=0.25s]
prediction: ['[CLS] coiled ( alltypical caretakers more like women makes works instead and monkstypical way out, putting athletes it reputation serious this way [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.037 (perp=9.552, rec=0.127), tot_loss_proj:3.142 [t=0.26s]
prediction: ['[CLS] coiled ( alltypical caretakers more like women makes works instead refers monkstypical way out, putting athletes, reputation serious this way [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.049 (perp=9.602, rec=0.129), tot_loss_proj:3.154 [t=0.26s]
prediction: ['[CLS]ological ( alltypical caretakers more like women makes works instead 止 monks coiled way out, putting athletes, reputation serious this way [SEP]']
[1500/2000] tot_loss=2.035 (perp=9.586, rec=0.118), tot_loss_proj:3.259 [t=0.27s]
prediction: ['[CLS]ological ( alltypical caretakers more like women makes works instead ի monks coiled way out, putting athletes, reputation serious this way [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.957 (perp=9.158, rec=0.125), tot_loss_proj:3.108 [t=0.27s]
prediction: ['[CLS]ological ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.857 (perp=8.650, rec=0.127), tot_loss_proj:3.039 [t=0.26s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
[1650/2000] tot_loss=1.854 (perp=8.650, rec=0.124), tot_loss_proj:3.044 [t=0.26s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.857 (perp=8.650, rec=0.127), tot_loss_proj:3.042 [t=0.27s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, reputation makes serious this way [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.798 (perp=8.367, rec=0.125), tot_loss_proj:3.098 [t=0.26s]
prediction: ['[CLS]typical ( allological caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
[1800/2000] tot_loss=1.832 (perp=8.566, rec=0.119), tot_loss_proj:3.058 [t=0.26s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.831 (perp=8.566, rec=0.117), tot_loss_proj:3.056 [t=0.26s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.830 (perp=8.566, rec=0.117), tot_loss_proj:3.051 [t=0.28s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
[1950/2000] tot_loss=1.837 (perp=8.566, rec=0.124), tot_loss_proj:3.055 [t=0.28s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.835 (perp=8.566, rec=0.121), tot_loss_proj:3.058 [t=0.29s]
prediction: ['[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS]typical ( alltypical caretakers more like women makes works instead monks coiled way out, putting athletes, makes reputation serious this way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 63.636 | r: 60.870
rouge2     | fm: 4.651 | p: 4.762 | r: 4.545
rougeL     | fm: 26.667 | p: 27.273 | r: 26.087
rougeLsum  | fm: 26.667 | p: 27.273 | r: 26.087
r1fm+r2fm = 66.873

[Aggregate metrics]:
rouge1     | fm: 78.237 | p: 76.480 | r: 80.557
rouge2     | fm: 39.482 | p: 38.847 | r: 40.244
rougeL     | fm: 70.615 | p: 68.890 | r: 72.779
rougeLsum  | fm: 70.308 | p: 68.512 | r: 72.403
r1fm+r2fm = 117.719

input #21 time: 0:11:08 | total time: 4:04:44


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
cosin similarity: -0.9087198991097636 normalized error: 1.8245618711317035
cosin similarity: 0.9087198991097637 normalized error: 0.45808974339065517
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 1.9687011684637357 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 1.8923598639402632 for ['[CLS] shakespeare operation emerald hip year art mcdowell model apart league rate [SEP]']
[Init] best rec loss: 1.8782002101606934 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 1.8742949802815434 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 1.8167711605783965 for ['[CLS] av waitingalis reception pillar anna deal mentionedhl etc showers [SEP]']
[Init] best rec loss: 1.7648179200842402 for ['[CLS] cloud road hey wynn under diiny stalk seduce variousour [SEP]']
[Init] best rec loss: 1.728552698662686 for ['[CLS] dialectotte [MASK] type became designing aired replacing piece dear travel [SEP]']
[Init] best rec loss: 1.7253352967604632 for ['[CLS]vi dudley sponsored then background che opposition laurencefc feat double [SEP]']
[Init] best rec loss: 1.6962413440899562 for ['[CLS] immortal dos standing commentarytort placehim corporal full cruisers carrier [SEP]']
[Init] best rec loss: 1.6901170832984254 for ['[CLS] sans services downstairsgar arched take network before simply dean jurgen [SEP]']
[Init] best rec loss: 1.611336990481398 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 1.6072025469481208 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 1.6019567471392189 for ['[CLS] phoenix her laughter over function schedule chinese boarders kids set [SEP]']
[Init] best perm rec loss: 1.6008067428671753 for ['[CLS] board chinese over function kids her phoenixers schedule set laughter [SEP]']
[Init] best perm rec loss: 1.5999882609269387 for ['[CLS] board over phoenix functioners her schedule kids laughter chinese set [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.100 (perp=11.911, rec=0.718), tot_loss_proj:3.997 [t=0.26s]
prediction: ['[CLS]?. colonel earlier an hardly engine uranium pending insufficient grossed [SEP]']
[ 100/2000] tot_loss=2.979 (perp=11.748, rec=0.630), tot_loss_proj:3.909 [t=0.27s]
prediction: ['[CLS] problem. colonel earlier a hurt recording overtime minor arrest grossed [SEP]']
[ 150/2000] tot_loss=2.997 (perp=12.087, rec=0.580), tot_loss_proj:4.222 [t=0.25s]
prediction: ['[CLS] sum his colonel earlier a communist recording some until filming austrian [SEP]']
[ 200/2000] tot_loss=3.009 (perp=12.205, rec=0.568), tot_loss_proj:4.341 [t=0.25s]
prediction: ['[CLS] fifa hit colonel thriller a communist filmed overtime joyah imprisonment liability [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.752 (perp=10.994, rec=0.553), tot_loss_proj:3.718 [t=0.26s]
prediction: ['[CLS] successful adaptation adventures thriller a film film unions joyah communist recording [SEP]']
[ 300/2000] tot_loss=2.748 (perp=11.149, rec=0.518), tot_loss_proj:3.624 [t=0.27s]
prediction: ['[CLS] successful adaptation adventures serialized a film adaptation unions cooperate communist efforts [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.980 (perp=12.299, rec=0.521), tot_loss_proj:4.017 [t=0.25s]
prediction: ['[CLS] successful adaptation tolkien a serialized film adaptation unions cooperate communist spilling [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.719 (perp=11.165, rec=0.486), tot_loss_proj:3.898 [t=0.25s]
prediction: ['[CLS] successful adaptation communist an serialized film adaptation unions repair tolkien splits [SEP]']
[ 450/2000] tot_loss=2.768 (perp=11.165, rec=0.535), tot_loss_proj:3.900 [t=0.26s]
prediction: ['[CLS] successful adaptation communist an serialized film adaptation unions repair tolkien splits [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.679 (perp=10.964, rec=0.486), tot_loss_proj:3.918 [t=0.27s]
prediction: ['[CLS] successful adaptation communist serialized film an adaptation unions repair tolkien browser [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.669 (perp=11.015, rec=0.466), tot_loss_proj:3.080 [t=0.29s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation unions enjoyable tolkien splits [SEP]']
[ 600/2000] tot_loss=2.695 (perp=11.015, rec=0.492), tot_loss_proj:3.085 [t=0.30s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation unions enjoyable tolkien splits [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.848 (perp=11.855, rec=0.477), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation a enjoyable finnish splits [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.666 (perp=11.149, rec=0.436), tot_loss_proj:3.156 [t=0.26s]
prediction: ['[CLS] successful adaptation communist serialized an enjoyable adaptation a finnish enjoyable splits [SEP]']
[ 750/2000] tot_loss=2.756 (perp=11.651, rec=0.426), tot_loss_proj:3.190 [t=0.27s]
prediction: ['[CLS] successful adaptation communist quick an enjoyable adaptation a finnish enjoyable splits [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.618 (perp=10.855, rec=0.447), tot_loss_proj:2.950 [t=0.27s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.609 (perp=10.855, rec=0.438), tot_loss_proj:2.955 [t=0.28s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
[ 900/2000] tot_loss=2.619 (perp=10.855, rec=0.448), tot_loss_proj:2.945 [t=0.27s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.876 (perp=10.855, rec=0.705), tot_loss_proj:2.942 [t=0.27s]
prediction: ['[CLS] successful adaptation election successful an enjoyable adaptation a finnish enjoyableouring [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.803 (perp=11.603, rec=0.482), tot_loss_proj:3.784 [t=0.26s]
prediction: ['[CLS] successful adaptation election successful compilation successful adaptation a finnish excuse splits [SEP]']
[1050/2000] tot_loss=2.821 (perp=11.885, rec=0.444), tot_loss_proj:3.271 [t=0.27s]
prediction: ['[CLS] successful adaptation election successful enjoyable successful adaptation a finnish enjoyable splits [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.765 (perp=11.630, rec=0.439), tot_loss_proj:3.111 [t=0.27s]
prediction: ['[CLS] successful successful a successful enjoyable successful adaptation election finnish enjoyable splits [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.759 (perp=11.641, rec=0.431), tot_loss_proj:3.143 [t=0.26s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election finnish enjoyable splits [SEP]']
[1200/2000] tot_loss=2.614 (perp=11.000, rec=0.414), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1250/2000] tot_loss=2.614 (perp=11.000, rec=0.414), tot_loss_proj:3.131 [t=0.25s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1300/2000] tot_loss=2.642 (perp=11.000, rec=0.442), tot_loss_proj:3.128 [t=0.28s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
[1350/2000] tot_loss=2.601 (perp=11.000, rec=0.401), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] successful successful a quick successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1400/2000] tot_loss=2.604 (perp=10.956, rec=0.413), tot_loss_proj:3.061 [t=0.28s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1450/2000] tot_loss=2.595 (perp=10.956, rec=0.404), tot_loss_proj:3.064 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
[1500/2000] tot_loss=2.589 (perp=10.956, rec=0.398), tot_loss_proj:3.060 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election succeeded enjoyableouring [SEP]']
Attempt swap
[1550/2000] tot_loss=2.582 (perp=10.940, rec=0.394), tot_loss_proj:2.904 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1600/2000] tot_loss=2.581 (perp=10.940, rec=0.393), tot_loss_proj:2.906 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
[1650/2000] tot_loss=2.572 (perp=10.940, rec=0.384), tot_loss_proj:2.898 [t=0.27s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1700/2000] tot_loss=2.579 (perp=10.940, rec=0.391), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1750/2000] tot_loss=2.580 (perp=10.940, rec=0.392), tot_loss_proj:2.903 [t=0.30s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
[1800/2000] tot_loss=2.580 (perp=10.940, rec=0.392), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1850/2000] tot_loss=2.578 (perp=10.940, rec=0.390), tot_loss_proj:2.905 [t=0.25s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[1900/2000] tot_loss=2.576 (perp=10.940, rec=0.388), tot_loss_proj:2.908 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
[1950/2000] tot_loss=2.565 (perp=10.940, rec=0.377), tot_loss_proj:2.905 [t=0.25s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Attempt swap
[2000/2000] tot_loss=2.575 (perp=10.940, rec=0.387), tot_loss_proj:2.903 [t=0.26s]
prediction: ['[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] successful successful a successful successful enjoyable adaptation election happiness enjoyableouring [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.000 | p: 50.000 | r: 46.154
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 40.000 | p: 41.667 | r: 38.462
rougeLsum  | fm: 40.000 | p: 41.667 | r: 38.462
r1fm+r2fm = 56.696

[Aggregate metrics]:
rouge1     | fm: 77.057 | p: 75.386 | r: 79.037
rouge2     | fm: 38.006 | p: 37.509 | r: 38.694
rougeL     | fm: 69.333 | p: 67.795 | r: 71.124
rougeLsum  | fm: 68.849 | p: 67.278 | r: 70.869
r1fm+r2fm = 115.064

input #22 time: 0:11:06 | total time: 4:15:50


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
cosin similarity: 0.9513774856923713 normalized error: 0.4344634306918702
cosin similarity: -0.9513774856923713 normalized error: 1.8373279839573082
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 1.3518757628141271 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 1.3198257475467645 for ['[CLS] jumped its ion [MASK] deep spirit tracks controls spun donated tape calendar ineligible martial airport breaths complexvas net straight vs # jake featurebal each roots record death share troubles chance scores mate frank holding quest exactlyul governments win far ap gathering toysience married club [SEP]']
[Init] best rec loss: 1.30550744134911 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 1.2570864343922903 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 1.2145625932985147 for ['[CLS] talent cause skirt handled ⁴ anne pieces mine! caused safety tor goal fore 2014 residents chosen offering chiefs number sun consumergementni property riding dolphin exchequerada saw occupants trades vale course kind coronation ballroom dona village totally selena winds firstd sums manga square scholar [SEP]']
[Init] best perm rec loss: 1.2142063278498108 for ['[CLS] pieces number talent course property occupants residents ⁴ dona ballroom safety village totally manga chiefs sums valeada scholar riding!d coronation square sun handled consumer winds tor chosen saw goal offering anne mine trades first dolphin causegement caused skirt fore selena exchequer 2014 kindni [SEP]']
[Init] best perm rec loss: 1.2127282717891918 for ['[CLS] cause dolphin manga trades scholar skirt pieces tor offering occupants anne saw dona riding ⁴ chiefsni 2014 goal totally safety numberada talent sums winds village consumer mine residents! caused selena ballroom square coronationd kind first chosen sun vale property course exchequergement fore handled [SEP]']
[Init] best perm rec loss: 1.2119208803839943 for ['[CLS] number sun 2014 first coronation consumer course residents village caused totally saw selena trades dolphin exchequer propertyd chosenni manga offering square safety tor minegement fore! causeada riding chiefs handled scholar talent anne ⁴ skirt dona sums winds goal vale occupants ballroom kind pieces [SEP]']
[Init] best perm rec loss: 1.2111210877200476 for ['[CLS] 2014 sumsd skirt occupants talent pieces number sun saw consumer square totallyni first exchequer ⁴ coronation cause trades ballroom handled residents! village riding dolphin valeada dona caused offering chosen tor fore property mine course goal kind selena safety chiefs scholar mangagement winds anne [SEP]']
[Init] best perm rec loss: 1.210146347666845 for ['[CLS]d first!ada riding chiefs consumer winds selenagement exchequer mine sums 2014 caused fore number ballroom property sun saw offering village residents course talent vale pieces scholar safety ⁴ torni cause square dolphin anne occupants kind manga coronation totally handled trades goal skirt dona chosen [SEP]']
[Init] best perm rec loss: 1.2095988735355152 for ['[CLS] ⁴ tor village residents course square chosen consumer occupantsgement handled saw! ballroom sun chiefs coronation safety first kind offering selena exchequer trades mine caused pieces skirt dona riding sums caused scholar fore 2014 anne propertyni dolphin totally windsada talent vale number manga goal [SEP]']
[Init] best perm rec loss: 1.207835147944121 for ['[CLS] goal saw ridinggement chosenni tor skirtada offering pieces trades mine consumer occupants safety sums dona kind anned exchequer manga ballroom talent totally fore! village first dolphin square selena handled cause property vale sun winds coronation 2014 number caused scholar course chiefs residents ⁴ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.757 (perp=10.958, rec=0.566), tot_loss_proj:3.360 [t=0.28s]
prediction: ["[CLS] lehigh combat box media group [SEP] engineering vision 2013 patrick art vc daily environment program uk : t with lifelong goal caring visual critical vision programminging orange year josh lonely c arsre oriented movement vale best therefore visual include contents'scholar paid pinch past 35 [SEP]"]
[ 100/2000] tot_loss=2.924 (perp=12.618, rec=0.400), tot_loss_proj:3.702 [t=0.26s]
prediction: ['[CLS] ricanvich devi media group [SEP] engineering southwest deliberately × war vc compassionead ghana also : bits thisir t sustainablehyllum critical vision globalf fighting action josh frowning feeling is expression information bnched best identify visual atlanta contents co scholar paid give past 35 [SEP]']
[ 150/2000] tot_loss=2.787 (perp=12.213, rec=0.345), tot_loss_proj:3.632 [t=0.27s]
prediction: ['[CLS] your fist devi conceptual medal constitution message environmental [SEP] × soldiers vc concernedt traumatic also : soldiers this object she caring joyah frederick visual :f battle ground its objective subjects is expression information bone fe best identify gaze nc contents should helping out give mission colleges [SEP]']
[ 200/2000] tot_loss=2.641 (perp=11.738, rec=0.293), tot_loss_proj:3.417 [t=0.26s]
prediction: ['[CLS] many the " concept its constitution tone vietnam [SEP] how soldiers vc concernedt traumatic also : soldiers this object threat caring joyah₍ realm :f battle field its objective : : proportion information dress hardin otherwise theory gaze nc vast co helping made give mission missions [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.372 (perp=10.478, rec=0.276), tot_loss_proj:3.101 [t=0.26s]
prediction: ['[CLS] your the : concept its theater picture vietnam [SEP] how soldiers, conflictt also : soldiers this object completely human foundation museum vietnam realm :f strategic ground its objective : : proportion information dress stress otherwise theory looksboro an a helping made to immediate missions [SEP]']
[ 300/2000] tot_loss=2.314 (perp=10.359, rec=0.242), tot_loss_proj:3.188 [t=0.27s]
prediction: ['[CLS] many the : idea its theater picture vietnam allmusic unfamiliar soldiers, create - of : soldiers this object despite popular foundation joyah vietnam goal :h strategic ground its objective : : proportion strategic dress stress otherwise theory - montreal its a helping made to immediate missions [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.208 (perp=9.945, rec=0.219), tot_loss_proj:3.151 [t=0.26s]
prediction: ['[CLS] many unfamiliar : idea its theater picture vietnam allmusic the soldiers, create, of : soldiers also object despite popular foundation joyah vietnam goal :h strategic centre its objective : : proportion strategic the stress otherwise theory -sboro an to helping made to immediate missions [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.328 (perp=10.623, rec=0.203), tot_loss_proj:3.459 [t=0.25s]
prediction: ['[CLS] many unfamiliar : idea its theater picture vietnam quickly the soldiers, create - vietnam of soldiers ultimately ultimately despite popular charitable joyah of goal lifeh strategic genus its objective : : proportion strategic the stress otherwise theory -sboro afi the helping made to main missions [SEP]']
[ 450/2000] tot_loss=2.264 (perp=10.314, rec=0.201), tot_loss_proj:3.376 [t=0.27s]
prediction: ['[CLS] many unfamiliar : idea its theater picture vietnam achieve the soldiers, create, vietnam of soldiers ultimately ultimately despite mainstream charitable joyah of goal lifeh strategic idea its objective : : the strategic the stress so theory -sboro afi the helping made to main missions [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.247 (perp=10.288, rec=0.189), tot_loss_proj:3.377 [t=0.26s]
prediction: ['[CLS] many unfamiliar : idea its objective picture vietnam achieve a soldiers, create, vietnam of soldiers ultimately ultimately despite mainstream charitable joyah of goal lifeh strategic idea its objective : : procession relationship the stress so strategic - kaladin afi the helping made to main missions [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.252 (perp=10.362, rec=0.180), tot_loss_proj:3.152 [t=0.27s]
prediction: ['[CLS] many unfamiliar : idea its objective picture achieve a soldiers, vietnam create, vietnam of soldiers ultimately ultimately their mainstream charitable joyah of goal lifeh strategic idea main objective : : pest relationship the stress so strategic - achieved afi the helping so to main missions [SEP]']
[ 600/2000] tot_loss=2.103 (perp=9.650, rec=0.173), tot_loss_proj:3.069 [t=0.27s]
prediction: ['[CLS] manyndra : idea its objective picture achieve a soldiers, vietnam build, vietnam of soldiers ultimately ultimately despite mainstream same joyah of goal lifeh strategic idea main objective : : the relationship the stress so strategic of achievedizing the helping so to main missions [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.101 (perp=9.681, rec=0.165), tot_loss_proj:2.940 [t=0.26s]
prediction: ['[CLS] manyrnik : idea to strategic picture achieve a soldiers, vietnam create, vietnam, soldiers ultimately ultimately its mainstream same joyah of objective life ra strategic idea main objective : :zing relationship theposed. strategic of achievedizing the helping so its main missions [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.117 (perp=9.767, rec=0.163), tot_loss_proj:2.965 [t=0.28s]
prediction: ['[CLS] althoughrnik : idea to strategic picture achieve a soldiers, vietnam create, vietnam, soldiers ultimately ultimately knowles mainstream same joyah life objective a ra strategic idea main objective : :zing relationship theposed. strategic of achievedizing the helping so its main missions [SEP]']
[ 750/2000] tot_loss=2.112 (perp=9.760, rec=0.160), tot_loss_proj:2.975 [t=0.26s]
prediction: ['[CLS] althoughrnik : idea to strategic picture achieve a soldiers, vietnam create, vietnam, soldiers ultimately ultimately knowles mainstream same joyah life objective a ra strategic idea main objective : :zing relationship theeering. strategic of kaladinizing the helping so its main missions [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.130 (perp=9.892, rec=0.151), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] althoughrnik : idea to strategic picture create achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately knowles mainstream same joyah lives objective a ra strategic idea main objective : :zing relationship the ـ. strategic of kaladinizing the helping so its main missions [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.121 (perp=9.838, rec=0.154), tot_loss_proj:3.040 [t=0.27s]
prediction: ['[CLS] althoughndra : idea to strategic picture create achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately knowleseses successful joyah lives objective a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinizing the helping so its main missions [SEP]']
[ 900/2000] tot_loss=2.113 (perp=9.839, rec=0.145), tot_loss_proj:3.035 [t=0.27s]
prediction: ['[CLS] althoughndra : idea to strategic picture create achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately withouteses successful joyah lives objective a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinizing the helping so its main missions [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.050 (perp=9.500, rec=0.150), tot_loss_proj:2.975 [t=0.28s]
prediction: ['[CLS] althoughndra : idea create strategic picture to achieve a soldiers, vietnam, vietnam, soldiers ultimately ultimately knowleseses successful joyah lives objective a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinizing the helping after its main missions [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.034 (perp=9.436, rec=0.146), tot_loss_proj:2.927 [t=0.29s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately itseses what joyah lives a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinenting the helping after its main missions [SEP]']
[1050/2000] tot_loss=2.033 (perp=9.436, rec=0.145), tot_loss_proj:2.921 [t=0.28s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately itseses what joyah lives a ra strategic idea main objective : :zing of the ـ. strategic relationship kaladinenting the helping after its main missions [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.100 (perp=9.826, rec=0.135), tot_loss_proj:3.060 [t=0.27s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its ra foreign same joyah lives a strategic idea main objective : strategiczing ofh ـ. strategic relationship kaladinenting the helping after its main missions [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.995 (perp=9.286, rec=0.138), tot_loss_proj:2.937 [t=0.27s]
prediction: ['[CLS] althoughching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its ra foreign what joyah lives a strategic idea main objective : dramazing of the ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
[1200/2000] tot_loss=2.032 (perp=9.492, rec=0.134), tot_loss_proj:2.951 [t=0.28s]
prediction: ['[CLS] whileching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its ra foreignzing joyah lives a strategic idea main objective : dramazing ofh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.943 (perp=9.029, rec=0.137), tot_loss_proj:2.858 [t=0.28s]
prediction: ['[CLS] whileching : idea create strategic picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.940 (perp=8.968, rec=0.146), tot_loss_proj:2.835 [t=0.27s]
prediction: ['[CLS] whileching : strategic idea create picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
[1350/2000] tot_loss=1.934 (perp=8.968, rec=0.140), tot_loss_proj:2.830 [t=0.26s]
prediction: ['[CLS] whileching : strategic idea create picture to achieve a objective soldiers, vietnam tone vietnam, soldiers ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic relationship kaladinenting the helping. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.923 (perp=8.894, rec=0.144), tot_loss_proj:2.824 [t=0.28s]
prediction: ['[CLS] while ( : strategic idea create picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladinenting the helping. after its main missions [SEP]']
Attempt swap
[1450/2000] tot_loss=1.936 (perp=9.014, rec=0.133), tot_loss_proj:2.833 [t=0.27s]
prediction: ['[CLS] whileching : strategic idea create picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
[1500/2000] tot_loss=1.927 (perp=8.976, rec=0.132), tot_loss_proj:2.858 [t=0.27s]
prediction: ['[CLS] while ( : strategic idea create picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.896 (perp=8.798, rec=0.137), tot_loss_proj:2.824 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea main objective : dramazing of foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.843 (perp=8.570, rec=0.129), tot_loss_proj:2.791 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramazing foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
[1650/2000] tot_loss=1.842 (perp=8.570, rec=0.128), tot_loss_proj:2.787 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramazing foreignh ـ strategic text kaladin drama the helping. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.820 (perp=8.466, rec=0.127), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text kaladin helping the drama. after its main missions [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.791 (perp=8.334, rec=0.125), tot_loss_proj:2.858 [t=0.28s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
[1800/2000] tot_loss=1.790 (perp=8.334, rec=0.124), tot_loss_proj:2.857 [t=0.25s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a ultimately soldiers, vietnam tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.779 (perp=8.229, rec=0.133), tot_loss_proj:2.826 [t=0.28s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Attempt swap
[1900/2000] tot_loss=1.775 (perp=8.229, rec=0.129), tot_loss_proj:2.819 [t=0.26s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.229, rec=0.120), tot_loss_proj:2.829 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve a soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Attempt swap
[2000/2000] tot_loss=1.765 (perp=8.146, rec=0.135), tot_loss_proj:2.803 [t=0.27s]
prediction: ['[CLS] while ( create strategic idea : picture to achieve the soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] while ( create strategic idea : picture to achieve the soldiers, vietnam ultimately tone soldiers, vietnam ultimately ultimately its razing joyah lives a strategic idea of main objective : dramati foreignh ـ strategic text. helping the drama kaladin after its main missions [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.000 | p: 45.000 | r: 45.000
rouge2     | fm: 10.256 | p: 10.256 | r: 10.256
rougeL     | fm: 32.500 | p: 32.500 | r: 32.500
rougeLsum  | fm: 32.500 | p: 32.500 | r: 32.500
r1fm+r2fm = 55.256

[Aggregate metrics]:
rouge1     | fm: 75.602 | p: 74.131 | r: 77.627
rouge2     | fm: 37.090 | p: 36.396 | r: 37.871
rougeL     | fm: 67.639 | p: 66.043 | r: 69.520
rougeLsum  | fm: 67.260 | p: 65.767 | r: 69.133
r1fm+r2fm = 112.692

input #23 time: 0:11:09 | total time: 4:27:00


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
cosin similarity: -0.9223604647986088 normalized error: 1.7670051703009635
cosin similarity: 0.9223604647986089 normalized error: 0.47736402311244497
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 1.8235173558366566 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 1.690636250427732 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 1.6660788999609562 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 1.639423956785702 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 1.3858401992514717 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 1.1764352784900491 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 1.174503061829458 for ['[CLS] bondwyl unless county em arms damned happy suffer play attack younger ryu midaneous bush snow village no port [SEP]']
[Init] best perm rec loss: 1.1737241560296066 for ['[CLS]wyl play county ryu village arms younger port mid bond attack em bush suffer damnedaneous no snow happy unless [SEP]']
[Init] best perm rec loss: 1.1691451229159813 for ['[CLS] younger port ryu countyaneous attack arms village bushwyl bond snow unless mid em no suffer happy play damned [SEP]']
[Init] best perm rec loss: 1.1685529381675073 for ['[CLS] bond ryu port county attack play village arms happywyl snow unless bush younger mid suffer no emaneous damned [SEP]']
[Init] best perm rec loss: 1.1671323903442032 for ['[CLS] portaneous play suffer attack arms bond ryu damned county snowwyl em bush happy mid village unless younger no [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.890 (perp=12.173, rec=0.455), tot_loss_proj:3.490 [t=0.27s]
prediction: ['[CLS] bad monitoring b tamil terrorists someone drug kanye destroy terrorist drug? phone constituency tribunal [ were taken evil interpret [SEP]']
[ 100/2000] tot_loss=2.848 (perp=12.444, rec=0.359), tot_loss_proj:3.471 [t=0.30s]
prediction: ['[CLS] bad marty a plot terrorists % bomb cruz stealing terrorist drug? research constituency tribunal narrower were taken evil terrorists [SEP]']
[ 150/2000] tot_loss=2.138 (perp=9.131, rec=0.312), tot_loss_proj:2.824 [t=0.29s]
prediction: ['[CLS] context context : are terrorists any bomb! terrorists terrorist protection? political context beings outside were taken evil terrorists [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.154, rec=0.232), tot_loss_proj:2.991 [t=0.26s]
prediction: ['[CLS] context context context are terrorists else (! terrorists terrorist his? political context beings outside were taken evil terrorists [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.174 (perp=9.868, rec=0.200), tot_loss_proj:2.957 [t=0.27s]
prediction: ['[CLS] context context the are taken % (! terrorists terrorist against of bombs context! outside were terrorists evil terrorists [SEP]']
[ 300/2000] tot_loss=2.166 (perp=9.928, rec=0.181), tot_loss_proj:2.916 [t=0.27s]
prediction: ['[CLS] context ( the are taken % (! terrorists terrorist political of political context! outside stare terrorists evil terrorists [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.214 (perp=10.244, rec=0.166), tot_loss_proj:2.984 [t=0.27s]
prediction: ['[CLS] context ( the stare taken than ( see abuse terrorist political of climate context than outside are terrorists evil economically [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.230 (perp=10.370, rec=0.156), tot_loss_proj:3.015 [t=0.29s]
prediction: ['[CLS] context ( the are taken than ( see environmental terrorist political ( climate context than outside are terrorists evil economically [SEP]']
[ 450/2000] tot_loss=2.238 (perp=10.494, rec=0.139), tot_loss_proj:3.032 [t=0.29s]
prediction: ['[CLS] context ( the are taken than ( see climate terrorist political ( climate context than outside are terrorists evil economically [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.268 (perp=10.654, rec=0.138), tot_loss_proj:3.153 [t=0.27s]
prediction: ['[CLS] ( context the are taken than ( see climate allah political ( climate context than outside are terrorists evil economically [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.063 (perp=9.657, rec=0.132), tot_loss_proj:3.009 [t=0.29s]
prediction: ['[CLS] ( context the are taken than ( see climate allah political current climate context! outside terrorists are evil economically [SEP]']
[ 600/2000] tot_loss=2.132 (perp=10.039, rec=0.125), tot_loss_proj:3.020 [t=0.28s]
prediction: ['[CLS] ( context the of taken than ( see climate allah political current climate context! outside terrorists are evil economically [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.021 (perp=9.498, rec=0.121), tot_loss_proj:2.832 [t=0.29s]
prediction: ['[CLS] ( context the political taken than ( see climate allah of current climate context! outside terrorists are evil economically [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.000 (perp=9.394, rec=0.122), tot_loss_proj:2.842 [t=0.25s]
prediction: ['[CLS] ( taken the political context than ( see abuse allah of current climate context! outside terrorists more evil economically [SEP]']
[ 750/2000] tot_loss=1.992 (perp=9.394, rec=0.113), tot_loss_proj:2.845 [t=0.26s]
prediction: ['[CLS] ( taken the political context than ( see abuse allah of current climate context! outside terrorists more evil economically [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.966 (perp=9.201, rec=0.125), tot_loss_proj:2.717 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see abuse terrorists of current context context! outside terrorists more evil economically [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.940 (perp=9.107, rec=0.119), tot_loss_proj:2.792 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context terrorists of current contextout! outside terrorists more evil lebanon [SEP]']
[ 900/2000] tot_loss=1.937 (perp=9.107, rec=0.116), tot_loss_proj:2.791 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than ( see context terrorists of current contextout! outside terrorists more evil lebanon [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.862 (perp=8.720, rec=0.117), tot_loss_proj:2.824 [t=0.26s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1000/2000] tot_loss=1.850 (perp=8.720, rec=0.106), tot_loss_proj:2.825 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
[1050/2000] tot_loss=1.851 (perp=8.720, rec=0.107), tot_loss_proj:2.823 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1100/2000] tot_loss=1.857 (perp=8.720, rec=0.113), tot_loss_proj:2.827 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1150/2000] tot_loss=1.861 (perp=8.720, rec=0.117), tot_loss_proj:2.827 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
[1200/2000] tot_loss=1.866 (perp=8.720, rec=0.122), tot_loss_proj:2.829 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil lebanon [SEP]']
Attempt swap
[1250/2000] tot_loss=1.901 (perp=8.948, rec=0.112), tot_loss_proj:2.779 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1300/2000] tot_loss=1.894 (perp=8.948, rec=0.105), tot_loss_proj:2.777 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
[1350/2000] tot_loss=1.899 (perp=8.948, rec=0.110), tot_loss_proj:2.777 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1400/2000] tot_loss=1.895 (perp=8.948, rec=0.105), tot_loss_proj:2.781 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1450/2000] tot_loss=1.898 (perp=8.948, rec=0.108), tot_loss_proj:2.781 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
[1500/2000] tot_loss=1.901 (perp=8.948, rec=0.112), tot_loss_proj:2.784 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1550/2000] tot_loss=1.896 (perp=8.948, rec=0.106), tot_loss_proj:2.778 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.816 (perp=8.565, rec=0.103), tot_loss_proj:2.712 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than context ( see context of current _out! outside terrorists more evil lebanon [SEP]']
[1650/2000] tot_loss=1.864 (perp=8.786, rec=0.107), tot_loss_proj:2.696 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than context ( see context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
[1700/2000] tot_loss=1.864 (perp=8.786, rec=0.107), tot_loss_proj:2.690 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than context ( see context of current _out! outside terrorists more evil respective [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.799 (perp=8.428, rec=0.113), tot_loss_proj:2.654 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more evil context [SEP]']
[1800/2000] tot_loss=1.800 (perp=8.428, rec=0.114), tot_loss_proj:2.653 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more evil context [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.782 (perp=8.346, rec=0.113), tot_loss_proj:2.600 [t=0.29s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more context evil [SEP]']
Attempt swap
[1900/2000] tot_loss=1.777 (perp=8.346, rec=0.108), tot_loss_proj:2.602 [t=0.28s]
prediction: ['[CLS] ( taken the political climate than intellectual ( see context of current _out! outside terrorists more context evil [SEP]']
[1950/2000] tot_loss=1.809 (perp=8.546, rec=0.100), tot_loss_proj:2.648 [t=0.27s]
prediction: ['[CLS] ( taken the political climate than respective ( see context of current _out! outside terrorists more context evil [SEP]']
Attempt swap
[2000/2000] tot_loss=1.805 (perp=8.546, rec=0.096), tot_loss_proj:2.648 [t=0.30s]
prediction: ['[CLS] ( taken the political climate than respective ( see context of current _out! outside terrorists more context evil [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] ( taken the political climate than ( see context context of current _out! outside terrorists more evil respective [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 23.529 | p: 23.529 | r: 23.529
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 106.863

[Aggregate metrics]:
rouge1     | fm: 76.019 | p: 74.563 | r: 78.027
rouge2     | fm: 36.442 | p: 35.859 | r: 37.005
rougeL     | fm: 67.312 | p: 65.920 | r: 69.064
rougeLsum  | fm: 66.751 | p: 65.329 | r: 68.704
r1fm+r2fm = 112.461

input #24 time: 0:11:18 | total time: 4:38:18


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
cosin similarity: 0.9657079483269472 normalized error: 0.40029975426057546
cosin similarity: -0.9657079483269473 normalized error: 1.9019384309452168
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.921533046557849 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 1.8493198516179912 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 1.6627446159709092 for ['[CLS] merit delaney canoniary [SEP]']
[Init] best rec loss: 1.6268557675971966 for ['[CLS] james adding letters received [SEP]']
[Init] best rec loss: 1.4347181383026864 for ['[CLS] mention acre old headline [SEP]']
[Init] best rec loss: 1.4075943361424101 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best rec loss: 1.2928002379071515 for ['[CLS] hide a seal mess [SEP]']
[Init] best perm rec loss: 1.286761864923727 for ['[CLS] hide seal mess a [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.258, rec=0.436), tot_loss_proj:3.171 [t=0.26s]
prediction: ['[CLS] portrait striking february natural [SEP]']
[ 100/2000] tot_loss=1.899 (perp=8.063, rec=0.287), tot_loss_proj:2.198 [t=0.28s]
prediction: ['[CLS] beautiful beautiful strange beautiful [SEP]']
[ 150/2000] tot_loss=2.278 (perp=10.292, rec=0.219), tot_loss_proj:2.621 [t=0.27s]
prediction: ['[CLS] film beautiful strange beautiful [SEP]']
[ 200/2000] tot_loss=2.577 (perp=11.985, rec=0.180), tot_loss_proj:2.902 [t=0.26s]
prediction: ['[CLS] film & strange beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.876 (perp=8.556, rec=0.165), tot_loss_proj:2.195 [t=0.27s]
prediction: ['[CLS] film strange & beautiful [SEP]']
[ 300/2000] tot_loss=1.745 (perp=8.016, rec=0.142), tot_loss_proj:2.016 [t=0.28s]
prediction: ['[CLS] film strange and beautiful [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.466 (perp=6.646, rec=0.136), tot_loss_proj:1.538 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.463 (perp=6.646, rec=0.134), tot_loss_proj:1.527 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.457 (perp=6.646, rec=0.128), tot_loss_proj:1.539 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.456 (perp=6.646, rec=0.126), tot_loss_proj:1.533 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.523 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.452 (perp=6.646, rec=0.123), tot_loss_proj:1.530 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.446 (perp=6.646, rec=0.116), tot_loss_proj:1.528 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.460 (perp=6.646, rec=0.130), tot_loss_proj:1.520 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.452 (perp=6.646, rec=0.123), tot_loss_proj:1.519 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.451 (perp=6.646, rec=0.122), tot_loss_proj:1.534 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.646, rec=0.124), tot_loss_proj:1.524 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.459 (perp=6.646, rec=0.129), tot_loss_proj:1.522 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.439 (perp=6.646, rec=0.110), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.449 (perp=6.646, rec=0.120), tot_loss_proj:1.523 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.440 (perp=6.646, rec=0.111), tot_loss_proj:1.533 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.524 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.446 (perp=6.646, rec=0.117), tot_loss_proj:1.526 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.449 (perp=6.646, rec=0.119), tot_loss_proj:1.530 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.454 (perp=6.646, rec=0.124), tot_loss_proj:1.527 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.446 (perp=6.646, rec=0.117), tot_loss_proj:1.535 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.448 (perp=6.646, rec=0.118), tot_loss_proj:1.532 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.466 (perp=6.646, rec=0.137), tot_loss_proj:1.519 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.646, rec=0.130), tot_loss_proj:1.519 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.453 (perp=6.646, rec=0.124), tot_loss_proj:1.522 [t=0.29s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.646, rec=0.118), tot_loss_proj:1.538 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.443 (perp=6.646, rec=0.113), tot_loss_proj:1.523 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.453 (perp=6.646, rec=0.123), tot_loss_proj:1.529 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.531 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.436 (perp=6.646, rec=0.107), tot_loss_proj:1.531 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.454 (perp=6.646, rec=0.125), tot_loss_proj:1.536 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.448 (perp=6.646, rec=0.119), tot_loss_proj:1.527 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.447 (perp=6.646, rec=0.118), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.443 (perp=6.646, rec=0.114), tot_loss_proj:1.516 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.452 (perp=6.646, rec=0.122), tot_loss_proj:1.518 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.822 | p: 75.505 | r: 78.660
rouge2     | fm: 38.290 | p: 37.782 | r: 39.042
rougeL     | fm: 68.312 | p: 66.996 | r: 70.104
rougeLsum  | fm: 68.056 | p: 66.634 | r: 69.893
r1fm+r2fm = 115.112

input #25 time: 0:11:08 | total time: 4:49:26


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
cosin similarity: -0.9021100735279437 normalized error: 1.801235038259484
cosin similarity: 0.9021100735279438 normalized error: 0.4706903940273791
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 1.8009709819325461 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 1.790939063684656 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 1.6105957617002156 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 1.5392134365327053 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 1.4764521072094978 for ['[CLS]sed benedict later housing why surroundingpinegrave nat use amount cast thy scored pattern run unknown authority travellingflict quotes guest lucan [SEP]']
[Init] best rec loss: 1.348597712309089 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 1.347903887077467 for ['[CLS] stakekar passing rides 65 turns speak mutant montrose capacity rid fur unite button riceª ak occupied cher following fully igo [SEP]']
[Init] best perm rec loss: 1.3444805281045762 for ['[CLS] rides stake occupiedª turns buttonkar capacity i following fur mutant passing speak fullygo cher rice 65 montrose ak unite rid [SEP]']
[Init] best perm rec loss: 1.32912584483422 for ['[CLS] i akgo passing 65 fur rid occupied capacity stake speak rice turns montrose unite rides button following fullyª cherkar mutant [SEP]']
[Init] best perm rec loss: 1.3274400066740004 for ['[CLS] occupied i button following akgo fur passing unite 65 rides mutant rice stake cherkar turns montrose fully speak capacity ridª [SEP]']
[Init] best perm rec loss: 1.3215558131738496 for ['[CLS] speak ak occupied capacity rid montrose i 65 fur ricego fully button passing turns rides stake cher uniteª mutantkar following [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.030 (perp=12.754, rec=0.479), tot_loss_proj:3.462 [t=0.27s]
prediction: ['[CLS] constituency national illegal money infrastructure attack stupid losing barrel guinea tape worm legislature " illegal leaders governmentgo government at dumb use scare [SEP]']
[ 100/2000] tot_loss=2.796 (perp=12.237, rec=0.349), tot_loss_proj:3.336 [t=0.27s]
prediction: ['[CLS] american national response money - attack pointless lost senate foreigners rican or canadiens in illegal farmers councilzi maybepa useless entrancegate [SEP]']
[ 150/2000] tot_loss=2.603 (perp=11.553, rec=0.292), tot_loss_proj:3.173 [t=0.28s]
prediction: ['[CLS] coming national bc network - entirely pointless shed import frenchboarding - import to youngest parties policezi maybepa pointless entrancegate [SEP]']
[ 200/2000] tot_loss=2.528 (perp=11.303, rec=0.268), tot_loss_proj:3.099 [t=0.30s]
prediction: ['[CLS] import national bc network - quite pointless shed import french importusly import totorium parties policezi importswal pointless importgate [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.514 (perp=11.354, rec=0.243), tot_loss_proj:3.130 [t=0.28s]
prediction: ['[CLS] coming national bc network - ) pointless import maybe french importusly import to age parties policeław importswal pointless importeron [SEP]']
[ 300/2000] tot_loss=2.495 (perp=11.367, rec=0.222), tot_loss_proj:3.099 [t=0.27s]
prediction: ['[CLS] coming national bc programme - ) pointless import coming import import sept import by sophie russians policeław importwal pointless importeron [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.548 (perp=11.644, rec=0.219), tot_loss_proj:3.162 [t=0.27s]
prediction: ['[CLS] coming national bc drug and ) french import coming pointless importterol import through sophie russians policeław importwal pointless importpoint [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.342 (perp=10.643, rec=0.214), tot_loss_proj:2.964 [t=0.25s]
prediction: ['[CLS] import ) bc campaign and ) french age coming pointless import sophie analysisusly import through policeław importwal pointless importpoint [SEP]']
[ 450/2000] tot_loss=2.479 (perp=11.464, rec=0.187), tot_loss_proj:3.103 [t=0.28s]
prediction: ['[CLS] this ) bc drug and ) french age coming pointless import sophie translatorusly import through policeław import ha pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.347 (perp=10.902, rec=0.167), tot_loss_proj:2.923 [t=0.28s]
prediction: ['[CLS] from )ing drug and ) french age coming pointless import sophie directorusly import through policemen this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.232 (perp=10.321, rec=0.167), tot_loss_proj:2.830 [t=0.28s]
prediction: ['[CLS] from thising drug and ) french age coming pointless import sophie importusly director through policemen this wo pointless importroller [SEP]']
[ 600/2000] tot_loss=2.287 (perp=10.685, rec=0.150), tot_loss_proj:2.922 [t=0.27s]
prediction: ['[CLS] from thising drug and ) french age coming pointless import sophie importject director through policeław this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.264 (perp=10.594, rec=0.145), tot_loss_proj:2.895 [t=0.27s]
prediction: ['[CLS] from thisingder and ) french age coming pointless import sophie importject directorław police - this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.146 (perp=10.045, rec=0.137), tot_loss_proj:2.804 [t=0.27s]
prediction: ['[CLS] from thising sophie and ) french age coming pointless importder importject directorław police - this wo pointless importroller [SEP]']
[ 750/2000] tot_loss=2.145 (perp=10.045, rec=0.136), tot_loss_proj:2.807 [t=0.27s]
prediction: ['[CLS] from thising sophie and ) french age coming pointless importder importject directorław police - this wo pointless importroller [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.065 (perp=9.679, rec=0.130), tot_loss_proj:2.739 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - importject directorław director - this wo pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.058 (perp=9.600, rec=0.138), tot_loss_proj:2.710 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - importwal directorław director - thisject pointless importroller [SEP]']
[ 900/2000] tot_loss=2.049 (perp=9.600, rec=0.129), tot_loss_proj:2.713 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - importwal directorław director - thisject pointless importroller [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.982 (perp=9.233, rec=0.135), tot_loss_proj:2.639 [t=0.30s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import - import - directorław directorwal thisject pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.053 (perp=9.629, rec=0.127), tot_loss_proj:2.722 [t=0.28s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless of - import - directorław directorwalject this pointless importroller [SEP]']
[1050/2000] tot_loss=2.143 (perp=10.141, rec=0.115), tot_loss_proj:2.884 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless of - import - directorław director nearlyject this pointless importroller [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.044 (perp=9.599, rec=0.124), tot_loss_proj:2.781 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless import of - - directorław director nearlyject this pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.022 (perp=9.441, rec=0.134), tot_loss_proj:2.752 [t=0.28s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless importł - - director of director nearlyject this pointless importroller [SEP]']
[1200/2000] tot_loss=2.013 (perp=9.441, rec=0.125), tot_loss_proj:2.749 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french age coming pointless importł - - director of director nearlyject this pointless importroller [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.969 (perp=9.240, rec=0.121), tot_loss_proj:2.727 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of director nearlyject this pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.943 (perp=9.074, rec=0.128), tot_loss_proj:2.652 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
[1350/2000] tot_loss=1.930 (perp=9.074, rec=0.115), tot_loss_proj:2.654 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=9.074, rec=0.118), tot_loss_proj:2.658 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
Attempt swap
[1450/2000] tot_loss=1.934 (perp=9.074, rec=0.119), tot_loss_proj:2.649 [t=0.28s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this nearlyject director pointless importroller [SEP]']
[1500/2000] tot_loss=1.967 (perp=9.262, rec=0.115), tot_loss_proj:2.711 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - - director of this congregationject director pointless importroller [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.932 (perp=9.075, rec=0.117), tot_loss_proj:2.669 [t=0.30s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import -growth director of this congregation - director pointless importroller [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.934 (perp=9.107, rec=0.113), tot_loss_proj:2.650 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directoros of this congregation - director pointless importroller [SEP]']
[1650/2000] tot_loss=1.916 (perp=8.957, rec=0.125), tot_loss_proj:2.620 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1700/2000] tot_loss=1.912 (perp=8.957, rec=0.120), tot_loss_proj:2.614 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1750/2000] tot_loss=1.901 (perp=8.957, rec=0.110), tot_loss_proj:2.623 [t=0.29s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
[1800/2000] tot_loss=1.908 (perp=8.957, rec=0.117), tot_loss_proj:2.616 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1850/2000] tot_loss=1.909 (perp=8.957, rec=0.118), tot_loss_proj:2.622 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[1900/2000] tot_loss=1.905 (perp=8.957, rec=0.113), tot_loss_proj:2.629 [t=0.27s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
[1950/2000] tot_loss=1.904 (perp=8.957, rec=0.113), tot_loss_proj:2.620 [t=0.28s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Attempt swap
[2000/2000] tot_loss=1.897 (perp=8.957, rec=0.105), tot_loss_proj:2.625 [t=0.26s]
prediction: ['[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] from thising sophie ) and french ageł coming pointless import - directorgrowth of this congregation - director pointless importroller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.286 | p: 72.222 | r: 76.471
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 38.889 | r: 41.176
rougeLsum  | fm: 40.000 | p: 38.889 | r: 41.176
r1fm+r2fm = 74.286

[Aggregate metrics]:
rouge1     | fm: 76.807 | p: 75.306 | r: 78.655
rouge2     | fm: 37.153 | p: 36.645 | r: 37.736
rougeL     | fm: 67.307 | p: 65.934 | r: 69.000
rougeLsum  | fm: 66.995 | p: 65.545 | r: 68.804
r1fm+r2fm = 113.960

input #26 time: 0:11:17 | total time: 5:00:44


Running input #27 of 100.
reference: 
========================
are so generic 
========================
cosin similarity: 0.899414383258682 normalized error: 0.48213710503675355
cosin similarity: -0.8994143832586818 normalized error: 1.7769088949744516
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 1.8601595221254046 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 1.7924729866904148 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 1.7105311767293034 for ['[CLS] and universal universe [SEP]']
[Init] best rec loss: 1.6237242091049946 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 1.4957063567670374 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 1.366203888774431 for ['[CLS] part portion mid [SEP]']
[Init] best rec loss: 1.312832420404023 for ['[CLS] fat mattream [SEP]']
[Init] best rec loss: 1.1867137081966508 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 1.1791401490460158 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.834 (perp=11.918, rec=0.451), tot_loss_proj:3.618 [t=0.29s]
prediction: ['[CLS] hulk hated saddam [SEP]']
[ 100/2000] tot_loss=2.677 (perp=11.939, rec=0.289), tot_loss_proj:3.122 [t=0.26s]
prediction: ['[CLS] extent trap generic [SEP]']
[ 150/2000] tot_loss=1.915 (perp=8.558, rec=0.204), tot_loss_proj:2.162 [t=0.28s]
prediction: ['[CLS] most so generic [SEP]']
[ 200/2000] tot_loss=1.847 (perp=8.320, rec=0.183), tot_loss_proj:1.927 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.825 (perp=8.320, rec=0.161), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.817 (perp=8.320, rec=0.153), tot_loss_proj:1.909 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.804 (perp=8.320, rec=0.140), tot_loss_proj:1.921 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.800 (perp=8.320, rec=0.136), tot_loss_proj:1.919 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.806 (perp=8.320, rec=0.142), tot_loss_proj:1.922 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.809 (perp=8.320, rec=0.145), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.802 (perp=8.320, rec=0.138), tot_loss_proj:1.920 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.795 (perp=8.320, rec=0.131), tot_loss_proj:1.920 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.807 (perp=8.320, rec=0.143), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.784 (perp=8.320, rec=0.120), tot_loss_proj:1.913 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.798 (perp=8.320, rec=0.134), tot_loss_proj:1.917 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.791 (perp=8.320, rec=0.127), tot_loss_proj:1.926 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.786 (perp=8.320, rec=0.122), tot_loss_proj:1.925 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.789 (perp=8.320, rec=0.125), tot_loss_proj:1.931 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.936 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.801 (perp=8.320, rec=0.137), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.914 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.800 (perp=8.320, rec=0.136), tot_loss_proj:1.922 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.320, rec=0.124), tot_loss_proj:1.923 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.792 (perp=8.320, rec=0.128), tot_loss_proj:1.915 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.793 (perp=8.320, rec=0.129), tot_loss_proj:1.935 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.801 (perp=8.320, rec=0.137), tot_loss_proj:1.925 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.798 (perp=8.320, rec=0.134), tot_loss_proj:1.926 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.795 (perp=8.320, rec=0.131), tot_loss_proj:1.914 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.786 (perp=8.320, rec=0.122), tot_loss_proj:1.917 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.792 (perp=8.320, rec=0.128), tot_loss_proj:1.918 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.800 (perp=8.320, rec=0.136), tot_loss_proj:1.938 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.320, rec=0.128), tot_loss_proj:1.923 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.930 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.786 (perp=8.320, rec=0.122), tot_loss_proj:1.933 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.784 (perp=8.320, rec=0.120), tot_loss_proj:1.922 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=8.320, rec=0.130), tot_loss_proj:1.918 [t=0.32s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.320, rec=0.132), tot_loss_proj:1.924 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.799 (perp=8.320, rec=0.135), tot_loss_proj:1.918 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.320, rec=0.139), tot_loss_proj:1.923 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.690 | p: 76.263 | r: 79.561
rouge2     | fm: 39.418 | p: 38.942 | r: 40.043
rougeL     | fm: 68.621 | p: 67.324 | r: 70.223
rougeLsum  | fm: 68.017 | p: 66.653 | r: 69.633
r1fm+r2fm = 117.108

input #27 time: 0:11:18 | total time: 5:12:02


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
cosin similarity: -0.8963603353465541 normalized error: 1.734303904161745
cosin similarity: 0.8963603353465541 normalized error: 0.5019644046112567
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 1.7238842479734258 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 1.6400437421395921 for ['[CLS] spare blaze following tempo [SEP]']
[Init] best rec loss: 1.5779799094010394 for ['[CLS] boundaries towards lands delivery [SEP]']
[Init] best rec loss: 1.57636484969019 for ['[CLS] medalist de empress wing [SEP]']
[Init] best rec loss: 1.5325416085225378 for ['[CLS] bro asher lit majority [SEP]']
[Init] best rec loss: 1.5284168767216904 for ['[CLS] costs ev rankin airways [SEP]']
[Init] best perm rec loss: 1.5207602268517522 for ['[CLS] ev airways costs rankin [SEP]']
[Init] best perm rec loss: 1.5207221061843765 for ['[CLS] airways ev costs rankin [SEP]']
[Init] best perm rec loss: 1.5195019595003252 for ['[CLS] costs rankin ev airways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.308 (perp=9.823, rec=0.343), tot_loss_proj:2.976 [t=0.29s]
prediction: ['[CLS] only twenty amber minutes [SEP]']
[ 100/2000] tot_loss=2.205 (perp=9.964, rec=0.212), tot_loss_proj:3.064 [t=0.32s]
prediction: ['[CLS] only only amber minutes [SEP]']
[ 150/2000] tot_loss=2.364 (perp=11.000, rec=0.164), tot_loss_proj:3.246 [t=0.31s]
prediction: ['[CLS] for only inhibitor minutes [SEP]']
[ 200/2000] tot_loss=2.016 (perp=9.313, rec=0.153), tot_loss_proj:2.946 [t=0.31s]
prediction: ['[CLS] for 71 bobby minutes [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.002 (perp=9.313, rec=0.139), tot_loss_proj:2.942 [t=0.29s]
prediction: ['[CLS] for 71 bobby minutes [SEP]']
[ 300/2000] tot_loss=1.994 (perp=9.313, rec=0.132), tot_loss_proj:2.936 [t=0.31s]
prediction: ['[CLS] for 71 bobby minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.178 (perp=10.208, rec=0.137), tot_loss_proj:3.024 [t=0.31s]
prediction: ['[CLS] for 71 au minutes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.939 (perp=8.974, rec=0.144), tot_loss_proj:2.779 [t=0.30s]
prediction: ['[CLS] for 71 minutes au [SEP]']
[ 450/2000] tot_loss=2.114 (perp=9.881, rec=0.138), tot_loss_proj:2.947 [t=0.28s]
prediction: ['[CLS] for 71 minutessling [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.982 (perp=9.266, rec=0.129), tot_loss_proj:2.804 [t=0.29s]
prediction: ['[CLS]ʳ for 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.854 (perp=8.655, rec=0.123), tot_loss_proj:3.075 [t=0.32s]
prediction: ['[CLS] hans for 71 minutes [SEP]']
[ 600/2000] tot_loss=1.977 (perp=9.262, rec=0.124), tot_loss_proj:3.106 [t=0.31s]
prediction: ['[CLS]sling for 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.971 (perp=9.262, rec=0.118), tot_loss_proj:3.101 [t=0.30s]
prediction: ['[CLS]sling for 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=9.262, rec=0.116), tot_loss_proj:3.107 [t=0.30s]
prediction: ['[CLS]sling for 71 minutes [SEP]']
[ 750/2000] tot_loss=1.892 (perp=8.844, rec=0.123), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.898 (perp=8.844, rec=0.129), tot_loss_proj:3.023 [t=0.31s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=8.844, rec=0.122), tot_loss_proj:3.027 [t=0.31s]
prediction: ['[CLS] au for 71 minutes [SEP]']
[ 900/2000] tot_loss=1.891 (perp=8.844, rec=0.122), tot_loss_proj:3.031 [t=0.29s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.890 (perp=8.844, rec=0.121), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.880 (perp=8.844, rec=0.111), tot_loss_proj:3.029 [t=0.29s]
prediction: ['[CLS] au for 71 minutes [SEP]']
[1050/2000] tot_loss=1.890 (perp=8.844, rec=0.121), tot_loss_proj:3.028 [t=0.30s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.902 (perp=8.844, rec=0.133), tot_loss_proj:3.027 [t=0.30s]
prediction: ['[CLS] au for 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.893 (perp=8.844, rec=0.124), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] au for 71 minutes [SEP]']
[1200/2000] tot_loss=1.962 (perp=9.171, rec=0.127), tot_loss_proj:3.023 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.023 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.951 (perp=9.171, rec=0.117), tot_loss_proj:3.017 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1350/2000] tot_loss=1.959 (perp=9.171, rec=0.125), tot_loss_proj:3.018 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.967 (perp=9.171, rec=0.132), tot_loss_proj:3.020 [t=0.31s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.964 (perp=9.171, rec=0.130), tot_loss_proj:3.025 [t=0.32s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1500/2000] tot_loss=1.956 (perp=9.171, rec=0.122), tot_loss_proj:3.016 [t=0.31s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.018 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.015 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1650/2000] tot_loss=1.955 (perp=9.171, rec=0.121), tot_loss_proj:3.013 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.949 (perp=9.171, rec=0.114), tot_loss_proj:3.014 [t=0.29s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=9.171, rec=0.128), tot_loss_proj:3.013 [t=0.31s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1800/2000] tot_loss=1.948 (perp=9.171, rec=0.114), tot_loss_proj:3.019 [t=0.29s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.957 (perp=9.171, rec=0.123), tot_loss_proj:3.017 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.947 (perp=9.171, rec=0.113), tot_loss_proj:3.014 [t=0.29s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
[1950/2000] tot_loss=1.953 (perp=9.171, rec=0.119), tot_loss_proj:3.019 [t=0.30s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.956 (perp=9.171, rec=0.122), tot_loss_proj:3.016 [t=0.32s]
prediction: ['[CLS] goth for 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS]sling for 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 77.735 | p: 76.375 | r: 79.618
rouge2     | fm: 39.520 | p: 39.047 | r: 40.115
rougeL     | fm: 68.956 | p: 67.743 | r: 70.651
rougeLsum  | fm: 68.546 | p: 67.180 | r: 70.301
r1fm+r2fm = 117.255

input #28 time: 0:12:22 | total time: 5:24:25


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
cosin similarity: 0.8935402273098988 normalized error: 0.5132934698956766
cosin similarity: -0.8935402273098987 normalized error: 1.7114680746096491
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 1.8951370295519259 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 1.7573377336300522 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 1.6662746918614864 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 1.6222173997270075 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 1.5402730288861677 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 1.4476836606098127 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 1.3916519224730641 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 1.3752690559401188 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 1.3590884018970015 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 1.3546598883795284 for ['[CLS] landed oil administration taste runs tvuted this envelope engagement [SEP]']
[Init] best perm rec loss: 1.3517942223727615 for ['[CLS] envelope taste landed oil tv runs engagementuted administration this [SEP]']
[Init] best perm rec loss: 1.3467121284205446 for ['[CLS] runs engagement landed tvuted this envelope oil taste administration [SEP]']
[Init] best perm rec loss: 1.3464084648223271 for ['[CLS]uted this taste landed envelope runs engagement administration oil tv [SEP]']
[Init] best perm rec loss: 1.3431373262775121 for ['[CLS] envelope oil taste engagement thisuted landed runs administration tv [SEP]']
[Init] best perm rec loss: 1.3415173260540905 for ['[CLS] taste oil runs engagement tv this envelope landeduted administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.083 (perp=12.918, rec=0.500), tot_loss_proj:4.002 [t=0.27s]
prediction: ['[CLS] popularity natural think engagement tv credits scandal hole avon government [SEP]']
[ 100/2000] tot_loss=2.571 (perp=10.897, rec=0.391), tot_loss_proj:4.058 [t=0.26s]
prediction: ['[CLS] rules natural progress engagement is picture angelica is dire not [SEP]']
[ 150/2000] tot_loss=2.387 (perp=10.162, rec=0.354), tot_loss_proj:3.344 [t=0.27s]
prediction: ['[CLS] believe natural fighting evil is picture angelica is its not [SEP]']
[ 200/2000] tot_loss=2.222 (perp=9.604, rec=0.301), tot_loss_proj:3.080 [t=0.26s]
prediction: ['[CLS] believe natural reportedly evil is it endangered is its not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.141 (perp=9.473, rec=0.247), tot_loss_proj:3.109 [t=0.25s]
prediction: ['[CLS] probably believe innocent evil is it endangered is is not [SEP]']
[ 300/2000] tot_loss=1.934 (perp=8.675, rec=0.199), tot_loss_proj:2.997 [t=0.27s]
prediction: ['[CLS] considered believe innocent evil is it evil is is not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.097 (perp=9.522, rec=0.193), tot_loss_proj:3.143 [t=0.26s]
prediction: ['[CLS] considered cold believe surface resident it resident is is not [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.147 (perp=9.869, rec=0.173), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] considered cold believe abby evil is resident it is not [SEP]']
[ 450/2000] tot_loss=2.320 (perp=10.819, rec=0.156), tot_loss_proj:3.424 [t=0.26s]
prediction: ['[CLS] consider sentinel believe abby evil that resident it is not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.968 (perp=8.945, rec=0.179), tot_loss_proj:2.953 [t=0.26s]
prediction: ['[CLS] consider resident believe resident evil that surface it is not [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.752 (perp=7.944, rec=0.163), tot_loss_proj:2.621 [t=0.25s]
prediction: ['[CLS] consider resident believe resident evil that it is not surface [SEP]']
[ 600/2000] tot_loss=1.750 (perp=7.944, rec=0.161), tot_loss_proj:2.620 [t=0.26s]
prediction: ['[CLS] consider resident believe resident evil that it is not surface [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.711 (perp=7.708, rec=0.169), tot_loss_proj:2.482 [t=0.26s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.692 (perp=7.708, rec=0.150), tot_loss_proj:2.480 [t=0.26s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
[ 750/2000] tot_loss=1.698 (perp=7.708, rec=0.156), tot_loss_proj:2.478 [t=0.25s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.695 (perp=7.708, rec=0.153), tot_loss_proj:2.480 [t=0.28s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.678 (perp=7.708, rec=0.136), tot_loss_proj:2.480 [t=0.28s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
[ 900/2000] tot_loss=1.678 (perp=7.708, rec=0.136), tot_loss_proj:2.485 [t=0.28s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=7.708, rec=0.146), tot_loss_proj:2.484 [t=0.27s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=7.708, rec=0.137), tot_loss_proj:2.483 [t=0.26s]
prediction: ['[CLS] consider resident believe that resident evil it is not surface [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.248, rec=0.132), tot_loss_proj:2.365 [t=0.27s]
prediction: ['[CLS] i resident believe that resident evil it is not surface [SEP]']
Attempt swap
[1100/2000] tot_loss=1.584 (perp=7.248, rec=0.134), tot_loss_proj:2.366 [t=0.26s]
prediction: ['[CLS] i resident believe that resident evil it is not surface [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.508 (perp=6.815, rec=0.145), tot_loss_proj:2.245 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil it is not surface [SEP]']
[1200/2000] tot_loss=1.504 (perp=6.815, rec=0.141), tot_loss_proj:2.247 [t=0.27s]
prediction: ['[CLS] i believe that resident resident evil it is not surface [SEP]']
Attempt swap
[1250/2000] tot_loss=1.496 (perp=6.815, rec=0.133), tot_loss_proj:2.245 [t=0.28s]
prediction: ['[CLS] i believe that resident resident evil it is not surface [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.445 (perp=6.531, rec=0.139), tot_loss_proj:2.402 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1350/2000] tot_loss=1.438 (perp=6.531, rec=0.132), tot_loss_proj:2.396 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1400/2000] tot_loss=1.441 (perp=6.531, rec=0.135), tot_loss_proj:2.396 [t=0.29s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1450/2000] tot_loss=1.442 (perp=6.531, rec=0.136), tot_loss_proj:2.393 [t=0.27s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1500/2000] tot_loss=1.438 (perp=6.531, rec=0.131), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1550/2000] tot_loss=1.442 (perp=6.531, rec=0.136), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1600/2000] tot_loss=1.430 (perp=6.531, rec=0.124), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1650/2000] tot_loss=1.430 (perp=6.531, rec=0.124), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1700/2000] tot_loss=1.435 (perp=6.531, rec=0.129), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1750/2000] tot_loss=1.434 (perp=6.531, rec=0.128), tot_loss_proj:2.400 [t=0.25s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1800/2000] tot_loss=1.440 (perp=6.531, rec=0.134), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.531, rec=0.126), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[1900/2000] tot_loss=1.432 (perp=6.531, rec=0.126), tot_loss_proj:2.396 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
[1950/2000] tot_loss=1.430 (perp=6.531, rec=0.124), tot_loss_proj:2.403 [t=0.26s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Attempt swap
[2000/2000] tot_loss=1.434 (perp=6.531, rec=0.128), tot_loss_proj:2.397 [t=0.25s]
prediction: ['[CLS] i believe that resident resident evil is it not surface [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe that resident resident evil is it not surface [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 134.576

[Aggregate metrics]:
rouge1     | fm: 78.260 | p: 76.729 | r: 80.122
rouge2     | fm: 39.940 | p: 39.424 | r: 40.599
rougeL     | fm: 69.420 | p: 68.015 | r: 71.026
rougeLsum  | fm: 68.995 | p: 67.624 | r: 70.741
r1fm+r2fm = 118.200

input #29 time: 0:11:03 | total time: 5:35:28


Running input #30 of 100.
reference: 
========================
fizzability 
========================
cosin similarity: -0.7819535962479063 normalized error: 1.6731907553169267
cosin similarity: 0.7819535962479063 normalized error: 0.5738673088944698
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 1.9198818170858516 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 1.6276032164601437 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 1.62706430419471 for ['[CLS] laws gp. [SEP]']
[Init] best rec loss: 1.4773479526785376 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 1.4401673488347653 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 1.329719044713277 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 1.3182118825344444 for ['[CLS] lizard acceleration council [SEP]']
[Init] best perm rec loss: 1.3156440405624523 for ['[CLS] acceleration lizard council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.641 (perp=10.938, rec=0.453), tot_loss_proj:3.535 [t=0.29s]
prediction: ['[CLS] brown estate burned [SEP]']
[ 100/2000] tot_loss=3.172 (perp=14.143, rec=0.343), tot_loss_proj:4.783 [t=0.26s]
prediction: ['[CLS]bilityzza shopping [SEP]']
[ 150/2000] tot_loss=2.657 (perp=11.839, rec=0.289), tot_loss_proj:3.502 [t=0.25s]
prediction: ['[CLS]bilityzzability [SEP]']
[ 200/2000] tot_loss=2.487 (perp=11.223, rec=0.242), tot_loss_proj:3.294 [t=0.26s]
prediction: ['[CLS]zzazzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.109 (perp=9.539, rec=0.202), tot_loss_proj:2.366 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.106 (perp=9.539, rec=0.198), tot_loss_proj:2.376 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.099 (perp=9.539, rec=0.191), tot_loss_proj:2.372 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.087 (perp=9.539, rec=0.179), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.061 (perp=9.539, rec=0.153), tot_loss_proj:2.362 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.067 (perp=9.539, rec=0.159), tot_loss_proj:2.374 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.070 (perp=9.539, rec=0.162), tot_loss_proj:2.370 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=2.083 (perp=9.539, rec=0.175), tot_loss_proj:2.376 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.047 (perp=9.539, rec=0.139), tot_loss_proj:2.377 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.044 (perp=9.539, rec=0.136), tot_loss_proj:2.366 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=2.063 (perp=9.539, rec=0.155), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.059 (perp=9.539, rec=0.151), tot_loss_proj:2.373 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.054 (perp=9.539, rec=0.146), tot_loss_proj:2.371 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=2.059 (perp=9.539, rec=0.151), tot_loss_proj:2.373 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.054 (perp=9.539, rec=0.146), tot_loss_proj:2.377 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=2.058 (perp=9.539, rec=0.151), tot_loss_proj:2.382 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=2.060 (perp=9.539, rec=0.152), tot_loss_proj:2.376 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=2.055 (perp=9.539, rec=0.147), tot_loss_proj:2.365 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.054 (perp=9.539, rec=0.146), tot_loss_proj:2.378 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=2.046 (perp=9.539, rec=0.138), tot_loss_proj:2.363 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=2.050 (perp=9.539, rec=0.142), tot_loss_proj:2.363 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=2.052 (perp=9.539, rec=0.144), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=2.044 (perp=9.539, rec=0.136), tot_loss_proj:2.367 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.049 (perp=9.539, rec=0.141), tot_loss_proj:2.369 [t=0.29s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=2.045 (perp=9.539, rec=0.137), tot_loss_proj:2.383 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.056 (perp=9.539, rec=0.148), tot_loss_proj:2.373 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=2.048 (perp=9.539, rec=0.140), tot_loss_proj:2.363 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=2.050 (perp=9.539, rec=0.142), tot_loss_proj:2.367 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=2.046 (perp=9.539, rec=0.138), tot_loss_proj:2.368 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=2.057 (perp=9.539, rec=0.150), tot_loss_proj:2.371 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.050 (perp=9.539, rec=0.142), tot_loss_proj:2.373 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=2.049 (perp=9.539, rec=0.142), tot_loss_proj:2.360 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.063 (perp=9.539, rec=0.155), tot_loss_proj:2.374 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=2.056 (perp=9.539, rec=0.148), tot_loss_proj:2.365 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=2.043 (perp=9.539, rec=0.136), tot_loss_proj:2.371 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=2.048 (perp=9.539, rec=0.140), tot_loss_proj:2.376 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.788 | p: 77.418 | r: 80.567
rouge2     | fm: 41.954 | p: 41.424 | r: 42.579
rougeL     | fm: 70.431 | p: 69.159 | r: 72.046
rougeLsum  | fm: 69.974 | p: 68.671 | r: 71.635
r1fm+r2fm = 120.741

input #30 time: 0:11:05 | total time: 5:46:34


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
cosin similarity: 0.8972750712825893 normalized error: 0.5145268960711955
cosin similarity: -0.8972750712825892 normalized error: 1.7058112387950424
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 1.9773721288501558 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 1.9019158403876166 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 1.8086576336662248 for ['[CLS] che episode band [SEP]']
[Init] best rec loss: 1.6337636516907696 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 1.606473108711593 for ['[CLS] seeing cat retrieved [SEP]']
[Init] best perm rec loss: 1.6009026623141054 for ['[CLS] retrieved cat seeing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.515 (perp=10.330, rec=0.449), tot_loss_proj:3.321 [t=0.25s]
prediction: ['[CLS] a truck better [SEP]']
[ 100/2000] tot_loss=2.267 (perp=9.889, rec=0.289), tot_loss_proj:2.898 [t=0.25s]
prediction: ['[CLS] a vehicle better [SEP]']
[ 150/2000] tot_loss=2.204 (perp=9.889, rec=0.226), tot_loss_proj:2.913 [t=0.26s]
prediction: ['[CLS] a vehicle better [SEP]']
[ 200/2000] tot_loss=2.195 (perp=9.889, rec=0.218), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] a vehicle better [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.726 (perp=7.603, rec=0.206), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.717 (perp=7.603, rec=0.196), tot_loss_proj:1.968 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.701 (perp=7.603, rec=0.181), tot_loss_proj:1.972 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.697 (perp=7.603, rec=0.177), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.691 (perp=7.603, rec=0.170), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.714 (perp=7.603, rec=0.193), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.697 (perp=7.603, rec=0.177), tot_loss_proj:1.974 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.695 (perp=7.603, rec=0.174), tot_loss_proj:1.973 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.708 (perp=7.603, rec=0.187), tot_loss_proj:1.973 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.692 (perp=7.603, rec=0.172), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.703 (perp=7.603, rec=0.182), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.702 (perp=7.603, rec=0.181), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.684 (perp=7.603, rec=0.163), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.700 (perp=7.603, rec=0.180), tot_loss_proj:1.955 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=7.603, rec=0.180), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.700 (perp=7.603, rec=0.179), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.691 (perp=7.603, rec=0.171), tot_loss_proj:1.984 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.687 (perp=7.603, rec=0.167), tot_loss_proj:1.978 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.683 (perp=7.603, rec=0.163), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.686 (perp=7.603, rec=0.165), tot_loss_proj:1.967 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.690 (perp=7.603, rec=0.170), tot_loss_proj:1.978 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.691 (perp=7.603, rec=0.171), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.694 (perp=7.603, rec=0.173), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.686 (perp=7.603, rec=0.165), tot_loss_proj:1.977 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.695 (perp=7.603, rec=0.174), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.694 (perp=7.603, rec=0.174), tot_loss_proj:1.984 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.687 (perp=7.603, rec=0.166), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.692 (perp=7.603, rec=0.171), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.694 (perp=7.603, rec=0.173), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.691 (perp=7.603, rec=0.171), tot_loss_proj:1.968 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.687 (perp=7.603, rec=0.166), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.697 (perp=7.603, rec=0.176), tot_loss_proj:1.972 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.688 (perp=7.603, rec=0.168), tot_loss_proj:1.979 [t=0.29s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.708 | p: 78.292 | r: 81.352
rouge2     | fm: 43.656 | p: 43.126 | r: 44.194
rougeL     | fm: 71.341 | p: 70.053 | r: 72.898
rougeLsum  | fm: 70.868 | p: 69.590 | r: 72.648
r1fm+r2fm = 123.364

input #31 time: 0:11:03 | total time: 5:57:38


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
cosin similarity: 0.9540072499327329 normalized error: 0.4076547528751486
cosin similarity: -0.954007249932733 normalized error: 1.8969876030351638
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.9211081790519218 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 1.76629793519009 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 1.7226820069981001 for ['[CLS] everywhere commission positively galaxy wasted dish engine maine linear finn hit circulated [SEP]']
[Init] best rec loss: 1.6831346488369228 for ['[CLS] particular usual lana rid part awaitfication felt worked bolt algorithm tristan [SEP]']
[Init] best perm rec loss: 1.68248123028659 for ['[CLS] algorithm feltfication particular lana rid part await bolt worked tristan usual [SEP]']
[Init] best perm rec loss: 1.680588822278398 for ['[CLS] algorithmfication await usual tristan lana rid felt worked bolt part particular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.547 (perp=10.908, rec=0.365), tot_loss_proj:2.854 [t=0.25s]
prediction: ['[CLS] expand photographer light narrative technology easily wise feeled a energy resource [SEP]']
[ 100/2000] tot_loss=2.664 (perp=11.853, rec=0.293), tot_loss_proj:3.706 [t=0.27s]
prediction: ['[CLS] pull rico salon stories story easily accessible feelotide prime easily available [SEP]']
[ 150/2000] tot_loss=2.682 (perp=12.318, rec=0.218), tot_loss_proj:4.283 [t=0.27s]
prediction: ['[CLS] pullund accessible stories stories easily accessibleonateulatedund easily together [SEP]']
[ 200/2000] tot_loss=2.737 (perp=12.740, rec=0.189), tot_loss_proj:4.423 [t=0.26s]
prediction: ["[CLS] pullund accessible' stories easily accessibleonateulatedund easily together [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.746 (perp=12.939, rec=0.158), tot_loss_proj:3.722 [t=0.28s]
prediction: ['[CLS] pullonate accessibleulously stories easily togetheronate prof profund that [SEP]']
[ 300/2000] tot_loss=2.781 (perp=13.162, rec=0.149), tot_loss_proj:3.727 [t=0.25s]
prediction: ['[CLS] pullonate accessiblesities stories easily togetheronate prof profund that [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.596 (perp=12.309, rec=0.134), tot_loss_proj:3.561 [t=0.26s]
prediction: ['[CLS] pullonate accessiblesities stories easily together profonate profund that [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.389 (perp=11.196, rec=0.150), tot_loss_proj:3.243 [t=0.25s]
prediction: ['[CLS] pullonate accessiblecasedonate easily together with stories profund that [SEP]']
[ 450/2000] tot_loss=2.312 (perp=10.922, rec=0.128), tot_loss_proj:3.228 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurityonate easily together with stories profund that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.105 (perp=9.901, rec=0.125), tot_loss_proj:3.002 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurityity easily together with stories that profund [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.092 (perp=9.901, rec=0.112), tot_loss_proj:3.001 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurityity easily together with stories that profund [SEP]']
[ 600/2000] tot_loss=2.098 (perp=9.901, rec=0.118), tot_loss_proj:3.002 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurityity easily together with stories that profund [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.939 (perp=9.177, rec=0.104), tot_loss_proj:2.711 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.945 (perp=9.177, rec=0.109), tot_loss_proj:2.724 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
[ 750/2000] tot_loss=1.942 (perp=9.177, rec=0.106), tot_loss_proj:2.718 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.939 (perp=9.177, rec=0.104), tot_loss_proj:2.711 [t=0.28s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.943 (perp=9.177, rec=0.107), tot_loss_proj:2.718 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
[ 900/2000] tot_loss=1.935 (perp=9.177, rec=0.100), tot_loss_proj:2.723 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity easily together with stories that profundity [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.864 (perp=8.742, rec=0.115), tot_loss_proj:2.677 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.850 (perp=8.742, rec=0.101), tot_loss_proj:2.686 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1050/2000] tot_loss=1.848 (perp=8.742, rec=0.099), tot_loss_proj:2.675 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.846 (perp=8.742, rec=0.098), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.857 (perp=8.742, rec=0.108), tot_loss_proj:2.671 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1200/2000] tot_loss=1.847 (perp=8.742, rec=0.099), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.847 (perp=8.742, rec=0.099), tot_loss_proj:2.674 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.839 (perp=8.742, rec=0.090), tot_loss_proj:2.682 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1350/2000] tot_loss=1.853 (perp=8.742, rec=0.104), tot_loss_proj:2.680 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.848 (perp=8.742, rec=0.099), tot_loss_proj:2.676 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.850 (perp=8.742, rec=0.102), tot_loss_proj:2.681 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1500/2000] tot_loss=1.859 (perp=8.742, rec=0.111), tot_loss_proj:2.675 [t=0.29s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.845 (perp=8.742, rec=0.097), tot_loss_proj:2.681 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.859 (perp=8.742, rec=0.111), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1650/2000] tot_loss=1.856 (perp=8.742, rec=0.108), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.849 (perp=8.742, rec=0.101), tot_loss_proj:2.682 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.851 (perp=8.742, rec=0.103), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1800/2000] tot_loss=1.849 (perp=8.742, rec=0.101), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.842 (perp=8.742, rec=0.093), tot_loss_proj:2.676 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.855 (perp=8.742, rec=0.107), tot_loss_proj:2.679 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
[1950/2000] tot_loss=1.847 (perp=8.742, rec=0.098), tot_loss_proj:2.670 [t=0.25s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.851 (perp=8.742, rec=0.103), tot_loss_proj:2.674 [t=0.27s]
prediction: ['[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pullonate accessibleurity stories that easily together with profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 31.579 | p: 33.333 | r: 30.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 107.769

[Aggregate metrics]:
rouge1     | fm: 79.377 | p: 78.243 | r: 80.982
rouge2     | fm: 42.850 | p: 42.324 | r: 43.553
rougeL     | fm: 70.981 | p: 69.886 | r: 72.456
rougeLsum  | fm: 70.584 | p: 69.429 | r: 72.211
r1fm+r2fm = 122.228

input #32 time: 0:11:03 | total time: 6:08:41


Running input #33 of 100.
reference: 
========================
higher 
========================
cosin similarity: 0.7986250644135383 normalized error: 0.5468308574685831
cosin similarity: -0.7986250644135384 normalized error: 1.7253964504394095
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.8752308361546675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 1.7699783893495125 for ['[CLS] lord [SEP]']
[Init] best rec loss: 1.7121624639697963 for ['[CLS] master [SEP]']
[Init] best rec loss: 1.6298144740724452 for ['[CLS] training [SEP]']
[Init] best rec loss: 1.512583442773785 for ['[CLS] strip [SEP]']
[Init] best rec loss: 1.499280831351446 for ['[CLS] less [SEP]']
[Init] best rec loss: 1.4961316351656644 for ['[CLS] frame [SEP]']
[Init] best rec loss: 1.2640420930217784 for ['[CLS] positive [SEP]']
[Init] best rec loss: 1.2514269065456496 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.656 (perp=11.231, rec=0.410), tot_loss_proj:2.995 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.604 (perp=11.231, rec=0.358), tot_loss_proj:2.915 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.595 (perp=11.231, rec=0.349), tot_loss_proj:2.896 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.605 (perp=11.231, rec=0.358), tot_loss_proj:2.895 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.601 (perp=11.231, rec=0.354), tot_loss_proj:2.898 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.603 (perp=11.231, rec=0.357), tot_loss_proj:2.891 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.598 (perp=11.231, rec=0.351), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.598 (perp=11.231, rec=0.352), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.598 (perp=11.231, rec=0.352), tot_loss_proj:2.896 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.594 (perp=11.231, rec=0.347), tot_loss_proj:2.868 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.600 (perp=11.231, rec=0.354), tot_loss_proj:2.879 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.591 (perp=11.231, rec=0.345), tot_loss_proj:2.864 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.590 (perp=11.231, rec=0.344), tot_loss_proj:2.865 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.596 (perp=11.231, rec=0.350), tot_loss_proj:2.863 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.581 (perp=11.231, rec=0.335), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.591 (perp=11.231, rec=0.345), tot_loss_proj:2.850 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.584 (perp=11.231, rec=0.337), tot_loss_proj:2.864 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.582 (perp=11.231, rec=0.336), tot_loss_proj:2.861 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.587 (perp=11.231, rec=0.341), tot_loss_proj:2.868 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.574 (perp=11.231, rec=0.328), tot_loss_proj:2.856 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.582 (perp=11.231, rec=0.336), tot_loss_proj:2.859 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.586 (perp=11.231, rec=0.339), tot_loss_proj:2.855 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.589 (perp=11.231, rec=0.343), tot_loss_proj:2.867 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.583 (perp=11.231, rec=0.336), tot_loss_proj:2.856 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.586 (perp=11.231, rec=0.340), tot_loss_proj:2.872 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.586 (perp=11.231, rec=0.340), tot_loss_proj:2.862 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.579 (perp=11.231, rec=0.333), tot_loss_proj:2.850 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.585 (perp=11.231, rec=0.339), tot_loss_proj:2.869 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.589 (perp=11.231, rec=0.343), tot_loss_proj:2.863 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.583 (perp=11.231, rec=0.337), tot_loss_proj:2.875 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.588 (perp=11.231, rec=0.341), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.586 (perp=11.231, rec=0.340), tot_loss_proj:2.875 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.586 (perp=11.231, rec=0.340), tot_loss_proj:2.856 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.589 (perp=11.231, rec=0.343), tot_loss_proj:2.865 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.579 (perp=11.231, rec=0.333), tot_loss_proj:2.862 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.577 (perp=11.231, rec=0.331), tot_loss_proj:2.855 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.582 (perp=11.231, rec=0.336), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.579 (perp=11.231, rec=0.333), tot_loss_proj:2.866 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.580 (perp=11.231, rec=0.333), tot_loss_proj:2.864 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.580 (perp=11.231, rec=0.334), tot_loss_proj:2.861 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.939 | p: 78.798 | r: 81.505
rouge2     | fm: 44.472 | p: 44.042 | r: 45.114
rougeL     | fm: 71.699 | p: 70.607 | r: 73.138
rougeLsum  | fm: 71.416 | p: 70.265 | r: 72.927
r1fm+r2fm = 124.412

input #33 time: 0:11:04 | total time: 6:19:45


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
cosin similarity: 0.8932598797628633 normalized error: 0.4609634765779029
cosin similarity: -0.8932598797628633 normalized error: 1.8346564869915711
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 1.8985526754050652 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 1.8872557456999548 for ['[CLS] mistress quality security throughout trunkught warning age marketing experiments despite bug travel [SEP]']
[Init] best rec loss: 1.8520096380894422 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 1.7836559245382833 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 1.758405871443009 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 1.7522172888231147 for ['[CLS] marks reflected beat projects plus respectively labradortila columbus estate customs whose marie [SEP]']
[Init] best rec loss: 1.7449057415668872 for ['[CLS] crumbling early?8 naturally episode judah financing highlight ness ford industrystorm [SEP]']
[Init] best rec loss: 1.7406904364769407 for ['[CLS] bangladesh park rival range direct alain desert early best secretsies manitical [SEP]']
[Init] best rec loss: 1.7235494299407326 for ['[CLS] laurel hung encouragement blurred quiz originally orient rather bentci sen ethiopian belmont [SEP]']
[Init] best rec loss: 1.522639053364564 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best rec loss: 1.4833163507243858 for ['[CLS] marie grammar blasted furrowed clyde splash still to caps chief failed impact level [SEP]']
[Init] best perm rec loss: 1.4696467025467284 for ['[CLS] chief caps furrowed impact still blasted grammar failed splash marie clyde to level [SEP]']
[Init] best perm rec loss: 1.4658515403071852 for ['[CLS] impact caps to marie clyde splash blasted still level grammar failed furrowed chief [SEP]']
[Init] best perm rec loss: 1.464656491326015 for ['[CLS] blasted level clyde to impact still marie splash failed grammar chief furrowed caps [SEP]']
[Init] best perm rec loss: 1.4635636998781716 for ['[CLS] still marie furrowed splash failed impact level blasted grammar chief clyde caps to [SEP]']
[Init] best perm rec loss: 1.4633178352098635 for ['[CLS] caps grammar to level furrowed impact blasted splash failed clyde chief still marie [SEP]']
[Init] best perm rec loss: 1.462763524598953 for ['[CLS] caps to grammar splash furrowed marie clyde level still blasted chief failed impact [SEP]']
[Init] best perm rec loss: 1.4619063578860712 for ['[CLS] marie to clyde still splash grammar blasted failed furrowed impact level chief caps [SEP]']
[Init] best perm rec loss: 1.4611379717454729 for ['[CLS] furrowed marie still clyde splash blasted failed level chief impact grammar caps to [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.109 (perp=13.574, rec=0.394), tot_loss_proj:3.917 [t=0.25s]
prediction: ['[CLS] domain would places urgency the audience 2002 accessible geographicage v8 gender understand [SEP]']
[ 100/2000] tot_loss=2.499 (perp=11.077, rec=0.284), tot_loss_proj:3.470 [t=0.26s]
prediction: ['[CLS] build would viewer urgency the viewersphere extreme roads immediate take. urgency [SEP]']
[ 150/2000] tot_loss=2.578 (perp=11.613, rec=0.255), tot_loss_proj:3.567 [t=0.27s]
prediction: ['[CLS] buildic population urgency the viewersphere extreme edges immediate take. urgency [SEP]']
[ 200/2000] tot_loss=2.402 (perp=11.009, rec=0.200), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] build on build urgency the viewersphere extreme amazing extreme take. urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.213 (perp=10.138, rec=0.185), tot_loss_proj:2.930 [t=0.28s]
prediction: ['[CLS] build on build urgency the viewersphere extreme gems. take extreme urgency [SEP]']
[ 300/2000] tot_loss=2.331 (perp=10.868, rec=0.158), tot_loss_proj:3.006 [t=0.26s]
prediction: ['[CLS] build in synthesis urgency the viewersphere extreme gems. take extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.011 (perp=9.330, rec=0.145), tot_loss_proj:2.750 [t=0.25s]
prediction: ['[CLS] build in mind gems the viewersphere extreme urgency. take extreme urgency [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.960 (perp=8.838, rec=0.193), tot_loss_proj:2.692 [t=0.26s]
prediction: ['[CLS] build in mind gems the viewer kn urgency. take on extreme urgency [SEP]']
[ 450/2000] tot_loss=1.934 (perp=8.920, rec=0.150), tot_loss_proj:2.940 [t=0.29s]
prediction: ['[CLS] build in mind segments the viewer kn urgency. take on extreme urgency [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.911 (perp=8.838, rec=0.143), tot_loss_proj:2.692 [t=0.25s]
prediction: ['[CLS] build in mind gems the viewer kn urgency. take on extreme urgency [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.836 (perp=8.503, rec=0.135), tot_loss_proj:2.654 [t=0.27s]
prediction: ['[CLS] build in mind gems the viewer kn urgency take on extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.886 (perp=8.809, rec=0.125), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] build in mind kelly the viewer kn urgency take on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.883 (perp=8.807, rec=0.121), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS] build in mind and kelly viewer kn urgency take on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.803 (perp=8.392, rec=0.124), tot_loss_proj:2.677 [t=0.27s]
prediction: ['[CLS] build in mind and kn kelly viewer urgency take on extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.392, rec=0.118), tot_loss_proj:2.681 [t=0.26s]
prediction: ['[CLS] build in mind and kn kelly viewer urgency take on extreme urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.790 (perp=8.392, rec=0.111), tot_loss_proj:2.691 [t=0.26s]
prediction: ['[CLS] build in mind and kn kelly viewer urgency take on extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.725 (perp=8.054, rec=0.115), tot_loss_proj:2.525 [t=0.29s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.054, rec=0.110), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.727 (perp=8.054, rec=0.116), tot_loss_proj:2.531 [t=0.26s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.719 (perp=8.054, rec=0.108), tot_loss_proj:2.520 [t=0.29s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.054, rec=0.091), tot_loss_proj:2.516 [t=0.30s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.719 (perp=8.054, rec=0.108), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.717 (perp=8.054, rec=0.106), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
[1200/2000] tot_loss=1.720 (perp=8.054, rec=0.109), tot_loss_proj:2.524 [t=0.29s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.722 (perp=8.054, rec=0.111), tot_loss_proj:2.526 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn urgency take on extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.717 (perp=8.096, rec=0.098), tot_loss_proj:2.572 [t=0.25s]
prediction: ['[CLS] build in mind focal viewer and kn mind take on extreme urgency. [SEP]']
[1350/2000] tot_loss=1.734 (perp=8.130, rec=0.108), tot_loss_proj:3.226 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.728 (perp=8.130, rec=0.102), tot_loss_proj:3.218 [t=0.25s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.724 (perp=8.130, rec=0.098), tot_loss_proj:3.215 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1500/2000] tot_loss=1.730 (perp=8.130, rec=0.104), tot_loss_proj:3.215 [t=0.28s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=8.130, rec=0.104), tot_loss_proj:3.215 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.736 (perp=8.130, rec=0.110), tot_loss_proj:3.218 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1650/2000] tot_loss=1.725 (perp=8.130, rec=0.099), tot_loss_proj:3.222 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.727 (perp=8.130, rec=0.101), tot_loss_proj:3.216 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.733 (perp=8.130, rec=0.107), tot_loss_proj:3.214 [t=0.27s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1800/2000] tot_loss=1.735 (perp=8.130, rec=0.109), tot_loss_proj:3.214 [t=0.28s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.733 (perp=8.130, rec=0.107), tot_loss_proj:3.216 [t=0.29s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=8.130, rec=0.109), tot_loss_proj:3.218 [t=0.26s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
[1950/2000] tot_loss=1.726 (perp=8.130, rec=0.100), tot_loss_proj:3.221 [t=0.29s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.729 (perp=8.130, rec=0.103), tot_loss_proj:3.216 [t=0.28s]
prediction: ['[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build in mind nonsense viewer and kn mind take on extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 53.846 | p: 53.846 | r: 53.846
rougeL     | fm: 78.571 | p: 78.571 | r: 78.571
rougeLsum  | fm: 78.571 | p: 78.571 | r: 78.571
r1fm+r2fm = 132.418

[Aggregate metrics]:
rouge1     | fm: 79.929 | p: 78.882 | r: 81.384
rouge2     | fm: 45.193 | p: 44.687 | r: 45.763
rougeL     | fm: 72.058 | p: 70.996 | r: 73.398
rougeLsum  | fm: 71.796 | p: 70.716 | r: 73.228
r1fm+r2fm = 125.122

input #34 time: 0:11:05 | total time: 6:30:51


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
cosin similarity: -0.9503733723742178 normalized error: 1.8923842993852011
cosin similarity: 0.9503733723742178 normalized error: 0.4112299561920301
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 1.9072460417616242 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 1.8966094508046802 for ['[CLS]end title seasons saysbib castle terror hand dear gu source woodland sport sheriff foughthala displacement plate wandered person spin lips constitution know tv callffed hahnply romeo automobiles door godfrey dearathi named wall why committee must efforts your [SEP]']
[Init] best rec loss: 1.852261241139072 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 1.8248313076065121 for ['[CLS] interview effectiveness hum saliva ring mao cheerleading aim respond medicine pointliftland lost happening gap placement solomon gertrude fabric four hair byte aimed ogden trains gnu beside jo tight spoke millionsᵢ folded girls halls man trail drawnvc rule authorities [SEP]']
[Init] best rec loss: 1.7643657672491058 for ["[CLS]bard boardless seed list arizona orders track be england lamb video name deep candy mont already nebraska offerings trained promise science last makeup qualifier ir lidciency about usesbrook'tag indefinitely grimes dress 2002 whether offerings design spear career [SEP]"]
[Init] best rec loss: 1.737547352247155 for ['[CLS]usionpm seeking tango casino over digital runway church radio cells an rom going endemicrted did penalty craft chance master no words [CLS] treatment bed caliphate quantum destination bladed down optical interested obvious rang recentguard hall theatre ballettt do [SEP]']
[Init] best rec loss: 1.6860270106594792 for ['[CLS] mi " therefore zev ms hays bun welles start pierce aquino interce specific causedpo normal texas often vocals secretaries themselves magic night court cesar stages achilles excellent fixed shi bertie leg rows plant alwaysch beijing futuretral young wall [SEP]']
[Init] best perm rec loss: 1.6827829914648578 for ['[CLS] future stages shi plant beijing often welles secretaries alwaysce bertie themselves excellent zev inter caused fixed achilles bun night specific mi rows hayspo aquinochtral leg normal therefore magic texas court wall ms " start young vocals cesar pierce [SEP]']
[Init] best perm rec loss: 1.6824930190927003 for ['[CLS] secretaries young fixed bun normal caused plant texaspo start excellenttral stages themselves court vocals beijing inter aquino pierce future always bertie shi night specific ms often " zev magic wallch therefore haysce rows cesar achilles mi leg welles [SEP]']
[Init] best perm rec loss: 1.681297142838472 for ['[CLS] welles court caused magic pierce mstral night vocals start therefore plant achilles shi zev specific bertie young beijing stages normalce texas wall cesar " mi legpo future fixed always interch rows themselves secretaries often hays aquino excellent bun [SEP]']
[Init] best perm rec loss: 1.6802185073922424 for ['[CLS] stages pierce often excellent ms normal specific hays fixed rows mipotral plant vocals achillesch young shi bun bertie therefore beijingce court " caused aquino magic night start inter themselves future cesar welles wall zev always texas leg secretaries [SEP]']
[Init] best perm rec loss: 1.6793486171160272 for ['[CLS] aquino excellent causedtral magicpo cesar always pierce bertie mi often start stages plantce night leg themselves specific " court secretariesch welles young zev ms inter shi texas bun hays achilles beijing fixed vocals future wall normal rows therefore [SEP]']
[Init] best perm rec loss: 1.6774741067481385 for ['[CLS] texas bertie mi stages shich often beijingce fixed bun secretaries pierce plant young specific rows aquino hays zev always cesar excellent therefore wall normal welles inter " future causedtral vocals magic night court themselves ms achilles startpo leg [SEP]']
[Init] best perm rec loss: 1.6774293348030225 for ['[CLS] wall achilles rows excellent secretariespo legch cesar hays zev fixed normalce court pierce ms bun night specific stages welles mi start beijing plant therefore inter magic vocals bertie future shi caused young oftentral texas aquino " themselves always [SEP]']
[Init] best perm rec loss: 1.6753105187579787 for ['[CLS] future hays shi cesartral specific zev start stages normal therefore fixed young themselves pierce mich caused nightce wall welles vocals secretaries excellent inter magicpo plant aquino achilles rows texas " always bertie ms beijing court often leg bun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.880 (perp=12.316, rec=0.417), tot_loss_proj:3.458 [t=0.27s]
prediction: ['[CLS] regional longest reception elevation fast roy unexpected sons wonder contemporary involved river greateyden south riley riley buddha around directors curator connection, amazing of historicalcion translated of world director necessary in 2010 firm intoivating completely taylor taylor another [SEP]']
[ 100/2000] tot_loss=2.447 (perp=10.556, rec=0.336), tot_loss_proj:3.447 [t=0.26s]
prediction: ['[CLS] personales book meaning : roy : hitleratory contemporary their river greatest roadire roy campus riley about seen, curator line, unique of greatcion translated about van daughter speak of greatest teacher care approximately really taylor taylor. [SEP]']
[ 150/2000] tot_loss=2.487 (perp=10.934, rec=0.300), tot_loss_proj:3.919 [t=0.27s]
prediction: ["[CLS] theired specialistˈ, paul or hitlertment the their lines great road ofpine previously rileynation ', director matter, good of greatest properties identity about van martyr speak from greatest teacher care approximately completely taylor taylor. [SEP]"]
[ 200/2000] tot_loss=2.299 (perp=10.116, rec=0.276), tot_loss_proj:3.192 [t=0.26s]
prediction: ["[CLS] theyed specialister which marguerite wenation discipline the their of great road but sawyer apparently (nation ', teacher matter, amazing of greatestations gift about makes rein speak from our teacher care about just teacher taylor. [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.287 (perp=9.956, rec=0.295), tot_loss_proj:3.057 [t=0.27s]
prediction: ["[CLS] we follow specialist johnson, marguerite wenation discipline the its'great road but hoffman apparently (nationbus, research in us excellent feature greatest things gift about rein rein of from your teacher care about because teacher latest. [SEP]"]
[ 300/2000] tot_loss=2.384 (perp=10.691, rec=0.246), tot_loss_proj:3.073 [t=0.30s]
prediction: ["[CLS] theed successful johnson full hire wenation discipline! its'greatest man, hoffman tampa (nationbus, teacher in us amazing visual greatest things helping about rein rein of of your teacher care about because teacher latest. [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.771 (perp=10.045, rec=0.762), tot_loss_proj:2.976 [t=0.27s]
prediction: ['[CLS] i,. feel. greg history community affair ‖ to being logan address. culture science is environmental aspects of director. us balanced discovery plant has makes about director article she [SEP] our teacher care about cedar highlighted 2011. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.512 (perp=9.109, rec=0.690), tot_loss_proj:2.821 [t=0.27s]
prediction: ['[CLS] i,. feel. greg makes communityrgeon ‖ to being award address. culture science is environmental aspects of science ) us balanced discovery plant and history about director article was the our teacher care about investments highlighted 2011. [SEP]']
[ 450/2000] tot_loss=2.468 (perp=9.119, rec=0.644), tot_loss_proj:3.013 [t=0.26s]
prediction: ['[CLS] i i. community. greg, community accessible ‖ to being award address. culture science is environmental aspects of science ) us balanced feature visual and history about director article was the our teacher care about investments highlighted 2011. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.533 (perp=9.625, rec=0.608), tot_loss_proj:3.461 [t=0.27s]
prediction: ['[CLS] we i. community. greg, community award ‖ to being picture address. hoffman science is environmental aspects of science ) us averaged feature visual and way about director directors was the our teacher care about investments highlighted director. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.524 (perp=9.641, rec=0.595), tot_loss_proj:3.550 [t=0.27s]
prediction: ['[CLS] j i. noted. greg, community award ‖ to being our address. hoffman science is environmental aspects of science ) us averaged feature visual and way about article directors was the picture teacher care about investments highlighted director. [SEP]']
[ 600/2000] tot_loss=2.495 (perp=9.641, rec=0.567), tot_loss_proj:3.542 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ to being our address. hoffman science is environmental aspects of science ) us averaged feature visual and way about article directors was the picture teacher care about investments highlighted director. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.424 (perp=9.318, rec=0.561), tot_loss_proj:3.285 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ hoffman science is to being our address. environmental aspects of science ) us averaged feature visual and way about article directors was the accessible teacher care about investments highlighted director. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.359 (perp=9.068, rec=0.545), tot_loss_proj:3.327 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is to being our address. environmental aspects of science ) us averaged feature visual and director way about directors was the accessible teacher care aboutductive highlighted director. [SEP]']
[ 750/2000] tot_loss=2.341 (perp=9.038, rec=0.534), tot_loss_proj:3.299 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science ) us averaged feature visual and director way about directors was the accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.213 (perp=8.433, rec=0.526), tot_loss_proj:3.389 [t=0.26s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science. us averaged. and article way about directors was the visual accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.268 (perp=8.747, rec=0.519), tot_loss_proj:3.414 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science. us averaged and article way about directors was discovery the visual accessible teacher care aboutductive highlighted director. [SEP]']
[ 900/2000] tot_loss=2.303 (perp=8.963, rec=0.510), tot_loss_proj:3.268 [t=0.29s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris science is of being our address. environmental aspects of science. us averaged and article history about director was discovery the visual accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.269 (perp=8.783, rec=0.513), tot_loss_proj:3.259 [t=0.27s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is science of being our address. environmental aspects of science. us averaged and article history about director was discovery the visual accessible teacher care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.260 (perp=8.768, rec=0.507), tot_loss_proj:3.223 [t=0.27s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is science of being stress address. environmental aspects of science teacher us averaged and article history about director was discovery the visual accessible. care aboutductive highlighted director. [SEP]']
[1050/2000] tot_loss=2.249 (perp=8.768, rec=0.496), tot_loss_proj:3.215 [t=0.27s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is science of being stress address. environmental aspects of science teacher us averaged and article history about director was discovery the visual accessible. care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.196 (perp=8.515, rec=0.493), tot_loss_proj:3.229 [t=0.27s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is history science of being stress address. environmental aspects of science teacher us averaged and article about director was discovery the visual accessible. care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.218 (perp=8.599, rec=0.498), tot_loss_proj:3.225 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is history science discovery of being our address. environmental aspects of science teacher us averaged and article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
[1200/2000] tot_loss=2.260 (perp=8.885, rec=0.483), tot_loss_proj:3.244 [t=0.28s]
prediction: ['[CLS] j i. noted. greg, community award ‖ harris is history science discovery of being our address. environmental aspects of science teacher us averaged arnold article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.324 (perp=9.173, rec=0.489), tot_loss_proj:3.327 [t=0.29s]
prediction: ['[CLS] noted i season j. greg, community award ‖ harris is history science discovery the being our address. environmental aspects of science teacher us averaged arnold article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.191 (perp=8.550, rec=0.481), tot_loss_proj:3.200 [t=0.27s]
prediction: ['[CLS] noted i season j. greg, community award ‖ harris is history science discovery being our address. the environmental aspects of science teacher us averaged and article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
[1350/2000] tot_loss=2.189 (perp=8.550, rec=0.479), tot_loss_proj:3.193 [t=0.27s]
prediction: ['[CLS] noted i season j. greg, community award ‖ harris is history science discovery being our address. the environmental aspects of science teacher us averaged and article about director sp the visual accessible ) care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.236 (perp=8.766, rec=0.483), tot_loss_proj:3.381 [t=0.26s]
prediction: ['[CLS] noted i season j greg, science award ‖ harris is history science discovery being our address. of environmental aspects of science teacher us averaged and article about director episode the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.212 (perp=8.662, rec=0.480), tot_loss_proj:3.358 [t=0.30s]
prediction: ['[CLS] noted i season j greg, address award ‖ harris is history science discovery being our science. of environmental aspects of science teacher us averaged and article about director episode the visual accessible. ) care aboutductive highlighted director. [SEP]']
[1500/2000] tot_loss=2.233 (perp=8.789, rec=0.475), tot_loss_proj:3.276 [t=0.27s]
prediction: ['[CLS] noted i season j greg, address award ‖ harris is history science discovery being our community. of environmental aspects of science teacher us averaged and article about director episode the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.196 (perp=8.605, rec=0.475), tot_loss_proj:3.263 [t=0.28s]
prediction: ['[CLS] noted i season j greg, address episode ‖ harris is history science discovery being our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.162 (perp=8.437, rec=0.474), tot_loss_proj:3.297 [t=0.27s]
prediction: ['[CLS] noted i season j greg, address being ‖ harris is history science discovery episode our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
[1650/2000] tot_loss=2.202 (perp=8.643, rec=0.473), tot_loss_proj:3.223 [t=0.26s]
prediction: ['[CLS] noted i season j greg, address been ‖ harris is history science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.183 (perp=8.571, rec=0.469), tot_loss_proj:3.249 [t=0.28s]
prediction: ['[CLS] noted i season j greg harris address been ‖, is history science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care aboutductive highlighted director. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.200 (perp=8.637, rec=0.473), tot_loss_proj:3.185 [t=0.26s]
prediction: ['[CLS] noted irin j greg harris address been, is history ‖ science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about premio highlighted director. [SEP]']
[1800/2000] tot_loss=2.197 (perp=8.637, rec=0.470), tot_loss_proj:3.179 [t=0.28s]
prediction: ['[CLS] noted irin j greg harris address been, is history ‖ science discovery story our community. of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about premio highlighted director. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.149 (perp=8.398, rec=0.469), tot_loss_proj:3.123 [t=0.27s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.146 (perp=8.398, rec=0.466), tot_loss_proj:3.126 [t=0.26s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
[1950/2000] tot_loss=2.147 (perp=8.398, rec=0.467), tot_loss_proj:3.122 [t=0.27s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.150 (perp=8.398, rec=0.471), tot_loss_proj:3.124 [t=0.29s]
prediction: ['[CLS] noted irin j greg harris address been, is ‖ science discovery story our community. history of environmental aspects of science teacher us averaged and article about director award the visual accessible. ) care about nba highlighted director. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] theed successful johnson full hire wenation discipline! its'greatest man, hoffman tampa (nationbus, teacher in us amazing visual greatest things helping about rein rein of of your teacher care about because teacher latest. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 31.429 | p: 31.429 | r: 31.429
rouge2     | fm: 2.941 | p: 2.941 | r: 2.941
rougeL     | fm: 20.000 | p: 20.000 | r: 20.000
rougeLsum  | fm: 20.000 | p: 20.000 | r: 20.000
r1fm+r2fm = 34.370

[Aggregate metrics]:
rouge1     | fm: 78.611 | p: 77.500 | r: 80.012
rouge2     | fm: 43.699 | p: 43.318 | r: 44.211
rougeL     | fm: 70.357 | p: 69.348 | r: 71.704
rougeLsum  | fm: 70.337 | p: 69.257 | r: 71.605
r1fm+r2fm = 122.310

input #35 time: 0:11:19 | total time: 6:42:11


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
cosin similarity: -0.9007084999897201 normalized error: 1.7564637892117434
cosin similarity: 0.9007084999897202 normalized error: 0.4904798791781636
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 1.9463439303535441 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 1.8597335676586169 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 1.6924834972748093 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 1.6912547128093005 for ['[CLS]va bonyrim seater [SEP]']
[Init] best rec loss: 1.4382111041870433 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 1.432398523081628 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 1.4317622020744187 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 1.4313524163463498 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 1.4287708516992645 for ['[CLS] ramsey harassment cornelius bates [SEP]']
[Init] best perm rec loss: 1.420618332142762 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.646 (perp=11.427, rec=0.360), tot_loss_proj:3.109 [t=0.26s]
prediction: ['[CLS] badly badly wrong wrong [SEP]']
[ 100/2000] tot_loss=2.140 (perp=9.529, rec=0.234), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=2.073 (perp=9.304, rec=0.212), tot_loss_proj:2.652 [t=0.27s]
prediction: ['[CLS] absolutely horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=2.680 (perp=12.544, rec=0.171), tot_loss_proj:3.655 [t=0.25s]
prediction: ['[CLS] damien horribly wrong wrong [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.939 (perp=8.830, rec=0.173), tot_loss_proj:2.315 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.918 (perp=8.830, rec=0.152), tot_loss_proj:2.313 [t=0.27s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.538 (perp=12.000, rec=0.138), tot_loss_proj:3.215 [t=0.25s]
prediction: ['[CLS] s wrong horriblyoic [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.287 (perp=10.754, rec=0.136), tot_loss_proj:2.799 [t=0.25s]
prediction: ['[CLS] s horribly wrong torture [SEP]']
[ 450/2000] tot_loss=2.275 (perp=10.754, rec=0.124), tot_loss_proj:2.803 [t=0.26s]
prediction: ['[CLS] s horribly wrong torture [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.458 (perp=11.688, rec=0.120), tot_loss_proj:3.340 [t=0.26s]
prediction: ['[CLS] skovic horribly wrong [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.236 (perp=10.617, rec=0.112), tot_loss_proj:2.980 [t=0.28s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[ 600/2000] tot_loss=2.241 (perp=10.617, rec=0.118), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.237 (perp=10.617, rec=0.114), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.237 (perp=10.617, rec=0.114), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[ 750/2000] tot_loss=2.238 (perp=10.617, rec=0.115), tot_loss_proj:2.984 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.233 (perp=10.617, rec=0.110), tot_loss_proj:2.983 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.240 (perp=10.617, rec=0.117), tot_loss_proj:2.982 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[ 900/2000] tot_loss=2.227 (perp=10.617, rec=0.104), tot_loss_proj:2.981 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.245 (perp=10.617, rec=0.121), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.231 (perp=10.617, rec=0.107), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1050/2000] tot_loss=2.234 (perp=10.617, rec=0.111), tot_loss_proj:2.976 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.231 (perp=10.617, rec=0.108), tot_loss_proj:2.973 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.226 (perp=10.617, rec=0.103), tot_loss_proj:2.969 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1200/2000] tot_loss=2.238 (perp=10.617, rec=0.114), tot_loss_proj:2.975 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.235 (perp=10.617, rec=0.112), tot_loss_proj:2.983 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.228 (perp=10.617, rec=0.104), tot_loss_proj:2.978 [t=0.28s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1350/2000] tot_loss=2.230 (perp=10.617, rec=0.107), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.235 (perp=10.617, rec=0.112), tot_loss_proj:2.972 [t=0.28s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.234 (perp=10.617, rec=0.110), tot_loss_proj:2.979 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1500/2000] tot_loss=2.232 (perp=10.617, rec=0.109), tot_loss_proj:2.976 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.228 (perp=10.617, rec=0.105), tot_loss_proj:2.976 [t=0.28s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.240 (perp=10.617, rec=0.116), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1650/2000] tot_loss=2.238 (perp=10.617, rec=0.115), tot_loss_proj:2.982 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.241 (perp=10.617, rec=0.117), tot_loss_proj:2.983 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.240 (perp=10.617, rec=0.117), tot_loss_proj:2.981 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1800/2000] tot_loss=2.233 (perp=10.617, rec=0.110), tot_loss_proj:2.979 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.236 (perp=10.617, rec=0.113), tot_loss_proj:2.971 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.229 (perp=10.617, rec=0.106), tot_loss_proj:2.978 [t=0.21s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1950/2000] tot_loss=2.228 (perp=10.617, rec=0.105), tot_loss_proj:2.977 [t=0.21s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.237 (perp=10.617, rec=0.114), tot_loss_proj:2.975 [t=0.21s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s horribly wrongkovic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 78.638 | p: 77.586 | r: 80.077
rouge2     | fm: 43.855 | p: 43.534 | r: 44.357
rougeL     | fm: 70.788 | p: 69.797 | r: 72.049
rougeLsum  | fm: 70.561 | p: 69.574 | r: 71.850
r1fm+r2fm = 122.493

input #36 time: 0:10:55 | total time: 6:53:06


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
cosin similarity: 0.9160557524849074 normalized error: 0.5048909406348259
cosin similarity: -0.9160557524849073 normalized error: 1.7122479261564743
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 1.5006748480817524 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 1.4465081559776138 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 1.4395158593330282 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 1.4008127448929162 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 1.2805219864328496 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 1.1848695802546465 for ['[CLS] quite sketch [SEP]']
[Init] best rec loss: 1.179312855528016 for ['[CLS] plainly holstein [SEP]']
[Init] best rec loss: 1.1543642241365162 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 1.143659906209792 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 1.1380497183729246 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 1.128497397896091 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.428 (perp=10.187, rec=0.391), tot_loss_proj:2.853 [t=0.20s]
prediction: ['[CLS] eccentric wife [SEP]']
[ 100/2000] tot_loss=2.555 (perp=11.791, rec=0.197), tot_loss_proj:3.201 [t=0.20s]
prediction: ['[CLS] eccentric indeed [SEP]']
[ 150/2000] tot_loss=2.065 (perp=9.583, rec=0.149), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=2.067 (perp=9.583, rec=0.151), tot_loss_proj:2.159 [t=0.20s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.596 (perp=11.411, rec=0.314), tot_loss_proj:2.973 [t=0.21s]
prediction: ['[CLS] therefore eccentric [SEP]']
[ 300/2000] tot_loss=2.431 (perp=11.266, rec=0.177), tot_loss_proj:2.925 [t=0.21s]
prediction: ['[CLS] indeed eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.238 (perp=10.438, rec=0.151), tot_loss_proj:2.743 [t=0.21s]
prediction: ['[CLS] besides eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.236 (perp=10.438, rec=0.148), tot_loss_proj:2.734 [t=0.21s]
prediction: ['[CLS] besides eccentric [SEP]']
[ 450/2000] tot_loss=2.231 (perp=10.438, rec=0.143), tot_loss_proj:2.728 [t=0.21s]
prediction: ['[CLS] besides eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.599 (perp=12.335, rec=0.132), tot_loss_proj:3.291 [t=0.21s]
prediction: ['[CLS] jared eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.604 (perp=12.335, rec=0.137), tot_loss_proj:3.285 [t=0.28s]
prediction: ['[CLS] jared eccentric [SEP]']
[ 600/2000] tot_loss=3.227 (perp=15.533, rec=0.120), tot_loss_proj:4.936 [t=0.25s]
prediction: ['[CLS]urity eccentric [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.665 (perp=12.620, rec=0.141), tot_loss_proj:3.483 [t=0.27s]
prediction: ['[CLS] eccentric jared [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.388 (perp=11.317, rec=0.124), tot_loss_proj:4.098 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[ 750/2000] tot_loss=2.401 (perp=11.317, rec=0.137), tot_loss_proj:4.093 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.379 (perp=11.317, rec=0.116), tot_loss_proj:4.089 [t=0.28s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.382 (perp=11.317, rec=0.119), tot_loss_proj:4.103 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[ 900/2000] tot_loss=2.392 (perp=11.317, rec=0.129), tot_loss_proj:4.099 [t=0.29s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.380 (perp=11.317, rec=0.117), tot_loss_proj:4.098 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:4.097 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1050/2000] tot_loss=2.376 (perp=11.317, rec=0.112), tot_loss_proj:4.097 [t=0.29s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.377 (perp=11.317, rec=0.114), tot_loss_proj:4.091 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.386 (perp=11.317, rec=0.123), tot_loss_proj:4.098 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1200/2000] tot_loss=2.380 (perp=11.317, rec=0.117), tot_loss_proj:4.087 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.382 (perp=11.317, rec=0.118), tot_loss_proj:4.091 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:4.094 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1350/2000] tot_loss=2.399 (perp=11.317, rec=0.136), tot_loss_proj:4.093 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.389 (perp=11.317, rec=0.126), tot_loss_proj:4.096 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.383 (perp=11.317, rec=0.120), tot_loss_proj:4.086 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1500/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:4.092 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.400 (perp=11.317, rec=0.137), tot_loss_proj:4.096 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.378 (perp=11.317, rec=0.115), tot_loss_proj:4.095 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1650/2000] tot_loss=2.391 (perp=11.317, rec=0.127), tot_loss_proj:4.089 [t=0.28s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.365 (perp=11.317, rec=0.102), tot_loss_proj:4.091 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.387 (perp=11.317, rec=0.123), tot_loss_proj:4.095 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1800/2000] tot_loss=2.383 (perp=11.317, rec=0.119), tot_loss_proj:4.087 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.384 (perp=11.317, rec=0.120), tot_loss_proj:4.088 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.382 (perp=11.317, rec=0.119), tot_loss_proj:4.093 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1950/2000] tot_loss=2.389 (perp=11.317, rec=0.125), tot_loss_proj:4.094 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.396 (perp=11.317, rec=0.133), tot_loss_proj:4.093 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentricurity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 66.667 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 66.667 | r: 50.000
rougeLsum  | fm: 57.143 | p: 66.667 | r: 50.000
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 78.090 | p: 77.347 | r: 79.361
rouge2     | fm: 43.128 | p: 42.641 | r: 43.549
rougeL     | fm: 70.171 | p: 69.438 | r: 71.248
rougeLsum  | fm: 70.416 | p: 69.590 | r: 71.496
r1fm+r2fm = 121.218

input #37 time: 0:10:10 | total time: 7:03:17


Running input #38 of 100.
reference: 
========================
scare 
========================
cosin similarity: -0.9177834580454345 normalized error: 1.7129305511605397
cosin similarity: 0.9177834580454345 normalized error: 0.5039674783213574
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 1.7734035403057808 for ['[CLS] course [SEP]']
[Init] best rec loss: 1.7676329486087006 for ['[CLS] 100 [SEP]']
[Init] best rec loss: 1.6444200642974889 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 1.492191168604056 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 1.4765153174854833 for ['[CLS] consciousness [SEP]']
[Init] best rec loss: 1.4302106789664772 for ['[CLS] private [SEP]']
[Init] best rec loss: 1.250476270925176 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.012 (perp=14.070, rec=0.198), tot_loss_proj:3.096 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.964 (perp=14.070, rec=0.150), tot_loss_proj:3.029 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.952 (perp=14.070, rec=0.137), tot_loss_proj:3.032 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.955 (perp=14.070, rec=0.141), tot_loss_proj:3.033 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.952 (perp=14.070, rec=0.138), tot_loss_proj:3.035 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.941 (perp=14.070, rec=0.127), tot_loss_proj:3.037 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.947 (perp=14.070, rec=0.133), tot_loss_proj:3.032 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.958 (perp=14.070, rec=0.144), tot_loss_proj:3.017 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.944 (perp=14.070, rec=0.129), tot_loss_proj:3.024 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.938 (perp=14.070, rec=0.124), tot_loss_proj:3.030 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.945 (perp=14.070, rec=0.131), tot_loss_proj:3.047 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.955 (perp=14.070, rec=0.141), tot_loss_proj:3.045 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.943 (perp=14.070, rec=0.129), tot_loss_proj:3.039 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.933 (perp=14.070, rec=0.119), tot_loss_proj:3.027 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.949 (perp=14.070, rec=0.135), tot_loss_proj:3.032 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.938 (perp=14.070, rec=0.123), tot_loss_proj:3.034 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.954 (perp=14.070, rec=0.140), tot_loss_proj:3.025 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.946 (perp=14.070, rec=0.132), tot_loss_proj:3.029 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.941 (perp=14.070, rec=0.127), tot_loss_proj:3.027 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.949 (perp=14.070, rec=0.135), tot_loss_proj:3.020 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.938 (perp=14.070, rec=0.124), tot_loss_proj:3.045 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.941 (perp=14.070, rec=0.127), tot_loss_proj:3.029 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.025 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.939 (perp=14.070, rec=0.125), tot_loss_proj:3.020 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.942 (perp=14.070, rec=0.128), tot_loss_proj:3.040 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.936 (perp=14.070, rec=0.122), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.030 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.942 (perp=14.070, rec=0.128), tot_loss_proj:3.035 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.953 (perp=14.070, rec=0.139), tot_loss_proj:3.016 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.934 (perp=14.070, rec=0.120), tot_loss_proj:3.021 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.039 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.932 (perp=14.070, rec=0.118), tot_loss_proj:3.027 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.942 (perp=14.070, rec=0.128), tot_loss_proj:3.028 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.938 (perp=14.070, rec=0.124), tot_loss_proj:3.026 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.937 (perp=14.070, rec=0.123), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.943 (perp=14.070, rec=0.129), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.939 (perp=14.070, rec=0.125), tot_loss_proj:3.036 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.946 (perp=14.070, rec=0.131), tot_loss_proj:3.045 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.937 (perp=14.070, rec=0.123), tot_loss_proj:3.022 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.931 (perp=14.070, rec=0.117), tot_loss_proj:3.030 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.709 | p: 77.991 | r: 79.734
rouge2     | fm: 44.290 | p: 43.916 | r: 44.786
rougeL     | fm: 71.118 | p: 70.319 | r: 72.183
rougeLsum  | fm: 71.006 | p: 70.282 | r: 72.050
r1fm+r2fm = 123.000

input #38 time: 0:08:05 | total time: 7:11:23


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
cosin similarity: -0.7643173159809633 normalized error: 1.7333089499394547
cosin similarity: 0.7643173159809634 normalized error: 0.560839091166381
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.950361821905691 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.9486013624905238 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 1.8971899816521889 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 1.7738379818514014 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 1.758819611469369 for ['[CLS]bis paranormal collaboration von below jared dynamics strong vincent reliefanna elevation greenfield glenn arrive stranded aubeltamen inter succession odin [SEP] anniversary name [SEP]']
[Init] best rec loss: 1.6898855215183355 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 1.6858491520501016 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best rec loss: 1.6586570803380538 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best rec loss: 1.6542327256966263 for ['[CLS] happens silk reads northwest walked peerage commandgu as legal ] erin comprehensive sampled commercial received sun green happens corrections splinter premiere colonel ground inclusive [SEP]']
[Init] best rec loss: 1.6491460734622378 for ['[CLS] laterpsy salt lieutenant natalily area mining step filmedties bad bow brownsgled phillip cousins stadium spit bat tracksce multi sy nail [SEP]']
[Init] best perm rec loss: 1.647166837914225 for ['[CLS]ties spit lieutenant brownspsy tracks phillip step mining bat multi cousins natalilygled bow area filmed saltce nail later bad sy stadium [SEP]']
[Init] best perm rec loss: 1.64350946420368 for ['[CLS] nail lieutenant stadium badce mining bat step area filmed tracks bowily browns saltties multi cousinspsy spit phillip sy natalgled later [SEP]']
[Init] best perm rec loss: 1.6417324567440574 for ['[CLS] spit tracks cousins lieutenant bat salt mining phillip sy stadium step filmed nail area badily multiceties browns bowpsy natal latergled [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.009 (perp=12.791, rec=0.451), tot_loss_proj:3.914 [t=0.21s]
prediction: ['[CLS]ilised route roots bryan century baron city gifts six renewed noble does provide strength need height include vogue aside mirage 2011peration modern mostly dominated [SEP]']
[ 100/2000] tot_loss=2.714 (perp=11.831, rec=0.348), tot_loss_proj:3.727 [t=0.21s]
prediction: ['[CLS]ilised tonnes travels bryan you grammy most gifts, rise to hiding gives texture new quality / conservativebound can fictionperationats common most [SEP]']
[ 150/2000] tot_loss=2.677 (perp=11.856, rec=0.305), tot_loss_proj:3.946 [t=0.21s]
prediction: ['[CLS] exactly tonnes travels bryan biggest wine conservativebound, relevance disrupt hide gives texture new quality / conservativebound time newperation beacon common most [SEP]']
[ 200/2000] tot_loss=2.666 (perp=12.039, rec=0.258), tot_loss_proj:3.883 [t=0.21s]
prediction: ['[CLS] luis tonnes travels bryan largest wine conservativebound, relevance bono hide gives texture new quality and conservativebound, reality edsnian most most [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.720 (perp=12.395, rec=0.241), tot_loss_proj:4.105 [t=0.21s]
prediction: ['[CLS] luis tonnes travels bryan most wine conservativebound, relevance bono hide gives texture new phenomenon and conservativebound movie realitynian basicple most [SEP]']
[ 300/2000] tot_loss=2.517 (perp=11.384, rec=0.240), tot_loss_proj:4.221 [t=0.21s]
prediction: ['[CLS] luis tonnes finds bryan most wine hidebound, relevance most hide gives texture new phenomenon and conservativebound movie reality khmer mostplebound [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.546 (perp=11.595, rec=0.227), tot_loss_proj:4.275 [t=0.21s]
prediction: ['[CLS] nothin tonnes finds bryan most hidebound, wine relevance most hide gives texture new phenomenon and conservativebound movie reality khmer mostple separating [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.341 (perp=10.621, rec=0.217), tot_loss_proj:3.507 [t=0.21s]
prediction: ['[CLS] nothin tonnes finds bryan most conservativebound, wine relevance and hide gives texture new quality and hidebound movie reality khmer of ayebound [SEP]']
[ 450/2000] tot_loss=2.323 (perp=10.621, rec=0.198), tot_loss_proj:3.508 [t=0.21s]
prediction: ['[CLS] nothin tonnes finds bryan most conservativebound, wine relevance and hide gives texture new quality and hidebound movie reality khmer of ayebound [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.340 (perp=10.749, rec=0.190), tot_loss_proj:3.531 [t=0.21s]
prediction: ['[CLS] tonnes finds bryan rules most conservativebound, acquired penguins and hide gives texture new traditions and hidebound movie reality khmer ofegabound [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.381 (perp=10.955, rec=0.190), tot_loss_proj:3.385 [t=0.21s]
prediction: ['[CLS] tonnes finds bryan lineman most conservativebound, acquired hide andwine gives texture new traditions and hidebound movie reality khmer of ayebound [SEP]']
[ 600/2000] tot_loss=2.320 (perp=10.757, rec=0.169), tot_loss_proj:3.622 [t=0.21s]
prediction: ['[CLS] tonnes finds bryan headed most conservativebound, acquired hide and penguins gives texture new traditions and hidebound movie reality khmer ofega few [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.283 (perp=10.562, rec=0.170), tot_loss_proj:3.755 [t=0.21s]
prediction: ['[CLS] tonnes finds bryan headed most conservativebound, acquired hide and penguins gives texture new traditions, hidebound reality polgara movie ofega few [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.140 (perp=9.823, rec=0.175), tot_loss_proj:3.590 [t=0.21s]
prediction: ['[CLS] tonnes finds together headed most conservative traditions, acquired hide and penguins gives texture new traditions, hidebound realitybound movie ofega few [SEP]']
[ 750/2000] tot_loss=2.202 (perp=10.228, rec=0.156), tot_loss_proj:3.907 [t=0.21s]
prediction: ['[CLS] tonnes findsard sided most conservative traditions, acquired hide and consequences gives texture new traditions, hidebound realitybound movie ofega few [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.218 (perp=10.290, rec=0.160), tot_loss_proj:3.468 [t=0.21s]
prediction: ['[CLS] almost finds together sided most conservative traditions and acquired hide and traditions gives texture new traditions, hidebound realitybound movie ofega few [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.137 (perp=9.914, rec=0.154), tot_loss_proj:3.259 [t=0.21s]
prediction: ['[CLS] almost finds together sided most conservative traditions and traditions hide and acquired gives texture new traditions, hidebound realitybound movie of hello few [SEP]']
[ 900/2000] tot_loss=2.136 (perp=9.953, rec=0.146), tot_loss_proj:3.351 [t=0.21s]
prediction: ['[CLS] almost finds together sided most conservative traditions and traditions hide and acquired gives texture new it, hidebound realitybound movie of hello few [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.024 (perp=9.369, rec=0.150), tot_loss_proj:3.386 [t=0.21s]
prediction: ['[CLS] it finds together sided most conservative traditions and traditions hide and acquired gives texture new almost, hidebound realitybound movie of pathetic separating [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.976 (perp=9.105, rec=0.155), tot_loss_proj:3.337 [t=0.21s]
prediction: ['[CLS] it finds together rent most conservative traditions and traditions hide and acquired gives texture new, almost hidebound realitybound movie of pathetic separating [SEP]']
[1050/2000] tot_loss=1.968 (perp=9.105, rec=0.147), tot_loss_proj:3.342 [t=0.21s]
prediction: ['[CLS] it finds together rent most conservative traditions and traditions hide and acquired gives texture new, almost hidebound realitybound movie of pathetic separating [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.925 (perp=8.918, rec=0.142), tot_loss_proj:3.273 [t=0.21s]
prediction: ['[CLS] it finds together acquired most conservative traditions and traditions hide and rent gives texture new, almost hidebound realitybound movie of pathetic separating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.933 (perp=8.918, rec=0.150), tot_loss_proj:3.267 [t=0.21s]
prediction: ['[CLS] it finds together acquired most conservative traditions and traditions hide and rent gives texture new, almost hidebound realitybound movie of pathetic separating [SEP]']
[1200/2000] tot_loss=1.925 (perp=8.918, rec=0.141), tot_loss_proj:3.271 [t=0.21s]
prediction: ['[CLS] it finds together acquired most conservative traditions and traditions hide and rent gives texture new, almost hidebound realitybound movie of pathetic separating [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.897 (perp=8.795, rec=0.138), tot_loss_proj:3.209 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound realitybound movie of pathetic separating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.915 (perp=8.861, rec=0.143), tot_loss_proj:3.259 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound realitybound movie of patheticputed [SEP]']
[1350/2000] tot_loss=1.910 (perp=8.861, rec=0.137), tot_loss_proj:3.254 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound realitybound movie of patheticputed [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.864 (perp=8.616, rec=0.141), tot_loss_proj:3.196 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound reality and movie of patheticputed [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.852 (perp=8.556, rec=0.140), tot_loss_proj:2.774 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound movie and reality of providingputed [SEP]']
[1500/2000] tot_loss=1.859 (perp=8.556, rec=0.148), tot_loss_proj:2.775 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound movie and reality of providingputed [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.831 (perp=8.443, rec=0.142), tot_loss_proj:3.423 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.826 (perp=8.443, rec=0.138), tot_loss_proj:3.422 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
[1650/2000] tot_loss=1.838 (perp=8.443, rec=0.150), tot_loss_proj:3.425 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.832 (perp=8.443, rec=0.143), tot_loss_proj:3.427 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions hide and rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.822 (perp=8.399, rec=0.142), tot_loss_proj:3.403 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions and traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
[1800/2000] tot_loss=1.954 (perp=9.091, rec=0.135), tot_loss_proj:3.559 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions one traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.955 (perp=9.091, rec=0.137), tot_loss_proj:3.564 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions one traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.949 (perp=9.091, rec=0.130), tot_loss_proj:3.557 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions one traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
[1950/2000] tot_loss=1.953 (perp=9.091, rec=0.135), tot_loss_proj:3.557 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions one traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.947 (perp=9.091, rec=0.129), tot_loss_proj:3.559 [t=0.21s]
prediction: ['[CLS] it finds acquired together most conservative traditions one traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] it finds acquired together most conservative traditions one traditions and hide rent gives texture new, almost hidebound movie andputed reality of pathetic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 66.667 | r: 72.727
rouge2     | fm: 18.182 | p: 17.391 | r: 19.048
rougeL     | fm: 47.826 | p: 45.833 | r: 50.000
rougeLsum  | fm: 47.826 | p: 45.833 | r: 50.000
r1fm+r2fm = 87.747

[Aggregate metrics]:
rouge1     | fm: 78.449 | p: 77.560 | r: 79.575
rouge2     | fm: 43.758 | p: 43.341 | r: 44.253
rougeL     | fm: 70.370 | p: 69.753 | r: 71.522
rougeLsum  | fm: 70.387 | p: 69.606 | r: 71.491
r1fm+r2fm = 122.206

input #39 time: 0:08:24 | total time: 7:19:48


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
cosin similarity: 0.7520072193431633 normalized error: 0.5835583402914879
cosin similarity: -0.7520072193431633 normalized error: 1.6842178880918164
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 1.919663213606563 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 1.8750292400090856 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 1.8070108547270045 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 1.7025860945920428 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 1.6918617581479485 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 1.673536622765821 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 1.5628137365362658 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 1.5441181350568889 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 1.4074242196869249 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 1.286685935873809 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 1.2804141762619776 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 1.2750975526205335 for ['[CLS] georgian already kent abd but deciding lady° many [SEP]']
[Init] best perm rec loss: 1.2718759074929233 for ['[CLS] deciding already kent many° lady abd but georgian [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.963 (perp=12.601, rec=0.443), tot_loss_proj:3.689 [t=0.21s]
prediction: ['[CLS] phone threat dyed crazy regime types wrong [ penalty [SEP]']
[ 100/2000] tot_loss=3.241 (perp=14.437, rec=0.354), tot_loss_proj:4.758 [t=0.21s]
prediction: ['[CLS] ph alexa dyedony regimetynɔ [ony [SEP]']
[ 150/2000] tot_loss=2.575 (perp=11.480, rec=0.279), tot_loss_proj:3.357 [t=0.21s]
prediction: ['[CLS] ph imagery phony sterntynmmel publishingony [SEP]']
[ 200/2000] tot_loss=2.434 (perp=10.778, rec=0.278), tot_loss_proj:3.087 [t=0.21s]
prediction: ['[CLS] ph imagery phony musictynmmel orony [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.046 (perp=13.528, rec=0.341), tot_loss_proj:3.995 [t=0.21s]
prediction: ['[CLS] ph imageryony ph tissueryl jewelry [ imagery [SEP]']
[ 300/2000] tot_loss=2.345 (perp=10.436, rec=0.258), tot_loss_proj:3.160 [t=0.21s]
prediction: ['[CLS] ph imageryony ph transmission unlike music or imagery [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.094 (perp=9.273, rec=0.240), tot_loss_proj:2.838 [t=0.21s]
prediction: ['[CLS] ph imagery phony transmissionう music or imagery [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.061 (perp=9.086, rec=0.243), tot_loss_proj:2.792 [t=0.21s]
prediction: ['[CLS] ph imagery podium phony transmission imagery or imagery [SEP]']
[ 450/2000] tot_loss=1.895 (perp=8.426, rec=0.210), tot_loss_proj:2.592 [t=0.21s]
prediction: ['[CLS] ph imageryraphic phony transmission imagery or imagery [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.225 (perp=10.147, rec=0.196), tot_loss_proj:2.929 [t=0.21s]
prediction: ['[CLS]mmel imageryraphiclinson phony imagery or imagery [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.062 (perp=9.342, rec=0.193), tot_loss_proj:2.749 [t=0.21s]
prediction: ['[CLS]mmellinson imageryraphic phony imagery or imagery [SEP]']
[ 600/2000] tot_loss=2.055 (perp=9.342, rec=0.186), tot_loss_proj:2.743 [t=0.21s]
prediction: ['[CLS]mmellinson imageryraphic phony imagery or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.158 (perp=9.907, rec=0.176), tot_loss_proj:2.858 [t=0.21s]
prediction: ['[CLS]mmellinson themraphic phony imagery or imagery [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.069 (perp=9.514, rec=0.166), tot_loss_proj:2.768 [t=0.21s]
prediction: ['[CLS]mmel themlinsonraphic phony imagery or imagery [SEP]']
[ 750/2000] tot_loss=2.072 (perp=9.514, rec=0.169), tot_loss_proj:2.768 [t=0.21s]
prediction: ['[CLS]mmel themlinsonraphic phony imagery or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.052 (perp=9.405, rec=0.171), tot_loss_proj:2.802 [t=0.21s]
prediction: ['[CLS]mmel uslinsonraphic phony imagery or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.049 (perp=9.405, rec=0.168), tot_loss_proj:2.791 [t=0.21s]
prediction: ['[CLS]mmel uslinsonraphic phony imagery or imagery [SEP]']
[ 900/2000] tot_loss=2.050 (perp=9.405, rec=0.169), tot_loss_proj:2.786 [t=0.21s]
prediction: ['[CLS]mmel uslinsonraphic phony imagery or imagery [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.114 (perp=9.764, rec=0.161), tot_loss_proj:2.865 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=2.121 (perp=9.764, rec=0.169), tot_loss_proj:2.861 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
[1050/2000] tot_loss=2.116 (perp=9.764, rec=0.164), tot_loss_proj:2.855 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=2.107 (perp=9.764, rec=0.155), tot_loss_proj:2.869 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=2.103 (perp=9.764, rec=0.150), tot_loss_proj:2.862 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
[1200/2000] tot_loss=2.109 (perp=9.764, rec=0.157), tot_loss_proj:2.860 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=2.108 (perp=9.764, rec=0.155), tot_loss_proj:2.866 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=2.109 (perp=9.764, rec=0.157), tot_loss_proj:2.857 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
[1350/2000] tot_loss=2.103 (perp=9.764, rec=0.150), tot_loss_proj:2.863 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=2.096 (perp=9.764, rec=0.143), tot_loss_proj:2.859 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=2.105 (perp=9.764, rec=0.152), tot_loss_proj:2.853 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
[1500/2000] tot_loss=2.098 (perp=9.764, rec=0.146), tot_loss_proj:2.862 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=2.109 (perp=9.764, rec=0.156), tot_loss_proj:2.867 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=2.097 (perp=9.764, rec=0.144), tot_loss_proj:2.866 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
[1650/2000] tot_loss=2.094 (perp=9.764, rec=0.141), tot_loss_proj:2.858 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=2.110 (perp=9.764, rec=0.157), tot_loss_proj:2.855 [t=0.21s]
prediction: ['[CLS]mmelfarlanelinson us phony imagery or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=2.412 (perp=11.315, rec=0.149), tot_loss_proj:3.100 [t=0.21s]
prediction: ['[CLS]mmelfarlane scar us phony imagery or imagery [SEP]']
[1800/2000] tot_loss=2.408 (perp=11.315, rec=0.145), tot_loss_proj:3.096 [t=0.22s]
prediction: ['[CLS]mmelfarlane scar us phony imagery or imagery [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.230 (perp=10.338, rec=0.163), tot_loss_proj:2.936 [t=0.21s]
prediction: ['[CLS]mmel scarfarlane us phony imagery or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=2.217 (perp=10.338, rec=0.149), tot_loss_proj:2.940 [t=0.21s]
prediction: ['[CLS]mmel scarfarlane us phony imagery or imagery [SEP]']
[1950/2000] tot_loss=2.206 (perp=10.338, rec=0.138), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS]mmel scarfarlane us phony imagery or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=2.222 (perp=10.338, rec=0.154), tot_loss_proj:2.928 [t=0.21s]
prediction: ['[CLS]mmel scarfarlane us phony imagery or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS]mmelfarlane scar us phony imagery or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 91.667

[Aggregate metrics]:
rouge1     | fm: 78.145 | p: 77.395 | r: 79.289
rouge2     | fm: 43.122 | p: 42.757 | r: 43.610
rougeL     | fm: 70.204 | p: 69.565 | r: 71.341
rougeLsum  | fm: 70.176 | p: 69.466 | r: 71.191
r1fm+r2fm = 121.267

input #40 time: 0:08:12 | total time: 7:28:01


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
cosin similarity: -0.9586736306406645 normalized error: 1.8620978720587626
cosin similarity: 0.9586736306406645 normalized error: 0.42054102770034735
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 1.9807413656640047 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 1.8783758999600992 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 1.8258731535338106 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 1.5699197359221344 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 1.5147527971791062 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 1.4065112444869143 for ['[CLS] hauntedrily [SEP]']
[Init] best rec loss: 1.348408171800872 for ["[CLS]'classification [SEP]"]
[Init] best rec loss: 1.3380154540705231 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 1.0463319870316985 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.8872571205676811 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.300 (perp=10.212, rec=0.258), tot_loss_proj:2.190 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.202 (perp=10.212, rec=0.159), tot_loss_proj:2.183 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.180 (perp=10.212, rec=0.137), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.181 (perp=10.212, rec=0.139), tot_loss_proj:2.197 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.173 (perp=10.212, rec=0.130), tot_loss_proj:2.197 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.165 (perp=10.212, rec=0.123), tot_loss_proj:2.176 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.161 (perp=10.212, rec=0.119), tot_loss_proj:2.199 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.167 (perp=10.212, rec=0.125), tot_loss_proj:2.182 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.161 (perp=10.212, rec=0.119), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.165 (perp=10.212, rec=0.123), tot_loss_proj:2.178 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.164 (perp=10.212, rec=0.122), tot_loss_proj:2.190 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.175 (perp=10.212, rec=0.133), tot_loss_proj:2.195 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.162 (perp=10.212, rec=0.120), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.169 (perp=10.212, rec=0.126), tot_loss_proj:2.183 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.177 (perp=10.212, rec=0.135), tot_loss_proj:2.179 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.171 (perp=10.212, rec=0.129), tot_loss_proj:2.189 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.165 (perp=10.212, rec=0.122), tot_loss_proj:2.190 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.166 (perp=10.212, rec=0.123), tot_loss_proj:2.191 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.184 (perp=10.212, rec=0.141), tot_loss_proj:2.193 [t=0.37s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.164 (perp=10.212, rec=0.122), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.170 (perp=10.212, rec=0.127), tot_loss_proj:2.193 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.172 (perp=10.212, rec=0.129), tot_loss_proj:2.190 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.174 (perp=10.212, rec=0.132), tot_loss_proj:2.183 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.170 (perp=10.212, rec=0.127), tot_loss_proj:2.195 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.164 (perp=10.212, rec=0.122), tot_loss_proj:2.188 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.178 (perp=10.212, rec=0.136), tot_loss_proj:2.188 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.180 (perp=10.212, rec=0.137), tot_loss_proj:2.185 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.168 (perp=10.212, rec=0.125), tot_loss_proj:2.176 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.173 (perp=10.212, rec=0.131), tot_loss_proj:2.190 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.162 (perp=10.212, rec=0.120), tot_loss_proj:2.180 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.172 (perp=10.212, rec=0.130), tot_loss_proj:2.196 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.169 (perp=10.212, rec=0.127), tot_loss_proj:2.173 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.175 (perp=10.212, rec=0.132), tot_loss_proj:2.176 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.173 (perp=10.212, rec=0.131), tot_loss_proj:2.179 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.176 (perp=10.212, rec=0.133), tot_loss_proj:2.202 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.173 (perp=10.212, rec=0.131), tot_loss_proj:2.183 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.169 (perp=10.212, rec=0.126), tot_loss_proj:2.182 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.174 (perp=10.212, rec=0.132), tot_loss_proj:2.200 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.175 (perp=10.212, rec=0.133), tot_loss_proj:2.192 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.167 (perp=10.212, rec=0.124), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.630 | p: 77.878 | r: 79.723
rouge2     | fm: 44.558 | p: 44.186 | r: 45.025
rougeL     | fm: 71.119 | p: 70.463 | r: 72.041
rougeLsum  | fm: 71.060 | p: 70.309 | r: 72.034
r1fm+r2fm = 123.188

input #41 time: 0:11:03 | total time: 7:39:05


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
cosin similarity: 0.7515790452467637 normalized error: 0.6030919457721563
cosin similarity: -0.7515790452467637 normalized error: 1.6304888937390711
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 1.9173784752685754 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 1.5231214295341136 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 1.5142328139048322 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 1.4642017247433694 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 1.4534022446529156 for ['[CLS] anymore read jersey pain / did felt outcomes water shitnagar brazil main subsidiarylde mp materials miami four fr wondering neither kingdom begun throne album [SEP]']
[Init] best rec loss: 1.328905465765787 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 1.3217662708682973 for ['[CLS]ures stages treaty cut wishbe ever lifted internationaltakingrs banda offended maple kitchen larger attracted supersededplinggible assignment enough scale darectric ran [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.041 (perp=12.988, rec=0.443), tot_loss_proj:3.610 [t=0.27s]
prediction: ['[CLS] apparently stall amnesty police minusno romanized drug stupid shirtf mom poorly media police circuit balls ring ignoring security ward prostitution old worst backwards transit [SEP]']
[ 100/2000] tot_loss=3.057 (perp=13.578, rec=0.341), tot_loss_proj:3.747 [t=0.27s]
prediction: ['[CLS] poorly poorly amnesty fbi poorly re violence equipment worst shirtf google poorly an trade d barely1 distracted guards ward threatened pot senate backwards legislation [SEP]']
[ 150/2000] tot_loss=2.834 (perp=12.674, rec=0.299), tot_loss_proj:3.545 [t=0.28s]
prediction: ['[CLS] poorly poorly percent medicine poorly re violence equipment worst sectionfboarding poorly any report d poorly1 ignoring guards harley threatened newark senate backwards legislation [SEP]']
[ 200/2000] tot_loss=2.838 (perp=12.711, rec=0.295), tot_loss_proj:3.551 [t=0.26s]
prediction: ['[CLS] poorly forgot percent medicine forgot re violence equipment poorly tickggerboarding poorly any report they poorly necessity for re harley ended newark scary backwards legislation [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.689 (perp=12.151, rec=0.259), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS] poorly forgot mapped medicine forgot arms iraqi equipment poorly re anythingammed poorly any report they poorly necessity to re harley into newark scary teammate legislation [SEP]']
[ 300/2000] tot_loss=2.807 (perp=12.902, rec=0.227), tot_loss_proj:3.568 [t=0.27s]
prediction: ['[CLS] poorly forgot mapped largest forgot tick films anything poorly to anything thayer poorlygger they they poorly necessity togger harley into newark scary teammate legislation [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.572 (perp=11.886, rec=0.195), tot_loss_proj:3.373 [t=0.27s]
prediction: ['[CLS] poorly forgot harley largest forgot scary films anything poorly to halfway mansion poorlygger they as poorly prepare togger mapped intoional scary teammate setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.687 (perp=12.499, rec=0.187), tot_loss_proj:3.490 [t=0.27s]
prediction: ['[CLS] poorly forgot salvatore largest forgot scary films anything poorly to halfway mansion poorlygger include as poorly prepare theygger filmmakers into traffic scary teammate setting [SEP]']
[ 450/2000] tot_loss=2.746 (perp=12.879, rec=0.170), tot_loss_proj:3.608 [t=0.28s]
prediction: ['[CLS] outbreak forgot sh largest forgot scary films anything poorly to halfway mansion poorlygger include as poorly prepare theygger filmmakers into commerce scary characters setting [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.667 (perp=12.545, rec=0.159), tot_loss_proj:3.556 [t=0.27s]
prediction: ['[CLS] salvatore poorly forgot largest forgot scary films anything poorly to halfway mansion poorlygger include as poorly prepare theygger filmmakers into commerce attraction depicted setting [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.635 (perp=12.386, rec=0.158), tot_loss_proj:3.530 [t=0.29s]
prediction: ['[CLS] salvatore outbreak forgot school scary films forgot anything poorly to halfway mansion poorlygger include as poorly prepare theygger filmmakers into commerce attraction depicted setting [SEP]']
[ 600/2000] tot_loss=2.669 (perp=12.586, rec=0.152), tot_loss_proj:3.577 [t=0.27s]
prediction: ['[CLS] salvatore outbreak forgot school scary films forgot anything they to halfway mansion poorlygger include as poorly prepare theygger filmmakers into highs attraction depicted setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.581 (perp=12.212, rec=0.138), tot_loss_proj:3.488 [t=0.27s]
prediction: ['[CLS] they outbreak forgot school scary films forgot anything they to halfway mansion poorlygger include as poorly prepare salvatoregger filmmakers into highs attraction depicted setting [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.583 (perp=12.212, rec=0.141), tot_loss_proj:3.485 [t=0.26s]
prediction: ['[CLS] they outbreak forgot school scary films forgot anything they to halfway mansion poorlygger include as poorly prepare salvatoregger filmmakers into highs attraction depicted setting [SEP]']
[ 750/2000] tot_loss=2.582 (perp=12.212, rec=0.139), tot_loss_proj:3.494 [t=0.28s]
prediction: ['[CLS] they outbreak forgot school scary films forgot anything they to halfway mansion poorlygger include as poorly prepare salvatoregger filmmakers into highs attraction depicted setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.628 (perp=12.467, rec=0.135), tot_loss_proj:3.507 [t=0.31s]
prediction: ['[CLS] they outbreak forgot school scary violence forgot anything they to halfway mansion poorlygger include as poorly setting salvatoregger filmmakers into highs attraction ourselves setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.555 (perp=12.119, rec=0.131), tot_loss_proj:3.411 [t=0.27s]
prediction: ['[CLS] they outbreak forgot school scaryrization forgot anything they to halfway mansion poorlygger include as poorly salvatore settinggger filmmakers into highs school ourselves setting [SEP]']
[ 900/2000] tot_loss=2.568 (perp=12.205, rec=0.127), tot_loss_proj:3.435 [t=0.28s]
prediction: ['[CLS] they outbreak forgot school scaryrization forgot anything they to halfway mansion poorlygger include as poorly salvatore depictedgger filmmakers into highs school ourselves setting [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.586 (perp=12.280, rec=0.130), tot_loss_proj:3.449 [t=0.29s]
prediction: ['[CLS] they outbreak forgot school scaryrization forgot anything they to halfway mansion poorlygger include as poorly salvatoregger filmmakers into transaction school depicted ourselves setting [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.512 (perp=11.912, rec=0.129), tot_loss_proj:3.363 [t=0.25s]
prediction: ['[CLS] they outbreak forgot school scaryrization forgot anything they to halfwayifice poorlygger include as poorly salvatoregger filmmakersmasters into school depicted ourselves setting [SEP]']
[1050/2000] tot_loss=2.544 (perp=12.100, rec=0.125), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] they etat forgot school scaryrization forgot anything they to halfwayifice poorlygger include as poorly salvatoregger filmmakerstf into school depicted ourselves setting [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.429 (perp=11.532, rec=0.123), tot_loss_proj:3.390 [t=0.27s]
prediction: ['[CLS] they etat forgot school scary filmmakers forgot anything they to halfwayifice poorlygger include as poorly salvatoreggerrization transaction into school depicted ourselves setting [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.415 (perp=11.436, rec=0.127), tot_loss_proj:3.353 [t=0.26s]
prediction: ['[CLS] they etat forgot school scary filmmakers forgot anything they to halfwayifice poorlygger include as poorly salvatoregger transactionrization into school depicted ourselves setting [SEP]']
[1200/2000] tot_loss=2.444 (perp=11.565, rec=0.131), tot_loss_proj:3.367 [t=0.26s]
prediction: ['[CLS] they etat forgot school scary filmmakers forgot anything they to halfwayifice poorlygger include as poorly salvatoreggerptionrization into school depicted ourselves setting [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.403 (perp=11.369, rec=0.129), tot_loss_proj:3.326 [t=0.28s]
prediction: ['[CLS] they etat forgot school scary filmmakers forgot anything they to halfwayifice poorlygger include as poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.314 (perp=10.940, rec=0.126), tot_loss_proj:3.215 [t=0.27s]
prediction: ['[CLS] they etat forgot school scary filmmakers forgot anything poorly to halfwayifice theygger include as poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]']
[1350/2000] tot_loss=2.294 (perp=10.818, rec=0.130), tot_loss_proj:3.236 [t=0.27s]
prediction: ['[CLS] they etat forgot school scary filmmakers forgot anything poorly to halfwayifice they re include as poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]']
Attempt swap
[1400/2000] tot_loss=2.284 (perp=10.823, rec=0.119), tot_loss_proj:3.212 [t=0.29s]
prediction: ['[CLS] the etat forgot school scary filmmakers forgot anything poorly to halfwayifice they re include as poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.236 (perp=10.587, rec=0.119), tot_loss_proj:3.161 [t=0.28s]
prediction: ['[CLS] the etat forgot school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]']
[1500/2000] tot_loss=2.231 (perp=10.587, rec=0.114), tot_loss_proj:3.166 [t=0.27s]
prediction: ['[CLS] the etat forgot school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.209 (perp=10.413, rec=0.126), tot_loss_proj:3.136 [t=0.29s]
prediction: ['[CLS] theption forgot school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school depicted setting ourselves [SEP]']
Attempt swap
[1600/2000] tot_loss=2.195 (perp=10.413, rec=0.113), tot_loss_proj:3.139 [t=0.27s]
prediction: ['[CLS] theption forgot school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school depicted setting ourselves [SEP]']
[1650/2000] tot_loss=2.197 (perp=10.413, rec=0.114), tot_loss_proj:3.140 [t=0.28s]
prediction: ['[CLS] theption forgot school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school depicted setting ourselves [SEP]']
Attempt swap
[1700/2000] tot_loss=2.204 (perp=10.413, rec=0.121), tot_loss_proj:3.138 [t=0.26s]
prediction: ['[CLS] theption forgot school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school depicted setting ourselves [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.269 (perp=10.762, rec=0.117), tot_loss_proj:3.135 [t=0.25s]
prediction: ['[CLS] the forgotmental school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school depicted setting ourselves [SEP]']
[1800/2000] tot_loss=2.196 (perp=10.372, rec=0.122), tot_loss_proj:3.095 [t=0.26s]
prediction: ['[CLS] the forgot rogers school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school depicted setting ourselves [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.192 (perp=10.338, rec=0.125), tot_loss_proj:3.083 [t=0.27s]
prediction: ['[CLS] the forgot rogers school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly salvatoregger etatrization into school setting depicted ourselves [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.146 (perp=10.055, rec=0.135), tot_loss_proj:3.044 [t=0.29s]
prediction: ['[CLS] the forgot rogers school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly depicted shgger etatrization into school setting ourselves [SEP]']
[1950/2000] tot_loss=2.145 (perp=10.129, rec=0.119), tot_loss_proj:3.061 [t=0.26s]
prediction: ['[CLS] the forgot rogers school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly depicted salvatoregger etatrization into school setting ourselves [SEP]']
Attempt swap
[2000/2000] tot_loss=2.150 (perp=10.129, rec=0.124), tot_loss_proj:3.053 [t=0.27s]
prediction: ['[CLS] the forgot rogers school scary filmmakers forgot anything poorly to halfwayifice as they re include poorly depicted salvatoregger etatrization into school setting ourselves [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] the etat forgot school scary filmmakers forgot anything poorly to halfwayifice they re include as poorly salvatoreggerptionrization into school depicted setting ourselves [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 62.500 | r: 62.500
rouge2     | fm: 8.696 | p: 8.696 | r: 8.696
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 71.196

[Aggregate metrics]:
rouge1     | fm: 78.227 | p: 77.510 | r: 79.341
rouge2     | fm: 44.000 | p: 43.674 | r: 44.541
rougeL     | fm: 70.592 | p: 69.818 | r: 71.587
rougeLsum  | fm: 70.543 | p: 69.748 | r: 71.556
r1fm+r2fm = 122.226

input #42 time: 0:11:17 | total time: 7:50:22


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
cosin similarity: -0.8206536545363274 normalized error: 1.7208620839187307
cosin similarity: 0.8206536545363273 normalized error: 0.5385766653645379
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 1.930642349247132 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 1.7851881997727803 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 1.6401963674852145 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 1.5806250046029051 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 1.4549208238461195 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 1.4183159966364798 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 1.2795261404886538 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 1.2649144397639163 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 1.1797931903189784 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 1.1795728389063767 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 1.1789216065817092 for ['[CLS] oxidation council enrollment deserved [SEP]']
[Init] best perm rec loss: 1.17678087706032 for ['[CLS] council oxidation deserved enrollment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.313 (perp=14.014, rec=0.510), tot_loss_proj:4.350 [t=0.27s]
prediction: ['[CLS]ountless qualify racial [SEP]']
[ 100/2000] tot_loss=2.988 (perp=13.182, rec=0.352), tot_loss_proj:4.374 [t=0.29s]
prediction: ['[CLS]ountlessptiveistic [SEP]']
[ 150/2000] tot_loss=3.036 (perp=13.726, rec=0.291), tot_loss_proj:4.701 [t=0.26s]
prediction: ['[CLS]ouse armycifulistic [SEP]']
[ 200/2000] tot_loss=2.407 (perp=10.763, rec=0.255), tot_loss_proj:2.931 [t=0.28s]
prediction: ['[CLS]ition naissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.376 (perp=10.766, rec=0.223), tot_loss_proj:2.934 [t=0.26s]
prediction: ['[CLS]iss naissistic [SEP]']
[ 300/2000] tot_loss=2.348 (perp=10.766, rec=0.195), tot_loss_proj:2.947 [t=0.26s]
prediction: ['[CLS]iss naissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.319 (perp=10.766, rec=0.166), tot_loss_proj:2.943 [t=0.26s]
prediction: ['[CLS]iss naissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.386 (perp=11.133, rec=0.159), tot_loss_proj:3.101 [t=0.27s]
prediction: ['[CLS] ec naissistic [SEP]']
[ 450/2000] tot_loss=2.378 (perp=11.133, rec=0.151), tot_loss_proj:3.081 [t=0.27s]
prediction: ['[CLS] ec naissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.381 (perp=11.133, rec=0.154), tot_loss_proj:3.092 [t=0.27s]
prediction: ['[CLS] ec naissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.369 (perp=11.133, rec=0.143), tot_loss_proj:3.100 [t=0.28s]
prediction: ['[CLS] ec naissistic [SEP]']
[ 600/2000] tot_loss=2.369 (perp=11.133, rec=0.143), tot_loss_proj:3.091 [t=0.26s]
prediction: ['[CLS] ec naissistic [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.108 (perp=9.766, rec=0.155), tot_loss_proj:3.221 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.103 (perp=9.766, rec=0.150), tot_loss_proj:3.235 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
[ 750/2000] tot_loss=2.089 (perp=9.766, rec=0.136), tot_loss_proj:3.234 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.075 (perp=9.766, rec=0.122), tot_loss_proj:3.230 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.094 (perp=9.766, rec=0.141), tot_loss_proj:3.240 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[ 900/2000] tot_loss=2.095 (perp=9.766, rec=0.142), tot_loss_proj:3.237 [t=0.30s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.091 (perp=9.766, rec=0.137), tot_loss_proj:3.241 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1000/2000] tot_loss=2.078 (perp=9.766, rec=0.125), tot_loss_proj:3.232 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1050/2000] tot_loss=2.092 (perp=9.766, rec=0.139), tot_loss_proj:3.236 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1100/2000] tot_loss=2.090 (perp=9.766, rec=0.137), tot_loss_proj:3.239 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1150/2000] tot_loss=2.080 (perp=9.766, rec=0.127), tot_loss_proj:3.244 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
[1200/2000] tot_loss=2.086 (perp=9.766, rec=0.133), tot_loss_proj:3.243 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1250/2000] tot_loss=2.084 (perp=9.766, rec=0.131), tot_loss_proj:3.235 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1300/2000] tot_loss=2.088 (perp=9.766, rec=0.135), tot_loss_proj:3.240 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
[1350/2000] tot_loss=2.094 (perp=9.766, rec=0.141), tot_loss_proj:3.245 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1400/2000] tot_loss=2.084 (perp=9.766, rec=0.131), tot_loss_proj:3.243 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1450/2000] tot_loss=2.089 (perp=9.766, rec=0.136), tot_loss_proj:3.247 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1500/2000] tot_loss=2.081 (perp=9.766, rec=0.128), tot_loss_proj:3.237 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1550/2000] tot_loss=2.080 (perp=9.766, rec=0.127), tot_loss_proj:3.247 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1600/2000] tot_loss=2.077 (perp=9.766, rec=0.124), tot_loss_proj:3.236 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1650/2000] tot_loss=2.078 (perp=9.766, rec=0.125), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1700/2000] tot_loss=2.092 (perp=9.766, rec=0.138), tot_loss_proj:3.242 [t=0.28s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1750/2000] tot_loss=2.091 (perp=9.766, rec=0.138), tot_loss_proj:3.240 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1800/2000] tot_loss=2.076 (perp=9.766, rec=0.123), tot_loss_proj:3.242 [t=0.25s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1850/2000] tot_loss=2.076 (perp=9.766, rec=0.122), tot_loss_proj:3.244 [t=0.27s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[1900/2000] tot_loss=2.098 (perp=9.766, rec=0.145), tot_loss_proj:3.242 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
[1950/2000] tot_loss=2.072 (perp=9.766, rec=0.118), tot_loss_proj:3.250 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Attempt swap
[2000/2000] tot_loss=2.088 (perp=9.766, rec=0.135), tot_loss_proj:3.243 [t=0.26s]
prediction: ['[CLS] ecissistic na [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] ecissistic na [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 77.771 | p: 76.834 | r: 79.080
rouge2     | fm: 42.765 | p: 42.425 | r: 43.253
rougeL     | fm: 70.359 | p: 69.458 | r: 71.493
rougeLsum  | fm: 70.250 | p: 69.377 | r: 71.443
r1fm+r2fm = 120.536

input #43 time: 0:11:03 | total time: 8:01:26


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
cosin similarity: -0.8568554930972359 normalized error: 1.74531016791114
cosin similarity: 0.856855493097236 normalized error: 0.5131648958461217
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.8408239056825355 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.5962682946128663 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 1.5329986037727885 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 1.532608173477598 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best rec loss: 1.5271526875466608 for ['[CLS] program jurisdiction earlier mistakes through learning near termhen death blank christianity skeleton besides merton son bikinittle ) eyebrows previous hamption civil antony seed architectural remained lie [SEP]']
[Init] best rec loss: 1.495407174316337 for ['[CLS] reservesdicated friendly sole rurallda counselan signals spec jamie americas foot emigrated tied [MASK] dex comfortdating artillery meditation joinednard readings eve solo ukraine why offspring [SEP]']
[Init] best perm rec loss: 1.4914100898253133 for ['[CLS] artillery [MASK] ukrainedatingnard signals joined sole friendly readings why counsel jamiedicated spec reserves offspring tied dex solo americaslda meditationan foot eve emigrated rural comfort [SEP]']
[Init] best perm rec loss: 1.4901355102475167 for ['[CLS] friendly dexlda signals solo tieddicated offspring ukraine reserves eve footnard meditation rural emigrated americas jamiedating spec readings comfort counsel artillery [MASK]an why sole joined [SEP]']
[Init] best perm rec loss: 1.4877398101619763 for ['[CLS] ukraine jamie friendlydicated readings spec eve tied rural footan dex signals emigrated comfort americas artillery meditation sole joined counsel [MASK] offspringnard reserves sololdadating why [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.650 (perp=11.323, rec=0.385), tot_loss_proj:3.176 [t=0.29s]
prediction: ['[CLS] lost loses editorial text screaming routine fled print rigged shell? apparently dumb mug design commercial coke false verdict paper and planned an allegedly damage ¨ category assignment jerked [SEP]']
[ 100/2000] tot_loss=2.590 (perp=11.440, rec=0.302), tot_loss_proj:3.156 [t=0.29s]
prediction: ['[CLS] lost lost published text screaming routine fled print rigged shelles routine dumb hollywood design routine coke false bowler chronology nor translation an allegedly damage another welles translation paused [SEP]']
[ 150/2000] tot_loss=2.694 (perp=12.074, rec=0.279), tot_loss_proj:3.258 [t=0.28s]
prediction: ['[CLS] was lost routine text gambling routine losttest rigged. is routine dumb hollywood performer routineos false bowler province nor translation the allegedlyort another objective translation afghanistan [SEP]']
[ 200/2000] tot_loss=2.540 (perp=11.587, rec=0.223), tot_loss_proj:3.320 [t=0.26s]
prediction: ['[CLS] is lost routine afterwardsₕ continuous lost it rigged.. routine. hollywood performer routinegos slack bowler. nor translation the palermoort another finals translation disbanded [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.477 (perp=11.420, rec=0.194), tot_loss_proj:3.232 [t=0.27s]
prediction: ['[CLS] been lost routine slackₕ continuous lostification rigged. in routine routine hollywoodfest.gos slack bowler. nor translation the palermoort another張 translationizes [SEP]']
[ 300/2000] tot_loss=2.333 (perp=10.811, rec=0.171), tot_loss_proj:3.133 [t=0.27s]
prediction: ['[CLS] been lost routine slackburgh continuous. ; rigged. in routine routine hollywoodfest. jed slack bowler. nor procedure the palermoort anotherfest translationizes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.204 (perp=10.188, rec=0.167), tot_loss_proj:3.062 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. ; rigged slack in routine routine hollywoodfest.kar. bowler. nor procedure the palermoort another″ translationizes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.173 (perp=10.111, rec=0.151), tot_loss_proj:3.041 [t=0.27s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest.kar. bowlerizes thereforealic the palermoort another execution translation. [SEP]']
[ 450/2000] tot_loss=2.172 (perp=10.128, rec=0.147), tot_loss_proj:3.015 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest.kar. doughizes thereforealic the palermoort another execution translation. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.271 (perp=10.593, rec=0.152), tot_loss_proj:3.206 [t=0.27s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkaralic doughizes therefore. the arabianort another execution translation. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.131 (perp=9.990, rec=0.133), tot_loss_proj:3.044 [t=0.27s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkar doughalicizes therefore. the arabianort another execution translation. [SEP]']
[ 600/2000] tot_loss=2.132 (perp=9.990, rec=0.134), tot_loss_proj:3.047 [t=0.26s]
prediction: ['[CLS] has lost routine slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkar doughalicizes therefore. the arabianort another execution translation. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.075 (perp=9.742, rec=0.127), tot_loss_proj:2.908 [t=0.26s]
prediction: ['[CLS] has lost execution slack ₍ continuous. the significance slack in routine routine hollywoodfest slackkar doughalicizes therefore. the arabianort another routine translation. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.112 (perp=9.918, rec=0.128), tot_loss_proj:2.959 [t=0.26s]
prediction: ['[CLS] has lost execution slack ₍ excessive. the significance slack in routine routine hollywoodfest slackkarartyalicizes therefore. the routine arabianort another translation. [SEP]']
[ 750/2000] tot_loss=2.099 (perp=9.848, rec=0.129), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS] has lost execution slack ₍ excessive. the significance slack in routine routine hollywoodfest slackkarartyalicizes therefore. the routine itsort another translation. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.021 (perp=9.429, rec=0.135), tot_loss_proj:3.011 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ excessive. the significance slack in routine routine hollywoodfest slack couldartyalicizes therefore. the routine its seat another translation. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.216 (perp=10.434, rec=0.130), tot_loss_proj:3.031 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ excessivealic the significance skirt in routine routine hollywoodfest slack couldartyalicizes therefore. the routine slack seat another translation. [SEP]']
[ 900/2000] tot_loss=2.271 (perp=10.755, rec=0.120), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] has lost slack execution hysteria excessivealic the significance skirt in routine routine hollywoodfest slack couldartyalicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.324 (perp=11.015, rec=0.121), tot_loss_proj:3.188 [t=0.28s]
prediction: ['[CLS] has lost slack execution hysteria excessivealic the significance skirt in routine routine hollywoodfest slack prophetkaralicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.226 (perp=10.474, rec=0.131), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] has lost slack execution hysteria the significance excessivealic skirt in routine routine hollywoodfest slackartykaralicizes therefore. the routine slack seat another translation. [SEP]']
[1050/2000] tot_loss=2.184 (perp=10.320, rec=0.120), tot_loss_proj:2.997 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the significance excessivealic skirt in routine routine hollywoodfest slackartykaralicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.144 (perp=10.121, rec=0.120), tot_loss_proj:2.936 [t=0.27s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic skirt in excessive routine routine hollywoodfest slackartykaralicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.209 (perp=10.438, rec=0.121), tot_loss_proj:3.015 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic excessive in skirt routine routine hollywoodfest slack prophetkaralicizes therefore. the routine slack seat another translation. [SEP]']
[1200/2000] tot_loss=2.155 (perp=10.190, rec=0.117), tot_loss_proj:2.918 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic excessive in skirt routine routine hollywoodfest slack prophet fairlyalicizes therefore. the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.106 (perp=9.965, rec=0.113), tot_loss_proj:2.849 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic. in skirt routine routine hollywoodfest slack prophet fairlyalicizes therefore excessive the routine slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.088 (perp=9.902, rec=0.108), tot_loss_proj:2.879 [t=0.30s]
prediction: ['[CLS] has lost slack execution ₍ the significancealic. in skirt routine routine hollywoodfest routine prophet fairlyalicizes therefore excessive the slack slack seat another translation. [SEP]']
[1350/2000] tot_loss=2.192 (perp=10.350, rec=0.122), tot_loss_proj:2.917 [t=0.29s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in tinted routine routine hollywoodfest routine prophet fairlyalicizes therefore excessive the slack slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.022 (perp=9.560, rec=0.110), tot_loss_proj:2.799 [t=0.29s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the routine routine hollywoodfest routine prophet fairlyalicizes therefore excessive skirt slack slack seat another translation. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.134 (perp=10.052, rec=0.124), tot_loss_proj:2.902 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine prophet racialalicizes therefore excessive another slack slack seat detectives translation. [SEP]']
[1500/2000] tot_loss=2.095 (perp=9.890, rec=0.117), tot_loss_proj:2.850 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine prophet racialalicizes therefore excessive another slack slack seat tinted translation. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.083 (perp=9.828, rec=0.117), tot_loss_proj:2.839 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine racial prophetalicizes therefore excessive another slack slack seat kensington translation. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.086 (perp=9.828, rec=0.120), tot_loss_proj:2.847 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine racial prophetalicizes therefore excessive another slack slack seat kensington translation. [SEP]']
[1650/2000] tot_loss=2.079 (perp=9.828, rec=0.113), tot_loss_proj:2.840 [t=0.26s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine racial prophetalicizes therefore excessive another slack slack seat kensington translation. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.071 (perp=9.757, rec=0.120), tot_loss_proj:2.812 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophetalicizes therefore excessive another slack slack seat racial translation. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.050 (perp=9.667, rec=0.116), tot_loss_proj:2.788 [t=0.25s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore excessive another slack slack seatalic translation. [SEP]']
[1800/2000] tot_loss=2.057 (perp=9.667, rec=0.124), tot_loss_proj:2.784 [t=0.27s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore excessive another slack slack seatalic translation. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.031 (perp=9.569, rec=0.118), tot_loss_proj:2.760 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore another excessive slack slack seatalic translation. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.012 (perp=9.487, rec=0.115), tot_loss_proj:2.752 [t=0.27s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes another therefore excessive slack slack seatalic translation. [SEP]']
[1950/2000] tot_loss=2.008 (perp=9.487, rec=0.110), tot_loss_proj:2.748 [t=0.28s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes another therefore excessive slack slack seatalic translation. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.013 (perp=9.475, rec=0.118), tot_loss_proj:2.776 [t=0.27s]
prediction: ['[CLS] has lost slack execution ₍ the premisealic. in the routine which hollywoodfest routine kensington prophet racializes another therefore excessive slack slack seatalic translation. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] has lost slack execution ₍ the premisealic. in the which routine hollywoodfest routine kensington prophet racializes therefore another excessive slack slack seatalic translation. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.319 | p: 54.167 | r: 56.522
rouge2     | fm: 13.333 | p: 13.043 | r: 13.636
rougeL     | fm: 34.043 | p: 33.333 | r: 34.783
rougeLsum  | fm: 34.043 | p: 33.333 | r: 34.783
r1fm+r2fm = 68.652

[Aggregate metrics]:
rouge1     | fm: 77.283 | p: 76.337 | r: 78.538
rouge2     | fm: 42.363 | p: 41.980 | r: 42.821
rougeL     | fm: 69.423 | p: 68.572 | r: 70.594
rougeLsum  | fm: 69.439 | p: 68.562 | r: 70.607
r1fm+r2fm = 119.646

input #44 time: 0:11:12 | total time: 8:12:39


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
cosin similarity: -0.8624079044552135 normalized error: 1.7449468372151096
cosin similarity: 0.8624079044552135 normalized error: 0.5109698971810958
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 1.9146515847063736 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 1.6332375251840188 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 1.500359427995984 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 1.2939814832067222 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 1.1644757465174165 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 1.1641417101783367 for ['[CLS] status football whoa joan tree enclosed entrance curtis gentry around few ( military skinlanda single bore v five special letter ku via taste operated2tiv murmured [SEP]']
[Init] best perm rec loss: 1.1631431773277008 for ['[CLS] single gentry tastelanda ( via tree bore few football special entrance status joan murmured whoa letter around v operated enclosed ku fivetiv2 skin curtis military [SEP]']
[Init] best perm rec loss: 1.1629994392654714 for ['[CLS] whoa entrance taste five around letter footballtiv single ku operated2 status skin joan enclosed military tree murmured gentrylanda v ( few bore via curtis special [SEP]']
[Init] best perm rec loss: 1.160602955912381 for ['[CLS] single gentry taste skin status via ku football tree special operated enclosed joantiv2 curtis whoa ( letterlanda military five murmured few around bore entrance v [SEP]']
[Init] best perm rec loss: 1.1604427087402178 for ['[CLS] taste ( gentry special skin tree statuslanda single operated joan whoa aroundtiv football curtis bore few five letter v military2 enclosed ku entrance via murmured [SEP]']
[Init] best perm rec loss: 1.1546550746046425 for ['[CLS] football around v2 murmured special vialanda enclosed skin joan entrance boretiv military letter whoa operated five few gentry single status tree ku taste curtis ( [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.859 (perp=12.294, rec=0.401), tot_loss_proj:3.360 [t=0.27s]
prediction: ["[CLS] ship demoted flipped post overseaser wiring in fifeit australian'trade at mob application an compared - passed display double block grade expogm pamphlet tonight [SEP]"]
[ 100/2000] tot_loss=2.593 (perp=11.321, rec=0.329), tot_loss_proj:3.132 [t=0.26s]
prediction: ["[CLS] trade funin post acte talking infu warlord -'trade than - application an operated - passed airing character block deck expogm agitation tonight [SEP]"]
[ 150/2000] tot_loss=2.544 (perp=11.219, rec=0.300), tot_loss_proj:3.157 [t=0.28s]
prediction: ["[CLS] move funin aspen acte movements infu exercise -'shelf than - on an bought - pass thus character exercise shootboardgp exercise tonight [SEP]"]
[ 200/2000] tot_loss=2.582 (perp=11.608, rec=0.261), tot_loss_proj:3.273 [t=0.27s]
prediction: ['[CLS] shelf funin aspen act - movements -fu exercise - - shelf than - - - shelf - otherwise thus character exercisemm exercise than exercise than [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.266 (perp=10.193, rec=0.228), tot_loss_proj:3.046 [t=0.27s]
prediction: ['[CLS] shelf fornin aspen bow - movements -mm bow - - shelf than this - - shelf - otherwise - character exercisemm exercisegp exercise pursuing [SEP]']
[ 300/2000] tot_loss=2.238 (perp=10.241, rec=0.190), tot_loss_proj:3.104 [t=0.26s]
prediction: ['[CLS] shelf fornin aspen bow - movements -mm bow - - shelf than this - - shelf - usually - character exercisemm exercisegp exercise pursuing [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.232 (perp=10.240, rec=0.184), tot_loss_proj:3.096 [t=0.28s]
prediction: ['[CLS] this innin aspen bow - movements -mm bow - - shelf than shelf - - shelf -ick - crime exercisemm exercisegp exercise pursuing [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.310 (perp=10.458, rec=0.218), tot_loss_proj:2.898 [t=0.29s]
prediction: ['[CLS] this funin - bow - movementselmm bow - / shelf than shelf - the shelf -ick - crime shootmm exercisegp exercise pursuing [SEP]']
[ 450/2000] tot_loss=2.445 (perp=11.339, rec=0.177), tot_loss_proj:3.257 [t=0.27s]
prediction: ['[CLS] this ginin - bow - movementselmm bow - / shelf than crime - on shelf -ick - crime shootmm exercisegp exercise pursued [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.204 (perp=10.180, rec=0.168), tot_loss_proj:3.093 [t=0.27s]
prediction: ['[CLS] this gi turning - bow - movements exercisemm bow - / shelf than crime - on shelf -ick - crime dramamm - connolly exercise pursued [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.149 (perp=9.974, rec=0.154), tot_loss_proj:3.017 [t=0.26s]
prediction: ['[CLS] this gi snapping - bow - movements exercisemm bow - than shelf / drama long on shelf -ick - crime dramamm - connolly exercise pursued [SEP]']
[ 600/2000] tot_loss=2.170 (perp=10.122, rec=0.146), tot_loss_proj:2.938 [t=0.29s]
prediction: ['[CLS] this gi snapping - bow - movements exercisemm bow - than shelf / drama long on shelf -ick - crime gimm - connolly exercise pursue [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.091 (perp=9.729, rec=0.146), tot_loss_proj:2.973 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / drama long snapping shelf -ick - crime gimm - connolly exercise pursue [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.039 (perp=9.509, rec=0.137), tot_loss_proj:2.873 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / exercise long snapping shelf -ick - crime gimm - connolly drama pursuing [SEP]']
[ 750/2000] tot_loss=2.037 (perp=9.509, rec=0.135), tot_loss_proj:2.872 [t=0.28s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / exercise long snapping shelf -ick - crime gimm - connolly drama pursuing [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.999 (perp=9.317, rec=0.135), tot_loss_proj:2.826 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercisemm bow - than shelf / exercise long shelf snapping -ick - crime gimm - connolly drama dramas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.952 (perp=9.076, rec=0.137), tot_loss_proj:2.653 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise shelf bow - than shelf ( exercise longmm snapping -ick - crime gimmick connolly drama dramas [SEP]']
[ 900/2000] tot_loss=1.960 (perp=9.141, rec=0.131), tot_loss_proj:2.672 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercise shelf bow - than shelf ( exercise longmm snapping -ick - crime gimmick connolly drama pursuing [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.860 (perp=8.654, rec=0.129), tot_loss_proj:2.583 [t=0.28s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf connolly exercise longmm snapping -ick - crime gimmick / drama pursuing [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.852 (perp=8.600, rec=0.132), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf dramas exercise longmm snapping -ick - crime gimmick / drama connolly [SEP]']
[1050/2000] tot_loss=1.843 (perp=8.562, rec=0.131), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ exercise longmm snapping -ick - crime gimmick / drama connolly [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.821 (perp=8.492, rec=0.122), tot_loss_proj:2.566 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ shoot longmmick - snapping - crime gimmick / drama connolly [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.780 (perp=8.251, rec=0.130), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ shoot longmmick - - snapping crime gimmick / drama connolly [SEP]']
[1200/2000] tot_loss=1.775 (perp=8.251, rec=0.125), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] this gi on - bow - movements exercise, bow - than shelf½ shoot longmmick - - snapping crime gimmick / drama connolly [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.684 (perp=7.787, rec=0.126), tot_loss_proj:2.404 [t=0.27s]
prediction: ['[CLS] this long on - bow - movements exercise, bow - than shelf½ shoot gimmick - - snapping crime gimmick / drama connolly [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.675 (perp=7.714, rec=0.132), tot_loss_proj:2.337 [t=0.27s]
prediction: ['[CLS] this long on - bow - movements exercise, bow - than shelf½ - shoot gimmick - hear crime gimmick / drama connolly [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.673, rec=0.127), tot_loss_proj:2.303 [t=0.26s]
prediction: ['[CLS] this long on - bow - movements exercise, bow - than shelf½ - shoot gimmick - hear crime gimmick / drama villiers [SEP]']
Attempt swap
[1400/2000] tot_loss=1.715 (perp=7.966, rec=0.121), tot_loss_proj:2.378 [t=0.27s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick / drama villiers [SEP]']
Attempt swap
[1450/2000] tot_loss=1.670 (perp=7.762, rec=0.117), tot_loss_proj:2.348 [t=0.26s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
[1500/2000] tot_loss=1.674 (perp=7.762, rec=0.122), tot_loss_proj:2.348 [t=0.27s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.762, rec=0.119), tot_loss_proj:2.350 [t=0.27s]
prediction: ['[CLS] this long on - bow - movements exercise,el - than shelf½ - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.637 (perp=7.551, rec=0.127), tot_loss_proj:2.346 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
[1650/2000] tot_loss=1.633 (perp=7.551, rec=0.123), tot_loss_proj:2.339 [t=0.29s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
[1700/2000] tot_loss=1.633 (perp=7.551, rec=0.123), tot_loss_proj:2.340 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - drama villiers [SEP]']
Attempt swap
[1750/2000] tot_loss=1.662 (perp=7.700, rec=0.122), tot_loss_proj:2.318 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]']
[1800/2000] tot_loss=1.660 (perp=7.700, rec=0.121), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]']
Attempt swap
[1850/2000] tot_loss=1.657 (perp=7.700, rec=0.117), tot_loss_proj:2.322 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.626 (perp=7.522, rec=0.122), tot_loss_proj:2.279 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise, crime - than shelf long - shoot gimmick - hearel gimmick - dramatock [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.522, rec=0.118), tot_loss_proj:2.271 [t=0.27s]
prediction: ['[CLS] this½ on - bow - movements exercise, crime - than shelf long - shoot gimmick - hearel gimmick - dramatock [SEP]']
Attempt swap
[2000/2000] tot_loss=1.627 (perp=7.522, rec=0.122), tot_loss_proj:2.274 [t=0.26s]
prediction: ['[CLS] this½ on - bow - movements exercise, crime - than shelf long - shoot gimmick - hearel gimmick - dramatock [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] this½ on - bow - movements exercise,el - than shelf long - shoot gimmick - hear crime gimmick - dramatock [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.857 | p: 64.706 | r: 61.111
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 41.176 | r: 38.889
rougeLsum  | fm: 40.000 | p: 41.176 | r: 38.889
r1fm+r2fm = 62.857

[Aggregate metrics]:
rouge1     | fm: 76.975 | p: 76.187 | r: 78.209
rouge2     | fm: 41.385 | p: 41.072 | r: 41.887
rougeL     | fm: 68.957 | p: 68.105 | r: 70.083
rougeLsum  | fm: 68.790 | p: 67.931 | r: 70.030
r1fm+r2fm = 118.360

input #45 time: 0:11:11 | total time: 8:23:51


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
cosin similarity: -0.6528367566872437 normalized error: 1.646257550301846
cosin similarity: 0.6528367566872438 normalized error: 0.6467475105930727
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 1.9149640327558815 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 1.724607024064467 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 1.6525990802247175 for ['[CLS] sank including privately heritage surfaced falcon [SEP]']
[Init] best perm rec loss: 1.650647995870167 for ['[CLS] sank falcon heritage surfaced privately including [SEP]']
[Init] best perm rec loss: 1.6445624687431768 for ['[CLS] including privately sank heritage falcon surfaced [SEP]']
[Init] best perm rec loss: 1.6413742130521314 for ['[CLS] including sank heritage falcon privately surfaced [SEP]']
[Init] best perm rec loss: 1.64109145611642 for ['[CLS] including falcon heritage privately sank surfaced [SEP]']
[Init] best perm rec loss: 1.6398843526264715 for ['[CLS] including privately heritage sank falcon surfaced [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.107 (perp=12.187, rec=0.670), tot_loss_proj:3.743 [t=0.26s]
prediction: ['[CLS] striking dudley striking slick burroughs led [SEP]']
[ 100/2000] tot_loss=2.830 (perp=12.324, rec=0.366), tot_loss_proj:3.438 [t=0.26s]
prediction: ['[CLS] striking touching striking slick affair slick [SEP]']
[ 150/2000] tot_loss=2.799 (perp=12.412, rec=0.317), tot_loss_proj:3.449 [t=0.25s]
prediction: ['[CLS] visually touching striking slickhit slick [SEP]']
[ 200/2000] tot_loss=2.777 (perp=12.412, rec=0.295), tot_loss_proj:3.448 [t=0.26s]
prediction: ['[CLS] visually touching striking slickhit slick [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.754 (perp=12.412, rec=0.271), tot_loss_proj:3.447 [t=0.26s]
prediction: ['[CLS] visually touching striking slickhit slick [SEP]']
[ 300/2000] tot_loss=2.757 (perp=12.412, rec=0.275), tot_loss_proj:3.451 [t=0.26s]
prediction: ['[CLS] visually touching striking slickhit slick [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.430 (perp=10.837, rec=0.262), tot_loss_proj:3.117 [t=0.26s]
prediction: ['[CLS] touching visually striking slickcased slick [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.407 (perp=10.837, rec=0.240), tot_loss_proj:3.111 [t=0.26s]
prediction: ['[CLS] touching visually striking slickcased slick [SEP]']
[ 450/2000] tot_loss=2.407 (perp=10.837, rec=0.240), tot_loss_proj:3.132 [t=0.25s]
prediction: ['[CLS] touching visually striking slickcased slick [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.375 (perp=10.691, rec=0.237), tot_loss_proj:3.096 [t=0.28s]
prediction: ['[CLS] touching visually striking slick millie slick [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.344 (perp=10.452, rec=0.253), tot_loss_proj:3.053 [t=0.27s]
prediction: ['[CLS] touching visually striking millie slick slick [SEP]']
[ 600/2000] tot_loss=2.493 (perp=11.313, rec=0.230), tot_loss_proj:3.263 [t=0.26s]
prediction: ['[CLS] touching visually striking housed slick slick [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.511 (perp=11.441, rec=0.222), tot_loss_proj:3.379 [t=0.27s]
prediction: ['[CLS] touching visually striking torment slick slick [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.453 (perp=10.878, rec=0.277), tot_loss_proj:3.157 [t=0.27s]
prediction: ['[CLS] touching visually striking slick slick housed [SEP]']
[ 750/2000] tot_loss=2.250 (perp=10.063, rec=0.237), tot_loss_proj:3.152 [t=0.28s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.237 (perp=10.063, rec=0.225), tot_loss_proj:3.149 [t=0.27s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.236 (perp=10.063, rec=0.224), tot_loss_proj:3.153 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[ 900/2000] tot_loss=2.233 (perp=10.063, rec=0.220), tot_loss_proj:3.145 [t=0.25s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.236 (perp=10.063, rec=0.223), tot_loss_proj:3.146 [t=0.28s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1000/2000] tot_loss=2.243 (perp=10.063, rec=0.231), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1050/2000] tot_loss=2.231 (perp=10.063, rec=0.218), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1100/2000] tot_loss=2.233 (perp=10.063, rec=0.221), tot_loss_proj:3.157 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1150/2000] tot_loss=2.243 (perp=10.063, rec=0.231), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1200/2000] tot_loss=2.228 (perp=10.063, rec=0.215), tot_loss_proj:3.146 [t=0.27s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1250/2000] tot_loss=2.239 (perp=10.063, rec=0.226), tot_loss_proj:3.149 [t=0.28s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1300/2000] tot_loss=2.229 (perp=10.063, rec=0.217), tot_loss_proj:3.146 [t=0.28s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1350/2000] tot_loss=2.233 (perp=10.063, rec=0.220), tot_loss_proj:3.154 [t=0.29s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1400/2000] tot_loss=2.222 (perp=10.063, rec=0.209), tot_loss_proj:3.153 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1450/2000] tot_loss=2.234 (perp=10.063, rec=0.221), tot_loss_proj:3.152 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1500/2000] tot_loss=2.223 (perp=10.063, rec=0.211), tot_loss_proj:3.150 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1550/2000] tot_loss=2.221 (perp=10.063, rec=0.208), tot_loss_proj:3.154 [t=0.28s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1600/2000] tot_loss=2.227 (perp=10.063, rec=0.214), tot_loss_proj:3.155 [t=0.29s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1650/2000] tot_loss=2.228 (perp=10.063, rec=0.215), tot_loss_proj:3.143 [t=0.27s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1700/2000] tot_loss=2.222 (perp=10.063, rec=0.210), tot_loss_proj:3.150 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1750/2000] tot_loss=2.223 (perp=10.063, rec=0.210), tot_loss_proj:3.152 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1800/2000] tot_loss=2.232 (perp=10.063, rec=0.219), tot_loss_proj:3.150 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1850/2000] tot_loss=2.227 (perp=10.063, rec=0.214), tot_loss_proj:3.146 [t=0.25s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[1900/2000] tot_loss=2.225 (perp=10.063, rec=0.213), tot_loss_proj:3.155 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
[1950/2000] tot_loss=2.225 (perp=10.063, rec=0.213), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Attempt swap
[2000/2000] tot_loss=2.222 (perp=10.063, rec=0.210), tot_loss_proj:3.149 [t=0.28s]
prediction: ['[CLS] touching visually striking slick slick torment [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] touching visually striking slick slick torment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 50.000 | r: 57.143
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 53.333 | p: 50.000 | r: 57.143
rougeLsum  | fm: 53.333 | p: 50.000 | r: 57.143
r1fm+r2fm = 68.718

[Aggregate metrics]:
rouge1     | fm: 76.423 | p: 75.557 | r: 77.700
rouge2     | fm: 40.878 | p: 40.522 | r: 41.279
rougeL     | fm: 68.515 | p: 67.685 | r: 69.676
rougeLsum  | fm: 68.352 | p: 67.539 | r: 69.597
r1fm+r2fm = 117.301

input #46 time: 0:11:04 | total time: 8:34:55


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
cosin similarity: -0.878594209824801 normalized error: 1.6392166029226003
cosin similarity: 0.878594209824801 normalized error: 0.552143322537014
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 1.3327846124508835 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 1.3039728765500995 for ['[CLS] bass settlement elder [SEP]']
[Init] best rec loss: 1.2958279178759948 for ['[CLS]zong ruiz its [SEP]']
[Init] best perm rec loss: 1.2917188398867314 for ['[CLS] itszong ruiz [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.988 (perp=12.798, rec=0.429), tot_loss_proj:3.833 [t=0.25s]
prediction: ['[CLS] transparent chargetropical [SEP]']
[ 100/2000] tot_loss=2.853 (perp=12.775, rec=0.298), tot_loss_proj:3.578 [t=0.31s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 150/2000] tot_loss=2.796 (perp=12.775, rec=0.241), tot_loss_proj:3.573 [t=0.30s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 200/2000] tot_loss=2.762 (perp=12.775, rec=0.207), tot_loss_proj:3.567 [t=0.30s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.734 (perp=12.775, rec=0.179), tot_loss_proj:3.565 [t=0.30s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 300/2000] tot_loss=2.731 (perp=12.775, rec=0.175), tot_loss_proj:3.568 [t=0.34s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.705 (perp=12.775, rec=0.150), tot_loss_proj:3.571 [t=0.30s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.693 (perp=12.775, rec=0.138), tot_loss_proj:3.574 [t=0.32s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 450/2000] tot_loss=2.618 (perp=12.355, rec=0.147), tot_loss_proj:3.492 [t=0.29s]
prediction: ['[CLS]らright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.605 (perp=12.355, rec=0.134), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS]らright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.563 (perp=12.153, rec=0.133), tot_loss_proj:3.254 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[ 600/2000] tot_loss=2.569 (perp=12.153, rec=0.139), tot_loss_proj:3.255 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.560 (perp=12.153, rec=0.130), tot_loss_proj:3.254 [t=0.31s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.561 (perp=12.153, rec=0.130), tot_loss_proj:3.258 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[ 750/2000] tot_loss=2.547 (perp=12.153, rec=0.116), tot_loss_proj:3.259 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.549 (perp=12.153, rec=0.118), tot_loss_proj:3.263 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.557 (perp=12.153, rec=0.126), tot_loss_proj:3.260 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[ 900/2000] tot_loss=2.560 (perp=12.153, rec=0.129), tot_loss_proj:3.264 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.552 (perp=12.153, rec=0.122), tot_loss_proj:3.264 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=2.555 (perp=12.153, rec=0.125), tot_loss_proj:3.263 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1050/2000] tot_loss=2.556 (perp=12.153, rec=0.126), tot_loss_proj:3.257 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.554 (perp=12.153, rec=0.123), tot_loss_proj:3.252 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.552 (perp=12.153, rec=0.121), tot_loss_proj:3.268 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1200/2000] tot_loss=2.552 (perp=12.153, rec=0.122), tot_loss_proj:3.263 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.553 (perp=12.153, rec=0.123), tot_loss_proj:3.257 [t=0.32s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.557 (perp=12.153, rec=0.126), tot_loss_proj:3.259 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1350/2000] tot_loss=2.537 (perp=12.153, rec=0.107), tot_loss_proj:3.260 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.543 (perp=12.153, rec=0.112), tot_loss_proj:3.263 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.550 (perp=12.153, rec=0.120), tot_loss_proj:3.260 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1500/2000] tot_loss=2.547 (perp=12.153, rec=0.117), tot_loss_proj:3.259 [t=0.31s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.550 (perp=12.153, rec=0.120), tot_loss_proj:3.256 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.547 (perp=12.153, rec=0.116), tot_loss_proj:3.261 [t=0.31s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1650/2000] tot_loss=2.546 (perp=12.153, rec=0.115), tot_loss_proj:3.262 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.554 (perp=12.153, rec=0.124), tot_loss_proj:3.264 [t=0.30s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=2.546 (perp=12.153, rec=0.116), tot_loss_proj:3.262 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1800/2000] tot_loss=2.551 (perp=12.153, rec=0.120), tot_loss_proj:3.264 [t=0.29s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.546 (perp=12.153, rec=0.116), tot_loss_proj:3.252 [t=0.31s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.554 (perp=12.153, rec=0.124), tot_loss_proj:3.259 [t=0.28s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
[1950/2000] tot_loss=2.551 (perp=12.153, rec=0.121), tot_loss_proj:3.261 [t=0.31s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=2.544 (perp=12.153, rec=0.113), tot_loss_proj:3.257 [t=0.31s]
prediction: ['[CLS] cunninghamright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] cunninghamright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 76.498 | p: 75.557 | r: 77.543
rouge2     | fm: 40.546 | p: 40.182 | r: 41.014
rougeL     | fm: 68.659 | p: 67.783 | r: 69.897
rougeLsum  | fm: 68.677 | p: 67.715 | r: 69.737
r1fm+r2fm = 117.044

input #47 time: 0:12:09 | total time: 8:47:05


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
cosin similarity: -0.6309706475604857 normalized error: 1.5825054937679657
cosin similarity: 0.6309706475604856 normalized error: 0.6756827814320959
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 1.7275167503123132 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 1.6511109935266564 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 1.491983435235669 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 1.4434253783882733 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 1.4429830256937493 for ['[CLS]tute runsdine graveyard [SEP]']
[Init] best perm rec loss: 1.4427131050402626 for ['[CLS] graveyarddinetute runs [SEP]']
[Init] best perm rec loss: 1.441733619298189 for ['[CLS]tute graveyarddine runs [SEP]']
[Init] best perm rec loss: 1.4398020150198119 for ['[CLS]dinetute runs graveyard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.153 (perp=13.509, rec=0.451), tot_loss_proj:3.763 [t=0.32s]
prediction: ['[CLS] rotting shut cas rotting [SEP]']
[ 100/2000] tot_loss=3.200 (perp=14.292, rec=0.342), tot_loss_proj:3.853 [t=0.30s]
prediction: ['[CLS] rotting under butt rotting [SEP]']
[ 150/2000] tot_loss=2.808 (perp=12.725, rec=0.263), tot_loss_proj:3.556 [t=0.30s]
prediction: ['[CLS] rotting under helmetᅥ [SEP]']
[ 200/2000] tot_loss=2.435 (perp=10.992, rec=0.237), tot_loss_proj:3.035 [t=0.29s]
prediction: ['[CLS] rotting underbelliring [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.433 (perp=10.992, rec=0.235), tot_loss_proj:3.037 [t=0.31s]
prediction: ['[CLS] rotting underbelliring [SEP]']
[ 300/2000] tot_loss=2.400 (perp=10.992, rec=0.201), tot_loss_proj:3.036 [t=0.29s]
prediction: ['[CLS] rotting underbelliring [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.405 (perp=10.992, rec=0.207), tot_loss_proj:3.030 [t=0.30s]
prediction: ['[CLS] rotting underbelliring [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.393 (perp=10.992, rec=0.195), tot_loss_proj:3.045 [t=0.32s]
prediction: ['[CLS] rotting underbelliring [SEP]']
[ 450/2000] tot_loss=2.384 (perp=10.992, rec=0.185), tot_loss_proj:3.020 [t=0.30s]
prediction: ['[CLS] rotting underbelliring [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.369 (perp=10.992, rec=0.171), tot_loss_proj:3.043 [t=0.30s]
prediction: ['[CLS] rotting underbelliring [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.374 (perp=10.992, rec=0.175), tot_loss_proj:3.029 [t=0.31s]
prediction: ['[CLS] rotting underbelliring [SEP]']
[ 600/2000] tot_loss=2.419 (perp=11.202, rec=0.178), tot_loss_proj:3.158 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.413 (perp=11.202, rec=0.172), tot_loss_proj:3.173 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.422 (perp=11.202, rec=0.181), tot_loss_proj:3.166 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[ 750/2000] tot_loss=2.413 (perp=11.202, rec=0.173), tot_loss_proj:3.164 [t=0.29s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.406 (perp=11.202, rec=0.165), tot_loss_proj:3.175 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.418 (perp=11.202, rec=0.178), tot_loss_proj:3.164 [t=0.31s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[ 900/2000] tot_loss=2.405 (perp=11.202, rec=0.165), tot_loss_proj:3.160 [t=0.29s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.406 (perp=11.202, rec=0.165), tot_loss_proj:3.170 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1000/2000] tot_loss=2.407 (perp=11.202, rec=0.167), tot_loss_proj:3.174 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1050/2000] tot_loss=2.402 (perp=11.202, rec=0.162), tot_loss_proj:3.175 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1100/2000] tot_loss=2.415 (perp=11.202, rec=0.174), tot_loss_proj:3.168 [t=0.30s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1150/2000] tot_loss=2.404 (perp=11.202, rec=0.164), tot_loss_proj:3.171 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1200/2000] tot_loss=2.403 (perp=11.202, rec=0.163), tot_loss_proj:3.174 [t=0.27s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1250/2000] tot_loss=2.417 (perp=11.202, rec=0.177), tot_loss_proj:3.167 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1300/2000] tot_loss=2.403 (perp=11.202, rec=0.163), tot_loss_proj:3.171 [t=0.27s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1350/2000] tot_loss=2.398 (perp=11.202, rec=0.157), tot_loss_proj:3.168 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1400/2000] tot_loss=2.406 (perp=11.202, rec=0.166), tot_loss_proj:3.165 [t=0.25s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1450/2000] tot_loss=2.409 (perp=11.202, rec=0.169), tot_loss_proj:3.176 [t=0.27s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1500/2000] tot_loss=2.403 (perp=11.202, rec=0.163), tot_loss_proj:3.173 [t=0.29s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1550/2000] tot_loss=2.404 (perp=11.202, rec=0.164), tot_loss_proj:3.166 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1600/2000] tot_loss=2.407 (perp=11.202, rec=0.167), tot_loss_proj:3.170 [t=0.27s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1650/2000] tot_loss=2.415 (perp=11.202, rec=0.175), tot_loss_proj:3.164 [t=0.27s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1700/2000] tot_loss=2.401 (perp=11.202, rec=0.161), tot_loss_proj:3.169 [t=0.27s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1750/2000] tot_loss=2.417 (perp=11.202, rec=0.177), tot_loss_proj:3.169 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1800/2000] tot_loss=2.397 (perp=11.202, rec=0.156), tot_loss_proj:3.158 [t=0.29s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1850/2000] tot_loss=2.413 (perp=11.202, rec=0.173), tot_loss_proj:3.174 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[1900/2000] tot_loss=2.418 (perp=11.202, rec=0.178), tot_loss_proj:3.165 [t=0.25s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
[1950/2000] tot_loss=2.422 (perp=11.202, rec=0.181), tot_loss_proj:3.163 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Attempt swap
[2000/2000] tot_loss=2.398 (perp=11.202, rec=0.158), tot_loss_proj:3.170 [t=0.26s]
prediction: ['[CLS] rotting underbell beginnings [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbell beginnings [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 76.191 | p: 75.269 | r: 77.550
rouge2     | fm: 40.520 | p: 40.104 | r: 41.048
rougeL     | fm: 68.547 | p: 67.595 | r: 69.869
rougeLsum  | fm: 68.474 | p: 67.482 | r: 69.851
r1fm+r2fm = 116.711

input #48 time: 0:11:48 | total time: 8:58:54


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
cosin similarity: 0.9683217036303956 normalized error: 0.4534142344774211
cosin similarity: -0.9683217036303957 normalized error: 1.7818465609311582
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 1.4778312589764235 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 1.4136233842593589 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 1.3607508643839044 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 1.297533454500428 for ['[CLS] chair assured dick fine chance household every expect boat couple freestyleerly [SEP]']
[Init] best perm rec loss: 1.2957378183063728 for ['[CLS] fine assured chair every freestyle dick boat couple chanceerly expect household [SEP]']
[Init] best perm rec loss: 1.2940180804195136 for ['[CLS] couple expect dick boat fine assured household chairerly chance every freestyle [SEP]']
[Init] best perm rec loss: 1.2878868872315852 for ['[CLS] expect household couple boat dickerly assured fine chair every freestyle chance [SEP]']
[Init] best perm rec loss: 1.2867992763169107 for ['[CLS] boat household chair dick couple fine chance freestyleerly expect every assured [SEP]']
[Init] best perm rec loss: 1.2865862604053442 for ['[CLS] chance every couple dick expect boaterly household freestyle chair assured fine [SEP]']
[Init] best perm rec loss: 1.2860970655053672 for ['[CLS] assured couple dick expecterly every household freestyle chair chance fine boat [SEP]']
[Init] best perm rec loss: 1.285564383519302 for ['[CLS] dick chance freestyle everyerly couple boat household fine expect chair assured [SEP]']
[Init] best perm rec loss: 1.2848470383984811 for ['[CLS] fine chair household assured boat expect every freestyleerly chance dick couple [SEP]']
[Init] best perm rec loss: 1.2833863283344924 for ['[CLS] chair dick household assured chance every boat freestyleerly expect fine couple [SEP]']
[Init] best perm rec loss: 1.278603297321006 for ['[CLS] chair assured freestyle boat expecterly every household couple dick fine chance [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.814 (perp=12.076, rec=0.398), tot_loss_proj:3.451 [t=0.27s]
prediction: ['[CLS] should clarksonold knew than blacks females be reduced suspect single care [SEP]']
[ 100/2000] tot_loss=2.589 (perp=11.443, rec=0.300), tot_loss_proj:3.345 [t=0.26s]
prediction: ['[CLS] could femaleold less contemptgging female be species be single instance [SEP]']
[ 150/2000] tot_loss=2.538 (perp=11.437, rec=0.250), tot_loss_proj:3.232 [t=0.26s]
prediction: ['[CLS] could female fitzgerald more contemptuous female be species be single contempt [SEP]']
[ 200/2000] tot_loss=2.480 (perp=11.293, rec=0.221), tot_loss_proj:3.158 [t=0.25s]
prediction: ['[CLS] could population fitzgerald more contemptuous female be least be single contempt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.155 (perp=9.911, rec=0.173), tot_loss_proj:3.010 [t=0.27s]
prediction: ['[CLS] possibly population. more contemptuous single female least be single contempt [SEP]']
[ 300/2000] tot_loss=2.225 (perp=10.351, rec=0.154), tot_loss_proj:3.118 [t=0.27s]
prediction: ['[CLS] possibly population. more contemptuous single female mira be single contempt [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.134 (perp=9.904, rec=0.154), tot_loss_proj:2.962 [t=0.25s]
prediction: ['[CLS] possiblyive. more contemptuous single female daughter be single population [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.040 (perp=9.445, rec=0.151), tot_loss_proj:2.804 [t=0.27s]
prediction: ['[CLS] possiblyive be. more contemptuous single female newly single population [SEP]']
[ 450/2000] tot_loss=2.011 (perp=9.329, rec=0.146), tot_loss_proj:2.851 [t=0.26s]
prediction: ['[CLS] possibly contempt be. more contemptuous single female newly single population [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.929 (perp=8.968, rec=0.136), tot_loss_proj:2.817 [t=0.26s]
prediction: ['[CLS] possibly be be. more contemptuous single female newly single population [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.886 (perp=8.722, rec=0.142), tot_loss_proj:2.612 [t=0.27s]
prediction: ['[CLS] possibly be be more contemptuous. single female newly disappearance population [SEP]']
[ 600/2000] tot_loss=1.878 (perp=8.713, rec=0.135), tot_loss_proj:2.637 [t=0.26s]
prediction: ['[CLS] possibly be be more contemptuous. single female daughter disappearance population [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.872 (perp=8.713, rec=0.130), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] possibly be be more contemptuous. single female daughter disappearance population [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.849 (perp=8.584, rec=0.132), tot_loss_proj:2.699 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughter disappearance population [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.402, rec=0.116), tot_loss_proj:2.547 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.802 (perp=8.402, rec=0.121), tot_loss_proj:2.545 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.804 (perp=8.402, rec=0.123), tot_loss_proj:2.550 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[ 900/2000] tot_loss=1.803 (perp=8.402, rec=0.122), tot_loss_proj:2.547 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.786 (perp=8.402, rec=0.106), tot_loss_proj:2.546 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.792 (perp=8.402, rec=0.111), tot_loss_proj:2.545 [t=0.31s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1050/2000] tot_loss=1.795 (perp=8.402, rec=0.114), tot_loss_proj:2.543 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.402, rec=0.113), tot_loss_proj:2.549 [t=0.28s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.790 (perp=8.402, rec=0.109), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1200/2000] tot_loss=1.792 (perp=8.402, rec=0.112), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.791 (perp=8.402, rec=0.110), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1300/2000] tot_loss=1.791 (perp=8.402, rec=0.111), tot_loss_proj:2.549 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1350/2000] tot_loss=1.788 (perp=8.402, rec=0.107), tot_loss_proj:2.551 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.789 (perp=8.402, rec=0.109), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.794 (perp=8.402, rec=0.114), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.402, rec=0.114), tot_loss_proj:2.549 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female daughterworm population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.872 (perp=8.772, rec=0.118), tot_loss_proj:2.607 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. single female newlyworm population [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.756 (perp=8.249, rec=0.106), tot_loss_proj:2.506 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
[1650/2000] tot_loss=1.762 (perp=8.249, rec=0.112), tot_loss_proj:2.509 [t=0.25s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.757 (perp=8.249, rec=0.107), tot_loss_proj:2.510 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.767 (perp=8.249, rec=0.117), tot_loss_proj:2.502 [t=0.27s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
[1800/2000] tot_loss=1.757 (perp=8.249, rec=0.108), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=8.249, rec=0.109), tot_loss_proj:2.505 [t=0.30s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=8.249, rec=0.110), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.249, rec=0.121), tot_loss_proj:2.508 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.755 (perp=8.249, rec=0.105), tot_loss_proj:2.508 [t=0.26s]
prediction: ['[CLS] be possibly be more contemptuous. newly single femaleworm population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] be possibly be more contemptuous. single female newlyworm population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 81.818 | r: 75.000
rouge2     | fm: 47.619 | p: 50.000 | r: 45.455
rougeL     | fm: 78.261 | p: 81.818 | r: 75.000
rougeLsum  | fm: 78.261 | p: 81.818 | r: 75.000
r1fm+r2fm = 125.880

[Aggregate metrics]:
rouge1     | fm: 76.208 | p: 75.301 | r: 77.484
rouge2     | fm: 40.542 | p: 40.131 | r: 40.987
rougeL     | fm: 68.723 | p: 67.888 | r: 69.976
rougeLsum  | fm: 68.674 | p: 67.800 | r: 69.913
r1fm+r2fm = 116.750

input #49 time: 0:11:03 | total time: 9:09:57


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
cosin similarity: 0.9451105335183868 normalized error: 0.508965433353086
cosin similarity: -0.9451105335183869 normalized error: 1.6843753468373812
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 1.7447391229628995 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 1.5633844270276005 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 1.5250435738473378 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 1.4189065270930936 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best perm rec loss: 1.4185997024513828 for ['[CLS] associated fueled trustok rama sq napkin gall unit [SEP]']
[Init] best perm rec loss: 1.412301089326974 for ['[CLS]ok gall napkin associated fueled sq trust unit rama [SEP]']
[Init] best perm rec loss: 1.4095784306625545 for ['[CLS] gall sq napkin trust fueled unit ramaok associated [SEP]']
[Init] best perm rec loss: 1.4041040650997367 for ['[CLS] napkinok trust unit gall fueled rama sq associated [SEP]']
[Init] best perm rec loss: 1.4040456915436497 for ['[CLS] trustok fueled napkin gall sq unit rama associated [SEP]']
[Init] best perm rec loss: 1.4037055539535581 for ['[CLS] associated sq trust napkinok unit rama gall fueled [SEP]']
[Init] best perm rec loss: 1.4017938043464744 for ['[CLS] napkin trust sq gallok associated unit rama fueled [SEP]']
[Init] best perm rec loss: 1.3994468356968173 for ['[CLS] associated trust unit gall fueled napkinok sq rama [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.035 (perp=12.753, rec=0.484), tot_loss_proj:4.249 [t=0.26s]
prediction: ['[CLS] ` disdain palmer = beside among marie wonderful stupid [SEP]']
[ 100/2000] tot_loss=3.053 (perp=13.233, rec=0.407), tot_loss_proj:4.076 [t=0.26s]
prediction: ['[CLS] ` as upper twice switch merely isabelle clever confused [SEP]']
[ 150/2000] tot_loss=3.166 (perp=13.961, rec=0.374), tot_loss_proj:4.027 [t=0.26s]
prediction: ['[CLS] ` as upper byeer already remy clever voluntary [SEP]']
[ 200/2000] tot_loss=2.590 (perp=11.385, rec=0.313), tot_loss_proj:3.379 [t=0.26s]
prediction: ['[CLS] ` as english byieg almost remy clever half [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.388 (perp=10.497, rec=0.288), tot_loss_proj:3.245 [t=0.25s]
prediction: ['[CLS] ` asˈ by english almost andre clever half [SEP]']
[ 300/2000] tot_loss=2.734 (perp=12.226, rec=0.289), tot_loss_proj:3.591 [t=0.27s]
prediction: ['[CLS] ` (asurable by english almost andre clever half [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.152 (perp=9.424, rec=0.267), tot_loss_proj:2.954 [t=0.30s]
prediction: ['[CLS] ` call by clever what by english almost half [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.997 (perp=8.774, rec=0.242), tot_loss_proj:3.293 [t=0.26s]
prediction: ['[CLS] ` what by clever call by english almost half [SEP]']
[ 450/2000] tot_loss=1.970 (perp=8.774, rec=0.215), tot_loss_proj:3.295 [t=0.28s]
prediction: ['[CLS] ` what by clever call by english almost half [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.898 (perp=8.414, rec=0.215), tot_loss_proj:3.192 [t=0.28s]
prediction: ['[CLS] ` by what clever call by english almost half [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.860 (perp=8.414, rec=0.177), tot_loss_proj:3.195 [t=0.26s]
prediction: ['[CLS] ` by what clever call by english almost half [SEP]']
[ 600/2000] tot_loss=1.844 (perp=8.414, rec=0.161), tot_loss_proj:3.197 [t=0.27s]
prediction: ['[CLS] ` by what clever call by english almost half [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.967 (perp=9.061, rec=0.155), tot_loss_proj:3.240 [t=0.26s]
prediction: ['[CLS] ` by what clever call by english do half [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.057 (perp=9.524, rec=0.152), tot_loss_proj:3.290 [t=0.28s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[ 750/2000] tot_loss=2.030 (perp=9.524, rec=0.125), tot_loss_proj:3.282 [t=0.27s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.022 (perp=9.524, rec=0.117), tot_loss_proj:3.282 [t=0.27s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.014 (perp=9.524, rec=0.109), tot_loss_proj:3.285 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[ 900/2000] tot_loss=2.014 (perp=9.524, rec=0.110), tot_loss_proj:3.279 [t=0.26s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.010 (perp=9.524, rec=0.105), tot_loss_proj:3.282 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1000/2000] tot_loss=2.008 (perp=9.524, rec=0.103), tot_loss_proj:3.285 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1050/2000] tot_loss=2.010 (perp=9.524, rec=0.105), tot_loss_proj:3.279 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1100/2000] tot_loss=2.002 (perp=9.524, rec=0.097), tot_loss_proj:3.282 [t=0.31s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1150/2000] tot_loss=2.000 (perp=9.524, rec=0.095), tot_loss_proj:3.281 [t=0.32s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1200/2000] tot_loss=2.009 (perp=9.524, rec=0.104), tot_loss_proj:3.281 [t=0.29s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1250/2000] tot_loss=2.000 (perp=9.524, rec=0.095), tot_loss_proj:3.275 [t=0.31s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1300/2000] tot_loss=2.000 (perp=9.524, rec=0.096), tot_loss_proj:3.281 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1350/2000] tot_loss=2.002 (perp=9.524, rec=0.097), tot_loss_proj:3.277 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1400/2000] tot_loss=2.001 (perp=9.524, rec=0.096), tot_loss_proj:3.283 [t=0.32s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1450/2000] tot_loss=2.001 (perp=9.524, rec=0.096), tot_loss_proj:3.279 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1500/2000] tot_loss=1.994 (perp=9.524, rec=0.090), tot_loss_proj:3.281 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.983 (perp=9.524, rec=0.078), tot_loss_proj:3.283 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.998 (perp=9.524, rec=0.094), tot_loss_proj:3.275 [t=0.33s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1650/2000] tot_loss=2.000 (perp=9.524, rec=0.095), tot_loss_proj:3.277 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.991 (perp=9.524, rec=0.087), tot_loss_proj:3.277 [t=0.31s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.991 (perp=9.524, rec=0.086), tot_loss_proj:3.280 [t=0.29s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1800/2000] tot_loss=1.990 (perp=9.524, rec=0.085), tot_loss_proj:3.273 [t=0.29s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.991 (perp=9.524, rec=0.086), tot_loss_proj:3.280 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.998 (perp=9.524, rec=0.094), tot_loss_proj:3.282 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
[1950/2000] tot_loss=1.993 (perp=9.524, rec=0.088), tot_loss_proj:3.278 [t=0.30s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=9.524, rec=0.086), tot_loss_proj:3.279 [t=0.32s]
prediction: ['[CLS] too ` what clever call by english do half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] too ` what clever call by english do half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 101.111

[Aggregate metrics]:
rouge1     | fm: 76.454 | p: 75.557 | r: 77.708
rouge2     | fm: 39.882 | p: 39.481 | r: 40.387
rougeL     | fm: 68.603 | p: 67.784 | r: 69.759
rougeLsum  | fm: 68.543 | p: 67.651 | r: 69.721
r1fm+r2fm = 116.336

input #50 time: 0:11:39 | total time: 9:21:36


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
cosin similarity: -0.9214147204321703 normalized error: 1.6234518397518047
cosin similarity: 0.9214147204321702 normalized error: 0.5471154596691675
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 1.6132520794545706 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 1.3670916137976665 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 1.3646106984125925 for ['[CLS] openmes sections shakespeare power? host cuba bonn depends [SEP]']
[Init] best rec loss: 1.3611530242162084 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 1.338883572473704 for ['[CLS] nationals offense - vaguely world justine domesticished majorage [SEP]']
[Init] best rec loss: 1.3212501357510134 for ['[CLS] termination musical guardaur chief electric oxford compilationrch sensor [SEP]']
[Init] best rec loss: 1.3056688377467667 for ['[CLS] political breadction sydney less nothin rican roll color classified [SEP]']
[Init] best rec loss: 1.3029854955057565 for ['[CLS]! marathi cot a wipe ski seniorstered studiolizer [SEP]']
[Init] best rec loss: 1.2765522592121463 for ['[CLS] of deal formula without replace demonstration green driver practice edition [SEP]']
[Init] best rec loss: 1.252414587965134 for ['[CLS] include plants hole abuse especially multiple fingers & since accepting [SEP]']
[Init] best perm rec loss: 1.2465105555631277 for ['[CLS] accepting hole multiple since abuse especially plants & include fingers [SEP]']
[Init] best perm rec loss: 1.246167531158738 for ['[CLS] multiple hole accepting & especially since fingers abuse plants include [SEP]']
[Init] best perm rec loss: 1.2458765469618287 for ['[CLS] since & hole plants especially abuse multiple include fingers accepting [SEP]']
[Init] best perm rec loss: 1.2451012068796579 for ['[CLS] since plants especially abuse & hole multiple fingers include accepting [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.585 (perp=12.701, rec=1.044), tot_loss_proj:4.225 [t=0.30s]
prediction: ['[CLS] luke praise finally combination nascar gable healing. stood... [SEP]']
[ 100/2000] tot_loss=3.202 (perp=11.875, rec=0.827), tot_loss_proj:3.903 [t=0.30s]
prediction: ['[CLS] matter commentary arguably feel zombie augustus wisdom. stood good [SEP]']
[ 150/2000] tot_loss=3.102 (perp=11.894, rec=0.724), tot_loss_proj:4.075 [t=0.30s]
prediction: ['[CLS] written say arguably points zombie gram wisdom. stood brave [SEP]']
[ 200/2000] tot_loss=3.288 (perp=13.077, rec=0.673), tot_loss_proj:4.118 [t=0.32s]
prediction: ['[CLS] funny initial albeit points unless gram wisdom. considered brave [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.794 (perp=10.536, rec=0.686), tot_loss_proj:3.919 [t=0.30s]
prediction: ['[CLS] funny a gram ) boom zombie wisdom. considered brave [SEP]']
[ 300/2000] tot_loss=2.816 (perp=10.732, rec=0.670), tot_loss_proj:4.041 [t=0.31s]
prediction: ['[CLS] funny a funny in points zombie wisdom. considered brave [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.944 (perp=11.525, rec=0.639), tot_loss_proj:3.384 [t=0.30s]
prediction: ['[CLS] funny a sucks zombie ) points wisdom. review sucks [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.956 (perp=11.377, rec=0.681), tot_loss_proj:3.490 [t=0.31s]
prediction: ['[CLS] funny reaction sucks unless ) points review good wisdom. [SEP]']
[ 450/2000] tot_loss=2.761 (perp=9.990, rec=0.763), tot_loss_proj:3.656 [t=0.32s]
prediction: ['[CLS] great reaction sucks apocalypse scorer reviews review brave wisdom. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.809 (perp=9.981, rec=0.813), tot_loss_proj:3.594 [t=0.29s]
prediction: ['[CLS] great reaction sucks ) points review apocalypse good wisdom, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.712 (perp=10.203, rec=0.671), tot_loss_proj:3.181 [t=0.30s]
prediction: ['[CLS] great reaction sucks multi knowledge review unless good points. [SEP]']
[ 600/2000] tot_loss=2.614 (perp=9.632, rec=0.687), tot_loss_proj:3.006 [t=0.29s]
prediction: ['[CLS] great reaction sucks. wisdom review unless good boom. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.869 (perp=10.489, rec=0.771), tot_loss_proj:3.486 [t=0.30s]
prediction: ['[CLS] great reaction sucks fledged sucks review unless knowledge points. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.312 (perp=8.505, rec=0.611), tot_loss_proj:3.018 [t=0.29s]
prediction: ['[CLS] great reaction sucks. unless review sucks knowledge points. [SEP]']
[ 750/2000] tot_loss=2.510 (perp=9.283, rec=0.653), tot_loss_proj:3.034 [t=0.29s]
prediction: ['[CLS] great reaction sucks. unless review good knowledge boom. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.802 (perp=9.223, rec=0.957), tot_loss_proj:3.306 [t=0.30s]
prediction: ['[CLS] eminent reaction sucks. sucks review unless knowledge points. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.516 (perp=9.417, rec=0.633), tot_loss_proj:3.286 [t=0.32s]
prediction: ['[CLS] eminent reaction sucks. sucks unless got knowledge boom. [SEP]']
[ 900/2000] tot_loss=2.774 (perp=9.596, rec=0.855), tot_loss_proj:3.353 [t=0.32s]
prediction: ['[CLS] eminent reaction sucks. sucks unless yeah knowledge points. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.494 (perp=9.325, rec=0.629), tot_loss_proj:3.063 [t=0.29s]
prediction: ['[CLS] funny reaction sucks. sucks unless got wisdom points. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.792 (perp=9.333, rec=0.925), tot_loss_proj:3.269 [t=0.29s]
prediction: ['[CLS] eminent reaction sucks. sucks unless got likes points. [SEP]']
[1050/2000] tot_loss=2.528 (perp=9.486, rec=0.631), tot_loss_proj:3.099 [t=0.30s]
prediction: ['[CLS] funny reaction sucks. sucks unless got knowledge points. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.329 (perp=8.739, rec=0.581), tot_loss_proj:2.744 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got knowledge points. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.448 (perp=9.211, rec=0.606), tot_loss_proj:2.815 [t=0.30s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1200/2000] tot_loss=2.353 (perp=9.211, rec=0.511), tot_loss_proj:2.814 [t=0.30s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.398 (perp=9.211, rec=0.555), tot_loss_proj:2.814 [t=0.30s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.375 (perp=9.211, rec=0.533), tot_loss_proj:2.815 [t=0.31s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1350/2000] tot_loss=2.362 (perp=9.211, rec=0.520), tot_loss_proj:2.812 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.347 (perp=9.211, rec=0.505), tot_loss_proj:2.817 [t=0.31s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.335 (perp=9.211, rec=0.493), tot_loss_proj:2.816 [t=0.30s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1500/2000] tot_loss=2.333 (perp=9.211, rec=0.491), tot_loss_proj:2.809 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.331 (perp=9.211, rec=0.489), tot_loss_proj:2.812 [t=0.30s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.331 (perp=9.211, rec=0.489), tot_loss_proj:2.812 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1650/2000] tot_loss=2.329 (perp=9.211, rec=0.486), tot_loss_proj:2.810 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.327 (perp=9.211, rec=0.485), tot_loss_proj:2.812 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.323 (perp=9.211, rec=0.481), tot_loss_proj:2.808 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1800/2000] tot_loss=2.324 (perp=9.211, rec=0.482), tot_loss_proj:2.808 [t=0.31s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.325 (perp=9.211, rec=0.483), tot_loss_proj:2.816 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.319 (perp=9.211, rec=0.477), tot_loss_proj:2.817 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
[1950/2000] tot_loss=2.322 (perp=9.211, rec=0.480), tot_loss_proj:2.813 [t=0.29s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.320 (perp=9.211, rec=0.478), tot_loss_proj:2.818 [t=0.31s]
prediction: ['[CLS] reaction funny sucks. sucks unless got likes points. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] reaction funny sucks. sucks unless got likes points. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 40.000 | r: 40.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.000 | p: 30.000 | r: 30.000
rougeLsum  | fm: 30.000 | p: 30.000 | r: 30.000
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 75.891 | p: 74.979 | r: 77.150
rouge2     | fm: 39.008 | p: 38.630 | r: 39.426
rougeL     | fm: 67.876 | p: 67.096 | r: 68.972
rougeLsum  | fm: 67.808 | p: 66.927 | r: 69.011
r1fm+r2fm = 114.900

input #51 time: 0:12:03 | total time: 9:33:39


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
cosin similarity: -0.913830416657226 normalized error: 1.7702200963928998
cosin similarity: 0.9138304166572259 normalized error: 0.47924693221818315
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 1.8918972745288198 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 1.7367219556579863 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 1.6020888656688619 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 1.5186443878427849 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 1.4754864182597114 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 1.021767545651363 for ['[CLS] token ghetto tree [SEP]']
[Init] best perm rec loss: 1.0208957600591795 for ['[CLS] tree ghetto token [SEP]']
[Init] best perm rec loss: 1.0200359378925175 for ['[CLS] token tree ghetto [SEP]']
[Init] best perm rec loss: 1.01193992970521 for ['[CLS] tree token ghetto [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.673 (perp=11.737, rec=0.326), tot_loss_proj:2.837 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.564 (perp=11.737, rec=0.217), tot_loss_proj:2.846 [t=0.29s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.507 (perp=11.737, rec=0.159), tot_loss_proj:2.848 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 200/2000] tot_loss=2.495 (perp=11.737, rec=0.147), tot_loss_proj:2.846 [t=0.32s]
prediction: ['[CLS] trailer trash trash [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.295 (perp=10.789, rec=0.137), tot_loss_proj:2.783 [t=0.31s]
prediction: ['[CLS] trash trailer trash [SEP]']
[ 300/2000] tot_loss=2.281 (perp=10.789, rec=0.123), tot_loss_proj:2.787 [t=0.30s]
prediction: ['[CLS] trash trailer trash [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.358 (perp=11.127, rec=0.133), tot_loss_proj:2.920 [t=0.29s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.357 (perp=11.127, rec=0.132), tot_loss_proj:2.911 [t=0.29s]
prediction: ['[CLS]frey trailer trash [SEP]']
[ 450/2000] tot_loss=2.355 (perp=11.127, rec=0.130), tot_loss_proj:2.911 [t=0.29s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.339 (perp=11.127, rec=0.114), tot_loss_proj:2.915 [t=0.29s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.342 (perp=11.127, rec=0.116), tot_loss_proj:2.910 [t=0.31s]
prediction: ['[CLS]frey trailer trash [SEP]']
[ 600/2000] tot_loss=2.330 (perp=11.127, rec=0.104), tot_loss_proj:2.913 [t=0.30s]
prediction: ['[CLS]frey trailer trash [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.360 (perp=11.184, rec=0.124), tot_loss_proj:2.857 [t=0.29s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.342 (perp=11.184, rec=0.106), tot_loss_proj:2.846 [t=0.32s]
prediction: ['[CLS]nagar trailer trash [SEP]']
[ 750/2000] tot_loss=2.355 (perp=11.184, rec=0.119), tot_loss_proj:2.854 [t=0.29s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.351 (perp=11.184, rec=0.115), tot_loss_proj:2.849 [t=0.30s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.357 (perp=11.184, rec=0.120), tot_loss_proj:2.846 [t=0.30s]
prediction: ['[CLS]nagar trailer trash [SEP]']
[ 900/2000] tot_loss=2.359 (perp=11.184, rec=0.122), tot_loss_proj:2.850 [t=0.30s]
prediction: ['[CLS]nagar trailer trash [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.233 (perp=10.609, rec=0.111), tot_loss_proj:2.571 [t=0.30s]
prediction: ['[CLS] - trailer trash [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.462 (perp=11.688, rec=0.125), tot_loss_proj:2.985 [t=0.31s]
prediction: ['[CLS] trash trailernagar [SEP]']
[1050/2000] tot_loss=2.459 (perp=11.688, rec=0.121), tot_loss_proj:2.991 [t=0.32s]
prediction: ['[CLS] trash trailernagar [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.321 (perp=10.986, rec=0.124), tot_loss_proj:2.912 [t=0.33s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1150/2000] tot_loss=2.322 (perp=10.986, rec=0.125), tot_loss_proj:2.917 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1200/2000] tot_loss=2.313 (perp=10.986, rec=0.116), tot_loss_proj:2.915 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1250/2000] tot_loss=2.300 (perp=10.986, rec=0.103), tot_loss_proj:2.911 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1300/2000] tot_loss=2.326 (perp=10.986, rec=0.128), tot_loss_proj:2.915 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1350/2000] tot_loss=2.321 (perp=10.986, rec=0.123), tot_loss_proj:2.916 [t=0.29s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1400/2000] tot_loss=2.310 (perp=10.986, rec=0.113), tot_loss_proj:2.916 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1450/2000] tot_loss=2.310 (perp=10.986, rec=0.113), tot_loss_proj:2.912 [t=0.31s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1500/2000] tot_loss=2.319 (perp=10.986, rec=0.122), tot_loss_proj:2.910 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1550/2000] tot_loss=2.315 (perp=10.986, rec=0.117), tot_loss_proj:2.920 [t=0.29s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1600/2000] tot_loss=2.309 (perp=10.986, rec=0.112), tot_loss_proj:2.909 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1650/2000] tot_loss=2.318 (perp=10.986, rec=0.121), tot_loss_proj:2.911 [t=0.29s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1700/2000] tot_loss=2.317 (perp=10.986, rec=0.120), tot_loss_proj:2.915 [t=0.29s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1750/2000] tot_loss=2.303 (perp=10.986, rec=0.105), tot_loss_proj:2.910 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1800/2000] tot_loss=2.320 (perp=10.986, rec=0.123), tot_loss_proj:2.913 [t=0.28s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1850/2000] tot_loss=2.301 (perp=10.986, rec=0.104), tot_loss_proj:2.919 [t=0.30s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[1900/2000] tot_loss=2.304 (perp=10.986, rec=0.107), tot_loss_proj:2.912 [t=0.32s]
prediction: ['[CLS]nagar trash trailer [SEP]']
[1950/2000] tot_loss=2.313 (perp=10.986, rec=0.115), tot_loss_proj:2.912 [t=0.29s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Attempt swap
[2000/2000] tot_loss=2.304 (perp=10.986, rec=0.107), tot_loss_proj:2.910 [t=0.29s]
prediction: ['[CLS]nagar trash trailer [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] - trailer trash [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.205 | p: 75.344 | r: 77.409
rouge2     | fm: 40.246 | p: 39.884 | r: 40.661
rougeL     | fm: 68.371 | p: 67.660 | r: 69.533
rougeLsum  | fm: 68.447 | p: 67.562 | r: 69.613
r1fm+r2fm = 116.452

input #52 time: 0:12:00 | total time: 9:45:39


Running input #53 of 100.
reference: 
========================
flinching 
========================
cosin similarity: 0.8177057447280546 normalized error: 0.5949757513681382
cosin similarity: -0.8177057447280545 normalized error: 1.5901821793009576
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 1.860857468996012 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 1.8326884834881505 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 1.78793463003454 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 1.7694669264075686 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 1.7461980450754935 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 1.6822965134714465 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 1.3790848816458245 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 1.3746548415711082 for ['[CLS] ralph not [SEP]']
[Init] best rec loss: 1.3267703807258537 for ['[CLS] praising won [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.827 (perp=12.384, rec=0.350), tot_loss_proj:3.613 [t=0.29s]
prediction: ['[CLS] flinch flinched [SEP]']
[ 100/2000] tot_loss=2.751 (perp=12.492, rec=0.253), tot_loss_proj:3.638 [t=0.29s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.700 (perp=12.492, rec=0.201), tot_loss_proj:3.645 [t=0.29s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.696 (perp=12.492, rec=0.198), tot_loss_proj:3.655 [t=0.29s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.675 (perp=12.492, rec=0.177), tot_loss_proj:3.648 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.676 (perp=12.492, rec=0.177), tot_loss_proj:3.641 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.669 (perp=12.492, rec=0.171), tot_loss_proj:3.639 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.663 (perp=12.492, rec=0.164), tot_loss_proj:3.643 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 450/2000] tot_loss=2.659 (perp=12.472, rec=0.165), tot_loss_proj:3.654 [t=0.29s]
prediction: ['[CLS] kayla flinch [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.417 (perp=11.225, rec=0.172), tot_loss_proj:3.291 [t=0.30s]
prediction: ['[CLS] flinch kayla [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.398 (perp=11.225, rec=0.153), tot_loss_proj:3.276 [t=0.29s]
prediction: ['[CLS] flinch kayla [SEP]']
[ 600/2000] tot_loss=2.390 (perp=11.225, rec=0.145), tot_loss_proj:3.288 [t=0.29s]
prediction: ['[CLS] flinch kayla [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.400 (perp=11.225, rec=0.155), tot_loss_proj:3.287 [t=0.29s]
prediction: ['[CLS] flinch kayla [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.785 (perp=8.090, rec=0.167), tot_loss_proj:2.031 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.767 (perp=8.090, rec=0.149), tot_loss_proj:2.037 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.781 (perp=8.090, rec=0.163), tot_loss_proj:2.037 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.769 (perp=8.090, rec=0.151), tot_loss_proj:2.025 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.781 (perp=8.090, rec=0.163), tot_loss_proj:2.037 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.780 (perp=8.090, rec=0.162), tot_loss_proj:2.036 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.769 (perp=8.090, rec=0.151), tot_loss_proj:2.036 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.778 (perp=8.090, rec=0.160), tot_loss_proj:2.014 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.766 (perp=8.090, rec=0.148), tot_loss_proj:2.027 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.776 (perp=8.090, rec=0.158), tot_loss_proj:2.029 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.761 (perp=8.090, rec=0.143), tot_loss_proj:2.027 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.766 (perp=8.090, rec=0.149), tot_loss_proj:2.036 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.766 (perp=8.090, rec=0.148), tot_loss_proj:2.022 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.775 (perp=8.090, rec=0.157), tot_loss_proj:2.022 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.774 (perp=8.090, rec=0.156), tot_loss_proj:2.021 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.765 (perp=8.090, rec=0.147), tot_loss_proj:2.031 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.772 (perp=8.090, rec=0.154), tot_loss_proj:2.012 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.756 (perp=8.090, rec=0.139), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.757 (perp=8.090, rec=0.139), tot_loss_proj:2.029 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.757 (perp=8.090, rec=0.139), tot_loss_proj:2.016 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.758 (perp=8.090, rec=0.140), tot_loss_proj:2.038 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.777 (perp=8.090, rec=0.159), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.788 (perp=8.090, rec=0.170), tot_loss_proj:2.036 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.768 (perp=8.090, rec=0.150), tot_loss_proj:2.025 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.773 (perp=8.090, rec=0.155), tot_loss_proj:2.031 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.090, rec=0.152), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.764 (perp=8.090, rec=0.146), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.739 | p: 75.847 | r: 77.897
rouge2     | fm: 41.187 | p: 40.821 | r: 41.630
rougeL     | fm: 69.030 | p: 68.249 | r: 70.166
rougeLsum  | fm: 68.952 | p: 68.054 | r: 70.140
r1fm+r2fm = 117.925

input #53 time: 0:11:43 | total time: 9:57:23


Running input #54 of 100.
reference: 
========================
hot topics 
========================
cosin similarity: -0.8756915472916371 normalized error: 1.7683841257581865
cosin similarity: 0.875691547291637 normalized error: 0.49565989248160147
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 1.6227908775326791 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 1.5987542074693561 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 1.5767884679215545 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 1.5682671519385059 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 1.5260936180324371 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 1.306422755073867 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 1.2822390957943035 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 1.261873184519111 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 1.1590576490000863 for ['[CLS] wild exercised [SEP]']
[Init] best rec loss: 1.152734810718929 for ['[CLS] shining blaine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.063 (perp=8.086, rec=0.446), tot_loss_proj:2.763 [t=0.26s]
prediction: ['[CLS] topic topics [SEP]']
[ 100/2000] tot_loss=2.626 (perp=11.553, rec=0.315), tot_loss_proj:2.957 [t=0.30s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.579 (perp=11.553, rec=0.268), tot_loss_proj:2.968 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.552 (perp=11.553, rec=0.242), tot_loss_proj:2.957 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.890 (perp=8.198, rec=0.251), tot_loss_proj:1.995 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.835 (perp=8.198, rec=0.195), tot_loss_proj:1.949 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.821 (perp=8.198, rec=0.182), tot_loss_proj:1.952 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.822 (perp=8.198, rec=0.182), tot_loss_proj:1.947 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.806 (perp=8.198, rec=0.166), tot_loss_proj:1.954 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.810 (perp=8.198, rec=0.171), tot_loss_proj:1.946 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.803 (perp=8.198, rec=0.164), tot_loss_proj:1.956 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.801 (perp=8.198, rec=0.161), tot_loss_proj:1.955 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.814 (perp=8.198, rec=0.175), tot_loss_proj:1.951 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.803 (perp=8.198, rec=0.163), tot_loss_proj:1.953 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.799 (perp=8.198, rec=0.160), tot_loss_proj:1.960 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.800 (perp=8.198, rec=0.161), tot_loss_proj:1.951 [t=0.29s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.796 (perp=8.198, rec=0.156), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.805 (perp=8.198, rec=0.165), tot_loss_proj:1.952 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.198, rec=0.159), tot_loss_proj:1.956 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=8.198, rec=0.164), tot_loss_proj:1.943 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.806 (perp=8.198, rec=0.166), tot_loss_proj:1.942 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.804 (perp=8.198, rec=0.165), tot_loss_proj:1.948 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.800 (perp=8.198, rec=0.161), tot_loss_proj:1.948 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.798 (perp=8.198, rec=0.159), tot_loss_proj:1.953 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.809 (perp=8.198, rec=0.169), tot_loss_proj:1.955 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.805 (perp=8.198, rec=0.166), tot_loss_proj:1.954 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.792 (perp=8.198, rec=0.152), tot_loss_proj:1.947 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.792 (perp=8.198, rec=0.153), tot_loss_proj:1.958 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.803 (perp=8.198, rec=0.163), tot_loss_proj:1.950 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.798 (perp=8.198, rec=0.158), tot_loss_proj:1.947 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.794 (perp=8.198, rec=0.155), tot_loss_proj:1.960 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.805 (perp=8.198, rec=0.165), tot_loss_proj:1.953 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.794 (perp=8.198, rec=0.155), tot_loss_proj:1.948 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.806 (perp=8.198, rec=0.166), tot_loss_proj:1.948 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.798 (perp=8.198, rec=0.159), tot_loss_proj:1.952 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.799 (perp=8.198, rec=0.159), tot_loss_proj:1.947 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.799 (perp=8.198, rec=0.160), tot_loss_proj:1.952 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.198, rec=0.157), tot_loss_proj:1.954 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.798 (perp=8.198, rec=0.159), tot_loss_proj:1.946 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.792 (perp=8.198, rec=0.152), tot_loss_proj:1.958 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.988 | p: 76.217 | r: 78.173
rouge2     | fm: 42.408 | p: 42.072 | r: 42.873
rougeL     | fm: 69.641 | p: 68.905 | r: 70.697
rougeLsum  | fm: 69.466 | p: 68.679 | r: 70.642
r1fm+r2fm = 119.397

input #54 time: 0:11:05 | total time: 10:08:28


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
cosin similarity: -0.9432948797398057 normalized error: 1.6850677566109011
cosin similarity: 0.9432948797398059 normalized error: 0.5091769049280793
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 1.8132597928905372 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 1.520339640262229 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 1.4178397981846766 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 1.364029795873306 for ['[CLS] leaflets highlighted the [SEP]']
[Init] best rec loss: 1.3321413016333503 for ['[CLS] precipitation written mounted [SEP]']
[Init] best perm rec loss: 1.3286311339900267 for ['[CLS] written precipitation mounted [SEP]']
[Init] best perm rec loss: 1.3279397570065152 for ['[CLS] written mounted precipitation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.721 (perp=10.755, rec=0.570), tot_loss_proj:3.443 [t=0.26s]
prediction: ['[CLS] problems recoverednsis [SEP]']
[ 100/2000] tot_loss=3.014 (perp=12.871, rec=0.439), tot_loss_proj:3.936 [t=0.27s]
prediction: ['[CLS]omi settle detect [SEP]']
[ 150/2000] tot_loss=2.665 (perp=11.449, rec=0.376), tot_loss_proj:3.648 [t=0.28s]
prediction: ['[CLS] down settle detect [SEP]']
[ 200/2000] tot_loss=2.807 (perp=12.286, rec=0.350), tot_loss_proj:3.720 [t=0.26s]
prediction: ['[CLS] down settle settles [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.454 (perp=10.337, rec=0.387), tot_loss_proj:3.052 [t=0.27s]
prediction: ['[CLS] down easily settle [SEP]']
[ 300/2000] tot_loss=1.918 (perp=8.185, rec=0.281), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] too easily settle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.959 (perp=8.688, rec=0.221), tot_loss_proj:2.425 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.902 (perp=8.688, rec=0.164), tot_loss_proj:2.428 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.876 (perp=8.688, rec=0.139), tot_loss_proj:2.432 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.873 (perp=8.688, rec=0.135), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.865 (perp=8.688, rec=0.127), tot_loss_proj:2.428 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.868 (perp=8.688, rec=0.131), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.857 (perp=8.688, rec=0.120), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.853 (perp=8.688, rec=0.116), tot_loss_proj:2.428 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.856 (perp=8.688, rec=0.118), tot_loss_proj:2.432 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.846 (perp=8.688, rec=0.108), tot_loss_proj:2.436 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.858 (perp=8.688, rec=0.120), tot_loss_proj:2.437 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.850 (perp=8.688, rec=0.113), tot_loss_proj:2.437 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.841 (perp=8.688, rec=0.103), tot_loss_proj:2.434 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.843 (perp=8.688, rec=0.105), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.845 (perp=8.688, rec=0.107), tot_loss_proj:2.434 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.853 (perp=8.688, rec=0.115), tot_loss_proj:2.426 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.854 (perp=8.688, rec=0.117), tot_loss_proj:2.438 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.847 (perp=8.688, rec=0.109), tot_loss_proj:2.433 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.849 (perp=8.688, rec=0.112), tot_loss_proj:2.437 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=8.688, rec=0.105), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.846 (perp=8.688, rec=0.108), tot_loss_proj:2.440 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.853 (perp=8.688, rec=0.116), tot_loss_proj:2.430 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=8.688, rec=0.110), tot_loss_proj:2.429 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.844 (perp=8.688, rec=0.106), tot_loss_proj:2.438 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.853 (perp=8.688, rec=0.115), tot_loss_proj:2.424 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.846 (perp=8.688, rec=0.109), tot_loss_proj:2.438 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.847 (perp=8.688, rec=0.109), tot_loss_proj:2.435 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.843 (perp=8.688, rec=0.105), tot_loss_proj:2.427 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.841 (perp=8.688, rec=0.104), tot_loss_proj:2.437 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.848 (perp=8.688, rec=0.110), tot_loss_proj:2.426 [t=0.28s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.845 (perp=8.688, rec=0.108), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.844 (perp=8.688, rec=0.107), tot_loss_proj:2.440 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.846 (perp=8.688, rec=0.109), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.839 (perp=8.688, rec=0.102), tot_loss_proj:2.433 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 77.534 | p: 76.676 | r: 78.671
rouge2     | fm: 42.161 | p: 41.837 | r: 42.601
rougeL     | fm: 69.813 | p: 69.024 | r: 70.956
rougeLsum  | fm: 69.735 | p: 68.922 | r: 70.875
r1fm+r2fm = 119.696

input #55 time: 0:11:05 | total time: 10:19:34


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
cosin similarity: -0.9308917516775046 normalized error: 1.780329755081986
cosin similarity: 0.9308917516775045 normalized error: 0.4680700509046626
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 1.657949479590898 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 1.5972682180982085 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 1.5830251744808155 for ['[CLS] gu listgnant brave xavier jenna lady behalf file productions experienced charmvah everything law commander shorts inner matchesonal boot [SEP]']
[Init] best rec loss: 1.5256889901627173 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 1.478327425027009 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 1.4694687572998928 for ['[CLS] sense en depression avid laid ironured bear k strike blame reflection technique determined backed unfortunately ; sympathy charter code tis [SEP]']
[Init] best perm rec loss: 1.4612084267702257 for ['[CLS] strike charter unfortunately en backed reflection code laid tis blame k determined depression technique sense bear sympathy ironured ; avid [SEP]']
[Init] best perm rec loss: 1.4561146937008274 for ['[CLS] strike reflection ; tisured determined sympathy backed k sense en unfortunately depression iron technique laid blame code avid charter bear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.715 (perp=11.675, rec=0.380), tot_loss_proj:3.307 [t=0.28s]
prediction: ['[CLS] forced phone barack paulo repair tape badly our days not worst unfortunately of crore provincial damage crude toilet if of caused [SEP]']
[ 100/2000] tot_loss=2.726 (perp=12.100, rec=0.306), tot_loss_proj:3.534 [t=0.26s]
prediction: ['[CLS] forcedcy afbphate repair raceway damageible am not damn unfortunately of centuries provincial damage country costly if of caused [SEP]']
[ 150/2000] tot_loss=2.529 (perp=11.336, rec=0.262), tot_loss_proj:3.255 [t=0.27s]
prediction: ['[CLS] yearscy filmsphate damage raceway damage that we not might unfortunately of centuries autopsy damage ty costly fix of caused [SEP]']
[ 200/2000] tot_loss=2.616 (perp=11.988, rec=0.218), tot_loss_proj:3.881 [t=0.26s]
prediction: ['[CLS] yearscy filmsphate analysis films damage that hours cause will unfortunately of centuries autopsy damage strained costly fix never unnecessary [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.443 (perp=11.150, rec=0.213), tot_loss_proj:3.871 [t=0.26s]
prediction: ['[CLS] yearscy filmsphate analysis films damage that hours cause of years autopsy damage strained costly fix will unfortunately never unnecessary [SEP]']
[ 300/2000] tot_loss=2.360 (perp=10.888, rec=0.182), tot_loss_proj:3.907 [t=0.28s]
prediction: ['[CLS] yearscy filmsphate analysis films damage that years cause of years autopsy damage of costly fix will unfortunately never unnecessary [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.228 (perp=10.340, rec=0.160), tot_loss_proj:3.425 [t=0.26s]
prediction: ['[CLS] yearscy films allah analysis films autopsy damage that years cause of years damage of costly fix will unfortunately never prohibit [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.152 (perp=10.055, rec=0.141), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] yearscy films allah analysis films ir damage that years cause of damage years of costly fix will unfortunately never prohibit [SEP]']
[ 450/2000] tot_loss=2.304 (perp=10.801, rec=0.143), tot_loss_proj:3.531 [t=0.27s]
prediction: ['[CLS] years { films allah analysis films ir damage that years cause of damage years of costly fix will dangerous never prohibit [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.269 (perp=10.668, rec=0.135), tot_loss_proj:3.319 [t=0.27s]
prediction: ['[CLS] years of films allah analysis which ir damage that years cause of damage yearsqua dangerous costly fix will never loads [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.323 (perp=10.976, rec=0.127), tot_loss_proj:3.485 [t=0.30s]
prediction: ['[CLS] years films allah analysis which ir trunk damage that years cause of damage yearsqua dangerous costly fix will never loads [SEP]']
[ 600/2000] tot_loss=2.321 (perp=10.976, rec=0.125), tot_loss_proj:3.485 [t=0.27s]
prediction: ['[CLS] years films allah analysis which ir trunk damage that years cause of damage yearsqua dangerous costly fix will never loads [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.108 (perp=9.915, rec=0.125), tot_loss_proj:3.300 [t=0.28s]
prediction: ['[CLS] of films allah analysis which irnce damage that years cause of damage years of costly dangerous fix will never loads [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.172 (perp=10.241, rec=0.124), tot_loss_proj:3.225 [t=0.27s]
prediction: ['[CLS] analysis of filmsbella which irired damage that years cause of damage years of costly dangerous fix will never loads [SEP]']
[ 750/2000] tot_loss=2.160 (perp=10.241, rec=0.112), tot_loss_proj:3.228 [t=0.27s]
prediction: ['[CLS] analysis of filmsbella which irired damage that years cause of damage years of costly dangerous fix will never loads [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.055 (perp=9.714, rec=0.113), tot_loss_proj:3.225 [t=0.28s]
prediction: ['[CLS] analysis of films which irbellaired damage that years cause of damage years of costly spectacular fix will never loads [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.996 (perp=9.424, rec=0.111), tot_loss_proj:3.144 [t=0.28s]
prediction: ['[CLS] analysis of films which irbellaired damage that years cause of spectacular years of costly damage fix will never loads [SEP]']
[ 900/2000] tot_loss=1.991 (perp=9.371, rec=0.117), tot_loss_proj:3.122 [t=0.27s]
prediction: ['[CLS] analysis of films whichparabellaired damage that years cause of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.838 (perp=8.623, rec=0.113), tot_loss_proj:2.852 [t=0.27s]
prediction: ['[CLS] analysis of films which causeparabellaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
[1000/2000] tot_loss=1.836 (perp=8.623, rec=0.111), tot_loss_proj:2.859 [t=0.27s]
prediction: ['[CLS] analysis of films which causeparabellaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
[1050/2000] tot_loss=1.838 (perp=8.623, rec=0.113), tot_loss_proj:2.854 [t=0.28s]
prediction: ['[CLS] analysis of films which causeparabellaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.828 (perp=8.596, rec=0.109), tot_loss_proj:2.815 [t=0.28s]
prediction: ['[CLS] analysis of films which causebellaparaired damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.895 (perp=8.963, rec=0.102), tot_loss_proj:2.751 [t=0.27s]
prediction: ['[CLS] analysis of which films causebellaparaulsive damage that years of spectacular years of costly damage fix will never loads [SEP]']
[1200/2000] tot_loss=1.894 (perp=8.963, rec=0.102), tot_loss_proj:2.749 [t=0.28s]
prediction: ['[CLS] analysis of which films causebellaparaulsive damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.855 (perp=8.739, rec=0.108), tot_loss_proj:2.744 [t=0.27s]
prediction: ['[CLS] analysis of which films causeulsiveparabella damage that years of spectacular years of costly damage fix will never loads [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.815 (perp=8.547, rec=0.105), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS] analysis of which films cause loadsparabella damage that years of spectacular years of costly damage fix will neverulsive [SEP]']
[1350/2000] tot_loss=1.820 (perp=8.547, rec=0.110), tot_loss_proj:2.631 [t=0.27s]
prediction: ['[CLS] analysis of which films cause loadsparabella damage that years of spectacular years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.816 (perp=8.547, rec=0.107), tot_loss_proj:2.628 [t=0.27s]
prediction: ['[CLS] analysis of which films cause loadsparabella damage that years of spectacular years of costly damage fix will neverulsive [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.790 (perp=8.404, rec=0.109), tot_loss_proj:2.538 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
[1500/2000] tot_loss=1.787 (perp=8.404, rec=0.106), tot_loss_proj:2.543 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.783 (perp=8.404, rec=0.102), tot_loss_proj:2.533 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.781 (perp=8.404, rec=0.100), tot_loss_proj:2.530 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]']
[1650/2000] tot_loss=1.803 (perp=8.508, rec=0.101), tot_loss_proj:2.764 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.807 (perp=8.508, rec=0.106), tot_loss_proj:2.763 [t=0.29s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.808 (perp=8.508, rec=0.106), tot_loss_proj:2.764 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
[1800/2000] tot_loss=1.808 (perp=8.508, rec=0.106), tot_loss_proj:2.766 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of less years of costly damage fix will neverulsive [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.749 (perp=8.233, rec=0.102), tot_loss_proj:2.665 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads ofparabella damage that years of years of less costly damage fix will neverulsive [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.778 (perp=8.271, rec=0.124), tot_loss_proj:2.558 [t=0.29s]
prediction: ['[CLS] analysis which films cause loads of periods ofparabella damage that years of dangerous costly damage fix will neverulsive [SEP]']
[1950/2000] tot_loss=1.760 (perp=8.271, rec=0.106), tot_loss_proj:2.562 [t=0.27s]
prediction: ['[CLS] analysis which films cause loads of periods ofparabella damage that years of dangerous costly damage fix will neverulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.271, rec=0.108), tot_loss_proj:2.563 [t=0.26s]
prediction: ['[CLS] analysis which films cause loads of periods ofparabella damage that years of dangerous costly damage fix will neverulsive [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] analysis which films cause loads ofparabella damage that years of dangerous years of costly damage fix will neverulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 26.316 | p: 26.316 | r: 26.316
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 106.316

[Aggregate metrics]:
rouge1     | fm: 77.534 | p: 76.778 | r: 78.691
rouge2     | fm: 41.766 | p: 41.402 | r: 42.226
rougeL     | fm: 69.727 | p: 68.927 | r: 70.744
rougeLsum  | fm: 69.535 | p: 68.773 | r: 70.719
r1fm+r2fm = 119.300

input #56 time: 0:11:09 | total time: 10:30:43


Running input #57 of 100.
reference: 
========================
wears 
========================
cosin similarity: -0.9322696138597257 normalized error: 1.6892108661716054
cosin similarity: 0.9322696138597257 normalized error: 0.510582375861863
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 1.7576340849318535 for ['[CLS]ne [SEP]']
[Init] best rec loss: 1.716505687086117 for ['[CLS] their [SEP]']
[Init] best rec loss: 1.6640945856224452 for ['[CLS] software [SEP]']
[Init] best rec loss: 1.6096875667724126 for ['[CLS] passed [SEP]']
[Init] best rec loss: 1.5187619586044785 for ['[CLS]cta [SEP]']
[Init] best rec loss: 1.501980876382866 for ['[CLS] darren [SEP]']
[Init] best rec loss: 1.4348307468367545 for ['[CLS] decision [SEP]']
[Init] best rec loss: 1.3838976232790914 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.926 (perp=12.705, rec=0.385), tot_loss_proj:3.345 [t=0.26s]
prediction: ['[CLS] wore [SEP]']
[ 100/2000] tot_loss=2.640 (perp=12.283, rec=0.183), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.626 (perp=12.283, rec=0.169), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.596 (perp=12.283, rec=0.139), tot_loss_proj:2.648 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.582 (perp=12.283, rec=0.125), tot_loss_proj:2.658 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.571 (perp=12.283, rec=0.114), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.565 (perp=12.283, rec=0.108), tot_loss_proj:2.647 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.587 (perp=12.283, rec=0.130), tot_loss_proj:2.643 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.568 (perp=12.283, rec=0.111), tot_loss_proj:2.656 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.572 (perp=12.283, rec=0.115), tot_loss_proj:2.653 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.562 (perp=12.283, rec=0.106), tot_loss_proj:2.655 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.582 (perp=12.283, rec=0.125), tot_loss_proj:2.655 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.567 (perp=12.283, rec=0.110), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.575 (perp=12.283, rec=0.118), tot_loss_proj:2.640 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.575 (perp=12.283, rec=0.118), tot_loss_proj:2.635 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.582 (perp=12.283, rec=0.126), tot_loss_proj:2.655 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.566 (perp=12.283, rec=0.110), tot_loss_proj:2.653 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.577 (perp=12.283, rec=0.120), tot_loss_proj:2.633 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.562 (perp=12.283, rec=0.106), tot_loss_proj:2.650 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.572 (perp=12.283, rec=0.116), tot_loss_proj:2.645 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.566 (perp=12.283, rec=0.110), tot_loss_proj:2.647 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.567 (perp=12.283, rec=0.110), tot_loss_proj:2.642 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.561 (perp=12.283, rec=0.105), tot_loss_proj:2.631 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.571 (perp=12.283, rec=0.114), tot_loss_proj:2.655 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.562 (perp=12.283, rec=0.106), tot_loss_proj:2.646 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.574 (perp=12.283, rec=0.118), tot_loss_proj:2.643 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.581 (perp=12.283, rec=0.125), tot_loss_proj:2.653 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.573 (perp=12.283, rec=0.116), tot_loss_proj:2.649 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.562 (perp=12.283, rec=0.105), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.585 (perp=12.283, rec=0.128), tot_loss_proj:2.648 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.574 (perp=12.283, rec=0.118), tot_loss_proj:2.647 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.565 (perp=12.283, rec=0.108), tot_loss_proj:2.645 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.574 (perp=12.283, rec=0.117), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.565 (perp=12.283, rec=0.108), tot_loss_proj:2.659 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.581 (perp=12.283, rec=0.124), tot_loss_proj:2.651 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.565 (perp=12.283, rec=0.109), tot_loss_proj:2.651 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.577 (perp=12.283, rec=0.120), tot_loss_proj:2.662 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.561 (perp=12.283, rec=0.104), tot_loss_proj:2.628 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.563 (perp=12.283, rec=0.106), tot_loss_proj:2.664 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.578 (perp=12.283, rec=0.121), tot_loss_proj:2.662 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.886 | p: 77.073 | r: 79.044
rouge2     | fm: 42.691 | p: 42.340 | r: 43.091
rougeL     | fm: 70.292 | p: 69.609 | r: 71.250
rougeLsum  | fm: 70.053 | p: 69.340 | r: 71.133
r1fm+r2fm = 120.576

input #57 time: 0:11:04 | total time: 10:41:47


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
cosin similarity: 0.74009822539267 normalized error: 0.5757614783650968
cosin similarity: -0.74009822539267 normalized error: 1.7263560850393105
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.9668464747323304 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 1.9450285339271698 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 1.933235515605162 for ['[CLS] talking honorary llc gray account feed very / cover robotics from which kin safe type tanks [SEP]']
[Init] best rec loss: 1.9236987166673536 for ['[CLS]ety spider gmina hypothesisjali brett endorsedhof avoid " joinsop programme friends designated looks [SEP]']
[Init] best rec loss: 1.9086421276345433 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 1.8659397234032546 for ['[CLS] beth early fred zealand puppy sherwood ancient snap artwork page non group paying kan mile marked [SEP]']
[Init] best rec loss: 1.8167857248948591 for ['[CLS] graphic drug car tenure heats ira rated effectivezzle woodrow horseshoe king delle viewingags shutter [SEP]']
[Init] best rec loss: 1.7871865220340717 for ['[CLS] insidethed subject layton devoted approachhead physicians keys vice tarzan mile norman warlord choosebaldi [SEP]']
[Init] best perm rec loss: 1.7846858994097983 for ['[CLS] choose layton keys normanthed inside physicians warlord vice mile subjecthead devoted tarzan approachbaldi [SEP]']
[Init] best perm rec loss: 1.7803387668958022 for ['[CLS] tarzanthed milehead keys warlord physicians devoted norman vicebaldi choose approach subject inside layton [SEP]']
[Init] best perm rec loss: 1.7785748965437005 for ['[CLS] inside keys normanhead warlord devoted subject approachthed mile vicebaldi tarzan choose physicians layton [SEP]']
[Init] best perm rec loss: 1.7776163704807897 for ['[CLS] approachbaldi inside subject layton mile tarzanthed choose warlord devoted physicians vicehead keys norman [SEP]']
[Init] best perm rec loss: 1.7764022642837602 for ['[CLS] subject devoted inside approach mile physicians tarzan warlord laytonbaldithedhead norman vice choose keys [SEP]']
[Init] best perm rec loss: 1.775629783756026 for ['[CLS] approach laytonhead tarzan subject mile physicians warlordthed vice inside devoted norman choose keysbaldi [SEP]']
[Init] best perm rec loss: 1.7749472684219532 for ['[CLS] physicians keys warlord norman approach subject mile devoted choose insidebaldihead tarzanthed vice layton [SEP]']
[Init] best perm rec loss: 1.7747323910638602 for ['[CLS] keys layton mile subject vice tarzan warlord physicians choosehead insidebaldi devoted normanthed approach [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.460 (perp=13.612, rec=0.737), tot_loss_proj:4.640 [t=0.28s]
prediction: ['[CLS] issues penalties wilderness no hezbollah eliminated alcohol housing observatory equipment later materials until johnson dry penal [SEP]']
[ 100/2000] tot_loss=3.236 (perp=13.173, rec=0.602), tot_loss_proj:4.468 [t=0.29s]
prediction: ['[CLS] issues campus wilderness one hezbollah ballot liquor exhausted consequences illness earlier experiences be energy ash facing [SEP]']
[ 150/2000] tot_loss=2.999 (perp=11.950, rec=0.609), tot_loss_proj:4.322 [t=0.28s]
prediction: ['[CLS] issues vermont facts one hezbollah ballot liquor constitutional influenced kill, experiences be energy raw is [SEP]']
[ 200/2000] tot_loss=3.000 (perp=12.346, rec=0.531), tot_loss_proj:4.303 [t=0.28s]
prediction: ['[CLS] his vermont facts confrontation hezbollah ballot liquor constitutional influenced capture, experiences be energy raw makes [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.643 (perp=10.705, rec=0.502), tot_loss_proj:3.338 [t=0.28s]
prediction: ['[CLS] one environmental memories : inspirational ballot continuation constitutional influenced innocence, experiences immediately energy raw makes [SEP]']
[ 300/2000] tot_loss=2.862 (perp=11.831, rec=0.496), tot_loss_proj:4.280 [t=0.28s]
prediction: ['[CLS] no environmental memories his inspirational ballot continuation waste capture innocence, experiences torn analog ash makes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.640 (perp=10.515, rec=0.537), tot_loss_proj:3.464 [t=0.28s]
prediction: ['[CLS] one environmental inspirational story inspirational affair continuationpment capture innocence, ash, analog experiences makes [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.571 (perp=10.592, rec=0.453), tot_loss_proj:3.439 [t=0.27s]
prediction: ['[CLS] one environmental inspirational story inspirational affair continuationpment inspirational innocence, met, analog experiences makes [SEP]']
[ 450/2000] tot_loss=2.657 (perp=11.022, rec=0.453), tot_loss_proj:4.134 [t=0.27s]
prediction: ['[CLS] no parish inspirational story inspirational affair continuationpment inspirational innocence, met, analog experiences makes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.641 (perp=10.956, rec=0.450), tot_loss_proj:4.138 [t=0.27s]
prediction: ['[CLS] no parish inspirational story inspirational affair continuationpment makes love postwar painful the analog story inspirational [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.766 (perp=11.574, rec=0.451), tot_loss_proj:4.264 [t=0.25s]
prediction: ['[CLS] no parish inspirational story inspirational affair continuation waste makes story twigs the legend postwar experiences capture [SEP]']
[ 600/2000] tot_loss=2.386 (perp=9.755, rec=0.435), tot_loss_proj:3.097 [t=0.30s]
prediction: ['[CLS] a parish inspirational story inspirational affair continuationpment makes encounter twigs the legend, story inspirational [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.391 (perp=9.795, rec=0.432), tot_loss_proj:3.516 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair supporterpment makes encounter painful the postwar legend story inspirational [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.546 (perp=10.362, rec=0.473), tot_loss_proj:4.024 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair continues waste makes encounter painful that legend postwar story inspirational [SEP]']
[ 750/2000] tot_loss=2.418 (perp=10.019, rec=0.414), tot_loss_proj:3.830 [t=0.28s]
prediction: ['[CLS] a parish inspirational story inspirational affair supporter waste makes love painful that legend postwar story inspirational [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.471 (perp=10.274, rec=0.416), tot_loss_proj:3.933 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair supporter waste makes love painful the legend postwar story inspirational [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.507 (perp=10.420, rec=0.423), tot_loss_proj:4.050 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair supporter waste makes encounter painful the efficiency postwar story inspirational [SEP]']
[ 900/2000] tot_loss=2.448 (perp=10.097, rec=0.429), tot_loss_proj:3.422 [t=0.29s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes love painful that osaka, story inspirational [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.699 (perp=11.529, rec=0.393), tot_loss_proj:3.807 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes postwar painful that osaka encounter story inspirational [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.484 (perp=10.310, rec=0.422), tot_loss_proj:3.883 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved waste makes encounter painful that efficiency postwar story inspirational [SEP]']
[1050/2000] tot_loss=2.562 (perp=10.873, rec=0.388), tot_loss_proj:3.592 [t=0.28s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter painful that osaka postwar story inspirational [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.398 (perp=10.069, rec=0.384), tot_loss_proj:3.394 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter the painfulerate postwar story inspirational [SEP]']
Attempt swap
[1150/2000] tot_loss=2.412 (perp=10.069, rec=0.398), tot_loss_proj:3.395 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter the painfulerate postwar story inspirational [SEP]']
[1200/2000] tot_loss=2.398 (perp=10.069, rec=0.384), tot_loss_proj:3.396 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter the painfulerate postwar story inspirational [SEP]']
Attempt swap
[1250/2000] tot_loss=2.397 (perp=10.069, rec=0.383), tot_loss_proj:3.393 [t=0.29s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter the painfulerate postwar story inspirational [SEP]']
Attempt swap
[1300/2000] tot_loss=2.476 (perp=10.069, rec=0.462), tot_loss_proj:3.397 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter the painfulerate postwar story inspirational [SEP]']
[1350/2000] tot_loss=2.398 (perp=10.069, rec=0.384), tot_loss_proj:3.394 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick makes encounter the painfulerate postwar story inspirational [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.331 (perp=9.754, rec=0.380), tot_loss_proj:3.334 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the painfulerate postwar story inspirational [SEP]']
Attempt swap
[1450/2000] tot_loss=2.423 (perp=10.248, rec=0.374), tot_loss_proj:3.401 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
[1500/2000] tot_loss=2.441 (perp=10.355, rec=0.370), tot_loss_proj:3.523 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes that hurtserate postwar story inspirational [SEP]']
Attempt swap
[1550/2000] tot_loss=2.438 (perp=10.355, rec=0.367), tot_loss_proj:3.522 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes that hurtserate postwar story inspirational [SEP]']
Attempt swap
[1600/2000] tot_loss=2.417 (perp=10.248, rec=0.367), tot_loss_proj:3.402 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
[1650/2000] tot_loss=2.439 (perp=10.355, rec=0.368), tot_loss_proj:3.521 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes that hurtserate postwar story inspirational [SEP]']
Attempt swap
[1700/2000] tot_loss=2.435 (perp=10.355, rec=0.364), tot_loss_proj:3.526 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes that hurtserate postwar story inspirational [SEP]']
Attempt swap
[1750/2000] tot_loss=2.415 (perp=10.248, rec=0.365), tot_loss_proj:3.399 [t=0.27s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
[1800/2000] tot_loss=2.417 (perp=10.248, rec=0.367), tot_loss_proj:3.400 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
Attempt swap
[1850/2000] tot_loss=2.417 (perp=10.248, rec=0.367), tot_loss_proj:3.401 [t=0.26s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
Attempt swap
[1900/2000] tot_loss=2.416 (perp=10.248, rec=0.366), tot_loss_proj:3.396 [t=0.28s]
prediction: ['[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
[1950/2000] tot_loss=2.496 (perp=10.664, rec=0.364), tot_loss_proj:3.502 [t=0.26s]
prediction: ['[CLS] a environmental inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
Attempt swap
[2000/2000] tot_loss=2.496 (perp=10.664, rec=0.363), tot_loss_proj:3.499 [t=0.26s]
prediction: ['[CLS] a environmental inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] a parish inspirational story inspirational affair loved patrick encounter makes the hurtserate postwar story inspirational [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 36.364 | p: 35.294 | r: 37.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 30.303 | p: 29.412 | r: 31.250
rougeLsum  | fm: 30.303 | p: 29.412 | r: 31.250
r1fm+r2fm = 36.364

[Aggregate metrics]:
rouge1     | fm: 77.235 | p: 76.452 | r: 78.364
rouge2     | fm: 42.199 | p: 41.880 | r: 42.576
rougeL     | fm: 69.523 | p: 68.741 | r: 70.575
rougeLsum  | fm: 69.396 | p: 68.606 | r: 70.565
r1fm+r2fm = 119.434

input #58 time: 0:11:10 | total time: 10:52:58


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
cosin similarity: -0.9816993464484325 normalized error: 1.900850405425909
cosin similarity: 0.9816993464484326 normalized error: 0.3937520154390487
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 1.9352468220595735 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 1.924344726965796 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 1.9235641936941186 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 1.9057989966081574 for ['[CLS] shares josephine settled commerce refrain bulletsgi moved plot awaitanies roger console fergusotidew [SEP]']
[Init] best rec loss: 1.8261733513192162 for ['[CLS] meetings primarily afar vietnamille sound explaining bun ii powerped able speaking [SEP] brow illumination [SEP]']
[Init] best rec loss: 1.8195959440220848 for ['[CLS]her mutual so furrowed biggest new and \\ mag ac infantry portuguesecturing honor st thunder [SEP]']
[Init] best rec loss: 1.7829898906195414 for ['[CLS] trollsity underoh othersrion vault sorry days premiereend wivesjit reachedhold motorway [SEP]']
[Init] best rec loss: 1.7449995235109532 for ['[CLS] approaches dumb accept households frame relation sport replymis logan surrounding dutch dragon different com discipline [SEP]']
[Init] best rec loss: 1.7358503800545138 for ['[CLS]manship channels finishing organized black og getting last education plant mad thisor swiss penalties milton [SEP]']
[Init] best rec loss: 1.731510353822376 for ['[CLS] return knows french describeza r steer tatum bowler park valve form & where digitft [SEP]']
[Init] best rec loss: 1.721799546019262 for ['[CLS] effects one marxist southeastcarbon first rural relations breast tony threatened ran rose dodgers temptation josie [SEP]']
[Init] best rec loss: 1.6841728449184612 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best rec loss: 1.4963156858759479 for ['[CLS] organic passengers heroic wall duty change surgery drag kay statesflower hadn retirement cross will money [SEP]']
[Init] best perm rec loss: 1.4889789914032447 for ['[CLS] states organic passengers dragflower retirement kay will cross heroic change money surgery duty hadn wall [SEP]']
[Init] best perm rec loss: 1.4856175553972626 for ['[CLS] cross passengers money change organic hadn retirement heroic will kay surgery wall states dutyflower drag [SEP]']
[Init] best perm rec loss: 1.4851606582037857 for ['[CLS] organic kay change hadn cross moneyflower states retirement wall drag heroic surgery duty will passengers [SEP]']
[Init] best perm rec loss: 1.4814596546115226 for ['[CLS] cross organic states change kay money heroicflower duty wall hadn drag surgery retirement will passengers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.842 (perp=12.154, rec=0.412), tot_loss_proj:4.218 [t=0.28s]
prediction: ['[CLS] elvis wanted batsman theater catchther (yo borneptive lady of " quinn managed little [SEP]']
[ 100/2000] tot_loss=2.870 (perp=12.805, rec=0.309), tot_loss_proj:4.088 [t=0.26s]
prediction: ['[CLS] has wanted child theatre woman screen (yo style sha woman who ability karen an young [SEP]']
[ 150/2000] tot_loss=2.531 (perp=11.128, rec=0.305), tot_loss_proj:3.733 [t=0.26s]
prediction: ['[CLS] has the womantta woman screen (li woman female woman who ability wife hold young [SEP]']
[ 200/2000] tot_loss=2.685 (perp=12.221, rec=0.241), tot_loss_proj:3.975 [t=0.30s]
prediction: ['[CLS] has has womantta woman screen (li who female screen who char wife hold young [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.351 (perp=10.624, rec=0.226), tot_loss_proj:3.744 [t=0.26s]
prediction: ['[CLS]ism has womanism where screen has a who how screen who char wife hold young [SEP]']
[ 300/2000] tot_loss=2.242 (perp=10.244, rec=0.193), tot_loss_proj:3.537 [t=0.26s]
prediction: ['[CLS]ism has woman of who screen has a who how screen who char wife hold young [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.032 (perp=9.343, rec=0.163), tot_loss_proj:3.196 [t=0.26s]
prediction: ['[CLS]ism has woman of who screen has a who screen who char wife hold the young [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.994 (perp=9.221, rec=0.150), tot_loss_proj:2.933 [t=0.26s]
prediction: ['[CLS]ism has woman of who screen has a screen who knows char wife hold the young [SEP]']
[ 450/2000] tot_loss=1.867 (perp=8.641, rec=0.139), tot_loss_proj:2.726 [t=0.27s]
prediction: ['[CLS]ism has woman of a screen has a screen who knows char wife hold the young [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.973 (perp=9.178, rec=0.137), tot_loss_proj:3.159 [t=0.26s]
prediction: ['[CLS]ism has woman of the screen hasised screen who knows char wife hold the young [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.864 (perp=8.721, rec=0.120), tot_loss_proj:2.794 [t=0.28s]
prediction: ['[CLS]ism has woman of the screen husbandism screen who knows char has hold the young [SEP]']
[ 600/2000] tot_loss=2.006 (perp=9.417, rec=0.123), tot_loss_proj:2.896 [t=0.27s]
prediction: ['[CLS]ism has woman of the screen knowsism screen who knows char has hold the young [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.899 (perp=8.926, rec=0.114), tot_loss_proj:2.825 [t=0.27s]
prediction: ['[CLS]ism has woman of the screenism screen knows who knows char has hold the young [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.863 (perp=8.691, rec=0.125), tot_loss_proj:2.777 [t=0.27s]
prediction: ['[CLS]ism has woman of the screen char screen knows who knowsism has hold the young [SEP]']
[ 750/2000] tot_loss=1.948 (perp=9.192, rec=0.110), tot_loss_proj:2.769 [t=0.27s]
prediction: ['[CLS]ism has woman of theism char screen knows who knowsism has hold the young [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.891 (perp=8.938, rec=0.103), tot_loss_proj:2.559 [t=0.26s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=8.938, rec=0.102), tot_loss_proj:2.553 [t=0.26s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
[ 900/2000] tot_loss=1.890 (perp=8.938, rec=0.102), tot_loss_proj:2.557 [t=0.26s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.893 (perp=8.938, rec=0.106), tot_loss_proj:2.560 [t=0.27s]
prediction: ['[CLS]ism has woman of the charism screen knows who knowsism has hold the young [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.870 (perp=8.798, rec=0.111), tot_loss_proj:2.486 [t=0.27s]
prediction: ['[CLS]ism hasism of the charism screen knows who knows woman has hold the young [SEP]']
[1050/2000] tot_loss=1.864 (perp=8.798, rec=0.105), tot_loss_proj:2.487 [t=0.28s]
prediction: ['[CLS]ism hasism of the charism screen knows who knows woman has hold the young [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.829 (perp=8.685, rec=0.092), tot_loss_proj:2.466 [t=0.27s]
prediction: ['[CLS]ismism has of the charism screen knows who knows woman has hold the young [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.818 (perp=8.572, rec=0.104), tot_loss_proj:2.559 [t=0.27s]
prediction: ['[CLS]ismism has of the charism screen knows who knows hold the young woman having [SEP]']
[1200/2000] tot_loss=1.817 (perp=8.572, rec=0.102), tot_loss_proj:2.560 [t=0.26s]
prediction: ['[CLS]ismism has of the charism screen knows who knows hold the young woman having [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.731 (perp=8.138, rec=0.104), tot_loss_proj:2.470 [t=0.28s]
prediction: ['[CLS]ismism has of the charism screen knows who knows having hold the young woman [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.631 (perp=7.652, rec=0.100), tot_loss_proj:2.244 [t=0.25s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1350/2000] tot_loss=1.624 (perp=7.652, rec=0.093), tot_loss_proj:2.247 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.631 (perp=7.652, rec=0.100), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1450/2000] tot_loss=1.628 (perp=7.652, rec=0.097), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1500/2000] tot_loss=1.632 (perp=7.652, rec=0.101), tot_loss_proj:2.232 [t=0.27s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1550/2000] tot_loss=1.629 (perp=7.652, rec=0.099), tot_loss_proj:2.230 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1600/2000] tot_loss=1.639 (perp=7.652, rec=0.109), tot_loss_proj:2.236 [t=0.29s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1650/2000] tot_loss=1.635 (perp=7.652, rec=0.104), tot_loss_proj:2.232 [t=0.28s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1700/2000] tot_loss=1.628 (perp=7.652, rec=0.098), tot_loss_proj:2.233 [t=0.28s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1750/2000] tot_loss=1.626 (perp=7.652, rec=0.095), tot_loss_proj:2.237 [t=0.29s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1800/2000] tot_loss=1.629 (perp=7.652, rec=0.098), tot_loss_proj:2.236 [t=0.27s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1850/2000] tot_loss=1.632 (perp=7.652, rec=0.102), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[1900/2000] tot_loss=1.628 (perp=7.652, rec=0.098), tot_loss_proj:2.234 [t=0.27s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
[1950/2000] tot_loss=1.625 (perp=7.652, rec=0.094), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Attempt swap
[2000/2000] tot_loss=1.631 (perp=7.652, rec=0.100), tot_loss_proj:2.235 [t=0.26s]
prediction: ['[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS]ismism has the charism screen of knows who knows having hold the young woman [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 101.667

[Aggregate metrics]:
rouge1     | fm: 77.151 | p: 76.377 | r: 78.254
rouge2     | fm: 41.644 | p: 41.303 | r: 42.046
rougeL     | fm: 69.169 | p: 68.453 | r: 70.315
rougeLsum  | fm: 69.409 | p: 68.664 | r: 70.462
r1fm+r2fm = 118.794

input #59 time: 0:11:06 | total time: 11:04:05


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
cosin similarity: 0.7253921869358013 normalized error: 0.6182812032239168
cosin similarity: -0.7253921869358013 normalized error: 1.6201739360599212
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 1.8354205428102135 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 1.6338969775323644 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 1.6313011023388608 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 1.5787617765693356 for ['[CLS] width stranger sector loyalist soundtrack opposition beside position didn eligible grants peter [SEP]']
[Init] best perm rec loss: 1.5701308636471314 for ['[CLS] beside stranger eligible peter soundtrack grants width didn loyalist sector position opposition [SEP]']
[Init] best perm rec loss: 1.5632120262640314 for ['[CLS] beside position loyalist eligible sector peter grants didn opposition soundtrack stranger width [SEP]']
[Init] best perm rec loss: 1.562876104876987 for ['[CLS] beside soundtrack eligible peter grants position opposition didn stranger width loyalist sector [SEP]']
[Init] best perm rec loss: 1.5588626760933004 for ['[CLS] width loyalist grants sector didn position eligible stranger soundtrack opposition peter beside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.002 (perp=13.108, rec=0.381), tot_loss_proj:3.807 [t=0.27s]
prediction: ['[CLS] mono reporters details press crab permit awkwardly diagnostic custody alien is bad [SEP]']
[ 100/2000] tot_loss=2.881 (perp=12.897, rec=0.302), tot_loss_proj:3.692 [t=0.25s]
prediction: ['[CLS] entire reporters shells forced rotor subdistrict awkwardly paced custody alien is confused [SEP]']
[ 150/2000] tot_loss=2.671 (perp=12.130, rec=0.245), tot_loss_proj:3.495 [t=0.26s]
prediction: ['[CLS] entire football 1989 awkwardly is anthology awkwardly paced custody hostage is wrong [SEP]']
[ 200/2000] tot_loss=2.743 (perp=12.680, rec=0.207), tot_loss_proj:3.603 [t=0.25s]
prediction: ['[CLS] entire soap 1989 awkwardly is anthology awkwardly paced custody hostage is waived [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.485 (perp=11.400, rec=0.205), tot_loss_proj:3.624 [t=0.25s]
prediction: ['[CLS] : soap is 1989 isgrapher awkwardly paced circuit hostage is waived [SEP]']
[ 300/2000] tot_loss=2.439 (perp=11.227, rec=0.194), tot_loss_proj:3.733 [t=0.26s]
prediction: ['[CLS] : soap is 1989 is anthology awkwardly paced circuit hostage is waived [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.410 (perp=11.115, rec=0.187), tot_loss_proj:3.549 [t=0.26s]
prediction: ['[CLS] : soap is anthology is 1989 awkwardly paced circuit hostage story waived [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.585 (perp=11.940, rec=0.197), tot_loss_proj:3.552 [t=0.26s]
prediction: ['[CLS] is soaph hostageplify is 1989 awkwardly paced circuit story waived [SEP]']
[ 450/2000] tot_loss=2.576 (perp=11.940, rec=0.188), tot_loss_proj:3.556 [t=0.24s]
prediction: ['[CLS] is soaph hostageplify is 1989 awkwardly paced circuit story waived [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.587 (perp=12.007, rec=0.185), tot_loss_proj:3.649 [t=0.28s]
prediction: ['[CLS] islightsh hostage soap is negotiations awkwardly paced circuit story waived [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.517 (perp=11.733, rec=0.171), tot_loss_proj:3.365 [t=0.29s]
prediction: ['[CLS] islightsh hostage soap negotiations is awkwardly paced circuit story oklahoma [SEP]']
[ 600/2000] tot_loss=2.513 (perp=11.733, rec=0.167), tot_loss_proj:3.368 [t=0.26s]
prediction: ['[CLS] islightsh hostage soap negotiations is awkwardly paced circuit story oklahoma [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.518 (perp=11.723, rec=0.173), tot_loss_proj:3.323 [t=0.25s]
prediction: ['[CLS] ishlightsevic soap negotiations is awkwardly paced circuit story oklahoma [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.603 (perp=12.158, rec=0.171), tot_loss_proj:3.379 [t=0.27s]
prediction: ['[CLS] iseviclightsh soapuming is awkwardly paced circuit story oklahoma [SEP]']
[ 750/2000] tot_loss=2.595 (perp=12.158, rec=0.163), tot_loss_proj:3.383 [t=0.26s]
prediction: ['[CLS] iseviclightsh soapuming is awkwardly paced circuit story oklahoma [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.588 (perp=12.108, rec=0.166), tot_loss_proj:3.377 [t=0.26s]
prediction: ['[CLS] isevic oklahomah soapwas is awkwardly paced circuit storyway [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.431 (perp=11.383, rec=0.155), tot_loss_proj:3.248 [t=0.28s]
prediction: ['[CLS] isevich soapwas is oklahoma awkwardly paced circuit storyway [SEP]']
[ 900/2000] tot_loss=2.438 (perp=11.383, rec=0.161), tot_loss_proj:3.244 [t=0.26s]
prediction: ['[CLS] isevich soapwas is oklahoma awkwardly paced circuit storyway [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.488 (perp=11.659, rec=0.157), tot_loss_proj:3.328 [t=0.26s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
Attempt swap
[1000/2000] tot_loss=2.484 (perp=11.659, rec=0.152), tot_loss_proj:3.324 [t=0.27s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
[1050/2000] tot_loss=2.499 (perp=11.659, rec=0.167), tot_loss_proj:3.337 [t=0.27s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
Attempt swap
[1100/2000] tot_loss=2.495 (perp=11.659, rec=0.163), tot_loss_proj:3.338 [t=0.29s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
Attempt swap
[1150/2000] tot_loss=2.480 (perp=11.659, rec=0.148), tot_loss_proj:3.332 [t=0.27s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
[1200/2000] tot_loss=2.476 (perp=11.659, rec=0.144), tot_loss_proj:3.326 [t=0.26s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
Attempt swap
[1250/2000] tot_loss=2.473 (perp=11.659, rec=0.141), tot_loss_proj:3.334 [t=0.27s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
Attempt swap
[1300/2000] tot_loss=2.475 (perp=11.659, rec=0.143), tot_loss_proj:3.329 [t=0.26s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
[1350/2000] tot_loss=2.479 (perp=11.659, rec=0.147), tot_loss_proj:3.327 [t=0.27s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit storylights [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.472 (perp=11.610, rec=0.150), tot_loss_proj:3.323 [t=0.26s]
prediction: ['[CLS] isevic soapwash is paced awkwardly oklahoma circuit storylights [SEP]']
Attempt swap
[1450/2000] tot_loss=2.473 (perp=11.610, rec=0.151), tot_loss_proj:3.322 [t=0.26s]
prediction: ['[CLS] isevic soapwash is paced awkwardly oklahoma circuit storylights [SEP]']
[1500/2000] tot_loss=2.448 (perp=11.526, rec=0.143), tot_loss_proj:3.342 [t=0.28s]
prediction: ['[CLS] isevic soapwash is paced awkwardly oklahoma circuit story hardly [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.444 (perp=11.489, rec=0.146), tot_loss_proj:3.295 [t=0.27s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit story hardly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.434 (perp=11.489, rec=0.137), tot_loss_proj:3.294 [t=0.24s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit story hardly [SEP]']
[1650/2000] tot_loss=2.435 (perp=11.489, rec=0.137), tot_loss_proj:3.293 [t=0.25s]
prediction: ['[CLS] isevic soapwash is oklahoma awkwardly paced circuit story hardly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.450 (perp=11.503, rec=0.150), tot_loss_proj:3.308 [t=0.27s]
prediction: ['[CLS] isevic soapwash isling awkwardly paced circuit story hardly [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.412 (perp=11.311, rec=0.150), tot_loss_proj:3.242 [t=0.26s]
prediction: ['[CLS] isevic soapwashling is awkwardly paced circuit story hardly [SEP]']
[1800/2000] tot_loss=2.364 (perp=11.054, rec=0.153), tot_loss_proj:3.208 [t=0.25s]
prediction: ['[CLS] isevic soap.hling is awkwardly paced circuit story hardly [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.276 (perp=10.626, rec=0.151), tot_loss_proj:3.025 [t=0.27s]
prediction: ['[CLS] ish soap.evicling is awkwardly paced circuit story hardly [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.486 (perp=11.649, rec=0.157), tot_loss_proj:3.306 [t=0.26s]
prediction: ['[CLS] is compounds soap.evic kansas is awkwardly paced circuit storyh [SEP]']
[1950/2000] tot_loss=2.513 (perp=11.814, rec=0.150), tot_loss_proj:3.284 [t=0.26s]
prediction: ['[CLS] islights soapwasevicling is awkwardly paced circuit storyh [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.439 (perp=11.423, rec=0.154), tot_loss_proj:3.227 [t=0.25s]
prediction: ['[CLS] ish soapwasevic kansas is awkwardly paced circuit story hardly [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] isevic soapwash is oklahoma awkwardly paced circuit story hardly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.636 | p: 63.636 | r: 63.636
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 73.636

[Aggregate metrics]:
rouge1     | fm: 76.881 | p: 76.152 | r: 78.045
rouge2     | fm: 41.391 | p: 41.021 | r: 41.739
rougeL     | fm: 69.077 | p: 68.337 | r: 70.080
rougeLsum  | fm: 69.029 | p: 68.286 | r: 70.117
r1fm+r2fm = 118.272

input #60 time: 0:11:04 | total time: 11:15:09


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
cosin similarity: -0.8662755347520332 normalized error: 1.839448386591049
cosin similarity: 0.8662755347520332 normalized error: 0.4720166028736299
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 1.8395388486350686 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 1.7747550251026512 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 1.627125089526111 for ['[CLS] age bad link [SEP]']
[Init] best rec loss: 1.6162559336635822 for ['[CLS] maximus broken initiative [SEP]']
[Init] best rec loss: 1.3438386127527544 for ['[CLS] request lets mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.016 (perp=7.753, rec=0.465), tot_loss_proj:2.129 [t=0.27s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.934 (perp=8.033, rec=0.327), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 150/2000] tot_loss=1.909 (perp=8.033, rec=0.302), tot_loss_proj:1.950 [t=0.25s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 200/2000] tot_loss=1.896 (perp=8.033, rec=0.289), tot_loss_proj:1.950 [t=0.25s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.728 (perp=7.102, rec=0.308), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.714 (perp=7.102, rec=0.294), tot_loss_proj:1.905 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.715 (perp=7.102, rec=0.294), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.707 (perp=7.102, rec=0.287), tot_loss_proj:1.900 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.718 (perp=7.102, rec=0.298), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.707 (perp=7.102, rec=0.287), tot_loss_proj:1.908 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=7.102, rec=0.260), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.666 (perp=7.102, rec=0.246), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.675 (perp=7.102, rec=0.255), tot_loss_proj:1.905 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=7.102, rec=0.255), tot_loss_proj:1.900 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.669 (perp=7.102, rec=0.249), tot_loss_proj:1.908 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.668 (perp=7.102, rec=0.248), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.671 (perp=7.102, rec=0.251), tot_loss_proj:1.908 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.672 (perp=7.102, rec=0.252), tot_loss_proj:1.911 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.667 (perp=7.102, rec=0.247), tot_loss_proj:1.909 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.667 (perp=7.102, rec=0.247), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.659 (perp=7.102, rec=0.239), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.661 (perp=7.102, rec=0.241), tot_loss_proj:1.906 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.664 (perp=7.102, rec=0.244), tot_loss_proj:1.897 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.671 (perp=7.102, rec=0.251), tot_loss_proj:1.911 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.102, rec=0.248), tot_loss_proj:1.902 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.661 (perp=7.102, rec=0.241), tot_loss_proj:1.915 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.669 (perp=7.102, rec=0.249), tot_loss_proj:1.905 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.672 (perp=7.102, rec=0.252), tot_loss_proj:1.900 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.663 (perp=7.102, rec=0.243), tot_loss_proj:1.898 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.102, rec=0.247), tot_loss_proj:1.894 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.661 (perp=7.102, rec=0.241), tot_loss_proj:1.912 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=7.102, rec=0.254), tot_loss_proj:1.893 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.663 (perp=7.102, rec=0.243), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.655 (perp=7.102, rec=0.234), tot_loss_proj:1.896 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.662 (perp=7.102, rec=0.242), tot_loss_proj:1.908 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.664 (perp=7.102, rec=0.244), tot_loss_proj:1.903 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.666 (perp=7.102, rec=0.246), tot_loss_proj:1.906 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.664 (perp=7.102, rec=0.244), tot_loss_proj:1.902 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.663 (perp=7.102, rec=0.243), tot_loss_proj:1.898 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.654 (perp=7.102, rec=0.234), tot_loss_proj:1.909 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.320 | p: 76.529 | r: 78.347
rouge2     | fm: 42.295 | p: 41.961 | r: 42.695
rougeL     | fm: 69.621 | p: 68.852 | r: 70.553
rougeLsum  | fm: 69.476 | p: 68.748 | r: 70.471
r1fm+r2fm = 119.615

input #61 time: 0:11:05 | total time: 11:26:15


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
cosin similarity: 0.9025832287894447 normalized error: 0.4617084804268676
cosin similarity: -0.9025832287894446 normalized error: 1.8223670581393703
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 1.9297349250196945 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 1.8903897177075442 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 1.844699101257625 for ['[CLS] young dance sacrifice cross regular drove huffington trip client gloss chosen butte actually t running buywide sms custom floating mug [SEP]']
[Init] best rec loss: 1.7349761959658436 for ['[CLS] help rarely extensionbreaker local sea team mom beacon tear wax chairmanphstatic mum new osman intervention [CLS] attentionius [SEP]']
[Init] best rec loss: 1.7294749743744964 for ['[CLS]ftbytry unit bulls ibnuit graf model annabelle finhop type municipalityusing blooded prank ms advantage if stone [SEP]']
[Init] best rec loss: 1.7171115198947655 for ['[CLS] think jacented pac serial hardcover mini showcase commissioned they familiar cho tire buildings hands commerce indoor muscle funding best sac [SEP]']
[Init] best rec loss: 1.7157574469863874 for ['[CLS] such duo demand appeared being pv status stereotypes superlary eight song signage thing conform take pup i planetary feed free [SEP]']
[Init] best rec loss: 1.6609326681959053 for ['[CLS] ammunition nowheregut opinion deemed romansdong was mattered al body mono turkish abet main alone stations bag lead facebook [SEP]']
[Init] best perm rec loss: 1.6607041937562856 for ['[CLS] romans body opinion al lead abegut nowhere bag mattered deemedt turkishdong was alone ammunition mono stations main facebook [SEP]']
[Init] best perm rec loss: 1.6603711363279208 for ['[CLS] body romans mono main al was facebook abegutdong turkish stations opiniont nowhere bag lead ammunition mattered alone deemed [SEP]']
[Init] best perm rec loss: 1.6599393968141325 for ['[CLS] ammunitiontdong abe stations mattered mono alone turkish body facebook deemed opiniongut bag romans lead main nowhere was al [SEP]']
[Init] best perm rec loss: 1.6582424510254032 for ['[CLS] mono lead body main facebook stations alone bagt nowhere romans mattered deemed ammunition wasgut abedong turkish opinion al [SEP]']
[Init] best perm rec loss: 1.657107630088984 for ['[CLS] bag nowhere lead opinion mono romans turkish deemed matteredgut bodydong abe alone main stationst was ammunition al facebook [SEP]']
[Init] best perm rec loss: 1.6554196095583933 for ['[CLS] ammunition mono maint turkish abedong leadgut opinion mattered body bag nowhere facebook alone deemed stations romans al was [SEP]']
[Init] best perm rec loss: 1.654280861231804 for ['[CLS]dong stations mattered opinion deemed abe body turkish facebook romans mono ammunition alone nowheret al maingut was lead bag [SEP]']
[Init] best perm rec loss: 1.654129012955191 for ['[CLS] nowhere mono bagt abe mattereddong stations alonegut deemed body ammunition al lead turkish facebook opinion main romans was [SEP]']
[Init] best perm rec loss: 1.6539011960149457 for ['[CLS] nowhere body alonet mattered turkishdong facebook romans stations bag ammunition deemedgut al mono main lead abe opinion was [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.946 (perp=11.424, rec=0.661), tot_loss_proj:3.798 [t=0.26s]
prediction: ['[CLS] nothing empty lost dating gaulle national inappropriate discrimination tv. waste ammunition worse fiat. forced via so equipment experienced letters [SEP]']
[ 100/2000] tot_loss=2.881 (perp=11.493, rec=0.582), tot_loss_proj:3.953 [t=0.28s]
prediction: ['[CLS] seem barely lost dating gaulle to inappropriate discrimination sometimes catholic waste which worse outcome rarely any to hero camera concentration letters [SEP]']
[ 150/2000] tot_loss=3.491 (perp=13.407, rec=0.809), tot_loss_proj:4.385 [t=0.27s]
prediction: ['[CLS] brazilian barely lost rick gaulle behind uncomfortableoulos journalism catholic say there worse victory called anyque films camera gillespie anything [SEP]']
[ 200/2000] tot_loss=2.882 (perp=11.460, rec=0.590), tot_loss_proj:3.838 [t=0.26s]
prediction: ['[CLS] lie barely lost call goddamn to uncomfortable waste. ordained claim nothing neverho called treasure with so eating liquor food [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.628 (perp=10.440, rec=0.540), tot_loss_proj:3.646 [t=0.27s]
prediction: ['[CLS] lie barely was scheduled goddamn to uncomfortable waste. war say nothing only mara called any peace with so eating percentage [SEP]']
[ 300/2000] tot_loss=2.662 (perp=10.506, rec=0.560), tot_loss_proj:3.765 [t=0.26s]
prediction: ['[CLS] seem barely of to goddamn shooting classified waste, war prevent nothing only mara called any best with movies about percentage [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.473 (perp=9.819, rec=0.509), tot_loss_proj:3.774 [t=0.26s]
prediction: ['[CLS] seemhole of to prevent finest to classified waste, war nothing better mara called the best with movies about percentage [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.552 (perp=10.331, rec=0.486), tot_loss_proj:3.976 [t=0.27s]
prediction: ['[CLS] seem beside of to prevent finest to classified waste, war any nothing only mara and best with movies about legislation [SEP]']
[ 450/2000] tot_loss=2.486 (perp=9.939, rec=0.499), tot_loss_proj:3.703 [t=0.27s]
prediction: ['[CLS] seem barely of to prevent finest to classified waste, war riches criticism better mara and best with movies about legislation [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.367 (perp=9.368, rec=0.493), tot_loss_proj:3.655 [t=0.25s]
prediction: ['[CLS] grace barely of want to prevent best to classified coincidence lifestyle movies before better mara and best with movies about legislation [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.491 (perp=10.146, rec=0.462), tot_loss_proj:3.897 [t=0.27s]
prediction: ['[CLS] gracepromising of want to prevent best classified coincidence, movies beforeudence better mara up best with movies does legislation [SEP]']
[ 600/2000] tot_loss=2.357 (perp=9.477, rec=0.461), tot_loss_proj:3.817 [t=0.27s]
prediction: ['[CLS] gracepromising of want to than best classified coincidence, movies before to better mara and best with movies does legislation [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.438 (perp=9.950, rec=0.448), tot_loss_proj:3.873 [t=0.26s]
prediction: ['[CLS] gracepromising of want to best classified coincidence, war before to better prevent maraify best with movies ever legislation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.339 (perp=9.405, rec=0.458), tot_loss_proj:3.805 [t=0.27s]
prediction: ['[CLS] grace mara of want to best classified coincidence, movies before to better preventpromisingify best with movies ever legislation [SEP]']
[ 750/2000] tot_loss=2.445 (perp=9.790, rec=0.487), tot_loss_proj:3.876 [t=0.27s]
prediction: ['[CLS] grace mara of want to best classified coincidence, war before to better preventpromising be best with movies ever legislation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.277 (perp=9.241, rec=0.429), tot_loss_proj:3.738 [t=0.30s]
prediction: ['[CLS] grace mara of want to best classified coincidence, war before to better than highly best be with movies ever legislation [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.392 (perp=9.659, rec=0.461), tot_loss_proj:3.847 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best characterized coincidence, prevention before to better prevent highly best with movies ever legislation [SEP]']
[ 900/2000] tot_loss=2.231 (perp=8.998, rec=0.432), tot_loss_proj:3.597 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.226 (perp=8.998, rec=0.427), tot_loss_proj:3.598 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
[1000/2000] tot_loss=2.236 (perp=8.998, rec=0.437), tot_loss_proj:3.600 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
[1050/2000] tot_loss=2.215 (perp=8.998, rec=0.415), tot_loss_proj:3.595 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence, war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.199 (perp=8.964, rec=0.406), tot_loss_proj:3.545 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified, coincidence war before to better than highly best with movies ever legislation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.234 (perp=9.080, rec=0.418), tot_loss_proj:3.694 [t=0.28s]
prediction: ['[CLS] grace mara of want to be best classified before coincidence war, to better prevent highly best with movies ever legislation [SEP]']
[1200/2000] tot_loss=2.303 (perp=9.080, rec=0.487), tot_loss_proj:3.692 [t=0.25s]
prediction: ['[CLS] grace mara of want to be best classified before coincidence war, to better prevent highly best with movies ever legislation [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.223 (perp=9.048, rec=0.414), tot_loss_proj:3.702 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, to better prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1300/2000] tot_loss=2.270 (perp=9.319, rec=0.406), tot_loss_proj:3.811 [t=0.26s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1350/2000] tot_loss=2.279 (perp=9.319, rec=0.415), tot_loss_proj:3.813 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1400/2000] tot_loss=2.263 (perp=9.319, rec=0.399), tot_loss_proj:3.814 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1450/2000] tot_loss=2.270 (perp=9.319, rec=0.406), tot_loss_proj:3.808 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1500/2000] tot_loss=2.263 (perp=9.319, rec=0.399), tot_loss_proj:3.812 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1550/2000] tot_loss=2.256 (perp=9.319, rec=0.392), tot_loss_proj:3.810 [t=0.28s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1600/2000] tot_loss=2.328 (perp=9.336, rec=0.461), tot_loss_proj:3.797 [t=0.27s]
prediction: ['[CLS] grace mara of want to be best classified coincidence before war, into better prevent highly best with movies ever legislation [SEP]']
[1650/2000] tot_loss=2.314 (perp=9.524, rec=0.409), tot_loss_proj:3.834 [t=0.27s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1700/2000] tot_loss=2.312 (perp=9.524, rec=0.407), tot_loss_proj:3.834 [t=0.26s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1750/2000] tot_loss=2.302 (perp=9.524, rec=0.397), tot_loss_proj:3.834 [t=0.26s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1800/2000] tot_loss=2.301 (perp=9.524, rec=0.396), tot_loss_proj:3.834 [t=0.27s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1850/2000] tot_loss=2.297 (perp=9.524, rec=0.392), tot_loss_proj:3.833 [t=0.27s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[1900/2000] tot_loss=2.293 (perp=9.524, rec=0.388), tot_loss_proj:3.836 [t=0.26s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
[1950/2000] tot_loss=2.293 (perp=9.524, rec=0.388), tot_loss_proj:3.837 [t=0.28s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Attempt swap
[2000/2000] tot_loss=2.299 (perp=9.524, rec=0.394), tot_loss_proj:3.836 [t=0.27s]
prediction: ['[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] graceare of want to be best classified coincidence before war, into best prevent highly best with movies ever legislation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 37.209 | p: 38.095 | r: 36.364
rouge2     | fm: 4.878 | p: 5.000 | r: 4.762
rougeL     | fm: 32.558 | p: 33.333 | r: 31.818
rougeLsum  | fm: 32.558 | p: 33.333 | r: 31.818
r1fm+r2fm = 42.087

[Aggregate metrics]:
rouge1     | fm: 76.703 | p: 75.949 | r: 77.705
rouge2     | fm: 41.605 | p: 41.364 | r: 41.943
rougeL     | fm: 68.997 | p: 68.315 | r: 69.986
rougeLsum  | fm: 68.907 | p: 68.233 | r: 69.888
r1fm+r2fm = 118.307

input #62 time: 0:11:09 | total time: 11:37:24


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
cosin similarity: 0.888152152709799 normalized error: 0.5233351577081562
cosin similarity: -0.8881521527097989 normalized error: 1.6937379034861368
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 1.7797503937975239 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 1.3290306339774856 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 1.291038887418315 for ['[CLS] builder jumping timber nasal grant [SEP]']
[Init] best perm rec loss: 1.2905503176438675 for ['[CLS] jumping grant timber builder nasal [SEP]']
[Init] best perm rec loss: 1.2892315809817956 for ['[CLS] builder jumping nasal grant timber [SEP]']
[Init] best perm rec loss: 1.2890984321985854 for ['[CLS] nasal grant jumping timber builder [SEP]']
[Init] best perm rec loss: 1.2890506922916605 for ['[CLS] builder jumping grant timber nasal [SEP]']
[Init] best perm rec loss: 1.2881710746637853 for ['[CLS] grant builder jumping timber nasal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.945 (perp=12.652, rec=0.415), tot_loss_proj:3.775 [t=0.27s]
prediction: ['[CLS] return return ticket coward drug [SEP]']
[ 100/2000] tot_loss=2.650 (perp=12.060, rec=0.237), tot_loss_proj:3.386 [t=0.26s]
prediction: ['[CLS] return return ticket cr looking [SEP]']
[ 150/2000] tot_loss=2.562 (perp=11.972, rec=0.168), tot_loss_proj:3.755 [t=0.28s]
prediction: ['[CLS] pardon return ticket convey looking [SEP]']
[ 200/2000] tot_loss=2.405 (perp=11.318, rec=0.141), tot_loss_proj:3.688 [t=0.28s]
prediction: ['[CLS] upon return ticket cr looking [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.507 (perp=11.774, rec=0.152), tot_loss_proj:4.043 [t=0.27s]
prediction: ['[CLS] upon convey ticket return looking [SEP]']
[ 300/2000] tot_loss=2.492 (perp=11.774, rec=0.137), tot_loss_proj:4.045 [t=0.25s]
prediction: ['[CLS] upon convey ticket return looking [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.337 (perp=11.039, rec=0.129), tot_loss_proj:3.972 [t=0.27s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.964 [t=0.27s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 450/2000] tot_loss=2.331 (perp=11.039, rec=0.124), tot_loss_proj:3.969 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.332 (perp=11.039, rec=0.124), tot_loss_proj:3.968 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.326 (perp=11.039, rec=0.118), tot_loss_proj:3.972 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 600/2000] tot_loss=2.327 (perp=11.039, rec=0.119), tot_loss_proj:3.974 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.328 (perp=11.039, rec=0.121), tot_loss_proj:3.977 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.329 (perp=11.039, rec=0.122), tot_loss_proj:3.979 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 750/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.982 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.326 (perp=11.039, rec=0.118), tot_loss_proj:3.981 [t=0.27s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.327 (perp=11.039, rec=0.120), tot_loss_proj:3.980 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[ 900/2000] tot_loss=2.309 (perp=11.039, rec=0.101), tot_loss_proj:3.976 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.318 (perp=11.039, rec=0.111), tot_loss_proj:3.987 [t=0.28s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.322 (perp=11.039, rec=0.115), tot_loss_proj:3.979 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
[1050/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.980 [t=0.26s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.325 (perp=11.039, rec=0.117), tot_loss_proj:3.980 [t=0.25s]
prediction: ['[CLS] gi ticket upon return looking [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.055 (perp=9.624, rec=0.130), tot_loss_proj:2.670 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1200/2000] tot_loss=2.030 (perp=9.624, rec=0.105), tot_loss_proj:2.671 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=2.027 (perp=9.624, rec=0.102), tot_loss_proj:2.680 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=2.035 (perp=9.624, rec=0.110), tot_loss_proj:2.676 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1350/2000] tot_loss=2.042 (perp=9.624, rec=0.117), tot_loss_proj:2.675 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=2.024 (perp=9.624, rec=0.099), tot_loss_proj:2.677 [t=0.28s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=2.025 (perp=9.624, rec=0.100), tot_loss_proj:2.676 [t=0.28s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1500/2000] tot_loss=2.035 (perp=9.624, rec=0.111), tot_loss_proj:2.681 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=2.034 (perp=9.624, rec=0.109), tot_loss_proj:2.674 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=2.033 (perp=9.624, rec=0.108), tot_loss_proj:2.678 [t=0.29s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1650/2000] tot_loss=2.041 (perp=9.624, rec=0.116), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=2.031 (perp=9.624, rec=0.106), tot_loss_proj:2.673 [t=0.29s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=2.031 (perp=9.624, rec=0.107), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1800/2000] tot_loss=2.046 (perp=9.624, rec=0.121), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=2.028 (perp=9.624, rec=0.104), tot_loss_proj:2.677 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=2.046 (perp=9.624, rec=0.122), tot_loss_proj:2.685 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
[1950/2000] tot_loss=2.043 (perp=9.624, rec=0.118), tot_loss_proj:2.680 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=2.031 (perp=9.624, rec=0.106), tot_loss_proj:2.671 [t=0.27s]
prediction: ['[CLS] gi looking for return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] gi looking for return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 76.800 | p: 76.078 | r: 77.852
rouge2     | fm: 41.765 | p: 41.447 | r: 42.183
rougeL     | fm: 69.180 | p: 68.510 | r: 70.115
rougeLsum  | fm: 69.236 | p: 68.477 | r: 70.246
r1fm+r2fm = 118.565

input #63 time: 0:11:03 | total time: 11:48:28


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
cosin similarity: 0.8897437545542236 normalized error: 0.4919963179002097
cosin similarity: -0.8897437545542237 normalized error: 1.7631371733077217
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 1.874859259969168 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 1.8443270537702192 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 1.8210097990032375 for ['[CLS]bled independence clearing [SEP]']
[Init] best rec loss: 1.5310293456421353 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 1.494383521887698 for ['[CLS] spends adrian mating [SEP]']
[Init] best rec loss: 1.3013654423332823 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 1.2933210474211365 for ['[CLS] water visionsonale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.034 (perp=8.505, rec=0.333), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] horror horror horror [SEP]']
[ 100/2000] tot_loss=1.953 (perp=8.653, rec=0.223), tot_loss_proj:2.226 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.928 (perp=8.653, rec=0.198), tot_loss_proj:2.219 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.910 (perp=8.653, rec=0.179), tot_loss_proj:2.222 [t=0.27s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.281 (perp=10.235, rec=0.234), tot_loss_proj:2.907 [t=0.27s]
prediction: ['[CLS] strange covent horror [SEP]']
[ 300/2000] tot_loss=2.331 (perp=10.705, rec=0.190), tot_loss_proj:3.125 [t=0.25s]
prediction: ['[CLS] strange allegro horror [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.200 (perp=10.131, rec=0.174), tot_loss_proj:3.362 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.188 (perp=10.131, rec=0.162), tot_loss_proj:3.362 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 450/2000] tot_loss=2.190 (perp=10.131, rec=0.164), tot_loss_proj:3.374 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.179 (perp=10.131, rec=0.153), tot_loss_proj:3.361 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.185 (perp=10.131, rec=0.158), tot_loss_proj:3.361 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 600/2000] tot_loss=2.172 (perp=10.131, rec=0.146), tot_loss_proj:3.361 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.175 (perp=10.131, rec=0.149), tot_loss_proj:3.360 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.168 (perp=10.131, rec=0.141), tot_loss_proj:3.355 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 750/2000] tot_loss=2.183 (perp=10.131, rec=0.157), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.169 (perp=10.131, rec=0.142), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.167 (perp=10.131, rec=0.141), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
[ 900/2000] tot_loss=2.172 (perp=10.131, rec=0.146), tot_loss_proj:3.363 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.177 (perp=10.131, rec=0.151), tot_loss_proj:3.354 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1000/2000] tot_loss=2.168 (perp=10.131, rec=0.142), tot_loss_proj:3.359 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1050/2000] tot_loss=2.177 (perp=10.131, rec=0.150), tot_loss_proj:3.357 [t=0.29s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1100/2000] tot_loss=2.159 (perp=10.131, rec=0.132), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1150/2000] tot_loss=2.169 (perp=10.131, rec=0.143), tot_loss_proj:3.358 [t=0.29s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1200/2000] tot_loss=2.165 (perp=10.131, rec=0.138), tot_loss_proj:3.355 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1250/2000] tot_loss=2.168 (perp=10.131, rec=0.142), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1300/2000] tot_loss=2.162 (perp=10.131, rec=0.136), tot_loss_proj:3.352 [t=0.28s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1350/2000] tot_loss=2.159 (perp=10.131, rec=0.132), tot_loss_proj:3.360 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1400/2000] tot_loss=2.171 (perp=10.131, rec=0.145), tot_loss_proj:3.359 [t=0.28s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1450/2000] tot_loss=2.163 (perp=10.131, rec=0.136), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1500/2000] tot_loss=2.176 (perp=10.131, rec=0.150), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1550/2000] tot_loss=2.163 (perp=10.131, rec=0.137), tot_loss_proj:3.349 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1600/2000] tot_loss=2.169 (perp=10.131, rec=0.143), tot_loss_proj:3.355 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1650/2000] tot_loss=2.166 (perp=10.131, rec=0.140), tot_loss_proj:3.357 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1700/2000] tot_loss=2.172 (perp=10.131, rec=0.146), tot_loss_proj:3.356 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1750/2000] tot_loss=2.167 (perp=10.131, rec=0.141), tot_loss_proj:3.354 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1800/2000] tot_loss=2.160 (perp=10.131, rec=0.134), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1850/2000] tot_loss=2.164 (perp=10.131, rec=0.138), tot_loss_proj:3.361 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[1900/2000] tot_loss=2.171 (perp=10.131, rec=0.145), tot_loss_proj:3.351 [t=0.26s]
prediction: ['[CLS] strange horror allegro [SEP]']
[1950/2000] tot_loss=2.167 (perp=10.131, rec=0.141), tot_loss_proj:3.357 [t=0.27s]
prediction: ['[CLS] strange horror allegro [SEP]']
Attempt swap
[2000/2000] tot_loss=2.180 (perp=10.131, rec=0.154), tot_loss_proj:3.354 [t=0.25s]
prediction: ['[CLS] strange horror allegro [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] strange horror allegro [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 76.996 | p: 76.274 | r: 77.971
rouge2     | fm: 41.837 | p: 41.549 | r: 42.140
rougeL     | fm: 69.444 | p: 68.814 | r: 70.383
rougeLsum  | fm: 69.493 | p: 68.731 | r: 70.440
r1fm+r2fm = 118.833

input #64 time: 0:11:03 | total time: 11:59:31


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
cosin similarity: -0.7178626049650516 normalized error: 1.7401795652390009
cosin similarity: 0.7178626049650515 normalized error: 0.5840441504396936
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.9870089554648294 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 1.9474131842984503 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 1.9100810061921827 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 1.8980951205333114 for ['[CLS] boss sucks goodbye poorlyions palestinianquest languagecliff [SEP]']
[Init] best rec loss: 1.8612592084697668 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 1.8289708508068814 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 1.7890262914226829 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 1.7827283867301924 for ['[CLS] butter memorandumece happy cry laurence cum york accept [SEP]']
[Init] best rec loss: 1.7013185811690277 for ['[CLS] forth drag roger choice rival familiar howellacingbies [SEP]']
[Init] best rec loss: 1.611037256349526 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best rec loss: 1.600135033832928 for ['[CLS] azerbaijan [ son ram propaganda spec hispanic on pads [SEP]']
[Init] best perm rec loss: 1.5971897279734137 for ['[CLS] on spec ram son propaganda azerbaijan hispanic pads [ [SEP]']
[Init] best perm rec loss: 1.5961415223902815 for ['[CLS] hispanic azerbaijan pads son propaganda [ spec on ram [SEP]']
[Init] best perm rec loss: 1.591742310602796 for ['[CLS] hispanic son azerbaijan ram spec pads [ on propaganda [SEP]']
[Init] best perm rec loss: 1.5908092231806066 for ['[CLS] hispanic ram spec son azerbaijan pads [ on propaganda [SEP]']
[Init] best perm rec loss: 1.5899510036100943 for ['[CLS] hispanic ram pads propaganda son [ azerbaijan on spec [SEP]']
[Init] best perm rec loss: 1.5883142124459069 for ['[CLS] pads azerbaijan son ram spec propaganda [ on hispanic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.560 (perp=10.330, rec=0.494), tot_loss_proj:3.134 [t=0.26s]
prediction: ['[CLS] sessions joy : joy halle and :a sea [SEP]']
[ 100/2000] tot_loss=2.560 (perp=10.907, rec=0.379), tot_loss_proj:3.629 [t=0.27s]
prediction: ['[CLS] wife joyousous dialectsous : out women [SEP]']
[ 150/2000] tot_loss=2.793 (perp=12.342, rec=0.325), tot_loss_proj:4.047 [t=0.27s]
prediction: ['[CLS] courts joyousous dialectsous : out golf [SEP]']
[ 200/2000] tot_loss=2.283 (perp=10.037, rec=0.276), tot_loss_proj:3.613 [t=0.26s]
prediction: ['[CLS] windmill joyousous romous. a film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.945 (perp=8.302, rec=0.284), tot_loss_proj:3.470 [t=0.25s]
prediction: ['[CLS] windmill joyous. confusionous. film film [SEP]']
[ 300/2000] tot_loss=2.080 (perp=9.196, rec=0.240), tot_loss_proj:3.710 [t=0.26s]
prediction: ['[CLS] fernandez joyous ; confusionous.med film [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.054 (perp=9.175, rec=0.219), tot_loss_proj:2.801 [t=0.26s]
prediction: ['[CLS] fernandez joyous, literous film. rom [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.986 (perp=8.729, rec=0.240), tot_loss_proj:2.853 [t=0.27s]
prediction: ['[CLS] fernandez joyous, literous rom a. [SEP]']
[ 450/2000] tot_loss=1.960 (perp=8.729, rec=0.215), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] fernandez joyous, literous rom a. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.917 (perp=8.507, rec=0.215), tot_loss_proj:2.615 [t=0.26s]
prediction: ['[CLS] film joyous, literous rom fernandez. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.229 (perp=10.092, rec=0.211), tot_loss_proj:3.217 [t=0.26s]
prediction: ['[CLS] film joyous, literouscased rom fernandez [SEP]']
[ 600/2000] tot_loss=2.331 (perp=10.624, rec=0.206), tot_loss_proj:3.266 [t=0.25s]
prediction: ['[CLS] film joyous, literous offs rom fernandez [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.645 (perp=12.177, rec=0.210), tot_loss_proj:4.244 [t=0.27s]
prediction: ['[CLS] film joy rom, liter offsous rom fernandez [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.334 (perp=10.527, rec=0.229), tot_loss_proj:3.368 [t=0.27s]
prediction: ['[CLS] film rom, liter offs joyous rom fernandez [SEP]']
[ 750/2000] tot_loss=2.315 (perp=10.527, rec=0.210), tot_loss_proj:3.354 [t=0.27s]
prediction: ['[CLS] film rom, liter offs joyous rom fernandez [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.347 (perp=10.717, rec=0.204), tot_loss_proj:3.505 [t=0.26s]
prediction: ['[CLS] filmcased, liter rom joyous rom fernandez [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.138 (perp=9.674, rec=0.203), tot_loss_proj:3.254 [t=0.27s]
prediction: ['[CLS] film rom, litercased joyous rom fernandez [SEP]']
[ 900/2000] tot_loss=2.317 (perp=10.527, rec=0.212), tot_loss_proj:3.361 [t=0.27s]
prediction: ['[CLS] film rom, liter offs joyous rom fernandez [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.188 (perp=9.951, rec=0.197), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS] film rom offs, liter joyous rom fernandez [SEP]']
Attempt swap
[1000/2000] tot_loss=2.185 (perp=9.951, rec=0.195), tot_loss_proj:3.458 [t=0.27s]
prediction: ['[CLS] film rom offs, liter joyous rom fernandez [SEP]']
[1050/2000] tot_loss=2.185 (perp=9.951, rec=0.195), tot_loss_proj:3.455 [t=0.27s]
prediction: ['[CLS] film rom offs, liter joyous rom fernandez [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.207 (perp=10.022, rec=0.203), tot_loss_proj:3.481 [t=0.26s]
prediction: ['[CLS] film rom consisting, fernandez joyous rom liter [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.087 (perp=9.430, rec=0.201), tot_loss_proj:3.554 [t=0.25s]
prediction: ['[CLS] film rom, consisting beer joyous rom liter [SEP]']
[1200/2000] tot_loss=2.082 (perp=9.430, rec=0.196), tot_loss_proj:3.563 [t=0.27s]
prediction: ['[CLS] film rom, consisting beer joyous rom liter [SEP]']
Attempt swap
[1250/2000] tot_loss=2.082 (perp=9.430, rec=0.196), tot_loss_proj:3.558 [t=0.28s]
prediction: ['[CLS] film rom, consisting beer joyous rom liter [SEP]']
Attempt swap
[1300/2000] tot_loss=2.160 (perp=9.820, rec=0.196), tot_loss_proj:3.791 [t=0.26s]
prediction: ['[CLS] film rom, offs beer joyous rom liter [SEP]']
[1350/2000] tot_loss=2.157 (perp=9.820, rec=0.193), tot_loss_proj:3.783 [t=0.26s]
prediction: ['[CLS] film rom, offs beer joyous rom liter [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.148 (perp=9.722, rec=0.203), tot_loss_proj:3.677 [t=0.27s]
prediction: ['[CLS] film rom offs, beer joyous rom liter [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.021 (perp=9.104, rec=0.200), tot_loss_proj:3.553 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
[1500/2000] tot_loss=2.014 (perp=9.104, rec=0.193), tot_loss_proj:3.553 [t=0.25s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[1550/2000] tot_loss=2.009 (perp=9.104, rec=0.188), tot_loss_proj:3.557 [t=0.27s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[1600/2000] tot_loss=2.011 (perp=9.104, rec=0.190), tot_loss_proj:3.554 [t=0.27s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
[1650/2000] tot_loss=2.017 (perp=9.104, rec=0.196), tot_loss_proj:3.555 [t=0.25s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[1700/2000] tot_loss=2.013 (perp=9.104, rec=0.192), tot_loss_proj:3.554 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[1750/2000] tot_loss=2.014 (perp=9.104, rec=0.193), tot_loss_proj:3.554 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
[1800/2000] tot_loss=2.010 (perp=9.104, rec=0.189), tot_loss_proj:3.556 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[1850/2000] tot_loss=2.016 (perp=9.104, rec=0.195), tot_loss_proj:3.554 [t=0.30s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[1900/2000] tot_loss=2.020 (perp=9.104, rec=0.199), tot_loss_proj:3.553 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
[1950/2000] tot_loss=2.006 (perp=9.104, rec=0.185), tot_loss_proj:3.557 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Attempt swap
[2000/2000] tot_loss=2.011 (perp=9.104, rec=0.190), tot_loss_proj:3.553 [t=0.26s]
prediction: ['[CLS] film rom offs, rom joyous beer liter [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] film rom offs, rom joyous beer liter [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 44.444 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 37.500 | p: 33.333 | r: 42.857
rougeLsum  | fm: 37.500 | p: 33.333 | r: 42.857
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 76.529 | p: 75.726 | r: 77.660
rouge2     | fm: 41.021 | p: 40.728 | r: 41.355
rougeL     | fm: 69.003 | p: 68.286 | r: 69.959
rougeLsum  | fm: 68.923 | p: 68.141 | r: 69.988
r1fm+r2fm = 117.550

input #65 time: 0:11:02 | total time: 12:10:34


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
cosin similarity: -0.9602693402946472 normalized error: 1.8654588241675922
cosin similarity: 0.9602693402946472 normalized error: 0.41839710947482045
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 1.9293739671387775 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 1.8552600330721851 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 1.830793744364479 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 1.761128777721764 for ['[CLS] school divisional labor liberals [SEP]']
[Init] best rec loss: 1.7438727355052204 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 1.5280836521470906 for ['[CLS] space leader screen [CLS] [SEP]']
[Init] best rec loss: 1.4192977185046012 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 1.2415355689949863 for ['[CLS] finish eachensis clark [SEP]']
[Init] best perm rec loss: 1.2339681075273201 for ['[CLS] each clarkensis finish [SEP]']
[Init] best perm rec loss: 1.2306118275322921 for ['[CLS]ensis clark each finish [SEP]']
[Init] best perm rec loss: 1.2279674772229399 for ['[CLS] eachensis clark finish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.069 (perp=13.377, rec=0.393), tot_loss_proj:3.406 [t=0.25s]
prediction: ['[CLS] firmly fan tolkien loved [SEP]']
[ 100/2000] tot_loss=2.056 (perp=9.181, rec=0.220), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 150/2000] tot_loss=2.008 (perp=9.181, rec=0.172), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 200/2000] tot_loss=1.997 (perp=9.181, rec=0.161), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.975 (perp=9.181, rec=0.139), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 300/2000] tot_loss=1.986 (perp=9.181, rec=0.150), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.982 (perp=9.181, rec=0.146), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.181, rec=0.130), tot_loss_proj:2.442 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 450/2000] tot_loss=1.981 (perp=9.181, rec=0.145), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.181, rec=0.135), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.966 (perp=9.181, rec=0.130), tot_loss_proj:2.447 [t=0.28s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.181, rec=0.139), tot_loss_proj:2.444 [t=0.29s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.963 (perp=9.181, rec=0.126), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.973 (perp=9.181, rec=0.137), tot_loss_proj:2.442 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 750/2000] tot_loss=1.971 (perp=9.181, rec=0.135), tot_loss_proj:2.444 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.955 (perp=9.181, rec=0.119), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.973 (perp=9.181, rec=0.137), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 900/2000] tot_loss=1.968 (perp=9.181, rec=0.131), tot_loss_proj:2.448 [t=0.28s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.973 (perp=9.181, rec=0.137), tot_loss_proj:2.457 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.967 (perp=9.181, rec=0.131), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1050/2000] tot_loss=1.962 (perp=9.181, rec=0.126), tot_loss_proj:2.446 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.957 (perp=9.181, rec=0.121), tot_loss_proj:2.447 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.977 (perp=9.181, rec=0.140), tot_loss_proj:2.443 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1200/2000] tot_loss=1.957 (perp=9.181, rec=0.121), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.970 (perp=9.181, rec=0.134), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.970 (perp=9.181, rec=0.134), tot_loss_proj:2.449 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1350/2000] tot_loss=1.961 (perp=9.181, rec=0.125), tot_loss_proj:2.443 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.957 (perp=9.181, rec=0.121), tot_loss_proj:2.447 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.963 (perp=9.181, rec=0.126), tot_loss_proj:2.448 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1500/2000] tot_loss=1.980 (perp=9.181, rec=0.144), tot_loss_proj:2.446 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=9.181, rec=0.125), tot_loss_proj:2.450 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.963 (perp=9.181, rec=0.127), tot_loss_proj:2.452 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1650/2000] tot_loss=1.952 (perp=9.181, rec=0.116), tot_loss_proj:2.451 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.961 (perp=9.181, rec=0.125), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.964 (perp=9.181, rec=0.128), tot_loss_proj:2.453 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1800/2000] tot_loss=1.968 (perp=9.181, rec=0.131), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.965 (perp=9.181, rec=0.128), tot_loss_proj:2.449 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.972 (perp=9.181, rec=0.136), tot_loss_proj:2.447 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1950/2000] tot_loss=1.967 (perp=9.181, rec=0.131), tot_loss_proj:2.445 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.964 (perp=9.181, rec=0.128), tot_loss_proj:2.450 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] longtime tolkien tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 143.333

[Aggregate metrics]:
rouge1     | fm: 76.644 | p: 75.852 | r: 77.721
rouge2     | fm: 41.417 | p: 41.074 | r: 41.854
rougeL     | fm: 69.208 | p: 68.582 | r: 70.215
rougeLsum  | fm: 69.142 | p: 68.394 | r: 70.230
r1fm+r2fm = 118.062

input #66 time: 0:11:01 | total time: 12:21:35


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
cosin similarity: 0.7089905831605775 normalized error: 0.5944421463060496
cosin similarity: -0.7089905831605776 normalized error: 1.7213575612207523
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.9019336303075132 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 1.8874165011503248 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 1.8292298942130991 for ['[CLS] gilbert bid released wonder needmeral historic comes repeatedly judgement [SEP]']
[Init] best rec loss: 1.825638881381011 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 1.780216453237748 for ['[CLS] flag fig before gordon quinlantop now seryu power [SEP]']
[Init] best rec loss: 1.7559918468609501 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 1.679376791758767 for ['[CLS] begunpile nbc united " by threatened found chryslereira [SEP]']
[Init] best perm rec loss: 1.6751465134697887 for ['[CLS] by "eira unitedpile chrysler threatened begun found nbc [SEP]']
[Init] best perm rec loss: 1.6688508244037252 for ['[CLS] nbc unitedpile begun found threatenedeira chrysler by " [SEP]']
[Init] best perm rec loss: 1.6635629728852337 for ['[CLS] threatenedpile found by nbc begun united chrysler "eira [SEP]']
[Init] best perm rec loss: 1.653727823458465 for ['[CLS] nbc threatened begun bypile chrysler found united "eira [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.228 (perp=13.679, rec=0.492), tot_loss_proj:4.546 [t=0.26s]
prediction: ['[CLS] admiredmo burn kinding, awayine brownish tradition [SEP]']
[ 100/2000] tot_loss=3.217 (perp=14.098, rec=0.398), tot_loss_proj:4.363 [t=0.27s]
prediction: ['[CLS] heartmo fire kinding kindtativeine rhode kind [SEP]']
[ 150/2000] tot_loss=3.509 (perp=15.789, rec=0.351), tot_loss_proj:4.669 [t=0.26s]
prediction: ['[CLS] heartmo visible kindpre kindtativent rhode kind [SEP]']
[ 200/2000] tot_loss=2.835 (perp=12.474, rec=0.340), tot_loss_proj:4.276 [t=0.25s]
prediction: ['[CLS] heartwar non kindwar kindtativent stack kind [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.078 (perp=13.489, rec=0.380), tot_loss_proj:3.927 [t=0.27s]
prediction: ['[CLS] kind heartwar animalspre kindbekuous galerie kind [SEP]']
[ 300/2000] tot_loss=2.858 (perp=12.736, rec=0.310), tot_loss_proj:3.700 [t=0.27s]
prediction: ['[CLS] kind heartwar animalspre kind fourieruousm kind [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.472 (perp=10.872, rec=0.298), tot_loss_proj:3.516 [t=0.25s]
prediction: ['[CLS] kind heartwarwar non kind fourierentalm kind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.824 (perp=12.645, rec=0.295), tot_loss_proj:3.886 [t=0.29s]
prediction: ['[CLS] kind heartwarwar trade kind fourierentalang kind [SEP]']
[ 450/2000] tot_loss=2.826 (perp=12.766, rec=0.273), tot_loss_proj:4.085 [t=0.26s]
prediction: ['[CLS] kind heartwarwar trade kindentationentalang kind [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.505 (perp=11.186, rec=0.268), tot_loss_proj:3.594 [t=0.26s]
prediction: ['[CLS] kind heartwarwarang kindentationental representation kind [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.441 (perp=10.902, rec=0.261), tot_loss_proj:3.540 [t=0.26s]
prediction: ['[CLS] kind heartwarwarang kindentationental kind representation [SEP]']
[ 600/2000] tot_loss=2.416 (perp=10.799, rec=0.256), tot_loss_proj:3.523 [t=0.29s]
prediction: ['[CLS] kind heartwarwarental kindentationental kind representation [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.598 (perp=11.769, rec=0.244), tot_loss_proj:3.700 [t=0.30s]
prediction: ['[CLS] kind heartwarpl non kindentationental kind representation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.476 (perp=11.109, rec=0.254), tot_loss_proj:3.618 [t=0.30s]
prediction: ['[CLS] kind heartwar nonwar kindentationental kind representation [SEP]']
[ 750/2000] tot_loss=2.393 (perp=10.725, rec=0.248), tot_loss_proj:3.667 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpl kindentationental kind representation [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.296 (perp=10.232, rec=0.250), tot_loss_proj:3.400 [t=0.32s]
prediction: ['[CLS] kind heartwar nonpreentation kindental kind representation [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.246 (perp=9.977, rec=0.251), tot_loss_proj:3.327 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreentation kindental representation kind [SEP]']
[ 900/2000] tot_loss=2.229 (perp=9.977, rec=0.234), tot_loss_proj:3.333 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpreentation kindental representation kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.222 (perp=9.977, rec=0.227), tot_loss_proj:3.334 [t=0.31s]
prediction: ['[CLS] kind heartwar nonpreentation kindental representation kind [SEP]']
Attempt swap
[1000/2000] tot_loss=2.230 (perp=9.977, rec=0.234), tot_loss_proj:3.328 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreentation kindental representation kind [SEP]']
[1050/2000] tot_loss=2.395 (perp=10.812, rec=0.233), tot_loss_proj:3.322 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpreentation kindental prose kind [SEP]']
Attempt swap
[1100/2000] tot_loss=2.385 (perp=10.812, rec=0.222), tot_loss_proj:3.329 [t=0.28s]
prediction: ['[CLS] kind heartwar nonpreentation kindental prose kind [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.319 (perp=10.426, rec=0.234), tot_loss_proj:3.260 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
[1200/2000] tot_loss=2.317 (perp=10.426, rec=0.232), tot_loss_proj:3.262 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1250/2000] tot_loss=2.307 (perp=10.426, rec=0.222), tot_loss_proj:3.262 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1300/2000] tot_loss=2.298 (perp=10.426, rec=0.213), tot_loss_proj:3.261 [t=0.32s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
[1350/2000] tot_loss=2.307 (perp=10.426, rec=0.222), tot_loss_proj:3.259 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1400/2000] tot_loss=2.306 (perp=10.426, rec=0.221), tot_loss_proj:3.263 [t=0.31s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1450/2000] tot_loss=2.297 (perp=10.426, rec=0.211), tot_loss_proj:3.261 [t=0.31s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
[1500/2000] tot_loss=2.310 (perp=10.426, rec=0.224), tot_loss_proj:3.261 [t=0.31s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1550/2000] tot_loss=2.304 (perp=10.426, rec=0.219), tot_loss_proj:3.258 [t=0.32s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1600/2000] tot_loss=2.309 (perp=10.426, rec=0.224), tot_loss_proj:3.262 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
[1650/2000] tot_loss=2.293 (perp=10.426, rec=0.207), tot_loss_proj:3.259 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1700/2000] tot_loss=2.298 (perp=10.426, rec=0.213), tot_loss_proj:3.259 [t=0.31s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1750/2000] tot_loss=2.300 (perp=10.426, rec=0.214), tot_loss_proj:3.259 [t=0.30s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
[1800/2000] tot_loss=2.290 (perp=10.426, rec=0.204), tot_loss_proj:3.263 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1850/2000] tot_loss=2.297 (perp=10.426, rec=0.211), tot_loss_proj:3.258 [t=0.29s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[1900/2000] tot_loss=2.301 (perp=10.426, rec=0.216), tot_loss_proj:3.258 [t=0.27s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
[1950/2000] tot_loss=2.299 (perp=10.426, rec=0.214), tot_loss_proj:3.262 [t=0.26s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Attempt swap
[2000/2000] tot_loss=2.294 (perp=10.426, rec=0.209), tot_loss_proj:3.259 [t=0.27s]
prediction: ['[CLS] kind heartwar nonpreental kindentation prose kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwar nonpreental kindentation prose kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.154 | p: 37.500 | r: 60.000
rouge2     | fm: 18.182 | p: 14.286 | r: 25.000
rougeL     | fm: 46.154 | p: 37.500 | r: 60.000
rougeLsum  | fm: 46.154 | p: 37.500 | r: 60.000
r1fm+r2fm = 64.336

[Aggregate metrics]:
rouge1     | fm: 76.221 | p: 75.279 | r: 77.520
rouge2     | fm: 41.082 | p: 40.736 | r: 41.459
rougeL     | fm: 68.822 | p: 68.059 | r: 69.894
rougeLsum  | fm: 68.854 | p: 68.066 | r: 70.015
r1fm+r2fm = 117.303

input #67 time: 0:11:42 | total time: 12:33:18


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
cosin similarity: 0.7579495317309078 normalized error: 0.5776880740757563
cosin similarity: -0.7579495317309077 normalized error: 1.6929431386951
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 1.9657990800754686 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 1.9501012528180102 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 1.6962652211121043 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 1.6522055010135488 for ['[CLS] °f force recreationalyde fighting extras who livestock guaranteed singles short gloves kitchen [SEP]']
[Init] best rec loss: 1.5646755629566675 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 1.538578854057068 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 1.3437515453656923 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 1.3302574243545204 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 1.325828912316945 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 1.3252527725086232 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 1.3224238790825233 for ['[CLS] possiblyiferous. diedyn beth riding medal councils view comfort floor form [SEP]']
[Init] best perm rec loss: 1.3208041965922868 for ['[CLS] died formyniferous comfort. floor possibly medal view beth riding councils [SEP]']
[Init] best perm rec loss: 1.3203076751432896 for ['[CLS]iferous comfort form ridingyn possibly. beth medal floor died councils view [SEP]']
[Init] best perm rec loss: 1.3171426193111844 for ['[CLS] bethyn comfort.iferous medal councils riding floor form possibly view died [SEP]']
[Init] best perm rec loss: 1.3160534941905848 for ['[CLS] beth comfortiferousyn. possibly form councils riding floor medal view died [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.854 (perp=12.689, rec=0.316), tot_loss_proj:3.605 [t=0.25s]
prediction: ['[CLS] confrontation cavity down and absurd any stunt absurd registry fake cmll vicious constructed [SEP]']
[ 100/2000] tot_loss=2.523 (perp=11.497, rec=0.224), tot_loss_proj:3.340 [t=0.26s]
prediction: ['[CLS] un org down and absurd patients stunt absurd edition ridiculous ncaa vicious constructed [SEP]']
[ 150/2000] tot_loss=2.588 (perp=11.966, rec=0.195), tot_loss_proj:3.453 [t=0.26s]
prediction: ['[CLS] unrcleial and absurd patients stunts absurd edition absurd ncaa viciousnal [SEP]']
[ 200/2000] tot_loss=2.517 (perp=11.689, rec=0.180), tot_loss_proj:3.325 [t=0.26s]
prediction: ['[CLS] unsibleuth and absurdrebolt absurd idiot absurd ncaa viciousnal [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.733 (perp=12.563, rec=0.220), tot_loss_proj:3.521 [t=0.29s]
prediction: ['[CLS] unsibleuth, absurd absurd own undonenson resulting ncaa vicious progress [SEP]']
[ 300/2000] tot_loss=2.685 (perp=12.600, rec=0.165), tot_loss_proj:3.539 [t=0.29s]
prediction: ['[CLS] unsibleuth and absurd absurd own unnoticednson resulting saxon viciousact [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.616 (perp=12.269, rec=0.162), tot_loss_proj:3.462 [t=0.30s]
prediction: ['[CLS] unsibleuth and resulting absurd absurd own unnoticednsonpala viciousact [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.299 (perp=10.633, rec=0.173), tot_loss_proj:3.089 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd absurd idiot unnoticed papuapala vicioussible [SEP]']
[ 450/2000] tot_loss=2.212 (perp=10.329, rec=0.146), tot_loss_proj:3.013 [t=0.26s]
prediction: ['[CLS] uncouth and extremely absurd absurd idiot pregnancynsonpala vicioussible [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.119 (perp=9.815, rec=0.156), tot_loss_proj:2.922 [t=0.26s]
prediction: ['[CLS] uncouth and extremely absurd absurd idiotsible recorded pregnancy vicioussible [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.163 (perp=10.036, rec=0.156), tot_loss_proj:3.071 [t=0.25s]
prediction: ['[CLS] uncouth and extremely absurd absurd pregnancysible recorded lacked vicioussible [SEP]']
[ 600/2000] tot_loss=2.302 (perp=10.819, rec=0.138), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] uncouth andeft absurd absurd pregnancysible recorded lacked vicioussible [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.274 (perp=10.677, rec=0.138), tot_loss_proj:3.217 [t=0.27s]
prediction: ['[CLS] uncouth and absurd absurdeft unnoticedsibleco lacked vicioussible [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.118 (perp=9.894, rec=0.139), tot_loss_proj:2.987 [t=0.28s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeftsible recorded idiot vicioussible [SEP]']
[ 750/2000] tot_loss=2.200 (perp=10.320, rec=0.136), tot_loss_proj:2.995 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeftsibleco idiot vicioussible [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.130 (perp=9.960, rec=0.138), tot_loss_proj:2.922 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeftcosible idiot vicioussible [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.108 (perp=9.924, rec=0.123), tot_loss_proj:2.938 [t=0.27s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedcheftsible idiot vicioussible [SEP]']
[ 900/2000] tot_loss=2.123 (perp=9.924, rec=0.138), tot_loss_proj:2.944 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedcheftsible idiot vicioussible [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.166 (perp=10.174, rec=0.131), tot_loss_proj:3.036 [t=0.27s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeftsible idiot kramer vicioussible [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.125 (perp=9.977, rec=0.130), tot_loss_proj:2.936 [t=0.25s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramersible idiot vicioussible [SEP]']
[1050/2000] tot_loss=2.117 (perp=9.977, rec=0.121), tot_loss_proj:2.933 [t=0.29s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramersible idiot vicioussible [SEP]']
Attempt swap
[1100/2000] tot_loss=2.135 (perp=10.038, rec=0.127), tot_loss_proj:3.018 [t=0.25s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramersible proved vicioussible [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.299 (perp=10.841, rec=0.130), tot_loss_proj:3.146 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeftsible kramer idiot vicioussible [SEP]']
[1200/2000] tot_loss=2.310 (perp=10.879, rec=0.134), tot_loss_proj:3.130 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeftsible kramer proved vicioushen [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.978 (perp=9.194, rec=0.140), tot_loss_proj:2.748 [t=0.25s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=9.194, rec=0.125), tot_loss_proj:2.747 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
[1350/2000] tot_loss=1.959 (perp=9.194, rec=0.121), tot_loss_proj:2.749 [t=0.25s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
Attempt swap
[1400/2000] tot_loss=1.956 (perp=9.194, rec=0.118), tot_loss_proj:2.757 [t=0.29s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
Attempt swap
[1450/2000] tot_loss=1.955 (perp=9.194, rec=0.116), tot_loss_proj:2.744 [t=0.27s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
[1500/2000] tot_loss=1.951 (perp=9.194, rec=0.113), tot_loss_proj:2.756 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
Attempt swap
[1550/2000] tot_loss=1.968 (perp=9.194, rec=0.129), tot_loss_proj:2.746 [t=0.27s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.962 (perp=9.194, rec=0.124), tot_loss_proj:2.753 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd unnoticedeft kramer proved vicioushensible [SEP]']
[1650/2000] tot_loss=2.059 (perp=9.639, rec=0.131), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] uncouth and absurd absurd indiraeft kramer proved vicioushensible [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.963 (perp=9.165, rec=0.130), tot_loss_proj:2.783 [t=0.28s]
prediction: ['[CLS] uncouth and absurd absurd indira kramereft proved vicioushensible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.955 (perp=9.165, rec=0.122), tot_loss_proj:2.778 [t=0.27s]
prediction: ['[CLS] uncouth and absurd absurd indira kramereft proved vicioushensible [SEP]']
[1800/2000] tot_loss=2.044 (perp=9.560, rec=0.132), tot_loss_proj:2.908 [t=0.26s]
prediction: ['[CLS] uncouth and absurdsible indira kramereft proved vicioushensible [SEP]']
Attempt swap
[1850/2000] tot_loss=2.038 (perp=9.560, rec=0.125), tot_loss_proj:2.908 [t=0.27s]
prediction: ['[CLS] uncouth and absurdsible indira kramereft proved vicioushensible [SEP]']
Attempt swap
[1900/2000] tot_loss=2.039 (perp=9.560, rec=0.127), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] uncouth and absurdsible indira kramereft proved vicioushensible [SEP]']
[1950/2000] tot_loss=2.039 (perp=9.560, rec=0.127), tot_loss_proj:2.909 [t=0.27s]
prediction: ['[CLS] uncouth and absurdsible indira kramereft proved vicioushensible [SEP]']
Attempt swap
[2000/2000] tot_loss=2.042 (perp=9.560, rec=0.130), tot_loss_proj:2.911 [t=0.26s]
prediction: ['[CLS] uncouth and absurdsible indira kramereft proved vicioushensible [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth and absurdsible indira kramereft proved vicioushensible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 44.444 | r: 57.143
rouge2     | fm: 14.286 | p: 12.500 | r: 16.667
rougeL     | fm: 50.000 | p: 44.444 | r: 57.143
rougeLsum  | fm: 50.000 | p: 44.444 | r: 57.143
r1fm+r2fm = 64.286

[Aggregate metrics]:
rouge1     | fm: 75.700 | p: 74.713 | r: 77.161
rouge2     | fm: 40.772 | p: 40.366 | r: 41.246
rougeL     | fm: 68.525 | p: 67.698 | r: 69.742
rougeLsum  | fm: 68.578 | p: 67.718 | r: 69.840
r1fm+r2fm = 116.473

input #68 time: 0:11:05 | total time: 12:44:24


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
cosin similarity: -0.7112078402311113 normalized error: 1.7043868488471028
cosin similarity: 0.7112078402311114 normalized error: 0.5980756544836167
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.894854630381926 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 1.8804272188923759 for ['[CLS] if 1st alphabet conclusion memorabilia gettingnaire sh worditated turtles makeup greg by changes hamilton [SEP]']
[Init] best rec loss: 1.8487875090027948 for ['[CLS] found starring several smart cemetery extant magnet entry being vessels small armed louisiana named price safe [SEP]']
[Init] best rec loss: 1.825584999709449 for ['[CLS] it dressednysies salvation go fault pierre decidedoit whilecamp drowning tellingitic peninsula [SEP]']
[Init] best rec loss: 1.7899190416763409 for ['[CLS] question world singled sweat front enoughdies back mainly nationals mab cia pieces tack fellow appointed [SEP]']
[Init] best rec loss: 1.7800754909626995 for ['[CLS] opener nights corps distanceowing speedq hack charting incarnation spirit suddenly employ orientalevich india [SEP]']
[Init] best perm rec loss: 1.771406631426274 for ['[CLS] suddenly corps nights spirit charting openerowing employ speed incarnation oriental hackq india distanceevich [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.957 (perp=12.319, rec=0.493), tot_loss_proj:3.905 [t=0.28s]
prediction: ['[CLS] making full simple light real lit grammyoire bold gunsists tactical thereforeh solo " [SEP]']
[ 100/2000] tot_loss=3.043 (perp=13.387, rec=0.366), tot_loss_proj:4.368 [t=0.26s]
prediction: ['[CLS] proof complete figured light real switches leagues religious bold winner afterwards spins expressiveh monterey russell [SEP]']
[ 150/2000] tot_loss=2.617 (perp=11.410, rec=0.336), tot_loss_proj:3.468 [t=0.27s]
prediction: ['[CLS] proof complete confident light funny funny nguyen religious smart winner afterwards spins funny, monterey, [SEP]']
[ 200/2000] tot_loss=2.667 (perp=11.756, rec=0.316), tot_loss_proj:3.732 [t=0.27s]
prediction: ['[CLS] bwf - practitioner smart funny subtle nguyen indo smart winner afterwards spins funny, monterey, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.762 (perp=12.146, rec=0.333), tot_loss_proj:3.755 [t=0.28s]
prediction: ['[CLS] bwf - practitioner smart funny subtle lexie indo smart winner duration stewartanalysis, physically, [SEP]']
[ 300/2000] tot_loss=2.647 (perp=11.788, rec=0.289), tot_loss_proj:3.790 [t=0.26s]
prediction: ['[CLS] winner - practitioner smart funny subtle lexie indo subtle winner duration stewartology, sharpe, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.593 (perp=11.537, rec=0.286), tot_loss_proj:3.862 [t=0.27s]
prediction: ['[CLS] winner -manship subtle funnyona client indo subtle winner subtle subtle recipient, physically, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.618 (perp=11.579, rec=0.302), tot_loss_proj:3.710 [t=0.30s]
prediction: ['[CLS] winner -manship winner funnyona client res subtle subtle subtle subtleology, physically, [SEP]']
[ 450/2000] tot_loss=2.592 (perp=11.658, rec=0.261), tot_loss_proj:3.518 [t=0.31s]
prediction: ['[CLS] winner -manship winner funnyona client res subtle subtle subtle subtle recipient, successful, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.250 (perp=9.880, rec=0.274), tot_loss_proj:3.100 [t=0.30s]
prediction: ['[CLS] winner - subtle winner resona - funny subtle subtle subtle subtlemology, physical ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.307 (perp=10.216, rec=0.263), tot_loss_proj:3.320 [t=0.30s]
prediction: ['[CLS] winner - subtle subtle resona fremantle funny winner subtle subtle subtlemology, successful ) [SEP]']
[ 600/2000] tot_loss=2.430 (perp=10.899, rec=0.250), tot_loss_proj:3.485 [t=0.31s]
prediction: ['[CLS] winner - subtle subtle resona fremantle funny winner subtle subtleockology, successful ) [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.487 (perp=11.154, rec=0.257), tot_loss_proj:3.697 [t=0.29s]
prediction: ['[CLS] ) - subtle subtle resona headline funny winner subtle subtleockology,zie winner [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.415 (perp=10.807, rec=0.253), tot_loss_proj:3.655 [t=0.30s]
prediction: ['[CLS] ) winner subtle subtle resona headline funny winner subtle subtle subtleology, winnerzie [SEP]']
[ 750/2000] tot_loss=2.402 (perp=10.807, rec=0.241), tot_loss_proj:3.658 [t=0.30s]
prediction: ['[CLS] ) winner subtle subtle resona headline funny winner subtle subtle subtleology, winnerzie [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.342 (perp=10.517, rec=0.239), tot_loss_proj:3.594 [t=0.30s]
prediction: ['[CLS], headline subtle subtle resona winner funny winner subtle subtle subtle dealers, winnerzie [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.226 (perp=9.895, rec=0.247), tot_loss_proj:3.493 [t=0.32s]
prediction: ['[CLS], headline subtle subtle resona winner subtle subtle winner funny subtle dealers, winnerzie [SEP]']
[ 900/2000] tot_loss=2.214 (perp=9.895, rec=0.235), tot_loss_proj:3.487 [t=0.30s]
prediction: ['[CLS], headline subtle subtle resona winner subtle subtle winner funny subtle dealers, winnerzie [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.126 (perp=9.433, rec=0.239), tot_loss_proj:3.388 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle winner subtle subtle winner funny subtle dealers, winnerzie [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.086 (perp=9.276, rec=0.231), tot_loss_proj:3.331 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
[1050/2000] tot_loss=2.090 (perp=9.276, rec=0.235), tot_loss_proj:3.322 [t=0.31s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
Attempt swap
[1100/2000] tot_loss=2.081 (perp=9.276, rec=0.226), tot_loss_proj:3.319 [t=0.34s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
Attempt swap
[1150/2000] tot_loss=2.084 (perp=9.276, rec=0.229), tot_loss_proj:3.326 [t=0.31s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
[1200/2000] tot_loss=2.076 (perp=9.276, rec=0.221), tot_loss_proj:3.323 [t=0.31s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
Attempt swap
[1250/2000] tot_loss=2.087 (perp=9.276, rec=0.232), tot_loss_proj:3.321 [t=0.31s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
Attempt swap
[1300/2000] tot_loss=2.083 (perp=9.276, rec=0.228), tot_loss_proj:3.321 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
[1350/2000] tot_loss=2.085 (perp=9.276, rec=0.229), tot_loss_proj:3.324 [t=0.32s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle footballer, winnerzie [SEP]']
Attempt swap
[1400/2000] tot_loss=2.083 (perp=9.274, rec=0.228), tot_loss_proj:3.328 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle bruins, winnerzie [SEP]']
Attempt swap
[1450/2000] tot_loss=2.080 (perp=9.274, rec=0.225), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle bruins, winnerzie [SEP]']
[1500/2000] tot_loss=1.948 (perp=8.579, rec=0.232), tot_loss_proj:3.173 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle winner, winnerzie [SEP]']
Attempt swap
[1550/2000] tot_loss=1.936 (perp=8.579, rec=0.220), tot_loss_proj:3.174 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle winner, winnerzie [SEP]']
Attempt swap
[1600/2000] tot_loss=1.947 (perp=8.579, rec=0.231), tot_loss_proj:3.174 [t=0.30s]
prediction: ['[CLS], resona headline subtle subtle subtle winner subtle winner funny subtle winner, winnerzie [SEP]']
[1650/2000] tot_loss=1.886 (perp=8.338, rec=0.219), tot_loss_proj:2.949 [t=0.31s]
prediction: ['[CLS], resona - subtle subtle subtle winner subtle - funny subtle winner, winnerzie [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.018 (perp=8.972, rec=0.224), tot_loss_proj:3.007 [t=0.30s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle bruins, winnerzie [SEP]']
Attempt swap
[1750/2000] tot_loss=1.868 (perp=8.247, rec=0.218), tot_loss_proj:2.863 [t=0.29s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]']
[1800/2000] tot_loss=1.873 (perp=8.247, rec=0.224), tot_loss_proj:2.858 [t=0.29s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]']
Attempt swap
[1850/2000] tot_loss=1.873 (perp=8.247, rec=0.223), tot_loss_proj:2.866 [t=0.30s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]']
Attempt swap
[1900/2000] tot_loss=1.868 (perp=8.247, rec=0.218), tot_loss_proj:2.860 [t=0.30s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]']
[1950/2000] tot_loss=1.867 (perp=8.247, rec=0.217), tot_loss_proj:2.857 [t=0.32s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]']
Attempt swap
[2000/2000] tot_loss=1.866 (perp=8.247, rec=0.217), tot_loss_proj:2.859 [t=0.30s]
prediction: ['[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS], resona - subtle subtle subtle subtle winner - funny subtle winner, winnerzie [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.455 | p: 41.667 | r: 50.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 45.455 | p: 41.667 | r: 50.000
rougeLsum  | fm: 45.455 | p: 41.667 | r: 50.000
r1fm+r2fm = 55.455

[Aggregate metrics]:
rouge1     | fm: 75.504 | p: 74.514 | r: 76.857
rouge2     | fm: 40.338 | p: 39.974 | r: 40.830
rougeL     | fm: 68.223 | p: 67.360 | r: 69.437
rougeLsum  | fm: 68.197 | p: 67.228 | r: 69.537
r1fm+r2fm = 115.842

input #69 time: 0:12:11 | total time: 12:56:36


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
cosin similarity: 0.8917103407547794 normalized error: 0.5638843529053624
cosin similarity: -0.8917103407547793 normalized error: 1.6072489476479808
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 1.7970043049026638 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 1.5994827807789185 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 1.4548180353512685 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 1.4481823068865651 for ['[CLS] piano myth casualty immediately vocal right bottle [SEP]']
[Init] best rec loss: 1.328233292199492 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 1.1803363520140064 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 1.1794856280623118 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 1.1764670266942903 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 1.176198336517593 for ['[CLS] muscle guybution party bob modern ি [SEP]']
[Init] best perm rec loss: 1.175268694659985 for ['[CLS] muscle modernbution party ি guy bob [SEP]']
[Init] best perm rec loss: 1.1728360348227085 for ['[CLS] guy modern musclebution ি party bob [SEP]']
[Init] best perm rec loss: 1.17282422239566 for ['[CLS] িbution muscle guy party modern bob [SEP]']
[Init] best perm rec loss: 1.1726098840835648 for ['[CLS] muscle bob modernbution ি guy party [SEP]']
[Init] best perm rec loss: 1.1690425348442939 for ['[CLS] guy িbution modern muscle party bob [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.874 (perp=12.307, rec=0.413), tot_loss_proj:4.327 [t=0.31s]
prediction: ['[CLS] storm sometimes public.bn after through [SEP]']
[ 100/2000] tot_loss=2.312 (perp=9.940, rec=0.324), tot_loss_proj:3.399 [t=0.32s]
prediction: ['[CLS] storm hardly institution clunky through [SEP]']
[ 150/2000] tot_loss=1.967 (perp=8.580, rec=0.251), tot_loss_proj:2.862 [t=0.29s]
prediction: ['[CLS] cong clunk clunky through [SEP]']
[ 200/2000] tot_loss=1.741 (perp=7.645, rec=0.212), tot_loss_proj:2.652 [t=0.30s]
prediction: ['[CLS] cl clunk clunky on [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.638 (perp=11.847, rec=0.269), tot_loss_proj:3.643 [t=0.31s]
prediction: ['[CLS] brooke clips cl opponent getsunky [SEP]']
[ 300/2000] tot_loss=2.298 (perp=10.493, rec=0.200), tot_loss_proj:2.913 [t=0.29s]
prediction: ['[CLS] brooke screen cl opponent clunky [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.082 (perp=9.437, rec=0.194), tot_loss_proj:2.888 [t=0.31s]
prediction: ['[CLS] screen screen cl brooke clunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.049 (perp=9.437, rec=0.161), tot_loss_proj:2.883 [t=0.32s]
prediction: ['[CLS] screen screen cl brooke clunky [SEP]']
[ 450/2000] tot_loss=1.559 (perp=7.054, rec=0.148), tot_loss_proj:2.169 [t=0.30s]
prediction: ['[CLS] screen screen clunk clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.561 (perp=7.054, rec=0.150), tot_loss_proj:2.174 [t=0.30s]
prediction: ['[CLS] screen screen clunk clunky [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.880 (perp=8.587, rec=0.163), tot_loss_proj:2.332 [t=0.30s]
prediction: ['[CLS] screen screenunk gets clunky [SEP]']
[ 600/2000] tot_loss=1.926 (perp=8.928, rec=0.140), tot_loss_proj:2.373 [t=0.31s]
prediction: ['[CLS] screen screenhorpe gets clunky [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.948 (perp=9.026, rec=0.143), tot_loss_proj:2.424 [t=0.33s]
prediction: ['[CLS] screen screen gets clunky piece [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.754 (perp=8.090, rec=0.136), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.748 (perp=8.090, rec=0.130), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.746 (perp=8.090, rec=0.128), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.742 (perp=8.090, rec=0.124), tot_loss_proj:2.185 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.733 (perp=8.090, rec=0.116), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.730 (perp=8.090, rec=0.112), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.731 (perp=8.090, rec=0.113), tot_loss_proj:2.186 [t=0.31s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1050/2000] tot_loss=1.731 (perp=8.090, rec=0.114), tot_loss_proj:2.185 [t=0.32s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.741 (perp=8.090, rec=0.123), tot_loss_proj:2.189 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.738 (perp=8.090, rec=0.120), tot_loss_proj:2.184 [t=0.32s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1200/2000] tot_loss=1.738 (perp=8.090, rec=0.120), tot_loss_proj:2.191 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.739 (perp=8.090, rec=0.121), tot_loss_proj:2.185 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.736 (perp=8.090, rec=0.118), tot_loss_proj:2.188 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1350/2000] tot_loss=1.731 (perp=8.090, rec=0.113), tot_loss_proj:2.178 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.090, rec=0.119), tot_loss_proj:2.181 [t=0.28s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.729 (perp=8.090, rec=0.111), tot_loss_proj:2.186 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1500/2000] tot_loss=1.732 (perp=8.090, rec=0.114), tot_loss_proj:2.177 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.723 (perp=8.090, rec=0.105), tot_loss_proj:2.180 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.737 (perp=8.090, rec=0.119), tot_loss_proj:2.183 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1650/2000] tot_loss=1.731 (perp=8.090, rec=0.114), tot_loss_proj:2.185 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.090, rec=0.124), tot_loss_proj:2.182 [t=0.32s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.730 (perp=8.090, rec=0.112), tot_loss_proj:2.186 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1800/2000] tot_loss=1.734 (perp=8.090, rec=0.116), tot_loss_proj:2.184 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=8.090, rec=0.118), tot_loss_proj:2.190 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=8.090, rec=0.110), tot_loss_proj:2.186 [t=0.29s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
[1950/2000] tot_loss=1.727 (perp=8.090, rec=0.109), tot_loss_proj:2.186 [t=0.30s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.734 (perp=8.090, rec=0.116), tot_loss_proj:2.185 [t=0.31s]
prediction: ['[CLS] screen piece screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] screen piece screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 88.095

[Aggregate metrics]:
rouge1     | fm: 75.375 | p: 74.415 | r: 76.754
rouge2     | fm: 39.829 | p: 39.519 | r: 40.275
rougeL     | fm: 68.160 | p: 67.192 | r: 69.411
rougeLsum  | fm: 68.247 | p: 67.253 | r: 69.525
r1fm+r2fm = 115.204

input #70 time: 0:12:22 | total time: 13:08:58


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
cosin similarity: -0.773327853527467 normalized error: 1.6542214243473703
cosin similarity: 0.7733278535274671 normalized error: 0.5848165919813948
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 1.8883225159251085 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 1.8827909075334508 for ['[CLS] originally oldestfold columns double end shelby strict bass hp rainbow lucy anthem strykerciation [SEP]']
[Init] best rec loss: 1.8050404016588697 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 1.66571860723273 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 1.6603553797552468 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 1.6303371516614291 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 1.5766401189600296 for ['[CLS]gies amir plus locomotive contacthane flat all highest helmet postal operations political blindness colors [SEP]']
[Init] best rec loss: 1.5665735656483575 for ['[CLS] fia finally meant ever slip means stephens admit concerned older each air ill educated occupation [SEP]']
[Init] best rec loss: 1.5406505795658527 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 1.5399722359477597 for ['[CLS] ramhear liam bed fall jean fewer professor over creatures queens molly sur marshall of [SEP]']
[Init] best perm rec loss: 1.5385920288805621 for ['[CLS] sur liam creatures jean of marshall bed molly fewer queens professor ram fallhear over [SEP]']
[Init] best perm rec loss: 1.5346949700599442 for ['[CLS] of queens fall ramhear marshall jean fewer liam molly bed creatures professor sur over [SEP]']
[Init] best perm rec loss: 1.534289049380892 for ['[CLS] queens ram marshall sur creatures fewer of liam professor fall jean over bedhear molly [SEP]']
[Init] best perm rec loss: 1.5341470501737808 for ['[CLS] professor of fall creatures molly liam marshall sur queens over ramhear fewer jean bed [SEP]']
[Init] best perm rec loss: 1.5288299286322835 for ['[CLS] queens overhear of professor liam fewer fall molly ram sur creatures bed jean marshall [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.873 (perp=11.892, rec=0.494), tot_loss_proj:3.880 [t=0.27s]
prediction: ['[CLS] th void overhead placedtle moment for mistakes reporters without few getting after afterwards lap [SEP]']
[ 100/2000] tot_loss=2.436 (perp=10.511, rec=0.333), tot_loss_proj:3.428 [t=0.27s]
prediction: ['[CLS] th void jump - con moment seat single record not single single - moment anywhere [SEP]']
[ 150/2000] tot_loss=2.264 (perp=10.023, rec=0.259), tot_loss_proj:3.351 [t=0.27s]
prediction: ['[CLS] your split single - shit moment seat - extremely not single jump seat moment anywhere [SEP]']
[ 200/2000] tot_loss=2.268 (perp=10.282, rec=0.212), tot_loss_proj:3.237 [t=0.27s]
prediction: ['[CLS] your decision ankle - shit moment jump - extremely not single jump seat moment anywhere [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.975 (perp=8.917, rec=0.191), tot_loss_proj:3.395 [t=0.27s]
prediction: ['[CLS] your ankle decision - y moment jump - extremely not single jump seat and anywhere [SEP]']
[ 300/2000] tot_loss=2.041 (perp=9.369, rec=0.167), tot_loss_proj:3.500 [t=0.27s]
prediction: ['[CLS] your ankle there - y moment your - extremely not single jump seat and your [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.915 (perp=8.747, rec=0.165), tot_loss_proj:3.423 [t=0.27s]
prediction: ['[CLS] your sized there - y moment - your extremely not single jump seat and your [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.933 (perp=8.920, rec=0.150), tot_loss_proj:3.665 [t=0.27s]
prediction: ['[CLS] s sized there - y moment - your located not single jump seat and your [SEP]']
[ 450/2000] tot_loss=1.931 (perp=8.920, rec=0.147), tot_loss_proj:3.667 [t=0.27s]
prediction: ['[CLS] s sized there - y moment - your located not single jump seat and your [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.112 (perp=9.904, rec=0.131), tot_loss_proj:3.784 [t=0.27s]
prediction: ['[CLS] anythingwana there a po moment - your located not single jump seat and s [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.959 (perp=9.134, rec=0.132), tot_loss_proj:3.607 [t=0.27s]
prediction: ['[CLS] anythingwana thereod a moment - your located not single jump seat and s [SEP]']
[ 600/2000] tot_loss=1.984 (perp=9.259, rec=0.133), tot_loss_proj:3.619 [t=0.27s]
prediction: ['[CLS] anything comrade thereod a moment - your located not single jump seat and s [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.030 (perp=9.546, rec=0.121), tot_loss_proj:3.546 [t=0.27s]
prediction: ['[CLS] anything item there po a moment - your ankle not single jump seat and s [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.945 (perp=9.092, rec=0.127), tot_loss_proj:3.578 [t=0.27s]
prediction: ['[CLS] item there po anything a moment - your ankle not single jump seat and s [SEP]']
[ 750/2000] tot_loss=1.940 (perp=9.092, rec=0.121), tot_loss_proj:3.578 [t=0.27s]
prediction: ['[CLS] item there po anything a moment - your ankle not single jump seat and s [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.905 (perp=8.945, rec=0.116), tot_loss_proj:3.549 [t=0.27s]
prediction: ['[CLS] item po there anything a moment - your ankle not single jump seat and s [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.881 (perp=8.820, rec=0.117), tot_loss_proj:3.544 [t=0.27s]
prediction: ['[CLS] there item po anything a moment - your ankle not single jump seat and s [SEP]']
[ 900/2000] tot_loss=2.023 (perp=9.505, rec=0.122), tot_loss_proj:3.714 [t=0.27s]
prediction: ['[CLS] there itemod anything a moment - yourwana not single jump seat and s [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.905 (perp=8.945, rec=0.116), tot_loss_proj:3.555 [t=0.27s]
prediction: ['[CLS] item po there anything a moment - your ankle not single jump seat and s [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.913 (perp=9.004, rec=0.112), tot_loss_proj:3.391 [t=0.27s]
prediction: ['[CLS] item po there without a moment - ankle not your single jump seat and s [SEP]']
[1050/2000] tot_loss=1.925 (perp=9.004, rec=0.124), tot_loss_proj:3.395 [t=0.27s]
prediction: ['[CLS] item po there without a moment - ankle not your single jump seat and s [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.863 (perp=8.769, rec=0.109), tot_loss_proj:3.264 [t=0.27s]
prediction: ['[CLS] item po there without a moment ankle - not your single jump seat and s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.865 (perp=8.769, rec=0.111), tot_loss_proj:3.272 [t=0.27s]
prediction: ['[CLS] item po there without a moment ankle - not your single jump seat and s [SEP]']
[1200/2000] tot_loss=1.901 (perp=8.951, rec=0.111), tot_loss_proj:3.197 [t=0.27s]
prediction: ['[CLS] item po there without a momenttua - not your single jump seat and s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.901 (perp=8.951, rec=0.111), tot_loss_proj:3.196 [t=0.30s]
prediction: ['[CLS] item po there without a momenttua - not your single jump seat and s [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.844 (perp=8.622, rec=0.120), tot_loss_proj:3.020 [t=0.29s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
[1350/2000] tot_loss=1.834 (perp=8.622, rec=0.110), tot_loss_proj:3.006 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1400/2000] tot_loss=1.834 (perp=8.622, rec=0.110), tot_loss_proj:3.013 [t=0.31s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1450/2000] tot_loss=1.834 (perp=8.622, rec=0.109), tot_loss_proj:3.019 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
[1500/2000] tot_loss=1.833 (perp=8.622, rec=0.108), tot_loss_proj:3.015 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1550/2000] tot_loss=1.840 (perp=8.622, rec=0.115), tot_loss_proj:3.020 [t=0.31s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1600/2000] tot_loss=1.829 (perp=8.622, rec=0.104), tot_loss_proj:3.022 [t=0.29s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
[1650/2000] tot_loss=1.832 (perp=8.622, rec=0.108), tot_loss_proj:3.019 [t=0.31s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1700/2000] tot_loss=1.837 (perp=8.622, rec=0.113), tot_loss_proj:3.016 [t=0.31s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1750/2000] tot_loss=1.836 (perp=8.622, rec=0.111), tot_loss_proj:3.015 [t=0.31s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
[1800/2000] tot_loss=1.830 (perp=8.622, rec=0.106), tot_loss_proj:3.020 [t=0.31s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1850/2000] tot_loss=1.839 (perp=8.622, rec=0.115), tot_loss_proj:3.011 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[1900/2000] tot_loss=1.837 (perp=8.622, rec=0.112), tot_loss_proj:3.021 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
[1950/2000] tot_loss=1.829 (perp=8.622, rec=0.105), tot_loss_proj:3.011 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Attempt swap
[2000/2000] tot_loss=1.836 (perp=8.622, rec=0.112), tot_loss_proj:3.014 [t=0.30s]
prediction: ['[CLS] s po there without a momenttua - not your single jump seat and item [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] s po there without a momenttua - not your single jump seat and item [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 7.692 | p: 7.143 | r: 8.333
rougeL     | fm: 57.143 | p: 53.333 | r: 61.538
rougeLsum  | fm: 57.143 | p: 53.333 | r: 61.538
r1fm+r2fm = 86.264

[Aggregate metrics]:
rouge1     | fm: 75.450 | p: 74.441 | r: 76.899
rouge2     | fm: 39.374 | p: 39.018 | r: 39.788
rougeL     | fm: 67.937 | p: 67.017 | r: 69.270
rougeLsum  | fm: 67.880 | p: 66.879 | r: 69.177
r1fm+r2fm = 114.824

input #71 time: 0:11:24 | total time: 13:20:23


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
cosin similarity: 0.8619169926329063 normalized error: 0.5020466964876452
cosin similarity: -0.8619169926329064 normalized error: 1.7673242729609802
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 1.752843905665214 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 1.6520627574430182 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 1.5570253903808349 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 1.5363156906424398 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 1.4755265598408513 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 1.395293902324087 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 1.3948383014151817 for ['[CLS] anne proud walked originally navigation blame spurs junior eastbery and located part swiss [SEP] [SEP]']
[Init] best rec loss: 1.3907338648757994 for ['[CLS] trophy exit ) hear stuffture prey gaytering opera progress spec companyheater broadcasts [SEP]']
[Init] best rec loss: 1.3516572504891111 for ['[CLS] things substitute air favors bishop defined werewolf anywaylusion ghana tonnesboard favorfin cy [SEP]']
[Init] best perm rec loss: 1.350628190650515 for ['[CLS] defined ghana things favorslusionfin werewolf anyway bishopboard favor air tonnes substitute cy [SEP]']
[Init] best perm rec loss: 1.3464317534270858 for ['[CLS] favor defined favors substitute bishop air things anywaylusionboardfin werewolf cy ghana tonnes [SEP]']
[Init] best perm rec loss: 1.3452217314798915 for ['[CLS] ghana anyway air cy things bishop substitutefin werewolf tonnes favor definedboardlusion favors [SEP]']
[Init] best perm rec loss: 1.3448562551891643 for ['[CLS] favor werewolfboard things bishop anyway air cyfin ghana defined favors substitutelusion tonnes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.066 (perp=13.218, rec=0.422), tot_loss_proj:3.771 [t=0.31s]
prediction: ['[CLS] thin agenda itsachal territoryency hard cop transition insisted pick something room. differential [SEP]']
[ 100/2000] tot_loss=2.797 (perp=12.481, rec=0.301), tot_loss_proj:3.656 [t=0.29s]
prediction: ['[CLS] tough resources specific upper time has tough toughac insistedogical something room ( when [SEP]']
[ 150/2000] tot_loss=2.365 (perp=10.690, rec=0.227), tot_loss_proj:3.619 [t=0.30s]
prediction: ['[CLS] tough resourceser more time has tough tough predecessors roogical its time housemates presidential [SEP]']
[ 200/2000] tot_loss=2.369 (perp=10.900, rec=0.189), tot_loss_proj:3.967 [t=0.31s]
prediction: ['[CLS] tough violenceer more time has tough tough print balancing inspired its timeˈ presidential [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.384 (perp=11.106, rec=0.162), tot_loss_proj:3.742 [t=0.30s]
prediction: ['[CLS] violenceer tougher time has tough tough mistake balancing inspired its timeˈ presidential [SEP]']
[ 300/2000] tot_loss=2.525 (perp=11.861, rec=0.153), tot_loss_proj:4.280 [t=0.30s]
prediction: ['[CLS] syndromeer tougher time has tough a simply balancing inspired its time grewenburg [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.252 (perp=10.572, rec=0.138), tot_loss_proj:3.699 [t=0.29s]
prediction: ['[CLS] timeer tougher time has tough a simply balancing inspired violence violence grewenburg [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.159 (perp=10.096, rec=0.139), tot_loss_proj:3.255 [t=0.29s]
prediction: ['[CLS] timeer tougher time has tough a simply balancing philosophy its housematesenburg philosophy [SEP]']
[ 450/2000] tot_loss=2.257 (perp=10.728, rec=0.111), tot_loss_proj:3.291 [t=0.30s]
prediction: ['[CLS] timeer tougher time has tough a simply balancing philosophy violence housematesenburg philosophy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.147 (perp=10.126, rec=0.121), tot_loss_proj:3.144 [t=0.31s]
prediction: ['[CLS] timeer tougher time has tough philosophy simply balancing with violence housematesenburg philosophy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.076 (perp=9.775, rec=0.121), tot_loss_proj:3.226 [t=0.30s]
prediction: ['[CLS] timeer tougher time has tough philosophy balancing simply with violence housematesenburg philosophy [SEP]']
[ 600/2000] tot_loss=2.044 (perp=9.682, rec=0.107), tot_loss_proj:3.332 [t=0.30s]
prediction: ['[CLS] timeer tougher time has tough philosophy balancing simply with violence accompaniedenburg philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.916 (perp=9.006, rec=0.115), tot_loss_proj:2.976 [t=0.33s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing simply with its accompanied philosophy philosophy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.914 (perp=9.006, rec=0.113), tot_loss_proj:2.970 [t=0.30s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing simply with its accompanied philosophy philosophy [SEP]']
[ 750/2000] tot_loss=1.935 (perp=9.112, rec=0.112), tot_loss_proj:3.110 [t=0.31s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing material with its accompanied philosophy philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.138 (perp=10.131, rec=0.112), tot_loss_proj:3.389 [t=0.30s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing philosophy simply a its accompanied philosophy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.866 (perp=8.773, rec=0.111), tot_loss_proj:3.146 [t=0.30s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing philosophy with its simply accompanied philosophy [SEP]']
[ 900/2000] tot_loss=1.974 (perp=9.267, rec=0.120), tot_loss_proj:3.361 [t=0.29s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing philosophy with its material accompanied philosophy [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.847 (perp=8.643, rec=0.118), tot_loss_proj:2.972 [t=0.30s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing its material philosophy with accompanied philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.829 (perp=8.643, rec=0.101), tot_loss_proj:2.978 [t=0.31s]
prediction: ['[CLS] timeer tougher time has toughenburg balancing its material philosophy with accompanied philosophy [SEP]']
[1050/2000] tot_loss=2.026 (perp=9.603, rec=0.105), tot_loss_proj:3.322 [t=0.29s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy with accompanied philosophy [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.016 (perp=9.549, rec=0.106), tot_loss_proj:3.240 [t=0.30s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.018 (perp=9.549, rec=0.109), tot_loss_proj:3.237 [t=0.31s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
[1200/2000] tot_loss=2.019 (perp=9.549, rec=0.110), tot_loss_proj:3.239 [t=0.29s]
prediction: ['[CLS] timeer violenceer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.998 (perp=9.441, rec=0.110), tot_loss_proj:3.235 [t=0.30s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=2.001 (perp=9.441, rec=0.113), tot_loss_proj:3.232 [t=0.29s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
[1350/2000] tot_loss=1.994 (perp=9.441, rec=0.105), tot_loss_proj:3.240 [t=0.30s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.992 (perp=9.441, rec=0.104), tot_loss_proj:3.231 [t=0.31s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.981 (perp=9.441, rec=0.093), tot_loss_proj:3.236 [t=0.31s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
[1500/2000] tot_loss=1.997 (perp=9.441, rec=0.109), tot_loss_proj:3.236 [t=0.30s]
prediction: ['[CLS] violenceer timeer time has toughenburg balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.100 (perp=9.965, rec=0.107), tot_loss_proj:2.832 [t=0.31s]
prediction: ['[CLS] violenceerenburger time has tough time balancing its material philosophy finch with philosophy [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.907 (perp=9.004, rec=0.106), tot_loss_proj:2.641 [t=0.30s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
[1650/2000] tot_loss=1.913 (perp=9.004, rec=0.112), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.905 (perp=9.004, rec=0.104), tot_loss_proj:2.640 [t=0.29s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.004, rec=0.104), tot_loss_proj:2.640 [t=0.30s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
[1800/2000] tot_loss=1.918 (perp=9.004, rec=0.117), tot_loss_proj:2.634 [t=0.31s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.897 (perp=9.004, rec=0.096), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.897 (perp=9.004, rec=0.096), tot_loss_proj:2.634 [t=0.29s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
[1950/2000] tot_loss=1.909 (perp=9.004, rec=0.108), tot_loss_proj:2.631 [t=0.31s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]']
Attempt swap
[2000/2000] tot_loss=2.071 (perp=9.805, rec=0.110), tot_loss_proj:2.809 [t=0.30s]
prediction: ['[CLS]enburger violenceer time has tough time balancing its material philosophy finch with philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]enburger violenceer time has tough time balancing its material philosophy accompanied with philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 53.333 | r: 61.538
rouge2     | fm: 23.077 | p: 21.429 | r: 25.000
rougeL     | fm: 57.143 | p: 53.333 | r: 61.538
rougeLsum  | fm: 57.143 | p: 53.333 | r: 61.538
r1fm+r2fm = 80.220

[Aggregate metrics]:
rouge1     | fm: 75.198 | p: 74.157 | r: 76.633
rouge2     | fm: 39.304 | p: 38.938 | r: 39.808
rougeL     | fm: 67.722 | p: 66.767 | r: 69.070
rougeLsum  | fm: 67.786 | p: 66.757 | r: 69.161
r1fm+r2fm = 114.501

input #72 time: 0:12:29 | total time: 13:32:52


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
cosin similarity: -0.7651320934251609 normalized error: 1.7071232564366776
cosin similarity: 0.7651320934251608 normalized error: 0.5693052337592939
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 1.8963770109068938 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 1.790848551131015 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 1.767256433357535 for ['[CLS] bitch natasha [SEP]']
[Init] best rec loss: 1.7520724617671528 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 1.7458244778956729 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 1.6698687280399032 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 1.6320378530832977 for ['[CLS] tierney sector [SEP]']
[Init] best rec loss: 1.5976117882231289 for ['[CLS] cruel ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.564 (perp=10.379, rec=0.489), tot_loss_proj:3.105 [t=0.29s]
prediction: ['[CLS] bad bad [SEP]']
[ 100/2000] tot_loss=2.241 (perp=9.577, rec=0.325), tot_loss_proj:2.669 [t=0.31s]
prediction: ['[CLS] bad journalism [SEP]']
[ 150/2000] tot_loss=2.231 (perp=9.724, rec=0.287), tot_loss_proj:2.416 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.206 (perp=9.724, rec=0.261), tot_loss_proj:2.433 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.208 (perp=9.724, rec=0.263), tot_loss_proj:2.424 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.212 (perp=9.724, rec=0.267), tot_loss_proj:2.429 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.194 (perp=9.724, rec=0.249), tot_loss_proj:2.418 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.200 (perp=9.724, rec=0.255), tot_loss_proj:2.428 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.178 (perp=9.724, rec=0.233), tot_loss_proj:2.413 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.185 (perp=9.724, rec=0.240), tot_loss_proj:2.431 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.173 (perp=9.724, rec=0.229), tot_loss_proj:2.421 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.182 (perp=9.724, rec=0.237), tot_loss_proj:2.421 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.180 (perp=9.724, rec=0.235), tot_loss_proj:2.419 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.185 (perp=9.724, rec=0.240), tot_loss_proj:2.417 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.179 (perp=9.724, rec=0.234), tot_loss_proj:2.422 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.171 (perp=9.724, rec=0.227), tot_loss_proj:2.418 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.187 (perp=9.724, rec=0.242), tot_loss_proj:2.419 [t=0.32s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.179 (perp=9.724, rec=0.234), tot_loss_proj:2.419 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.180 (perp=9.724, rec=0.236), tot_loss_proj:2.414 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.181 (perp=9.724, rec=0.237), tot_loss_proj:2.413 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.173 (perp=9.724, rec=0.229), tot_loss_proj:2.433 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.174 (perp=9.724, rec=0.229), tot_loss_proj:2.425 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.186 (perp=9.724, rec=0.241), tot_loss_proj:2.424 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.176 (perp=9.724, rec=0.231), tot_loss_proj:2.422 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.172 (perp=9.724, rec=0.227), tot_loss_proj:2.431 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.175 (perp=9.724, rec=0.230), tot_loss_proj:2.420 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.168 (perp=9.724, rec=0.223), tot_loss_proj:2.433 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.169 (perp=9.724, rec=0.225), tot_loss_proj:2.430 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.178 (perp=9.724, rec=0.233), tot_loss_proj:2.423 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.161 (perp=9.724, rec=0.216), tot_loss_proj:2.422 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.177 (perp=9.724, rec=0.233), tot_loss_proj:2.427 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.174 (perp=9.724, rec=0.229), tot_loss_proj:2.424 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.173 (perp=9.724, rec=0.228), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.171 (perp=9.724, rec=0.226), tot_loss_proj:2.427 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.182 (perp=9.724, rec=0.237), tot_loss_proj:2.434 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.170 (perp=9.724, rec=0.226), tot_loss_proj:2.424 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.175 (perp=9.724, rec=0.230), tot_loss_proj:2.435 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.183 (perp=9.724, rec=0.238), tot_loss_proj:2.422 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.180 (perp=9.724, rec=0.235), tot_loss_proj:2.423 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.178 (perp=9.724, rec=0.233), tot_loss_proj:2.430 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 75.518 | p: 74.436 | r: 77.007
rouge2     | fm: 39.922 | p: 39.589 | r: 40.426
rougeL     | fm: 68.203 | p: 67.260 | r: 69.437
rougeLsum  | fm: 68.267 | p: 67.284 | r: 69.617
r1fm+r2fm = 115.440

input #73 time: 0:12:20 | total time: 13:45:13


Running input #74 of 100.
reference: 
========================
share 
========================
cosin similarity: 0.5745548755000613 normalized error: 0.7164188335902618
cosin similarity: -0.5745548755000613 normalized error: 1.541116032221923
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.7749139595634436 for ['[CLS]wed [SEP]']
[Init] best rec loss: 1.6155631969186581 for ['[CLS] storage [SEP]']
[Init] best rec loss: 1.5762464844293522 for ['[CLS] answering [SEP]']
[Init] best rec loss: 1.5544247628293064 for ['[CLS] ahead [SEP]']
[Init] best rec loss: 1.5079940066359137 for ['[CLS] coup [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.571 (perp=8.178, rec=0.935), tot_loss_proj:2.913 [t=0.30s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=2.246 (perp=8.178, rec=0.611), tot_loss_proj:2.793 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=2.205 (perp=8.178, rec=0.569), tot_loss_proj:2.742 [t=0.29s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=2.018 (perp=8.178, rec=0.383), tot_loss_proj:2.663 [t=0.29s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.999 (perp=8.178, rec=0.363), tot_loss_proj:2.547 [t=0.30s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.984 (perp=8.178, rec=0.349), tot_loss_proj:2.517 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.980 (perp=8.178, rec=0.344), tot_loss_proj:2.487 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.970 (perp=8.178, rec=0.334), tot_loss_proj:2.466 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.963 (perp=8.178, rec=0.328), tot_loss_proj:2.461 [t=0.29s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.978 (perp=8.178, rec=0.342), tot_loss_proj:2.449 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.967 (perp=8.178, rec=0.332), tot_loss_proj:2.446 [t=0.31s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.963 (perp=8.178, rec=0.328), tot_loss_proj:2.454 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.951 (perp=8.178, rec=0.315), tot_loss_proj:2.439 [t=0.29s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.962 (perp=8.178, rec=0.326), tot_loss_proj:2.437 [t=0.30s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.977 (perp=8.178, rec=0.341), tot_loss_proj:2.427 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.956 (perp=8.178, rec=0.321), tot_loss_proj:2.420 [t=0.29s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.943 (perp=8.178, rec=0.307), tot_loss_proj:2.425 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.972 (perp=8.178, rec=0.337), tot_loss_proj:2.431 [t=0.30s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.961 (perp=8.178, rec=0.326), tot_loss_proj:2.419 [t=0.29s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.949 (perp=8.178, rec=0.313), tot_loss_proj:2.427 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.965 (perp=8.178, rec=0.330), tot_loss_proj:2.431 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.943 (perp=8.178, rec=0.308), tot_loss_proj:2.409 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.951 (perp=8.178, rec=0.315), tot_loss_proj:2.425 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.954 (perp=8.178, rec=0.318), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.952 (perp=8.178, rec=0.316), tot_loss_proj:2.418 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.945 (perp=8.178, rec=0.309), tot_loss_proj:2.405 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.948 (perp=8.178, rec=0.312), tot_loss_proj:2.405 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.954 (perp=8.178, rec=0.319), tot_loss_proj:2.411 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.946 (perp=8.178, rec=0.311), tot_loss_proj:2.414 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.953 (perp=8.178, rec=0.318), tot_loss_proj:2.430 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.945 (perp=8.178, rec=0.309), tot_loss_proj:2.420 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.952 (perp=8.178, rec=0.317), tot_loss_proj:2.414 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.941 (perp=8.178, rec=0.306), tot_loss_proj:2.410 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.956 (perp=8.178, rec=0.321), tot_loss_proj:2.421 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.956 (perp=8.178, rec=0.321), tot_loss_proj:2.420 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.952 (perp=8.178, rec=0.316), tot_loss_proj:2.408 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.958 (perp=8.178, rec=0.322), tot_loss_proj:2.411 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.949 (perp=8.178, rec=0.314), tot_loss_proj:2.417 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.940 (perp=8.178, rec=0.305), tot_loss_proj:2.408 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.952 (perp=8.178, rec=0.316), tot_loss_proj:2.409 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 75.835 | p: 74.800 | r: 77.335
rouge2     | fm: 40.795 | p: 40.436 | r: 41.236
rougeL     | fm: 68.672 | p: 67.725 | r: 69.887
rougeLsum  | fm: 68.594 | p: 67.600 | r: 69.936
r1fm+r2fm = 116.630

input #74 time: 0:11:42 | total time: 13:56:55


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
cosin similarity: 0.8721797930098243 normalized error: 0.5185604172624592
cosin similarity: -0.8721797930098243 normalized error: 1.7177417220859112
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 1.8861748611996618 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 1.8705921993801187 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 1.8253952638064617 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 1.7451496849903472 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 1.7248061963322525 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 1.7089033866910621 for ['[CLS] surrounding imlence health flow mecklenburg dining twins execution plannercott by yes guy rattle senior batch 社 earth [SEP]']
[Init] best rec loss: 1.7052668652087082 for ['[CLS] cabin titled feedbi humble wbning translation chance tempo area true trailing legislative be yellowish popular granite midwest [SEP]']
[Init] best perm rec loss: 1.7052304604017312 for ['[CLS] be legislative yellowish chance humblebi cabin midwest tempo true titled area translation granitening trailing popular wb feed [SEP]']
[Init] best perm rec loss: 1.7046288236619875 for ['[CLS] granitening humble be translation tempo popular cabin legislativebi titled trailing true chance area feed yellowish wb midwest [SEP]']
[Init] best perm rec loss: 1.704073331904696 for ['[CLS] legislative midwest be trailing yellowish granite titled tempo true cabin humble feed area translationningbi popular wb chance [SEP]']
[Init] best perm rec loss: 1.702376819265071 for ['[CLS] granite tempo yellowish feed wb titledning cabin areabi midwest popular legislative translation humble chance be true trailing [SEP]']
[Init] best perm rec loss: 1.7013103710980708 for ['[CLS]bi true trailing translation humble legislative tempo yellowishning area chance cabin be granite feed midwest titled wb popular [SEP]']
[Init] best perm rec loss: 1.6972391532988222 for ['[CLS]ning humble be titled feed chance cabin legislative area tempobi true trailing yellowish popular granite wb midwest translation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.074 (perp=13.027, rec=0.469), tot_loss_proj:3.805 [t=0.29s]
prediction: ['[CLS] fashion good appreciated ni look of settle ivan emphasispor studied universidad gu officer, noble meyer inter mark [SEP]']
[ 100/2000] tot_loss=3.032 (perp=13.356, rec=0.361), tot_loss_proj:4.316 [t=0.26s]
prediction: ['[CLS] fashion perfect expected into diplomatic of retired allows emphasiseterchule wicket besides envy, dismissed ignored crossed commemorate [SEP]']
[ 150/2000] tot_loss=3.130 (perp=14.115, rec=0.307), tot_loss_proj:4.587 [t=0.27s]
prediction: ['[CLS] smashwords tested expected upon diplomatic beast retired allows savannah mathias universidad isn awardederic not dismissed easily passes dismissed [SEP]']
[ 200/2000] tot_loss=2.824 (perp=12.886, rec=0.247), tot_loss_proj:4.325 [t=0.26s]
prediction: ['[CLS] smashwords silk expected libertadoresative into retired 発 opportunity mathias derek isn.eric not dismissed easily easily dismissed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.550 (perp=11.588, rec=0.233), tot_loss_proj:3.857 [t=0.28s]
prediction: ['[CLS] finish silk expected el instability into mhz instability joey mathias iseric. isn not dismissed easily easily dismissed [SEP]']
[ 300/2000] tot_loss=2.561 (perp=11.731, rec=0.215), tot_loss_proj:3.963 [t=0.29s]
prediction: ['[CLS] finish demonstrated expected el instability into mhz instability joey mathias is expensive. isn not dismissed easily easily dismissed [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.588 (perp=11.832, rec=0.221), tot_loss_proj:3.992 [t=0.26s]
prediction: ['[CLS] this demonstrated expected el instability into mhz joeyeded isxxciful instability never not dismissed easily easily dismissed [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.658 (perp=12.120, rec=0.234), tot_loss_proj:3.899 [t=0.27s]
prediction: ['[CLS] this this available el instability excursionciful joeyeded isxx mhz instability never not dismissed easily easily dismissed [SEP]']
[ 450/2000] tot_loss=2.565 (perp=11.884, rec=0.189), tot_loss_proj:3.654 [t=0.27s]
prediction: ['[CLS] this this available el instability excursionciful joeyeded is sophie mhz instability not not dismissed easily easily dismissed [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.537 (perp=11.749, rec=0.187), tot_loss_proj:4.204 [t=0.26s]
prediction: ['[CLS] this this available eleit instability excursion joey instability is sophie mhz instability not not dismissed easilyasurable dismissed [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.568 (perp=11.899, rec=0.188), tot_loss_proj:4.018 [t=0.26s]
prediction: ['[CLS] this this available eleit is excursion opportunity instability instabilitympt mhz instability isn not dismissed easily although dismissed [SEP]']
[ 600/2000] tot_loss=2.520 (perp=11.713, rec=0.177), tot_loss_proj:3.706 [t=0.27s]
prediction: ['[CLS] this this available eleit is excursion opportunity instability instability brooklyn mhz instability wasn not dismissed easily or dismissed [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.409 (perp=11.214, rec=0.166), tot_loss_proj:3.600 [t=0.26s]
prediction: ['[CLS] this this available 主. is excursion opportunity renumbered mhz instability instability instability wasn not dismissed easily or dismissed [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.302 (perp=10.620, rec=0.178), tot_loss_proj:3.594 [t=0.27s]
prediction: ['[CLS] this this available 主 is excursion opportunity renumbered mhz instability instability instability. wasn not dismissed easily or dismissed [SEP]']
[ 750/2000] tot_loss=2.272 (perp=10.530, rec=0.166), tot_loss_proj:3.784 [t=0.27s]
prediction: ['[CLS] this this templar 主 is excursion joey renumbered mhz instability instability instability.enter not dismissed easily or dismissed [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.238 (perp=10.320, rec=0.174), tot_loss_proj:3.362 [t=0.27s]
prediction: ['[CLS] this this templar el is excursion joey renumberedএ instability instability instability.enter not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.159 (perp=9.980, rec=0.163), tot_loss_proj:3.321 [t=0.27s]
prediction: ['[CLS] this this templar 主 is excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
[ 900/2000] tot_loss=2.112 (perp=9.757, rec=0.161), tot_loss_proj:3.317 [t=0.27s]
prediction: ['[CLS] this this equally 主 is excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.025 (perp=9.332, rec=0.159), tot_loss_proj:3.221 [t=0.28s]
prediction: ['[CLS] this is equally 主 this excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.063 (perp=9.511, rec=0.161), tot_loss_proj:3.609 [t=0.28s]
prediction: ['[CLS] this is this forget 主 excursion joey renumberedএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
[1050/2000] tot_loss=2.016 (perp=9.306, rec=0.155), tot_loss_proj:3.599 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=9.306, rec=0.162), tot_loss_proj:3.604 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.017 (perp=9.306, rec=0.156), tot_loss_proj:3.599 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
[1200/2000] tot_loss=2.019 (perp=9.306, rec=0.158), tot_loss_proj:3.601 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeycolaএ instability instability instabilityenter. not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.979 (perp=9.105, rec=0.158), tot_loss_proj:3.570 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
[1300/2000] tot_loss=1.979 (perp=9.105, rec=0.158), tot_loss_proj:3.571 [t=0.26s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.105, rec=0.149), tot_loss_proj:3.577 [t=0.27s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
[1400/2000] tot_loss=1.982 (perp=9.105, rec=0.161), tot_loss_proj:3.571 [t=0.26s]
prediction: ['[CLS] this is this forget 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
[1450/2000] tot_loss=1.936 (perp=8.904, rec=0.155), tot_loss_proj:3.231 [t=0.25s]
prediction: ['[CLS] this is thisable 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
[1500/2000] tot_loss=1.934 (perp=8.904, rec=0.153), tot_loss_proj:3.231 [t=0.27s]
prediction: ['[CLS] this is thisable 主 excursion joeyentercolaএ instability instability instability. not easily dismissed or dismissed [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.013 (perp=9.318, rec=0.150), tot_loss_proj:3.608 [t=0.27s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.012 (perp=9.318, rec=0.148), tot_loss_proj:3.608 [t=0.28s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
[1650/2000] tot_loss=2.014 (perp=9.318, rec=0.150), tot_loss_proj:3.607 [t=0.25s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.008 (perp=9.318, rec=0.144), tot_loss_proj:3.610 [t=0.26s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.012 (perp=9.318, rec=0.149), tot_loss_proj:3.605 [t=0.27s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
[1800/2000] tot_loss=2.017 (perp=9.318, rec=0.154), tot_loss_proj:3.611 [t=0.27s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or dismissed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.032 (perp=9.431, rec=0.146), tot_loss_proj:3.699 [t=0.27s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.039 (perp=9.431, rec=0.152), tot_loss_proj:3.699 [t=0.27s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
[1950/2000] tot_loss=2.039 (perp=9.431, rec=0.153), tot_loss_proj:3.693 [t=0.28s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.038 (perp=9.431, rec=0.152), tot_loss_proj:3.699 [t=0.26s]
prediction: ['[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this is this 主 forget excursion joeyentercolaএ instability instability mental. not easily dismissed or. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 73.333 | r: 64.706
rouge2     | fm: 26.667 | p: 28.571 | r: 25.000
rougeL     | fm: 56.250 | p: 60.000 | r: 52.941
rougeLsum  | fm: 56.250 | p: 60.000 | r: 52.941
r1fm+r2fm = 95.417

[Aggregate metrics]:
rouge1     | fm: 75.751 | p: 74.780 | r: 77.146
rouge2     | fm: 40.543 | p: 40.254 | r: 40.914
rougeL     | fm: 68.215 | p: 67.408 | r: 69.544
rougeLsum  | fm: 68.477 | p: 67.470 | r: 69.784
r1fm+r2fm = 116.295

input #75 time: 0:11:10 | total time: 14:08:06


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
cosin similarity: 0.8993835694058105 normalized error: 0.4740738023882021
cosin similarity: -0.8993835694058105 normalized error: 1.7959496496602403
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 1.7927852314865809 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 1.7453874883585057 for ['[CLS] vimes spread stanford telescope formed neighbourhood wire chang miniseries farmers kyle having bend attempt [SEP]']
[Init] best rec loss: 1.7336280263095611 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 1.704004183913559 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 1.547392456147973 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 1.478506002806667 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 1.4752863838910206 for ['[CLS] pushed ( purse onwards lefthaw tautoning surreal hard ab backwardˣ mango [SEP]']
[Init] best perm rec loss: 1.4748151393159554 for ['[CLS]ˣ mango taut purse backward onwards left surreal hardoning ab ( pushedhaw [SEP]']
[Init] best perm rec loss: 1.4740360588253913 for ['[CLS] tautˣoninghaw mango surreal left onwards hard backward pushed purse ( ab [SEP]']
[Init] best perm rec loss: 1.4725668657707782 for ['[CLS]oning onwards abhaw ( pushed backwardˣ hard left surreal purse taut mango [SEP]']
[Init] best perm rec loss: 1.4708118839200626 for ['[CLS] abˣ purse surrealoning left hard taut ( backward onwards pushedhaw mango [SEP]']
[Init] best perm rec loss: 1.4704620886867759 for ['[CLS] onwards pushed ab hard surrealoning lefthaw taut purseˣ ( mango backward [SEP]']
[Init] best perm rec loss: 1.4674005283156941 for ['[CLS] tautˣ backward hard (oning left onwards purse mangohaw pushed ab surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.675 (perp=11.320, rec=0.411), tot_loss_proj:3.362 [t=0.20s]
prediction: ['[CLS] british barrel software forgotten from family packet closed career felt companies finally stopped qualifying [SEP]']
[ 100/2000] tot_loss=2.580 (perp=10.931, rec=0.394), tot_loss_proj:3.457 [t=0.20s]
prediction: ['[CLS] gr heat attack stopped off. metal oil only seemed challenge afterwards stopped challenging [SEP]']
[ 150/2000] tot_loss=2.696 (perp=12.151, rec=0.266), tot_loss_proj:4.043 [t=0.20s]
prediction: ['[CLS] of weeks war stopped great. silver industries when feels challenge culminated stopped challenging [SEP]']
[ 200/2000] tot_loss=2.431 (perp=11.045, rec=0.223), tot_loss_proj:3.946 [t=0.21s]
prediction: ['[CLS] of barack war stopped great. silver industry when feels challenging has stopped challenging [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.342 (perp=10.662, rec=0.210), tot_loss_proj:3.324 [t=0.20s]
prediction: ['[CLS] he barack when 16 stopped great. silver industries seems challenging has stopped challenging [SEP]']
[ 300/2000] tot_loss=2.473 (perp=11.452, rec=0.183), tot_loss_proj:3.358 [t=0.21s]
prediction: ['[CLS] when kilometers when 16 stopped great. silver industries seems himself has stopped challenging [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.308 (perp=10.682, rec=0.172), tot_loss_proj:3.212 [t=0.20s]
prediction: ['[CLS] when kilometers when 66 stopped. silver industries great seems himself has stopped challenging [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.209 (perp=10.251, rec=0.159), tot_loss_proj:3.249 [t=0.21s]
prediction: ['[CLS] when kerman if when 66 stopped. silver industries great himself has stopped challenging [SEP]']
[ 450/2000] tot_loss=2.195 (perp=10.251, rec=0.145), tot_loss_proj:3.250 [t=0.20s]
prediction: ['[CLS] when kerman if when 66 stopped. silver industries great himself has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.177 (perp=10.185, rec=0.139), tot_loss_proj:3.384 [t=0.21s]
prediction: ['[CLS] when kerman when if 66 stopped. silver oil great himself has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.117 (perp=9.932, rec=0.131), tot_loss_proj:3.014 [t=0.21s]
prediction: ['[CLS] when kerman when if 66 ended, great oil silver himself has stopped challenging [SEP]']
[ 600/2000] tot_loss=2.112 (perp=9.932, rec=0.126), tot_loss_proj:3.008 [t=0.20s]
prediction: ['[CLS] when kerman when if 66 ended, great oil silver himself has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.136 (perp=10.061, rec=0.124), tot_loss_proj:3.023 [t=0.20s]
prediction: ['[CLS] when silveryman when if 66 leaves, very oil himself has stopped challenging [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.078 (perp=9.753, rec=0.127), tot_loss_proj:3.160 [t=0.21s]
prediction: ['[CLS] when silveryman when if 66 leaves at at oil has stopped challenging himself [SEP]']
[ 750/2000] tot_loss=2.110 (perp=9.966, rec=0.117), tot_loss_proj:3.200 [t=0.20s]
prediction: ['[CLS] when silver kerman when if 66 leaves at at oil has stopped challenging himself [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.024 (perp=9.516, rec=0.121), tot_loss_proj:3.180 [t=0.20s]
prediction: ['[CLS] when silver kerman when if at 66 leaves very oil has stopped challenging himself [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.949 (perp=9.139, rec=0.122), tot_loss_proj:3.150 [t=0.20s]
prediction: ['[CLS] when silver kerman when if at 66 leaves oil has stopped very challenging himself [SEP]']
[ 900/2000] tot_loss=1.909 (perp=8.937, rec=0.122), tot_loss_proj:2.903 [t=0.21s]
prediction: ['[CLS] when ur kerman when if at 66 leaves - has stopped very challenging himself [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.914 (perp=8.937, rec=0.127), tot_loss_proj:2.905 [t=0.20s]
prediction: ['[CLS] when ur kerman when if at 66 leaves - has stopped very challenging himself [SEP]']
Attempt swap
[1000/2000] tot_loss=1.892 (perp=8.887, rec=0.114), tot_loss_proj:2.884 [t=0.26s]
prediction: ['[CLS] when ur allen when if at 66 leaves - has stopped very challenging himself [SEP]']
[1050/2000] tot_loss=1.887 (perp=8.887, rec=0.110), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS] when ur allen when if at 66 leaves - has stopped very challenging himself [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.836 (perp=8.638, rec=0.108), tot_loss_proj:2.752 [t=0.25s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]']
Attempt swap
[1150/2000] tot_loss=1.842 (perp=8.638, rec=0.115), tot_loss_proj:2.750 [t=0.26s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]']
[1200/2000] tot_loss=1.841 (perp=8.638, rec=0.113), tot_loss_proj:2.755 [t=0.27s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]']
Attempt swap
[1250/2000] tot_loss=1.879 (perp=8.818, rec=0.116), tot_loss_proj:2.799 [t=0.25s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
[1300/2000] tot_loss=1.877 (perp=8.818, rec=0.113), tot_loss_proj:2.803 [t=0.26s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
[1350/2000] tot_loss=1.879 (perp=8.818, rec=0.116), tot_loss_proj:2.802 [t=0.28s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
[1400/2000] tot_loss=1.875 (perp=8.818, rec=0.111), tot_loss_proj:2.804 [t=0.28s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
[1450/2000] tot_loss=1.870 (perp=8.818, rec=0.107), tot_loss_proj:2.802 [t=0.26s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
[1500/2000] tot_loss=1.879 (perp=8.818, rec=0.115), tot_loss_proj:2.803 [t=0.27s]
prediction: ['[CLS] when ur when if at 66 leaves - allen has stopped ( challenging himself [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.834 (perp=8.592, rec=0.115), tot_loss_proj:2.775 [t=0.27s]
prediction: ['[CLS] when ( when if at 66 leaves - allen has stopped ur challenging himself [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.880 (perp=8.892, rec=0.102), tot_loss_proj:3.413 [t=0.27s]
prediction: ['[CLS] when ( - if at 66 proper when allen has stopped ur challenging himself [SEP]']
[1650/2000] tot_loss=1.890 (perp=8.892, rec=0.111), tot_loss_proj:3.412 [t=0.25s]
prediction: ['[CLS] when ( - if at 66 proper when allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.815 (perp=8.558, rec=0.103), tot_loss_proj:3.309 [t=0.27s]
prediction: ['[CLS] when if ( - at 66 proper when allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.793 (perp=8.415, rec=0.110), tot_loss_proj:3.194 [t=0.28s]
prediction: ['[CLS] when if ( - at 66 when leaves allen has stopped ur challenging himself [SEP]']
[1800/2000] tot_loss=1.798 (perp=8.415, rec=0.115), tot_loss_proj:3.190 [t=0.27s]
prediction: ['[CLS] when if ( - at 66 when leaves allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.754 (perp=8.211, rec=0.111), tot_loss_proj:3.293 [t=0.26s]
prediction: ['[CLS] when if - ( at 66 when proper allen has stopped ur challenging himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.753 (perp=8.211, rec=0.111), tot_loss_proj:3.294 [t=0.29s]
prediction: ['[CLS] when if - ( at 66 when proper allen has stopped ur challenging himself [SEP]']
[1950/2000] tot_loss=1.822 (perp=8.515, rec=0.119), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] when as - ( at 66 when proper allen has stopped ur challenging himself [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.743 (perp=8.148, rec=0.113), tot_loss_proj:3.287 [t=0.26s]
prediction: ['[CLS] when as ( at 66 - when proper allen has stopped ur challenging himself [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] when ur when if at 66 leaves - allen has stopped very challenging himself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 66.667 | r: 83.333
rouge2     | fm: 32.000 | p: 28.571 | r: 36.364
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 106.074

[Aggregate metrics]:
rouge1     | fm: 75.661 | p: 74.595 | r: 77.198
rouge2     | fm: 40.336 | p: 40.054 | r: 40.872
rougeL     | fm: 68.337 | p: 67.416 | r: 69.713
rougeLsum  | fm: 68.488 | p: 67.496 | r: 69.847
r1fm+r2fm = 115.997

input #76 time: 0:09:35 | total time: 14:17:41


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
cosin similarity: -0.96511151779788 normalized error: 1.8886612138874637
cosin similarity: 0.9651115177978798 normalized error: 0.40625056343347843
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 1.666193725103536 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 1.6577978970606757 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 1.6427321829678994 for ['[CLS]cing conducted core worship often scientific rama riding clubs kira furrowed ta stack phenomenon leigh [SEP]']
[Init] best rec loss: 1.3998614203474378 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 1.3943678329145157 for ['[CLS] where medium limeraphicno ways ole sheep sometime purple outside win most gray park [SEP]']
[Init] best perm rec loss: 1.3934208400648185 for ['[CLS] medium outside purple gray ways sheep ole lime most park win sometime whereraphicno [SEP]']
[Init] best perm rec loss: 1.3891200283681246 for ['[CLS] whereno parkraphic sheep ways sometime gray most ole lime purple outside win medium [SEP]']
[Init] best perm rec loss: 1.3853828023597805 for ['[CLS] park medium where sheep purple grayraphic ole sometime winno outside lime ways most [SEP]']
[Init] best perm rec loss: 1.38414973943817 for ['[CLS] park lime where sheep gray ways sometime most oleraphic outsideno win purple medium [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.484, rec=0.413), tot_loss_proj:3.370 [t=0.26s]
prediction: ['[CLS]ه jean blue life capitalfy could its experience above brand be legend jacksonville sweet [SEP]']
[ 100/2000] tot_loss=2.684 (perp=11.807, rec=0.323), tot_loss_proj:3.528 [t=0.27s]
prediction: ['[CLS] its jean blue life life ka ins its experience above made be waterwski promised [SEP]']
[ 150/2000] tot_loss=2.592 (perp=11.522, rec=0.288), tot_loss_proj:3.429 [t=0.27s]
prediction: ['[CLS] its you love life life ka ins its position above promise above mythwski promised [SEP]']
[ 200/2000] tot_loss=2.520 (perp=11.429, rec=0.234), tot_loss_proj:3.476 [t=0.26s]
prediction: ['[CLS] is its feel life life pro ins its assets above make above mythstellar promised [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.396 (perp=10.864, rec=0.223), tot_loss_proj:3.452 [t=0.26s]
prediction: ['[CLS] is its believe life fly life insars promise above make above realmstellar composed [SEP]']
[ 300/2000] tot_loss=2.542 (perp=11.680, rec=0.206), tot_loss_proj:3.443 [t=0.27s]
prediction: ['[CLS] is its make lifeg believe thinkars promise above make above realm consideredars [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.345 (perp=10.799, rec=0.185), tot_loss_proj:3.390 [t=0.26s]
prediction: ['[CLS] is its make lifeg believe thinkars promise above promise above realm believears [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.163 (perp=9.937, rec=0.176), tot_loss_proj:3.170 [t=0.26s]
prediction: ['[CLS] is its make lifears believe thinkars promise above promise above material believeg [SEP]']
[ 450/2000] tot_loss=2.091 (perp=9.612, rec=0.169), tot_loss_proj:3.029 [t=0.25s]
prediction: ['[CLS] is its make lifears believe thinkars promise above that above material believeg [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.983 (perp=9.103, rec=0.162), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] is its make believe lifears thinkars promise above that above material believeg [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.977 (perp=9.103, rec=0.156), tot_loss_proj:2.911 [t=0.26s]
prediction: ['[CLS] is its make believears life thinkars promise above that above material believeat [SEP]']
[ 600/2000] tot_loss=2.231 (perp=10.387, rec=0.154), tot_loss_proj:3.095 [t=0.26s]
prediction: ['[CLS] is its make makesars life thinkars promise above that above material believe crow [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.092 (perp=9.720, rec=0.148), tot_loss_proj:3.193 [t=0.27s]
prediction: ['[CLS] is its make makes rely life thinkars promise above that the material believears [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.895 (perp=8.683, rec=0.159), tot_loss_proj:2.953 [t=0.27s]
prediction: ['[CLS] is its material makes rely life thinkars promise above that the make believears [SEP]']
[ 750/2000] tot_loss=1.866 (perp=8.647, rec=0.137), tot_loss_proj:2.914 [t=0.26s]
prediction: ['[CLS] is its material makes rely life thinkars promise above that the make believe so [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.830 (perp=8.420, rec=0.146), tot_loss_proj:2.871 [t=0.26s]
prediction: ['[CLS] is its material makes rely life thinkars above promise that the make believe so [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.767 (perp=8.162, rec=0.135), tot_loss_proj:2.806 [t=0.25s]
prediction: ['[CLS] is its material rely make life thinkars above promise that the make believe so [SEP]']
[ 900/2000] tot_loss=1.769 (perp=8.162, rec=0.136), tot_loss_proj:2.816 [t=0.26s]
prediction: ['[CLS] is its material rely make life thinkars above promise that the make believe so [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.916 (perp=8.955, rec=0.125), tot_loss_proj:2.918 [t=0.26s]
prediction: ['[CLS] is its material rely make life thinkars above promise that the believe believe so [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.799 (perp=8.317, rec=0.135), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] is its material rely make life think promise that the believe realm soars above [SEP]']
[1050/2000] tot_loss=1.781 (perp=8.317, rec=0.118), tot_loss_proj:2.318 [t=0.27s]
prediction: ['[CLS] is its material rely make life think promise that the believe realm soars above [SEP]']
Attempt swap
[1100/2000] tot_loss=1.777 (perp=8.317, rec=0.114), tot_loss_proj:2.320 [t=0.26s]
prediction: ['[CLS] is its material rely make life think promise that the believe realm soars above [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.882 (perp=8.825, rec=0.117), tot_loss_proj:2.510 [t=0.27s]
prediction: ['[CLS] is its material rely make life sh promise believe that the realm soars above [SEP]']
[1200/2000] tot_loss=1.927 (perp=9.069, rec=0.113), tot_loss_proj:2.470 [t=0.29s]
prediction: ['[CLS] is its materialll make life sh promise believe that the realm soars above [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.679 (perp=7.845, rec=0.110), tot_loss_proj:2.187 [t=0.26s]
prediction: ['[CLS] is its material keeps entirely make life promise believe that the realm soars above [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.737 (perp=8.139, rec=0.110), tot_loss_proj:2.206 [t=0.26s]
prediction: ['[CLS] is its material keeps make life cube promise believe that the realm soars above [SEP]']
[1350/2000] tot_loss=1.738 (perp=8.139, rec=0.111), tot_loss_proj:2.211 [t=0.27s]
prediction: ['[CLS] is its material keeps make life cube promise believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.686 (perp=7.921, rec=0.102), tot_loss_proj:2.177 [t=0.25s]
prediction: ['[CLS] is its material keeps make life promise cube believe that the realm soars above [SEP]']
Attempt swap
[1450/2000] tot_loss=1.695 (perp=7.921, rec=0.110), tot_loss_proj:2.169 [t=0.26s]
prediction: ['[CLS] is its material keeps make life promise cube believe that the realm soars above [SEP]']
[1500/2000] tot_loss=1.822 (perp=8.601, rec=0.101), tot_loss_proj:2.402 [t=0.26s]
prediction: ['[CLS] is its materiallyn make life promise cube believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.811 (perp=8.535, rec=0.104), tot_loss_proj:2.329 [t=0.27s]
prediction: ['[CLS] is its make keeps material life promise cube believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.798 (perp=8.430, rec=0.112), tot_loss_proj:2.271 [t=0.27s]
prediction: ['[CLS] is its keeps make material life promise cube believe that the realm soars above [SEP]']
[1650/2000] tot_loss=1.790 (perp=8.430, rec=0.104), tot_loss_proj:2.274 [t=0.28s]
prediction: ['[CLS] is its keeps make material life promise cube believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.764 (perp=8.285, rec=0.107), tot_loss_proj:2.236 [t=0.30s]
prediction: ['[CLS] is its keeps make cube life promise material believe that the realm soars above [SEP]']
Attempt swap
[1750/2000] tot_loss=1.936 (perp=9.171, rec=0.101), tot_loss_proj:2.513 [t=0.27s]
prediction: ['[CLS] is itslyn make cube life promise material believe that the realm soars above [SEP]']
[1800/2000] tot_loss=1.939 (perp=9.171, rec=0.105), tot_loss_proj:2.506 [t=0.26s]
prediction: ['[CLS] is itslyn make cube life promise material believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.802 (perp=8.480, rec=0.106), tot_loss_proj:2.288 [t=0.28s]
prediction: ['[CLS] is its make keeps cube life promise material believe that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.777 (perp=8.349, rec=0.107), tot_loss_proj:2.271 [t=0.27s]
prediction: ['[CLS] is its make believe cube life promise material keeps that the realm soars above [SEP]']
[1950/2000] tot_loss=1.808 (perp=8.514, rec=0.105), tot_loss_proj:2.305 [t=0.26s]
prediction: ['[CLS] is its make believe cube life promise materiallyn that the realm soars above [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.766 (perp=8.306, rec=0.105), tot_loss_proj:2.289 [t=0.26s]
prediction: ['[CLS] is its make believe life cube promise materiallyn that the realm soars above [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is its make believe cube life promise materiallyn that the realm soars above [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 122.381

[Aggregate metrics]:
rouge1     | fm: 75.830 | p: 74.706 | r: 77.317
rouge2     | fm: 40.311 | p: 39.957 | r: 40.785
rougeL     | fm: 68.418 | p: 67.503 | r: 69.815
rougeLsum  | fm: 68.350 | p: 67.416 | r: 69.729
r1fm+r2fm = 116.141

input #77 time: 0:11:05 | total time: 14:28:47


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
cosin similarity: 0.9052137094556744 normalized error: 0.5044539339140962
cosin similarity: -0.9052137094556745 normalized error: 1.7215015739206312
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 1.9062914134112117 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 1.8520335989306531 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 1.498924850161912 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 1.4925886357125542 for ['[CLS] v focus wang [SEP]']
[Init] best rec loss: 1.3836849457314573 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 1.3773987256555427 for ['[CLS] le grant screens [SEP]']
[Init] best perm rec loss: 1.3753151746446246 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 1.373104293474772 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.269 (perp=9.321, rec=0.405), tot_loss_proj:2.920 [t=0.25s]
prediction: ['[CLS] exit pack exit [SEP]']
[ 100/2000] tot_loss=2.022 (perp=8.971, rec=0.228), tot_loss_proj:2.701 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.979 (perp=8.971, rec=0.184), tot_loss_proj:2.701 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.959 (perp=8.971, rec=0.165), tot_loss_proj:2.697 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.959 (perp=8.971, rec=0.164), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 300/2000] tot_loss=1.963 (perp=8.971, rec=0.168), tot_loss_proj:2.709 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.950 (perp=8.971, rec=0.156), tot_loss_proj:2.701 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.948 (perp=8.971, rec=0.154), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 450/2000] tot_loss=1.943 (perp=8.971, rec=0.149), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.935 (perp=8.971, rec=0.140), tot_loss_proj:2.706 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.949 (perp=8.971, rec=0.155), tot_loss_proj:2.707 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 600/2000] tot_loss=1.939 (perp=8.971, rec=0.144), tot_loss_proj:2.707 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.943 (perp=8.971, rec=0.149), tot_loss_proj:2.706 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.943 (perp=8.971, rec=0.149), tot_loss_proj:2.704 [t=0.27s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 750/2000] tot_loss=1.934 (perp=8.971, rec=0.140), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.929 (perp=8.971, rec=0.135), tot_loss_proj:2.708 [t=0.25s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.940 (perp=8.971, rec=0.146), tot_loss_proj:2.712 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 900/2000] tot_loss=1.941 (perp=8.971, rec=0.147), tot_loss_proj:2.711 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.932 (perp=8.971, rec=0.137), tot_loss_proj:2.707 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.938 (perp=8.971, rec=0.143), tot_loss_proj:2.701 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
[1050/2000] tot_loss=1.930 (perp=8.971, rec=0.135), tot_loss_proj:2.705 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.929 (perp=8.971, rec=0.135), tot_loss_proj:2.704 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.935 (perp=8.971, rec=0.141), tot_loss_proj:2.709 [t=0.31s]
prediction: ['[CLS] exit theater exit [SEP]']
[1200/2000] tot_loss=1.921 (perp=8.971, rec=0.127), tot_loss_proj:2.706 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.929 (perp=8.971, rec=0.134), tot_loss_proj:2.709 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.924 (perp=8.971, rec=0.129), tot_loss_proj:2.707 [t=0.31s]
prediction: ['[CLS] exit theater exit [SEP]']
[1350/2000] tot_loss=1.933 (perp=8.971, rec=0.139), tot_loss_proj:2.707 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=8.971, rec=0.137), tot_loss_proj:2.704 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.924 (perp=8.971, rec=0.130), tot_loss_proj:2.703 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
[1500/2000] tot_loss=1.927 (perp=8.971, rec=0.132), tot_loss_proj:2.701 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.926 (perp=8.971, rec=0.132), tot_loss_proj:2.704 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.924 (perp=8.971, rec=0.129), tot_loss_proj:2.704 [t=0.30s]
prediction: ['[CLS] exit theater exit [SEP]']
[1650/2000] tot_loss=1.927 (perp=8.971, rec=0.133), tot_loss_proj:2.706 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.927 (perp=8.971, rec=0.132), tot_loss_proj:2.706 [t=0.31s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.928 (perp=8.971, rec=0.134), tot_loss_proj:2.704 [t=0.31s]
prediction: ['[CLS] exit theater exit [SEP]']
[1800/2000] tot_loss=1.929 (perp=8.971, rec=0.135), tot_loss_proj:2.706 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.928 (perp=8.971, rec=0.134), tot_loss_proj:2.699 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.920 (perp=8.971, rec=0.126), tot_loss_proj:2.702 [t=0.28s]
prediction: ['[CLS] exit theater exit [SEP]']
[1950/2000] tot_loss=1.919 (perp=8.971, rec=0.125), tot_loss_proj:2.705 [t=0.29s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=2.449 (perp=11.605, rec=0.128), tot_loss_proj:3.329 [t=0.32s]
prediction: ['[CLS] exit theater tamara [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 75.878 | p: 74.825 | r: 77.354
rouge2     | fm: 40.116 | p: 39.727 | r: 40.564
rougeL     | fm: 68.593 | p: 67.731 | r: 69.916
rougeLsum  | fm: 68.549 | p: 67.537 | r: 69.971
r1fm+r2fm = 115.994

input #78 time: 0:11:46 | total time: 14:40:33


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
cosin similarity: -0.9542445893279807 normalized error: 1.8914472775898075
cosin similarity: 0.9542445893279807 normalized error: 0.4098774975167472
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 1.92151040770786 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 1.916817931985512 for ['[CLS] scoutsᴵ [SEP]']
[Init] best rec loss: 1.896975546355378 for ['[CLS] chicago militia [SEP]']
[Init] best rec loss: 1.8672783061280573 for ['[CLS] notation nu [SEP]']
[Init] best rec loss: 1.608048471705002 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 1.4920240202236046 for ['[CLS] combined quickly [SEP]']
[Init] best rec loss: 1.4482479800464858 for ['[CLS]wl patrol [SEP]']
[Init] best rec loss: 1.2479964178600431 for ['[CLS] texas qualified [SEP]']
[Init] best rec loss: 1.0314914604474852 for ['[CLS] own terrain [SEP]']
[Init] best perm rec loss: 1.0254998278411258 for ['[CLS] terrain own [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.565 (perp=11.427, rec=0.279), tot_loss_proj:2.706 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.535 (perp=11.427, rec=0.250), tot_loss_proj:2.703 [t=0.30s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.489 (perp=11.427, rec=0.204), tot_loss_proj:2.713 [t=0.31s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=1.881 (perp=8.695, rec=0.142), tot_loss_proj:2.082 [t=0.31s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.078 [t=0.30s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.078 [t=0.32s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.891 (perp=8.695, rec=0.152), tot_loss_proj:2.069 [t=0.29s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.887 (perp=8.695, rec=0.148), tot_loss_proj:2.086 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.075 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.894 (perp=8.695, rec=0.155), tot_loss_proj:2.074 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.892 (perp=8.695, rec=0.153), tot_loss_proj:2.077 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.881 (perp=8.695, rec=0.142), tot_loss_proj:2.073 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.882 (perp=8.695, rec=0.143), tot_loss_proj:2.075 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.896 (perp=8.695, rec=0.157), tot_loss_proj:2.069 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=8.695, rec=0.151), tot_loss_proj:2.079 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.887 (perp=8.695, rec=0.148), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.894 (perp=8.695, rec=0.155), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.874 (perp=8.695, rec=0.135), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.894 (perp=8.695, rec=0.155), tot_loss_proj:2.083 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.873 (perp=8.695, rec=0.135), tot_loss_proj:2.077 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=8.695, rec=0.149), tot_loss_proj:2.078 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.891 (perp=8.695, rec=0.152), tot_loss_proj:2.080 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.878 (perp=8.695, rec=0.139), tot_loss_proj:2.078 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.892 (perp=8.695, rec=0.153), tot_loss_proj:2.074 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.887 (perp=8.695, rec=0.148), tot_loss_proj:2.082 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.875 (perp=8.695, rec=0.136), tot_loss_proj:2.079 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.892 (perp=8.695, rec=0.153), tot_loss_proj:2.078 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.081 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.884 (perp=8.695, rec=0.145), tot_loss_proj:2.077 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.897 (perp=8.695, rec=0.158), tot_loss_proj:2.078 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.890 (perp=8.695, rec=0.151), tot_loss_proj:2.067 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.891 (perp=8.695, rec=0.152), tot_loss_proj:2.071 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.880 (perp=8.695, rec=0.141), tot_loss_proj:2.079 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.885 (perp=8.695, rec=0.146), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.883 (perp=8.695, rec=0.144), tot_loss_proj:2.083 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.890 (perp=8.695, rec=0.151), tot_loss_proj:2.083 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.883 (perp=8.695, rec=0.144), tot_loss_proj:2.067 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 76.227 | p: 75.179 | r: 77.604
rouge2     | fm: 39.793 | p: 39.457 | r: 40.271
rougeL     | fm: 68.550 | p: 67.676 | r: 69.839
rougeLsum  | fm: 68.674 | p: 67.749 | r: 69.982
r1fm+r2fm = 116.020

input #79 time: 0:11:18 | total time: 14:51:51


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
cosin similarity: 0.9707110677809513 normalized error: 0.39211658681230543
cosin similarity: -0.9707110677809512 normalized error: 1.9159028974782109
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 1.8992503833461423 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 1.746037412600804 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 1.7210905498079565 for ['[CLS] we message phantom sir carpathian [SEP]']
[Init] best rec loss: 1.6528549078043888 for ['[CLS] here lecture mid [MASK]kko [SEP]']
[Init] best rec loss: 1.5989477478729168 for ['[CLS]ghtlving dried days dressing [SEP]']
[Init] best perm rec loss: 1.5970663445019415 for ['[CLS] dried daysghtlving dressing [SEP]']
[Init] best perm rec loss: 1.593624974902322 for ['[CLS] dried days dressingghtlving [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.554 (perp=14.140, rec=0.726), tot_loss_proj:4.722 [t=0.25s]
prediction: ['[CLS] inuit eyebrows fine oppositionop [SEP]']
[ 100/2000] tot_loss=3.365 (perp=13.650, rec=0.636), tot_loss_proj:4.216 [t=0.26s]
prediction: ['[CLS] stupid overs finezenski [SEP]']
[ 150/2000] tot_loss=3.309 (perp=12.855, rec=0.738), tot_loss_proj:4.049 [t=0.27s]
prediction: ['[CLS] stupiddate blank ltnor [SEP]']
[ 200/2000] tot_loss=3.315 (perp=13.355, rec=0.644), tot_loss_proj:4.428 [t=0.27s]
prediction: ['[CLS] candidate tech ash lt diet [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.252 (perp=13.439, rec=0.564), tot_loss_proj:4.620 [t=0.26s]
prediction: ['[CLS] ucinniszen offera [SEP]']
[ 300/2000] tot_loss=2.592 (perp=10.285, rec=0.535), tot_loss_proj:3.987 [t=0.26s]
prediction: ['[CLS]ernniszen niera [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.767 (perp=10.699, rec=0.627), tot_loss_proj:4.091 [t=0.26s]
prediction: ['[CLS] ninniszen candidatezen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.417 (perp=9.455, rec=0.526), tot_loss_proj:3.805 [t=0.26s]
prediction: ['[CLS] ninniszenzenves [SEP]']
[ 450/2000] tot_loss=3.345 (perp=14.143, rec=0.516), tot_loss_proj:3.992 [t=0.26s]
prediction: ['[CLS] ni learnzenzen wise [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.886 (perp=11.958, rec=0.495), tot_loss_proj:3.421 [t=0.26s]
prediction: ['[CLS] nizenzen learn wise [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.658 (perp=15.108, rec=0.636), tot_loss_proj:4.969 [t=0.26s]
prediction: ['[CLS] issnveszen learnae [SEP]']
[ 600/2000] tot_loss=3.465 (perp=14.565, rec=0.552), tot_loss_proj:4.866 [t=0.26s]
prediction: ['[CLS] linedveszen learnius [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.113 (perp=12.969, rec=0.520), tot_loss_proj:4.322 [t=0.26s]
prediction: ['[CLS] lined wisezenzen learn [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.948 (perp=12.159, rec=0.516), tot_loss_proj:3.077 [t=0.27s]
prediction: ['[CLS] wise wizenzen learn [SEP]']
[ 750/2000] tot_loss=2.918 (perp=12.159, rec=0.486), tot_loss_proj:3.083 [t=0.26s]
prediction: ['[CLS] wise wizenzen learn [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.031 (perp=12.624, rec=0.506), tot_loss_proj:3.461 [t=0.25s]
prediction: ['[CLS] wise wizen palmer learn [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.955 (perp=12.356, rec=0.484), tot_loss_proj:3.444 [t=0.25s]
prediction: ['[CLS] wise wizen petersen learn [SEP]']
[ 900/2000] tot_loss=2.980 (perp=12.356, rec=0.508), tot_loss_proj:3.449 [t=0.26s]
prediction: ['[CLS] wise wizen petersen learn [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.952 (perp=12.356, rec=0.481), tot_loss_proj:3.453 [t=0.25s]
prediction: ['[CLS] wise wizen petersen learn [SEP]']
Attempt swap
[1000/2000] tot_loss=2.883 (perp=12.088, rec=0.465), tot_loss_proj:3.575 [t=0.27s]
prediction: ['[CLS] wise wizenaur learn [SEP]']
[1050/2000] tot_loss=2.783 (perp=11.644, rec=0.454), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1100/2000] tot_loss=2.801 (perp=11.644, rec=0.472), tot_loss_proj:3.274 [t=0.28s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1150/2000] tot_loss=2.775 (perp=11.644, rec=0.446), tot_loss_proj:3.282 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1200/2000] tot_loss=2.774 (perp=11.644, rec=0.445), tot_loss_proj:3.270 [t=0.27s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1250/2000] tot_loss=2.773 (perp=11.644, rec=0.445), tot_loss_proj:3.276 [t=0.28s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1300/2000] tot_loss=2.782 (perp=11.644, rec=0.453), tot_loss_proj:3.273 [t=0.27s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1350/2000] tot_loss=2.769 (perp=11.644, rec=0.440), tot_loss_proj:3.278 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1400/2000] tot_loss=2.763 (perp=11.644, rec=0.435), tot_loss_proj:3.274 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1450/2000] tot_loss=2.765 (perp=11.644, rec=0.437), tot_loss_proj:3.275 [t=0.27s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1500/2000] tot_loss=2.768 (perp=11.644, rec=0.439), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1550/2000] tot_loss=2.763 (perp=11.644, rec=0.434), tot_loss_proj:3.271 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1600/2000] tot_loss=2.757 (perp=11.644, rec=0.428), tot_loss_proj:3.272 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1650/2000] tot_loss=2.759 (perp=11.644, rec=0.430), tot_loss_proj:3.273 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1700/2000] tot_loss=2.764 (perp=11.644, rec=0.435), tot_loss_proj:3.272 [t=0.27s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1750/2000] tot_loss=2.759 (perp=11.644, rec=0.430), tot_loss_proj:3.272 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1800/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1850/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[1900/2000] tot_loss=2.752 (perp=11.644, rec=0.424), tot_loss_proj:3.274 [t=0.25s]
prediction: ['[CLS] wise wizenius learn [SEP]']
[1950/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.278 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Attempt swap
[2000/2000] tot_loss=2.753 (perp=11.644, rec=0.424), tot_loss_proj:3.272 [t=0.26s]
prediction: ['[CLS] wise wizenius learn [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise wizenius learn [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 76.067 | p: 74.955 | r: 77.600
rouge2     | fm: 39.665 | p: 39.261 | r: 40.209
rougeL     | fm: 68.584 | p: 67.577 | r: 69.958
rougeLsum  | fm: 68.652 | p: 67.580 | r: 70.044
r1fm+r2fm = 115.732

input #80 time: 0:11:00 | total time: 15:02:52


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
cosin similarity: -0.9108721734199294 normalized error: 1.741715381589591
cosin similarity: 0.9108721734199295 normalized error: 0.4931494713940682
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 1.8293099945045699 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 1.5943592952630858 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 1.5742121294350335 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 1.4662792401728457 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 1.4483613597750806 for ['[CLS] mass seeneer off joe đ [SEP]']
[Init] best rec loss: 1.4483097384213772 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 1.4027965780698894 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 1.3837556186032505 for ['[CLS] eligibilityetched folk ava list cfl [SEP]']
[Init] best rec loss: 1.3711582294895788 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 1.3680713291447872 for ['[CLS] donaldson ivyvikplatedown proceeded [SEP]']
[Init] best perm rec loss: 1.367640960015664 for ['[CLS]vikdown donaldson proceeded ivyplate [SEP]']
[Init] best perm rec loss: 1.362997111250602 for ['[CLS]vik proceededdown donaldsonplate ivy [SEP]']
[Init] best perm rec loss: 1.3623241379086424 for ['[CLS]vikdown ivy donaldson proceededplate [SEP]']
[Init] best perm rec loss: 1.362096490695115 for ['[CLS] ivyvik proceededdown donaldsonplate [SEP]']
[Init] best perm rec loss: 1.3593138508527556 for ['[CLS] donaldsondown proceededvik ivyplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.100 (perp=13.053, rec=0.489), tot_loss_proj:3.822 [t=0.26s]
prediction: ['[CLS] poorly stage military nobody oricon contested [SEP]']
[ 100/2000] tot_loss=2.597 (perp=11.191, rec=0.359), tot_loss_proj:3.217 [t=0.26s]
prediction: ['[CLS] not meeting nonetheless never impressive藤 [SEP]']
[ 150/2000] tot_loss=2.545 (perp=11.326, rec=0.280), tot_loss_proj:3.303 [t=0.28s]
prediction: ['[CLS] not prospect most not impressive藤 [SEP]']
[ 200/2000] tot_loss=2.543 (perp=11.513, rec=0.240), tot_loss_proj:3.074 [t=0.27s]
prediction: ['[CLS] not being mostlat impressive players [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.215 (perp=9.966, rec=0.222), tot_loss_proj:3.788 [t=0.25s]
prediction: ['[CLS] not is most impressive shoulder player [SEP]']
[ 300/2000] tot_loss=2.173 (perp=9.966, rec=0.180), tot_loss_proj:3.914 [t=0.25s]
prediction: ['[CLS] not is most impressive shoulder player [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.946 (perp=8.923, rec=0.161), tot_loss_proj:2.414 [t=0.26s]
prediction: ['[CLS] is not most impressive shoulder player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.925 (perp=8.923, rec=0.141), tot_loss_proj:2.413 [t=0.26s]
prediction: ['[CLS] is not most impressive shoulder player [SEP]']
[ 450/2000] tot_loss=1.940 (perp=8.944, rec=0.151), tot_loss_proj:2.561 [t=0.27s]
prediction: ['[CLS] is not most impressive been player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.939 (perp=8.944, rec=0.151), tot_loss_proj:2.570 [t=0.28s]
prediction: ['[CLS] is not most impressive been player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.915 (perp=8.944, rec=0.127), tot_loss_proj:2.564 [t=0.25s]
prediction: ['[CLS] is not most impressive been player [SEP]']
[ 600/2000] tot_loss=1.930 (perp=8.945, rec=0.141), tot_loss_proj:2.453 [t=0.28s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.931 (perp=8.945, rec=0.142), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.915 (perp=8.945, rec=0.126), tot_loss_proj:2.458 [t=0.26s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
[ 750/2000] tot_loss=1.919 (perp=8.945, rec=0.130), tot_loss_proj:2.463 [t=0.27s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.908 (perp=8.945, rec=0.119), tot_loss_proj:2.465 [t=0.25s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.910 (perp=8.945, rec=0.121), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] is not most impressivecus player [SEP]']
[ 900/2000] tot_loss=1.940 (perp=9.038, rec=0.132), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] is not most impressive absolutely player [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.004 (perp=9.288, rec=0.147), tot_loss_proj:3.038 [t=0.28s]
prediction: ['[CLS] is not most condensed impressive player [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.977 (perp=9.107, rec=0.156), tot_loss_proj:2.593 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1050/2000] tot_loss=1.971 (perp=9.107, rec=0.150), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.965 (perp=9.107, rec=0.144), tot_loss_proj:2.584 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.964 (perp=9.107, rec=0.143), tot_loss_proj:2.585 [t=0.27s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1200/2000] tot_loss=1.963 (perp=9.107, rec=0.142), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.975 (perp=9.107, rec=0.154), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=9.107, rec=0.143), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.107, rec=0.149), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.959 (perp=9.107, rec=0.137), tot_loss_proj:2.594 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.965 (perp=9.107, rec=0.143), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1500/2000] tot_loss=1.965 (perp=9.107, rec=0.143), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.973 (perp=9.107, rec=0.152), tot_loss_proj:2.594 [t=0.28s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.974 (perp=9.107, rec=0.152), tot_loss_proj:2.589 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1650/2000] tot_loss=1.960 (perp=9.107, rec=0.138), tot_loss_proj:2.590 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.966 (perp=9.107, rec=0.145), tot_loss_proj:2.592 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.969 (perp=9.107, rec=0.147), tot_loss_proj:2.595 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1800/2000] tot_loss=1.961 (perp=9.107, rec=0.140), tot_loss_proj:2.595 [t=0.27s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.961 (perp=9.107, rec=0.139), tot_loss_proj:2.598 [t=0.25s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.965 (perp=9.107, rec=0.144), tot_loss_proj:2.589 [t=0.28s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
[1950/2000] tot_loss=1.961 (perp=9.107, rec=0.139), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.959 (perp=9.107, rec=0.138), tot_loss_proj:2.593 [t=0.26s]
prediction: ['[CLS] is not most impressive condensed player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not most impressivecus player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 76.067 | p: 75.024 | r: 77.549
rouge2     | fm: 39.642 | p: 39.310 | r: 40.089
rougeL     | fm: 68.744 | p: 67.849 | r: 70.016
rougeLsum  | fm: 68.838 | p: 67.856 | r: 70.184
r1fm+r2fm = 115.709

input #81 time: 0:11:02 | total time: 15:13:55


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
cosin similarity: 0.8627532589286222 normalized error: 0.5239208010726941
cosin similarity: -0.8627532589286222 normalized error: 1.713868722056115
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 1.9232511060650235 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 1.7593884380864369 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 1.7294200531575432 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 1.6955706906365182 for ['[CLS] maltaierif ace players reserve hmm rpm [SEP]']
[Init] best rec loss: 1.6565519157416173 for ['[CLS] worse terms everyday down sandsbed supporting due [SEP]']
[Init] best rec loss: 1.6488327845043949 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 1.530765826551578 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 1.5301077648105523 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best rec loss: 1.5291422418169685 for ['[CLS] allegations bloodles noctuidae kappa before version where [SEP]']
[Init] best rec loss: 1.449259868093832 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 1.432699200229046 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 1.432098731195023 for ['[CLS]basket rolefurach whoever plumage respective record [SEP]']
[Init] best perm rec loss: 1.4316574518747034 for ['[CLS]furbasket role whoeverach respective record plumage [SEP]']
[Init] best perm rec loss: 1.429876031148659 for ['[CLS]basketfur role whoeverach plumage record respective [SEP]']
[Init] best perm rec loss: 1.429873857376806 for ['[CLS]basket whoeverach respective recordfur plumage role [SEP]']
[Init] best perm rec loss: 1.4272721424733839 for ['[CLS]basketfur respective whoever role plumage recordach [SEP]']
[Init] best perm rec loss: 1.42690239852947 for ['[CLS]basket whoever roleachfur respective plumage record [SEP]']
[Init] best perm rec loss: 1.4254638558439783 for ['[CLS]basketfur role respective recordach plumage whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.001 (perp=13.064, rec=0.388), tot_loss_proj:3.742 [t=0.26s]
prediction: ['[CLS] undone undone process lithuanian tradition shows undone hadley [SEP]']
[ 100/2000] tot_loss=2.616 (perp=11.813, rec=0.253), tot_loss_proj:3.472 [t=0.27s]
prediction: ["[CLS] undone undone 'keeping script script undone saetan [SEP]"]
[ 150/2000] tot_loss=2.452 (perp=11.356, rec=0.181), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] undone undone is hemisphere by script undone institutions [SEP]']
[ 200/2000] tot_loss=2.764 (perp=13.126, rec=0.139), tot_loss_proj:3.537 [t=0.26s]
prediction: ['[CLS] sloppy undone s suppose by script undone bandage [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.535 (perp=12.034, rec=0.128), tot_loss_proj:3.278 [t=0.25s]
prediction: ['[CLS] undone sstellar by sloppy script undone bandage [SEP]']
[ 300/2000] tot_loss=2.396 (perp=11.353, rec=0.125), tot_loss_proj:3.101 [t=0.25s]
prediction: ['[CLS] undone s pomeranian by sloppy script undone bandage [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.472 (perp=10.179, rec=0.436), tot_loss_proj:2.659 [t=0.27s]
prediction: ['[CLS] undone is undone by sloppy script half item [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.531 (perp=10.953, rec=0.341), tot_loss_proj:3.000 [t=0.26s]
prediction: ['[CLS] undone centenary it undone by sloppy script item [SEP]']
[ 450/2000] tot_loss=2.486 (perp=10.978, rec=0.290), tot_loss_proj:2.948 [t=0.25s]
prediction: ['[CLS] undone sideways itllen by sloppy script item [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.525 (perp=11.295, rec=0.266), tot_loss_proj:2.977 [t=0.27s]
prediction: ['[CLS] undone item isllen by sloppy script sideways [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.233 (perp=9.976, rec=0.237), tot_loss_proj:2.628 [t=0.26s]
prediction: ['[CLS]llen item is undone by sloppy script sideways [SEP]']
[ 600/2000] tot_loss=2.215 (perp=9.976, rec=0.219), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS]llen item is undone by sloppy script sideways [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.212 (perp=9.976, rec=0.217), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS]llen item is undone by sloppy script sideways [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.314 (perp=10.583, rec=0.197), tot_loss_proj:2.716 [t=0.25s]
prediction: ['[CLS] itemllen is undone by sloppy script entrusted [SEP]']
[ 750/2000] tot_loss=2.312 (perp=10.583, rec=0.195), tot_loss_proj:2.717 [t=0.26s]
prediction: ['[CLS] itemllen is undone by sloppy script entrusted [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=2.246 (perp=10.283, rec=0.189), tot_loss_proj:2.615 [t=0.26s]
prediction: ['[CLS] entrusted itemllen is undone by sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.296 (perp=10.631, rec=0.169), tot_loss_proj:2.668 [t=0.26s]
prediction: ['[CLS] entrusted packagellen is undone by sloppy script [SEP]']
[ 900/2000] tot_loss=2.567 (perp=12.023, rec=0.163), tot_loss_proj:2.951 [t=0.26s]
prediction: ['[CLS] entrusted packagellen s undone by sloppy script [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.783 (perp=13.082, rec=0.167), tot_loss_proj:3.288 [t=0.27s]
prediction: ['[CLS] packagellen instrumental s undone by sloppy script [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=2.328 (perp=10.722, rec=0.183), tot_loss_proj:2.937 [t=0.27s]
prediction: ['[CLS] s undone by sloppy script packagellen instrumental [SEP]']
[1050/2000] tot_loss=2.389 (perp=11.064, rec=0.176), tot_loss_proj:3.004 [t=0.26s]
prediction: ['[CLS] s undone by sloppy script itemllen instrumental [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.177 (perp=10.074, rec=0.162), tot_loss_proj:2.669 [t=0.25s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1150/2000] tot_loss=2.236 (perp=10.379, rec=0.160), tot_loss_proj:2.821 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental outcome [SEP]']
[1200/2000] tot_loss=2.235 (perp=10.379, rec=0.160), tot_loss_proj:2.826 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental outcome [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.489 (perp=11.653, rec=0.159), tot_loss_proj:3.017 [t=0.28s]
prediction: ['[CLS] s instrumental item undone by sloppy scriptllen [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.169 (perp=10.074, rec=0.154), tot_loss_proj:2.675 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1350/2000] tot_loss=2.180 (perp=10.074, rec=0.165), tot_loss_proj:2.669 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1400/2000] tot_loss=2.173 (perp=10.074, rec=0.159), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1450/2000] tot_loss=2.160 (perp=10.074, rec=0.145), tot_loss_proj:2.667 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1500/2000] tot_loss=2.164 (perp=10.074, rec=0.149), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1550/2000] tot_loss=2.163 (perp=10.074, rec=0.148), tot_loss_proj:2.669 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1600/2000] tot_loss=2.163 (perp=10.074, rec=0.148), tot_loss_proj:2.671 [t=0.28s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1650/2000] tot_loss=2.158 (perp=10.074, rec=0.143), tot_loss_proj:2.665 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1700/2000] tot_loss=2.155 (perp=10.074, rec=0.140), tot_loss_proj:2.679 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1750/2000] tot_loss=2.169 (perp=10.074, rec=0.154), tot_loss_proj:2.675 [t=0.28s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1800/2000] tot_loss=2.157 (perp=10.074, rec=0.143), tot_loss_proj:2.678 [t=0.29s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1850/2000] tot_loss=2.173 (perp=10.074, rec=0.158), tot_loss_proj:2.668 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[1900/2000] tot_loss=2.161 (perp=10.074, rec=0.146), tot_loss_proj:2.673 [t=0.26s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
[1950/2000] tot_loss=2.152 (perp=10.074, rec=0.138), tot_loss_proj:2.677 [t=0.27s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Attempt swap
[2000/2000] tot_loss=2.153 (perp=10.074, rec=0.139), tot_loss_proj:2.677 [t=0.30s]
prediction: ['[CLS] s undone by sloppy scriptllen instrumental item [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] undone s pomeranian by sloppy script undone bandage [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 76.046 | p: 74.976 | r: 77.540
rouge2     | fm: 39.371 | p: 39.068 | r: 39.854
rougeL     | fm: 68.736 | p: 67.740 | r: 70.093
rougeLsum  | fm: 68.709 | p: 67.770 | r: 70.014
r1fm+r2fm = 115.417

input #82 time: 0:11:06 | total time: 15:25:01


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
cosin similarity: 0.926325547377931 normalized error: 0.4375947399134601
cosin similarity: -0.926325547377931 normalized error: 1.855119767074716
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 1.8595740001953698 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 1.843287356173501 for ['[CLS] expressing congratulations butch evacuate copyright grenadasome snow paid confidence [SEP]']
[Init] best rec loss: 1.820005483585518 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 1.7389689969756927 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 1.7380943515029363 for ['[CLS]ki car sebastian positions directed gleam here visiting scope easier [SEP]']
[Init] best rec loss: 1.6253996902143903 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 1.555076169647435 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best perm rec loss: 1.5486948480774083 for ['[CLS] hit already use £ benji runaway mercy wild publishing someone [SEP]']
[Init] best perm rec loss: 1.547261495508724 for ['[CLS] already £ publishing use hit mercy someone wild benji runaway [SEP]']
[Init] best perm rec loss: 1.5465915335737765 for ['[CLS] benji already someone £ use mercy wild publishing runaway hit [SEP]']
[Init] best perm rec loss: 1.5465131298345318 for ['[CLS] mercy already publishing use £ hit wild benji runaway someone [SEP]']
[Init] best perm rec loss: 1.5418853219075874 for ['[CLS] benji publishing £ already use runaway hit mercy wild someone [SEP]']
[Init] best perm rec loss: 1.5413632965528183 for ['[CLS] publishing £ already benji runaway use hit someone mercy wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.975 (perp=12.176, rec=0.540), tot_loss_proj:3.590 [t=0.20s]
prediction: ['[CLS] really makesness austrian inaiest to something powerness [SEP]']
[ 100/2000] tot_loss=2.835 (perp=12.351, rec=0.365), tot_loss_proj:3.431 [t=0.20s]
prediction: ['[CLS] know gives environment early growsful how something powerity [SEP]']
[ 150/2000] tot_loss=2.690 (perp=11.998, rec=0.290), tot_loss_proj:3.676 [t=0.27s]
prediction: ['[CLS] know grows environment came growsfulhesion what power when [SEP]']
[ 200/2000] tot_loss=2.709 (perp=12.249, rec=0.259), tot_loss_proj:3.831 [t=0.27s]
prediction: ['[CLS] know wants up coming growsfulhesion what power when [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.800 (perp=12.505, rec=0.299), tot_loss_proj:4.028 [t=0.26s]
prediction: ['[CLS] know here... coming growsful peel what original when [SEP]']
[ 300/2000] tot_loss=2.603 (perp=11.821, rec=0.239), tot_loss_proj:4.245 [t=0.26s]
prediction: ['[CLS] know when up become grows when peel wants original when [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.233 (perp=10.059, rec=0.222), tot_loss_proj:3.698 [t=0.26s]
prediction: ['[CLS] know when original your grows to peel wants up when [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.029 (perp=9.109, rec=0.207), tot_loss_proj:3.001 [t=0.26s]
prediction: ['[CLS] know when energy your wants when peel grows up when [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.004, rec=0.187), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] know what energy your wants to peel be grows when [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.043 (perp=9.363, rec=0.170), tot_loss_proj:3.432 [t=0.28s]
prediction: ['[CLS] know what several energy wants to peel be grows when [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.028 (perp=9.348, rec=0.158), tot_loss_proj:2.809 [t=0.25s]
prediction: ['[CLS] know what it energy wants what besee grows when [SEP]']
[ 600/2000] tot_loss=2.071 (perp=9.600, rec=0.151), tot_loss_proj:2.963 [t=0.29s]
prediction: ['[CLS] know what it primary wants what besee grows when [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.973 (perp=9.093, rec=0.155), tot_loss_proj:2.963 [t=0.26s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.953 (perp=9.093, rec=0.134), tot_loss_proj:2.955 [t=0.27s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
[ 750/2000] tot_loss=1.939 (perp=9.093, rec=0.121), tot_loss_proj:2.962 [t=0.25s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.942 (perp=9.093, rec=0.124), tot_loss_proj:2.955 [t=0.27s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.941 (perp=9.093, rec=0.122), tot_loss_proj:2.962 [t=0.29s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
[ 900/2000] tot_loss=2.238 (perp=10.600, rec=0.118), tot_loss_proj:3.539 [t=0.29s]
prediction: ['[CLS] know let it wants what primary besee grows when [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.930 (perp=9.093, rec=0.111), tot_loss_proj:2.963 [t=0.25s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
Attempt swap
[1000/2000] tot_loss=1.932 (perp=9.093, rec=0.113), tot_loss_proj:2.964 [t=0.26s]
prediction: ['[CLS] know what it wants what primary besee grows when [SEP]']
[1050/2000] tot_loss=1.881 (perp=8.864, rec=0.108), tot_loss_proj:2.877 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1100/2000] tot_loss=1.883 (perp=8.864, rec=0.110), tot_loss_proj:2.877 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=8.864, rec=0.115), tot_loss_proj:2.882 [t=0.30s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
[1200/2000] tot_loss=1.888 (perp=8.864, rec=0.115), tot_loss_proj:2.883 [t=0.27s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1250/2000] tot_loss=1.885 (perp=8.864, rec=0.112), tot_loss_proj:2.875 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1300/2000] tot_loss=1.873 (perp=8.864, rec=0.100), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
[1350/2000] tot_loss=1.876 (perp=8.864, rec=0.103), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] know what it wants what nurse besee grows when [SEP]']
Attempt swap
[1400/2000] tot_loss=1.949 (perp=9.184, rec=0.112), tot_loss_proj:2.965 [t=0.26s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
Attempt swap
[1450/2000] tot_loss=1.940 (perp=9.184, rec=0.103), tot_loss_proj:2.962 [t=0.26s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
[1500/2000] tot_loss=1.935 (perp=9.184, rec=0.098), tot_loss_proj:2.960 [t=0.26s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.065 (perp=9.752, rec=0.114), tot_loss_proj:3.223 [t=0.29s]
prediction: ['[CLS] know what it wants what besee nurse grows when [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.259 (perp=10.741, rec=0.111), tot_loss_proj:3.566 [t=0.26s]
prediction: ['[CLS] know what it wants visit offs besee grows when [SEP]']
[1650/2000] tot_loss=2.250 (perp=10.741, rec=0.102), tot_loss_proj:3.567 [t=0.25s]
prediction: ['[CLS] know what it wants visit offs besee grows when [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.944 (perp=9.184, rec=0.107), tot_loss_proj:2.957 [t=0.29s]
prediction: ['[CLS] know what it wants what visit besee grows when [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.937 (perp=9.088, rec=0.120), tot_loss_proj:2.856 [t=0.26s]
prediction: ['[CLS] know what it wantssee visit be another grows when [SEP]']
[1800/2000] tot_loss=1.934 (perp=9.088, rec=0.117), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] know what it wantssee visit be another grows when [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.936 (perp=9.135, rec=0.109), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
Attempt swap
[1900/2000] tot_loss=1.934 (perp=9.135, rec=0.107), tot_loss_proj:2.767 [t=0.26s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
[1950/2000] tot_loss=1.931 (perp=9.135, rec=0.104), tot_loss_proj:2.770 [t=0.27s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
Attempt swap
[2000/2000] tot_loss=1.939 (perp=9.135, rec=0.112), tot_loss_proj:2.770 [t=0.27s]
prediction: ['[CLS] know what it wants besee visit beings grows when [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants what visit besee grows when [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 72.727 | r: 66.667
rouge2     | fm: 38.095 | p: 40.000 | r: 36.364
rougeL     | fm: 60.870 | p: 63.636 | r: 58.333
rougeLsum  | fm: 60.870 | p: 63.636 | r: 58.333
r1fm+r2fm = 107.660

[Aggregate metrics]:
rouge1     | fm: 76.021 | p: 75.038 | r: 77.397
rouge2     | fm: 39.253 | p: 38.905 | r: 39.681
rougeL     | fm: 68.549 | p: 67.713 | r: 69.795
rougeLsum  | fm: 68.624 | p: 67.729 | r: 69.868
r1fm+r2fm = 115.274

input #83 time: 0:10:46 | total time: 15:35:48


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
cosin similarity: 0.6775109157164033 normalized error: 0.6290108483508133
cosin similarity: -0.6775109157164034 normalized error: 1.6610204403509696
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 1.8604344756341837 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 1.780706662756565 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 1.7322435216346515 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 1.6610456675132736 for ['[CLS] sap diana resident than donovan november frustration [SEP]']
[Init] best rec loss: 1.638840420891208 for ['[CLS] runs transport rodney gonna guardsibe good [SEP]']
[Init] best rec loss: 1.5893669911224788 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 1.5666426593046832 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 1.5663105798792534 for ['[CLS] each itsiter infinite caused ca going [SEP]']
[Init] best perm rec loss: 1.563213897379615 for ['[CLS] infinite itsiter caused each ca going [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.781 (perp=11.407, rec=0.500), tot_loss_proj:4.130 [t=0.27s]
prediction: ['[CLS] cognitive shopping from old wealth black old [SEP]']
[ 100/2000] tot_loss=2.841 (perp=12.365, rec=0.368), tot_loss_proj:3.840 [t=0.28s]
prediction: ['[CLS] people shopping under dominican ability lost lost [SEP]']
[ 150/2000] tot_loss=2.443 (perp=10.762, rec=0.291), tot_loss_proj:3.389 [t=0.29s]
prediction: ['[CLS] people lost lack dominican ability lost lost [SEP]']
[ 200/2000] tot_loss=1.773 (perp=7.622, rec=0.249), tot_loss_proj:2.821 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.747 (perp=7.622, rec=0.223), tot_loss_proj:2.823 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 300/2000] tot_loss=1.733 (perp=7.622, rec=0.209), tot_loss_proj:2.827 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.723 (perp=7.622, rec=0.199), tot_loss_proj:2.811 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.718 (perp=7.622, rec=0.193), tot_loss_proj:2.809 [t=0.25s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 450/2000] tot_loss=1.707 (perp=7.622, rec=0.183), tot_loss_proj:2.813 [t=0.25s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.708 (perp=7.622, rec=0.184), tot_loss_proj:2.805 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.703 (perp=7.622, rec=0.178), tot_loss_proj:2.808 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 600/2000] tot_loss=1.698 (perp=7.622, rec=0.173), tot_loss_proj:2.808 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.698 (perp=7.622, rec=0.174), tot_loss_proj:2.807 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.697 (perp=7.622, rec=0.173), tot_loss_proj:2.804 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 750/2000] tot_loss=1.695 (perp=7.622, rec=0.171), tot_loss_proj:2.802 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.700 (perp=7.622, rec=0.176), tot_loss_proj:2.809 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=7.622, rec=0.162), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 900/2000] tot_loss=1.698 (perp=7.622, rec=0.173), tot_loss_proj:2.808 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.694 (perp=7.622, rec=0.170), tot_loss_proj:2.805 [t=0.25s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1000/2000] tot_loss=1.702 (perp=7.622, rec=0.177), tot_loss_proj:2.807 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1050/2000] tot_loss=1.684 (perp=7.622, rec=0.160), tot_loss_proj:2.807 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1100/2000] tot_loss=1.681 (perp=7.622, rec=0.156), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1150/2000] tot_loss=1.689 (perp=7.622, rec=0.164), tot_loss_proj:2.806 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1200/2000] tot_loss=1.692 (perp=7.622, rec=0.168), tot_loss_proj:2.802 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1250/2000] tot_loss=1.689 (perp=7.622, rec=0.165), tot_loss_proj:2.801 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1300/2000] tot_loss=1.690 (perp=7.622, rec=0.165), tot_loss_proj:2.805 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1350/2000] tot_loss=1.684 (perp=7.622, rec=0.160), tot_loss_proj:2.802 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1400/2000] tot_loss=1.689 (perp=7.622, rec=0.164), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1450/2000] tot_loss=1.688 (perp=7.622, rec=0.164), tot_loss_proj:2.799 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1500/2000] tot_loss=1.692 (perp=7.622, rec=0.167), tot_loss_proj:2.810 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1550/2000] tot_loss=1.677 (perp=7.622, rec=0.153), tot_loss_proj:2.806 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1600/2000] tot_loss=1.680 (perp=7.622, rec=0.156), tot_loss_proj:2.801 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1650/2000] tot_loss=1.683 (perp=7.622, rec=0.158), tot_loss_proj:2.803 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1700/2000] tot_loss=1.686 (perp=7.622, rec=0.162), tot_loss_proj:2.807 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1750/2000] tot_loss=1.686 (perp=7.622, rec=0.162), tot_loss_proj:2.805 [t=0.29s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1800/2000] tot_loss=1.684 (perp=7.622, rec=0.159), tot_loss_proj:2.805 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1850/2000] tot_loss=1.681 (perp=7.622, rec=0.156), tot_loss_proj:2.805 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1900/2000] tot_loss=1.683 (perp=7.622, rec=0.159), tot_loss_proj:2.802 [t=0.27s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1950/2000] tot_loss=1.697 (perp=7.622, rec=0.173), tot_loss_proj:2.798 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[2000/2000] tot_loss=1.685 (perp=7.622, rec=0.161), tot_loss_proj:2.801 [t=0.26s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people think have the ability have lost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 76.115 | p: 75.115 | r: 77.560
rouge2     | fm: 39.375 | p: 39.062 | r: 39.795
rougeL     | fm: 68.478 | p: 67.586 | r: 69.804
rougeLsum  | fm: 68.601 | p: 67.715 | r: 69.945
r1fm+r2fm = 115.490

input #84 time: 0:11:00 | total time: 15:46:48


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
cosin similarity: -0.758194645185029 normalized error: 1.6150630674115598
cosin similarity: 0.7581946451850291 normalized error: 0.6062368659084983
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 1.9792487864972446 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 1.889739081813596 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 1.86376137267988 for ['[CLS] brakeship and acronym senate developing technical leadrine reserve [SEP]']
[Init] best rec loss: 1.8207886867868974 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 1.8033760176761628 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 1.6487458544247389 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 1.5823604337713457 for ['[CLS]lete cecilcc goals bar [ rules man brodiestation [SEP]']
[Init] best perm rec loss: 1.5806840434510323 for ['[CLS] cecil brodie manstationcclete [ bar rules goals [SEP]']
[Init] best perm rec loss: 1.5806421137323081 for ['[CLS]stationcc cecil barlete goals [ man brodie rules [SEP]']
[Init] best perm rec loss: 1.580473489864845 for ['[CLS] rules brodieletestation [ cecil man barcc goals [SEP]']
[Init] best perm rec loss: 1.5781051322703572 for ['[CLS] rules cecil man bar goals brodie [leteccstation [SEP]']
[Init] best perm rec loss: 1.5772637594046084 for ['[CLS] barstation brodieletecc cecil [ man goals rules [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.897 (perp=12.134, rec=0.470), tot_loss_proj:3.719 [t=0.27s]
prediction: ['[CLS], commander wrong stomach refusedero record company poorly inch [SEP]']
[ 100/2000] tot_loss=3.043 (perp=13.263, rec=0.390), tot_loss_proj:4.065 [t=0.26s]
prediction: ['[CLS] unfortunately pathogen notoukharero record section not unfortunately [SEP]']
[ 150/2000] tot_loss=2.419 (perp=10.280, rec=0.363), tot_loss_proj:3.310 [t=0.26s]
prediction: ['[CLS] unfortunately pc unfortunately we anger favorite unfortunately is not unfortunately [SEP]']
[ 200/2000] tot_loss=2.199 (perp=9.350, rec=0.329), tot_loss_proj:3.066 [t=0.25s]
prediction: ['[CLS] unfortunately pc unfortunately he certainly mildly unfortunately, not unfortunately [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.213 (perp=9.592, rec=0.294), tot_loss_proj:3.848 [t=0.27s]
prediction: ['[CLS] unfortunately certainly unfortunately good although debate unfortunately, not unfortunately [SEP]']
[ 300/2000] tot_loss=2.051 (perp=9.053, rec=0.241), tot_loss_proj:3.508 [t=0.28s]
prediction: ['[CLS] unfortunately certainly unfortunately good good defeat unfortunately is not unfortunately [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.003 (perp=8.997, rec=0.204), tot_loss_proj:2.954 [t=0.27s]
prediction: ['[CLS] unfortunately very unfortunately good mildly unfortunately is not unfortunately good [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.063 (perp=9.303, rec=0.203), tot_loss_proj:3.796 [t=0.26s]
prediction: ['[CLS] also very unfortunately good it geoffrey unfortunately not unfortunately good [SEP]']
[ 450/2000] tot_loss=2.033 (perp=9.303, rec=0.172), tot_loss_proj:3.813 [t=0.28s]
prediction: ['[CLS] also very unfortunately good it geoffrey unfortunately not unfortunately good [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.927 (perp=8.826, rec=0.161), tot_loss_proj:3.662 [t=0.26s]
prediction: ['[CLS] also very good unfortunately it geoffrey unfortunately not unfortunately good [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.019 (perp=9.253, rec=0.169), tot_loss_proj:3.564 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also unfortunately not unfortunately thriller [SEP]']
[ 600/2000] tot_loss=1.941 (perp=8.934, rec=0.154), tot_loss_proj:3.216 [t=0.27s]
prediction: ['[CLS] idiot very good unfortunately it also unfortunately not unfortunately quite [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.878 (perp=8.615, rec=0.155), tot_loss_proj:3.157 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also unfortunately not quite unfortunately [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.874 (perp=8.615, rec=0.151), tot_loss_proj:3.161 [t=0.29s]
prediction: ['[CLS] idiot very good unfortunately it also unfortunately not quite unfortunately [SEP]']
[ 750/2000] tot_loss=1.876 (perp=8.615, rec=0.153), tot_loss_proj:3.160 [t=0.29s]
prediction: ['[CLS] idiot very good unfortunately it also unfortunately not quite unfortunately [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.896 (perp=8.776, rec=0.140), tot_loss_proj:2.898 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also badly not quite quite [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.900 (perp=8.776, rec=0.144), tot_loss_proj:2.897 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also badly not quite quite [SEP]']
[ 900/2000] tot_loss=1.906 (perp=8.776, rec=0.151), tot_loss_proj:2.908 [t=0.27s]
prediction: ['[CLS] idiot very good unfortunately it also badly not quite quite [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.897 (perp=8.776, rec=0.142), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] idiot very good unfortunately it also badly not quite quite [SEP]']
Attempt swap
[1000/2000] tot_loss=1.904 (perp=8.776, rec=0.149), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] idiot very good unfortunately it also badly not quite quite [SEP]']
[1050/2000] tot_loss=1.891 (perp=8.776, rec=0.136), tot_loss_proj:2.898 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also badly not quite quite [SEP]']
Attempt swap
[1100/2000] tot_loss=1.923 (perp=8.905, rec=0.142), tot_loss_proj:2.947 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also shortly not quite quite [SEP]']
Attempt swap
[1150/2000] tot_loss=1.930 (perp=8.905, rec=0.149), tot_loss_proj:2.944 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also shortly not quite quite [SEP]']
[1200/2000] tot_loss=1.928 (perp=8.905, rec=0.147), tot_loss_proj:2.948 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also shortly not quite quite [SEP]']
Attempt swap
[1250/2000] tot_loss=1.925 (perp=8.905, rec=0.144), tot_loss_proj:2.945 [t=0.25s]
prediction: ['[CLS] idiot very good unfortunately it also shortly not quite quite [SEP]']
Attempt swap
[1300/2000] tot_loss=2.100 (perp=9.778, rec=0.144), tot_loss_proj:3.156 [t=0.27s]
prediction: ['[CLS] idiot very good unfortunately it also shortly not quitenaud [SEP]']
[1350/2000] tot_loss=2.097 (perp=9.778, rec=0.141), tot_loss_proj:3.160 [t=0.26s]
prediction: ['[CLS] idiot very good unfortunately it also shortly not quitenaud [SEP]']
Attempt swap
[1400/2000] tot_loss=1.840 (perp=8.536, rec=0.133), tot_loss_proj:3.179 [t=0.27s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=8.536, rec=0.141), tot_loss_proj:3.186 [t=0.27s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
[1500/2000] tot_loss=1.831 (perp=8.536, rec=0.124), tot_loss_proj:3.176 [t=0.27s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.843 (perp=8.536, rec=0.135), tot_loss_proj:3.181 [t=0.26s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.838 (perp=8.536, rec=0.131), tot_loss_proj:3.188 [t=0.27s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
[1650/2000] tot_loss=1.838 (perp=8.536, rec=0.131), tot_loss_proj:3.185 [t=0.25s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.842 (perp=8.536, rec=0.135), tot_loss_proj:3.191 [t=0.26s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.836 (perp=8.536, rec=0.129), tot_loss_proj:3.187 [t=0.27s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
[1800/2000] tot_loss=1.831 (perp=8.536, rec=0.124), tot_loss_proj:3.181 [t=0.26s]
prediction: ['[CLS]just very good unfortunately it also shortly not quite. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.711 (perp=7.905, rec=0.130), tot_loss_proj:2.765 [t=0.26s]
prediction: ['[CLS]just good unfortunately it also very shortly not quite. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.718 (perp=7.905, rec=0.137), tot_loss_proj:2.767 [t=0.25s]
prediction: ['[CLS]just good unfortunately it also very shortly not quite. [SEP]']
[1950/2000] tot_loss=1.712 (perp=7.905, rec=0.131), tot_loss_proj:2.765 [t=0.27s]
prediction: ['[CLS]just good unfortunately it also very shortly not quite. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.722 (perp=7.905, rec=0.141), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS]just good unfortunately it also very shortly not quite. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS]just good unfortunately it also very shortly not quite. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 72.727 | r: 88.889
rouge2     | fm: 11.111 | p: 10.000 | r: 12.500
rougeL     | fm: 60.000 | p: 54.545 | r: 66.667
rougeLsum  | fm: 60.000 | p: 54.545 | r: 66.667
r1fm+r2fm = 91.111

[Aggregate metrics]:
rouge1     | fm: 76.194 | p: 75.058 | r: 77.695
rouge2     | fm: 38.848 | p: 38.483 | r: 39.317
rougeL     | fm: 68.439 | p: 67.514 | r: 69.738
rougeLsum  | fm: 68.477 | p: 67.512 | r: 69.821
r1fm+r2fm = 115.041

input #85 time: 0:11:01 | total time: 15:57:50


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
cosin similarity: 0.7228011680586494 normalized error: 0.5916657809355386
cosin similarity: -0.7228011680586492 normalized error: 1.7047895219844555
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 1.9290641428355495 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 1.809579803163229 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 1.7895126744156338 for ['[CLS] maria passingerative [SEP]']
[Init] best rec loss: 1.7761940937850853 for ['[CLS]riding ad u [SEP]']
[Init] best rec loss: 1.7161355214326077 for ['[CLS] middle pop deserves [SEP]']
[Init] best rec loss: 1.6140058836795657 for ['[CLS] bipolar sea set [SEP]']
[Init] best rec loss: 1.563752730479628 for ['[CLS] noah apron respect [SEP]']
[Init] best rec loss: 1.2615644615607815 for ['[CLS] talks karen flipped [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.046 (perp=12.028, rec=0.641), tot_loss_proj:3.251 [t=0.26s]
prediction: ['[CLS] exciting jessie clarity [SEP]']
[ 100/2000] tot_loss=2.920 (perp=12.819, rec=0.356), tot_loss_proj:3.459 [t=0.27s]
prediction: ['[CLS] exciting rapper clarity [SEP]']
[ 150/2000] tot_loss=2.741 (perp=12.328, rec=0.276), tot_loss_proj:3.392 [t=0.27s]
prediction: ['[CLS] emotional federer clarity [SEP]']
[ 200/2000] tot_loss=2.754 (perp=12.328, rec=0.288), tot_loss_proj:3.392 [t=0.26s]
prediction: ['[CLS] emotional federer clarity [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.395 (perp=10.690, rec=0.257), tot_loss_proj:3.014 [t=0.26s]
prediction: ['[CLS] federer emotional clarity [SEP]']
[ 300/2000] tot_loss=2.384 (perp=10.690, rec=0.246), tot_loss_proj:3.012 [t=0.27s]
prediction: ['[CLS] federer emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.365 (perp=10.690, rec=0.227), tot_loss_proj:3.023 [t=0.25s]
prediction: ['[CLS] federer emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.447 (perp=11.124, rec=0.223), tot_loss_proj:3.072 [t=0.25s]
prediction: ['[CLS]inas emotional clarity [SEP]']
[ 450/2000] tot_loss=2.448 (perp=11.124, rec=0.223), tot_loss_proj:3.065 [t=0.25s]
prediction: ['[CLS]inas emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.442 (perp=11.124, rec=0.217), tot_loss_proj:3.072 [t=0.26s]
prediction: ['[CLS]inas emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.443 (perp=11.124, rec=0.218), tot_loss_proj:3.082 [t=0.26s]
prediction: ['[CLS]inas emotional clarity [SEP]']
[ 600/2000] tot_loss=2.440 (perp=11.124, rec=0.216), tot_loss_proj:3.075 [t=0.26s]
prediction: ['[CLS]inas emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.472 (perp=11.301, rec=0.212), tot_loss_proj:3.418 [t=0.26s]
prediction: ['[CLS]rued emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.479 (perp=11.301, rec=0.219), tot_loss_proj:3.418 [t=0.27s]
prediction: ['[CLS]rued emotional clarity [SEP]']
[ 750/2000] tot_loss=2.474 (perp=11.301, rec=0.214), tot_loss_proj:3.414 [t=0.26s]
prediction: ['[CLS]rued emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.323 (perp=10.581, rec=0.207), tot_loss_proj:2.980 [t=0.25s]
prediction: ['[CLS]eving emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.312 (perp=10.581, rec=0.195), tot_loss_proj:2.975 [t=0.26s]
prediction: ['[CLS]eving emotional clarity [SEP]']
[ 900/2000] tot_loss=2.317 (perp=10.581, rec=0.201), tot_loss_proj:2.974 [t=0.27s]
prediction: ['[CLS]eving emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.315 (perp=10.581, rec=0.199), tot_loss_proj:2.984 [t=0.26s]
prediction: ['[CLS]eving emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.268 (perp=10.333, rec=0.201), tot_loss_proj:2.948 [t=0.28s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1050/2000] tot_loss=2.279 (perp=10.333, rec=0.212), tot_loss_proj:2.960 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.276 (perp=10.333, rec=0.209), tot_loss_proj:2.954 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.271 (perp=10.333, rec=0.204), tot_loss_proj:2.945 [t=0.25s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1200/2000] tot_loss=2.276 (perp=10.333, rec=0.210), tot_loss_proj:2.956 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.270 (perp=10.333, rec=0.203), tot_loss_proj:2.947 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.277 (perp=10.333, rec=0.211), tot_loss_proj:2.947 [t=0.25s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1350/2000] tot_loss=2.260 (perp=10.333, rec=0.193), tot_loss_proj:2.949 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.268 (perp=10.333, rec=0.201), tot_loss_proj:2.955 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.270 (perp=10.333, rec=0.204), tot_loss_proj:2.956 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1500/2000] tot_loss=2.257 (perp=10.333, rec=0.190), tot_loss_proj:2.945 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.269 (perp=10.333, rec=0.202), tot_loss_proj:2.948 [t=0.28s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.274 (perp=10.333, rec=0.208), tot_loss_proj:2.956 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1650/2000] tot_loss=2.265 (perp=10.333, rec=0.199), tot_loss_proj:2.958 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.272 (perp=10.333, rec=0.206), tot_loss_proj:2.944 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.274 (perp=10.333, rec=0.207), tot_loss_proj:2.944 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1800/2000] tot_loss=2.269 (perp=10.333, rec=0.202), tot_loss_proj:2.948 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.265 (perp=10.333, rec=0.199), tot_loss_proj:2.950 [t=0.27s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.273 (perp=10.333, rec=0.206), tot_loss_proj:2.952 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
[1950/2000] tot_loss=2.269 (perp=10.333, rec=0.202), tot_loss_proj:2.953 [t=0.26s]
prediction: ['[CLS]while emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.268 (perp=10.333, rec=0.202), tot_loss_proj:2.957 [t=0.25s]
prediction: ['[CLS]while emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS]while emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 76.225 | p: 75.091 | r: 77.642
rouge2     | fm: 38.528 | p: 38.184 | r: 38.987
rougeL     | fm: 68.320 | p: 67.416 | r: 69.647
rougeLsum  | fm: 68.356 | p: 67.432 | r: 69.749
r1fm+r2fm = 114.753

input #86 time: 0:11:03 | total time: 16:08:53


Running input #87 of 100.
reference: 
========================
propulsive 
========================
cosin similarity: -0.8262707904900606 normalized error: 1.743809880519691
cosin similarity: 0.8262707904900606 normalized error: 0.527192570891694
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 1.4629596179488529 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 1.2731322894502164 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 1.1974297411161507 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 1.1639252972571845 for ['[CLS] d close [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.003 (perp=12.534, rec=0.496), tot_loss_proj:3.507 [t=0.28s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.858 (perp=12.534, rec=0.352), tot_loss_proj:3.499 [t=0.28s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=2.825 (perp=12.534, rec=0.319), tot_loss_proj:3.505 [t=0.26s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 200/2000] tot_loss=2.843 (perp=12.534, rec=0.336), tot_loss_proj:3.508 [t=0.27s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.798 (perp=12.534, rec=0.292), tot_loss_proj:3.518 [t=0.25s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 300/2000] tot_loss=2.769 (perp=12.534, rec=0.263), tot_loss_proj:3.518 [t=0.28s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.778 (perp=12.534, rec=0.271), tot_loss_proj:3.524 [t=0.27s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.761 (perp=12.534, rec=0.254), tot_loss_proj:3.522 [t=0.25s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 450/2000] tot_loss=1.700 (perp=7.258, rec=0.249), tot_loss_proj:1.837 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.707 (perp=7.258, rec=0.255), tot_loss_proj:1.831 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.699 (perp=7.258, rec=0.247), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.688 (perp=7.258, rec=0.237), tot_loss_proj:1.828 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.688 (perp=7.258, rec=0.236), tot_loss_proj:1.833 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.688 (perp=7.258, rec=0.237), tot_loss_proj:1.831 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.692 (perp=7.258, rec=0.241), tot_loss_proj:1.832 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.688 (perp=7.258, rec=0.236), tot_loss_proj:1.834 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=7.258, rec=0.228), tot_loss_proj:1.827 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.677 (perp=7.258, rec=0.226), tot_loss_proj:1.839 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.675 (perp=7.258, rec=0.223), tot_loss_proj:1.834 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.664 (perp=7.258, rec=0.212), tot_loss_proj:1.839 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.674 (perp=7.258, rec=0.223), tot_loss_proj:1.829 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.678 (perp=7.258, rec=0.226), tot_loss_proj:1.849 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.669 (perp=7.258, rec=0.217), tot_loss_proj:1.835 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.666 (perp=7.258, rec=0.214), tot_loss_proj:1.843 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.669 (perp=7.258, rec=0.217), tot_loss_proj:1.844 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.676 (perp=7.258, rec=0.225), tot_loss_proj:1.834 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.668 (perp=7.258, rec=0.217), tot_loss_proj:1.837 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=7.258, rec=0.219), tot_loss_proj:1.842 [t=0.29s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.665 (perp=7.258, rec=0.213), tot_loss_proj:1.843 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.666 (perp=7.258, rec=0.214), tot_loss_proj:1.848 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.676 (perp=7.258, rec=0.224), tot_loss_proj:1.830 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
