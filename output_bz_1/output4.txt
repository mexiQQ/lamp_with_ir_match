


Command: attack2.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 2000 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
cosin similarity: -0.8934663382597008 normalized error: 1.733659495003061
cosin similarity: 0.8934663382597008 normalized error: 0.5033565318294141
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.939629852771759 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8900268077850342 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8449910283088684 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.7806059718132019 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.143 (perp=10.251, rec=0.093), tot_loss_proj:2.127 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.123 (perp=10.251, rec=0.073), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.121 (perp=10.251, rec=0.071), tot_loss_proj:2.128 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.116 (perp=10.251, rec=0.065), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.104 (perp=10.251, rec=0.054), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.104 (perp=10.251, rec=0.053), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.111 (perp=10.251, rec=0.061), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.102 (perp=10.251, rec=0.051), tot_loss_proj:2.125 [t=0.30s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.113 (perp=10.251, rec=0.063), tot_loss_proj:2.118 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.113 (perp=10.251, rec=0.063), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.113 (perp=10.251, rec=0.063), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.135 (perp=10.251, rec=0.085), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.097 (perp=10.251, rec=0.047), tot_loss_proj:2.122 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.108 (perp=10.251, rec=0.058), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.112 (perp=10.251, rec=0.062), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.108 (perp=10.251, rec=0.057), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.113 (perp=10.251, rec=0.062), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.117 (perp=10.251, rec=0.067), tot_loss_proj:2.126 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.110 (perp=10.251, rec=0.060), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.108 (perp=10.251, rec=0.058), tot_loss_proj:2.123 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.100 (perp=10.251, rec=0.050), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.104 (perp=10.251, rec=0.054), tot_loss_proj:2.114 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.102 (perp=10.251, rec=0.052), tot_loss_proj:2.119 [t=0.35s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.106 (perp=10.251, rec=0.056), tot_loss_proj:2.106 [t=0.32s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.109 (perp=10.251, rec=0.058), tot_loss_proj:2.123 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.127 (perp=10.251, rec=0.077), tot_loss_proj:2.125 [t=0.32s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.112 (perp=10.251, rec=0.061), tot_loss_proj:2.118 [t=0.33s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.115 (perp=10.251, rec=0.065), tot_loss_proj:2.114 [t=0.36s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.117 (perp=10.251, rec=0.067), tot_loss_proj:2.116 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.114 (perp=10.251, rec=0.064), tot_loss_proj:2.129 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.117 (perp=10.251, rec=0.067), tot_loss_proj:2.126 [t=0.33s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.109 (perp=10.251, rec=0.059), tot_loss_proj:2.116 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.106 (perp=10.251, rec=0.056), tot_loss_proj:2.126 [t=0.33s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.112 (perp=10.251, rec=0.062), tot_loss_proj:2.116 [t=0.32s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.108 (perp=10.251, rec=0.058), tot_loss_proj:2.117 [t=0.33s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.105 (perp=10.251, rec=0.054), tot_loss_proj:2.118 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.107 (perp=10.251, rec=0.057), tot_loss_proj:2.124 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.103 (perp=10.251, rec=0.052), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.114 (perp=10.251, rec=0.064), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.108 (perp=10.251, rec=0.058), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:11:49 | total time: 0:11:49


Running input #1 of 100.
reference: 
========================
splendidly 
========================
cosin similarity: -0.9215972518936497 normalized error: 1.862747916466129
cosin similarity: 0.9215972518936498 normalized error: 0.4365905743006529
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9459381103515625 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9362095594406128 for ['[CLS] [CLS]ric [SEP]']
[Init] best rec loss: 0.898902416229248 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 0.8971470594406128 for ['[CLS] gone honorary [SEP]']
[Init] best rec loss: 0.8528517484664917 for ['[CLS] j native [SEP]']
[Init] best rec loss: 0.8402220606803894 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.8316920399665833 for ['[CLS] dana tombstone [SEP]']
[Init] best rec loss: 0.8216210603713989 for ['[CLS] mentioned winner [SEP]']
[Init] best rec loss: 0.7306999564170837 for ['[CLS] finally relative [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.165 (perp=9.613, rec=0.242), tot_loss_proj:2.750 [t=0.26s]
prediction: ['[CLS] finally successfully [SEP]']
[ 100/2000] tot_loss=2.238 (perp=10.288, rec=0.180), tot_loss_proj:2.342 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.161 (perp=10.288, rec=0.103), tot_loss_proj:2.341 [t=0.26s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.151 (perp=10.288, rec=0.093), tot_loss_proj:2.347 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.922 (perp=9.171, rec=0.088), tot_loss_proj:1.898 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.911 (perp=9.171, rec=0.077), tot_loss_proj:1.904 [t=0.35s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.911 (perp=9.171, rec=0.077), tot_loss_proj:1.895 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.900 (perp=9.171, rec=0.065), tot_loss_proj:1.890 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.895 (perp=9.171, rec=0.061), tot_loss_proj:1.903 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.903 (perp=9.171, rec=0.068), tot_loss_proj:1.903 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.900 (perp=9.171, rec=0.065), tot_loss_proj:1.905 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.900 (perp=9.171, rec=0.066), tot_loss_proj:1.900 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.903 (perp=9.171, rec=0.069), tot_loss_proj:1.910 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.901 (perp=9.171, rec=0.067), tot_loss_proj:1.908 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.904 (perp=9.171, rec=0.070), tot_loss_proj:1.887 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.887 (perp=9.171, rec=0.053), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.903 (perp=9.171, rec=0.069), tot_loss_proj:1.897 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.908 (perp=9.171, rec=0.074), tot_loss_proj:1.889 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.900 (perp=9.171, rec=0.066), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.909 (perp=9.171, rec=0.075), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.904 (perp=9.171, rec=0.070), tot_loss_proj:1.898 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.898 (perp=9.171, rec=0.064), tot_loss_proj:1.911 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.901 (perp=9.171, rec=0.066), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.908 (perp=9.171, rec=0.074), tot_loss_proj:1.897 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.908 (perp=9.171, rec=0.074), tot_loss_proj:1.912 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.896 (perp=9.171, rec=0.062), tot_loss_proj:1.894 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.901 (perp=9.171, rec=0.067), tot_loss_proj:1.895 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.905 (perp=9.171, rec=0.071), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.914 (perp=9.171, rec=0.080), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.908 (perp=9.171, rec=0.074), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.899 (perp=9.171, rec=0.065), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.905 (perp=9.171, rec=0.071), tot_loss_proj:1.906 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.895 (perp=9.171, rec=0.061), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.917 (perp=9.171, rec=0.083), tot_loss_proj:1.909 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.171, rec=0.071), tot_loss_proj:1.907 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.908 (perp=9.171, rec=0.074), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.909 (perp=9.171, rec=0.075), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.903 (perp=9.171, rec=0.068), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.913 (perp=9.171, rec=0.079), tot_loss_proj:1.900 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.909 (perp=9.171, rec=0.075), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:11:01 | total time: 0:22:50


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
cosin similarity: 0.9258773195154295 normalized error: 0.4567743850008564
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7362629771232605 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.7090058922767639 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best perm rec loss: 0.7089882493019104 for ['[CLS] otherwiseb [SEP] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.217 (perp=8.854, rec=0.447), tot_loss_proj:2.227 [t=0.26s]
prediction: ['[CLS] getting sports recognition [SEP]']
[ 100/2000] tot_loss=2.138 (perp=9.230, rec=0.292), tot_loss_proj:2.148 [t=0.26s]
prediction: ['[CLS] much gaining momentum [SEP]']
[ 150/2000] tot_loss=2.235 (perp=10.072, rec=0.220), tot_loss_proj:2.233 [t=0.27s]
prediction: ['[CLS] gaining gaining momentum [SEP]']
[ 200/2000] tot_loss=2.206 (perp=10.072, rec=0.191), tot_loss_proj:2.240 [t=0.26s]
prediction: ['[CLS] gaining gaining momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.192 (perp=10.072, rec=0.178), tot_loss_proj:2.254 [t=0.26s]
prediction: ['[CLS] gaining gaining momentum [SEP]']
[ 300/2000] tot_loss=2.007 (perp=9.230, rec=0.161), tot_loss_proj:2.170 [t=0.25s]
prediction: ['[CLS] much gaining momentum [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.460 (perp=11.520, rec=0.156), tot_loss_proj:2.843 [t=0.26s]
prediction: ['[CLS] gainingtablished momentum [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.312 (perp=10.726, rec=0.167), tot_loss_proj:2.791 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[ 450/2000] tot_loss=2.294 (perp=10.726, rec=0.149), tot_loss_proj:2.792 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.292 (perp=10.726, rec=0.147), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.299 (perp=10.726, rec=0.154), tot_loss_proj:2.791 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[ 600/2000] tot_loss=2.310 (perp=10.726, rec=0.165), tot_loss_proj:2.795 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.296 (perp=10.726, rec=0.151), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.302 (perp=10.726, rec=0.156), tot_loss_proj:2.788 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[ 750/2000] tot_loss=2.293 (perp=10.726, rec=0.148), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.275 (perp=10.726, rec=0.130), tot_loss_proj:2.791 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.275 (perp=10.726, rec=0.129), tot_loss_proj:2.794 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[ 900/2000] tot_loss=2.287 (perp=10.726, rec=0.142), tot_loss_proj:2.791 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.305 (perp=10.726, rec=0.160), tot_loss_proj:2.789 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.286 (perp=10.726, rec=0.140), tot_loss_proj:2.789 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[1050/2000] tot_loss=2.289 (perp=10.726, rec=0.144), tot_loss_proj:2.798 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.295 (perp=10.726, rec=0.150), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.297 (perp=10.726, rec=0.152), tot_loss_proj:2.792 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[1200/2000] tot_loss=2.292 (perp=10.726, rec=0.147), tot_loss_proj:2.786 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.294 (perp=10.726, rec=0.148), tot_loss_proj:2.793 [t=0.27s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.278 (perp=10.726, rec=0.133), tot_loss_proj:2.796 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[1350/2000] tot_loss=2.286 (perp=10.726, rec=0.140), tot_loss_proj:2.792 [t=0.26s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.290 (perp=10.726, rec=0.145), tot_loss_proj:2.797 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.284 (perp=10.726, rec=0.139), tot_loss_proj:2.789 [t=0.25s]
prediction: ['[CLS]tablished gaining momentum [SEP]']
[1500/2000] tot_loss=2.435 (perp=11.446, rec=0.146), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.427 (perp=11.446, rec=0.138), tot_loss_proj:2.671 [t=0.26s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.427 (perp=11.446, rec=0.138), tot_loss_proj:2.668 [t=0.26s]
prediction: ['[CLS]uis gaining momentum [SEP]']
[1650/2000] tot_loss=2.419 (perp=11.446, rec=0.129), tot_loss_proj:2.659 [t=0.26s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.432 (perp=11.446, rec=0.142), tot_loss_proj:2.660 [t=0.25s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.416 (perp=11.446, rec=0.127), tot_loss_proj:2.675 [t=0.25s]
prediction: ['[CLS]uis gaining momentum [SEP]']
[1800/2000] tot_loss=2.425 (perp=11.446, rec=0.136), tot_loss_proj:2.662 [t=0.28s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.440 (perp=11.446, rec=0.151), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.434 (perp=11.446, rec=0.145), tot_loss_proj:2.660 [t=0.24s]
prediction: ['[CLS]uis gaining momentum [SEP]']
[1950/2000] tot_loss=2.437 (perp=11.446, rec=0.148), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.431 (perp=11.446, rec=0.142), tot_loss_proj:2.666 [t=0.28s]
prediction: ['[CLS]uis gaining momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS]uis gaining momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 93.333 | p: 93.333 | r: 93.333
rougeLsum  | fm: 93.333 | p: 93.333 | r: 93.333
r1fm+r2fm = 168.333

input #2 time: 0:11:01 | total time: 0:33:51


Running input #3 of 100.
reference: 
========================
flawless film 
========================
cosin similarity: -0.7101217562261617 normalized error: 1.6831364410360434
cosin similarity: 0.7101217562261617 normalized error: 0.6049972845812499
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9855863451957703 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.7907690405845642 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.7634335160255432 for ['[CLS] anton laughed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.280 (perp=10.476, rec=0.185), tot_loss_proj:2.419 [t=0.25s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 100/2000] tot_loss=2.112 (perp=10.226, rec=0.067), tot_loss_proj:2.352 [t=0.28s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.096 (perp=10.226, rec=0.051), tot_loss_proj:2.364 [t=0.26s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.110 (perp=10.226, rec=0.065), tot_loss_proj:2.366 [t=0.26s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.763 (perp=8.385, rec=0.086), tot_loss_proj:1.767 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.746 (perp=8.385, rec=0.069), tot_loss_proj:1.759 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.730 (perp=8.385, rec=0.053), tot_loss_proj:1.755 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.747 (perp=8.385, rec=0.070), tot_loss_proj:1.750 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.739 (perp=8.385, rec=0.062), tot_loss_proj:1.752 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.758 (perp=8.385, rec=0.081), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.734 (perp=8.385, rec=0.057), tot_loss_proj:1.766 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.745 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.731 (perp=8.385, rec=0.054), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.748 (perp=8.385, rec=0.071), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.743 (perp=8.385, rec=0.066), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.718 (perp=8.385, rec=0.041), tot_loss_proj:1.758 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.742 (perp=8.385, rec=0.065), tot_loss_proj:1.767 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.762 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.385, rec=0.055), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.385, rec=0.044), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.749 (perp=8.385, rec=0.072), tot_loss_proj:1.751 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.748 (perp=8.385, rec=0.071), tot_loss_proj:1.752 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.724 (perp=8.385, rec=0.048), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.730 (perp=8.385, rec=0.053), tot_loss_proj:1.746 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.740 (perp=8.385, rec=0.063), tot_loss_proj:1.754 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.747 (perp=8.385, rec=0.070), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.729 (perp=8.385, rec=0.052), tot_loss_proj:1.762 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.744 (perp=8.385, rec=0.067), tot_loss_proj:1.759 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.715 (perp=8.385, rec=0.038), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.737 (perp=8.385, rec=0.060), tot_loss_proj:1.762 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.748 (perp=8.385, rec=0.071), tot_loss_proj:1.752 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.737 (perp=8.385, rec=0.060), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.729 (perp=8.385, rec=0.052), tot_loss_proj:1.758 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.746 (perp=8.385, rec=0.069), tot_loss_proj:1.765 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.385, rec=0.066), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.385, rec=0.059), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 81.250 | p: 81.250 | r: 81.250
rougeL     | fm: 95.000 | p: 95.000 | r: 95.000
rougeLsum  | fm: 95.000 | p: 95.000 | r: 95.000
r1fm+r2fm = 176.250

input #3 time: 0:11:00 | total time: 0:44:52


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
cosin similarity: -0.9048403215042558 normalized error: 1.78792991317121
cosin similarity: 0.9048403215042556 normalized error: 0.475176931612047
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9320096373558044 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9055554270744324 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.8933168649673462 for ['[CLS] counters ragedu [SEP]']
[Init] best rec loss: 0.8702189922332764 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8454023003578186 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8036168217658997 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.208 (perp=14.362, rec=0.335), tot_loss_proj:3.315 [t=0.27s]
prediction: ['[CLS] tires uglyome [SEP]']
[ 100/2000] tot_loss=2.791 (perp=12.901, rec=0.211), tot_loss_proj:3.017 [t=0.25s]
prediction: ['[CLS] tires awfulome [SEP]']
[ 150/2000] tot_loss=2.388 (perp=11.053, rec=0.178), tot_loss_proj:2.385 [t=0.25s]
prediction: ['[CLS] tiresomeome [SEP]']
[ 200/2000] tot_loss=2.374 (perp=11.053, rec=0.164), tot_loss_proj:2.386 [t=0.27s]
prediction: ['[CLS] tiresomeome [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.202 (perp=9.735, rec=0.255), tot_loss_proj:2.215 [t=0.25s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 300/2000] tot_loss=2.114 (perp=9.735, rec=0.168), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.096 (perp=9.735, rec=0.149), tot_loss_proj:2.229 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.091 (perp=9.735, rec=0.144), tot_loss_proj:2.222 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 450/2000] tot_loss=2.089 (perp=9.735, rec=0.142), tot_loss_proj:2.225 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.079 (perp=9.735, rec=0.132), tot_loss_proj:2.225 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.077 (perp=9.735, rec=0.130), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 600/2000] tot_loss=2.079 (perp=9.735, rec=0.132), tot_loss_proj:2.231 [t=0.26s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.073 (perp=9.680, rec=0.137), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.030 (perp=9.501, rec=0.130), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
[ 750/2000] tot_loss=2.026 (perp=9.501, rec=0.126), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=2.214 (perp=10.468, rec=0.120), tot_loss_proj:2.295 [t=0.26s]
prediction: ['[CLS] tiresomelike [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=2.077 (perp=9.680, rec=0.141), tot_loss_proj:2.228 [t=0.25s]
prediction: ['[CLS]like tiresome [SEP]']
[ 900/2000] tot_loss=2.064 (perp=9.680, rec=0.128), tot_loss_proj:2.227 [t=0.25s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.070 (perp=9.680, rec=0.134), tot_loss_proj:2.240 [t=0.28s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[1000/2000] tot_loss=2.059 (perp=9.680, rec=0.123), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS]like tiresome [SEP]']
[1050/2000] tot_loss=2.058 (perp=9.680, rec=0.122), tot_loss_proj:2.246 [t=0.28s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[1100/2000] tot_loss=2.060 (perp=9.680, rec=0.124), tot_loss_proj:2.225 [t=0.28s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[1150/2000] tot_loss=2.059 (perp=9.680, rec=0.123), tot_loss_proj:2.237 [t=0.26s]
prediction: ['[CLS]like tiresome [SEP]']
[1200/2000] tot_loss=2.053 (perp=9.680, rec=0.117), tot_loss_proj:2.242 [t=0.25s]
prediction: ['[CLS]like tiresome [SEP]']
Attempt swap
[1250/2000] tot_loss=2.022 (perp=9.501, rec=0.122), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
Put prefix at the end
[1300/2000] tot_loss=2.222 (perp=10.468, rec=0.128), tot_loss_proj:2.300 [t=0.26s]
prediction: ['[CLS] tiresomelike [SEP]']
[1350/2000] tot_loss=2.228 (perp=10.468, rec=0.134), tot_loss_proj:2.299 [t=0.26s]
prediction: ['[CLS] tiresomelike [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.016 (perp=9.501, rec=0.116), tot_loss_proj:2.396 [t=0.26s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
Put prefix at the end
[1450/2000] tot_loss=2.218 (perp=10.468, rec=0.125), tot_loss_proj:2.304 [t=0.26s]
prediction: ['[CLS] tiresomelike [SEP]']
[1500/2000] tot_loss=2.213 (perp=10.468, rec=0.119), tot_loss_proj:2.297 [t=0.27s]
prediction: ['[CLS] tiresomelike [SEP]']
Attempt swap
Put prefix at the end
[1550/2000] tot_loss=2.032 (perp=9.501, rec=0.131), tot_loss_proj:2.388 [t=0.25s]
prediction: ['[CLS] minds tiresome [SEP]']
Attempt swap
Put prefix at the end
[1600/2000] tot_loss=1.855 (perp=8.640, rec=0.127), tot_loss_proj:2.237 [t=0.25s]
prediction: ['[CLS] tiresome minds [SEP]']
[1650/2000] tot_loss=1.788 (perp=8.293, rec=0.129), tot_loss_proj:2.090 [t=0.25s]
prediction: ['[CLS] tiresome ernie [SEP]']
Attempt swap
[1700/2000] tot_loss=1.781 (perp=8.293, rec=0.122), tot_loss_proj:2.112 [t=0.27s]
prediction: ['[CLS] tiresome ernie [SEP]']
Attempt swap
[1750/2000] tot_loss=1.771 (perp=8.293, rec=0.113), tot_loss_proj:2.098 [t=0.26s]
prediction: ['[CLS] tiresome ernie [SEP]']
[1800/2000] tot_loss=1.850 (perp=8.640, rec=0.122), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS] tiresome minds [SEP]']
Attempt swap
[1850/2000] tot_loss=1.847 (perp=8.640, rec=0.119), tot_loss_proj:2.243 [t=0.26s]
prediction: ['[CLS] tiresome minds [SEP]']
Attempt swap
[1900/2000] tot_loss=1.838 (perp=8.640, rec=0.110), tot_loss_proj:2.231 [t=0.25s]
prediction: ['[CLS] tiresome minds [SEP]']
[1950/2000] tot_loss=1.859 (perp=8.640, rec=0.131), tot_loss_proj:2.235 [t=0.26s]
prediction: ['[CLS] tiresome minds [SEP]']
Attempt swap
[2000/2000] tot_loss=1.856 (perp=8.640, rec=0.128), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS] tiresome minds [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresome minds [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 87.429 | p: 86.000 | r: 89.333
rouge2     | fm: 65.000 | p: 65.000 | r: 65.000
rougeL     | fm: 87.429 | p: 86.000 | r: 89.333
rougeLsum  | fm: 87.429 | p: 86.000 | r: 89.333
r1fm+r2fm = 152.429

input #4 time: 0:10:58 | total time: 0:55:51


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
cosin similarity: -0.6976662371922135 normalized error: 1.6799576310302529
cosin similarity: 0.6976662371922135 normalized error: 0.6126100487423699
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9211751222610474 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.8462492227554321 for ['[CLS] works flow [SEP]']
[Init] best rec loss: 0.8158178329467773 for ['[CLS] sur golden [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=11.854, rec=0.130), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 100/2000] tot_loss=2.427 (perp=11.854, rec=0.057), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 150/2000] tot_loss=2.441 (perp=11.854, rec=0.071), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 200/2000] tot_loss=2.439 (perp=11.854, rec=0.068), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.440 (perp=11.854, rec=0.069), tot_loss_proj:2.587 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.437 (perp=11.854, rec=0.067), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.431 (perp=11.854, rec=0.060), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.430 (perp=11.854, rec=0.059), tot_loss_proj:2.590 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.434 (perp=11.854, rec=0.063), tot_loss_proj:2.595 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.436 (perp=11.854, rec=0.065), tot_loss_proj:2.573 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.439 (perp=11.854, rec=0.068), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.433 (perp=11.854, rec=0.062), tot_loss_proj:2.587 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.440 (perp=11.854, rec=0.070), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.422 (perp=11.854, rec=0.051), tot_loss_proj:2.594 [t=0.29s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.433 (perp=11.854, rec=0.062), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.437 (perp=11.854, rec=0.066), tot_loss_proj:2.600 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.428 (perp=11.854, rec=0.057), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.445 (perp=11.854, rec=0.074), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.435 (perp=11.854, rec=0.064), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.420 (perp=11.854, rec=0.049), tot_loss_proj:2.584 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.435 (perp=11.854, rec=0.064), tot_loss_proj:2.590 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.439 (perp=11.854, rec=0.068), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.424 (perp=11.854, rec=0.053), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.433 (perp=11.854, rec=0.062), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.438 (perp=11.854, rec=0.067), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.425 (perp=11.854, rec=0.054), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.438 (perp=11.854, rec=0.068), tot_loss_proj:2.592 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.427 (perp=11.854, rec=0.057), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.434 (perp=11.854, rec=0.063), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.431 (perp=11.854, rec=0.060), tot_loss_proj:2.589 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.423 (perp=11.854, rec=0.052), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.448 (perp=11.854, rec=0.077), tot_loss_proj:2.587 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.430 (perp=11.854, rec=0.059), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.425 (perp=11.854, rec=0.054), tot_loss_proj:2.594 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.435 (perp=11.854, rec=0.064), tot_loss_proj:2.598 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.436 (perp=11.854, rec=0.065), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.440 (perp=11.854, rec=0.069), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.443 (perp=11.854, rec=0.072), tot_loss_proj:2.596 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.441 (perp=11.854, rec=0.071), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.424 (perp=11.854, rec=0.053), tot_loss_proj:2.595 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.524 | p: 88.333 | r: 91.111
rouge2     | fm: 54.167 | p: 54.167 | r: 54.167
rougeL     | fm: 85.357 | p: 84.167 | r: 86.944
rougeLsum  | fm: 85.357 | p: 84.167 | r: 86.944
r1fm+r2fm = 143.690

input #5 time: 0:10:57 | total time: 1:06:49


Running input #6 of 100.
reference: 
========================
grayish 
========================
cosin similarity: -0.9293236555171187 normalized error: 1.7532736189764786
cosin similarity: 0.9293236555171187 normalized error: 0.4810054002498873
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9385210275650024 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9077579975128174 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.8129591345787048 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7856830954551697 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7246884107589722 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6939626336097717 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6851747035980225 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.6829671263694763 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.6711090803146362 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.714 (perp=6.813, rec=0.352), tot_loss_proj:2.063 [t=0.26s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.593 (perp=6.813, rec=0.231), tot_loss_proj:2.046 [t=0.25s]
prediction: ['[CLS] gray gray [SEP]']
[ 150/2000] tot_loss=1.767 (perp=8.089, rec=0.149), tot_loss_proj:1.698 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.751 (perp=8.089, rec=0.133), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.721 (perp=8.089, rec=0.103), tot_loss_proj:1.698 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.729 (perp=8.089, rec=0.111), tot_loss_proj:1.692 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.740 (perp=8.089, rec=0.122), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.724 (perp=8.089, rec=0.106), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.723 (perp=8.089, rec=0.106), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.726 (perp=8.089, rec=0.108), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.735 (perp=8.089, rec=0.117), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.731 (perp=8.089, rec=0.113), tot_loss_proj:1.684 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.714 (perp=8.089, rec=0.096), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.717 (perp=8.089, rec=0.099), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.089, rec=0.102), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.720 (perp=8.089, rec=0.102), tot_loss_proj:1.696 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.713 (perp=8.089, rec=0.095), tot_loss_proj:1.709 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.710 (perp=8.089, rec=0.092), tot_loss_proj:1.699 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.727 (perp=8.089, rec=0.109), tot_loss_proj:1.696 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.733 (perp=8.089, rec=0.115), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.719 (perp=8.089, rec=0.102), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.725 (perp=8.089, rec=0.107), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.089, rec=0.113), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.718 (perp=8.089, rec=0.100), tot_loss_proj:1.700 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.720 (perp=8.089, rec=0.102), tot_loss_proj:1.699 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.725 (perp=8.089, rec=0.107), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.716 (perp=8.089, rec=0.098), tot_loss_proj:1.673 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.724 (perp=8.089, rec=0.106), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.720 (perp=8.089, rec=0.102), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.724 (perp=8.089, rec=0.107), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.722 (perp=8.089, rec=0.104), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.727 (perp=8.089, rec=0.110), tot_loss_proj:1.699 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.731 (perp=8.089, rec=0.113), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.723 (perp=8.089, rec=0.105), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.720 (perp=8.089, rec=0.102), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.728 (perp=8.089, rec=0.110), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.728 (perp=8.089, rec=0.110), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.725 (perp=8.089, rec=0.107), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.729 (perp=8.089, rec=0.112), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.719 (perp=8.089, rec=0.101), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.020 | p: 90.000 | r: 92.381
rouge2     | fm: 60.714 | p: 60.714 | r: 60.714
rougeL     | fm: 87.755 | p: 86.429 | r: 88.810
rougeLsum  | fm: 87.449 | p: 86.429 | r: 88.810
r1fm+r2fm = 151.735

input #6 time: 0:10:59 | total time: 1:17:49


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
cosin similarity: -0.8826673880610065 normalized error: 1.6975368459944407
cosin similarity: 0.8826673880610065 normalized error: 0.5235793653735517
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.898560106754303 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8691129684448242 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8639413118362427 for ['[CLS]eringtracted bros ppfounded to extra billion bride collective darted doping actually riley measurement guybl news found muchox only affiliation sister times down [SEP]']
[Init] best rec loss: 0.8619006276130676 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.8427982926368713 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.8238486051559448 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 0.8100714683532715 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best perm rec loss: 0.8090068697929382 for ['[CLS] child conspiracy all micro d twins behind stanley line maintained rule something echoelli fighting hoptative sykes legal earlybation job park ni medicine aces [SEP]']
[Init] best perm rec loss: 0.8070053458213806 for ['[CLS] medicine conspiracy echo all fighting legal jobelli stanley aces hop behind early maintained sykes micro line park child twins somethingtative ni rulebation d [SEP]']
[Init] best perm rec loss: 0.8063103556632996 for ['[CLS] medicine fighting early line echo rule child parkelli aces maintained hop behind all ni legal microtativebation twins stanley d job conspiracy sykes something [SEP]']
[Init] best perm rec loss: 0.8059252500534058 for ['[CLS] child aceselli twins hop ni maintained d all stanley fighting legal job conspiracy medicine line park somethingtative rule echo early micro sykesbation behind [SEP]']
[Init] best perm rec loss: 0.8053761720657349 for ['[CLS] aces ni maintained hop park legal conspiracy rule fighting child delli job medicine micro somethingtative behind all sykesbation line stanley echo twins early [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.371 (perp=10.404, rec=0.290), tot_loss_proj:2.850 [t=0.27s]
prediction: ['[CLS] no singular ; term problem no stupid ruled settled against or character or anything problem wassboro character ;. not he has problem problem easy [SEP]']
[ 100/2000] tot_loss=2.046 (perp=9.309, rec=0.184), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS] no cute is here during no i - not?. character or anything problem issboro character love. relationships he has problem problem easy [SEP]']
[ 150/2000] tot_loss=1.721 (perp=7.812, rec=0.159), tot_loss_proj:2.243 [t=0.25s]
prediction: ['[CLS] no cute is here. no not ; not?. character or anything problem is otherwise character love.able he has problem is easy [SEP]']
[ 200/2000] tot_loss=1.608 (perp=7.339, rec=0.140), tot_loss_proj:2.055 [t=0.27s]
prediction: ['[CLS] no cute is here. no not ; not.. cute or eyes problem is or character love.able he has problem is. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.765 (perp=8.001, rec=0.165), tot_loss_proj:2.192 [t=0.28s]
prediction: ['[CLS] no cute is here for no not ; not or. character or mind is anything otherwise character love.able he has problem ; ugly [SEP]']
[ 300/2000] tot_loss=1.989 (perp=8.726, rec=0.244), tot_loss_proj:2.341 [t=0.26s]
prediction: ["[CLS] no cute is here of no not ;''. factor or mind ugly i favourites character love uglyable he has problem. nasty [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.865 (perp=8.417, rec=0.182), tot_loss_proj:2.303 [t=0.27s]
prediction: ["[CLS] no cute is here the no not ; convention the '. factor or mind we equity character love uglyable he has problem., [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.757 (perp=7.811, rec=0.195), tot_loss_proj:2.277 [t=0.26s]
prediction: ["[CLS] no cute is here the no not ugly ; convention is '. factor or mind we original character loveable he has problem., [SEP]"]
[ 450/2000] tot_loss=1.638 (perp=7.392, rec=0.159), tot_loss_proj:2.155 [t=0.27s]
prediction: ["[CLS] no cute is here the no not ugly ;? it '. factor or mind! character character loveable he has problem., [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.706 (perp=7.823, rec=0.142), tot_loss_proj:2.231 [t=0.25s]
prediction: ["[CLS] no cute is here to no not ugly dagger? the '. factor or mind. ; character loveable he has problem., [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.653 (perp=7.582, rec=0.136), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] no cute is here. no not ugly dagger? the i to factor or mind. ; character loveable he has problem., [SEP]']
[ 600/2000] tot_loss=1.661 (perp=7.654, rec=0.130), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] no cute is here. no not ugly otherwise? the i to factor or mindable ; character loveable he has problem.. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.573 (perp=7.251, rec=0.123), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] no cute is here. no not ugly otherwise? the i character factor or mindable ; the loveable he has problem.. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.748 (perp=7.800, rec=0.188), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS] no cute is here. no. ugly blinked? it i character factor or mindable ; of loveable he has problem not. [SEP]']
[ 750/2000] tot_loss=1.748 (perp=8.042, rec=0.140), tot_loss_proj:2.227 [t=0.26s]
prediction: ['[CLS] no cute is here. no purse ugly blinked? it i character factor or mindable ;, loveable he has problem not. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.624 (perp=7.503, rec=0.123), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] no cute is here. no purse ugly ugly? it not character factor or mindable ;, loveable he has problem i. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.561 (perp=7.145, rec=0.131), tot_loss_proj:2.007 [t=0.27s]
prediction: ['[CLS] no cute is here. no purse ugly ugly? it, character factor or mindable ; not loveable he has problem i. [SEP]']
[ 900/2000] tot_loss=1.500 (perp=6.937, rec=0.113), tot_loss_proj:1.917 [t=0.26s]
prediction: ['[CLS] no cute is here. no. ugly ugly? ugly, character factor or mindable ; not loveable he has problem i. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.459 (perp=6.690, rec=0.121), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] no cute is here. no. ugly ugly, ugly? character factor or mindable ; not loveable he has problem i. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.426 (perp=6.552, rec=0.116), tot_loss_proj:1.838 [t=0.28s]
prediction: ['[CLS] no cute is here. no. ugly ugly, ugly? character factor or mindable not loveable ; he has problem i. [SEP]']
[1050/2000] tot_loss=1.423 (perp=6.552, rec=0.113), tot_loss_proj:1.843 [t=0.25s]
prediction: ['[CLS] no cute is here. no. ugly ugly, ugly? character factor or mindable not loveable ; he has problem i. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.377 (perp=6.277, rec=0.122), tot_loss_proj:1.797 [t=0.27s]
prediction: ['[CLS] no cute is here. no. ugly ugly, ugly? character factor or mind not loveable ; he has problemable i. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.363 (perp=6.277, rec=0.107), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS] no cute is here. no. ugly ugly, ugly? character factor or mind not loveable ; he has problemable i. [SEP]']
[1200/2000] tot_loss=1.367 (perp=6.277, rec=0.112), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS] no cute is here. no. ugly ugly, ugly? character factor or mind not loveable ; he has problemable i. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.351 (perp=6.216, rec=0.108), tot_loss_proj:1.851 [t=0.25s]
prediction: ['[CLS] no cute is here. no ugly. ugly, ugly? character factor or mind not loveable ; he has problemable i. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.348 (perp=6.216, rec=0.105), tot_loss_proj:1.834 [t=0.26s]
prediction: ['[CLS] no cute is here. no ugly. ugly, ugly? character factor or mind not loveable ; he has problemable i. [SEP]']
[1350/2000] tot_loss=1.347 (perp=6.216, rec=0.104), tot_loss_proj:1.829 [t=0.27s]
prediction: ['[CLS] no cute is here. no ugly. ugly, ugly? character factor or mind not loveable ; he has problemable i. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.317 (perp=6.026, rec=0.112), tot_loss_proj:1.940 [t=0.26s]
prediction: ['[CLS] no cute is here. ugly. ugly, ugly? character factor or mind not loveable ; he has no problemable i. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.314 (perp=6.026, rec=0.109), tot_loss_proj:1.942 [t=0.27s]
prediction: ['[CLS] no cute is here. ugly. ugly, ugly? character factor or mind not loveable ; he has no problemable i. [SEP]']
[1500/2000] tot_loss=1.314 (perp=6.026, rec=0.108), tot_loss_proj:1.936 [t=0.26s]
prediction: ['[CLS] no cute is here. ugly. ugly, ugly? character factor or mind not loveable ; he has no problemable i. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.287 (perp=5.878, rec=0.111), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? character factor. mind not loveable ; he has no problemable i. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.284 (perp=5.878, rec=0.108), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? character factor. mind not loveable ; he has no problemable i. [SEP]']
[1650/2000] tot_loss=1.278 (perp=5.878, rec=0.102), tot_loss_proj:1.962 [t=0.28s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? character factor. mind not loveable ; he has no problemable i. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.226 (perp=5.606, rec=0.105), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.225 (perp=5.606, rec=0.104), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
[1800/2000] tot_loss=1.226 (perp=5.606, rec=0.105), tot_loss_proj:2.018 [t=0.28s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.217 (perp=5.606, rec=0.096), tot_loss_proj:2.016 [t=0.27s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.214 (perp=5.606, rec=0.093), tot_loss_proj:2.023 [t=0.29s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
[1950/2000] tot_loss=1.218 (perp=5.606, rec=0.097), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.223 (perp=5.606, rec=0.102), tot_loss_proj:2.015 [t=0.29s]
prediction: ['[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] no cute is here. ugly or ugly, ugly? i factor. mind not loveable ; he has no problemable character. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.927 | p: 85.000 | r: 80.952
rouge2     | fm: 20.513 | p: 21.053 | r: 20.000
rougeL     | fm: 53.659 | p: 55.000 | r: 52.381
rougeLsum  | fm: 53.659 | p: 55.000 | r: 52.381
r1fm+r2fm = 103.440

[Aggregate metrics]:
rouge1     | fm: 90.375 | p: 90.000 | r: 91.012
rouge2     | fm: 55.689 | p: 55.757 | r: 55.625
rougeL     | fm: 83.393 | p: 82.500 | r: 84.583
rougeLsum  | fm: 83.057 | p: 82.500 | r: 84.256
r1fm+r2fm = 146.064

input #7 time: 0:10:59 | total time: 1:28:48


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
cosin similarity: 0.9218859490507135 normalized error: 0.5104764842116075
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7303442358970642 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7254684567451477 for ['[CLS] behalf eireann pts ask solutionog rhythm revived sky bonus derek yet affairsstick weird meaning now wellverse beforeα arterial centuries network [SEP]']
[Init] best rec loss: 0.71721351146698 for ['[CLS] classical mister sign country publication in sunsetieg touchdown right sherman read possible gathered string manufactureurian antony havewardbahn great retired spike [SEP]']
[Init] best rec loss: 0.7158087491989136 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.7104514241218567 for ['[CLS] al valleyowing ends gen $ born plan platform des previousvey castle month phased reach calcutta project grade one anne forward shift hiring [SEP]']
[Init] best rec loss: 0.7092781662940979 for ['[CLS] wayne back boncin yourself portugueseh put goldsmith trustulf nana along grown surge handed military grace married layout retirement maynard deep defense [SEP]']
[Init] best rec loss: 0.7067294716835022 for ['[CLS]dicatedw mixed thought hold cassie bare such belarus experimental railroad underlying near pitch sodiumographer crash kit election draw lambert fai cole installation [SEP]']
[Init] best rec loss: 0.706499457359314 for ['[CLS] rosie shankar clear fog press \\ record ni sad meritorious village closely pi indira broadway life bound located today sh transportationally murder editorial [SEP]']
[Init] best perm rec loss: 0.70647132396698 for ['[CLS] fog today ni meritorious indira village press editorial murder clear bound broadway lifeally closely located pi sad transportation record rosie shankar sh \\ [SEP]']
[Init] best perm rec loss: 0.7057152390480042 for ['[CLS] press indira broadway rosie meritorious editorial murder clearally life bound sad transportation \\ fog today pi record sh village located shankar ni closely [SEP]']
[Init] best perm rec loss: 0.7049582004547119 for ['[CLS] rosieally sh shankar \\ ni sad fog editorial pi closely bound transportation today murder press village life located meritorious clear indira broadway record [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.086 (perp=13.298, rec=0.426), tot_loss_proj:3.446 [t=0.26s]
prediction: ['[CLS] professionals [UNK] hateque least every maud cooper, educated modeled beneath fell thirtyvery true tournament circus conception scheme stables penal film ltd [SEP]']
[ 100/2000] tot_loss=3.175 (perp=14.073, rec=0.360), tot_loss_proj:3.647 [t=0.27s]
prediction: ['[CLS] professionals hence hate barrelstypical everymax duo, filmyauance cutting hundred no × tournament nobel terrifiedmax program penal film australia [SEP]']
[ 150/2000] tot_loss=2.899 (perp=12.909, rec=0.317), tot_loss_proj:3.331 [t=0.27s]
prediction: ['[CLS] professionals thereby vanity debt because everymax refused a film debtuance ceased percent no × tournament pulitzer preymax account pmid film australia [SEP]']
[ 200/2000] tot_loss=2.668 (perp=11.828, rec=0.302), tot_loss_proj:3.060 [t=0.26s]
prediction: ['[CLS] professionals thereby vanity debt because everymax havoc a film debtuance pay owe townland vacuum value vanity preymax provides fright film ethics [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.011 (perp=13.227, rec=0.365), tot_loss_proj:3.348 [t=0.27s]
prediction: ['[CLS] andrews ץ films vanity debt becauseˈmax fitzpatrick a profittiqueuance owe twenty vacuum russia purchasedmain debt provides fright film ethics [SEP]']
[ 300/2000] tot_loss=2.924 (perp=13.167, rec=0.291), tot_loss_proj:3.404 [t=0.29s]
prediction: ['[CLS] andrewsrix films vanity doubt becauseˈmax pandora a pays considerable desmond owed twenty vacuum felt vanitymain debt pays fright film ethics [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.698 (perp=12.148, rec=0.268), tot_loss_proj:3.159 [t=0.28s]
prediction: ['[CLS] arix pays vanity doubt because cvmax pandora andrews pays considerable desmond owed twenty looked what vanity fright debt pays vanity film ethics [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.864 (perp=12.759, rec=0.312), tot_loss_proj:3.345 [t=0.26s]
prediction: ['[CLS] a debt removal vanity doubt fright cvmaxzziness pays pays what testament owed twenty what how vanity beginrix pays fright film disk [SEP]']
[ 450/2000] tot_loss=2.811 (perp=12.758, rec=0.259), tot_loss_proj:3.344 [t=0.27s]
prediction: ['[CLS] a debt was vanity doubt fright pretendmaxzziness andrews pays what testament owed twenty what how vanity beginrix pays fright filmista [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.681 (perp=12.172, rec=0.247), tot_loss_proj:3.173 [t=0.27s]
prediction: ['[CLS] a debt which vanity doubt frightখmax what andrews pays what testament no debthiro excuse vanity beginrix pays fright filmista [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.517 (perp=11.360, rec=0.245), tot_loss_proj:2.956 [t=0.27s]
prediction: ['[CLS] a debt which vanity doubt fright paysmax what andrews pays what testament no debt versus excuse vanity surprised wasngnant fright filmista [SEP]']
[ 600/2000] tot_loss=2.405 (perp=10.932, rec=0.219), tot_loss_proj:2.877 [t=0.28s]
prediction: ['[CLS] a debt which vanity doubt fright paysmax what andrews pays what testament no debt versus how vanity surprised wasnsonic fright film that [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.329 (perp=10.530, rec=0.223), tot_loss_proj:2.787 [t=0.26s]
prediction: ['[CLS] a debt which vanity doubtmax pays fright what andrews pays what testament no debt versus how vanity surprised wasn ® fright film that [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.409 (perp=10.937, rec=0.222), tot_loss_proj:2.850 [t=0.27s]
prediction: ['[CLS] a gladly debt which vanity doubtmax pays fright what andrews pays what no debt off felt vanity surprised sgnant fright film that [SEP]']
[ 750/2000] tot_loss=2.302 (perp=10.446, rec=0.213), tot_loss_proj:2.758 [t=0.31s]
prediction: ['[CLS] a photon debt which vanity doubtmax pays fright what andrews pays what no debt off how vanity surprised ssonic fright film that [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.382 (perp=10.927, rec=0.197), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] a grunt debt which vanity doubtmax pays fright what andrews pays what no debt offsonic vanity surprised s felt fright film that [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.427 (perp=11.186, rec=0.190), tot_loss_proj:2.905 [t=0.27s]
prediction: ['[CLS] a grunt debt which vanity doubtmax pays fright what andrews pays what no debt off ® vanity surprised s fright film that how [SEP]']
[ 900/2000] tot_loss=2.317 (perp=10.616, rec=0.194), tot_loss_proj:2.860 [t=0.28s]
prediction: ['[CLS] a fools debt which vanity doubtmax pays fright what andrews pays what no debt offsonic vanity surprised s fright film that felt [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.282 (perp=10.486, rec=0.185), tot_loss_proj:2.791 [t=0.29s]
prediction: ['[CLS] which fools debt a vanity doubtmax pays fright what andrews pays what no debt offsonic vanity surprised s fright film that felt [SEP]']
Attempt swap
[1000/2000] tot_loss=2.279 (perp=10.486, rec=0.182), tot_loss_proj:2.793 [t=0.26s]
prediction: ['[CLS] which fools debt a vanity doubtmax pays fright what andrews pays what no debt offsonic vanity surprised s fright film that felt [SEP]']
[1050/2000] tot_loss=2.363 (perp=10.899, rec=0.184), tot_loss_proj:2.917 [t=0.27s]
prediction: ['[CLS] which fools debt a vanity doubtmax pays fright what possessions pays what no debt offsonic vanity surprised s fright film that benign [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.336 (perp=10.793, rec=0.178), tot_loss_proj:2.915 [t=0.28s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright what possessions pays what no debt off hangul vanity surprised fools fright film that benign [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.284 (perp=10.536, rec=0.176), tot_loss_proj:2.879 [t=0.28s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, possessions pays felt no debt off hangul fools surprised vanity fright film that benign [SEP]']
[1200/2000] tot_loss=2.288 (perp=10.536, rec=0.181), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, possessions pays felt no debt off hangul fools surprised vanity fright film that benign [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.234 (perp=10.313, rec=0.171), tot_loss_proj:2.831 [t=0.26s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, possessions pays off no debt felt hangul fools surprised vanity fright film that benign [SEP]']
Attempt swap
[1300/2000] tot_loss=2.236 (perp=10.313, rec=0.174), tot_loss_proj:2.830 [t=0.27s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, possessions pays off no debt felt hangul fools surprised vanity fright film that benign [SEP]']
[1350/2000] tot_loss=2.229 (perp=10.313, rec=0.167), tot_loss_proj:2.832 [t=0.29s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, possessions pays off no debt felt hangul fools surprised vanity fright film that benign [SEP]']
Attempt swap
[1400/2000] tot_loss=2.225 (perp=10.313, rec=0.162), tot_loss_proj:2.829 [t=0.26s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, possessions pays off no debt felt hangul fools surprised vanity fright film that benign [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.175 (perp=10.022, rec=0.171), tot_loss_proj:2.761 [t=0.27s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, fright pays off no debt felt hangul fools surprised vanity possessions film that benign [SEP]']
[1500/2000] tot_loss=2.170 (perp=10.022, rec=0.166), tot_loss_proj:2.756 [t=0.27s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, fright pays off no debt felt hangul fools surprised vanity possessions film that benign [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.168 (perp=10.022, rec=0.164), tot_loss_proj:2.762 [t=0.27s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, fright pays off no debt felt hangul fools surprised vanity possessions film that benign [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.160 (perp=9.928, rec=0.175), tot_loss_proj:2.673 [t=0.27s]
prediction: ['[CLS] which s debt a vanity doubtmax pays fright, fright pays off no debt benign hangul fools surprised vanity possessions film that felt [SEP]']
[1650/2000] tot_loss=2.177 (perp=10.089, rec=0.159), tot_loss_proj:2.656 [t=0.27s]
prediction: ['[CLS] which s what a vanity doubtmax pays fright, fright pays off no debt benignheard fools surprised vanity possessions film that felt [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.212 (perp=10.240, rec=0.164), tot_loss_proj:2.734 [t=0.27s]
prediction: ['[CLS] which s hangul a vanity doubtmax pays fright, fright pays off no debt benign debt fools surprised vanity possessions film that felt [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.205 (perp=10.169, rec=0.171), tot_loss_proj:2.740 [t=0.27s]
prediction: ['[CLS] which s hangul a vanity doubtmax pays fright, what fright pays off no debt benign fools surprised vanity possessions film that felt [SEP]']
[1800/2000] tot_loss=2.194 (perp=10.169, rec=0.161), tot_loss_proj:2.735 [t=0.26s]
prediction: ['[CLS] which s hangul a vanity doubtmax pays fright, what fright pays off no debt benign fools surprised vanity possessions film that felt [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.129 (perp=9.786, rec=0.171), tot_loss_proj:2.632 [t=0.27s]
prediction: ['[CLS] which s hangul a vanity doubtmax pays fright, fright pays off no debt what benign fools surprised vanity possessions film that felt [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.116 (perp=9.747, rec=0.166), tot_loss_proj:2.598 [t=0.28s]
prediction: ['[CLS] which s aheard vanity doubtmax pays fright, fright pays off no debt what benign fools surprised vanity possessions film that felt [SEP]']
[1950/2000] tot_loss=2.115 (perp=9.747, rec=0.166), tot_loss_proj:2.599 [t=0.27s]
prediction: ['[CLS] which s aheard vanity doubtmax pays fright, fright pays off no debt what benign fools surprised vanity possessions film that felt [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.117 (perp=9.786, rec=0.159), tot_loss_proj:2.629 [t=0.27s]
prediction: ['[CLS] which s hangul a vanity doubtmax pays fright, fright pays off no debt what benign fools surprised vanity possessions film that felt [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] which sheard a vanity doubtmax pays fright, fright pays off no debt what benign fools surprised vanity possessions film that felt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.814 | p: 52.174 | r: 60.000
rouge2     | fm: 9.756 | p: 9.091 | r: 10.526
rougeL     | fm: 37.209 | p: 34.783 | r: 40.000
rougeLsum  | fm: 37.209 | p: 34.783 | r: 40.000
r1fm+r2fm = 65.570

[Aggregate metrics]:
rouge1     | fm: 86.357 | p: 85.676 | r: 87.513
rouge2     | fm: 50.087 | p: 50.133 | r: 50.058
rougeL     | fm: 78.350 | p: 77.476 | r: 79.894
rougeLsum  | fm: 78.664 | p: 77.754 | r: 79.894
r1fm+r2fm = 136.444

input #8 time: 0:11:05 | total time: 1:39:54


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
cosin similarity: -0.9468267247362503 normalized error: 1.6636662226335797
cosin similarity: 0.9468267247362503 normalized error: 0.5190218301597448
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7862826585769653 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.714831531047821 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7137311100959778 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.6930262446403503 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6749818921089172 for ['[CLS]ser further afitionrn wore high bottom [SEP]']
[Init] best rec loss: 0.6679653525352478 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6647075414657593 for ['[CLS] luck decca cody outlaw edward deathsdden arsenal [SEP]']
[Init] best perm rec loss: 0.664131224155426 for ['[CLS] cody outlawdden arsenal edward decca luck deaths [SEP]']
[Init] best perm rec loss: 0.6612327694892883 for ['[CLS] cody luck deaths outlaw edward arsenal deccadden [SEP]']
[Init] best perm rec loss: 0.660236120223999 for ['[CLS] decca deaths arsenal luck edward outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6575775146484375 for ['[CLS] deaths luck arsenal edward codydden decca outlaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.685 (perp=12.007, rec=0.284), tot_loss_proj:3.023 [t=0.31s]
prediction: ['[CLS]d plus occult lateral seeking of dip steam [SEP]']
[ 100/2000] tot_loss=2.642 (perp=12.109, rec=0.220), tot_loss_proj:3.050 [t=0.27s]
prediction: ['[CLS] clap softhead partial clapped of claphead [SEP]']
[ 150/2000] tot_loss=2.418 (perp=11.162, rec=0.185), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] clap softhead partial clap of claptra [SEP]']
[ 200/2000] tot_loss=2.580 (perp=12.093, rec=0.161), tot_loss_proj:2.938 [t=0.27s]
prediction: ['[CLS] clap softhead metaphysicalheads of claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.450 (perp=11.469, rec=0.156), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] clap metaphysical of softhead metaphysical claptra [SEP]']
[ 300/2000] tot_loss=2.466 (perp=11.469, rec=0.173), tot_loss_proj:2.873 [t=0.26s]
prediction: ['[CLS] clap metaphysical of softhead metaphysical claptra [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.238 (perp=10.480, rec=0.142), tot_loss_proj:2.638 [t=0.26s]
prediction: ['[CLS]tra metaphysical of metaphysical claptra softhead [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.168 (perp=10.190, rec=0.130), tot_loss_proj:2.624 [t=0.26s]
prediction: ['[CLS]tra metaphysical metaphysical of claptra softhead [SEP]']
[ 450/2000] tot_loss=2.177 (perp=10.190, rec=0.139), tot_loss_proj:2.615 [t=0.25s]
prediction: ['[CLS]tra metaphysical metaphysical of claptra softhead [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.174 (perp=10.190, rec=0.136), tot_loss_proj:2.625 [t=0.25s]
prediction: ['[CLS]tra metaphysical metaphysical of claptra softhead [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.165 (perp=10.190, rec=0.128), tot_loss_proj:2.621 [t=0.27s]
prediction: ['[CLS]tra metaphysical metaphysical of claptra softhead [SEP]']
[ 600/2000] tot_loss=2.157 (perp=10.190, rec=0.119), tot_loss_proj:2.625 [t=0.26s]
prediction: ['[CLS]tra metaphysical metaphysical of claptra softhead [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.157 (perp=10.105, rec=0.136), tot_loss_proj:2.497 [t=0.25s]
prediction: ['[CLS] oftra metaphysical emotional claptra softhead [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.043 (perp=9.647, rec=0.114), tot_loss_proj:2.422 [t=0.25s]
prediction: ['[CLS] oftra metaphysical metaphysical claptra softhead [SEP]']
[ 750/2000] tot_loss=2.047 (perp=9.647, rec=0.117), tot_loss_proj:2.425 [t=0.26s]
prediction: ['[CLS] oftra metaphysical metaphysical claptra softhead [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.047 (perp=9.647, rec=0.118), tot_loss_proj:2.416 [t=0.26s]
prediction: ['[CLS] oftra metaphysical metaphysical claptra softhead [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.044 (perp=9.647, rec=0.115), tot_loss_proj:2.425 [t=0.25s]
prediction: ['[CLS] oftra metaphysical metaphysical claptra softhead [SEP]']
[ 900/2000] tot_loss=2.041 (perp=9.647, rec=0.111), tot_loss_proj:2.421 [t=0.26s]
prediction: ['[CLS] oftra metaphysical metaphysical claptra softhead [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.027 (perp=9.647, rec=0.098), tot_loss_proj:2.424 [t=0.26s]
prediction: ['[CLS] oftra metaphysical metaphysical claptra softhead [SEP]']
Attempt swap
[1000/2000] tot_loss=2.252 (perp=10.721, rec=0.108), tot_loss_proj:2.642 [t=0.29s]
prediction: ['[CLS] oftra metaphysical partial claptra softhead [SEP]']
[1050/2000] tot_loss=2.263 (perp=10.721, rec=0.118), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] oftra metaphysical partial claptra softhead [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.243 (perp=10.591, rec=0.125), tot_loss_proj:2.621 [t=0.26s]
prediction: ['[CLS] oftra partial metaphysical claptra softhead [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.142 (perp=10.096, rec=0.122), tot_loss_proj:2.437 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
[1200/2000] tot_loss=2.137 (perp=10.096, rec=0.117), tot_loss_proj:2.433 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1250/2000] tot_loss=2.134 (perp=10.096, rec=0.115), tot_loss_proj:2.437 [t=0.27s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1300/2000] tot_loss=2.129 (perp=10.096, rec=0.110), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
[1350/2000] tot_loss=2.118 (perp=10.096, rec=0.099), tot_loss_proj:2.440 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1400/2000] tot_loss=2.129 (perp=10.096, rec=0.110), tot_loss_proj:2.438 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1450/2000] tot_loss=2.124 (perp=10.096, rec=0.104), tot_loss_proj:2.438 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
[1500/2000] tot_loss=2.130 (perp=10.096, rec=0.111), tot_loss_proj:2.436 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1550/2000] tot_loss=2.120 (perp=10.096, rec=0.101), tot_loss_proj:2.443 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1600/2000] tot_loss=2.126 (perp=10.096, rec=0.107), tot_loss_proj:2.439 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
[1650/2000] tot_loss=2.121 (perp=10.096, rec=0.101), tot_loss_proj:2.437 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1700/2000] tot_loss=2.128 (perp=10.096, rec=0.108), tot_loss_proj:2.434 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1750/2000] tot_loss=2.124 (perp=10.096, rec=0.105), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
[1800/2000] tot_loss=2.134 (perp=10.096, rec=0.115), tot_loss_proj:2.441 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1850/2000] tot_loss=2.136 (perp=10.096, rec=0.116), tot_loss_proj:2.439 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[1900/2000] tot_loss=2.119 (perp=10.096, rec=0.100), tot_loss_proj:2.438 [t=0.27s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
[1950/2000] tot_loss=2.131 (perp=10.096, rec=0.112), tot_loss_proj:2.440 [t=0.25s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Attempt swap
[2000/2000] tot_loss=2.132 (perp=10.096, rec=0.113), tot_loss_proj:2.442 [t=0.26s]
prediction: ['[CLS] of partial metaphysical claptra softheadtra [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of partial metaphysical claptra softheadtra [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 57.143 | r: 66.667
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 61.538 | p: 57.143 | r: 66.667
rougeLsum  | fm: 61.538 | p: 57.143 | r: 66.667
r1fm+r2fm = 79.720

[Aggregate metrics]:
rouge1     | fm: 83.872 | p: 82.714 | r: 85.429
rouge2     | fm: 47.295 | p: 47.105 | r: 47.553
rougeL     | fm: 76.372 | p: 74.978 | r: 77.976
rougeLsum  | fm: 76.809 | p: 75.500 | r: 78.607
r1fm+r2fm = 131.167

input #9 time: 0:11:00 | total time: 1:50:54


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
cosin similarity: 0.650630223734263 normalized error: 0.6565642629854562
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8756442666053772 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8336741924285889 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8261200785636902 for ['[CLS] kiran instrumental whoeverwarinae band system news victorian coalition compilation shoulderscast [SEP]']
[Init] best rec loss: 0.7976791858673096 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.7825101017951965 for ['[CLS] driving below batting israel early style isa handwriting coast sometimes about field oral [SEP]']
[Init] best rec loss: 0.7551528215408325 for ['[CLS]date hate hard older mute showednivorous starred mv quickneas worlds equal [SEP]']
[Init] best perm rec loss: 0.7465006113052368 for ['[CLS] starreddate mute hardneas equalnivorous worlds hate mv quick older showed [SEP]']
[Init] best perm rec loss: 0.7439329624176025 for ['[CLS] equaldate mv quick showed starred mute older hate worldsnivorousneas hard [SEP]']
[Init] best perm rec loss: 0.7436820864677429 for ['[CLS]date equal mute starred hard showednivorous mv worlds older quick hateneas [SEP]']
[Init] best perm rec loss: 0.7434845566749573 for ['[CLS]neas showed equal quick starred hard older hate worlds mute mvdatenivorous [SEP]']
[Init] best perm rec loss: 0.7434006333351135 for ['[CLS]date worlds showednivorous equal quick starred hate hard olderneas mute mv [SEP]']
[Init] best perm rec loss: 0.743076741695404 for ['[CLS]nivorousdateneas starred hard worlds equal hate showed quick mv older mute [SEP]']
[Init] best perm rec loss: 0.7428372502326965 for ['[CLS]dateneas showed hard starrednivorous equal worlds quick older mv hate mute [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.324 (perp=10.492, rec=0.225), tot_loss_proj:2.469 [t=0.26s]
prediction: ['[CLS] ably balance ab instrumentals real rhythms with rhythmulsiveulsive method [SEP]']
[ 100/2000] tot_loss=2.166 (perp=10.119, rec=0.142), tot_loss_proj:2.395 [t=0.27s]
prediction: ['[CLS] ably balance ab concertos real rhythms with rhythmulsiveulsive and [SEP]']
[ 150/2000] tot_loss=1.797 (perp=8.396, rec=0.118), tot_loss_proj:2.049 [t=0.26s]
prediction: ['[CLS] ably balance ab reals real rhythms with rhythm propulsive. [SEP]']
[ 200/2000] tot_loss=1.978 (perp=9.409, rec=0.096), tot_loss_proj:2.298 [t=0.25s]
prediction: ['[CLS] ably balance ab times real rhythms with incident propulsive. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.883 (perp=8.734, rec=0.136), tot_loss_proj:2.055 [t=0.26s]
prediction: ['[CLS] ably balances time ab real rhythms with incident propulsive ; [SEP]']
[ 300/2000] tot_loss=1.988 (perp=8.576, rec=0.273), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] ably balances time ab real rhythms with. propulsive ; [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.715 (perp=7.721, rec=0.171), tot_loss_proj:1.913 [t=0.26s]
prediction: ['[CLS] ably. balances time ab real rhythms with propulsive. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.560 (perp=7.044, rec=0.151), tot_loss_proj:1.770 [t=0.25s]
prediction: ['[CLS] ably. balances time ab real with propulsive rhythms. [SEP]']
[ 450/2000] tot_loss=1.527 (perp=7.044, rec=0.118), tot_loss_proj:1.769 [t=0.27s]
prediction: ['[CLS] ably. balances time ab real with propulsive rhythms. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.784 (perp=8.427, rec=0.098), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] ably. balances time ab real with propulsive rhythms incident [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.644 (perp=9.720, rec=0.700), tot_loss_proj:2.553 [t=0.26s]
prediction: ['[CLS] occurred ably. balances time ab real with tendencyulsive rhythms [SEP]']
[ 600/2000] tot_loss=2.418 (perp=9.720, rec=0.474), tot_loss_proj:2.548 [t=0.24s]
prediction: ['[CLS] occurred ably. balances time ab real with tendencyulsive rhythms [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=2.202 (perp=8.970, rec=0.408), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS]ulsive rhythms occurred ably. balances time ab real with tendency [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.304 (perp=9.753, rec=0.353), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. ablytor balances time asteroids real with tendency [SEP]']
[ 750/2000] tot_loss=2.329 (perp=10.109, rec=0.307), tot_loss_proj:2.626 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. ablytor balances time asteroids real with episode [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.195 (perp=9.209, rec=0.354), tot_loss_proj:2.231 [t=0.27s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances real timeenary with hero [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.095 (perp=8.884, rec=0.318), tot_loss_proj:2.160 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances real time withenary hero [SEP]']
[ 900/2000] tot_loss=2.244 (perp=9.758, rec=0.292), tot_loss_proj:2.454 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances ab time withenary hero [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.143 (perp=9.379, rec=0.267), tot_loss_proj:2.342 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. ably viewpoint balances abenary with time hero [SEP]']
Attempt swap
[1000/2000] tot_loss=2.160 (perp=9.477, rec=0.264), tot_loss_proj:2.423 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ablyulsive balances abenary with time hero [SEP]']
[1050/2000] tot_loss=2.154 (perp=9.477, rec=0.258), tot_loss_proj:2.409 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. ablyulsive balances abenary with time hero [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.057 (perp=9.012, rec=0.254), tot_loss_proj:2.381 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. abulsively balances abenary with time hero [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.002 (perp=8.796, rec=0.243), tot_loss_proj:2.423 [t=0.25s]
prediction: ['[CLS]ulsive rhythms. abenaryly balances abulsive with time hero [SEP]']
[1200/2000] tot_loss=1.995 (perp=8.796, rec=0.236), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS]ulsive rhythms. abenaryly balances abulsive with time hero [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.896 (perp=8.267, rec=0.243), tot_loss_proj:2.355 [t=0.26s]
prediction: ['[CLS]ly rhythms hero abenaryly balances abulsive with time. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.769 (perp=7.624, rec=0.244), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS]ulsive rhythms hero abenaryly balances ably with time. [SEP]']
[1350/2000] tot_loss=1.754 (perp=7.624, rec=0.230), tot_loss_proj:2.042 [t=0.26s]
prediction: ['[CLS]ulsive rhythms hero abenaryly balances ably with time. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.674 (perp=7.159, rec=0.243), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] rhythms hero abenaryly balances abulsively with time. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.540 (perp=6.521, rec=0.236), tot_loss_proj:2.004 [t=0.26s]
prediction: ['[CLS] characters abenaryly rhythms balances abulsively with time. [SEP]']
[1500/2000] tot_loss=1.599 (perp=6.875, rec=0.224), tot_loss_proj:2.055 [t=0.27s]
prediction: ['[CLS] multiple abenaryly rhythms balances abulsively with time. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.536 (perp=6.542, rec=0.228), tot_loss_proj:2.051 [t=0.26s]
prediction: ['[CLS] multiple rhythmsenaryly ab balances abulsively with time. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.533 (perp=6.542, rec=0.224), tot_loss_proj:2.054 [t=0.25s]
prediction: ['[CLS] multiple rhythmsenaryly ab balances abulsively with time. [SEP]']
[1650/2000] tot_loss=1.530 (perp=6.542, rec=0.222), tot_loss_proj:2.051 [t=0.26s]
prediction: ['[CLS] multiple rhythmsenaryly ab balances abulsively with time. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.511 (perp=6.438, rec=0.223), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.502 (perp=6.438, rec=0.214), tot_loss_proj:2.003 [t=0.27s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
[1800/2000] tot_loss=1.500 (perp=6.438, rec=0.212), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.501 (perp=6.438, rec=0.214), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] multiple rhythms abenaryly balances abulsively with time. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.474 (perp=6.283, rec=0.218), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS]enaryly multiple rhythms ab balances abulsively with time. [SEP]']
[1950/2000] tot_loss=1.475 (perp=6.283, rec=0.218), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS]enaryly multiple rhythms ab balances abulsively with time. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=6.283, rec=0.211), tot_loss_proj:1.984 [t=0.27s]
prediction: ['[CLS]enaryly multiple rhythms ab balances abulsively with time. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] ably. balances time ab real with propulsive rhythms incident [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 84.864 | p: 83.245 | r: 86.753
rouge2     | fm: 46.763 | p: 46.452 | r: 47.270
rougeL     | fm: 76.434 | p: 74.974 | r: 78.398
rougeLsum  | fm: 76.607 | p: 75.391 | r: 78.398
r1fm+r2fm = 131.627

input #10 time: 0:10:55 | total time: 2:01:50


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
cosin similarity: 0.8925993019126218 normalized error: 0.48881034290755365
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8786575794219971 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8608336448669434 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7708872556686401 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7703498005867004 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.7699822783470154 for ['[CLS] platform inlandgu tal mevd drawn familiar mileture [SEP]']
[Init] best perm rec loss: 0.7689697742462158 for ['[CLS]gu inland tal drawn me platformvdture familiar mile [SEP]']
[Init] best perm rec loss: 0.7677933573722839 for ['[CLS] inlandgu mile me platform drawn talvdture familiar [SEP]']
[Init] best perm rec loss: 0.7674289345741272 for ['[CLS] talguvd inland mile familiar drawnture me platform [SEP]']
[Init] best perm rec loss: 0.7667564153671265 for ['[CLS] familiar drawn tal inland platform mile meguturevd [SEP]']
[Init] best perm rec loss: 0.7639989256858826 for ['[CLS] drawnture tal familiar me platformgu milevd inland [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.661 (perp=11.844, rec=0.293), tot_loss_proj:3.062 [t=0.26s]
prediction: ['[CLS] being hit " refused landing galaxytically gel refused sick [SEP]']
[ 100/2000] tot_loss=2.799 (perp=13.171, rec=0.165), tot_loss_proj:3.389 [t=0.25s]
prediction: ['[CLS] being attemptedcles stubborn attempted mayor that gel refused refused [SEP]']
[ 150/2000] tot_loss=2.500 (perp=11.849, rec=0.130), tot_loss_proj:3.058 [t=0.25s]
prediction: ['[CLS] was attempted here stubborn attemptedly that gel refused refused [SEP]']
[ 200/2000] tot_loss=2.479 (perp=11.849, rec=0.110), tot_loss_proj:3.059 [t=0.28s]
prediction: ['[CLS] was attempted here stubborn attemptedly that gel refused refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.126 (perp=10.134, rec=0.099), tot_loss_proj:2.742 [t=0.25s]
prediction: ['[CLS] was attempted here attempted stubbornly that gel refused refused [SEP]']
[ 300/2000] tot_loss=2.127 (perp=10.241, rec=0.079), tot_loss_proj:2.784 [t=0.25s]
prediction: ['[CLS] was attempted here attempted stubbornly that gel refused madness [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.131 (perp=10.095, rec=0.112), tot_loss_proj:2.655 [t=0.26s]
prediction: ['[CLS] was attempted here attempted stubbornly that refused gel taking [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.039 (perp=9.710, rec=0.097), tot_loss_proj:2.514 [t=0.26s]
prediction: ['[CLS] was attempted here attempted stubbornly that refused taking gel [SEP]']
[ 450/2000] tot_loss=2.028 (perp=9.710, rec=0.086), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] was attempted here attempted stubbornly that refused taking gel [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.831 (perp=8.764, rec=0.079), tot_loss_proj:2.299 [t=0.26s]
prediction: ['[CLS] here was attempted attempted stubbornly that refused taking gel [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.729 (perp=8.175, rec=0.094), tot_loss_proj:2.184 [t=0.25s]
prediction: ['[CLS] here was attempted attempted stubbornly that being refused gel [SEP]']
[ 600/2000] tot_loss=1.679 (perp=7.940, rec=0.091), tot_loss_proj:2.122 [t=0.27s]
prediction: ['[CLS] here was being attempted stubbornly that being refused gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.668 (perp=7.940, rec=0.080), tot_loss_proj:2.105 [t=0.25s]
prediction: ['[CLS] here was being attempted stubbornly that being refused gel [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.610 (perp=7.697, rec=0.071), tot_loss_proj:2.004 [t=0.25s]
prediction: ['[CLS] here was being attempted that stubbornly being refused gel [SEP]']
[ 750/2000] tot_loss=1.617 (perp=7.697, rec=0.077), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] here was being attempted that stubbornly being refused gel [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.568 (perp=7.412, rec=0.085), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.569 (perp=7.412, rec=0.087), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[ 900/2000] tot_loss=1.578 (perp=7.412, rec=0.096), tot_loss_proj:1.967 [t=0.27s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.561 (perp=7.412, rec=0.079), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.553 (perp=7.412, rec=0.070), tot_loss_proj:1.973 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1050/2000] tot_loss=1.557 (perp=7.412, rec=0.075), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.565 (perp=7.412, rec=0.083), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.562 (perp=7.412, rec=0.080), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1200/2000] tot_loss=1.559 (perp=7.412, rec=0.077), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.559 (perp=7.412, rec=0.076), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.555 (perp=7.412, rec=0.073), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1350/2000] tot_loss=1.568 (perp=7.412, rec=0.086), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.562 (perp=7.412, rec=0.080), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.555 (perp=7.412, rec=0.073), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1500/2000] tot_loss=1.563 (perp=7.412, rec=0.081), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.412, rec=0.076), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.563 (perp=7.412, rec=0.080), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1650/2000] tot_loss=1.553 (perp=7.412, rec=0.071), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.547 (perp=7.412, rec=0.065), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.555 (perp=7.412, rec=0.073), tot_loss_proj:1.968 [t=0.27s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1800/2000] tot_loss=1.556 (perp=7.412, rec=0.074), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.550 (perp=7.412, rec=0.067), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.565 (perp=7.412, rec=0.082), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
[1950/2000] tot_loss=1.548 (perp=7.412, rec=0.065), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.556 (perp=7.412, rec=0.073), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] here was being attempted that being stubbornly refused gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was being attempted that being stubbornly refused gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 85.277 | p: 83.934 | r: 87.100
rouge2     | fm: 45.748 | p: 45.409 | r: 46.204
rougeL     | fm: 77.129 | p: 75.621 | r: 78.626
rougeLsum  | fm: 77.129 | p: 75.880 | r: 78.822
r1fm+r2fm = 131.025

input #11 time: 0:10:57 | total time: 2:12:47


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
cosin similarity: 0.7888396314640075 normalized error: 0.6055704316055367
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8458387851715088 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.7732340693473816 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.769726037979126 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7622662782669067 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.7430709600448608 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 0.7324323058128357 for ['[CLS] vice cruiseola duces designation josh, shop program laurel at citizen formations [SEP]']
[Init] best perm rec loss: 0.7290112376213074 for ['[CLS] citizen viceces designation cruise du shop joshola formations at laurel program, [SEP]']
[Init] best perm rec loss: 0.7279205918312073 for ['[CLS] formations designation at program shopces du vice josh citizen, laurel cruiseola [SEP]']
[Init] best perm rec loss: 0.7277432680130005 for ['[CLS] cruise designation vice citizen duola josh formations, laurel shop at programces [SEP]']
[Init] best perm rec loss: 0.7272396087646484 for ['[CLS], du shop program citizen designationces josh vice formations cruise atola laurel [SEP]']
[Init] best perm rec loss: 0.7269186973571777 for ['[CLS] vice shop at citizen josh formations du, programolaces cruise laurel designation [SEP]']
[Init] best perm rec loss: 0.725749671459198 for ['[CLS] vice program du laurel designation formations citizenola cruise shop, atces josh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.435 (perp=10.860, rec=0.263), tot_loss_proj:2.698 [t=0.25s]
prediction: ['[CLS] a policy radiation cable seeing better advantage especially on any is help barely cable [SEP]']
[ 100/2000] tot_loss=1.961 (perp=8.961, rec=0.169), tot_loss_proj:2.307 [t=0.28s]
prediction: ['[CLS] that will cable cable to better advantage especially on its is help barely barely [SEP]']
[ 150/2000] tot_loss=2.050 (perp=9.626, rec=0.124), tot_loss_proj:2.410 [t=0.27s]
prediction: ['[CLS] that will either cable seen better advantage especially on on its. barely barely [SEP]']
[ 200/2000] tot_loss=2.093 (perp=9.926, rec=0.107), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] that will especially cable seen better advantage considering on on its, barely barely [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.998 (perp=9.435, rec=0.111), tot_loss_proj:2.374 [t=0.25s]
prediction: ['[CLS] that especially cable will seen better advantage considering on on its to barely barely [SEP]']
[ 300/2000] tot_loss=1.972 (perp=9.435, rec=0.085), tot_loss_proj:2.375 [t=0.26s]
prediction: ['[CLS] that especially cable will seen better advantage considering on on its to barely barely [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.896 (perp=9.110, rec=0.073), tot_loss_proj:2.320 [t=0.26s]
prediction: ['[CLS] that especially cable will seen better advantage considering on its to barely barely on [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.850 (perp=8.882, rec=0.074), tot_loss_proj:2.354 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage considering on its to barely barely cable [SEP]']
[ 450/2000] tot_loss=1.852 (perp=8.882, rec=0.076), tot_loss_proj:2.357 [t=0.24s]
prediction: ['[CLS] that especially on will seen better advantage considering on its to barely barely cable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.816 (perp=8.659, rec=0.084), tot_loss_proj:2.283 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage considering on its cable barely barely to [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.788 (perp=8.568, rec=0.074), tot_loss_proj:2.260 [t=0.27s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
[ 600/2000] tot_loss=1.782 (perp=8.568, rec=0.069), tot_loss_proj:2.262 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.792 (perp=8.568, rec=0.078), tot_loss_proj:2.265 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.780 (perp=8.568, rec=0.067), tot_loss_proj:2.261 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
[ 750/2000] tot_loss=1.791 (perp=8.568, rec=0.078), tot_loss_proj:2.259 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.789 (perp=8.568, rec=0.076), tot_loss_proj:2.263 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.788 (perp=8.524, rec=0.084), tot_loss_proj:2.247 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage especially on considering its cable barely to [SEP]']
[ 900/2000] tot_loss=1.784 (perp=8.599, rec=0.064), tot_loss_proj:2.291 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=8.599, rec=0.073), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.788 (perp=8.599, rec=0.069), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
[1050/2000] tot_loss=1.792 (perp=8.599, rec=0.073), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.599, rec=0.073), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] that especially on will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
[1150/2000] tot_loss=1.777 (perp=8.523, rec=0.073), tot_loss_proj:2.245 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage barely on considering its cable barely to [SEP]']
[1200/2000] tot_loss=1.779 (perp=8.523, rec=0.075), tot_loss_proj:2.245 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage barely on considering its cable barely to [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.767 (perp=8.469, rec=0.074), tot_loss_proj:2.158 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1300/2000] tot_loss=1.768 (perp=8.469, rec=0.075), tot_loss_proj:2.155 [t=0.27s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1350/2000] tot_loss=1.763 (perp=8.469, rec=0.069), tot_loss_proj:2.155 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1400/2000] tot_loss=1.765 (perp=8.469, rec=0.071), tot_loss_proj:2.159 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1450/2000] tot_loss=1.771 (perp=8.469, rec=0.077), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1500/2000] tot_loss=1.768 (perp=8.469, rec=0.074), tot_loss_proj:2.156 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.769 (perp=8.469, rec=0.075), tot_loss_proj:2.157 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1600/2000] tot_loss=1.770 (perp=8.469, rec=0.076), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1650/2000] tot_loss=1.759 (perp=8.469, rec=0.065), tot_loss_proj:2.159 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1700/2000] tot_loss=1.760 (perp=8.469, rec=0.066), tot_loss_proj:2.157 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1750/2000] tot_loss=1.761 (perp=8.469, rec=0.067), tot_loss_proj:2.160 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1800/2000] tot_loss=1.763 (perp=8.469, rec=0.069), tot_loss_proj:2.158 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1850/2000] tot_loss=1.760 (perp=8.469, rec=0.066), tot_loss_proj:2.154 [t=0.34s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[1900/2000] tot_loss=1.764 (perp=8.469, rec=0.071), tot_loss_proj:2.158 [t=0.25s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
[1950/2000] tot_loss=1.765 (perp=8.469, rec=0.071), tot_loss_proj:2.160 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]']
Attempt swap
[2000/2000] tot_loss=1.744 (perp=8.380, rec=0.068), tot_loss_proj:2.173 [t=0.26s]
prediction: ['[CLS] that especially, will seen better advantage on considering its cable barely, to [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] that especially, will seen better advantage on considering its cable barely barely to [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 73.333 | p: 73.333 | r: 73.333
rougeLsum  | fm: 73.333 | p: 73.333 | r: 73.333
r1fm+r2fm = 121.905

[Aggregate metrics]:
rouge1     | fm: 86.171 | p: 84.843 | r: 87.766
rouge2     | fm: 44.389 | p: 44.094 | r: 44.704
rougeL     | fm: 76.925 | p: 75.705 | r: 78.312
rougeLsum  | fm: 76.899 | p: 75.673 | r: 78.443
r1fm+r2fm = 130.560

input #12 time: 0:10:57 | total time: 2:23:45


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
cosin similarity: -0.7751034936878405 normalized error: 1.6080171585416112
cosin similarity: 0.7751034936878405 normalized error: 0.6023913888772761
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8799152374267578 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8692481517791748 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.7824040055274963 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7573435306549072 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7498305439949036 for ['[CLS] pdf along timing started mal practical prevailed [SEP]']
[Init] best rec loss: 0.7135336399078369 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best perm rec loss: 0.7128738164901733 for ['[CLS] speakerxygled as finish do eh [SEP]']
[Init] best perm rec loss: 0.708302915096283 for ['[CLS]xy asgled finish do eh speaker [SEP]']
[Init] best perm rec loss: 0.7081822752952576 for ['[CLS]xy speaker dogled eh finish as [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.855 (perp=12.494, rec=0.357), tot_loss_proj:3.109 [t=0.25s]
prediction: ['[CLS] point. flame [SEP] [SEP] inherently bitch [SEP]']
[ 100/2000] tot_loss=2.878 (perp=12.914, rec=0.295), tot_loss_proj:3.471 [t=0.26s]
prediction: ['[CLS] point cases flame [SEP] [SEP] flame into [SEP]']
[ 150/2000] tot_loss=2.551 (perp=11.633, rec=0.225), tot_loss_proj:3.039 [t=0.24s]
prediction: ['[CLS] point cases flame [SEP]ossa explode into [SEP]']
[ 200/2000] tot_loss=2.513 (perp=11.633, rec=0.187), tot_loss_proj:3.043 [t=0.26s]
prediction: ['[CLS] point cases flame [SEP]ossa explode into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.229 (perp=10.121, rec=0.205), tot_loss_proj:2.572 [t=0.27s]
prediction: ['[CLS] point cases [SEP] mountains explode into flame [SEP]']
[ 300/2000] tot_loss=2.156 (perp=10.005, rec=0.154), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] point cases [SEP]ossa explode into flame [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.154 (perp=10.005, rec=0.152), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] point cases [SEP]ossa explode into flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.183 (perp=10.143, rec=0.154), tot_loss_proj:2.606 [t=0.25s]
prediction: ['[CLS] point cases [SEP] guys explode into flame [SEP]']
[ 450/2000] tot_loss=2.168 (perp=10.143, rec=0.140), tot_loss_proj:2.599 [t=0.27s]
prediction: ['[CLS] point cases [SEP] guys explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.218 (perp=10.390, rec=0.140), tot_loss_proj:2.633 [t=0.26s]
prediction: ['[CLS] point guys [SEP] things explode into flame [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.160 (perp=10.094, rec=0.141), tot_loss_proj:2.515 [t=0.26s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
[ 600/2000] tot_loss=2.149 (perp=10.094, rec=0.130), tot_loss_proj:2.523 [t=0.26s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.150 (perp=10.094, rec=0.131), tot_loss_proj:2.521 [t=0.27s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.141 (perp=10.094, rec=0.122), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
[ 750/2000] tot_loss=2.144 (perp=10.094, rec=0.125), tot_loss_proj:2.527 [t=0.26s]
prediction: ['[CLS] [SEP] point guys things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.841 (perp=8.540, rec=0.134), tot_loss_proj:2.212 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.826 (perp=8.540, rec=0.118), tot_loss_proj:2.208 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
[ 900/2000] tot_loss=1.837 (perp=8.540, rec=0.129), tot_loss_proj:2.212 [t=0.26s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.837 (perp=8.540, rec=0.129), tot_loss_proj:2.208 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.830 (perp=8.540, rec=0.122), tot_loss_proj:2.206 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
[1050/2000] tot_loss=1.834 (perp=8.540, rec=0.127), tot_loss_proj:2.202 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.822 (perp=8.540, rec=0.114), tot_loss_proj:2.214 [t=0.27s]
prediction: ['[CLS] [SEP] point, things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.529 (perp=7.088, rec=0.112), tot_loss_proj:1.787 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
[1200/2000] tot_loss=1.542 (perp=7.088, rec=0.124), tot_loss_proj:1.775 [t=0.27s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.536 (perp=7.088, rec=0.118), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.536 (perp=7.088, rec=0.118), tot_loss_proj:1.781 [t=0.26s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
[1350/2000] tot_loss=1.543 (perp=7.088, rec=0.125), tot_loss_proj:1.775 [t=0.26s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.545 (perp=7.088, rec=0.127), tot_loss_proj:1.777 [t=0.26s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.530 (perp=7.088, rec=0.112), tot_loss_proj:1.778 [t=0.26s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
[1500/2000] tot_loss=1.542 (perp=7.088, rec=0.124), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.525 (perp=7.088, rec=0.107), tot_loss_proj:1.778 [t=0.25s]
prediction: ['[CLS] at point, things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.893 (perp=8.873, rec=0.118), tot_loss_proj:2.220 [t=0.27s]
prediction: ['[CLS] at point ones things explode into flame [SEP]']
[1650/2000] tot_loss=1.882 (perp=8.873, rec=0.107), tot_loss_proj:2.220 [t=0.28s]
prediction: ['[CLS] at point ones things explode into flame [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.674 (perp=7.768, rec=0.121), tot_loss_proj:1.958 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.677 (perp=7.768, rec=0.124), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
[1800/2000] tot_loss=1.672 (perp=7.768, rec=0.118), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.672 (perp=7.768, rec=0.118), tot_loss_proj:1.956 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=7.768, rec=0.129), tot_loss_proj:1.957 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
[1950/2000] tot_loss=1.660 (perp=7.768, rec=0.106), tot_loss_proj:1.959 [t=0.25s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.680 (perp=7.768, rec=0.126), tot_loss_proj:1.962 [t=0.26s]
prediction: ['[CLS] at ones point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at ones point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 86.144 | p: 84.947 | r: 87.759
rouge2     | fm: 44.125 | p: 43.820 | r: 44.419
rougeL     | fm: 76.878 | p: 75.784 | r: 78.203
rougeLsum  | fm: 76.942 | p: 75.773 | r: 78.386
r1fm+r2fm = 130.269

input #13 time: 0:10:59 | total time: 2:34:45


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
cosin similarity: 0.9712534810517994 normalized error: 0.4024497074016018
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9447705745697021 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9171150922775269 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9017971754074097 for ['[CLS]grass would shitnes lam [SEP]']
[Init] best rec loss: 0.8775820732116699 for ['[CLS] templar west minister friend fox [SEP]']
[Init] best rec loss: 0.8674244284629822 for ['[CLS] individual jensvable underground, [SEP]']
[Init] best rec loss: 0.8492484092712402 for ['[CLS] quiver federation maddie sacramentoboard [SEP]']
[Init] best rec loss: 0.8114392161369324 for ['[CLS] magic team came directed basis [SEP]']
[Init] best perm rec loss: 0.8070271611213684 for ['[CLS] directed basis team came magic [SEP]']
[Init] best perm rec loss: 0.8068185448646545 for ['[CLS] came magic directed team basis [SEP]']
[Init] best perm rec loss: 0.8067232370376587 for ['[CLS] directed team magic basis came [SEP]']
[Init] best perm rec loss: 0.8057131171226501 for ['[CLS] basis magic came team directed [SEP]']
[Init] best perm rec loss: 0.8056298494338989 for ['[CLS] basis directed magic came team [SEP]']
[Init] best perm rec loss: 0.804003894329071 for ['[CLS] magic directed came team basis [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.607 (perp=11.589, rec=0.289), tot_loss_proj:2.819 [t=0.26s]
prediction: ['[CLS] intriguing film gave regardless intriguing [SEP]']
[ 100/2000] tot_loss=2.842 (perp=13.350, rec=0.172), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] intriguing film fullyenia intriguing [SEP]']
[ 150/2000] tot_loss=2.957 (perp=14.021, rec=0.152), tot_loss_proj:3.300 [t=0.25s]
prediction: ['[CLS] intriguing filmblyenia intriguing [SEP]']
[ 200/2000] tot_loss=2.915 (perp=14.021, rec=0.111), tot_loss_proj:3.297 [t=0.25s]
prediction: ['[CLS] intriguing filmblyenia intriguing [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.445 (perp=6.728, rec=0.099), tot_loss_proj:1.411 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 300/2000] tot_loss=1.432 (perp=6.728, rec=0.086), tot_loss_proj:1.403 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.414 (perp=6.728, rec=0.068), tot_loss_proj:1.406 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.413 (perp=6.728, rec=0.067), tot_loss_proj:1.402 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.407 (perp=6.728, rec=0.061), tot_loss_proj:1.418 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.419 (perp=6.728, rec=0.073), tot_loss_proj:1.411 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.414 (perp=6.728, rec=0.069), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.401 (perp=6.728, rec=0.055), tot_loss_proj:1.412 [t=0.29s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.417 (perp=6.728, rec=0.072), tot_loss_proj:1.398 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.427 (perp=6.728, rec=0.082), tot_loss_proj:1.406 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.418 (perp=6.728, rec=0.072), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.418 (perp=6.728, rec=0.073), tot_loss_proj:1.422 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.425 (perp=6.728, rec=0.079), tot_loss_proj:1.401 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.418 (perp=6.728, rec=0.073), tot_loss_proj:1.407 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.416 (perp=6.728, rec=0.071), tot_loss_proj:1.408 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.414 (perp=6.728, rec=0.068), tot_loss_proj:1.408 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.412 (perp=6.728, rec=0.067), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.412 (perp=6.728, rec=0.067), tot_loss_proj:1.407 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.401 (perp=6.728, rec=0.056), tot_loss_proj:1.419 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.408 (perp=6.728, rec=0.062), tot_loss_proj:1.409 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.404 (perp=6.728, rec=0.058), tot_loss_proj:1.409 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.414 (perp=6.728, rec=0.069), tot_loss_proj:1.403 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.423 (perp=6.728, rec=0.077), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.408 (perp=6.728, rec=0.063), tot_loss_proj:1.407 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.411 (perp=6.728, rec=0.066), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.420 (perp=6.728, rec=0.075), tot_loss_proj:1.400 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.411 (perp=6.728, rec=0.065), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.409 (perp=6.728, rec=0.064), tot_loss_proj:1.408 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.415 (perp=6.728, rec=0.070), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.410 (perp=6.728, rec=0.065), tot_loss_proj:1.416 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.407 (perp=6.728, rec=0.061), tot_loss_proj:1.409 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.421 (perp=6.728, rec=0.075), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.412 (perp=6.728, rec=0.066), tot_loss_proj:1.410 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.411 (perp=6.728, rec=0.066), tot_loss_proj:1.411 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.406 (perp=6.728, rec=0.060), tot_loss_proj:1.406 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.407 (perp=6.728, rec=0.061), tot_loss_proj:1.411 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.258 | p: 86.245 | r: 88.690
rouge2     | fm: 47.870 | p: 47.606 | r: 48.255
rougeL     | fm: 78.487 | p: 77.486 | r: 79.734
rougeLsum  | fm: 78.390 | p: 77.412 | r: 79.645
r1fm+r2fm = 135.129

input #14 time: 0:10:59 | total time: 2:45:45


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
cosin similarity: 0.6748695288074162 normalized error: 0.6247062170652273
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9225282073020935 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.906060516834259 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.9007771015167236 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8829787373542786 for ['[CLS] danger italiana vehicles tibet obligation ball fantastic tessa [SEP]']
[Init] best rec loss: 0.861305832862854 for ['[CLS]ₑ scouts jeffital near mills reserveignment [SEP]']
[Init] best perm rec loss: 0.8612588047981262 for ['[CLS] near reserveital jeff millsₑ scoutsignment [SEP]']
[Init] best perm rec loss: 0.8599888682365417 for ['[CLS] nearignment scouts reserveitalₑ mills jeff [SEP]']
[Init] best perm rec loss: 0.8591567277908325 for ['[CLS] jeff mills scouts nearitalₑignment reserve [SEP]']
[Init] best perm rec loss: 0.85694420337677 for ['[CLS] millsital jeff reserve nearₑ scoutsignment [SEP]']
[Init] best perm rec loss: 0.85686194896698 for ['[CLS] jeff scouts reserveital nearₑ millsignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.667 (perp=12.215, rec=0.224), tot_loss_proj:3.037 [t=0.25s]
prediction: ['[CLS] efficient efficientablyably chill anonymous, anonymous [SEP]']
[ 100/2000] tot_loss=2.293 (perp=10.729, rec=0.147), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS]ably efficientably suit chiller. anonymous [SEP]']
[ 150/2000] tot_loss=2.270 (perp=10.893, rec=0.091), tot_loss_proj:2.606 [t=0.26s]
prediction: ['[CLS]ably efficientably suit chiller, anonymous [SEP]']
[ 200/2000] tot_loss=2.266 (perp=10.893, rec=0.088), tot_loss_proj:2.609 [t=0.25s]
prediction: ['[CLS]ably efficientably suit chiller, anonymous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.722 (perp=8.122, rec=0.098), tot_loss_proj:1.934 [t=0.25s]
prediction: ['[CLS]ably suitably efficient chiller, anonymous [SEP]']
[ 300/2000] tot_loss=1.711 (perp=8.122, rec=0.086), tot_loss_proj:1.938 [t=0.25s]
prediction: ['[CLS]ably suitably efficient chiller, anonymous [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.612 (perp=7.643, rec=0.084), tot_loss_proj:1.807 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.610 (perp=7.643, rec=0.081), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 450/2000] tot_loss=1.609 (perp=7.643, rec=0.080), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.603 (perp=7.643, rec=0.075), tot_loss_proj:1.801 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.602 (perp=7.643, rec=0.073), tot_loss_proj:1.797 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 600/2000] tot_loss=1.603 (perp=7.643, rec=0.075), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.604 (perp=7.643, rec=0.075), tot_loss_proj:1.805 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.605 (perp=7.643, rec=0.076), tot_loss_proj:1.800 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 750/2000] tot_loss=1.604 (perp=7.643, rec=0.075), tot_loss_proj:1.801 [t=0.28s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.594 (perp=7.643, rec=0.066), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.599 (perp=7.643, rec=0.070), tot_loss_proj:1.806 [t=0.27s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.609 (perp=7.643, rec=0.080), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.605 (perp=7.643, rec=0.076), tot_loss_proj:1.803 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1000/2000] tot_loss=1.606 (perp=7.643, rec=0.077), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1050/2000] tot_loss=1.603 (perp=7.643, rec=0.074), tot_loss_proj:1.807 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.603 (perp=7.643, rec=0.074), tot_loss_proj:1.808 [t=0.28s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1150/2000] tot_loss=1.599 (perp=7.643, rec=0.070), tot_loss_proj:1.806 [t=0.29s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1200/2000] tot_loss=1.605 (perp=7.643, rec=0.077), tot_loss_proj:1.802 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1250/2000] tot_loss=1.607 (perp=7.643, rec=0.078), tot_loss_proj:1.797 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1300/2000] tot_loss=1.605 (perp=7.643, rec=0.076), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.643, rec=0.077), tot_loss_proj:1.801 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1400/2000] tot_loss=1.606 (perp=7.643, rec=0.078), tot_loss_proj:1.800 [t=0.26s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1450/2000] tot_loss=1.600 (perp=7.643, rec=0.071), tot_loss_proj:1.801 [t=0.28s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.643, rec=0.071), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS]ably suitably efficient, anonymous chiller [SEP]']
Attempt swap
[1550/2000] tot_loss=1.943 (perp=9.324, rec=0.078), tot_loss_proj:2.165 [t=0.26s]
prediction: ['[CLS]ably suit. efficient, anonymous chiller [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.640 (perp=7.815, rec=0.077), tot_loss_proj:1.829 [t=0.25s]
prediction: ['[CLS] suitably. efficient, anonymous chiller [SEP]']
[1650/2000] tot_loss=1.630 (perp=7.815, rec=0.067), tot_loss_proj:1.831 [t=0.26s]
prediction: ['[CLS] suitably. efficient, anonymous chiller [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.405 (perp=6.697, rec=0.065), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.405 (perp=6.697, rec=0.066), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.398 (perp=6.697, rec=0.058), tot_loss_proj:1.514 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.413 (perp=6.697, rec=0.073), tot_loss_proj:1.510 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.403 (perp=6.697, rec=0.064), tot_loss_proj:1.518 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.409 (perp=6.697, rec=0.070), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.697, rec=0.062), tot_loss_proj:1.522 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 88.089 | p: 87.121 | r: 89.313
rouge2     | fm: 46.825 | p: 46.638 | r: 47.153
rougeL     | fm: 78.626 | p: 77.711 | r: 79.821
rougeLsum  | fm: 78.707 | p: 77.843 | r: 79.948
r1fm+r2fm = 134.914

input #15 time: 0:10:59 | total time: 2:56:45


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
cosin similarity: 0.8608126130577575 normalized error: 0.5227461674587929
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.9955482482910156 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8621894121170044 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7274268269538879 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7240097522735596 for ['[CLS] alta film various slowly lordathi [SEP]']
[Init] best perm rec loss: 0.7223813533782959 for ['[CLS] various lord slowlyathi alta film [SEP]']
[Init] best perm rec loss: 0.7219346165657043 for ['[CLS] variousathi slowly lord film alta [SEP]']
[Init] best perm rec loss: 0.7211410999298096 for ['[CLS] lord alta slowly various filmathi [SEP]']
[Init] best perm rec loss: 0.7205631136894226 for ['[CLS] slowly lord various film altaathi [SEP]']
[Init] best perm rec loss: 0.7197867631912231 for ['[CLS] various filmathi lord alta slowly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.192 (perp=8.826, rec=0.426), tot_loss_proj:2.809 [t=0.26s]
prediction: ['[CLS] all for ; [SEP] more slowly [SEP]']
[ 100/2000] tot_loss=1.936 (perp=8.210, rec=0.294), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] all for, this more this [SEP]']
[ 150/2000] tot_loss=1.839 (perp=7.974, rec=0.244), tot_loss_proj:2.051 [t=0.25s]
prediction: ['[CLS] all of, of more this [SEP]']
[ 200/2000] tot_loss=1.759 (perp=7.941, rec=0.171), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] all of and of more this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.377 (perp=5.901, rec=0.197), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] all of and more of this [SEP]']
[ 300/2000] tot_loss=1.324 (perp=5.901, rec=0.144), tot_loss_proj:1.513 [t=0.26s]
prediction: ['[CLS] all of and more of this [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.202 (perp=5.407, rec=0.120), tot_loss_proj:1.409 [t=0.26s]
prediction: ['[CLS] all of this and more of [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.191 (perp=5.407, rec=0.109), tot_loss_proj:1.410 [t=0.27s]
prediction: ['[CLS] all of this and more of [SEP]']
[ 450/2000] tot_loss=1.177 (perp=5.407, rec=0.096), tot_loss_proj:1.404 [t=0.26s]
prediction: ['[CLS] all of this and more of [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.177 (perp=5.407, rec=0.095), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] all of this and more of [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.177 (perp=5.407, rec=0.096), tot_loss_proj:1.403 [t=0.25s]
prediction: ['[CLS] all of this and more of [SEP]']
[ 600/2000] tot_loss=1.169 (perp=5.407, rec=0.088), tot_loss_proj:1.404 [t=0.26s]
prediction: ['[CLS] all of this and more of [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.082 (perp=4.891, rec=0.104), tot_loss_proj:1.295 [t=0.26s]
prediction: ['[CLS] all of this and more, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.026 (perp=4.697, rec=0.087), tot_loss_proj:1.190 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.028 (perp=4.697, rec=0.089), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.012 (perp=4.697, rec=0.073), tot_loss_proj:1.186 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.009 (perp=4.697, rec=0.070), tot_loss_proj:1.190 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.017 (perp=4.697, rec=0.077), tot_loss_proj:1.179 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.023 (perp=4.697, rec=0.083), tot_loss_proj:1.192 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.008 (perp=4.697, rec=0.069), tot_loss_proj:1.186 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.010 (perp=4.697, rec=0.070), tot_loss_proj:1.187 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.022 (perp=4.697, rec=0.083), tot_loss_proj:1.191 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.015 (perp=4.697, rec=0.075), tot_loss_proj:1.182 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.013 (perp=4.697, rec=0.073), tot_loss_proj:1.197 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.010 (perp=4.697, rec=0.070), tot_loss_proj:1.192 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.016 (perp=4.697, rec=0.076), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.012 (perp=4.697, rec=0.073), tot_loss_proj:1.191 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.012 (perp=4.697, rec=0.072), tot_loss_proj:1.191 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.010 (perp=4.697, rec=0.071), tot_loss_proj:1.189 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.015 (perp=4.697, rec=0.075), tot_loss_proj:1.196 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.011 (perp=4.697, rec=0.072), tot_loss_proj:1.197 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.014 (perp=4.697, rec=0.074), tot_loss_proj:1.197 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.012 (perp=4.697, rec=0.072), tot_loss_proj:1.189 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.015 (perp=4.697, rec=0.075), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.018 (perp=4.697, rec=0.078), tot_loss_proj:1.188 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.017 (perp=4.697, rec=0.077), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.013 (perp=4.697, rec=0.074), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.015 (perp=4.697, rec=0.076), tot_loss_proj:1.190 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.006 (perp=4.697, rec=0.066), tot_loss_proj:1.185 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.016 (perp=4.697, rec=0.077), tot_loss_proj:1.195 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.793 | p: 87.833 | r: 90.072
rouge2     | fm: 50.943 | p: 50.677 | r: 51.065
rougeL     | fm: 80.031 | p: 79.105 | r: 81.306
rougeLsum  | fm: 79.927 | p: 78.926 | r: 81.082
r1fm+r2fm = 139.736

input #16 time: 0:11:00 | total time: 3:07:45


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
cosin similarity: 0.9037399408049033 normalized error: 0.5024741745837585
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8212438821792603 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.803966224193573 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.794378936290741 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7878751158714294 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7689838409423828 for ['[CLS] highestlt short ad relation minority black bunch marine above different [SEP]']
[Init] best rec loss: 0.735167384147644 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best perm rec loss: 0.7347737550735474 for ['[CLS] shooter levi tiute atislav attitude aria lead garde average [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.296 (perp=13.915, rec=0.513), tot_loss_proj:3.587 [t=0.27s]
prediction: ['[CLS] attack expecting ruled junk fuck become junk immediately death bitch according [SEP]']
[ 100/2000] tot_loss=2.695 (perp=11.542, rec=0.387), tot_loss_proj:3.074 [t=0.26s]
prediction: ['[CLS] tsunami expecting want think stuff too junk much death want an [SEP]']
[ 150/2000] tot_loss=2.601 (perp=11.450, rec=0.311), tot_loss_proj:2.999 [t=0.26s]
prediction: ['[CLS] about value want much about too junk much death want want [SEP]']
[ 200/2000] tot_loss=2.555 (perp=11.700, rec=0.215), tot_loss_proj:3.008 [t=0.25s]
prediction: ['[CLS] about value want much about too junk think split want want [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.315 (perp=10.678, rec=0.179), tot_loss_proj:2.788 [t=0.27s]
prediction: ["[CLS] about citizenship think much about too junk want'want want [SEP]"]
[ 300/2000] tot_loss=2.204 (perp=10.340, rec=0.136), tot_loss_proj:2.691 [t=0.25s]
prediction: ["[CLS] about put think much about too going want'want want [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.978 (perp=9.240, rec=0.130), tot_loss_proj:2.440 [t=0.26s]
prediction: ["[CLS] about put too much about think going want'want want [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.798 (perp=8.414, rec=0.115), tot_loss_proj:2.276 [t=0.26s]
prediction: ["[CLS] about put too much think about going want'want want [SEP]"]
[ 450/2000] tot_loss=1.553 (perp=7.187, rec=0.116), tot_loss_proj:2.062 [t=0.26s]
prediction: ["[CLS] about put too much think about going to'want get [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.387 (perp=6.412, rec=0.105), tot_loss_proj:1.874 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.395 (perp=6.412, rec=0.112), tot_loss_proj:1.878 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
[ 600/2000] tot_loss=1.390 (perp=6.412, rec=0.108), tot_loss_proj:1.880 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.376 (perp=6.412, rec=0.094), tot_loss_proj:1.874 [t=0.25s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.389 (perp=6.412, rec=0.107), tot_loss_proj:1.878 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
[ 750/2000] tot_loss=1.373 (perp=6.412, rec=0.090), tot_loss_proj:1.879 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.376 (perp=6.412, rec=0.094), tot_loss_proj:1.884 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.376 (perp=6.412, rec=0.093), tot_loss_proj:1.883 [t=0.25s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
[ 900/2000] tot_loss=1.374 (perp=6.412, rec=0.092), tot_loss_proj:1.885 [t=0.27s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.369 (perp=6.412, rec=0.086), tot_loss_proj:1.882 [t=0.28s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.375 (perp=6.412, rec=0.092), tot_loss_proj:1.882 [t=0.25s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
[1050/2000] tot_loss=1.376 (perp=6.412, rec=0.094), tot_loss_proj:1.880 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.375 (perp=6.412, rec=0.092), tot_loss_proj:1.878 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.367 (perp=6.412, rec=0.085), tot_loss_proj:1.885 [t=0.26s]
prediction: ["[CLS] about put too much think about going'want to get [SEP]"]
[1200/2000] tot_loss=1.432 (perp=6.676, rec=0.096), tot_loss_proj:2.003 [t=0.26s]
prediction: ["[CLS] about put too much think about what'want to get [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.330 (perp=6.184, rec=0.093), tot_loss_proj:1.785 [t=0.27s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.334 (perp=6.184, rec=0.098), tot_loss_proj:1.788 [t=0.28s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
[1350/2000] tot_loss=1.331 (perp=6.184, rec=0.094), tot_loss_proj:1.784 [t=0.26s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.320 (perp=6.184, rec=0.084), tot_loss_proj:1.781 [t=0.25s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.338 (perp=6.184, rec=0.101), tot_loss_proj:1.785 [t=0.27s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
[1500/2000] tot_loss=1.326 (perp=6.184, rec=0.089), tot_loss_proj:1.786 [t=0.26s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.333 (perp=6.184, rec=0.096), tot_loss_proj:1.785 [t=0.29s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.324 (perp=6.184, rec=0.087), tot_loss_proj:1.782 [t=0.26s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
[1650/2000] tot_loss=1.332 (perp=6.184, rec=0.095), tot_loss_proj:1.778 [t=0.25s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.331 (perp=6.184, rec=0.095), tot_loss_proj:1.791 [t=0.25s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.324 (perp=6.184, rec=0.087), tot_loss_proj:1.783 [t=0.29s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
[1800/2000] tot_loss=1.341 (perp=6.184, rec=0.104), tot_loss_proj:1.788 [t=0.27s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.331 (perp=6.184, rec=0.094), tot_loss_proj:1.789 [t=0.26s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.337 (perp=6.184, rec=0.100), tot_loss_proj:1.784 [t=0.28s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
[1950/2000] tot_loss=1.333 (perp=6.184, rec=0.096), tot_loss_proj:1.784 [t=0.28s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.329 (perp=6.184, rec=0.092), tot_loss_proj:1.793 [t=0.26s]
prediction: ["[CLS] put too much think about going about'want to get [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] put too much think about going about'want to get [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 18.182 | p: 18.182 | r: 18.182
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 93.182

[Aggregate metrics]:
rouge1     | fm: 88.065 | p: 87.128 | r: 89.218
rouge2     | fm: 49.336 | p: 49.191 | r: 49.625
rougeL     | fm: 78.634 | p: 77.780 | r: 79.780
rougeLsum  | fm: 78.042 | p: 77.174 | r: 79.226
r1fm+r2fm = 137.401

input #17 time: 0:11:01 | total time: 3:18:46


Running input #18 of 100.
reference: 
========================
invigorating 
========================
cosin similarity: -0.8663931959498936 normalized error: 1.8094839224181716
cosin similarity: 0.8663931959498935 normalized error: 0.4833655777924054
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.0221320390701294 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.8916367888450623 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8877899050712585 for ['[CLS] chartsw tom steps [SEP]']
[Init] best rec loss: 0.8709782361984253 for ['[CLS] br delta ave giant [SEP]']
[Init] best rec loss: 0.8579446077346802 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.8397160172462463 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best rec loss: 0.828350305557251 for ['[CLS] dual circle duodle [SEP]']
[Init] best rec loss: 0.8198036551475525 for ['[CLS] canellant replication calm [SEP]']
[Init] best perm rec loss: 0.8189406394958496 for ['[CLS] replicationellant can calm [SEP]']
[Init] best perm rec loss: 0.8171579837799072 for ['[CLS] can replicationellant calm [SEP]']
[Init] best perm rec loss: 0.8157240748405457 for ['[CLS] calm replicationellant can [SEP]']
[Init] best perm rec loss: 0.8152039647102356 for ['[CLS] can replication calmellant [SEP]']
[Init] best perm rec loss: 0.8143218755722046 for ['[CLS] replication can calmellant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.169 (perp=9.602, rec=0.249), tot_loss_proj:2.552 [t=0.26s]
prediction: ['[CLS] present +gorating [SEP]']
[ 100/2000] tot_loss=1.812 (perp=8.519, rec=0.108), tot_loss_proj:2.102 [t=0.29s]
prediction: ['[CLS]atingvigorating [SEP]']
[ 150/2000] tot_loss=1.791 (perp=8.519, rec=0.087), tot_loss_proj:2.110 [t=0.27s]
prediction: ['[CLS]atingvigorating [SEP]']
[ 200/2000] tot_loss=1.193 (perp=5.588, rec=0.076), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.195 (perp=5.588, rec=0.077), tot_loss_proj:1.190 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.170 (perp=5.588, rec=0.053), tot_loss_proj:1.193 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.176 (perp=5.588, rec=0.058), tot_loss_proj:1.174 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.176 (perp=5.588, rec=0.059), tot_loss_proj:1.194 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.173 (perp=5.588, rec=0.056), tot_loss_proj:1.186 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.176 (perp=5.588, rec=0.058), tot_loss_proj:1.188 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.178 (perp=5.588, rec=0.060), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.185 (perp=5.588, rec=0.068), tot_loss_proj:1.192 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.172 (perp=5.588, rec=0.055), tot_loss_proj:1.189 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.176 (perp=5.588, rec=0.058), tot_loss_proj:1.186 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.177 (perp=5.588, rec=0.060), tot_loss_proj:1.177 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.183 (perp=5.588, rec=0.066), tot_loss_proj:1.180 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.187 (perp=5.588, rec=0.070), tot_loss_proj:1.182 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.172 (perp=5.588, rec=0.054), tot_loss_proj:1.185 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.178 (perp=5.588, rec=0.061), tot_loss_proj:1.183 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.174 (perp=5.588, rec=0.057), tot_loss_proj:1.177 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.190 (perp=5.588, rec=0.073), tot_loss_proj:1.183 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.176 (perp=5.588, rec=0.058), tot_loss_proj:1.177 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.588, rec=0.060), tot_loss_proj:1.181 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.175 (perp=5.588, rec=0.057), tot_loss_proj:1.187 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.173 (perp=5.588, rec=0.056), tot_loss_proj:1.189 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.180 (perp=5.588, rec=0.062), tot_loss_proj:1.189 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.173 (perp=5.588, rec=0.056), tot_loss_proj:1.189 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.179 (perp=5.588, rec=0.062), tot_loss_proj:1.189 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.167 (perp=5.588, rec=0.049), tot_loss_proj:1.187 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.188 (perp=5.588, rec=0.070), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.180 (perp=5.588, rec=0.062), tot_loss_proj:1.190 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.175 (perp=5.588, rec=0.057), tot_loss_proj:1.185 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.181 (perp=5.588, rec=0.063), tot_loss_proj:1.187 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.177 (perp=5.588, rec=0.059), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.175 (perp=5.588, rec=0.058), tot_loss_proj:1.184 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.184 (perp=5.588, rec=0.066), tot_loss_proj:1.176 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.176 (perp=5.588, rec=0.058), tot_loss_proj:1.183 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.179 (perp=5.588, rec=0.061), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.171 (perp=5.588, rec=0.053), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.188 (perp=5.588, rec=0.070), tot_loss_proj:1.192 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.570 | p: 87.709 | r: 89.707
rouge2     | fm: 51.826 | p: 51.607 | r: 52.112
rougeL     | fm: 79.811 | p: 78.953 | r: 80.799
rougeLsum  | fm: 79.259 | p: 78.299 | r: 80.407
r1fm+r2fm = 140.395

input #18 time: 0:11:10 | total time: 3:29:57


Running input #19 of 100.
reference: 
========================
to infamy 
========================
cosin similarity: 0.8340207118100215 normalized error: 0.5752933257115956
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7525543570518494 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7188570499420166 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.695348858833313 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6873683929443359 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.679279625415802 for ['[CLS] behold loud longest finally [SEP]']
[Init] best rec loss: 0.6786624789237976 for ['[CLS] intra raf soviet events [SEP]']
[Init] best perm rec loss: 0.6772951483726501 for ['[CLS] soviet raf events intra [SEP]']
[Init] best perm rec loss: 0.6733114719390869 for ['[CLS] soviet raf intra events [SEP]']
[Init] best perm rec loss: 0.672423779964447 for ['[CLS] events soviet intra raf [SEP]']
[Init] best perm rec loss: 0.6723832488059998 for ['[CLS] events raf soviet intra [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.549 (perp=11.040, rec=0.342), tot_loss_proj:2.913 [t=0.20s]
prediction: ['[CLS] to pressxymy [SEP]']
[ 100/2000] tot_loss=2.353 (perp=11.013, rec=0.150), tot_loss_proj:2.882 [t=0.21s]
prediction: ['[CLS] tofafamy [SEP]']
[ 150/2000] tot_loss=1.303 (perp=6.110, rec=0.081), tot_loss_proj:1.298 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 200/2000] tot_loss=1.292 (perp=6.110, rec=0.070), tot_loss_proj:1.306 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.304 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.287 (perp=6.110, rec=0.065), tot_loss_proj:1.297 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.288 (perp=6.110, rec=0.066), tot_loss_proj:1.303 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.293 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.276 (perp=6.110, rec=0.054), tot_loss_proj:1.301 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.283 (perp=6.110, rec=0.061), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.303 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.276 (perp=6.110, rec=0.055), tot_loss_proj:1.304 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.275 (perp=6.110, rec=0.053), tot_loss_proj:1.298 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.273 (perp=6.110, rec=0.051), tot_loss_proj:1.301 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.297 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.286 (perp=6.110, rec=0.064), tot_loss_proj:1.290 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.285 (perp=6.110, rec=0.063), tot_loss_proj:1.294 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.273 (perp=6.110, rec=0.051), tot_loss_proj:1.302 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.278 (perp=6.110, rec=0.056), tot_loss_proj:1.300 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.289 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.281 (perp=6.110, rec=0.059), tot_loss_proj:1.298 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.268 (perp=6.110, rec=0.046), tot_loss_proj:1.290 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.282 (perp=6.110, rec=0.060), tot_loss_proj:1.301 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.273 (perp=6.110, rec=0.051), tot_loss_proj:1.285 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.286 (perp=6.110, rec=0.064), tot_loss_proj:1.290 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.280 (perp=6.110, rec=0.058), tot_loss_proj:1.299 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.285 (perp=6.110, rec=0.063), tot_loss_proj:1.296 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.283 (perp=6.110, rec=0.061), tot_loss_proj:1.296 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.285 (perp=6.110, rec=0.063), tot_loss_proj:1.299 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.295 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.273 (perp=6.110, rec=0.051), tot_loss_proj:1.297 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.298 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.284 (perp=6.110, rec=0.062), tot_loss_proj:1.298 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.290 (perp=6.110, rec=0.068), tot_loss_proj:1.286 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.294 (perp=6.110, rec=0.072), tot_loss_proj:1.296 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.291 (perp=6.110, rec=0.069), tot_loss_proj:1.292 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.277 (perp=6.110, rec=0.055), tot_loss_proj:1.303 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.267 (perp=6.110, rec=0.045), tot_loss_proj:1.293 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.366 | p: 88.454 | r: 90.340
rouge2     | fm: 54.269 | p: 54.084 | r: 54.538
rougeL     | fm: 80.790 | p: 80.057 | r: 81.837
rougeLsum  | fm: 80.510 | p: 79.668 | r: 81.387
r1fm+r2fm = 143.635

input #19 time: 0:10:26 | total time: 3:40:24


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
cosin similarity: -0.8303731972303416 normalized error: 1.7135635582976205
cosin similarity: 0.8303731972303418 normalized error: 0.5372736947116259
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8536838889122009 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8406611680984497 for ['[CLS] sal focalgee weeks [SEP]']
[Init] best rec loss: 0.8051146268844604 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.7779421210289001 for ['[CLS] trialuce tai sweet [SEP]']
[Init] best rec loss: 0.7694435715675354 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7648006081581116 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best rec loss: 0.761886715888977 for ['[CLS] + mandarin tropical schools [SEP]']
[Init] best rec loss: 0.7570974826812744 for ['[CLS]wenan oddław [SEP]']
[Init] best perm rec loss: 0.7548872232437134 for ['[CLS]ławan oddwen [SEP]']
[Init] best perm rec loss: 0.7540498375892639 for ['[CLS] oddanławwen [SEP]']
[Init] best perm rec loss: 0.7527672648429871 for ['[CLS] oddanwenław [SEP]']
[Init] best perm rec loss: 0.7527267932891846 for ['[CLS]anławwen odd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.865 (perp=12.573, rec=0.350), tot_loss_proj:3.196 [t=0.25s]
prediction: ['[CLS] pleasureheaverseverse [SEP]']
[ 100/2000] tot_loss=2.423 (perp=10.972, rec=0.228), tot_loss_proj:2.786 [t=0.25s]
prediction: ['[CLS] pleasure ′verse pleasure [SEP]']
[ 150/2000] tot_loss=2.310 (perp=10.566, rec=0.196), tot_loss_proj:2.586 [t=0.27s]
prediction: ['[CLS] pleasureverseverse pleasure [SEP]']
[ 200/2000] tot_loss=2.207 (perp=10.414, rec=0.125), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] pleasure theverse pleasure [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.840 (perp=8.517, rec=0.137), tot_loss_proj:2.325 [t=0.28s]
prediction: ['[CLS] pleasure the pleasureverse [SEP]']
[ 300/2000] tot_loss=1.639 (perp=7.535, rec=0.132), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.589 (perp=7.535, rec=0.082), tot_loss_proj:1.960 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.587 (perp=7.535, rec=0.080), tot_loss_proj:1.962 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 450/2000] tot_loss=1.583 (perp=7.535, rec=0.076), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.565 (perp=7.535, rec=0.058), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 600/2000] tot_loss=1.581 (perp=7.535, rec=0.074), tot_loss_proj:1.978 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.579 (perp=7.535, rec=0.072), tot_loss_proj:1.956 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.570 (perp=7.535, rec=0.063), tot_loss_proj:1.964 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 750/2000] tot_loss=1.572 (perp=7.535, rec=0.065), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.573 (perp=7.535, rec=0.066), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.575 (perp=7.535, rec=0.068), tot_loss_proj:1.960 [t=0.29s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 900/2000] tot_loss=1.575 (perp=7.535, rec=0.068), tot_loss_proj:1.961 [t=0.28s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.572 (perp=7.535, rec=0.065), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.563 (perp=7.535, rec=0.056), tot_loss_proj:1.960 [t=0.28s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1050/2000] tot_loss=1.584 (perp=7.535, rec=0.077), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.582 (perp=7.535, rec=0.075), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.570 (perp=7.535, rec=0.063), tot_loss_proj:1.963 [t=0.34s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1200/2000] tot_loss=1.583 (perp=7.535, rec=0.076), tot_loss_proj:1.971 [t=0.37s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.968 [t=0.34s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.567 (perp=7.535, rec=0.060), tot_loss_proj:1.963 [t=0.33s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.535, rec=0.080), tot_loss_proj:1.965 [t=0.31s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.565 (perp=7.535, rec=0.058), tot_loss_proj:1.961 [t=0.34s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.582 (perp=7.535, rec=0.075), tot_loss_proj:1.960 [t=0.35s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1500/2000] tot_loss=1.572 (perp=7.535, rec=0.065), tot_loss_proj:1.961 [t=0.43s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.578 (perp=7.535, rec=0.071), tot_loss_proj:1.963 [t=0.41s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=7.535, rec=0.064), tot_loss_proj:1.967 [t=0.30s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1650/2000] tot_loss=1.576 (perp=7.535, rec=0.069), tot_loss_proj:1.963 [t=0.28s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.572 (perp=7.535, rec=0.065), tot_loss_proj:1.969 [t=0.31s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.569 (perp=7.535, rec=0.062), tot_loss_proj:1.958 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1800/2000] tot_loss=1.564 (perp=7.535, rec=0.057), tot_loss_proj:1.961 [t=0.28s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.566 (perp=7.535, rec=0.059), tot_loss_proj:1.972 [t=0.29s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.574 (perp=7.535, rec=0.067), tot_loss_proj:1.970 [t=0.33s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1950/2000] tot_loss=1.578 (perp=7.535, rec=0.071), tot_loss_proj:1.959 [t=0.30s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.535, rec=0.075), tot_loss_proj:1.963 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] pleasure the perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 89.847 | p: 88.995 | r: 90.781
rouge2     | fm: 53.152 | p: 53.030 | r: 53.343
rougeL     | fm: 80.593 | p: 79.848 | r: 81.640
rougeLsum  | fm: 80.196 | p: 79.394 | r: 81.212
r1fm+r2fm = 142.999

input #20 time: 0:11:57 | total time: 3:52:21


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
cosin similarity: -0.9150968145462328 normalized error: 1.7452712448861945
cosin similarity: 0.9150968145462328 normalized error: 0.48995361248248304
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9329794645309448 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8720284700393677 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.7994774580001831 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7595756649971008 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7553408145904541 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.754297137260437 for ['[CLS] there she fauna vii general connecticut size, bent item rights loan pose baby situations labor deetakingback according especially [UNK] golden side stony [SEP]']
[Init] best perm rec loss: 0.7533199191093445 for ['[CLS], loan bent labor pose rights baby she especially there fauna side viiback [UNK] item according size connecticut deetaking stony golden situations general [SEP]']
[Init] best perm rec loss: 0.7531570792198181 for ['[CLS] situationsback fauna labor side baby [UNK] she general connecticut stony item accordingtaking especially pose loan there vii, rights size golden bent dee [SEP]']
[Init] best perm rec loss: 0.7526695132255554 for ['[CLS] side [UNK],back especiallytaking bent rights golden connecticut size fauna there item she stony general situations labor according vii pose loan dee baby [SEP]']
[Init] best perm rec loss: 0.7512536644935608 for ['[CLS] dee vii item [UNK] loan labor especially she there stony situations according general rights size baby bent pose connecticut sideback faunataking, golden [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.984 (perp=12.532, rec=0.478), tot_loss_proj:3.239 [t=0.29s]
prediction: ['[CLS] german saddam factory australia substance government stupid which garbage no diocese became? debate report election worst placing no drug similarpo tube become slab [SEP]']
[ 100/2000] tot_loss=2.992 (perp=13.075, rec=0.377), tot_loss_proj:3.350 [t=0.26s]
prediction: ['[CLS] german saddam complex looked substancester interfere which garbage the diocese according? debateeum lawsuit worst considered no violence afterwardspo unpleasant getting extremely [SEP]']
[ 150/2000] tot_loss=2.835 (perp=12.390, rec=0.357), tot_loss_proj:3.142 [t=0.29s]
prediction: ['[CLS] german through store why lookedster interfere or statements the diocese seems? debate shown facial obvious unpleasant less station afterwards whereby instead getting giovanni [SEP]']
[ 200/2000] tot_loss=2.802 (perp=12.543, rec=0.293), tot_loss_proj:3.199 [t=0.28s]
prediction: ['[CLS] german through store from lookedster interfere and statements the diocese seems? works torture benito obvious instead lessco athletes of instead countries giovanni [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.594 (perp=11.543, rec=0.286), tot_loss_proj:2.974 [t=0.26s]
prediction: ['[CLS] german through store from lookedster titular and statements the paint works in works torture feminist obvious instead not performance athletes of instead hiv giovanni [SEP]']
[ 300/2000] tot_loss=2.539 (perp=11.426, rec=0.254), tot_loss_proj:2.981 [t=0.28s]
prediction: ['[CLS] metal through store from looked women titular and statements the paint out of works gandhi women generalized instead serious performance athletes of insteaditia giovanni [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.414 (perp=10.862, rec=0.242), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] metal / store from looked womentypical and statements the paint out of works described only municipalities instead serious performance athletes of womenitia giovanni [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.325 (perp=10.409, rec=0.243), tot_loss_proj:2.724 [t=0.26s]
prediction: ['[CLS] claims each shop from looked womentypical / out the paint out of works immediately discrimination municipalities instead serious of athletes of women how giovanni [SEP]']
[ 450/2000] tot_loss=2.412 (perp=10.973, rec=0.217), tot_loss_proj:2.871 [t=0.26s]
prediction: ['[CLS] claims each shop all looked womentypical the out all paint out of works immediately only municipalities instead serious teachers athletes of women way giovanni [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.333 (perp=10.633, rec=0.206), tot_loss_proj:2.836 [t=0.25s]
prediction: ['[CLS] latin made shop all looked out the paint out of works poems womentypical the only ᵒ instead serious teachers athletes of women way giovanni [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.284 (perp=10.478, rec=0.188), tot_loss_proj:2.748 [t=0.26s]
prediction: ['[CLS] latin paint situation all looked out the made works of works poems womentypical as bonus overs instead serious teachers athletes of women way donations [SEP]']
[ 600/2000] tot_loss=2.324 (perp=10.688, rec=0.186), tot_loss_proj:2.781 [t=0.25s]
prediction: ['[CLS] female paint stereo all looked out the made works of works poems womentypical as bonus out instead serious teachers athletes of women way donations [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.309 (perp=10.634, rec=0.182), tot_loss_proj:2.762 [t=0.26s]
prediction: ['[CLS] out paint stereo all looked out the made works of works hallways womentypical as bonus female instead serious teachers athletes of women way donations [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.114 (perp=9.702, rec=0.174), tot_loss_proj:2.580 [t=0.27s]
prediction: ['[CLS] out paint stereo all looked out like made out of works justine women insteadtypical as female instead serious teachers athletes of women way donations [SEP]']
[ 750/2000] tot_loss=2.096 (perp=9.702, rec=0.155), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] out paint stereo all looked out like made out of works justine women insteadtypical as female instead serious teachers athletes of women way donations [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.005 (perp=9.268, rec=0.151), tot_loss_proj:2.494 [t=0.26s]
prediction: ['[CLS] out crowd stereo all looked out described made out of works like women insteadtypical the female instead serious teachers athletes of women way donations [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.951 (perp=9.009, rec=0.149), tot_loss_proj:2.422 [t=0.26s]
prediction: ['[CLS] out crowd stereo all looked out described made out of works like women insteadtypical the teachers instead serious female athletes of women way donations [SEP]']
[ 900/2000] tot_loss=1.941 (perp=8.986, rec=0.144), tot_loss_proj:2.436 [t=0.25s]
prediction: ['[CLS] out crowd stereo all looked out described made out of works like women insteadtypical the teachers instead serious female athletes of women way giovanni [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.860 (perp=8.577, rec=0.144), tot_loss_proj:2.298 [t=0.26s]
prediction: ['[CLS] out crowd stereo all looked out creature made out of the works like women insteadtypical teachers instead serious female athletes of women way giovanni [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.866 (perp=8.614, rec=0.143), tot_loss_proj:2.305 [t=0.26s]
prediction: ['[CLS] out crowd stereo all look out makes out of the works like women insteadtypical creature teachers instead serious female athletes of women way giovanni [SEP]']
[1050/2000] tot_loss=1.859 (perp=8.614, rec=0.136), tot_loss_proj:2.310 [t=0.25s]
prediction: ['[CLS] out crowd stereo all look out makes out of the works like women insteadtypical creature teachers instead serious female athletes of women way giovanni [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.803 (perp=8.359, rec=0.131), tot_loss_proj:2.245 [t=0.26s]
prediction: ['[CLS] out crowd stereo all look giovanni makes out of the works like women insteadtypical creature teachers instead serious female athletes of women way out [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.788 (perp=8.268, rec=0.135), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature teachers instead serious female athletes crowd women way out [SEP]']
[1200/2000] tot_loss=1.784 (perp=8.268, rec=0.131), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature teachers instead serious female athletes crowd women way out [SEP]']
Attempt swap
[1250/2000] tot_loss=1.844 (perp=8.616, rec=0.121), tot_loss_proj:2.338 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker instead serious female athletes crowd women way out [SEP]']
Attempt swap
[1300/2000] tot_loss=1.859 (perp=8.616, rec=0.135), tot_loss_proj:2.335 [t=0.29s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker instead serious female athletes crowd women way out [SEP]']
[1350/2000] tot_loss=1.898 (perp=8.870, rec=0.124), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker instead serious female athletes⁺ women way out [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.836 (perp=8.587, rec=0.119), tot_loss_proj:2.310 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker women instead serious female athletes⁺ way out [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=8.587, rec=0.131), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker women instead serious female athletes⁺ way out [SEP]']
[1500/2000] tot_loss=1.842 (perp=8.587, rec=0.125), tot_loss_proj:2.306 [t=0.27s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker women instead serious female athletes⁺ way out [SEP]']
Attempt swap
[1550/2000] tot_loss=1.857 (perp=8.698, rec=0.118), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the works like women insteadtypical creature caretaker women instead serious female athletes⁺ way more [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.847 (perp=8.616, rec=0.123), tot_loss_proj:2.337 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of⁺ works like women insteadtypical creature caretaker women instead serious female athletes the way more [SEP]']
[1650/2000] tot_loss=1.863 (perp=8.756, rec=0.112), tot_loss_proj:2.344 [t=0.27s]
prediction: ['[CLS] out of stereo all look giovanni makes out of window works like women insteadtypical creature caretaker women instead serious female athletes the way more [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.828 (perp=8.550, rec=0.118), tot_loss_proj:2.309 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the⁺ works like women insteadtypical creature caretaker women instead serious female athletes way more [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.794 (perp=8.364, rec=0.121), tot_loss_proj:2.281 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.364, rec=0.123), tot_loss_proj:2.279 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.802 (perp=8.364, rec=0.129), tot_loss_proj:2.281 [t=0.26s]
prediction: ['[CLS] out of stereo all look giovanni makes out of the⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.778 (perp=8.271, rec=0.123), tot_loss_proj:2.276 [t=0.26s]
prediction: ['[CLS] out of all stereo look giovanni makes out of the⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]']
[1950/2000] tot_loss=1.781 (perp=8.271, rec=0.127), tot_loss_proj:2.273 [t=0.26s]
prediction: ['[CLS] out of all stereo look giovanni makes out of the⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.740 (perp=8.107, rec=0.119), tot_loss_proj:2.239 [t=0.27s]
prediction: ['[CLS] out of all the look giovanni makes out of stereo⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] out of stereo all look giovanni makes out of the⁺ works like women caretaker insteadtypical creature women instead serious female athletes way more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.000 | r: 69.565
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 37.500 | p: 36.000 | r: 39.130
rougeLsum  | fm: 37.500 | p: 36.000 | r: 39.130
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 88.709 | p: 87.894 | r: 89.801
rouge2     | fm: 50.308 | p: 50.154 | r: 50.527
rougeL     | fm: 78.806 | p: 77.985 | r: 79.796
rougeLsum  | fm: 78.231 | p: 77.523 | r: 79.289
r1fm+r2fm = 139.017

input #21 time: 0:11:01 | total time: 4:03:23


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
cosin similarity: -0.9087198991097636 normalized error: 1.8245618711317035
cosin similarity: 0.9087198991097637 normalized error: 0.45808974339065517
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9823786616325378 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9707271456718445 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9388471841812134 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9381992816925049 for ['[CLS] ;tailrbelt youvill hearingwa jun population street [SEP]']
[Init] best rec loss: 0.9317052960395813 for ['[CLS] bodies yokohama dubbed themed andes book domestic alarmilised sunen [SEP]']
[Init] best rec loss: 0.9261810779571533 for ['[CLS] kernel up magic unitafless east club alcohol manner educating [SEP]']
[Init] best rec loss: 0.9245930314064026 for ['[CLS] clan mainstream symptoms contributing shipsters power investigationt bound chronicle [SEP]']
[Init] best rec loss: 0.9160696864128113 for ['[CLS] milk recovering buildings wormsaga trials housed finds love lucian jonathan [SEP]']
[Init] best rec loss: 0.9085896015167236 for ['[CLS] shin leslie stage good lead streetstze band easter dr prey [SEP]']
[Init] best perm rec loss: 0.9077809453010559 for ['[CLS] streets leadtze good easter dr leslie prey shin band stage [SEP]']
[Init] best perm rec loss: 0.9060751795768738 for ['[CLS] dr leslie band lead easter prey shintze good stage streets [SEP]']
[Init] best perm rec loss: 0.9044312238693237 for ['[CLS] lead stage streets good leslie prey shin dr eastertze band [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=12.457, rec=0.258), tot_loss_proj:2.989 [t=0.27s]
prediction: ['[CLS] successful adaptation adaptation produced julie good enjoyable successful successful an successful [SEP]']
[ 100/2000] tot_loss=2.615 (perp=11.893, rec=0.236), tot_loss_proj:2.831 [t=0.26s]
prediction: ['[CLS] successful adaptation adaptation andita an enjoyable enjoyable successful his successful [SEP]']
[ 150/2000] tot_loss=2.504 (perp=11.473, rec=0.209), tot_loss_proj:2.780 [t=0.25s]
prediction: ['[CLS] successful adaptation adaptation and courthouse an enjoyable enjoyable successful his successful [SEP]']
[ 200/2000] tot_loss=2.450 (perp=11.378, rec=0.174), tot_loss_proj:2.766 [t=0.25s]
prediction: ['[CLS] a adaptation adaptation and courthouse an enjoyable enjoyable successful his successful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.237 (perp=10.278, rec=0.181), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] a multimedia adaptation and knees an enjoyable adaptation successful his own [SEP]']
[ 300/2000] tot_loss=2.233 (perp=10.313, rec=0.170), tot_loss_proj:2.574 [t=0.26s]
prediction: ['[CLS] a consecutive adaptation andible an enjoyable adaptation successfulsibility own [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.006 (perp=9.228, rec=0.160), tot_loss_proj:2.352 [t=0.27s]
prediction: ['[CLS] a consecutiveible films and an enjoyable adaptation successfulsy right [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.989 (perp=9.110, rec=0.167), tot_loss_proj:2.295 [t=0.25s]
prediction: ['[CLS] a successfulible films and an enjoyable adaptation consecutivesibility right [SEP]']
[ 450/2000] tot_loss=1.978 (perp=9.097, rec=0.158), tot_loss_proj:2.293 [t=0.25s]
prediction: ['[CLS] a successfulible films and an enjoyable adaptation consecutivenished right [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.965 (perp=9.097, rec=0.146), tot_loss_proj:2.288 [t=0.28s]
prediction: ['[CLS] a successfulible films and an enjoyable adaptation consecutivenished right [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.945 (perp=8.936, rec=0.158), tot_loss_proj:2.246 [t=0.26s]
prediction: ['[CLS] a successfulա films and an enjoyable adaptation rightnished legitimate [SEP]']
[ 600/2000] tot_loss=1.886 (perp=8.701, rec=0.146), tot_loss_proj:2.223 [t=0.26s]
prediction: ['[CLS] a successful agra films and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.891 (perp=8.701, rec=0.151), tot_loss_proj:2.224 [t=0.27s]
prediction: ['[CLS] a successful agra films and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.895 (perp=8.701, rec=0.155), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS] a successful agra films and an enjoyable adaptation rightnished legitimate [SEP]']
[ 750/2000] tot_loss=1.898 (perp=8.701, rec=0.158), tot_loss_proj:2.223 [t=0.25s]
prediction: ['[CLS] a successful agra films and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.885 (perp=8.701, rec=0.145), tot_loss_proj:2.229 [t=0.27s]
prediction: ['[CLS] a successful agra films and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.912 (perp=8.849, rec=0.142), tot_loss_proj:2.247 [t=0.27s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
[ 900/2000] tot_loss=1.914 (perp=8.849, rec=0.144), tot_loss_proj:2.246 [t=0.26s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.911 (perp=8.849, rec=0.141), tot_loss_proj:2.247 [t=0.25s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1000/2000] tot_loss=1.912 (perp=8.849, rec=0.142), tot_loss_proj:2.237 [t=0.33s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
[1050/2000] tot_loss=1.913 (perp=8.849, rec=0.144), tot_loss_proj:2.242 [t=0.27s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1100/2000] tot_loss=1.917 (perp=8.849, rec=0.147), tot_loss_proj:2.243 [t=0.31s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1150/2000] tot_loss=1.908 (perp=8.849, rec=0.139), tot_loss_proj:2.247 [t=0.36s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
[1200/2000] tot_loss=1.904 (perp=8.849, rec=0.134), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1250/2000] tot_loss=1.909 (perp=8.849, rec=0.139), tot_loss_proj:2.239 [t=0.29s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1300/2000] tot_loss=1.908 (perp=8.849, rec=0.138), tot_loss_proj:2.243 [t=0.28s]
prediction: ['[CLS] a successful agra film and an enjoyable adaptation rightnished legitimate [SEP]']
[1350/2000] tot_loss=1.864 (perp=8.645, rec=0.135), tot_loss_proj:2.240 [t=0.30s]
prediction: ['[CLS] a successful everyone film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1400/2000] tot_loss=1.861 (perp=8.645, rec=0.132), tot_loss_proj:2.252 [t=0.26s]
prediction: ['[CLS] a successful everyone film and an enjoyable adaptation rightnished legitimate [SEP]']
Attempt swap
[1450/2000] tot_loss=1.875 (perp=8.645, rec=0.146), tot_loss_proj:2.240 [t=0.27s]
prediction: ['[CLS] a successful everyone film and an enjoyable adaptation rightnished legitimate [SEP]']
[1500/2000] tot_loss=1.848 (perp=8.591, rec=0.129), tot_loss_proj:2.395 [t=0.27s]
prediction: ['[CLS] a successful everyone film and an enjoyable adaptation right else legitimate [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.782 (perp=8.247, rec=0.133), tot_loss_proj:2.207 [t=0.33s]
prediction: ['[CLS] a successful everyone else and an enjoyable adaptation right film legitimate [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.751 (perp=8.006, rec=0.150), tot_loss_proj:2.166 [t=0.25s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
[1650/2000] tot_loss=1.743 (perp=8.006, rec=0.142), tot_loss_proj:2.171 [t=0.25s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
Attempt swap
[1700/2000] tot_loss=1.745 (perp=8.006, rec=0.144), tot_loss_proj:2.169 [t=0.25s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
Attempt swap
[1750/2000] tot_loss=1.738 (perp=8.006, rec=0.137), tot_loss_proj:2.171 [t=0.25s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
[1800/2000] tot_loss=1.738 (perp=8.006, rec=0.137), tot_loss_proj:2.167 [t=0.26s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
Attempt swap
[1850/2000] tot_loss=1.739 (perp=8.006, rec=0.138), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=8.006, rec=0.140), tot_loss_proj:2.169 [t=0.26s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
[1950/2000] tot_loss=1.737 (perp=8.006, rec=0.136), tot_loss_proj:2.168 [t=0.27s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
Attempt swap
[2000/2000] tot_loss=1.734 (perp=8.006, rec=0.133), tot_loss_proj:2.165 [t=0.26s]
prediction: ['[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful everyone else and an enjoyable film adaptation right legitimate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 41.667 | p: 41.667 | r: 41.667
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 118.590

[Aggregate metrics]:
rouge1     | fm: 88.138 | p: 87.340 | r: 89.191
rouge2     | fm: 50.244 | p: 50.041 | r: 50.418
rougeL     | fm: 78.361 | p: 77.657 | r: 79.169
rougeLsum  | fm: 77.816 | p: 77.027 | r: 78.828
r1fm+r2fm = 138.381

input #22 time: 0:11:26 | total time: 4:14:49


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
cosin similarity: 0.9513774856923713 normalized error: 0.4344634306918702
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7905304431915283 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7447362542152405 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7258021235466003 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7168440222740173 for ['[CLS] ya million [SEP] till mr sp task can under beerarth bulk at light sa torch thing sign guard level fuck bless abby sons land representing health in husband traffic soldier strikes receivedending deputy second cars general cut surgery herself grabphysical wouldn nord mental lord idol [SEP]']
[Init] best perm rec loss: 0.7167462706565857 for ['[CLS] representing [SEP]arth lord health herself sp ya abby sons wouldn grab torch bulk received level mr sign can second land cars deputy trafficending strikes fuck idol million in task nord surgery sa soldier under mental guard husband beer at thing cutphysical light bless till general [SEP]']
[Init] best perm rec loss: 0.7164266705513 for ['[CLS] sa receivedphysical fuck general beer [SEP] sign bulk wouldn level second abby light thing husband deputy strikes herself idolarth in yaending million cars nord grab surgery health traffic under cut torch sons mental sp land lord at till representing bless task mr can guard soldier [SEP]']
[Init] best perm rec loss: 0.7143876552581787 for ['[CLS] can under land [SEP]arth sa task sp sign sons idol husbandphysical light abby deputy lord cars at mr traffic till soldierending representing fuck grab strikes in mental ya bulk cut torch received beer guard million wouldn thing nord herself health second bless general level surgery [SEP]']
[Init] best perm rec loss: 0.7142759561538696 for ['[CLS] in ya abby second [SEP] bulk idol task mr surgery strikes grab health lord at guard herself soldier nord trafficending level sons sp thing bless husband cut beer sa tillphysical can light million mental wouldn general deputyarth representing cars sign received torch fuck under land [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.056 (perp=12.938, rec=0.468), tot_loss_proj:3.314 [t=0.28s]
prediction: ['[CLS]tech theory rights project iron shadow stony lack wooden clinical quebec davidphi vision remix portrait [SEP] soldier vision - goal pointedence design sword atmosphere vision kiss innovative role. joiningnos my valley kantphi push social project release meat peak [SEP] spirit psyche mama coli [SEP]']
[ 100/2000] tot_loss=2.756 (perp=12.019, rec=0.352), tot_loss_proj:3.111 [t=0.25s]
prediction: ['[CLS] cancer, action, war so its war suffrage patriotic ended is management picture also about [SEP] strategic vision psychological picture pointed adolescent water sword atmosphere strategic energy innovative strategic level awarded strategic my - aimedphi the det project ∞ reduction soldiers [SEP] dream exhaled workshop soldiers [SEP]']
[ 150/2000] tot_loss=2.597 (perp=11.451, rec=0.307), tot_loss_proj:2.968 [t=0.28s]
prediction: ['[CLS] requirement ) objective, missionberg quebec without soldier patriotic ultimately is - picture also / [SEP] strategic / military picture pointed ago water poem telescope strategic time spark strategic strategy ultimately strategic my - thus national the cost idea strategic reduction soldiers [SEP] killer establishing story soldiers [SEP]']
[ 200/2000] tot_loss=2.444 (perp=10.944, rec=0.256), tot_loss_proj:2.874 [t=0.25s]
prediction: ['[CLS] na, objective, missionberg its without soldier patriotic ultimately a of picture and : [SEP] objective of religious picture color ago taylorᆼ achieved strategic eventually picture strategic strategy ultimately strategic : - -hot the cost idea ∞ lump soldiers [SEP] killer establishing workshop soldiers [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.397 (perp=10.816, rec=0.234), tot_loss_proj:2.827 [t=0.25s]
prediction: ['[CLS] na, objective, mission when its without soldier picture ultimately a of picture i of hamas objective of military object color ago taylorᆼ achieved perry finally patriotic strategic strategy achieve strategic : - - else the its idea initially vietnam soldiers inherently when imposed workshop soldiers [SEP]']
[ 300/2000] tot_loss=2.312 (perp=10.510, rec=0.210), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] delta, objective, mission when its peculiar whose picture ultimately a of picture a of settlement objective of military object tone ago conflict racecourse ultimately perry eventually patriotic strategic strategy achieve strategic : the : hits the its idea ensure vietnam soldiers inherently when imposedglass soldiers [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.324 (perp=10.663, rec=0.191), tot_loss_proj:2.853 [t=0.29s]
prediction: ['[CLS] ultimately, objective, mission when its without moon picture ultimately a of picture a, settlement objective of military object tone ago conflict racecourse delta perry increasingly patriotic strategic objective achieve strategic : the : hits the its idea # vietnam soldiers inherently when bio rules soldiers [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.294 (perp=9.840, rec=0.326), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] to. objective, object some soldiers - war picture ultimately a vietnam picture i. despite objective of documentary object tone campbell conflict tae commander of but patriotic strategic strategy achieve strategic : the : hitsizing - idea while vietnam soldiers -. introduce rules its [SEP]']
[ 450/2000] tot_loss=2.283 (perp=10.347, rec=0.213), tot_loss_proj:2.733 [t=0.27s]
prediction: ['[CLS] and. objective, objectcor soldiers so war drama ultimately a vietnam picture i? an objective of film, lend jenny conflict. flags venue and patriotic strategic strategy achieve main : the :nonizing -tively to contest vietnamesee. without burkina its [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.055 (perp=9.329, rec=0.189), tot_loss_proj:2.542 [t=0.25s]
prediction: ["[CLS] '. objective, object into soldiers soe drama ultimately a vietnam picture i. an objective of film, tone campbell conflict. actions venue with patriotic strategic strategy achieve main : the :nonizing - receive to contest conflict war. & rules its [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.000 (perp=9.158, rec=0.169), tot_loss_proj:2.475 [t=0.25s]
prediction: ["[CLS] '. objective, object into soldiers soe drama ultimately a vietnam picture i. treatment objective of film, tone andy conflict. actions fitness with patriotic strategic objective achieve main : - :nonizing the receive to contest conflict war. & rules its [SEP]"]
[ 600/2000] tot_loss=1.971 (perp=9.033, rec=0.164), tot_loss_proj:2.437 [t=0.27s]
prediction: ["[CLS] '. objective while object for soldiers soe drama ultimately a vietnam picture i. treatment objective of drama, tone andy conflict. actions fitness with patriotic strategic objective achieve main : - :nonizing the idea to contest conflict war. & rules its [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.960 (perp=9.017, rec=0.157), tot_loss_proj:2.442 [t=0.27s]
prediction: ["[CLS] '. : while object for soldiers soe drama ultimately a vietnam picture i. treatment objective a drama, tone andy conflict. actions fitness to patriotic strategic objective achieve main objective - :nonizing the idea while contest conflict war. & rules its [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=2.010 (perp=9.287, rec=0.152), tot_loss_proj:2.506 [t=0.28s]
prediction: ["[CLS] '. : while object soldiers into soe drama ultimately a vietnam picture i. treatment objective a drama, tone andy conflict. actions fitness to patriotic strategic objective achieve main objective - :nonizing the idea while contest conflict war. & rules its [SEP]"]
[ 750/2000] tot_loss=1.985 (perp=9.195, rec=0.146), tot_loss_proj:2.484 [t=0.27s]
prediction: ['[CLS] and. : while object soldiers into soe drama ultimately a vietnam picture i. treatment objective a drama, tone andy conflict. actions fitness to patriotic strategic objective achieve main objective - :nonizing the idea while ra conflict war. & rules its [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.988 (perp=9.222, rec=0.143), tot_loss_proj:2.492 [t=0.25s]
prediction: ['[CLS] and. : while object soldiers into soe drama ultimately a vietnam picture i. treatment objective a drama, tone andy conflict. actions fitness a achieve strategic objective patriotic main objective - :nonizing the idea while ra conflict war. & rules its [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.052 (perp=9.542, rec=0.143), tot_loss_proj:2.566 [t=0.27s]
prediction: ['[CLS] the while : while object soldiers into soe drama ultimately a vietnam picture i. treatment objective a drama, tone andy conflict. actions fitness a achieve strategic objective patriotic main objective - :nonizing the idea. ra conflict war - buried rules its [SEP]']
[ 900/2000] tot_loss=2.015 (perp=9.393, rec=0.136), tot_loss_proj:2.554 [t=0.26s]
prediction: ['[CLS] the while : while object soldiers into soe drama ultimately a vietnam picture i. treatment objective a drama, ra andy conflict. actions popular the achieve strategic objective patriotic main objective - :nonizing the idea. ra conflict war - buried rules its [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.965 (perp=9.129, rec=0.139), tot_loss_proj:2.505 [t=0.26s]
prediction: ['[CLS] the while : while object soldiers into soe drama ultimately a vietnam picture i. treatment objective a drama, ra andy conflict. actions popular the achieve strategic objective patriotic main objective - :nonizing the idea. ra conflict war its buried rules - [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.938 (perp=9.029, rec=0.132), tot_loss_proj:2.420 [t=0.26s]
prediction: ['[CLS] the conflict : while object soldiers into soe drama ultimately a vietnam picture i these treat objective a drama, ra tone conflict? propaganda popular the achieve strategic objective patriotic main objective - :nonizing the idea. ra while war its buried rules - [SEP]']
[1050/2000] tot_loss=1.945 (perp=9.029, rec=0.139), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] the conflict : while object soldiers into soe drama ultimately a vietnam picture i these treat objective a drama, ra tone conflict? propaganda popular the achieve strategic objective patriotic main objective - :nonizing the idea. ra while war its buried rules - [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.873 (perp=8.668, rec=0.139), tot_loss_proj:2.357 [t=0.25s]
prediction: ['[CLS] the conflict : while object soldiers into soe drama ultimately a vietnam picture i. treat objective a drama, ra tone conflict? attain popular the achieve strategic objective patriotic main objective - :nonizing the war idea. ra while its buried rules - [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.840 (perp=8.531, rec=0.134), tot_loss_proj:2.331 [t=0.27s]
prediction: ['[CLS] the conflict : while object soldiers into soe drama ultimately a vietnam picture i. treat objective a drama, ra tone conflict? propaganda popular achieve the strategic objective patriotic main objective - :nonizing the war idea. ra while its buried rules - [SEP]']
[1200/2000] tot_loss=1.850 (perp=8.579, rec=0.134), tot_loss_proj:2.327 [t=0.27s]
prediction: ['[CLS] the conflict : while object soldiers ( soe drama ultimately a vietnam picture i. treat objective a drama, ra tone conflict? propaganda popular achieve a strategic objective patriotic main objective - :nonizing the war idea. ra while its buried rules - [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.867 (perp=8.687, rec=0.130), tot_loss_proj:2.322 [t=0.29s]
prediction: ['[CLS] the conflict : while object soldiers ( soe drama ultimately a vietnam picturee the treat objective a drama, ra tone conflict? attain popular patriotic achieve the strategic objective main objective - :nonizing the war object. ra while its buried rules - [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.817 (perp=8.414, rec=0.134), tot_loss_proj:2.282 [t=0.25s]
prediction: ['[CLS] the conflict : while object soldiers ( soe drama ultimately a vietnam picturee the treat objective a drama, rah conflict? attain popular patriotic achieve the strategic objective main objective - :nonizing the war buried. ra while its many rules - [SEP]']
[1350/2000] tot_loss=1.804 (perp=8.414, rec=0.122), tot_loss_proj:2.280 [t=0.27s]
prediction: ['[CLS] the conflict : while object soldiers ( soe drama ultimately a vietnam picturee the treat objective a drama, rah conflict? attain popular patriotic achieve the strategic objective main objective - :nonizing the war buried. ra while its many rules - [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.758 (perp=8.157, rec=0.126), tot_loss_proj:2.244 [t=0.26s]
prediction: ['[CLS] the conflict : while object soldiers ( soe drama treat a vietnam picturee the ultimately objective a drama, rah conflict? attain fitness patriotic achieve a strategic objective main objective - :nonizing the war buried. ra while its many rules - [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.834 (perp=8.491, rec=0.136), tot_loss_proj:2.304 [t=0.26s]
prediction: ['[CLS] the conflict : while conflict soldiers ( soe drama treat a vietnam picturee the ultimately objective a drama, rah object? attain fitness patriotic achieve a strategic objective main objective - :nonizing the war buried. ra while its object rules - [SEP]']
[1500/2000] tot_loss=1.796 (perp=8.348, rec=0.127), tot_loss_proj:2.273 [t=0.26s]
prediction: ['[CLS] the conflict : while conflict soldiers ( soe drama treat a vietnam picturee the ultimately objective a drama, rah object? attain classic patriotic achieve the strategic objective main objective - :nonizing the war buried. ra while its object rules - [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.759 (perp=8.132, rec=0.132), tot_loss_proj:2.270 [t=0.26s]
prediction: ['[CLS] the conflict : while conflict soldiers ( soe drama treat a vietnam picturee the ultimately objective a drama, rah object? attain while patriotic achieve the strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.726 (perp=7.978, rec=0.131), tot_loss_proj:2.250 [t=0.25s]
prediction: ['[CLS] the conflict : while conflict soldiers ( soe drama treat a vietnam picture tone the ultimately objective a drama, rae object? actions while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
[1650/2000] tot_loss=1.749 (perp=8.116, rec=0.126), tot_loss_proj:2.283 [t=0.27s]
prediction: ['[CLS] the conflict : while conflict soldiers ( soe drama treat a vietnam picture tone the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.744 (perp=8.116, rec=0.121), tot_loss_proj:2.285 [t=0.25s]
prediction: ['[CLS] the conflict : while conflict soldiers ( soe drama treat a vietnam picture tone the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.735 (perp=8.022, rec=0.130), tot_loss_proj:2.250 [t=0.28s]
prediction: ['[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
[1800/2000] tot_loss=1.727 (perp=8.022, rec=0.123), tot_loss_proj:2.256 [t=0.27s]
prediction: ['[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.734 (perp=8.022, rec=0.130), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.736 (perp=8.022, rec=0.131), tot_loss_proj:2.253 [t=0.26s]
prediction: ['[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
[1950/2000] tot_loss=1.727 (perp=8.022, rec=0.122), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.735 (perp=8.022, rec=0.131), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] the conflict : while soldiers conflict ( soe drama treat a vietnam pictureh the ultimately objective a drama, rae object? attain while patriotic achieve a strategic objective main objective - :nonizing the war buried. ra classic its object rules - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.718 | p: 50.000 | r: 47.500
rouge2     | fm: 7.895 | p: 8.108 | r: 7.692
rougeL     | fm: 25.641 | p: 26.316 | r: 25.000
rougeLsum  | fm: 25.641 | p: 26.316 | r: 25.000
r1fm+r2fm = 56.613

[Aggregate metrics]:
rouge1     | fm: 86.755 | p: 86.035 | r: 87.677
rouge2     | fm: 48.367 | p: 48.204 | r: 48.537
rougeL     | fm: 76.179 | p: 75.490 | r: 77.041
rougeLsum  | fm: 75.698 | p: 74.995 | r: 76.647
r1fm+r2fm = 135.122

input #23 time: 0:11:02 | total time: 4:25:52


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
cosin similarity: -0.9223604647986088 normalized error: 1.7670051703009635
cosin similarity: 0.9223604647986089 normalized error: 0.47736402311244497
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8722712993621826 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8380476832389832 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8145232200622559 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7925075888633728 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.772286593914032 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7617300748825073 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.7240146398544312 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7211897373199463 for ['[CLS] attack ryuaneous unless snow play younger suffer county mid village no arms bond happy portwyl damned bush em [SEP]']
[Init] best perm rec loss: 0.7209998369216919 for ['[CLS] snow suffer county emaneous bond play arms attack mid unless bush ryu happy younger nowyl port damned village [SEP]']
[Init] best perm rec loss: 0.7209053635597229 for ['[CLS] emwyl play county unless attack suffer villageaneous bond no happy ryu mid port snow younger bush arms damned [SEP]']
[Init] best perm rec loss: 0.7208337187767029 for ['[CLS] attack bond county village unless suffer em arms snow happy portaneous damned no mid ryu playwyl younger bush [SEP]']
[Init] best perm rec loss: 0.7201138734817505 for ['[CLS] snow villageaneous unless arms ryu suffer mid county port happy no damned bush younger attackwyl bond em play [SEP]']
[Init] best perm rec loss: 0.719951868057251 for ['[CLS] port mid arms village no county damned bush happy attack bond snow play em youngerwyl unlessaneous ryu suffer [SEP]']
[Init] best perm rec loss: 0.7186954617500305 for ['[CLS] damned unless arms mid playwyl county suffer no attack port bondaneous younger happy snow village em bush ryu [SEP]']
[Init] best perm rec loss: 0.718177080154419 for ['[CLS] village suffer bush damned attack bond county snow arms port play em nowyl unless younger happyaneous ryu mid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.781 (perp=11.665, rec=0.448), tot_loss_proj:3.015 [t=0.27s]
prediction: ['[CLS] were political prevent damned against drug activist drug allegedly terrorists bo poison escaped illegal choked againsttory victims satan suicide [SEP]']
[ 100/2000] tot_loss=2.703 (perp=11.661, rec=0.371), tot_loss_proj:2.990 [t=0.25s]
prediction: ['[CLS] feared political terrorist evil attacking drug activist drug allegedly terrorists terrorists evil throughoutsville choked various object victims! hoax [SEP]']
[ 150/2000] tot_loss=2.714 (perp=11.948, rec=0.324), tot_loss_proj:3.006 [t=0.26s]
prediction: ['[CLS] ignored political affect evil attacked agency context drug institutions terrorists terrorists evil throughoutsville taken the objects terrorism! taken [SEP]']
[ 200/2000] tot_loss=2.606 (perp=11.617, rec=0.283), tot_loss_proj:2.932 [t=0.26s]
prediction: ['[CLS] taken context relations evil terrorists attitude outside drug political terrorists terrorists evil throughoutsville taken the objects indeed! taken [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.483 (perp=11.172, rec=0.249), tot_loss_proj:2.897 [t=0.26s]
prediction: ['[CLS] taken context complexion evil terrorists climate outside the political terrorists terrorists evil throughoutsville taken outside see > taken! [SEP]']
[ 300/2000] tot_loss=2.546 (perp=11.731, rec=0.200), tot_loss_proj:2.986 [t=0.26s]
prediction: ['[CLS] taken context climate evil terrorists climate outside the political terrorists terrorists evil throughoutsville less outside see > taken! [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.405 (perp=11.139, rec=0.177), tot_loss_proj:2.790 [t=0.25s]
prediction: ['[CLS] taken context climate evil terrorists climate outside the political terrorists terrorists evil throughoutsville the see less : taken! [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.229 (perp=10.323, rec=0.164), tot_loss_proj:2.632 [t=0.31s]
prediction: ['[CLS] taken context climate evil terrorists climate outside political political terrorists see evil onlysville the terrorists less : taken! [SEP]']
[ 450/2000] tot_loss=2.265 (perp=10.525, rec=0.160), tot_loss_proj:2.686 [t=0.31s]
prediction: ['[CLS] taken context climate evil terrorists climate outside the political terrorists see evil thansville the difficulty less : taken! [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.111 (perp=9.794, rec=0.152), tot_loss_proj:2.565 [t=0.33s]
prediction: ['[CLS] taken context climate evil terrorists outside the political climate terrorists see evil than sectors the difficulty less : taken! [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.943 (perp=8.957, rec=0.151), tot_loss_proj:2.453 [t=0.32s]
prediction: ['[CLS] taken context climate evil terrorists outside the political climate terrorists see less evil than sectors the difficulty : taken! [SEP]']
[ 600/2000] tot_loss=1.936 (perp=8.957, rec=0.145), tot_loss_proj:2.451 [t=0.31s]
prediction: ['[CLS] taken context climate evil terrorists outside the political climate terrorists see less evil than sectors the difficulty : taken! [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.743 (perp=8.009, rec=0.141), tot_loss_proj:2.254 [t=0.34s]
prediction: ['[CLS] taken context evil climate terrorists outside the political climate terrorists see less evil than from the difficulty : taken! [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.632 (perp=7.407, rec=0.151), tot_loss_proj:2.105 [t=0.36s]
prediction: ['[CLS] taken from context evil climate terrorists outside the political climate terrorists see less evil than the difficulty : taken! [SEP]']
[ 750/2000] tot_loss=1.624 (perp=7.407, rec=0.142), tot_loss_proj:2.106 [t=0.33s]
prediction: ['[CLS] taken from context evil climate terrorists outside the political climate terrorists see less evil than the difficulty : taken! [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.579 (perp=7.169, rec=0.145), tot_loss_proj:2.101 [t=0.27s]
prediction: ['[CLS] taken from context evil climate terrorists outside the political climate : terrorists see less evil than the difficulty taken! [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.525 (perp=6.920, rec=0.141), tot_loss_proj:2.086 [t=0.32s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
[ 900/2000] tot_loss=1.519 (perp=6.920, rec=0.135), tot_loss_proj:2.081 [t=0.28s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.520 (perp=6.920, rec=0.136), tot_loss_proj:2.083 [t=0.34s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1000/2000] tot_loss=1.510 (perp=6.920, rec=0.126), tot_loss_proj:2.087 [t=0.26s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
[1050/2000] tot_loss=1.516 (perp=6.920, rec=0.132), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1100/2000] tot_loss=1.511 (perp=6.920, rec=0.127), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1150/2000] tot_loss=1.512 (perp=6.920, rec=0.128), tot_loss_proj:2.081 [t=0.27s]
prediction: ['[CLS] taken from context evil climate terrorists : outside the political climate : see less evil than the difficulty taken! [SEP]']
[1200/2000] tot_loss=1.622 (perp=7.458, rec=0.131), tot_loss_proj:2.187 [t=0.27s]
prediction: ['[CLS] taken from context evil climate terrorists : outside are political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1250/2000] tot_loss=1.632 (perp=7.458, rec=0.140), tot_loss_proj:2.191 [t=0.28s]
prediction: ['[CLS] taken from context evil climate terrorists : outside are political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1300/2000] tot_loss=1.615 (perp=7.458, rec=0.124), tot_loss_proj:2.192 [t=0.26s]
prediction: ['[CLS] taken from context evil climate terrorists : outside are political climate : see less evil than the difficulty taken! [SEP]']
[1350/2000] tot_loss=1.622 (perp=7.458, rec=0.131), tot_loss_proj:2.193 [t=0.26s]
prediction: ['[CLS] taken from context evil climate terrorists : outside are political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.593 (perp=7.375, rec=0.118), tot_loss_proj:2.178 [t=0.29s]
prediction: ['[CLS] taken from context evil climate : terrorists outside are political climate : see less evil than the difficulty taken! [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.573 (perp=7.194, rec=0.134), tot_loss_proj:2.130 [t=0.27s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
[1500/2000] tot_loss=1.564 (perp=7.194, rec=0.126), tot_loss_proj:2.129 [t=0.26s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1550/2000] tot_loss=1.578 (perp=7.194, rec=0.139), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1600/2000] tot_loss=1.561 (perp=7.194, rec=0.122), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
[1650/2000] tot_loss=1.566 (perp=7.194, rec=0.127), tot_loss_proj:2.124 [t=0.28s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1700/2000] tot_loss=1.566 (perp=7.194, rec=0.127), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1750/2000] tot_loss=1.566 (perp=7.194, rec=0.128), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
[1800/2000] tot_loss=1.568 (perp=7.194, rec=0.129), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1850/2000] tot_loss=1.574 (perp=7.194, rec=0.135), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=7.194, rec=0.134), tot_loss_proj:2.128 [t=0.29s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
[1950/2000] tot_loss=1.566 (perp=7.194, rec=0.127), tot_loss_proj:2.125 [t=0.28s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Attempt swap
[2000/2000] tot_loss=1.564 (perp=7.194, rec=0.125), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] taken from context evil climate : outside are political climate terrorists : see less evil than the difficulty taken! [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.270 | p: 68.421 | r: 72.222
rouge2     | fm: 17.143 | p: 16.667 | r: 17.647
rougeL     | fm: 48.649 | p: 47.368 | r: 50.000
rougeLsum  | fm: 48.649 | p: 47.368 | r: 50.000
r1fm+r2fm = 87.413

[Aggregate metrics]:
rouge1     | fm: 85.887 | p: 85.089 | r: 86.860
rouge2     | fm: 47.226 | p: 47.008 | r: 47.420
rougeL     | fm: 74.974 | p: 74.243 | r: 75.939
rougeLsum  | fm: 74.594 | p: 73.826 | r: 75.534
r1fm+r2fm = 133.112

input #24 time: 0:11:27 | total time: 4:37:19


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
cosin similarity: 0.9657079483269472 normalized error: 0.40029975426057546
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9224249720573425 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9092468619346619 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.8601564764976501 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.8461288809776306 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.8204855918884277 for ['[CLS] mention acre old headline [SEP]']
[Init] best rec loss: 0.8180537819862366 for ['[CLS] hide a seal mess [SEP]']
[Init] best perm rec loss: 0.8127614259719849 for ['[CLS] hide seal mess a [SEP]']
[Init] best perm rec loss: 0.8123824000358582 for ['[CLS] a hide seal mess [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.791 (perp=7.142, rec=0.363), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] beautiful beautiful beautiful 3d [SEP]']
[ 100/2000] tot_loss=2.255 (perp=10.023, rec=0.250), tot_loss_proj:2.383 [t=0.26s]
prediction: ['[CLS] beautiful beautiful culture strange [SEP]']
[ 150/2000] tot_loss=2.103 (perp=9.712, rec=0.161), tot_loss_proj:2.279 [t=0.26s]
prediction: ['[CLS] beautiful beautiful film strange [SEP]']
[ 200/2000] tot_loss=2.079 (perp=9.712, rec=0.137), tot_loss_proj:2.284 [t=0.26s]
prediction: ['[CLS] beautiful beautiful film strange [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.475 (perp=6.913, rec=0.093), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS] and beautiful strange film [SEP]']
[ 300/2000] tot_loss=1.461 (perp=6.913, rec=0.078), tot_loss_proj:1.690 [t=0.27s]
prediction: ['[CLS] and beautiful strange film [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.417 (perp=6.646, rec=0.088), tot_loss_proj:1.474 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.401 (perp=6.646, rec=0.072), tot_loss_proj:1.463 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.396 (perp=6.646, rec=0.066), tot_loss_proj:1.467 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.404 (perp=6.646, rec=0.074), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.406 (perp=6.646, rec=0.077), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.404 (perp=6.646, rec=0.074), tot_loss_proj:1.465 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.403 (perp=6.646, rec=0.074), tot_loss_proj:1.458 [t=0.29s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.402 (perp=6.646, rec=0.072), tot_loss_proj:1.461 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.397 (perp=6.646, rec=0.068), tot_loss_proj:1.469 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.416 (perp=6.646, rec=0.086), tot_loss_proj:1.471 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.396 (perp=6.646, rec=0.067), tot_loss_proj:1.465 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.397 (perp=6.646, rec=0.068), tot_loss_proj:1.466 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.395 (perp=6.646, rec=0.066), tot_loss_proj:1.459 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.405 (perp=6.646, rec=0.076), tot_loss_proj:1.454 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.399 (perp=6.646, rec=0.070), tot_loss_proj:1.468 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.405 (perp=6.646, rec=0.076), tot_loss_proj:1.465 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.405 (perp=6.646, rec=0.075), tot_loss_proj:1.470 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.407 (perp=6.646, rec=0.078), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.396 (perp=6.646, rec=0.067), tot_loss_proj:1.475 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.396 (perp=6.646, rec=0.067), tot_loss_proj:1.464 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.394 (perp=6.646, rec=0.065), tot_loss_proj:1.456 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.389 (perp=6.646, rec=0.060), tot_loss_proj:1.461 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.402 (perp=6.646, rec=0.073), tot_loss_proj:1.464 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.400 (perp=6.646, rec=0.071), tot_loss_proj:1.467 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.401 (perp=6.646, rec=0.072), tot_loss_proj:1.457 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.393 (perp=6.646, rec=0.063), tot_loss_proj:1.459 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.403 (perp=6.646, rec=0.074), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.391 (perp=6.646, rec=0.062), tot_loss_proj:1.457 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.397 (perp=6.646, rec=0.068), tot_loss_proj:1.458 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.396 (perp=6.646, rec=0.067), tot_loss_proj:1.463 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.401 (perp=6.646, rec=0.072), tot_loss_proj:1.465 [t=0.29s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.392 (perp=6.646, rec=0.062), tot_loss_proj:1.473 [t=0.32s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.393 (perp=6.646, rec=0.064), tot_loss_proj:1.461 [t=0.35s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.646, rec=0.067), tot_loss_proj:1.460 [t=0.34s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.410 | p: 85.654 | r: 87.397
rouge2     | fm: 48.965 | p: 48.847 | r: 49.156
rougeL     | fm: 76.112 | p: 75.358 | r: 76.967
rougeLsum  | fm: 75.409 | p: 74.709 | r: 76.281
r1fm+r2fm = 135.375

input #25 time: 0:11:13 | total time: 4:48:33


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
cosin similarity: -0.9021100735279437 normalized error: 1.801235038259484
cosin similarity: 0.9021100735279438 normalized error: 0.4706903940273791
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8739010691642761 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.7807756066322327 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.7666357159614563 for ['[CLS]sed benedict later housing why surroundingpinegrave nat use amount cast thy scored pattern run unknown authority travellingflict quotes guest lucan [SEP]']
[Init] best rec loss: 0.730324923992157 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.722449004650116 for ['[CLS] stakekar passing rides 65 turns speak mutant montrose capacity rid fur unite button riceª ak occupied cher following fully igo [SEP]']
[Init] best rec loss: 0.7101433277130127 for ['[CLS] close both singularification tv for oclc maxim catalog station himselfomy rowater rafcl increasing could there metropolitan townland caps maria [SEP]']
[Init] best perm rec loss: 0.7078802585601807 for ['[CLS]ification close couldcl forwater both station caps metropolitanomy maxim singular oclc townland maria there raf tv catalog increasing ro himself [SEP]']
[Init] best perm rec loss: 0.7074587941169739 for ['[CLS] caps increasing maria singular tvomy himself could station close oclc raf for catalog roificationwater metropolitan townlandcl there both maxim [SEP]']
[Init] best perm rec loss: 0.7046199440956116 for ['[CLS]omy himself for catalogification close stationwater there singular increasing maria townland maxim ro tv oclc caps both could metropolitancl raf [SEP]']
[Init] best perm rec loss: 0.7042733430862427 for ['[CLS] maxim caps maria oclc increasingificationcl station roomy could there catalog bothwater close townland raf himself tv for singular metropolitan [SEP]']
[Init] best perm rec loss: 0.7026723027229309 for ['[CLS] himself closeomy could ro increasing metropolitancl catalog bothwater tv oclc caps forification singular raf townland station maria maxim there [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.827 (perp=12.264, rec=0.375), tot_loss_proj:3.100 [t=0.31s]
prediction: ['[CLS] enoughrom scheduled could oil pay pointless import procedure leftmarket pointless runs caps during under [ archbishop import nonless bb post [SEP]']
[ 100/2000] tot_loss=2.507 (perp=11.147, rec=0.277), tot_loss_proj:2.858 [t=0.30s]
prediction: ['[CLS] thatrom import couldex import pointless import reflex down seem pointless runs import from foreign - import import nonchedleader post [SEP]']
[ 150/2000] tot_loss=2.465 (perp=11.180, rec=0.229), tot_loss_proj:2.875 [t=0.31s]
prediction: ['[CLS] thatrom import could french import pointless importut down seem pointless front import from import - import import nonched symmetry board [SEP]']
[ 200/2000] tot_loss=2.606 (perp=12.038, rec=0.199), tot_loss_proj:3.000 [t=0.33s]
prediction: ['[CLS] thatrom ) dominic french import pointless italianut essayfest pointless front import from age - import import - communist symmetry board [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.388 (perp=10.991, rec=0.189), tot_loss_proj:2.765 [t=0.31s]
prediction: ['[CLS] thisrom ) dominic french coming pointless french essay coming decor pointless length import from age - import import - communist society board [SEP]']
[ 300/2000] tot_loss=2.337 (perp=10.862, rec=0.164), tot_loss_proj:2.826 [t=0.33s]
prediction: ['[CLS] thisrom ) no french coming pointless french essay coming decor pointless length import from age - import import - communist society board [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.370 (perp=11.044, rec=0.161), tot_loss_proj:2.851 [t=0.35s]
prediction: ['[CLS] decor this via ) no realm coming pointless french essay coming pointless representation import from age - import writer - communist symmetry post [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.227 (perp=10.385, rec=0.151), tot_loss_proj:2.786 [t=0.40s]
prediction: ['[CLS] raid this ) ) no realm coming pointless french essay coming from age pointless representation import - import writer - sophie drury board [SEP]']
[ 450/2000] tot_loss=2.298 (perp=10.812, rec=0.135), tot_loss_proj:2.750 [t=0.35s]
prediction: ['[CLS] raid this ) ) and realm coming pointless french leading coming from age pointless features per - import director sophie sophie sister board [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.306 (perp=10.872, rec=0.131), tot_loss_proj:2.741 [t=0.38s]
prediction: ['[CLS]iom this board ) and realm coming pointless french leadinging from age pointless department per - import director sophie sophie sister ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.281 (perp=10.785, rec=0.124), tot_loss_proj:2.712 [t=0.34s]
prediction: ['[CLS]iom this board ) and realm coming pointless french meaning from age dominican department per - import director sophie sophie pointless ) [SEP]']
[ 600/2000] tot_loss=2.255 (perp=10.677, rec=0.119), tot_loss_proj:2.707 [t=0.30s]
prediction: ['[CLS]iom this board ) and realm coming pointless french mean of from age sister department bets - import director sophie sophie pointless ) [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.252 (perp=10.656, rec=0.120), tot_loss_proj:2.709 [t=0.39s]
prediction: ['[CLS] this raid board ) and realm coming pointless french mean of from age sister department bets - import director sophie sophie pointless ) [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.159 (perp=10.208, rec=0.117), tot_loss_proj:2.570 [t=0.34s]
prediction: ['[CLS] thisiom - ) and pseudo coming pointless french mean of sister department bets from age - import director sophie sophie pointless ) [SEP]']
[ 750/2000] tot_loss=2.139 (perp=10.208, rec=0.097), tot_loss_proj:2.572 [t=0.29s]
prediction: ['[CLS] thisiom - ) and pseudo coming pointless french mean of sister department bets from age - import director sophie sophie pointless ) [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.036 (perp=9.608, rec=0.114), tot_loss_proj:2.489 [t=0.37s]
prediction: ['[CLS] thisiom - ) otherwise - department coming pointless french mean of sister bets from age and import director sophie sophie pig ) [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.983 (perp=9.400, rec=0.103), tot_loss_proj:2.458 [t=0.27s]
prediction: ['[CLS] thisiom - ) otherwise - department coming french pointless mean of sister bets from age and import director sophie - pig ) [SEP]']
[ 900/2000] tot_loss=2.049 (perp=9.715, rec=0.106), tot_loss_proj:2.533 [t=0.29s]
prediction: ['[CLS] this bin - ) otherwise - department coming french pointless mean of sister caps from age and import director sophie - pig ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.005 (perp=9.507, rec=0.103), tot_loss_proj:2.444 [t=0.34s]
prediction: ['[CLS] this bin - ) otherwise - - coming french pointless mean of sister caps from age and import director sophie department pig ) [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.062 (perp=9.774, rec=0.107), tot_loss_proj:2.508 [t=0.35s]
prediction: ['[CLS] this bin otherwise ) - - - coming french pointless mean of sister caps from age and import director sophie directors pigir [SEP]']
[1050/2000] tot_loss=2.060 (perp=9.774, rec=0.105), tot_loss_proj:2.507 [t=0.39s]
prediction: ['[CLS] this bin otherwise ) - - - coming french pointless mean of sister caps from age and import director sophie directors pigir [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.017 (perp=9.552, rec=0.107), tot_loss_proj:2.452 [t=0.37s]
prediction: ['[CLS] this bin otherwise ) - - - coming french pointless mean of sister caps from age and import director directors sophie pigir [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.972 (perp=9.385, rec=0.095), tot_loss_proj:2.408 [t=0.27s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister bin caps from age and import director directors sophie pigir [SEP]']
[1200/2000] tot_loss=1.981 (perp=9.385, rec=0.104), tot_loss_proj:2.408 [t=0.28s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister bin caps from age and import director directors sophie pigir [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.919 (perp=9.072, rec=0.105), tot_loss_proj:2.368 [t=0.26s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and raid import director directors sophie pigir [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.858 (perp=8.834, rec=0.091), tot_loss_proj:2.325 [t=0.27s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and import raid director directors sophie pigir [SEP]']
[1350/2000] tot_loss=1.863 (perp=8.834, rec=0.096), tot_loss_proj:2.325 [t=0.29s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and import raid director directors sophie pigir [SEP]']
Attempt swap
[1400/2000] tot_loss=1.921 (perp=9.077, rec=0.106), tot_loss_proj:2.374 [t=0.27s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and import bin director directors sophie pigir [SEP]']
Attempt swap
[1450/2000] tot_loss=1.918 (perp=9.077, rec=0.102), tot_loss_proj:2.366 [t=0.27s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and import bin director directors sophie pigir [SEP]']
[1500/2000] tot_loss=1.907 (perp=9.077, rec=0.092), tot_loss_proj:2.370 [t=0.27s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and import bin director directors sophie pigir [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.947 (perp=9.215, rec=0.105), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age raid import and director directors sophie pigir [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.906 (perp=9.016, rec=0.103), tot_loss_proj:2.351 [t=0.25s]
prediction: ['[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age pig import and director directors sophie raidir [SEP]']
[1650/2000] tot_loss=2.088 (perp=9.933, rec=0.102), tot_loss_proj:2.515 [t=0.26s]
prediction: ['[CLS] this savoy ) - - - coming french pointless mean of sister caps from age pig import and director directors sophie raidir [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.019 (perp=9.629, rec=0.093), tot_loss_proj:2.485 [t=0.27s]
prediction: ['[CLS] this and ) - - - coming french pointless mean of sister caps from age pig import otherwise director directors sophie raidir [SEP]']
Attempt swap
[1750/2000] tot_loss=1.965 (perp=9.351, rec=0.095), tot_loss_proj:2.405 [t=0.26s]
prediction: ['[CLS] this and ) - - - coming french pointless mean of sister caps from age pig import savoy director directors sophie raidir [SEP]']
[1800/2000] tot_loss=1.967 (perp=9.351, rec=0.096), tot_loss_proj:2.403 [t=0.27s]
prediction: ['[CLS] this and ) - - - coming french pointless mean of sister caps from age pig import savoy director directors sophie raidir [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.914 (perp=9.064, rec=0.101), tot_loss_proj:2.339 [t=0.26s]
prediction: ['[CLS] this and ) - - - coming french pointless mean of sister caps from pig age import savoy director directors sophie binir [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.878 (perp=8.911, rec=0.096), tot_loss_proj:2.315 [t=0.25s]
prediction: ['[CLS] and this ) - - - coming french pointless mean of sister caps from pig age import savoy director directors sophie binir [SEP]']
[1950/2000] tot_loss=1.880 (perp=8.911, rec=0.098), tot_loss_proj:2.315 [t=0.28s]
prediction: ['[CLS] and this ) - - - coming french pointless mean of sister caps from pig age import savoy director directors sophie binir [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.871 (perp=8.837, rec=0.104), tot_loss_proj:2.278 [t=0.27s]
prediction: ['[CLS] and this ) - - - coming french pointless mean of sister caps from pig age import director directors sophieiomir savoy [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this otherwise ) - - - coming french pointless mean of sister caps from age and import bin director directors sophie pigir [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.270 | p: 65.000 | r: 76.471
rouge2     | fm: 5.714 | p: 5.263 | r: 6.250
rougeL     | fm: 48.649 | p: 45.000 | r: 52.941
rougeLsum  | fm: 48.649 | p: 45.000 | r: 52.941
r1fm+r2fm = 75.985

[Aggregate metrics]:
rouge1     | fm: 85.901 | p: 84.933 | r: 87.013
rouge2     | fm: 47.329 | p: 47.190 | r: 47.502
rougeL     | fm: 74.833 | p: 74.046 | r: 75.834
rougeLsum  | fm: 74.713 | p: 73.777 | r: 75.674
r1fm+r2fm = 133.230

input #26 time: 0:12:14 | total time: 5:00:47


Running input #27 of 100.
reference: 
========================
are so generic 
========================
cosin similarity: 0.899414383258682 normalized error: 0.48213710503675355
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.8849934339523315 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.8727608323097229 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.8223716616630554 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.8063605427742004 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.7686142325401306 for ['[CLS] part portion mid [SEP]']
[Init] best rec loss: 0.7563238143920898 for ['[CLS] fat mattream [SEP]']
[Init] best rec loss: 0.7304683327674866 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.725821316242218 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.561 (perp=11.526, rec=0.256), tot_loss_proj:2.730 [t=0.26s]
prediction: ['[CLS] florida left generic [SEP]']
[ 100/2000] tot_loss=1.746 (perp=8.320, rec=0.082), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 150/2000] tot_loss=1.731 (perp=8.320, rec=0.067), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 200/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.724 (perp=8.320, rec=0.060), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.721 (perp=8.320, rec=0.057), tot_loss_proj:1.752 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.719 (perp=8.320, rec=0.055), tot_loss_proj:1.756 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.725 (perp=8.320, rec=0.061), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.738 (perp=8.320, rec=0.074), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.741 (perp=8.320, rec=0.077), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.711 (perp=8.320, rec=0.047), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.732 (perp=8.320, rec=0.068), tot_loss_proj:1.748 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.720 (perp=8.320, rec=0.056), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.723 (perp=8.320, rec=0.059), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.729 (perp=8.320, rec=0.065), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.715 (perp=8.320, rec=0.051), tot_loss_proj:1.750 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.723 (perp=8.320, rec=0.059), tot_loss_proj:1.741 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.720 (perp=8.320, rec=0.056), tot_loss_proj:1.748 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.726 (perp=8.320, rec=0.062), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.718 (perp=8.320, rec=0.054), tot_loss_proj:1.746 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.717 (perp=8.320, rec=0.053), tot_loss_proj:1.733 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.733 (perp=8.320, rec=0.069), tot_loss_proj:1.728 [t=0.34s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.720 (perp=8.320, rec=0.056), tot_loss_proj:1.752 [t=0.32s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.735 (perp=8.320, rec=0.071), tot_loss_proj:1.755 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.717 (perp=8.320, rec=0.053), tot_loss_proj:1.752 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.730 (perp=8.320, rec=0.066), tot_loss_proj:1.748 [t=0.34s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.708 (perp=8.320, rec=0.044), tot_loss_proj:1.757 [t=0.35s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.709 (perp=8.320, rec=0.045), tot_loss_proj:1.738 [t=0.31s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.750 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.716 (perp=8.320, rec=0.052), tot_loss_proj:1.742 [t=0.32s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.736 (perp=8.320, rec=0.072), tot_loss_proj:1.738 [t=0.32s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.718 (perp=8.320, rec=0.054), tot_loss_proj:1.750 [t=0.37s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.734 (perp=8.320, rec=0.070), tot_loss_proj:1.744 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.726 (perp=8.320, rec=0.062), tot_loss_proj:1.747 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.722 (perp=8.320, rec=0.058), tot_loss_proj:1.752 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.723 (perp=8.320, rec=0.059), tot_loss_proj:1.745 [t=0.33s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.721 (perp=8.320, rec=0.057), tot_loss_proj:1.748 [t=0.39s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.732 (perp=8.320, rec=0.068), tot_loss_proj:1.747 [t=0.34s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.728 (perp=8.320, rec=0.064), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.517 | p: 85.562 | r: 87.559
rouge2     | fm: 49.007 | p: 48.827 | r: 49.177
rougeL     | fm: 75.894 | p: 75.054 | r: 76.772
rougeLsum  | fm: 75.384 | p: 74.571 | r: 76.382
r1fm+r2fm = 135.525

input #27 time: 0:11:45 | total time: 5:12:32


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
cosin similarity: -0.8963603353465541 normalized error: 1.734303904161745
cosin similarity: 0.8963603353465541 normalized error: 0.5019644046112567
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8342882990837097 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8243166208267212 for ['[CLS] boundaries towards lands delivery [SEP]']
[Init] best rec loss: 0.8236411809921265 for ['[CLS] lake abd master landing [SEP]']
[Init] best rec loss: 0.7971720099449158 for ['[CLS] athletic type m3 number [SEP]']
[Init] best rec loss: 0.7839605808258057 for ['[CLS] full zero broodachal [SEP]']
[Init] best rec loss: 0.7793408632278442 for ['[CLS] immortal coma thierry imperial [SEP]']
[Init] best rec loss: 0.7606765627861023 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best perm rec loss: 0.7543970346450806 for ['[CLS] mixed battlefield fullyuro [SEP]']
[Init] best perm rec loss: 0.7540392875671387 for ['[CLS] battlefield fullyuro mixed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.949 (perp=8.619, rec=0.225), tot_loss_proj:2.334 [t=0.28s]
prediction: ['[CLS] minutes for short minutes [SEP]']
[ 100/2000] tot_loss=2.145 (perp=10.133, rec=0.118), tot_loss_proj:2.481 [t=0.28s]
prediction: ['[CLS] 71 for only minutes [SEP]']
[ 150/2000] tot_loss=2.099 (perp=10.133, rec=0.072), tot_loss_proj:2.486 [t=0.25s]
prediction: ['[CLS] 71 for only minutes [SEP]']
[ 200/2000] tot_loss=2.103 (perp=10.133, rec=0.076), tot_loss_proj:2.490 [t=0.27s]
prediction: ['[CLS] 71 for only minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.602 (perp=7.699, rec=0.062), tot_loss_proj:1.615 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 300/2000] tot_loss=1.590 (perp=7.699, rec=0.051), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.589 (perp=7.699, rec=0.049), tot_loss_proj:1.614 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.604 (perp=7.699, rec=0.064), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.581 (perp=7.699, rec=0.041), tot_loss_proj:1.622 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.589 (perp=7.699, rec=0.050), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.598 (perp=7.699, rec=0.058), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.699, rec=0.055), tot_loss_proj:1.619 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.607 (perp=7.699, rec=0.068), tot_loss_proj:1.622 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.611 (perp=7.699, rec=0.071), tot_loss_proj:1.608 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.596 (perp=7.699, rec=0.056), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.601 (perp=7.699, rec=0.062), tot_loss_proj:1.619 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.598 (perp=7.699, rec=0.059), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.594 (perp=7.699, rec=0.054), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.580 (perp=7.699, rec=0.040), tot_loss_proj:1.619 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.618 (perp=7.699, rec=0.078), tot_loss_proj:1.606 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.606 (perp=7.699, rec=0.066), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.612 (perp=7.699, rec=0.073), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.603 (perp=7.699, rec=0.064), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.596 (perp=7.699, rec=0.056), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.610 (perp=7.699, rec=0.070), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.594 (perp=7.699, rec=0.055), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.699, rec=0.048), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.699, rec=0.058), tot_loss_proj:1.610 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.699, rec=0.062), tot_loss_proj:1.605 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.699, rec=0.060), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.594 (perp=7.699, rec=0.054), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.598 (perp=7.699, rec=0.059), tot_loss_proj:1.616 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.602 (perp=7.699, rec=0.062), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.601 (perp=7.699, rec=0.062), tot_loss_proj:1.607 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.594 (perp=7.699, rec=0.054), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.608 (perp=7.699, rec=0.069), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.589 (perp=7.699, rec=0.049), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.605 (perp=7.699, rec=0.065), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.597 (perp=7.699, rec=0.058), tot_loss_proj:1.616 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.594 (perp=7.699, rec=0.055), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.851 | p: 85.926 | r: 87.975
rouge2     | fm: 50.841 | p: 50.680 | r: 51.011
rougeL     | fm: 76.681 | p: 75.992 | r: 77.528
rougeLsum  | fm: 76.138 | p: 75.418 | r: 77.086
r1fm+r2fm = 137.693

input #28 time: 0:11:08 | total time: 5:23:40


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
cosin similarity: 0.8935402273098988 normalized error: 0.5132934698956766
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8969075679779053 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8934383988380432 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8905164003372192 for ['[CLS] witness gould resonance debt porte of localure elliptic last [SEP]']
[Init] best rec loss: 0.8865633010864258 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8741384744644165 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 0.8301542401313782 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.805610179901123 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 0.7979037165641785 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 0.7851349711418152 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.7848773002624512 for ['[CLS] ufounded meters mostly cells axle bu transmit f veto [SEP]']
[Init] best perm rec loss: 0.7844664454460144 for ['[CLS]founded bu u cells mostly veto f meters axle transmit [SEP]']
[Init] best perm rec loss: 0.783543586730957 for ['[CLS] bu transmit cells meters veto mostlyfounded u f axle [SEP]']
[Init] best perm rec loss: 0.7820736765861511 for ['[CLS] veto transmit bu f axle cells u mostlyfounded meters [SEP]']
[Init] best perm rec loss: 0.781797468662262 for ['[CLS]founded transmit mostly veto cells f meters axle bu u [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.224 (perp=9.499, rec=0.324), tot_loss_proj:2.683 [t=0.26s]
prediction: ['[CLS] not indeed imagine believe you especially is it seminary not [SEP]']
[ 100/2000] tot_loss=1.859 (perp=8.475, rec=0.164), tot_loss_proj:2.554 [t=0.27s]
prediction: ['[CLS] not evil believe believe that also resident is it not [SEP]']
[ 150/2000] tot_loss=1.848 (perp=8.633, rec=0.122), tot_loss_proj:2.405 [t=0.25s]
prediction: ['[CLS] we evil resident believe that also resident is it not [SEP]']
[ 200/2000] tot_loss=1.637 (perp=7.734, rec=0.090), tot_loss_proj:2.259 [t=0.26s]
prediction: ['[CLS] i evil i believe that also resident is it not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.539 (perp=7.290, rec=0.081), tot_loss_proj:2.186 [t=0.26s]
prediction: ['[CLS] we also i believe that evil resident is it not [SEP]']
[ 300/2000] tot_loss=1.533 (perp=7.290, rec=0.074), tot_loss_proj:2.188 [t=0.25s]
prediction: ['[CLS] we also i believe that evil resident is it not [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.306 (perp=6.172, rec=0.071), tot_loss_proj:1.939 [t=0.26s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.314 (perp=6.172, rec=0.079), tot_loss_proj:1.940 [t=0.30s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
[ 450/2000] tot_loss=1.311 (perp=6.172, rec=0.076), tot_loss_proj:1.940 [t=0.31s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.309 (perp=6.172, rec=0.075), tot_loss_proj:1.938 [t=0.34s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.310 (perp=6.172, rec=0.075), tot_loss_proj:1.940 [t=0.37s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
[ 600/2000] tot_loss=1.305 (perp=6.172, rec=0.071), tot_loss_proj:1.944 [t=0.29s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.307 (perp=6.172, rec=0.073), tot_loss_proj:1.945 [t=0.43s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.302 (perp=6.172, rec=0.068), tot_loss_proj:1.942 [t=0.28s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
[ 750/2000] tot_loss=1.308 (perp=6.172, rec=0.073), tot_loss_proj:1.947 [t=0.28s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.307 (perp=6.172, rec=0.073), tot_loss_proj:1.946 [t=0.29s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.309 (perp=6.172, rec=0.075), tot_loss_proj:1.940 [t=0.29s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
[ 900/2000] tot_loss=1.312 (perp=6.172, rec=0.078), tot_loss_proj:1.937 [t=0.31s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.311 (perp=6.172, rec=0.076), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.308 (perp=6.172, rec=0.073), tot_loss_proj:1.950 [t=0.37s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
[1050/2000] tot_loss=1.304 (perp=6.172, rec=0.070), tot_loss_proj:1.942 [t=0.31s]
prediction: ['[CLS] we also i believe that resident evil is it not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.292 (perp=6.104, rec=0.071), tot_loss_proj:1.889 [t=0.39s]
prediction: ['[CLS]. also i believe that resident evil is it not [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.207 (perp=5.616, rec=0.084), tot_loss_proj:1.750 [t=0.34s]
prediction: ['[CLS]. i also believe that resident evil is it not [SEP]']
[1200/2000] tot_loss=1.200 (perp=5.616, rec=0.077), tot_loss_proj:1.757 [t=0.31s]
prediction: ['[CLS]. i also believe that resident evil is it not [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.145 (perp=5.331, rec=0.079), tot_loss_proj:1.740 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.147 (perp=5.331, rec=0.080), tot_loss_proj:1.746 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[1350/2000] tot_loss=1.143 (perp=5.331, rec=0.077), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.138 (perp=5.331, rec=0.071), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.135 (perp=5.331, rec=0.069), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[1500/2000] tot_loss=1.144 (perp=5.331, rec=0.078), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.145 (perp=5.331, rec=0.079), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.143 (perp=5.331, rec=0.077), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[1650/2000] tot_loss=1.137 (perp=5.331, rec=0.071), tot_loss_proj:1.740 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.131 (perp=5.331, rec=0.065), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.060 (perp=4.884, rec=0.083), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1800/2000] tot_loss=1.054 (perp=4.884, rec=0.078), tot_loss_proj:1.513 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.058 (perp=4.884, rec=0.081), tot_loss_proj:1.513 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.060 (perp=4.884, rec=0.084), tot_loss_proj:1.508 [t=0.28s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1950/2000] tot_loss=1.050 (perp=4.884, rec=0.073), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.884, rec=0.077), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil. is it not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 87.304 | p: 86.476 | r: 88.374
rouge2     | fm: 51.742 | p: 51.636 | r: 51.780
rougeL     | fm: 77.294 | p: 76.618 | r: 78.185
rougeLsum  | fm: 76.775 | p: 76.068 | r: 77.752
r1fm+r2fm = 139.046

input #29 time: 0:11:45 | total time: 5:35:26


Running input #30 of 100.
reference: 
========================
fizzability 
========================
cosin similarity: -0.7819535962479063 normalized error: 1.6731907553169267
cosin similarity: 0.7819535962479063 normalized error: 0.5738673088944698
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9207770228385925 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.7793105840682983 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7627937197685242 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7625120878219604 for ['[CLS] laws gp. [SEP]']
[Init] best rec loss: 0.7374953031539917 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 0.7038500308990479 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.676681637763977 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.6746949553489685 for ['[CLS] lizard acceleration council [SEP]']
[Init] best perm rec loss: 0.6745884418487549 for ['[CLS] council lizard acceleration [SEP]']
[Init] best perm rec loss: 0.670194685459137 for ['[CLS] acceleration lizard council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.744 (perp=12.475, rec=0.249), tot_loss_proj:3.000 [t=0.27s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 100/2000] tot_loss=2.398 (perp=11.223, rec=0.154), tot_loss_proj:2.656 [t=0.27s]
prediction: ['[CLS]zzazzability [SEP]']
[ 150/2000] tot_loss=1.989 (perp=9.539, rec=0.081), tot_loss_proj:1.984 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=1.985 (perp=9.539, rec=0.077), tot_loss_proj:1.979 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.978 (perp=9.539, rec=0.070), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.539, rec=0.060), tot_loss_proj:1.971 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.967 (perp=9.539, rec=0.059), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.951 (perp=9.539, rec=0.043), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.963 (perp=9.539, rec=0.055), tot_loss_proj:1.978 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.978 (perp=9.539, rec=0.071), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=9.539, rec=0.065), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.955 (perp=9.539, rec=0.047), tot_loss_proj:1.988 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.969 (perp=9.539, rec=0.061), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.981 (perp=9.539, rec=0.074), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.964 (perp=9.539, rec=0.056), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.962 (perp=9.539, rec=0.054), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.968 (perp=9.539, rec=0.060), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.966 (perp=9.539, rec=0.058), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.961 (perp=9.539, rec=0.053), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.962 (perp=9.539, rec=0.054), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.952 (perp=9.539, rec=0.044), tot_loss_proj:1.986 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.981 (perp=9.539, rec=0.073), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.966 (perp=9.539, rec=0.058), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.975 (perp=9.539, rec=0.068), tot_loss_proj:1.985 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.971 (perp=9.539, rec=0.063), tot_loss_proj:1.979 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.976 (perp=9.539, rec=0.068), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.976 (perp=9.539, rec=0.068), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.977 (perp=9.539, rec=0.070), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.980 (perp=9.539, rec=0.072), tot_loss_proj:1.977 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.979 (perp=9.539, rec=0.071), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.972 (perp=9.539, rec=0.064), tot_loss_proj:1.981 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.972 (perp=9.539, rec=0.064), tot_loss_proj:1.982 [t=0.34s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.963 (perp=9.539, rec=0.055), tot_loss_proj:1.972 [t=0.38s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.973 (perp=9.539, rec=0.065), tot_loss_proj:1.979 [t=0.30s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.968 (perp=9.539, rec=0.060), tot_loss_proj:1.978 [t=0.34s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.643 | p: 86.840 | r: 88.732
rouge2     | fm: 53.172 | p: 53.030 | r: 53.322
rougeL     | fm: 77.996 | p: 77.323 | r: 78.808
rougeLsum  | fm: 77.370 | p: 76.670 | r: 78.246
r1fm+r2fm = 140.815

input #30 time: 0:11:10 | total time: 5:46:36


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
cosin similarity: 0.8972750712825893 normalized error: 0.5145268960711955
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9974946975708008 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.9556524157524109 for ['[CLS] che episode band [SEP]']
[Init] best rec loss: 0.9520253539085388 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.9408921003341675 for ['[CLS] some mafiabourg [SEP]']
[Init] best rec loss: 0.9357284307479858 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.9331911206245422 for ['[CLS] loser english sicily [SEP]']
[Init] best rec loss: 0.9303955435752869 for ['[CLS] playhouse saxons garde [SEP]']
[Init] best rec loss: 0.9086271524429321 for ['[CLS] comments research campaign [SEP]']
[Init] best rec loss: 0.9013904929161072 for ['[CLS] favour profile anyway [SEP]']
[Init] best rec loss: 0.9005585312843323 for ['[CLS] toe thin... [SEP]']
[Init] best rec loss: 0.8927534818649292 for ['[CLS]ousricting rang [SEP]']
[Init] best rec loss: 0.8848918676376343 for ['[CLS] while caribbean ups [SEP]']
[Init] best perm rec loss: 0.8841394782066345 for ['[CLS] caribbean while ups [SEP]']
[Init] best perm rec loss: 0.8832005858421326 for ['[CLS] caribbean ups while [SEP]']
[Init] best perm rec loss: 0.8827286958694458 for ['[CLS] while ups caribbean [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.475 (perp=10.294, rec=0.417), tot_loss_proj:2.903 [t=0.28s]
prediction: ['[CLS] better newer vehicle [SEP]']
[ 100/2000] tot_loss=2.113 (perp=9.604, rec=0.193), tot_loss_proj:2.468 [t=0.30s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 150/2000] tot_loss=2.065 (perp=9.604, rec=0.144), tot_loss_proj:2.455 [t=0.26s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 200/2000] tot_loss=2.068 (perp=9.604, rec=0.147), tot_loss_proj:2.456 [t=0.25s]
prediction: ['[CLS] better better vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.841 (perp=8.581, rec=0.125), tot_loss_proj:2.342 [t=0.25s]
prediction: ['[CLS] another better vehicle [SEP]']
[ 300/2000] tot_loss=1.612 (perp=7.603, rec=0.092), tot_loss_proj:1.673 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.610 (perp=7.603, rec=0.090), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.583 (perp=7.603, rec=0.063), tot_loss_proj:1.682 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.573 (perp=7.603, rec=0.052), tot_loss_proj:1.689 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.579 (perp=7.603, rec=0.058), tot_loss_proj:1.693 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.579 (perp=7.603, rec=0.059), tot_loss_proj:1.687 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.580 (perp=7.603, rec=0.059), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.585 (perp=7.603, rec=0.064), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.586 (perp=7.603, rec=0.065), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.589 (perp=7.603, rec=0.069), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.585 (perp=7.603, rec=0.064), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.588 (perp=7.603, rec=0.068), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.578 (perp=7.603, rec=0.058), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.577 (perp=7.603, rec=0.057), tot_loss_proj:1.682 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.574 (perp=7.603, rec=0.054), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.589 (perp=7.603, rec=0.069), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=7.603, rec=0.054), tot_loss_proj:1.687 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.580 (perp=7.603, rec=0.059), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.575 (perp=7.603, rec=0.054), tot_loss_proj:1.683 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.575 (perp=7.603, rec=0.054), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.578 (perp=7.603, rec=0.058), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.576 (perp=7.603, rec=0.055), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.594 (perp=7.603, rec=0.073), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.583 (perp=7.603, rec=0.062), tot_loss_proj:1.693 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.603, rec=0.064), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.591 (perp=7.603, rec=0.070), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.603, rec=0.052), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.603, rec=0.065), tot_loss_proj:1.685 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.579 (perp=7.603, rec=0.058), tot_loss_proj:1.696 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.582 (perp=7.603, rec=0.061), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.578 (perp=7.603, rec=0.057), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.580 (perp=7.603, rec=0.060), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.581 (perp=7.603, rec=0.061), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.590 (perp=7.603, rec=0.070), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.580 (perp=7.603, rec=0.059), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.138 | p: 87.308 | r: 89.132
rouge2     | fm: 54.614 | p: 54.494 | r: 54.773
rougeL     | fm: 78.614 | p: 77.966 | r: 79.488
rougeLsum  | fm: 78.416 | p: 77.693 | r: 79.291
r1fm+r2fm = 142.752

input #31 time: 0:11:06 | total time: 5:57:43


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
cosin similarity: 0.9540072499327329 normalized error: 0.4076547528751486
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9472867846488953 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9454873204231262 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.9376259446144104 for ['[CLS] lord designers voice det 01 sec see check entirely arch spiral youth [SEP]']
[Init] best rec loss: 0.9178409576416016 for ['[CLS] actver⋅ bond dimebruck nocus " happy california marine [SEP]']
[Init] best rec loss: 0.9105584621429443 for ['[CLS] voyage khmerו existing else as enigma vapor most belgarath willing aurora [SEP]']
[Init] best rec loss: 0.9105017781257629 for ['[CLS] wishing period othertown silver cell languageator southwestgraph james louis [SEP]']
[Init] best rec loss: 0.9077782034873962 for ['[CLS] jax nerve tipiver theater aside watch friend higher would linear appearing [SEP]']
[Init] best rec loss: 0.8919404149055481 for ['[CLS] di round even career rome away buddha athena seatsation brigadier speed [SEP]']
[Init] best rec loss: 0.867600679397583 for ['[CLS] particular usual lana rid part awaitfication felt worked bolt algorithm tristan [SEP]']
[Init] best rec loss: 0.8674671649932861 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8674428462982178 for ['[CLS] let forth mud gods lips inclination airport unanimous baptism alongside between ″ [SEP]']
[Init] best perm rec loss: 0.8665698766708374 for ['[CLS] mud let gods alongside forth airport between unanimous inclination lips baptism ″ [SEP]']
[Init] best perm rec loss: 0.8649026155471802 for ['[CLS] forth between let ″ mud gods lips baptism unanimous alongside inclination airport [SEP]']
[Init] best perm rec loss: 0.8623632788658142 for ['[CLS] ″ airport gods unanimous forth lips baptism between alongside mud let inclination [SEP]']
[Init] best perm rec loss: 0.861396849155426 for ['[CLS] unanimous gods mud let inclination airport lips between baptism ″ forth alongside [SEP]']
[Init] best perm rec loss: 0.8612459897994995 for ['[CLS] gods unanimous airport ″ let mud between lips inclination forth alongside baptism [SEP]']
[Init] best perm rec loss: 0.8602272868156433 for ['[CLS] inclination unanimous airport mud lips between ″ forth gods let baptism alongside [SEP]']
[Init] best perm rec loss: 0.8590973615646362 for ['[CLS] airport let ″ inclination forth between mud gods unanimous lips baptism alongside [SEP]']
[Init] best perm rec loss: 0.8590601682662964 for ['[CLS] forth airport unanimous mud lips inclination gods baptism between let ″ alongside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.230 (perp=14.449, rec=0.340), tot_loss_proj:3.586 [t=0.26s]
prediction: ['[CLS] forth archbishop warmth into riders manage format fully added puckuga focus [SEP]']
[ 100/2000] tot_loss=2.653 (perp=11.958, rec=0.261), tot_loss_proj:3.081 [t=0.25s]
prediction: ['[CLS] create easily easily online accessible pull stories fully easilyfest yourselfonate [SEP]']
[ 150/2000] tot_loss=2.900 (perp=13.457, rec=0.209), tot_loss_proj:3.282 [t=0.26s]
prediction: ['[CLS] create presley easily together accessible pull storiesonate easilyonate pullonate [SEP]']
[ 200/2000] tot_loss=2.912 (perp=13.636, rec=0.185), tot_loss_proj:3.343 [t=0.25s]
prediction: ['[CLS] pull presley easily together accessible pull storiesonate easilyonate pullonate [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.697 (perp=12.556, rec=0.186), tot_loss_proj:3.100 [t=0.25s]
prediction: ['[CLS] pull ellison easily pull together accessible storiesonate easilyonateonateonate [SEP]']
[ 300/2000] tot_loss=2.670 (perp=12.598, rec=0.150), tot_loss_proj:3.183 [t=0.26s]
prediction: ['[CLS] pullcased easily pull together accessible storiesonate easilyundonateonate [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.511 (perp=11.913, rec=0.128), tot_loss_proj:3.081 [t=0.25s]
prediction: ['[CLS] pull 河 with pull together accessible stories easilyonateund linkonate [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.379 (perp=11.222, rec=0.134), tot_loss_proj:3.088 [t=0.25s]
prediction: ['[CLS] pullplaced easily pull together accessible stories withonateund linkity [SEP]']
[ 450/2000] tot_loss=2.305 (perp=10.937, rec=0.118), tot_loss_proj:2.886 [t=0.25s]
prediction: ['[CLS] res 河 easily pull together accessible stories withonateund linkity [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.435 (perp=11.540, rec=0.127), tot_loss_proj:3.326 [t=0.25s]
prediction: ['[CLS] resplaced easily pull together accessible storiesplify withonateundity [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.286 (perp=10.891, rec=0.108), tot_loss_proj:3.210 [t=0.28s]
prediction: ['[CLS] resplaced easily pull together flex accessible stories withonateundity [SEP]']
[ 600/2000] tot_loss=2.081 (perp=9.814, rec=0.118), tot_loss_proj:2.536 [t=0.25s]
prediction: ['[CLS] restures easily pull together flex accessible stories withonateundity [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.988 (perp=9.349, rec=0.119), tot_loss_proj:2.295 [t=0.26s]
prediction: ['[CLS] resonatetures easily pull togetherines accessible stories withundity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.981 (perp=9.349, rec=0.112), tot_loss_proj:2.295 [t=0.25s]
prediction: ['[CLS] resonatetures easily pull togetherines accessible stories withundity [SEP]']
[ 750/2000] tot_loss=1.981 (perp=9.349, rec=0.111), tot_loss_proj:2.301 [t=0.25s]
prediction: ['[CLS] resonatetures easily pull togetherines accessible stories withundity [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.131 (perp=10.094, rec=0.112), tot_loss_proj:2.566 [t=0.25s]
prediction: ['[CLS] profonatetures easily pullines together accessible stories withundity [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.177 (perp=10.327, rec=0.112), tot_loss_proj:2.562 [t=0.25s]
prediction: ['[CLS] profines chapman easily pullonate together accessible stories withundity [SEP]']
[ 900/2000] tot_loss=2.242 (perp=10.664, rec=0.109), tot_loss_proj:2.681 [t=0.27s]
prediction: ['[CLS] prof priced chapman easily pullonate together accessible stories withundity [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.191 (perp=10.413, rec=0.108), tot_loss_proj:2.728 [t=0.25s]
prediction: ['[CLS] prof priced chapman easily pull stories together accessibleonate withundity [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.119 (perp=9.999, rec=0.119), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] with priced chapman easily pull stories together accessibleonate profundity [SEP]']
[1050/2000] tot_loss=2.112 (perp=9.999, rec=0.112), tot_loss_proj:2.525 [t=0.27s]
prediction: ['[CLS] with priced chapman easily pull stories together accessibleonate profundity [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.976 (perp=9.362, rec=0.104), tot_loss_proj:2.357 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.977 (perp=9.362, rec=0.104), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
[1200/2000] tot_loss=1.973 (perp=9.362, rec=0.101), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.976 (perp=9.362, rec=0.104), tot_loss_proj:2.354 [t=0.27s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.982 (perp=9.362, rec=0.109), tot_loss_proj:2.350 [t=0.31s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
[1350/2000] tot_loss=1.973 (perp=9.362, rec=0.101), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.973 (perp=9.362, rec=0.101), tot_loss_proj:2.353 [t=0.32s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.972 (perp=9.362, rec=0.100), tot_loss_proj:2.353 [t=0.28s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
[1500/2000] tot_loss=1.967 (perp=9.362, rec=0.095), tot_loss_proj:2.351 [t=0.30s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.971 (perp=9.362, rec=0.099), tot_loss_proj:2.353 [t=0.30s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.971 (perp=9.362, rec=0.099), tot_loss_proj:2.349 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
[1650/2000] tot_loss=1.967 (perp=9.362, rec=0.095), tot_loss_proj:2.350 [t=0.28s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.976 (perp=9.362, rec=0.103), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.963 (perp=9.362, rec=0.091), tot_loss_proj:2.352 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
[1800/2000] tot_loss=1.966 (perp=9.362, rec=0.094), tot_loss_proj:2.349 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.971 (perp=9.362, rec=0.099), tot_loss_proj:2.349 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.975 (perp=9.362, rec=0.103), tot_loss_proj:2.346 [t=0.27s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
[1950/2000] tot_loss=1.981 (perp=9.362, rec=0.109), tot_loss_proj:2.351 [t=0.26s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.977 (perp=9.362, rec=0.104), tot_loss_proj:2.345 [t=0.27s]
prediction: ['[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] withonate chapman easily pull stories together accessible priced profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 82.727

[Aggregate metrics]:
rouge1     | fm: 87.627 | p: 86.851 | r: 88.603
rouge2     | fm: 53.258 | p: 53.150 | r: 53.427
rougeL     | fm: 77.734 | p: 77.132 | r: 78.492
rougeLsum  | fm: 77.612 | p: 77.083 | r: 78.359
r1fm+r2fm = 140.886

input #32 time: 0:11:08 | total time: 6:08:51


Running input #33 of 100.
reference: 
========================
higher 
========================
cosin similarity: 0.7986250644135383 normalized error: 0.5468308574685831
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9893083572387695 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9107549786567688 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8910643458366394 for ['[CLS] bar [SEP]']
[Init] best rec loss: 0.8839766383171082 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.8669291734695435 for ['[CLS] charged [SEP]']
[Init] best rec loss: 0.8415970206260681 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.8240987062454224 for ['[CLS] higher [SEP]']
[Init] best rec loss: 0.8214564919471741 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7940399646759033 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7562564015388489 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.7383552193641663 for ['[CLS] states [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.341 (perp=11.231, rec=0.095), tot_loss_proj:2.644 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.311 (perp=11.231, rec=0.065), tot_loss_proj:2.508 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.314 (perp=11.231, rec=0.068), tot_loss_proj:2.479 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.310 (perp=11.231, rec=0.063), tot_loss_proj:2.507 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.481 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.290 (perp=11.231, rec=0.044), tot_loss_proj:2.488 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=11.231, rec=0.059), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.320 (perp=11.231, rec=0.074), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.297 (perp=11.231, rec=0.051), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.301 (perp=11.231, rec=0.055), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.316 (perp=11.231, rec=0.069), tot_loss_proj:2.477 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.314 (perp=11.231, rec=0.068), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.316 (perp=11.231, rec=0.069), tot_loss_proj:2.485 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.310 (perp=11.231, rec=0.064), tot_loss_proj:2.480 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.303 (perp=11.231, rec=0.056), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.300 (perp=11.231, rec=0.053), tot_loss_proj:2.481 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.296 (perp=11.231, rec=0.050), tot_loss_proj:2.494 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.292 (perp=11.231, rec=0.046), tot_loss_proj:2.493 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.309 (perp=11.231, rec=0.063), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.290 (perp=11.231, rec=0.044), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.294 (perp=11.231, rec=0.048), tot_loss_proj:2.488 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.475 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.311 (perp=11.231, rec=0.065), tot_loss_proj:2.483 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.295 (perp=11.231, rec=0.049), tot_loss_proj:2.470 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.306 (perp=11.231, rec=0.060), tot_loss_proj:2.493 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.305 (perp=11.231, rec=0.059), tot_loss_proj:2.482 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.298 (perp=11.231, rec=0.052), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.318 (perp=11.231, rec=0.072), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.318 (perp=11.231, rec=0.072), tot_loss_proj:2.483 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.304 (perp=11.231, rec=0.058), tot_loss_proj:2.491 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.293 (perp=11.231, rec=0.047), tot_loss_proj:2.486 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.292 (perp=11.231, rec=0.046), tot_loss_proj:2.490 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.492 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.303 (perp=11.231, rec=0.057), tot_loss_proj:2.476 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.302 (perp=11.231, rec=0.056), tot_loss_proj:2.485 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.319 (perp=11.231, rec=0.073), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.307 (perp=11.231, rec=0.061), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.308 (perp=11.231, rec=0.062), tot_loss_proj:2.493 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.301 (perp=11.231, rec=0.055), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.303 (perp=11.231, rec=0.057), tot_loss_proj:2.480 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.960 | p: 87.142 | r: 88.833
rouge2     | fm: 54.704 | p: 54.607 | r: 54.881
rougeL     | fm: 78.488 | p: 77.849 | r: 79.342
rougeLsum  | fm: 78.342 | p: 77.746 | r: 79.052
r1fm+r2fm = 142.664

input #33 time: 0:11:00 | total time: 6:19:52


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
cosin similarity: 0.8932598797628633 normalized error: 0.4609634765779029
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8985891342163086 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8732905387878418 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8665227293968201 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8396279215812683 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.8279643654823303 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best rec loss: 0.8156946301460266 for ['[CLS] learn trading pontifical levels louvre dave qaedafilmfy took cadets constant lawyers [SEP]']
[Init] best perm rec loss: 0.812947690486908 for ['[CLS] tookfy levels constant qaeda pontifical trading cadets dave learn louvrefilm lawyers [SEP]']
[Init] best perm rec loss: 0.8104835152626038 for ['[CLS] dave lawyers constant qaeda tradingfilm cadets pontifical took learnfy louvre levels [SEP]']
[Init] best perm rec loss: 0.8103250861167908 for ['[CLS]film lawyers dave levels cadets took qaeda learn louvrefy constant trading pontifical [SEP]']
[Init] best perm rec loss: 0.8094421029090881 for ['[CLS] learn levels took trading pontifical qaedafilm cadets dave lawyersfy constant louvre [SEP]']
[Init] best perm rec loss: 0.8076161742210388 for ['[CLS] lawyers levels davefy qaedafilm pontifical learn constant trading took louvre cadets [SEP]']
[Init] best perm rec loss: 0.80738765001297 for ['[CLS] louvre lawyers qaeda learn took trading constant cadets dave levels pontificalfilmfy [SEP]']
[Init] best perm rec loss: 0.8068898320198059 for ['[CLS] took constantfy cadets dave qaeda tradingfilm lawyers pontifical learn louvre levels [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.421 (perp=10.768, rec=0.268), tot_loss_proj:2.880 [t=0.25s]
prediction: ['[CLS] urgencydown into the recording visual ; extreme stride into existing images urgency [SEP]']
[ 100/2000] tot_loss=1.930 (perp=8.570, rec=0.217), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] urgency build an audience into extreme and extreme stride take the viewer urgency [SEP]']
[ 150/2000] tot_loss=2.079 (perp=9.792, rec=0.121), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] urgency build any the in mind and extreme stride take the viewer urgency [SEP]']
[ 200/2000] tot_loss=1.909 (perp=9.038, rec=0.101), tot_loss_proj:2.356 [t=0.26s]
prediction: ['[CLS] urgency build an the in mind and extreme mind take the viewer urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.663 (perp=7.837, rec=0.095), tot_loss_proj:2.096 [t=0.27s]
prediction: ['[CLS] urgency build on in of mind and extreme mind take the viewer urgency [SEP]']
[ 300/2000] tot_loss=1.657 (perp=7.837, rec=0.089), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] urgency build on in of mind and extreme mind take the viewer urgency [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.437 (perp=6.718, rec=0.093), tot_loss_proj:1.819 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and mind take the viewer urgency [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.522 (perp=7.167, rec=0.089), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] extreme build build on in the mind and mind take the viewer urgency [SEP]']
[ 450/2000] tot_loss=1.510 (perp=7.167, rec=0.076), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] extreme build build on in the mind and mind take the viewer urgency [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.510 (perp=7.128, rec=0.085), tot_loss_proj:1.913 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and. take the viewer urgency [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.284 (perp=6.011, rec=0.082), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[ 600/2000] tot_loss=1.286 (perp=6.011, rec=0.084), tot_loss_proj:1.626 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.282 (perp=6.011, rec=0.080), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.279 (perp=6.011, rec=0.077), tot_loss_proj:1.627 [t=0.27s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[ 750/2000] tot_loss=1.278 (perp=6.011, rec=0.075), tot_loss_proj:1.628 [t=0.30s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.271 (perp=6.011, rec=0.069), tot_loss_proj:1.628 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.263 (perp=6.011, rec=0.061), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[ 900/2000] tot_loss=1.273 (perp=6.011, rec=0.071), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.265 (perp=6.011, rec=0.063), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.265 (perp=6.011, rec=0.063), tot_loss_proj:1.630 [t=0.28s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1050/2000] tot_loss=1.275 (perp=6.011, rec=0.073), tot_loss_proj:1.622 [t=0.27s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.272 (perp=6.011, rec=0.070), tot_loss_proj:1.632 [t=0.29s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.270 (perp=6.011, rec=0.068), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1200/2000] tot_loss=1.270 (perp=6.011, rec=0.067), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.260 (perp=6.011, rec=0.058), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.271 (perp=6.011, rec=0.068), tot_loss_proj:1.627 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1350/2000] tot_loss=1.267 (perp=6.011, rec=0.065), tot_loss_proj:1.629 [t=0.28s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.271 (perp=6.011, rec=0.069), tot_loss_proj:1.630 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.273 (perp=6.011, rec=0.071), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1500/2000] tot_loss=1.275 (perp=6.011, rec=0.073), tot_loss_proj:1.634 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.264 (perp=6.011, rec=0.061), tot_loss_proj:1.628 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.270 (perp=6.011, rec=0.067), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1650/2000] tot_loss=1.278 (perp=6.011, rec=0.076), tot_loss_proj:1.631 [t=0.27s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.260 (perp=6.011, rec=0.058), tot_loss_proj:1.633 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.281 (perp=6.011, rec=0.079), tot_loss_proj:1.626 [t=0.27s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1800/2000] tot_loss=1.262 (perp=6.011, rec=0.060), tot_loss_proj:1.630 [t=0.28s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.266 (perp=6.011, rec=0.064), tot_loss_proj:1.633 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.266 (perp=6.011, rec=0.064), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
[1950/2000] tot_loss=1.280 (perp=6.011, rec=0.077), tot_loss_proj:1.634 [t=0.26s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.262 (perp=6.011, rec=0.060), tot_loss_proj:1.623 [t=0.27s]
prediction: ['[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] extreme urgency build on in the mind and take the viewer urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 92.857 | r: 92.857
rouge2     | fm: 46.154 | p: 46.154 | r: 46.154
rougeL     | fm: 64.286 | p: 64.286 | r: 64.286
rougeLsum  | fm: 64.286 | p: 64.286 | r: 64.286
r1fm+r2fm = 139.011

[Aggregate metrics]:
rouge1     | fm: 88.102 | p: 87.480 | r: 88.995
rouge2     | fm: 54.483 | p: 54.356 | r: 54.596
rougeL     | fm: 77.989 | p: 77.361 | r: 78.716
rougeLsum  | fm: 77.807 | p: 77.172 | r: 78.624
r1fm+r2fm = 142.585

input #34 time: 0:11:05 | total time: 6:30:57


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
cosin similarity: -0.9503733723742178 normalized error: 1.8923842993852011
cosin similarity: 0.9503733723742178 normalized error: 0.4112299561920301
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9167530536651611 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8966804146766663 for ['[CLS]end title seasons saysbib castle terror hand dear gu source woodland sport sheriff foughthala displacement plate wandered person spin lips constitution know tv callffed hahnply romeo automobiles door godfrey dearathi named wall why committee must efforts your [SEP]']
[Init] best rec loss: 0.8818689584732056 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.8787881135940552 for ['[CLS] several robert group possible hollyetched lecturewashed slayer news preach bed barren liga fails carterags adopted poppy pilot fen episodesson chair where wed afterrmed boost sp oriented ་ shiierzer almost an margin lifestyle television leader anywhere [SEP]']
[Init] best rec loss: 0.8786954283714294 for ['[CLS] treat selected heal head fair between nationalist lean level isles murmured day now det dark do ground question correct been parked ejected grafος ceiling deployedoir knocked secret comedianbackminated fought learn pre innocent butler speaker qaeda random → playstation [SEP]']
[Init] best rec loss: 0.8690423369407654 for ['[CLS] ya natural dangerously returned cartoon coast clean likely court strauss hall member edge avantoot benefit reserved consider m nana pmid white shayloid master wash andre advantage alone real strength case case cause boom lockedmanship sincefeit extent marvel man [SEP]']
[Init] best rec loss: 0.8637733459472656 for ['[CLS] mi " therefore zev ms hays bun welles start pierce aquino interce specific causedpo normal texas often vocals secretaries themselves magic night court cesar stages achilles excellent fixed shi bertie leg rows plant alwaysch beijing futuretral young wall [SEP]']
[Init] best perm rec loss: 0.8591026067733765 for ['[CLS] start mi plant excellent therefore vocals young magic zev often night caused texas court wall futurepo fixedtral " leg pierce welles always rows bertiece shich ms stages beijing achilles aquino inter bun themselves secretaries specific cesar hays normal [SEP]']
[Init] best perm rec loss: 0.8582074642181396 for ['[CLS] start welles pierce bertie buntral normal wall cesarpo " texas zev aquino fixed vocals oftence excellent futurech plant magic secretaries ms night rows hays young mi achilles specific leg stages beijing court therefore caused inter shi always themselves [SEP]']
[Init] best perm rec loss: 0.858093798160553 for ['[CLS] bertie texas future caused hays magic night beijing secretaries themselves " inter vocals wall often mi rows plant start alwaystral leg therefore courtch excellentce zev shi cesar pierce normal stages fixed specific welles bun aquino achilles mspo young [SEP]']
[Init] best perm rec loss: 0.8565170168876648 for ['[CLS]ce bun aquino court rows future magic shi wall plant " leg vocals bertie secretaries zev cesarpo specific night therefore mi caused young fixed pierce hays always inter stagestral texas often achilles themselves excellent msch beijing normal start welles [SEP]']
[Init] best perm rec loss: 0.8561890125274658 for ['[CLS] always normal cesar bertie rows night young fixed mi shi aquino bun beijing secretarieschce ms walltral inter leg achilles future " hays court pierce excellent vocals magic welles texas themselves start specific often caused zevpo stages plant therefore [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.813 (perp=11.936, rec=0.426), tot_loss_proj:3.080 [t=0.26s]
prediction: ['[CLS] dating region and neighborhood indiana intercept cyrusrac childhood book keeper history structure exactly charity. firmrs bai of profile belly woman " unique good steven beautiful reflecting heritage propertystraße birth hands\'mount heart\'big deeper rec because [SEP]']
[ 100/2000] tot_loss=2.389 (perp=10.177, rec=0.354), tot_loss_proj:2.802 [t=0.27s]
prediction: ["[CLS] our region, reacher almost chorus cyrus seen italy center bulletin historical structure exactly care about with of young the achievements belly'· having good weight great community heritage world care birth hands'province least'a 1930s class. [SEP]"]
[ 150/2000] tot_loss=2.396 (perp=10.504, rec=0.295), tot_loss_proj:2.877 [t=0.26s]
prediction: ["[CLS] our., lindsey almost chorusnation seen italy lives advisor ( work exactly care about with of latest several achievements june'makes but good command great communitynation our carenation turning'congregation seen'a whom teacher. [SEP]"]
[ 200/2000] tot_loss=2.361 (perp=10.435, rec=0.274), tot_loss_proj:2.840 [t=0.26s]
prediction: ["[CLS] our. with dale'chorusnation beforewood younger teacher. teacher exactly care but with of best several compilation in roles makes but great command great writtennation our care the engine'wood seen. a teacher teacher fruit [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=3.198 (perp=12.729, rec=0.652), tot_loss_proj:3.349 [t=0.26s]
prediction: ['[CLS]ores [SEP] foundation but starring cooperchenko resource before infantry locomotives captain edition where care but opened third the several opponent a soon makes boat as individuals famous alone happened our priority "aneous buenos three and river meanwhile harry giro adventure [SEP]']
[ 300/2000] tot_loss=2.905 (perp=11.852, rec=0.535), tot_loss_proj:3.252 [t=0.26s]
prediction: ['[CLS]ores [SEP] colony commissioner included an beta. before initially century territory [SEP] compromise care but opened serious the several. drama v8 makes [SEP] as individuals! [SEP] happened is [SEP] [SEP] inning佐 three. river meanwhile in gotten breed [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.734 (perp=11.262, rec=0.481), tot_loss_proj:3.157 [t=0.27s]
prediction: ['[CLS]ores [SEP] alone fiscal included an lack. before attack developed territory reagan care but opened serious the several. [SEP] started v8 makes [SEP] as individuals! [SEP] happened is [SEP] [SEP] issp three. traditional meanwhile in gotten? [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.772 (perp=11.528, rec=0.466), tot_loss_proj:3.144 [t=0.25s]
prediction: ['[CLS]ores [SEP]ation however included an finally. before attack developed territory reagan care but through serious the several. [SEP] first what makes is [SEP] [SEP] is ے threeennial traditional meanwhile [SEP] as individuals famous [SEP] happenedifies gotten? [SEP]']
[ 450/2000] tot_loss=2.762 (perp=11.670, rec=0.428), tot_loss_proj:3.170 [t=0.26s]
prediction: ['[CLS]ores [SEP]dication rather included an finally. before storyline developed territory reagan care but. serious the several. [SEP] first what makes is [SEP] [SEP] is ے three originally traditional meanwhile [SEP] as individuals famous [SEP] happened modern gotten? [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.733 (perp=11.614, rec=0.410), tot_loss_proj:3.109 [t=0.26s]
prediction: ['[CLS]ores [SEP]lase rather included an ready. before storyline traditional territory reagan careses. serious the several. [SEP] first what makes is [SEP] [SEP] is wolfe three owners powerful meanwhile [SEP] as individuals famous [SEP] happenedifies gotten? [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.728 (perp=11.726, rec=0.383), tot_loss_proj:3.212 [t=0.26s]
prediction: ['[CLS]ores [SEP]ouse rather included [SEP] ready. before storyline traditional territory reagan careses : serious the several. [SEP] most skyla makes is [SEP] an is wolfe threeessedricting meanwhile [SEP] as players famous [SEP] happenedifies timmy? [SEP]']
[ 600/2000] tot_loss=2.898 (perp=12.417, rec=0.415), tot_loss_proj:3.320 [t=0.29s]
prediction: ['[CLS]ores [SEP] importance little included [SEP]ciency. before ambush traditional territory hayden care [SEP] martha successful the inter. [SEP] most kyle makes is [SEP] [SEP] is wolfe three recently corvette meanwhile [SEP] great artists famous [SEP] oftenivation timmy breed [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.965 (perp=12.900, rec=0.385), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS]ores [SEP] jelly little wolfe [SEP]ciency. before almost traditional territory hayden care [SEP] included professional the inter. [SEP] most kyle makes is [SEP] [SEP] is included three recently corvette meanwhile [SEP] great artists famous [SEP] oftenivation timmy breed [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.806 (perp=12.129, rec=0.380), tot_loss_proj:3.196 [t=0.26s]
prediction: ['[CLS]ores [SEP] nearly little wolfe [SEP] m³. before ambush traditional territory hayden care [SEP]ivation professional the inter. [SEP] most kyle makes is [SEP] [SEP] is included three recently corvette meanwhile [SEP] great artists famous [SEP] often included because breed [SEP]']
[ 750/2000] tot_loss=2.804 (perp=12.187, rec=0.366), tot_loss_proj:3.199 [t=0.28s]
prediction: ['[CLS]ores [SEP] nearly profit wolfe [SEP]ciency. before ambush traditional territory hayden care [SEP]ivation professional the inter. [SEP] most kyle makes is [SEP] [SEP] is included three whose corvette meanwhile [SEP] great artists famous [SEP] often included because breed [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.680 (perp=11.646, rec=0.351), tot_loss_proj:3.115 [t=0.25s]
prediction: ["[CLS] hayden [SEP] nearly profit'[SEP] processes. before nearly traditional territoryores care [SEP]ivation professional the inter. [SEP] most kyle makes a [SEP] [SEP] is included three whosestic meanwhile [SEP] great artists famous [SEP] often included because trainer [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.628 (perp=11.401, rec=0.348), tot_loss_proj:3.057 [t=0.26s]
prediction: ["[CLS] hayden [SEP] nearly profit'[SEP] processes. before nearly traditional territoryores care [SEP]ivation professional the inter. [SEP] meanwhile kyle makes a [SEP] [SEP] is included three whosestic most [SEP] great artists famous [SEP] often included because trainer [SEP]"]
[ 900/2000] tot_loss=2.595 (perp=11.273, rec=0.340), tot_loss_proj:3.026 [t=0.26s]
prediction: ["[CLS] hayden [SEP]oint profit'[SEP]tery. before nearly traditional territoryores care [SEP]ivation professional the inter. [SEP] meanwhile kyle makes a value [SEP] is included three whosestic most [SEP] great artists famous [SEP] often : because skiing [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.641 (perp=11.504, rec=0.340), tot_loss_proj:3.056 [t=0.26s]
prediction: ["[CLS] hayden [SEP]ointelman'[SEP]tery. before nearly traditional territoryores care [SEP]ivation inter the professional. [SEP] meanwhile kyle makes a value [SEP] is included threeratorstic most [SEP] great artists famous [SEP] often, because trainer [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.646 (perp=11.538, rec=0.339), tot_loss_proj:3.108 [t=0.29s]
prediction: ["[CLS] hayden [SEP]ointelman'grandfathertery. before nearly traditional territoryores care [SEP]ivation inter the professional. [SEP] meanwhile kyle makes a [SEP] [SEP] is included three [SEP]nation most [SEP] personal artists famous [SEP] often, because trainer [SEP]"]
[1050/2000] tot_loss=2.655 (perp=11.590, rec=0.337), tot_loss_proj:3.096 [t=0.25s]
prediction: ['[CLS] hayden [SEP]ointelmanwn grandfathertery. before nearly traditional territoryores care [SEP]ivation inter the professional. [SEP] meanwhile kyle makes a value [SEP] is included three [SEP]nation most [SEP] personal artists famous [SEP] often, because trainer [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.597 (perp=11.289, rec=0.339), tot_loss_proj:3.030 [t=0.27s]
prediction: ['[CLS] hayden [SEP]ointelmanwn grandfather [SEP]. before nearly traditional territoryores care [SEP]ivation inter the professional. [SEP] meanwhile kyle makes atery [SEP] is included three [SEP]nation most [SEP] personal artists greatest [SEP] often, because trainer [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.566 (perp=11.185, rec=0.329), tot_loss_proj:2.999 [t=0.27s]
prediction: ['[CLS] hayden [SEP]ointelmanwn grandfather [SEP]. before nearly traditional territoryores care [SEP]ivation inter the professional. [SEP] meanwhile kyle makes atery [SEP] is included three [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
[1200/2000] tot_loss=2.653 (perp=11.658, rec=0.322), tot_loss_proj:3.089 [t=0.27s]
prediction: ['[CLS] hayden [SEP]ointelmanwn having [SEP]. before nearly traditional territoryores care [SEP]ivation inter the professional. [SEP] meanwhile kyle makes ahas [SEP] is included three [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.694 (perp=11.801, rec=0.334), tot_loss_proj:3.113 [t=0.26s]
prediction: ['[CLS] hayden [SEP]ointelman [SEP] havingwn. before nearly traditional territoryores care [SEP] breathing inter the professional investigation [SEP] meanwhile therefore makes ahas [SEP] is included three [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.625 (perp=11.442, rec=0.337), tot_loss_proj:3.029 [t=0.26s]
prediction: ['[CLS] hayden [SEP]ointelman [SEP] havingwn. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is included three [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
[1350/2000] tot_loss=2.616 (perp=11.442, rec=0.327), tot_loss_proj:3.028 [t=0.26s]
prediction: ['[CLS] hayden [SEP]ointelman [SEP] havingwn. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is included three [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.598 (perp=11.355, rec=0.327), tot_loss_proj:3.012 [t=0.28s]
prediction: ['[CLS] hayden [SEP]ointelman [SEP] havingwn. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.591 (perp=11.321, rec=0.327), tot_loss_proj:2.988 [t=0.26s]
prediction: ['[CLS] hayden [SEP]ointelman value havingwn. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP]nation [SEP] most personal artists greatest [SEP] often, because trainer [SEP]']
[1500/2000] tot_loss=2.645 (perp=11.672, rec=0.311), tot_loss_proj:3.100 [t=0.27s]
prediction: ['[CLS] hayden [SEP]ointelman value havingwn. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP]nation [SEP] most personal artists greatest [SEP] often, offs trainer [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.614 (perp=11.410, rec=0.332), tot_loss_proj:3.044 [t=0.28s]
prediction: ['[CLS] hayden [SEP]ointelman value havingwn. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP] trainer [SEP] most personal artists greatest [SEP] often,tialnation [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.548 (perp=11.113, rec=0.325), tot_loss_proj:3.003 [t=0.25s]
prediction: ["[CLS] hayden [SEP]ointelman value having '. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP] trainer [SEP] most personal artists [SEP] greatest often, offsnation [SEP]"]
[1650/2000] tot_loss=2.581 (perp=11.281, rec=0.325), tot_loss_proj:3.004 [t=0.27s]
prediction: ["[CLS] hayden [SEP]ointelman value having '. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP] trainer [SEP] most personal artists [SEP] greatest often,ntonnation [SEP]"]
Attempt swap
[1700/2000] tot_loss=2.582 (perp=11.281, rec=0.326), tot_loss_proj:2.995 [t=0.26s]
prediction: ["[CLS] hayden [SEP]ointelman value having '. before nearly traditional territoryores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP] trainer [SEP] most personal artists [SEP] greatest often,ntonnation [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.642 (perp=11.630, rec=0.316), tot_loss_proj:3.064 [t=0.25s]
prediction: ["[CLS] hayden [SEP]ointelman value having '. before nearly traditional settlersores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP] trainer [SEP] most personal artists [SEP] greatest often,ntonnation [SEP]"]
[1800/2000] tot_loss=2.645 (perp=11.630, rec=0.319), tot_loss_proj:3.068 [t=0.26s]
prediction: ["[CLS] hayden [SEP]ointelman value having '. before nearly traditional settlersores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is three included [SEP] trainer [SEP] most personal artists [SEP] greatest often,ntonnation [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.604 (perp=11.443, rec=0.316), tot_loss_proj:3.033 [t=0.27s]
prediction: ["[CLS] hayden [SEP]ointelman value having '. before nearly traditional settlersores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is [SEP] included [SEP] trainer three most personal artists [SEP] greatest often,ntonnation [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.539 (perp=11.137, rec=0.312), tot_loss_proj:2.986 [t=0.28s]
prediction: ["[CLS] settlers [SEP]ointelman value having '. before nearly traditional haydenores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is [SEP] included [SEP] trainer three most personal artists [SEP] greatest often,ntonnation [SEP]"]
[1950/2000] tot_loss=2.530 (perp=11.078, rec=0.314), tot_loss_proj:2.960 [t=0.26s]
prediction: ["[CLS] settlers [SEP]ointelman value having '. before nearly traditional haydenores care [SEP] meanwhile inter the professional investigation press breathing therefore makes ahas [SEP] is [SEP] included [SEP] trainer three most personal artists [SEP] greatest often,ntonstic [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.481 (perp=10.846, rec=0.312), tot_loss_proj:2.908 [t=0.27s]
prediction: ["[CLS] settlers [SEP]ointelman value having '. before nearly traditional haydenores care [SEP] meanwhile is the professional investigation press breathing therefore makes ahas [SEP] inter [SEP] included [SEP] trainer three most personal artists [SEP] greatest often,ntonstic [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] our. with dale'chorusnation beforewood younger teacher. teacher exactly care but with of best several compilation in roles makes but great command great writtennation our care the great'wood seen. a teacher teacher fruit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 33.803 | p: 33.333 | r: 34.286
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 22.535 | p: 22.222 | r: 22.857
rougeLsum  | fm: 22.535 | p: 22.222 | r: 22.857
r1fm+r2fm = 33.803

[Aggregate metrics]:
rouge1     | fm: 86.594 | p: 85.880 | r: 87.435
rouge2     | fm: 52.764 | p: 52.656 | r: 52.871
rougeL     | fm: 76.423 | p: 75.744 | r: 77.130
rougeLsum  | fm: 76.269 | p: 75.637 | r: 77.001
r1fm+r2fm = 139.358

input #35 time: 0:11:07 | total time: 6:42:04


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
cosin similarity: -0.9007084999897201 normalized error: 1.7564637892117434
cosin similarity: 0.9007084999897202 normalized error: 0.4904798791781636
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9609956741333008 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9531316757202148 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9116296768188477 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.9092094898223877 for ['[CLS]va bonyrim seater [SEP]']
[Init] best rec loss: 0.8740737438201904 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8710837960243225 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 0.8706764578819275 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.562 (perp=11.427, rec=0.277), tot_loss_proj:2.785 [t=0.27s]
prediction: ['[CLS] badly badly wrong wrong [SEP]']
[ 100/2000] tot_loss=2.100 (perp=9.529, rec=0.194), tot_loss_proj:2.262 [t=0.27s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=2.044 (perp=9.304, rec=0.183), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] absolutely horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=2.659 (perp=12.544, rec=0.151), tot_loss_proj:3.181 [t=0.26s]
prediction: ['[CLS] damien horribly wrong wrong [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.550 (perp=11.979, rec=0.154), tot_loss_proj:3.150 [t=0.29s]
prediction: ['[CLS] damien cruel horribly wrong [SEP]']
[ 300/2000] tot_loss=1.756 (perp=8.141, rec=0.128), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] s odds horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.085 (perp=9.796, rec=0.125), tot_loss_proj:2.454 [t=0.27s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.075 (perp=9.796, rec=0.116), tot_loss_proj:2.453 [t=0.27s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
[ 450/2000] tot_loss=2.080 (perp=9.796, rec=0.121), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.068 (perp=9.796, rec=0.109), tot_loss_proj:2.451 [t=0.27s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.066 (perp=9.796, rec=0.107), tot_loss_proj:2.451 [t=0.27s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
[ 600/2000] tot_loss=2.074 (perp=9.796, rec=0.115), tot_loss_proj:2.451 [t=0.25s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.077 (perp=9.796, rec=0.117), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.050 (perp=9.796, rec=0.091), tot_loss_proj:2.448 [t=0.26s]
prediction: ['[CLS] s torture horribly wrong [SEP]']
[ 750/2000] tot_loss=2.372 (perp=11.334, rec=0.105), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] s paige horribly wrong [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.253 (perp=10.754, rec=0.102), tot_loss_proj:2.562 [t=0.26s]
prediction: ['[CLS] s horribly wrong torture [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.160 (perp=10.260, rec=0.108), tot_loss_proj:2.657 [t=0.25s]
prediction: ['[CLS] s kenji horribly wrong [SEP]']
[ 900/2000] tot_loss=2.154 (perp=10.260, rec=0.102), tot_loss_proj:2.653 [t=0.27s]
prediction: ['[CLS] s kenji horribly wrong [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.442 (perp=11.688, rec=0.105), tot_loss_proj:2.945 [t=0.27s]
prediction: ['[CLS] skovic horribly wrong [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.229 (perp=10.617, rec=0.106), tot_loss_proj:2.695 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1050/2000] tot_loss=2.182 (perp=10.431, rec=0.096), tot_loss_proj:2.635 [t=0.25s]
prediction: ['[CLS] s horribly wrong kenji [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.151 (perp=10.260, rec=0.100), tot_loss_proj:2.652 [t=0.28s]
prediction: ['[CLS] s kenji horribly wrong [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.230 (perp=10.617, rec=0.107), tot_loss_proj:2.685 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1200/2000] tot_loss=2.218 (perp=10.617, rec=0.095), tot_loss_proj:2.688 [t=0.29s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.232 (perp=10.617, rec=0.109), tot_loss_proj:2.690 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.231 (perp=10.617, rec=0.108), tot_loss_proj:2.682 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1350/2000] tot_loss=2.223 (perp=10.617, rec=0.100), tot_loss_proj:2.692 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.225 (perp=10.617, rec=0.101), tot_loss_proj:2.696 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.214 (perp=10.617, rec=0.091), tot_loss_proj:2.691 [t=0.29s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1500/2000] tot_loss=2.219 (perp=10.617, rec=0.096), tot_loss_proj:2.684 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.223 (perp=10.617, rec=0.099), tot_loss_proj:2.684 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.235 (perp=10.617, rec=0.111), tot_loss_proj:2.689 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1650/2000] tot_loss=2.224 (perp=10.617, rec=0.100), tot_loss_proj:2.688 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.222 (perp=10.617, rec=0.099), tot_loss_proj:2.694 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.228 (perp=10.617, rec=0.104), tot_loss_proj:2.687 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1800/2000] tot_loss=2.223 (perp=10.617, rec=0.100), tot_loss_proj:2.688 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.226 (perp=10.617, rec=0.102), tot_loss_proj:2.691 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.223 (perp=10.617, rec=0.099), tot_loss_proj:2.685 [t=0.27s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
[1950/2000] tot_loss=2.218 (perp=10.617, rec=0.094), tot_loss_proj:2.683 [t=0.25s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.226 (perp=10.617, rec=0.103), tot_loss_proj:2.689 [t=0.26s]
prediction: ['[CLS] s horribly wrongkovic [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s torture horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 66.667 | p: 60.000 | r: 75.000
rougeL     | fm: 90.909 | p: 83.333 | r: 100.000
rougeLsum  | fm: 90.909 | p: 83.333 | r: 100.000
r1fm+r2fm = 157.576

[Aggregate metrics]:
rouge1     | fm: 86.759 | p: 85.829 | r: 87.847
rouge2     | fm: 53.256 | p: 52.894 | r: 53.561
rougeL     | fm: 76.901 | p: 76.047 | r: 77.908
rougeLsum  | fm: 76.731 | p: 75.930 | r: 77.728
r1fm+r2fm = 140.015

input #36 time: 0:11:05 | total time: 6:53:09


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
cosin similarity: 0.9160557524849074 normalized error: 0.5048909406348259
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.8686551451683044 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.8187575340270996 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.7996755838394165 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.7604445219039917 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7475942969322205 for ['[CLS] seats coordinates [SEP]']
[Init] best rec loss: 0.7352431416511536 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.716214656829834 for ['[CLS] loomed col [SEP]']
[Init] best rec loss: 0.7030590176582336 for ['[CLS] plainly holstein [SEP]']
[Init] best rec loss: 0.6905093789100647 for ['[CLS] private rush [SEP]']
[Init] best rec loss: 0.6843785643577576 for ['[CLS] hall anson [SEP]']
[Init] best rec loss: 0.6564062833786011 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 0.6513819098472595 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6406217217445374 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.377 (perp=10.187, rec=0.339), tot_loss_proj:2.487 [t=0.25s]
prediction: ['[CLS] eccentric wife [SEP]']
[ 100/2000] tot_loss=2.537 (perp=11.791, rec=0.179), tot_loss_proj:2.819 [t=0.25s]
prediction: ['[CLS] eccentric indeed [SEP]']
[ 150/2000] tot_loss=2.057 (perp=9.583, rec=0.140), tot_loss_proj:2.000 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=2.058 (perp=9.583, rec=0.141), tot_loss_proj:1.988 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.532 (perp=11.411, rec=0.250), tot_loss_proj:2.638 [t=0.26s]
prediction: ['[CLS] therefore eccentric [SEP]']
[ 300/2000] tot_loss=2.419 (perp=11.266, rec=0.166), tot_loss_proj:2.623 [t=0.25s]
prediction: ['[CLS] indeed eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.231 (perp=10.438, rec=0.143), tot_loss_proj:2.415 [t=0.26s]
prediction: ['[CLS] besides eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.230 (perp=10.438, rec=0.142), tot_loss_proj:2.406 [t=0.28s]
prediction: ['[CLS] besides eccentric [SEP]']
[ 450/2000] tot_loss=2.225 (perp=10.438, rec=0.138), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] besides eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.594 (perp=12.335, rec=0.127), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] jared eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.599 (perp=12.335, rec=0.132), tot_loss_proj:2.843 [t=0.25s]
prediction: ['[CLS] jared eccentric [SEP]']
[ 600/2000] tot_loss=3.222 (perp=15.533, rec=0.115), tot_loss_proj:3.939 [t=0.25s]
prediction: ['[CLS]urity eccentric [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.659 (perp=12.620, rec=0.135), tot_loss_proj:2.968 [t=0.25s]
prediction: ['[CLS] eccentric jared [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.382 (perp=11.317, rec=0.119), tot_loss_proj:3.114 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[ 750/2000] tot_loss=2.395 (perp=11.317, rec=0.132), tot_loss_proj:3.109 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.374 (perp=11.317, rec=0.110), tot_loss_proj:3.105 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.377 (perp=11.317, rec=0.113), tot_loss_proj:3.120 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[ 900/2000] tot_loss=2.387 (perp=11.317, rec=0.123), tot_loss_proj:3.116 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.375 (perp=11.317, rec=0.112), tot_loss_proj:3.114 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.380 (perp=11.317, rec=0.116), tot_loss_proj:3.114 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1050/2000] tot_loss=2.370 (perp=11.317, rec=0.107), tot_loss_proj:3.114 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.372 (perp=11.317, rec=0.108), tot_loss_proj:3.108 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.381 (perp=11.317, rec=0.117), tot_loss_proj:3.115 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
[1200/2000] tot_loss=2.374 (perp=11.317, rec=0.111), tot_loss_proj:3.104 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.376 (perp=11.317, rec=0.113), tot_loss_proj:3.107 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.380 (perp=11.317, rec=0.117), tot_loss_proj:3.111 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
[1350/2000] tot_loss=2.394 (perp=11.317, rec=0.130), tot_loss_proj:3.110 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.384 (perp=11.317, rec=0.120), tot_loss_proj:3.113 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.378 (perp=11.317, rec=0.114), tot_loss_proj:3.103 [t=0.28s]
prediction: ['[CLS] eccentricurity [SEP]']
[1500/2000] tot_loss=2.379 (perp=11.317, rec=0.116), tot_loss_proj:3.109 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.395 (perp=11.317, rec=0.132), tot_loss_proj:3.113 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.373 (perp=11.317, rec=0.110), tot_loss_proj:3.112 [t=0.33s]
prediction: ['[CLS] eccentricurity [SEP]']
[1650/2000] tot_loss=2.385 (perp=11.317, rec=0.122), tot_loss_proj:3.106 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.360 (perp=11.317, rec=0.097), tot_loss_proj:3.108 [t=0.29s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.381 (perp=11.317, rec=0.118), tot_loss_proj:3.112 [t=0.29s]
prediction: ['[CLS] eccentricurity [SEP]']
[1800/2000] tot_loss=2.377 (perp=11.317, rec=0.114), tot_loss_proj:3.104 [t=0.31s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.378 (perp=11.317, rec=0.115), tot_loss_proj:3.105 [t=0.25s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.377 (perp=11.317, rec=0.113), tot_loss_proj:3.110 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
[1950/2000] tot_loss=2.383 (perp=11.317, rec=0.120), tot_loss_proj:3.111 [t=0.26s]
prediction: ['[CLS] eccentricurity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.391 (perp=11.317, rec=0.128), tot_loss_proj:3.110 [t=0.27s]
prediction: ['[CLS] eccentricurity [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentricurity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 66.667 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 66.667 | r: 50.000
rougeLsum  | fm: 57.143 | p: 66.667 | r: 50.000
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 85.903 | p: 85.264 | r: 86.845
rouge2     | fm: 51.960 | p: 51.553 | r: 52.286
rougeL     | fm: 76.301 | p: 75.802 | r: 77.051
rougeLsum  | fm: 76.357 | p: 75.751 | r: 77.132
r1fm+r2fm = 137.864

input #37 time: 0:11:03 | total time: 7:04:13


Running input #38 of 100.
reference: 
========================
scare 
========================
cosin similarity: -0.9177834580454345 normalized error: 1.7129305511605397
cosin similarity: 0.9177834580454345 normalized error: 0.5039674783213574
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8057335615158081 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8002467751502991 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.7790198922157288 for ['[CLS] 100 [SEP]']
[Init] best rec loss: 0.7413572669029236 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.723089873790741 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6939710974693298 for ['[CLS] consciousness [SEP]']
[Init] best rec loss: 0.6531814932823181 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6146848201751709 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.969 (perp=14.070, rec=0.155), tot_loss_proj:2.939 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.928 (perp=14.070, rec=0.114), tot_loss_proj:2.872 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.919 (perp=14.070, rec=0.105), tot_loss_proj:2.875 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.918 (perp=14.070, rec=0.104), tot_loss_proj:2.876 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.920 (perp=14.070, rec=0.106), tot_loss_proj:2.877 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.912 (perp=14.070, rec=0.097), tot_loss_proj:2.880 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.918 (perp=14.070, rec=0.104), tot_loss_proj:2.874 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.928 (perp=14.070, rec=0.114), tot_loss_proj:2.859 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.912 (perp=14.070, rec=0.098), tot_loss_proj:2.867 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.909 (perp=14.070, rec=0.095), tot_loss_proj:2.873 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.914 (perp=14.070, rec=0.100), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.926 (perp=14.070, rec=0.112), tot_loss_proj:2.887 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.914 (perp=14.070, rec=0.100), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.905 (perp=14.070, rec=0.091), tot_loss_proj:2.870 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.921 (perp=14.070, rec=0.107), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.909 (perp=14.070, rec=0.095), tot_loss_proj:2.877 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.926 (perp=14.070, rec=0.112), tot_loss_proj:2.867 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.917 (perp=14.070, rec=0.103), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.913 (perp=14.070, rec=0.099), tot_loss_proj:2.869 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.920 (perp=14.070, rec=0.106), tot_loss_proj:2.863 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.910 (perp=14.070, rec=0.096), tot_loss_proj:2.887 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.913 (perp=14.070, rec=0.099), tot_loss_proj:2.871 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.902 (perp=14.070, rec=0.088), tot_loss_proj:2.868 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.911 (perp=14.070, rec=0.097), tot_loss_proj:2.862 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.914 (perp=14.070, rec=0.100), tot_loss_proj:2.883 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.908 (perp=14.070, rec=0.094), tot_loss_proj:2.874 [t=0.30s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.903 (perp=14.070, rec=0.089), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.914 (perp=14.070, rec=0.100), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
