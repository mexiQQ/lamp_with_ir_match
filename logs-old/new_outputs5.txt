


Command: attack3.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 500 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
*********************************
*********************************
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0055351257324219 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9447663426399231 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9361805319786072 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9271856546401978 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9249287247657776 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8513282537460327 for ['[CLS] panel officer [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.194 (perp=9.874, rec=0.202, cos=0.017), tot_loss_proj:2.547 [t=0.25s]
prediction: ['[CLS] bishop disappointed [SEP]']
Attempt swap
[ 100/ 500] tot_loss=2.204 (perp=10.251, rec=0.143, cos=0.012), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/ 500] tot_loss=2.184 (perp=10.251, rec=0.123, cos=0.010), tot_loss_proj:2.126 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.136 (perp=10.251, rec=0.083, cos=0.003), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/ 500] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/ 500] tot_loss=2.095 (perp=10.251, rec=0.044, cos=0.001), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/ 500] tot_loss=2.117 (perp=10.251, rec=0.065, cos=0.001), tot_loss_proj:2.108 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/ 500] tot_loss=2.107 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.129 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/ 500] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/ 500] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:03:29 | total time: 0:03:29


Running input #1 of 100.
reference: 
========================
splendidly 
========================
*********************************
*********************************
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0210397243499756 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9793888926506042 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8951830267906189 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.864271879196167 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8217445015907288 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8215807676315308 for ['[CLS] siam presidents [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.395 (perp=10.892, rec=0.213, cos=0.003), tot_loss_proj:2.534 [t=0.25s]
prediction: ['[CLS] wonderful splendid [SEP]']
Attempt swap
[ 100/ 500] tot_loss=2.221 (perp=10.288, rec=0.162, cos=0.002), tot_loss_proj:2.344 [t=0.26s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/ 500] tot_loss=2.139 (perp=10.288, rec=0.080, cos=0.001), tot_loss_proj:2.349 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Put prefix at the end
[ 200/ 500] tot_loss=1.887 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.910 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.898 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/ 500] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.889 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.892 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/ 500] tot_loss=1.885 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.889 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.890 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:03:23 | total time: 0:06:52


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
*********************************
*********************************
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8397367596626282 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8254684805870056 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8126578330993652 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.805020809173584 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7947117686271667 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7828556895256042 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7795121073722839 for ['[CLS] would we working [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.449 (perp=10.279, rec=0.353, cos=0.040), tot_loss_proj:2.931 [t=0.25s]
prediction: ['[CLS] culture technology momentum [SEP]']
Attempt swap
[ 100/ 500] tot_loss=1.921 (perp=8.515, rec=0.208, cos=0.010), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/ 500] tot_loss=1.798 (perp=8.515, rec=0.093, cos=0.002), tot_loss_proj:1.799 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.789 (perp=8.515, rec=0.084, cos=0.002), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/ 500] tot_loss=1.788 (perp=8.515, rec=0.083, cos=0.002), tot_loss_proj:1.795 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.783 (perp=8.515, rec=0.079, cos=0.001), tot_loss_proj:1.799 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.774 (perp=8.515, rec=0.069, cos=0.002), tot_loss_proj:1.795 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/ 500] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.774 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:03:25 | total time: 0:10:18


Running input #3 of 100.
reference: 
========================
flawless film 
========================
*********************************
*********************************
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0116136074066162 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9035081267356873 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8794226050376892 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8757002949714661 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8483982086181641 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8467844724655151 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8355522155761719 for ['[CLS] anthony robin [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.272 (perp=10.224, rec=0.222, cos=0.005), tot_loss_proj:2.376 [t=0.25s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 100/ 500] tot_loss=1.754 (perp=8.385, rec=0.075, cos=0.002), tot_loss_proj:1.757 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/ 500] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.761 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.730 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.746 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/ 500] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/ 500] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.756 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:03:25 | total time: 0:13:43


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
*********************************
*********************************
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0361230373382568 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9819928407669067 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.963243842124939 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9556242823600769 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9394267797470093 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9341257810592651 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9212238788604736 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9182291030883789 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8931007385253906 for ['[CLS] fatedss jack [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.120 (perp=9.706, rec=0.172, cos=0.007), tot_loss_proj:2.156 [t=0.26s]
prediction: ['[CLS] tiresomently [SEP]']
Attempt swap
[ 100/ 500] tot_loss=1.585 (perp=7.516, rec=0.079, cos=0.002), tot_loss_proj:1.579 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/ 500] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.573 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.579 (perp=7.516, rec=0.075, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.573 (perp=7.516, rec=0.068, cos=0.001), tot_loss_proj:1.574 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/ 500] tot_loss=1.560 (perp=7.516, rec=0.056, cos=0.001), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.001), tot_loss_proj:1.566 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.578 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/ 500] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.001), tot_loss_proj:1.568 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:03:24 | total time: 0:17:08


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
*********************************
*********************************
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9572856426239014 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517245292663574 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9491873979568481 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9308651685714722 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.927051305770874 for ['[CLS]iv fl [SEP]']
[Init] best rec loss: 0.9123218059539795 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8898680210113525 for ['[CLS] quiet. [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.480 (perp=11.370, rec=0.201, cos=0.005), tot_loss_proj:3.532 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 100/ 500] tot_loss=2.410 (perp=11.370, rec=0.134, cos=0.002), tot_loss_proj:3.501 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/ 500] tot_loss=2.370 (perp=11.370, rec=0.094, cos=0.002), tot_loss_proj:3.510 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.545 (perp=12.316, rec=0.080, cos=0.001), tot_loss_proj:2.534 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 250/ 500] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 300/ 500] tot_loss=2.523 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 350/ 500] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.526 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 400/ 500] tot_loss=2.530 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 450/ 500] tot_loss=2.528 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 500/ 500] tot_loss=2.524 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.513 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] enjoyable ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #5 time: 0:03:24 | total time: 0:20:33


Running input #6 of 100.
reference: 
========================
grayish 
========================
*********************************
*********************************
average of cosine similarity 0.9992504694447222
highest_index [0]
highest [0.9992504694447222]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9556694626808167 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9542555809020996 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9281026721000671 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.870527982711792 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8636731505393982 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8084701895713806 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7869214415550232 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7772212028503418 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7523331046104431 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7494601011276245 for ['[CLS] too u2 [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=1.599 (perp=6.813, rec=0.222, cos=0.015), tot_loss_proj:2.724 [t=0.25s]
prediction: ['[CLS] gray gray [SEP]']
Attempt swap
[ 100/ 500] tot_loss=1.724 (perp=8.089, rec=0.103, cos=0.003), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 150/ 500] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.693 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.697 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 300/ 500] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.002), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 450/ 500] tot_loss=1.666 (perp=8.089, rec=0.047, cos=0.002), tot_loss_proj:1.696 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #6 time: 0:03:25 | total time: 0:23:58


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
*********************************
*********************************
average of cosine similarity 0.9991768686555791
highest_index [0]
highest [0.9991768686555791]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9112632274627686 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8373158574104309 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8293389678001404 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7947319149971008 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7944874167442322 for ['[CLS] manual main disease mukherjee pacific animal battalion classics careernies gold 17th none ranide on blow depending sony alec madagascar tourismzed moffat consisting life [SEP]']
[Init] best perm rec loss: 0.7915330529212952 for ['[CLS] blow animal disease manual consistingzedidenies battalion main pacific on career gold madagascar 17th mukherjee sony alec none depending classics ran life tourism moffat [SEP]']
[Init] best perm rec loss: 0.7903832793235779 for ['[CLS] ran tourism career 17th consisting battalionzed classics madagascar depending manual none gold blowide disease life mainnies animal alec pacific sony mukherjee moffat on [SEP]']
[Init] best perm rec loss: 0.790372371673584 for ['[CLS] none consistingnies depending tourism main moffat classics 17th animal blow alec battalion life ran manual on sony madagascar career goldzed diseaseide mukherjee pacific [SEP]']
[Init] best perm rec loss: 0.790019154548645 for ['[CLS] tourism aleczedidenies depending moffat blow 17th none ran pacific sony main gold madagascar mukherjee manual life classics consisting on disease battalion career animal [SEP]']
[Init] best perm rec loss: 0.7886852025985718 for ['[CLS] tourism disease mainide battalionnies 17th moffat on animal madagascar consistingzed life career sony ran pacific gold alec depending mukherjee manual blow none classics [SEP]']
[Init] best perm rec loss: 0.7882210612297058 for ['[CLS] gold 17th on classics sony blow career pacific battalionzed depending tourismnies ran mukherjee animal consisting diseaseide main madagascar life manual moffat alec none [SEP]']
Nsteps: 500
[  50/2000] tot_loss=2.555 (perp=10.912, rec=0.342, cos=0.031), tot_loss_proj:3.304 [t=0.25s]
prediction: ['[CLS] problem none that quite lacking notroid so defense problem asshole currently. ( unfortunately bad drug made sector sexual. or understand no ugly giving [SEP]']
[ 100/2000] tot_loss=2.059 (perp=8.903, rec=0.264, cos=0.014), tot_loss_proj:2.914 [t=0.25s]
prediction: ['[CLS] problem problem was problem ugly not ugly that wrong no character ; no ( unfortunately problem is love meant love. or sure has ugly or [SEP]']
[ 150/2000] tot_loss=1.976 (perp=8.829, rec=0.202, cos=0.008), tot_loss_proj:2.816 [t=0.27s]
prediction: ['[CLS] problem problem was problem ugly not ugly that problem no character ; no he involves problem is loveiness love. or sure has ugly or [SEP]']
[ 200/2000] tot_loss=1.834 (perp=8.271, rec=0.173, cos=0.007), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] cute problemr is ugly not ugly no i i mind ; no he is problem is loveable love character or sure has ugly. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.243 (perp=8.287, rec=0.471, cos=0.115), tot_loss_proj:3.148 [t=0.24s]
prediction: ['[CLS] cute. is not problem not interesting.. no brain ; no he logistics problem offendersrzy possible cute character. now has ugly. [SEP]']
[ 300/2000] tot_loss=2.146 (perp=8.715, rec=0.367, cos=0.037), tot_loss_proj:3.563 [t=0.26s]
prediction: ['[CLS] tourist. is not problem. window... mind ; no he gary problem crzy possible via character. enough has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.102 (perp=9.008, rec=0.286, cos=0.015), tot_loss_proj:3.523 [t=0.27s]
prediction: ['[CLS] tourist. is without problem. sight. he. character ; no. considered problem crzy sufficient exclusively character. twice has ugly. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.077 (perp=9.067, rec=0.252, cos=0.011), tot_loss_proj:3.556 [t=0.26s]
prediction: ['[CLS] tourist compound is without problem. news. he. character ; no ( considered sufficient problem c love exclusively character. twice has ugly. [SEP]']
[ 450/2000] tot_loss=2.069 (perp=9.128, rec=0.234, cos=0.009), tot_loss_proj:3.398 [t=0.25s]
prediction: ['[CLS] tourist compound is without problem is odd. he. character ; no ( considered sufficient problem c love love character. twice has ugly. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.997 (perp=8.827, rec=0.224, cos=0.008), tot_loss_proj:3.635 [t=0.26s]
prediction: ['[CLS] tourist compound is without problem. he is information. character ; no ( considered sufficient problem c love love character. not has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.976 (perp=8.737, rec=0.221, cos=0.008), tot_loss_proj:2.674 [t=0.26s]
prediction: ['[CLS] ugly compound is after problem. he is information. character ; no c considered sufficient problem ( love love character. votes has ugly. [SEP]']
[ 600/2000] tot_loss=1.878 (perp=8.306, rec=0.210, cos=0.006), tot_loss_proj:3.446 [t=0.26s]
prediction: ['[CLS] tourist compound is after problem. he is information. character ; no c considered sufficient problem. love love character. not has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.813 (perp=8.033, rec=0.200, cos=0.006), tot_loss_proj:3.323 [t=0.26s]
prediction: ['[CLS] considered compound is after problem. he is information. character ; no c ugly sufficient problem. love love character. not has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.545 (perp=9.021, rec=0.569, cos=0.172), tot_loss_proj:3.350 [t=0.28s]
prediction: ['[CLS] though though is an problem. he ease location. character ; no mcc has possible problem from love love character. although sherlock ugly. [SEP]']
[ 750/2000] tot_loss=2.120 (perp=8.212, rec=0.404, cos=0.073), tot_loss_proj:3.241 [t=0.25s]
prediction: ['[CLS] terry though is an problem. he ease location. character. no kirby has possible problem from love ) character. although comic ugly. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.094 (perp=8.420, rec=0.360, cos=0.050), tot_loss_proj:2.666 [t=0.27s]
prediction: ['[CLS] terry though is an problem. he ease location. ugly. no mcc has possible problem from love ) character. although domesday character. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.037 (perp=8.311, rec=0.335, cos=0.041), tot_loss_proj:2.679 [t=0.28s]
prediction: ['[CLS] terry he is an problem. though ease location. ugly. no mcc has possible problem from love ) character. although domesday character. [SEP]']
[ 900/2000] tot_loss=2.013 (perp=8.311, rec=0.317, cos=0.034), tot_loss_proj:2.680 [t=0.28s]
prediction: ['[CLS] terry he is an problem. though ease location. ugly. no mcc has possible problem from love ) character. although domesday character. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.982 (perp=8.249, rec=0.303, cos=0.029), tot_loss_proj:2.767 [t=0.26s]
prediction: ['[CLS] terry he is an problem. though ease location. ugly. no ranger has possible problem from love ) character. although domesday character. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.950 (perp=8.142, rec=0.296, cos=0.025), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] he is an terry problem. though ease location. ugly. no steps has possible problem from love ) character. although domesday character. [SEP]']
[1050/2000] tot_loss=1.999 (perp=8.430, rec=0.290, cos=0.023), tot_loss_proj:3.321 [t=0.25s]
prediction: ['[CLS] he is an terry problem. though ease location without ugly. no steps has possible problem from love ) character. although domesday character. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.866 (perp=7.780, rec=0.289, cos=0.021), tot_loss_proj:2.575 [t=0.26s]
prediction: ['[CLS] he is 2 terry problem. though ease location. ugly. no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.857 (perp=7.780, rec=0.282, cos=0.019), tot_loss_proj:2.573 [t=0.25s]
prediction: ['[CLS] he is 2 terry problem. though ease location. ugly. no character has possible problem from love ) character. although domesday steps. [SEP]']
[1200/2000] tot_loss=1.893 (perp=8.004, rec=0.275, cos=0.017), tot_loss_proj:3.263 [t=0.26s]
prediction: ['[CLS] he is 2 considered problem. though ease location without ugly. no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.979 (perp=8.446, rec=0.274, cos=0.016), tot_loss_proj:3.182 [t=0.30s]
prediction: ['[CLS] he is 2 considered problem. though ease location without ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.966 (perp=8.409, rec=0.269, cos=0.015), tot_loss_proj:3.123 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem. though ease location without ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
[1350/2000] tot_loss=1.954 (perp=8.409, rec=0.258, cos=0.015), tot_loss_proj:3.120 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem. though ease location without ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.957 (perp=8.409, rec=0.261, cos=0.014), tot_loss_proj:3.125 [t=0.29s]
prediction: ['[CLS] he 2 is considered problem. though ease location without ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.928 (perp=8.269, rec=0.260, cos=0.014), tot_loss_proj:2.540 [t=0.31s]
prediction: ['[CLS] he 2 is considered problem without though ease location. ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
[1500/2000] tot_loss=1.918 (perp=8.269, rec=0.250, cos=0.013), tot_loss_proj:2.533 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem without though ease location. ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.852 (perp=7.910, rec=0.257, cos=0.013), tot_loss_proj:2.446 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem without location ease though. ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.854 (perp=7.910, rec=0.259, cos=0.013), tot_loss_proj:2.444 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem without location ease though. ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
[1650/2000] tot_loss=1.849 (perp=7.910, rec=0.255, cos=0.013), tot_loss_proj:2.453 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem without location ease though. ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.829 (perp=7.834, rec=0.250, cos=0.012), tot_loss_proj:2.508 [t=0.31s]
prediction: ['[CLS] he 2 is considered problem without location ease. though ugly like no character has possible problem from love ) character. although domesday steps. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.805 (perp=7.670, rec=0.259, cos=0.012), tot_loss_proj:2.479 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem without location ease. though ugly like no character has possible problem from love steps character. although domesday ). [SEP]']
[1800/2000] tot_loss=1.801 (perp=7.670, rec=0.255, cos=0.012), tot_loss_proj:2.478 [t=0.29s]
prediction: ['[CLS] he 2 is considered problem without location ease. though ugly like no character has possible problem from love steps character. although domesday ). [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=7.670, rec=0.248, cos=0.011), tot_loss_proj:2.470 [t=0.29s]
prediction: ['[CLS] he 2 is considered problem without location ease. though ugly like no character has possible problem from love steps character. although domesday ). [SEP]']
Attempt swap
[1900/2000] tot_loss=1.795 (perp=7.670, rec=0.250, cos=0.011), tot_loss_proj:2.478 [t=0.30s]
prediction: ['[CLS] he 2 is considered problem without location ease. though ugly like no character has possible problem from love steps character. although domesday ). [SEP]']
[1950/2000] tot_loss=1.799 (perp=7.670, rec=0.254, cos=0.011), tot_loss_proj:2.476 [t=0.29s]
prediction: ['[CLS] he 2 is considered problem without location ease. though ugly like no character has possible problem from love steps character. although domesday ). [SEP]']
Attempt swap
[2000/2000] tot_loss=1.838 (perp=7.902, rec=0.247, cos=0.011), tot_loss_proj:3.139 [t=0.29s]
prediction: ['[CLS] he 2 is funny problem without location ease. though ugly like no character has possible problem from love steps character. although domesday ). [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] cute problemr is ugly not ugly no mind i mind ; no he is problem is loveable love character or sure has ugly that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.913 | p: 68.000 | r: 80.952
rouge2     | fm: 9.091 | p: 8.333 | r: 10.000
rougeL     | fm: 43.478 | p: 40.000 | r: 47.619
rougeLsum  | fm: 43.478 | p: 40.000 | r: 47.619
r1fm+r2fm = 83.004

[Aggregate metrics]:
rouge1     | fm: 96.739 | p: 96.000 | r: 97.619
rouge2     | fm: 88.636 | p: 88.542 | r: 88.750
rougeL     | fm: 92.935 | p: 92.500 | r: 93.452
rougeLsum  | fm: 92.935 | p: 92.500 | r: 93.452
r1fm+r2fm = 185.375

input #7 time: 0:11:25 | total time: 0:35:24


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
*********************************
*********************************
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7545608878135681 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7099087834358215 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6953709125518799 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6868163347244263 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6856463551521301 for ['[CLS] shouts guards germany space establishments sometimes flags dead rear protestant floyd breed article gut id occupational development institute loss joint hull meat mode required [SEP]']
[Init] best rec loss: 0.6826488375663757 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6799412369728088 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6793580651283264 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6682642102241516 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6651372313499451 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6647960543632507 for ['[CLS] si socially tail dna wanda res arkansas february eisenhower screens sweat season franchiseey prison adventure product canonmeitta facts badminton plaquedent [SEP]']
[Init] best perm rec loss: 0.6633939146995544 for ['[CLS] dna sweat factsttadent sociallymei arkansas eisenhower si franchise canon adventure plaque season product tail res prison screens badminton wanda februaryey [SEP]']
[Init] best perm rec loss: 0.6628186106681824 for ['[CLS]mei si franchise wanda sweat product dna adventure eisenhowertta arkansas seasoney canon plaquedent tail february facts screens badminton res prison socially [SEP]']
[Init] best perm rec loss: 0.6616048216819763 for ['[CLS] res product socially badminton tail arkansas february facts sweat wandameident prison plaque eisenhower franchise adventure sitta dna seasoney screens canon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.494 (perp=13.996, rec=0.450, cos=0.244), tot_loss_proj:4.168 [t=0.29s]
prediction: ['[CLS] fee surely first fission free lucien [SEP] dollars this relax fee fay vanity terrorists manor dared debt gets rico fools hector wish streets madame [SEP]']
[ 100/2000] tot_loss=3.138 (perp=13.820, rec=0.307, cos=0.067), tot_loss_proj:4.129 [t=0.30s]
prediction: ['[CLS] pays s only fission free film [SEP] paid which au benefactor vanity vanity fright film metro debt pays whatever fools janet debt dick island [SEP]']
[ 150/2000] tot_loss=3.199 (perp=14.109, rec=0.268, cos=0.109), tot_loss_proj:4.096 [t=0.28s]
prediction: ['[CLS] vanity s vanity fission of films [SEP] vanity which¨ landmark vanity vanity fright film quietly debt pays what fools owed debt tumors y [SEP]']
[ 200/2000] tot_loss=3.022 (perp=13.239, rec=0.229, cos=0.145), tot_loss_proj:3.968 [t=0.29s]
prediction: ['[CLS] vanity s vanity vanity old film [SEP] vanity that \\ thing doubt vanity vanity film quietly debt pays what fools owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.499 (perp=11.559, rec=0.176, cos=0.011), tot_loss_proj:3.531 [t=0.29s]
prediction: ['[CLS] that s vanity vanity rights film [SEP] vanity vanity \\ says doubt vanity vanity film quietly debt pays what fools owed off benigni [SEP]']
[ 300/2000] tot_loss=2.487 (perp=11.638, rec=0.150, cos=0.010), tot_loss_proj:3.564 [t=0.30s]
prediction: ['[CLS] that s vanity vanity rights film [SEP] vanity vanity off says doubt vanity frightmax quietly debt pays what vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.378 (perp=11.173, rec=0.134, cos=0.009), tot_loss_proj:3.574 [t=0.31s]
prediction: ['[CLS] that s vanity vanity of film [SEP] a vanity fright frowned doubt vanity \\max quietly debt pays what vanity owed off benigni [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.146 (perp=9.997, rec=0.133, cos=0.014), tot_loss_proj:3.138 [t=0.31s]
prediction: ['[CLS] that s vanity vanity of film [SEP] a vanity fright, doubt vanity \\max quietly pays what debt vanity owed off benigni [SEP]']
[ 450/2000] tot_loss=2.247 (perp=10.239, rec=0.141, cos=0.058), tot_loss_proj:3.273 [t=0.29s]
prediction: ['[CLS] that s vanity vanitymax film [SEP] a vanity fright, doubt vanity \\max awake pays what debt vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.276 (perp=10.754, rec=0.120, cos=0.005), tot_loss_proj:3.353 [t=0.29s]
prediction: ['[CLS] that s vanity filmmax vanity [SEP] a vanity fright, doubt vanity \\max awake pays what debt whom owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.100 (perp=9.889, rec=0.116, cos=0.005), tot_loss_proj:3.221 [t=0.29s]
prediction: ['[CLS] that s \\ film off vanity [SEP] a vanity fright, doubtful vanitymax felt pays what debt mis owed off benigni [SEP]']
[ 600/2000] tot_loss=2.147 (perp=10.159, rec=0.110, cos=0.005), tot_loss_proj:3.200 [t=0.32s]
prediction: ['[CLS] that s \\ filmful fright ¨ a vanity fright, doubtful vanitymax felt pays what debt terrified owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.105 (perp=9.992, rec=0.101, cos=0.006), tot_loss_proj:3.216 [t=0.27s]
prediction: ['[CLS] that s \\ filmful fright [SEP] a because fright, doubtful vanitymax felt pays what debt vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.082 (perp=9.899, rec=0.098, cos=0.005), tot_loss_proj:2.868 [t=0.27s]
prediction: ['[CLS] that s \\ filmful fright armstrong a no fright, doubtful vanitymax [SEP] pays what debt vanity owed off benigni [SEP]']
[ 750/2000] tot_loss=1.994 (perp=9.476, rec=0.094, cos=0.004), tot_loss_proj:2.936 [t=0.26s]
prediction: ['[CLS] that s \\ filmful fright suspects a no fright, doubtful vanitymax [SEP] pays what debt vanity owed off benigni [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.934 (perp=9.164, rec=0.097, cos=0.005), tot_loss_proj:2.781 [t=0.26s]
prediction: ['[CLS] that s \\ film frightful suspects a no fright, doubtful vanitymax [SEP] pays what debt vanity owed off benigni [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.844 (perp=8.710, rec=0.098, cos=0.005), tot_loss_proj:2.735 [t=0.27s]
prediction: ['[CLS] that s \\ film fright suspects a no frightful, doubtful vanitymax [SEP] pays what debt vanity owed off benigni [SEP]']
[ 900/2000] tot_loss=1.846 (perp=8.701, rec=0.101, cos=0.004), tot_loss_proj:3.082 [t=0.27s]
prediction: ['[CLS] that s \\ film fright insisted a no frightful, doubtful vanitymax no pays what debt vanity owed off benigni [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.894 (perp=8.982, rec=0.094, cos=0.004), tot_loss_proj:3.169 [t=0.27s]
prediction: ['[CLS] that s \\ film fright suspects a no fright immediate, doubtful vanitymax no pays what debt vanity owed off benigni [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.845 (perp=8.731, rec=0.095, cos=0.004), tot_loss_proj:3.055 [t=0.26s]
prediction: ['[CLS] that s \\ film fright felt a no fright immediate, doubtfulmax no vanity pays what debt vanity owed off benigni [SEP]']
[1050/2000] tot_loss=1.841 (perp=8.731, rec=0.091, cos=0.004), tot_loss_proj:3.057 [t=0.26s]
prediction: ['[CLS] that s \\ film fright felt a no fright immediate, doubtfulmax no vanity pays what debt vanity owed off benigni [SEP]']
Attempt swap
[1100/2000] tot_loss=1.839 (perp=8.731, rec=0.090, cos=0.003), tot_loss_proj:3.055 [t=0.27s]
prediction: ['[CLS] that s \\ film fright felt a no fright immediate, doubtfulmax no vanity pays what debt vanity owed off benigni [SEP]']
Attempt swap
[1150/2000] tot_loss=1.842 (perp=8.731, rec=0.093, cos=0.003), tot_loss_proj:3.061 [t=0.29s]
prediction: ['[CLS] that s \\ film fright felt a no fright immediate, doubtfulmax no vanity pays what debt vanity owed off benigni [SEP]']
[1200/2000] tot_loss=1.838 (perp=8.731, rec=0.089, cos=0.003), tot_loss_proj:3.058 [t=0.26s]
prediction: ['[CLS] that s \\ film fright felt a no fright immediate, doubtfulmax no vanity pays what debt vanity owed off benigni [SEP]']
Attempt swap
[1250/2000] tot_loss=1.861 (perp=8.843, rec=0.090, cos=0.003), tot_loss_proj:3.143 [t=0.26s]
prediction: ['[CLS] that s \\ film fright felt a no frightmax, doubtfulmax no vanity pays what debt vanity owed off benigni [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.826 (perp=8.717, rec=0.079, cos=0.003), tot_loss_proj:3.394 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no no pays what debt vanity owed off benigni [SEP]']
[1350/2000] tot_loss=1.836 (perp=8.717, rec=0.089, cos=0.003), tot_loss_proj:3.390 [t=0.25s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no no pays what debt vanity owed off benigni [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.814 (perp=8.589, rec=0.093, cos=0.003), tot_loss_proj:3.133 [t=0.26s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[1450/2000] tot_loss=1.805 (perp=8.589, rec=0.084, cos=0.003), tot_loss_proj:3.130 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no pays what no debt vanity owed off benigni [SEP]']
[1500/2000] tot_loss=1.810 (perp=8.589, rec=0.089, cos=0.003), tot_loss_proj:3.131 [t=0.25s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[1550/2000] tot_loss=1.802 (perp=8.589, rec=0.081, cos=0.003), tot_loss_proj:3.132 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[1600/2000] tot_loss=1.801 (perp=8.589, rec=0.080, cos=0.003), tot_loss_proj:3.129 [t=0.25s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no pays what no debt vanity owed off benigni [SEP]']
[1650/2000] tot_loss=1.795 (perp=8.589, rec=0.074, cos=0.003), tot_loss_proj:3.134 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, doubtfulmax no pays what no debt vanity owed off benigni [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.740 (perp=8.278, rec=0.081, cos=0.003), tot_loss_proj:2.828 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[1750/2000] tot_loss=1.745 (perp=8.278, rec=0.086, cos=0.003), tot_loss_proj:2.822 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
[1800/2000] tot_loss=1.743 (perp=8.278, rec=0.084, cos=0.003), tot_loss_proj:2.828 [t=0.26s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[1850/2000] tot_loss=1.739 (perp=8.278, rec=0.080, cos=0.003), tot_loss_proj:2.829 [t=0.26s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[1900/2000] tot_loss=1.747 (perp=8.278, rec=0.089, cos=0.003), tot_loss_proj:2.823 [t=0.25s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
[1950/2000] tot_loss=1.739 (perp=8.278, rec=0.080, cos=0.003), tot_loss_proj:2.826 [t=0.27s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
Attempt swap
[2000/2000] tot_loss=1.737 (perp=8.278, rec=0.079, cos=0.003), tot_loss_proj:2.829 [t=0.26s]
prediction: ['[CLS] that s \\ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] that s \ film a fright felt no frightmax, no doubtfulmax pays what no debt vanity owed off benigni [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 5.263 | p: 5.263 | r: 5.263
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 80.263

[Aggregate metrics]:
rouge1     | fm: 94.324 | p: 93.667 | r: 95.106
rouge2     | fm: 79.373 | p: 79.288 | r: 79.474
rougeL     | fm: 88.164 | p: 87.778 | r: 88.624
rougeLsum  | fm: 88.164 | p: 87.778 | r: 88.624
r1fm+r2fm = 173.696

input #8 time: 0:11:20 | total time: 0:46:44


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
*********************************
*********************************
average of cosine similarity 0.9993981275486598
highest_index [0]
highest [0.9993981275486598]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8187081217765808 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7782889604568481 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7333240509033203 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7192718386650085 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6858556866645813 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6808661222457886 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6510923504829407 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6500662565231323 for ['[CLS] cody luck deaths outlaw decca arsenaldden edward [SEP]']
[Init] best perm rec loss: 0.6491195559501648 for ['[CLS]dden deaths arsenal luck decca outlaw cody edward [SEP]']
[Init] best perm rec loss: 0.648005485534668 for ['[CLS] outlaw deaths luckdden cody edward arsenal decca [SEP]']
[Init] best perm rec loss: 0.6462655663490295 for ['[CLS] decca cody luck edward deaths outlawdden arsenal [SEP]']
[Init] best perm rec loss: 0.6440391540527344 for ['[CLS] cody decca deaths arsenal luck edwarddden outlaw [SEP]']
[Init] best perm rec loss: 0.6436610221862793 for ['[CLS] cody decca outlaw luck arsenal edwarddden deaths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.755 (perp=11.724, rec=0.290, cos=0.120), tot_loss_proj:3.520 [t=0.24s]
prediction: ['[CLS] neill quantum garagehead metaphysical metaphysical claptra [SEP]']
[ 100/2000] tot_loss=2.477 (perp=11.170, rec=0.210, cos=0.033), tot_loss_proj:3.038 [t=0.26s]
prediction: ['[CLS] of soft claphead metaphysical metaphysical claptra [SEP]']
[ 150/2000] tot_loss=2.568 (perp=12.132, rec=0.137, cos=0.005), tot_loss_proj:3.038 [t=0.26s]
prediction: ['[CLS] of softheadheadhead metaphysical claptra [SEP]']
[ 200/2000] tot_loss=2.559 (perp=12.132, rec=0.122, cos=0.011), tot_loss_proj:3.027 [t=0.25s]
prediction: ['[CLS] of softheadheadhead metaphysical claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.200 (perp=10.310, rec=0.129, cos=0.009), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS] of metaphysical claptra softheadheadhead [SEP]']
[ 300/2000] tot_loss=2.392 (perp=11.394, rec=0.110, cos=0.003), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] of metaphysical claptra softtraheaded [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.939 (perp=9.124, rec=0.110, cos=0.005), tot_loss_proj:2.432 [t=0.26s]
prediction: ['[CLS] oftra metaphysical claptra softheaded [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.915 (perp=9.124, rec=0.087, cos=0.003), tot_loss_proj:2.424 [t=0.25s]
prediction: ['[CLS] oftra metaphysical claptra softheaded [SEP]']
[ 450/2000] tot_loss=1.910 (perp=9.124, rec=0.083, cos=0.002), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] oftra metaphysical claptra softheaded [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.903 (perp=9.124, rec=0.077, cos=0.002), tot_loss_proj:2.431 [t=0.25s]
prediction: ['[CLS] oftra metaphysical claptra softheaded [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.943 (perp=9.368, rec=0.068, cos=0.001), tot_loss_proj:2.564 [t=0.25s]
prediction: ['[CLS] oftra metaphysical clapp softheaded [SEP]']
[ 600/2000] tot_loss=1.950 (perp=9.368, rec=0.075, cos=0.001), tot_loss_proj:2.559 [t=0.25s]
prediction: ['[CLS] oftra metaphysical clapp softheaded [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.572 (perp=7.429, rec=0.084, cos=0.002), tot_loss_proj:1.764 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.561 (perp=7.429, rec=0.074, cos=0.001), tot_loss_proj:1.765 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[ 750/2000] tot_loss=1.562 (perp=7.429, rec=0.075, cos=0.001), tot_loss_proj:1.764 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.555 (perp=7.429, rec=0.068, cos=0.001), tot_loss_proj:1.772 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.549 (perp=7.429, rec=0.062, cos=0.001), tot_loss_proj:1.768 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[ 900/2000] tot_loss=1.559 (perp=7.429, rec=0.072, cos=0.001), tot_loss_proj:1.771 [t=0.27s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.555 (perp=7.429, rec=0.068, cos=0.001), tot_loss_proj:1.769 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1000/2000] tot_loss=1.560 (perp=7.429, rec=0.073, cos=0.001), tot_loss_proj:1.765 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.429, rec=0.071, cos=0.001), tot_loss_proj:1.765 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1100/2000] tot_loss=1.555 (perp=7.429, rec=0.068, cos=0.001), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1150/2000] tot_loss=1.556 (perp=7.429, rec=0.069, cos=0.001), tot_loss_proj:1.769 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1200/2000] tot_loss=1.554 (perp=7.429, rec=0.067, cos=0.001), tot_loss_proj:1.768 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1250/2000] tot_loss=1.547 (perp=7.429, rec=0.060, cos=0.001), tot_loss_proj:1.769 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1300/2000] tot_loss=1.545 (perp=7.429, rec=0.059, cos=0.001), tot_loss_proj:1.769 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1350/2000] tot_loss=1.555 (perp=7.429, rec=0.068, cos=0.001), tot_loss_proj:1.770 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1400/2000] tot_loss=1.552 (perp=7.429, rec=0.065, cos=0.001), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1450/2000] tot_loss=1.547 (perp=7.429, rec=0.060, cos=0.001), tot_loss_proj:1.763 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.429, rec=0.067, cos=0.001), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1550/2000] tot_loss=1.559 (perp=7.429, rec=0.072, cos=0.001), tot_loss_proj:1.770 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1600/2000] tot_loss=1.555 (perp=7.429, rec=0.068, cos=0.001), tot_loss_proj:1.764 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1650/2000] tot_loss=1.546 (perp=7.429, rec=0.059, cos=0.001), tot_loss_proj:1.767 [t=0.28s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1700/2000] tot_loss=1.548 (perp=7.429, rec=0.061, cos=0.001), tot_loss_proj:1.774 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1750/2000] tot_loss=1.548 (perp=7.429, rec=0.061, cos=0.001), tot_loss_proj:1.763 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1800/2000] tot_loss=1.557 (perp=7.429, rec=0.070, cos=0.001), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1850/2000] tot_loss=1.550 (perp=7.429, rec=0.063, cos=0.001), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[1900/2000] tot_loss=1.552 (perp=7.429, rec=0.065, cos=0.001), tot_loss_proj:1.763 [t=0.25s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
[1950/2000] tot_loss=1.553 (perp=7.429, rec=0.066, cos=0.001), tot_loss_proj:1.775 [t=0.26s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=7.429, rec=0.063, cos=0.001), tot_loss_proj:1.766 [t=0.24s]
prediction: ['[CLS] of metaphysical claptrap softheaded [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical claptrap softheaded [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 94.891 | p: 94.300 | r: 95.595
rouge2     | fm: 75.435 | p: 75.360 | r: 75.526
rougeL     | fm: 88.333 | p: 88.000 | r: 88.333
rougeLsum  | fm: 88.333 | p: 88.000 | r: 88.333
r1fm+r2fm = 170.327

input #9 time: 0:10:53 | total time: 0:57:38


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
*********************************
*********************************
average of cosine similarity 0.9991472052153931
highest_index [0]
highest [0.9991472052153931]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8814778923988342 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8704736828804016 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8242684602737427 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8198046684265137 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8065224885940552 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8059665560722351 for ['[CLS] help reachercar hid championship immediately besideselin accompanied eva nervous pounded swing [SEP]']
[Init] best perm rec loss: 0.8049544095993042 for ['[CLS] help nervouscarelin besides reacher championship swing pounded hid immediately accompanied eva [SEP]']
[Init] best perm rec loss: 0.8048099279403687 for ['[CLS] hid helpcar pounded eva immediately besideselin swing reacher championship accompanied nervous [SEP]']
[Init] best perm rec loss: 0.8033286333084106 for ['[CLS] besides nervous immediately eva hid swing pounded reacherelincar accompanied help championship [SEP]']
[Init] best perm rec loss: 0.8032909035682678 for ['[CLS]car championship hid accompanied reacher swing evaelin immediately nervous help pounded besides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.953 (perp=12.834, rec=0.358, cos=0.028), tot_loss_proj:4.379 [t=0.24s]
prediction: ['[CLS] anders 6fully ends differently percussion eva in songs freelytrayignant very [SEP]']
[ 100/2000] tot_loss=2.388 (perp=10.733, rec=0.234, cos=0.008), tot_loss_proj:3.945 [t=0.28s]
prediction: ['[CLS] ab doggly balances rhythmtime in months abtrayulsively [SEP]']
[ 150/2000] tot_loss=2.593 (perp=11.712, rec=0.242, cos=0.008), tot_loss_proj:3.552 [t=0.25s]
prediction: ['[CLS] ab 2005ly balance real rhythms with from months ab soundtrackulsive ab [SEP]']
[ 200/2000] tot_loss=2.389 (perp=11.073, rec=0.166, cos=0.008), tot_loss_proj:3.508 [t=0.26s]
prediction: ['[CLS] ab 2005ly balance real rhythms with. days ab rhythmsulsive ab [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.038 (perp=9.421, rec=0.148, cos=0.006), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] ab 2005ly balance real rhythms with days. abulsive. ab [SEP]']
[ 300/2000] tot_loss=2.030 (perp=9.438, rec=0.137, cos=0.005), tot_loss_proj:2.700 [t=0.24s]
prediction: ['[CLS]ly famously balance real rhythms with moments. abulsive. ab [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.013 (perp=9.366, rec=0.136, cos=0.005), tot_loss_proj:2.628 [t=0.25s]
prediction: ['[CLS]ly classicly balance rhythms with real moments. ab incident. ab [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.930 (perp=8.976, rec=0.129, cos=0.005), tot_loss_proj:2.449 [t=0.26s]
prediction: ['[CLS]ly classicly balance rhythms with real moments incident. ab. ab [SEP]']
[ 450/2000] tot_loss=1.934 (perp=8.976, rec=0.134, cos=0.004), tot_loss_proj:2.457 [t=0.25s]
prediction: ['[CLS]ly classicly balance rhythms with real moments incident. ab. ab [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.233 (perp=9.374, rec=0.333, cos=0.024), tot_loss_proj:2.647 [t=0.27s]
prediction: ['[CLS]ly supremely balance rhythms with real incident having about ab. ab [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.042 (perp=8.825, rec=0.264, cos=0.013), tot_loss_proj:2.593 [t=0.26s]
prediction: ['[CLS] incidently supremely balance rhythms with real having the ab. ab [SEP]']
[ 600/2000] tot_loss=2.196 (perp=9.894, rec=0.210, cos=0.008), tot_loss_proj:2.724 [t=0.25s]
prediction: ['[CLS] incidently supremely balance rhythms with real having subsequent ab. ab [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.046 (perp=9.214, rec=0.197, cos=0.007), tot_loss_proj:3.415 [t=0.26s]
prediction: ['[CLS] incidently ªly balance rhythms with ab real having minor ab. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.915 (perp=8.666, rec=0.176, cos=0.006), tot_loss_proj:2.725 [t=0.26s]
prediction: ['[CLS] incidently pictorially balance rhythms with ab real having minor ab. [SEP]']
[ 750/2000] tot_loss=1.882 (perp=8.564, rec=0.164, cos=0.005), tot_loss_proj:2.457 [t=0.26s]
prediction: ['[CLS] incidently pictorially balance rhythms with ab real having local ab. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.838 (perp=8.395, rec=0.154, cos=0.005), tot_loss_proj:2.363 [t=0.24s]
prediction: ['[CLS] incidently pictorially balance rhythms with real ab having local ab. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.898 (perp=8.772, rec=0.139, cos=0.004), tot_loss_proj:2.506 [t=0.26s]
prediction: ['[CLS] incident riff pictorially balance rhythms with real ab having local ab. [SEP]']
[ 900/2000] tot_loss=1.910 (perp=8.772, rec=0.152, cos=0.004), tot_loss_proj:2.510 [t=0.25s]
prediction: ['[CLS] incident riff pictorially balance rhythms with real ab having local ab. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.897 (perp=8.772, rec=0.139, cos=0.004), tot_loss_proj:2.508 [t=0.26s]
prediction: ['[CLS] incident riff pictorially balance rhythms with real ab having local ab. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.056 (perp=9.526, rec=0.147, cos=0.004), tot_loss_proj:3.002 [t=0.26s]
prediction: ['[CLS] riff incident ªly balance rhythms with real ab having local ab. [SEP]']
[1050/2000] tot_loss=2.092 (perp=9.775, rec=0.134, cos=0.004), tot_loss_proj:3.134 [t=0.25s]
prediction: ['[CLS] riff incident ªly balance rhythms with real ab happened local ab. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.041 (perp=9.487, rec=0.140, cos=0.003), tot_loss_proj:2.753 [t=0.26s]
prediction: ['[CLS] riff pictorial incidently balance rhythms with real ab having local ab. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.878 (perp=8.685, rec=0.137, cos=0.003), tot_loss_proj:2.919 [t=0.26s]
prediction: ['[CLS] riff real incidently balance ab with real ab having local rhythms. [SEP]']
[1200/2000] tot_loss=1.931 (perp=8.974, rec=0.133, cos=0.003), tot_loss_proj:3.050 [t=0.25s]
prediction: ['[CLS] riff real incidently balance ab with real ab happened local rhythms. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.829 (perp=8.475, rec=0.131, cos=0.003), tot_loss_proj:2.913 [t=0.25s]
prediction: ['[CLS] riff real incident ably balance with real ab happened local rhythms. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.863 (perp=8.601, rec=0.139, cos=0.004), tot_loss_proj:2.785 [t=0.25s]
prediction: ['[CLS]ignant real incident balance ably with real ab happened local rhythms. [SEP]']
[1350/2000] tot_loss=1.743 (perp=8.072, rec=0.125, cos=0.003), tot_loss_proj:3.399 [t=0.26s]
prediction: ['[CLS] riff real incident balance ably with real ab happened minor rhythms. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.733 (perp=7.992, rec=0.131, cos=0.003), tot_loss_proj:2.963 [t=0.25s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened local rhythms. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.719 (perp=7.992, rec=0.118, cos=0.003), tot_loss_proj:2.962 [t=0.26s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened local rhythms. [SEP]']
[1500/2000] tot_loss=1.737 (perp=7.992, rec=0.136, cos=0.003), tot_loss_proj:2.959 [t=0.27s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened local rhythms. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.682 (perp=7.724, rec=0.134, cos=0.003), tot_loss_proj:3.390 [t=0.26s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened minor rhythms. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.664 (perp=7.724, rec=0.117, cos=0.003), tot_loss_proj:3.397 [t=0.26s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened minor rhythms. [SEP]']
[1650/2000] tot_loss=1.675 (perp=7.724, rec=0.127, cos=0.003), tot_loss_proj:3.392 [t=0.25s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened minor rhythms. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.668 (perp=7.724, rec=0.120, cos=0.003), tot_loss_proj:3.390 [t=0.26s]
prediction: ['[CLS] riff real ab balance incidently with real ab happened minor rhythms. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.842 (perp=8.600, rec=0.119, cos=0.003), tot_loss_proj:3.531 [t=0.26s]
prediction: ['[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]']
[1800/2000] tot_loss=1.843 (perp=8.600, rec=0.120, cos=0.003), tot_loss_proj:3.529 [t=0.26s]
prediction: ['[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.853 (perp=8.600, rec=0.130, cos=0.003), tot_loss_proj:3.529 [t=0.25s]
prediction: ['[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.842 (perp=8.600, rec=0.120, cos=0.003), tot_loss_proj:3.529 [t=0.24s]
prediction: ['[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]']
[1950/2000] tot_loss=1.843 (perp=8.600, rec=0.121, cos=0.003), tot_loss_proj:3.527 [t=0.26s]
prediction: ['[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.836 (perp=8.600, rec=0.113, cos=0.003), tot_loss_proj:3.529 [t=0.25s]
prediction: ['[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] investigation real ab balance incidently with real ab happened minor rhythms. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 43.478 | p: 38.462 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 34.783 | p: 30.769 | r: 40.000
rougeLsum  | fm: 34.783 | p: 30.769 | r: 40.000
r1fm+r2fm = 43.478

[Aggregate metrics]:
rouge1     | fm: 90.217 | p: 89.224 | r: 91.450
rouge2     | fm: 68.643 | p: 68.608 | r: 68.684
rougeL     | fm: 82.938 | p: 82.191 | r: 83.723
rougeLsum  | fm: 83.465 | p: 82.797 | r: 84.329
r1fm+r2fm = 158.860

input #10 time: 0:10:51 | total time: 1:08:30


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
*********************************
*********************************
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9119930863380432 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9002856016159058 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8241632580757141 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8143832683563232 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.8102236986160278 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.8092162609100342 for ['[CLS] inlandture drawngu platform tal familiar mevd mile [SEP]']
[Init] best perm rec loss: 0.8080193400382996 for ['[CLS] inland mevdgu mile tal drawn familiarture platform [SEP]']
[Init] best perm rec loss: 0.8064080476760864 for ['[CLS] inland me milevd platformture familiar talgu drawn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=10.238, rec=0.304, cos=0.027), tot_loss_proj:3.416 [t=0.30s]
prediction: ['[CLS] that attempted gel that refused was refused gel （ refused [SEP]']
[ 100/2000] tot_loss=2.268 (perp=10.415, rec=0.177, cos=0.008), tot_loss_proj:3.027 [t=0.29s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel attempted stubborn [SEP]']
[ 150/2000] tot_loss=2.253 (perp=10.660, rec=0.118, cos=0.003), tot_loss_proj:2.941 [t=0.29s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel here stubborn [SEP]']
[ 200/2000] tot_loss=2.226 (perp=10.660, rec=0.091, cos=0.002), tot_loss_proj:2.948 [t=0.28s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel here stubborn [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.807 (perp=8.529, rec=0.099, cos=0.002), tot_loss_proj:2.102 [t=0.29s]
prediction: ['[CLS] was attempted here that stubbornly refused to gel stubborn [SEP]']
[ 300/2000] tot_loss=1.794 (perp=8.529, rec=0.086, cos=0.002), tot_loss_proj:2.113 [t=0.29s]
prediction: ['[CLS] was attempted here that stubbornly refused to gel stubborn [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.445 (perp=6.849, rec=0.074, cos=0.001), tot_loss_proj:1.499 [t=0.30s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.439 (perp=6.849, rec=0.068, cos=0.001), tot_loss_proj:1.502 [t=0.28s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[ 450/2000] tot_loss=1.445 (perp=6.849, rec=0.073, cos=0.001), tot_loss_proj:1.502 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.438 (perp=6.849, rec=0.067, cos=0.001), tot_loss_proj:1.498 [t=0.28s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.437 (perp=6.849, rec=0.066, cos=0.001), tot_loss_proj:1.494 [t=0.28s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[ 600/2000] tot_loss=1.436 (perp=6.849, rec=0.065, cos=0.001), tot_loss_proj:1.501 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.441 (perp=6.849, rec=0.070, cos=0.001), tot_loss_proj:1.509 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.431 (perp=6.849, rec=0.060, cos=0.001), tot_loss_proj:1.492 [t=0.31s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[ 750/2000] tot_loss=1.431 (perp=6.849, rec=0.060, cos=0.001), tot_loss_proj:1.500 [t=0.27s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.438 (perp=6.849, rec=0.067, cos=0.001), tot_loss_proj:1.496 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.435 (perp=6.849, rec=0.064, cos=0.001), tot_loss_proj:1.489 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[ 900/2000] tot_loss=1.432 (perp=6.849, rec=0.061, cos=0.001), tot_loss_proj:1.495 [t=0.28s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.433 (perp=6.849, rec=0.062, cos=0.001), tot_loss_proj:1.491 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.434 (perp=6.849, rec=0.063, cos=0.001), tot_loss_proj:1.487 [t=0.30s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1050/2000] tot_loss=1.440 (perp=6.849, rec=0.068, cos=0.001), tot_loss_proj:1.497 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.443 (perp=6.849, rec=0.072, cos=0.001), tot_loss_proj:1.502 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.432 (perp=6.849, rec=0.061, cos=0.001), tot_loss_proj:1.498 [t=0.30s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.438 (perp=6.849, rec=0.067, cos=0.001), tot_loss_proj:1.497 [t=0.28s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.431 (perp=6.849, rec=0.060, cos=0.001), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.431 (perp=6.849, rec=0.060, cos=0.001), tot_loss_proj:1.491 [t=0.27s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.437 (perp=6.849, rec=0.066, cos=0.001), tot_loss_proj:1.498 [t=0.29s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.441 (perp=6.849, rec=0.070, cos=0.001), tot_loss_proj:1.497 [t=0.27s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.433 (perp=6.849, rec=0.062, cos=0.001), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.435 (perp=6.849, rec=0.064, cos=0.001), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.429 (perp=6.849, rec=0.058, cos=0.001), tot_loss_proj:1.498 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.430 (perp=6.849, rec=0.059, cos=0.001), tot_loss_proj:1.503 [t=0.26s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.438 (perp=6.849, rec=0.067, cos=0.001), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.439 (perp=6.849, rec=0.068, cos=0.001), tot_loss_proj:1.502 [t=0.28s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.437 (perp=6.849, rec=0.066, cos=0.001), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.433 (perp=6.849, rec=0.062, cos=0.001), tot_loss_proj:1.498 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.849, rec=0.061, cos=0.001), tot_loss_proj:1.499 [t=0.26s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.436 (perp=6.849, rec=0.065, cos=0.001), tot_loss_proj:1.506 [t=0.27s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.849, rec=0.066, cos=0.001), tot_loss_proj:1.502 [t=0.25s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.433 (perp=6.849, rec=0.062, cos=0.001), tot_loss_proj:1.498 [t=0.24s]
prediction: ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.123 | p: 90.311 | r: 92.163
rouge2     | fm: 71.515 | p: 71.389 | r: 71.667
rougeL     | fm: 84.843 | p: 84.231 | r: 85.397
rougeLsum  | fm: 84.903 | p: 84.295 | r: 85.675
r1fm+r2fm = 162.638

input #11 time: 0:11:44 | total time: 1:20:15


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
*********************************
*********************************
average of cosine similarity 0.9993439176315202
highest_index [0]
highest [0.9993439176315202]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.867132842540741 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.861339807510376 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799628496170044 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7725229263305664 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7675877213478088 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.743887186050415 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7403388023376465 for ['[CLS] ha guess shades margin office series bethitasyn few victor laynction translate [SEP]']
[Init] best perm rec loss: 0.7387611269950867 for ['[CLS] guess beth ha few series shadesitas translate office marginnction layyn victor [SEP]']
[Init] best perm rec loss: 0.7375137805938721 for ['[CLS]nction translate few victor beth office margin series shades haitas guessyn lay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.133 (perp=9.226, rec=0.257, cos=0.031), tot_loss_proj:2.738 [t=0.25s]
prediction: ['[CLS] cable cable barely better to advantage advantage as would to exceptional cable rule cable [SEP]']
[ 100/2000] tot_loss=2.245 (perp=10.247, rec=0.173, cos=0.023), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS] cable cable barely better to seen advantage on will its especially cable internal cable [SEP]']
[ 150/2000] tot_loss=2.180 (perp=10.102, rec=0.148, cos=0.011), tot_loss_proj:2.886 [t=0.26s]
prediction: ['[CLS] cable its barely better to seen advantage on will its especially cable internal cable [SEP]']
[ 200/2000] tot_loss=2.222 (perp=10.450, rec=0.125, cos=0.008), tot_loss_proj:3.161 [t=0.25s]
prediction: ['[CLS] cable on barely better to seen advantage on will its especially cable its especially [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.002 (perp=9.440, rec=0.107, cos=0.007), tot_loss_proj:2.727 [t=0.26s]
prediction: ['[CLS] especially on barely better to seen advantage on will its especially cable its cable [SEP]']
[ 300/2000] tot_loss=2.038 (perp=9.707, rec=0.091, cos=0.005), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its especially cable its cable [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.932 (perp=9.227, rec=0.083, cos=0.004), tot_loss_proj:2.792 [t=0.28s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its that especially its cable [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.838 (perp=8.800, rec=0.075, cos=0.003), tot_loss_proj:2.757 [t=0.28s]
prediction: ['[CLS] especially on barely better to seen advantage considering its will that especially its cable [SEP]']
[ 450/2000] tot_loss=1.840 (perp=8.800, rec=0.077, cos=0.003), tot_loss_proj:2.750 [t=0.27s]
prediction: ['[CLS] especially on barely better to seen advantage considering its will that especially its cable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.794 (perp=8.592, rec=0.073, cos=0.003), tot_loss_proj:2.747 [t=0.30s]
prediction: ['[CLS] especially on barely seen to better advantage considering its will that especially its cable [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.800 (perp=8.592, rec=0.079, cos=0.003), tot_loss_proj:2.743 [t=0.28s]
prediction: ['[CLS] especially on barely seen to better advantage considering its will that especially its cable [SEP]']
[ 600/2000] tot_loss=1.790 (perp=8.592, rec=0.069, cos=0.003), tot_loss_proj:2.741 [t=0.28s]
prediction: ['[CLS] especially on barely seen to better advantage considering its will that especially its cable [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.715 (perp=8.148, rec=0.082, cos=0.003), tot_loss_proj:2.590 [t=0.30s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.705 (perp=8.148, rec=0.072, cos=0.003), tot_loss_proj:2.591 [t=0.29s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
[ 750/2000] tot_loss=1.702 (perp=8.148, rec=0.069, cos=0.003), tot_loss_proj:2.582 [t=0.30s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.711 (perp=8.148, rec=0.079, cos=0.003), tot_loss_proj:2.584 [t=0.29s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.703 (perp=8.148, rec=0.070, cos=0.003), tot_loss_proj:2.581 [t=0.30s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
[ 900/2000] tot_loss=1.706 (perp=8.148, rec=0.074, cos=0.003), tot_loss_proj:2.581 [t=0.30s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.704 (perp=8.148, rec=0.072, cos=0.003), tot_loss_proj:2.577 [t=0.29s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
Attempt swap
[1000/2000] tot_loss=1.705 (perp=8.148, rec=0.072, cos=0.003), tot_loss_proj:2.582 [t=0.29s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
[1050/2000] tot_loss=1.700 (perp=8.148, rec=0.068, cos=0.003), tot_loss_proj:2.575 [t=0.29s]
prediction: ['[CLS] especially seen barely on to better advantage considering its will that especially its cable [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.684 (perp=8.056, rec=0.070, cos=0.003), tot_loss_proj:2.383 [t=0.28s]
prediction: ['[CLS] especially seen barely on to better advantage its will considering that especially its cable [SEP]']
Attempt swap
[1150/2000] tot_loss=1.682 (perp=8.056, rec=0.068, cos=0.003), tot_loss_proj:2.381 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will considering that especially its cable [SEP]']
[1200/2000] tot_loss=1.689 (perp=8.056, rec=0.075, cos=0.003), tot_loss_proj:2.385 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will considering that especially its cable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.686 (perp=8.056, rec=0.072, cos=0.003), tot_loss_proj:2.381 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will considering that especially its cable [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.643 (perp=7.839, rec=0.072, cos=0.003), tot_loss_proj:2.308 [t=0.24s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
[1350/2000] tot_loss=1.648 (perp=7.839, rec=0.078, cos=0.003), tot_loss_proj:2.311 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.640 (perp=7.839, rec=0.069, cos=0.003), tot_loss_proj:2.313 [t=0.28s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1450/2000] tot_loss=1.644 (perp=7.839, rec=0.073, cos=0.003), tot_loss_proj:2.303 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
[1500/2000] tot_loss=1.637 (perp=7.839, rec=0.067, cos=0.003), tot_loss_proj:2.308 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.640 (perp=7.839, rec=0.070, cos=0.003), tot_loss_proj:2.309 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=7.839, rec=0.073, cos=0.003), tot_loss_proj:2.311 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
[1650/2000] tot_loss=1.645 (perp=7.839, rec=0.074, cos=0.003), tot_loss_proj:2.306 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.644 (perp=7.839, rec=0.074, cos=0.003), tot_loss_proj:2.308 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.646 (perp=7.839, rec=0.075, cos=0.003), tot_loss_proj:2.310 [t=0.28s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
[1800/2000] tot_loss=1.643 (perp=7.839, rec=0.072, cos=0.003), tot_loss_proj:2.307 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.641 (perp=7.839, rec=0.070, cos=0.003), tot_loss_proj:2.305 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.647 (perp=7.839, rec=0.076, cos=0.003), tot_loss_proj:2.305 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
[1950/2000] tot_loss=1.648 (perp=7.839, rec=0.077, cos=0.003), tot_loss_proj:2.312 [t=0.25s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.642 (perp=7.839, rec=0.071, cos=0.003), tot_loss_proj:2.308 [t=0.26s]
prediction: ['[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] especially seen barely on to better advantage its will especially considering that its cable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 20.690 | p: 20.000 | r: 21.429
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 111.012

[Aggregate metrics]:
rouge1     | fm: 91.396 | p: 90.343 | r: 92.637
rouge2     | fm: 67.311 | p: 67.200 | r: 67.438
rougeL     | fm: 82.393 | p: 81.657 | r: 83.333
rougeLsum  | fm: 82.393 | p: 81.598 | r: 83.187
r1fm+r2fm = 158.707

input #12 time: 0:11:24 | total time: 1:31:40


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
*********************************
*********************************
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8887738585472107 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8844950199127197 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8545551896095276 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7818396091461182 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7813502550125122 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7700784802436829 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7579190731048584 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7517123222351074 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 0.7473309636116028 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7472784519195557 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 0.7453463077545166 for ['[CLS] cardinal arm defeat rowe permanent precisionional [SEP]']
[Init] best perm rec loss: 0.7436425089836121 for ['[CLS]ional precision arm cardinal permanent rowe defeat [SEP]']
[Init] best perm rec loss: 0.7426804900169373 for ['[CLS] rowe cardinal defeat armional permanent precision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.506 (perp=10.953, rec=0.271, cos=0.044), tot_loss_proj:3.438 [t=0.25s]
prediction: ['[CLS] point flame flame entity explode contract point [SEP]']
[ 100/2000] tot_loss=2.480 (perp=11.578, rec=0.156, cos=0.008), tot_loss_proj:3.300 [t=0.26s]
prediction: ['[CLS] at flame flame things into explode point [SEP]']
[ 150/2000] tot_loss=2.430 (perp=11.578, rec=0.109, cos=0.005), tot_loss_proj:3.322 [t=0.26s]
prediction: ['[CLS] at flame flame things into explode point [SEP]']
[ 200/2000] tot_loss=2.421 (perp=11.578, rec=0.102, cos=0.003), tot_loss_proj:3.325 [t=0.26s]
prediction: ['[CLS] at flame flame things into explode point [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.984 (perp=9.280, rec=0.119, cos=0.008), tot_loss_proj:2.831 [t=0.26s]
prediction: ['[CLS] into flame flame things at explode point [SEP]']
[ 300/2000] tot_loss=1.948 (perp=9.258, rec=0.093, cos=0.004), tot_loss_proj:2.719 [t=0.24s]
prediction: ['[CLS] into flame things things at explode point [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.694 (perp=8.038, rec=0.085, cos=0.002), tot_loss_proj:2.766 [t=0.26s]
prediction: ['[CLS] things flame into things at explode point [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.433 (perp=6.767, rec=0.077, cos=0.002), tot_loss_proj:2.477 [t=0.27s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[ 450/2000] tot_loss=1.424 (perp=6.767, rec=0.069, cos=0.002), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.428 (perp=6.767, rec=0.073, cos=0.002), tot_loss_proj:2.481 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.423 (perp=6.767, rec=0.068, cos=0.002), tot_loss_proj:2.474 [t=0.27s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[ 600/2000] tot_loss=1.426 (perp=6.767, rec=0.071, cos=0.002), tot_loss_proj:2.468 [t=0.26s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.422 (perp=6.767, rec=0.067, cos=0.002), tot_loss_proj:2.469 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.419 (perp=6.767, rec=0.064, cos=0.002), tot_loss_proj:2.475 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[ 750/2000] tot_loss=1.421 (perp=6.767, rec=0.066, cos=0.002), tot_loss_proj:2.475 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.418 (perp=6.767, rec=0.063, cos=0.002), tot_loss_proj:2.474 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.419 (perp=6.767, rec=0.064, cos=0.002), tot_loss_proj:2.476 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[ 900/2000] tot_loss=1.420 (perp=6.767, rec=0.065, cos=0.002), tot_loss_proj:2.474 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.424 (perp=6.767, rec=0.069, cos=0.002), tot_loss_proj:2.470 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1000/2000] tot_loss=1.421 (perp=6.767, rec=0.066, cos=0.002), tot_loss_proj:2.473 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1050/2000] tot_loss=1.424 (perp=6.767, rec=0.069, cos=0.002), tot_loss_proj:2.472 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1100/2000] tot_loss=1.409 (perp=6.767, rec=0.054, cos=0.002), tot_loss_proj:2.464 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1150/2000] tot_loss=1.418 (perp=6.767, rec=0.063, cos=0.002), tot_loss_proj:2.467 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1200/2000] tot_loss=1.425 (perp=6.767, rec=0.070, cos=0.002), tot_loss_proj:2.469 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1250/2000] tot_loss=1.424 (perp=6.767, rec=0.069, cos=0.002), tot_loss_proj:2.473 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1300/2000] tot_loss=1.418 (perp=6.767, rec=0.063, cos=0.002), tot_loss_proj:2.467 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1350/2000] tot_loss=1.424 (perp=6.767, rec=0.069, cos=0.002), tot_loss_proj:2.466 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1400/2000] tot_loss=1.423 (perp=6.767, rec=0.068, cos=0.002), tot_loss_proj:2.466 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1450/2000] tot_loss=1.422 (perp=6.767, rec=0.068, cos=0.002), tot_loss_proj:2.461 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1500/2000] tot_loss=1.422 (perp=6.767, rec=0.067, cos=0.002), tot_loss_proj:2.469 [t=0.20s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1550/2000] tot_loss=1.419 (perp=6.767, rec=0.064, cos=0.002), tot_loss_proj:2.466 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1600/2000] tot_loss=1.412 (perp=6.767, rec=0.058, cos=0.002), tot_loss_proj:2.465 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1650/2000] tot_loss=1.429 (perp=6.767, rec=0.074, cos=0.002), tot_loss_proj:2.473 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1700/2000] tot_loss=1.417 (perp=6.767, rec=0.062, cos=0.002), tot_loss_proj:2.471 [t=0.27s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1750/2000] tot_loss=1.416 (perp=6.767, rec=0.061, cos=0.002), tot_loss_proj:2.469 [t=0.27s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1800/2000] tot_loss=1.414 (perp=6.767, rec=0.060, cos=0.002), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.767, rec=0.079, cos=0.002), tot_loss_proj:2.474 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[1900/2000] tot_loss=1.416 (perp=6.767, rec=0.061, cos=0.002), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
[1950/2000] tot_loss=1.420 (perp=6.767, rec=0.065, cos=0.002), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Attempt swap
[2000/2000] tot_loss=1.414 (perp=6.767, rec=0.059, cos=0.002), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] things flame into explode at that point [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] things flame into explode at that point [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 91.925 | p: 90.964 | r: 92.857
rouge2     | fm: 62.438 | p: 62.290 | r: 62.570
rougeL     | fm: 79.572 | p: 78.874 | r: 80.317
rougeLsum  | fm: 79.731 | p: 79.162 | r: 80.584
r1fm+r2fm = 154.364

input #13 time: 0:09:45 | total time: 1:41:26


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
*********************************
*********************************
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9556125998497009 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9368494749069214 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9233089089393616 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9153460264205933 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9128281474113464 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8928517699241638 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8734212517738342 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720963597297668 for ['[CLS] myers sprayed harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720387816429138 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8698037266731262 for ['[CLS] tom [MASK] harold myers sprayed [SEP]']
[Init] best perm rec loss: 0.8688009977340698 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.659 (perp=12.090, rec=0.237, cos=0.005), tot_loss_proj:2.776 [t=0.25s]
prediction: ['[CLS] intriguingbly genuinely film film [SEP]']
[ 100/2000] tot_loss=2.804 (perp=13.344, rec=0.133, cos=0.002), tot_loss_proj:3.716 [t=0.26s]
prediction: ['[CLS] intriguingblyenia film film [SEP]']
[ 150/2000] tot_loss=2.769 (perp=13.344, rec=0.098, cos=0.002), tot_loss_proj:3.705 [t=0.25s]
prediction: ['[CLS] intriguingblyenia film film [SEP]']
[ 200/2000] tot_loss=2.762 (perp=13.344, rec=0.091, cos=0.002), tot_loss_proj:3.715 [t=0.25s]
prediction: ['[CLS] intriguingblyenia film film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.897 (perp=8.954, rec=0.104, cos=0.002), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] intriguing filmeniably film [SEP]']
[ 300/2000] tot_loss=1.888 (perp=8.954, rec=0.095, cos=0.002), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.768 (perp=8.412, rec=0.084, cos=0.002), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] filmeniably intriguing film [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.101 (perp=10.074, rec=0.085, cos=0.002), tot_loss_proj:2.365 [t=0.25s]
prediction: ['[CLS] film filmeniably intriguing [SEP]']
[ 450/2000] tot_loss=1.579 (perp=7.446, rec=0.088, cos=0.002), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] film undeniably intriguing [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.409 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.405 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.405 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.403 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.411 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.410 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.399 (perp=6.728, rec=0.052, cos=0.001), tot_loss_proj:1.399 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.404 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.408 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.408 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.405 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.419 (perp=6.728, rec=0.072, cos=0.001), tot_loss_proj:1.401 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.416 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.412 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.404 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.402 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.404 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.408 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.403 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.398 (perp=6.728, rec=0.051, cos=0.001), tot_loss_proj:1.410 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.409 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.398 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.409 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.405 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.393 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.405 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.399 (perp=6.728, rec=0.052, cos=0.001), tot_loss_proj:1.413 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.403 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.401 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.402 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.557 | p: 91.731 | r: 93.333
rouge2     | fm: 65.003 | p: 64.906 | r: 65.113
rougeL     | fm: 80.937 | p: 80.320 | r: 81.587
rougeLsum  | fm: 80.913 | p: 80.283 | r: 81.630
r1fm+r2fm = 157.560

input #14 time: 0:10:48 | total time: 1:52:14


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
*********************************
*********************************
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9709395170211792 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9276955127716064 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9179652333259583 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9067785143852234 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9063056707382202 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8998844623565674 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8911759257316589 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8846814036369324 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8817172050476074 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8800804018974304 for ['[CLS] easily first olivia metaphor fetch 0 humanities sweden [SEP]']
[Init] best perm rec loss: 0.879218578338623 for ['[CLS] easily sweden humanities first olivia 0 fetch metaphor [SEP]']
[Init] best perm rec loss: 0.879126250743866 for ['[CLS] easily sweden humanities 0 olivia first fetch metaphor [SEP]']
[Init] best perm rec loss: 0.8768956065177917 for ['[CLS] fetch humanities first 0 sweden olivia easily metaphor [SEP]']
[Init] best perm rec loss: 0.8764843344688416 for ['[CLS] 0 first humanities sweden olivia metaphor easily fetch [SEP]']
[Init] best perm rec loss: 0.8753165006637573 for ['[CLS] 0 sweden fetch metaphor humanities olivia first easily [SEP]']
[Init] best perm rec loss: 0.8751561641693115 for ['[CLS] metaphor 0 first humanities sweden olivia easily fetch [SEP]']
[Init] best perm rec loss: 0.8732092976570129 for ['[CLS] metaphor first sweden fetch 0 easily olivia humanities [SEP]']
[Init] best perm rec loss: 0.8722246885299683 for ['[CLS] first easily 0 sweden metaphor olivia humanities fetch [SEP]']
[Init] best perm rec loss: 0.8716493844985962 for ['[CLS] metaphor humanities first sweden olivia fetch easily 0 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.867 (perp=12.962, rec=0.265, cos=0.009), tot_loss_proj:3.551 [t=0.25s]
prediction: ['[CLS] solid intendedably efficient suit meet suit pink [SEP]']
[ 100/2000] tot_loss=2.739 (perp=12.664, rec=0.199, cos=0.007), tot_loss_proj:4.235 [t=0.25s]
prediction: ['[CLS] chill acceptableably efficienter chill suit chill [SEP]']
[ 150/2000] tot_loss=2.992 (perp=14.260, rec=0.134, cos=0.005), tot_loss_proj:4.612 [t=0.26s]
prediction: ['[CLS] chill anonymousably efficienter chill suit chill [SEP]']
[ 200/2000] tot_loss=2.897 (perp=13.852, rec=0.122, cos=0.004), tot_loss_proj:4.415 [t=0.26s]
prediction: ['[CLS]stein anonymousably efficienter chill suit chill [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.223 (perp=10.534, rec=0.112, cos=0.004), tot_loss_proj:2.824 [t=0.25s]
prediction: ['[CLS]. anonymousably efficient chill chill suiter [SEP]']
[ 300/2000] tot_loss=2.194 (perp=10.534, rec=0.085, cos=0.002), tot_loss_proj:2.807 [t=0.27s]
prediction: ['[CLS]. anonymousably efficient chill chill suiter [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.050 (perp=9.824, rec=0.083, cos=0.002), tot_loss_proj:2.698 [t=0.28s]
prediction: ['[CLS]. anonymousably efficient chill chiller suit [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.921 (perp=9.196, rec=0.080, cos=0.002), tot_loss_proj:2.411 [t=0.24s]
prediction: ['[CLS]ably anonymous. efficient chill chiller suit [SEP]']
[ 450/2000] tot_loss=1.921 (perp=9.196, rec=0.080, cos=0.002), tot_loss_proj:2.410 [t=0.25s]
prediction: ['[CLS]ably anonymous. efficient chill chiller suit [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.799 (perp=8.576, rec=0.082, cos=0.002), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] suitably anonymous. efficient anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.637 (perp=7.676, rec=0.100, cos=0.002), tot_loss_proj:1.771 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[ 600/2000] tot_loss=1.612 (perp=7.676, rec=0.075, cos=0.002), tot_loss_proj:1.773 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.764 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.675 (perp=7.817, rec=0.109, cos=0.003), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] anonymous suitably efficient, anonymous chiller [SEP]']
[ 750/2000] tot_loss=1.544 (perp=7.271, rec=0.088, cos=0.002), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS]. suitably efficient, anonymous chiller [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=1.421 (perp=6.697, rec=0.080, cos=0.002), tot_loss_proj:1.512 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.666 (perp=7.910, rec=0.082, cos=0.002), tot_loss_proj:1.887 [t=0.28s]
prediction: ['[CLS] suitably efficient,. anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.627 (perp=7.676, rec=0.090, cos=0.002), tot_loss_proj:1.773 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.616 (perp=7.676, rec=0.079, cos=0.002), tot_loss_proj:1.773 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.627 (perp=7.676, rec=0.090, cos=0.002), tot_loss_proj:1.777 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1050/2000] tot_loss=1.615 (perp=7.676, rec=0.078, cos=0.002), tot_loss_proj:1.773 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.610 (perp=7.676, rec=0.073, cos=0.002), tot_loss_proj:1.771 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1150/2000] tot_loss=1.614 (perp=7.676, rec=0.077, cos=0.002), tot_loss_proj:1.768 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1200/2000] tot_loss=1.638 (perp=7.811, rec=0.074, cos=0.002), tot_loss_proj:1.869 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous. chiller [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.414 (perp=6.697, rec=0.073, cos=0.002), tot_loss_proj:1.521 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.417 (perp=6.697, rec=0.076, cos=0.002), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.424 (perp=6.697, rec=0.083, cos=0.002), tot_loss_proj:1.515 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.420 (perp=6.697, rec=0.079, cos=0.002), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.002), tot_loss_proj:1.515 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.421 (perp=6.697, rec=0.080, cos=0.002), tot_loss_proj:1.514 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.002), tot_loss_proj:1.508 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.002), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.002), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.416 (perp=6.697, rec=0.075, cos=0.002), tot_loss_proj:1.515 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.002), tot_loss_proj:1.518 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.002), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.416 (perp=6.697, rec=0.075, cos=0.002), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.406 (perp=6.697, rec=0.065, cos=0.002), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.002), tot_loss_proj:1.511 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.002), tot_loss_proj:1.504 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 93.207 | p: 92.248 | r: 94.077
rouge2     | fm: 63.440 | p: 63.350 | r: 63.543
rougeL     | fm: 81.280 | p: 80.695 | r: 81.999
rougeLsum  | fm: 81.168 | p: 80.604 | r: 81.865
r1fm+r2fm = 156.647

input #15 time: 0:10:52 | total time: 2:03:06


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
*********************************
*********************************
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.018147349357605 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9020346403121948 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7366529107093811 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7362502217292786 for ['[CLS]athi alta lord film slowly various [SEP]']
[Init] best perm rec loss: 0.7362011075019836 for ['[CLS] lord slowly film variousathi alta [SEP]']
[Init] best perm rec loss: 0.7361390590667725 for ['[CLS] various slowly film lordathi alta [SEP]']
[Init] best perm rec loss: 0.7351789474487305 for ['[CLS]athi alta lord slowly various film [SEP]']
[Init] best perm rec loss: 0.7351776957511902 for ['[CLS] various film lord slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7336527705192566 for ['[CLS] various film lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.419 (perp=12.256, rec=0.595, cos=0.373), tot_loss_proj:4.073 [t=0.24s]
prediction: ['[CLS] rope up bedroom christmas county you [SEP]']
[ 100/2000] tot_loss=3.224 (perp=12.711, rec=0.478, cos=0.204), tot_loss_proj:3.976 [t=0.26s]
prediction: ['[CLS] rope up latest christmas county you [SEP]']
[ 150/2000] tot_loss=2.611 (perp=10.619, rec=0.400, cos=0.087), tot_loss_proj:3.563 [t=0.26s]
prediction: ['[CLS] brian all data christmas more everything [SEP]']
[ 200/2000] tot_loss=2.283 (perp=9.583, rec=0.320, cos=0.046), tot_loss_proj:3.169 [t=0.26s]
prediction: ['[CLS] her all data christmas more that [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.326 (perp=10.135, rec=0.266, cos=0.034), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] her all data christmas more this [SEP]']
[ 300/2000] tot_loss=1.981 (perp=8.677, rec=0.216, cos=0.030), tot_loss_proj:3.042 [t=0.25s]
prediction: ['[CLS] her all data christmas of this [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.944 (perp=8.611, rec=0.195, cos=0.028), tot_loss_proj:3.146 [t=0.25s]
prediction: ['[CLS] data all her christmas of this [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.917 (perp=8.507, rec=0.190, cos=0.026), tot_loss_proj:3.224 [t=0.28s]
prediction: ['[CLS] data all more christmas of this [SEP]']
[ 450/2000] tot_loss=1.917 (perp=8.507, rec=0.191, cos=0.025), tot_loss_proj:3.220 [t=0.29s]
prediction: ['[CLS] data all more christmas of this [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.594 (perp=6.918, rec=0.185, cos=0.026), tot_loss_proj:2.561 [t=0.25s]
prediction: ['[CLS] later all more of this christmas [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.389 (perp=5.862, rec=0.192, cos=0.025), tot_loss_proj:2.069 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
[ 600/2000] tot_loss=1.369 (perp=5.862, rec=0.173, cos=0.024), tot_loss_proj:2.060 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.373 (perp=5.862, rec=0.178, cos=0.023), tot_loss_proj:2.067 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.367 (perp=5.862, rec=0.172, cos=0.023), tot_loss_proj:2.063 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
[ 750/2000] tot_loss=1.361 (perp=5.862, rec=0.167, cos=0.022), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.357 (perp=5.862, rec=0.163, cos=0.021), tot_loss_proj:2.065 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.355 (perp=5.862, rec=0.162, cos=0.020), tot_loss_proj:2.066 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
[ 900/2000] tot_loss=1.360 (perp=5.862, rec=0.168, cos=0.020), tot_loss_proj:2.069 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.355 (perp=5.862, rec=0.164, cos=0.019), tot_loss_proj:2.063 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.352 (perp=5.862, rec=0.161, cos=0.019), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
[1050/2000] tot_loss=1.340 (perp=5.862, rec=0.151, cos=0.017), tot_loss_proj:2.074 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.346 (perp=5.862, rec=0.158, cos=0.015), tot_loss_proj:2.067 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.333 (perp=5.862, rec=0.146, cos=0.014), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
[1200/2000] tot_loss=1.326 (perp=5.862, rec=0.139, cos=0.014), tot_loss_proj:2.073 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.331 (perp=5.862, rec=0.145, cos=0.013), tot_loss_proj:2.072 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.326 (perp=5.862, rec=0.140, cos=0.013), tot_loss_proj:2.071 [t=0.29s]
prediction: ['[CLS] later all of this and more [SEP]']
[1350/2000] tot_loss=1.329 (perp=5.862, rec=0.143, cos=0.013), tot_loss_proj:2.072 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.320 (perp=5.862, rec=0.135, cos=0.013), tot_loss_proj:2.072 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.321 (perp=5.862, rec=0.136, cos=0.013), tot_loss_proj:2.069 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
[1500/2000] tot_loss=1.325 (perp=5.862, rec=0.140, cos=0.013), tot_loss_proj:2.066 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.335 (perp=5.862, rec=0.150, cos=0.012), tot_loss_proj:2.070 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.324 (perp=5.862, rec=0.139, cos=0.012), tot_loss_proj:2.066 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
[1650/2000] tot_loss=1.329 (perp=5.862, rec=0.144, cos=0.012), tot_loss_proj:2.070 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.323 (perp=5.862, rec=0.138, cos=0.012), tot_loss_proj:2.071 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.322 (perp=5.862, rec=0.137, cos=0.012), tot_loss_proj:2.066 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
[1800/2000] tot_loss=1.329 (perp=5.862, rec=0.144, cos=0.012), tot_loss_proj:2.068 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.315 (perp=5.862, rec=0.130, cos=0.012), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.322 (perp=5.862, rec=0.138, cos=0.012), tot_loss_proj:2.067 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
[1950/2000] tot_loss=1.319 (perp=5.862, rec=0.134, cos=0.012), tot_loss_proj:2.071 [t=0.25s]
prediction: ['[CLS] later all of this and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.320 (perp=5.862, rec=0.136, cos=0.012), tot_loss_proj:2.070 [t=0.27s]
prediction: ['[CLS] later all of this and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] later all of this and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 92.945 | p: 91.779 | r: 94.118
rouge2     | fm: 64.309 | p: 63.697 | r: 64.987
rougeL     | fm: 82.312 | p: 81.524 | r: 83.380
rougeLsum  | fm: 82.191 | p: 81.287 | r: 83.137
r1fm+r2fm = 157.254

input #16 time: 0:10:56 | total time: 2:14:03


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
*********************************
*********************************
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8486641645431519 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8205068111419678 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8189647197723389 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8072818517684937 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7922393679618835 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7693865895271301 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7615459561347961 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7598406076431274 for ['[CLS] meeting marius miss pressure greyuin i magazine saved lieutenant honestly [SEP]']
[Init] best perm rec loss: 0.7584831714630127 for ['[CLS] marius missuin lieutenant grey magazine honestly i saved meeting pressure [SEP]']
[Init] best perm rec loss: 0.7562015652656555 for ['[CLS] pressure marius honestly magazine saved meeting grey lieutenant iuin miss [SEP]']
[Init] best perm rec loss: 0.7561701536178589 for ['[CLS] i pressure marius lieutenant magazine miss greyuin meeting saved honestly [SEP]']
[Init] best perm rec loss: 0.7556576132774353 for ['[CLS]uin lieutenant honestly i pressure marius miss meeting grey saved magazine [SEP]']
[Init] best perm rec loss: 0.7535409927368164 for ['[CLS] i meetinguin pressure honestly magazine grey lieutenant marius saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.990 (perp=12.291, rec=0.402, cos=0.131), tot_loss_proj:3.878 [t=0.27s]
prediction: ['[CLS] too brain drawer case covered were problem put want bleak disappearance [SEP]']
[ 100/2000] tot_loss=2.441 (perp=11.111, rec=0.195, cos=0.024), tot_loss_proj:3.309 [t=0.29s]
prediction: ['[CLS] too much hitter too again much s about want think much [SEP]']
[ 150/2000] tot_loss=2.114 (perp=9.870, rec=0.132, cos=0.008), tot_loss_proj:3.006 [t=0.25s]
prediction: ['[CLS] too much enough too around much what about want think think [SEP]']
[ 200/2000] tot_loss=2.071 (perp=9.863, rec=0.095, cos=0.004), tot_loss_proj:2.892 [t=0.24s]
prediction: ['[CLS] too much on too going much what about want think think [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.865 (perp=8.718, rec=0.115, cos=0.006), tot_loss_proj:2.809 [t=0.26s]
prediction: ['[CLS] too much going to going much what about want on think [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.718, rec=0.089, cos=0.003), tot_loss_proj:2.818 [t=0.26s]
prediction: ['[CLS] too much going to going much what about want on think [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.566 (perp=7.400, rec=0.083, cos=0.003), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] too much going to what much going about want on think [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.718 (perp=8.248, rec=0.066, cos=0.003), tot_loss_proj:3.062 [t=0.26s]
prediction: ['[CLS] too what going to what much going on about want think [SEP]']
[ 450/2000] tot_loss=1.728 (perp=8.248, rec=0.076, cos=0.002), tot_loss_proj:3.056 [t=0.25s]
prediction: ['[CLS] too what going to what much going on about want think [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.706 (perp=8.116, rec=0.081, cos=0.002), tot_loss_proj:2.468 [t=0.25s]
prediction: ['[CLS] too much going to s what going on about want think [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.385 (perp=6.580, rec=0.066, cos=0.002), tot_loss_proj:2.084 [t=0.25s]
prediction: ['[CLS] too much going to what s going on about want think [SEP]']
[ 600/2000] tot_loss=1.386 (perp=6.580, rec=0.068, cos=0.002), tot_loss_proj:2.093 [t=0.25s]
prediction: ['[CLS] too much going to what s going on about want think [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.331 (perp=6.331, rec=0.063, cos=0.002), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] too much going to want what s going on about think [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.268 (perp=6.022, rec=0.062, cos=0.002), tot_loss_proj:2.505 [t=0.26s]
prediction: ['[CLS] too much going to want what s going on think about [SEP]']
[ 750/2000] tot_loss=1.266 (perp=6.022, rec=0.060, cos=0.002), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] too much going to want what s going on think about [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.280 (perp=6.022, rec=0.074, cos=0.002), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS] too much going to want what s going on think about [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.389 (perp=6.595, rec=0.069, cos=0.002), tot_loss_proj:2.303 [t=0.26s]
prediction: ['[CLS] too much emotionally to want what s going on think about [SEP]']
[ 900/2000] tot_loss=1.390 (perp=6.595, rec=0.069, cos=0.002), tot_loss_proj:2.305 [t=0.26s]
prediction: ['[CLS] too much emotionally to want what s going on think about [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.362 (perp=6.462, rec=0.068, cos=0.002), tot_loss_proj:2.172 [t=0.26s]
prediction: ['[CLS] too much to want emotionally what s going on think about [SEP]']
Attempt swap
[1000/2000] tot_loss=1.352 (perp=6.462, rec=0.058, cos=0.002), tot_loss_proj:2.167 [t=0.25s]
prediction: ['[CLS] too much to want emotionally what s going on think about [SEP]']
[1050/2000] tot_loss=1.368 (perp=6.462, rec=0.074, cos=0.002), tot_loss_proj:2.173 [t=0.27s]
prediction: ['[CLS] too much to want emotionally what s going on think about [SEP]']
Attempt swap
[1100/2000] tot_loss=1.359 (perp=6.462, rec=0.065, cos=0.002), tot_loss_proj:2.174 [t=0.27s]
prediction: ['[CLS] too much to want emotionally what s going on think about [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.312 (perp=6.239, rec=0.062, cos=0.002), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] too much to want what s going on think about emotionally [SEP]']
[1200/2000] tot_loss=1.319 (perp=6.239, rec=0.070, cos=0.002), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS] too much to want what s going on think about emotionally [SEP]']
Attempt swap
[1250/2000] tot_loss=1.316 (perp=6.239, rec=0.067, cos=0.002), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] too much to want what s going on think about emotionally [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.241 (perp=5.791, rec=0.080, cos=0.003), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] too much to want think about what s going on emotionally [SEP]']
[1350/2000] tot_loss=1.230 (perp=5.791, rec=0.070, cos=0.002), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] too much to want think about what s going on emotionally [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.064 (perp=4.939, rec=0.074, cos=0.002), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1450/2000] tot_loss=1.059 (perp=4.939, rec=0.070, cos=0.002), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
[1500/2000] tot_loss=1.059 (perp=4.939, rec=0.070, cos=0.002), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1550/2000] tot_loss=1.057 (perp=4.939, rec=0.068, cos=0.002), tot_loss_proj:1.714 [t=0.25s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1600/2000] tot_loss=1.062 (perp=4.939, rec=0.073, cos=0.002), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
[1650/2000] tot_loss=1.063 (perp=4.939, rec=0.074, cos=0.002), tot_loss_proj:1.711 [t=0.30s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1700/2000] tot_loss=1.059 (perp=4.939, rec=0.070, cos=0.002), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1750/2000] tot_loss=1.059 (perp=4.939, rec=0.069, cos=0.002), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
[1800/2000] tot_loss=1.052 (perp=4.939, rec=0.063, cos=0.002), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1850/2000] tot_loss=1.059 (perp=4.939, rec=0.069, cos=0.002), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[1900/2000] tot_loss=1.062 (perp=4.939, rec=0.073, cos=0.002), tot_loss_proj:1.715 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
[1950/2000] tot_loss=1.053 (perp=4.939, rec=0.064, cos=0.002), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Attempt swap
[2000/2000] tot_loss=1.060 (perp=4.939, rec=0.070, cos=0.002), tot_loss_proj:1.706 [t=0.24s]
prediction: ['[CLS] too much want to think about what s going on emotionally [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] too much want to think about what s going on emotionally [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 60.870 | p: 58.333 | r: 63.636
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 156.870

[Aggregate metrics]:
rouge1     | fm: 93.036 | p: 91.751 | r: 94.444
rouge2     | fm: 63.996 | p: 63.606 | r: 64.710
rougeL     | fm: 82.005 | p: 81.049 | r: 83.320
rougeLsum  | fm: 82.051 | p: 81.047 | r: 83.144
r1fm+r2fm = 157.032

input #17 time: 0:10:57 | total time: 2:25:00


Running input #18 of 100.
reference: 
========================
invigorating 
========================
*********************************
*********************************
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9796279072761536 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9423751831054688 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9344695806503296 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9258310198783875 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8895648717880249 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8812242150306702 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.869970977306366 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8667334318161011 for ['[CLS] middle away mc reserves [SEP]']
[Init] best rec loss: 0.8235080242156982 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8209102153778076 for ['[CLS]odle circle du dual [SEP]']
[Init] best perm rec loss: 0.8185354471206665 for ['[CLS] dual duodle circle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.090 (perp=9.278, rec=0.231, cos=0.004), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS]vigoratingating [SEP]']
[ 100/2000] tot_loss=2.350 (perp=10.971, rec=0.153, cos=0.003), tot_loss_proj:2.702 [t=0.25s]
prediction: ['[CLS]vigorgorating [SEP]']
[ 150/2000] tot_loss=2.294 (perp=10.971, rec=0.098, cos=0.002), tot_loss_proj:2.735 [t=0.26s]
prediction: ['[CLS]vigorgorating [SEP]']
[ 200/2000] tot_loss=1.942 (perp=9.401, rec=0.061, cos=0.001), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS]vi ingorating [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.180 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.177 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.187 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.175 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.184 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.169 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.190 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.167 (perp=5.588, rec=0.048, cos=0.001), tot_loss_proj:1.184 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.175 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.182 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.174 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.173 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.185 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.185 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.197 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.176 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.190 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.177 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.175 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.181 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.177 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.187 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.179 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.179 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.182 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.188 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.187 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.188 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.177 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.175 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.182 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.177 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.171 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.180 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.476 | p: 92.268 | r: 94.737
rouge2     | fm: 66.386 | p: 65.859 | r: 66.944
rougeL     | fm: 83.115 | p: 82.225 | r: 84.311
rougeLsum  | fm: 83.019 | p: 82.068 | r: 84.031
r1fm+r2fm = 159.862

input #18 time: 0:10:56 | total time: 2:35:56


Running input #19 of 100.
reference: 
========================
to infamy 
========================
*********************************
*********************************
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7703872323036194 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7632964253425598 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7431591749191284 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7254143357276917 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7071809768676758 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7017049789428711 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.688244640827179 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.680355966091156 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6743445992469788 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6420117020606995 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6395600438117981 for ['[CLS] reaching pin orderyna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.927 (perp=12.311, rec=0.362, cos=0.102), tot_loss_proj:3.739 [t=0.26s]
prediction: ['[CLS] alley education violent in [SEP]']
[ 100/2000] tot_loss=2.668 (perp=12.367, rec=0.184, cos=0.011), tot_loss_proj:3.833 [t=0.25s]
prediction: ['[CLS]mymy tofa [SEP]']
[ 150/2000] tot_loss=2.587 (perp=12.367, rec=0.111, cos=0.003), tot_loss_proj:3.859 [t=0.26s]
prediction: ['[CLS]mymy tofa [SEP]']
[ 200/2000] tot_loss=2.492 (perp=11.902, rec=0.097, cos=0.014), tot_loss_proj:3.998 [t=0.25s]
prediction: ['[CLS] inmy tofa [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.382 (perp=6.522, rec=0.074, cos=0.004), tot_loss_proj:1.748 [t=0.25s]
prediction: ['[CLS] infamy to [SEP]']
[ 300/2000] tot_loss=1.371 (perp=6.522, rec=0.066, cos=0.001), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.367 (perp=6.522, rec=0.061, cos=0.001), tot_loss_proj:1.739 [t=0.25s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.370 (perp=6.522, rec=0.064, cos=0.001), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] infamy to [SEP]']
[ 450/2000] tot_loss=1.379 (perp=6.522, rec=0.073, cos=0.001), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.378 (perp=6.522, rec=0.073, cos=0.001), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.377 (perp=6.522, rec=0.071, cos=0.001), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] infamy to [SEP]']
[ 600/2000] tot_loss=1.365 (perp=6.522, rec=0.060, cos=0.001), tot_loss_proj:1.752 [t=0.26s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.372 (perp=6.522, rec=0.066, cos=0.001), tot_loss_proj:1.745 [t=0.28s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
Put prefix at the end
[ 700/2000] tot_loss=1.285 (perp=6.110, rec=0.061, cos=0.002), tot_loss_proj:1.312 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.307 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.298 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.289 (perp=6.110, rec=0.065, cos=0.001), tot_loss_proj:1.294 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.302 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.304 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.313 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.314 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.298 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.282 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.298 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.286 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.305 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.291 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.285 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.299 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.293 (perp=6.110, rec=0.069, cos=0.001), tot_loss_proj:1.289 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.281 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.301 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.297 (perp=6.110, rec=0.074, cos=0.001), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.285 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.288 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.291 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.291 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.314 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.802 | p: 92.679 | r: 95.000
rouge2     | fm: 68.075 | p: 67.584 | r: 68.600
rougeL     | fm: 84.127 | p: 83.261 | r: 85.111
rougeLsum  | fm: 83.831 | p: 82.925 | r: 84.778
r1fm+r2fm = 161.877

input #19 time: 0:10:49 | total time: 2:46:46


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
*********************************
*********************************
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.813522219657898 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8018914461135864 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7928059697151184 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7927916049957275 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7916965484619141 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.765182614326477 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7627440690994263 for ['[CLS]pid poor forming african [SEP]']
[Init] best perm rec loss: 0.7611280083656311 for ['[CLS] african poor formingpid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=11.724, rec=0.349, cos=0.060), tot_loss_proj:3.702 [t=0.26s]
prediction: ['[CLS]verse [ pleasureverse [SEP]']
[ 100/2000] tot_loss=2.635 (perp=11.845, rec=0.235, cos=0.031), tot_loss_proj:4.078 [t=0.25s]
prediction: ['[CLS]verse her pleasureverse [SEP]']
[ 150/2000] tot_loss=2.425 (perp=10.923, rec=0.207, cos=0.033), tot_loss_proj:3.612 [t=0.25s]
prediction: ['[CLS]verse per pleasureverse [SEP]']
[ 200/2000] tot_loss=2.310 (perp=10.783, rec=0.139, cos=0.015), tot_loss_proj:3.313 [t=0.25s]
prediction: ['[CLS]verse the pleasure per [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.706 (perp=7.784, rec=0.137, cos=0.012), tot_loss_proj:1.931 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 300/2000] tot_loss=1.657 (perp=7.784, rec=0.096, cos=0.004), tot_loss_proj:1.948 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.606 (perp=7.610, rec=0.082, cos=0.002), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.600 (perp=7.610, rec=0.076, cos=0.002), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.595 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.740 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.610 (perp=7.610, rec=0.086, cos=0.002), tot_loss_proj:1.743 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.745 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.737 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.732 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.732 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.735 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.610, rec=0.071, cos=0.002), tot_loss_proj:1.743 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.592 (perp=7.610, rec=0.068, cos=0.002), tot_loss_proj:1.747 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.731 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.578 (perp=7.610, rec=0.054, cos=0.002), tot_loss_proj:1.741 [t=0.33s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.610, rec=0.074, cos=0.002), tot_loss_proj:1.729 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.734 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.728 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.731 [t=0.33s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.580 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.730 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.736 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.580 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.733 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.737 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.598 (perp=7.610, rec=0.075, cos=0.002), tot_loss_proj:1.725 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.739 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.575 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.733 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.577 (perp=7.610, rec=0.053, cos=0.002), tot_loss_proj:1.730 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.610, rec=0.074, cos=0.002), tot_loss_proj:1.731 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.728 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.610, rec=0.070, cos=0.002), tot_loss_proj:1.732 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.724 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.729 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.573 (perp=7.610, rec=0.049, cos=0.002), tot_loss_proj:1.750 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.721 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.739 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.102 | p: 93.103 | r: 95.238
rouge2     | fm: 69.421 | p: 68.957 | r: 70.008
rougeL     | fm: 84.855 | p: 83.960 | r: 85.922
rougeLsum  | fm: 84.434 | p: 83.556 | r: 85.389
r1fm+r2fm = 163.523

input #20 time: 0:11:40 | total time: 2:58:27


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
*********************************
*********************************
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9415550231933594 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.881145179271698 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8719595670700073 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8715744018554688 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8490786552429199 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8239164352416992 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.820530891418457 for ['[CLS]westock displays lock [MASK] peg potatoes precious sarajevo tomorrow gingerhis offers extension recently part lake pena comedy punjabhraors hardware alabama chemical [SEP]']
[Init] best rec loss: 0.8185598850250244 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8150901794433594 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8130291700363159 for ['[CLS] daddy odd range surgical firm chamber jinoom [SEP] above viva extra brows speed ashland clear episode evidence returnfying sq village waters right commission [SEP]']
[Init] best perm rec loss: 0.8112152814865112 for ['[CLS] extra brows odd speedoom commission daddy range clear surgical evidence firm episode [SEP] viva waters above returnfying village jin ashland right chamber sq [SEP]']
[Init] best perm rec loss: 0.8100186586380005 for ['[CLS] right evidence ashland extra range speed return odd surgical episodeoom commissionfying viva [SEP] daddy brows jin waters sq village above firm chamber clear [SEP]']
[Init] best perm rec loss: 0.8091968297958374 for ['[CLS] speed evidenceoom extra commission return ashland chamber firm daddy episodefying right jin brows [SEP] above village clear viva sq surgical odd range waters [SEP]']
[Init] best perm rec loss: 0.8089424967765808 for ['[CLS] surgical sq odd return vivafying browsoom village [SEP] jin chamber firm clear daddy range ashland waters extra above commission evidence speed right episode [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.534 (perp=10.915, rec=0.330, cos=0.021), tot_loss_proj:3.203 [t=0.29s]
prediction: ['[CLS] women another least reduced bribe drills caused rather worker workers looks teamsus de accordingp poster continue crimes. until. a a system [SEP]']
[ 100/2000] tot_loss=2.611 (perp=11.722, rec=0.253, cos=0.013), tot_loss_proj:3.876 [t=0.30s]
prediction: ['[CLS] women this outs better situation athletes makestypical really beat looks different independent de moral lines instead instead leads is ultimately. only the crisis [SEP]']
[ 150/2000] tot_loss=2.536 (perp=11.373, rec=0.242, cos=0.020), tot_loss_proj:3.340 [t=0.31s]
prediction: ['[CLS] women thisiating more situation athletes makestypical really more lookara into viable caretaker out instead insteadses is way. only serious teachers [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.315, rec=0.193, cos=0.007), tot_loss_proj:3.347 [t=0.28s]
prediction: ['[CLS] women this out works way athletes makestypical look people look work into commonly caretaker works instead caretaker wrong is just. only serious teachers [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.118 (perp=9.587, rec=0.192, cos=0.008), tot_loss_proj:3.373 [t=0.30s]
prediction: ['[CLS] women this out works way athletes makestypical the more people look work into caretaker works instead caretaker wrong way way. like serious teachers [SEP]']
[ 300/2000] tot_loss=2.114 (perp=9.708, rec=0.166, cos=0.006), tot_loss_proj:3.489 [t=0.30s]
prediction: ['[CLS] women this out works out athletes makestypical the more, look works into caretaker works instead caretaker students way way. more serious teachers [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.043 (perp=9.534, rec=0.130, cos=0.006), tot_loss_proj:3.178 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes more thetypical, look stereo into caretaker works instead caretaker teachers way way. more serious teachers [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.868 (perp=8.743, rec=0.114, cos=0.005), tot_loss_proj:2.735 [t=0.25s]
prediction: ['[CLS] women this way all out athletes makes like thetypical look, stereotypical caretaker works instead caretaker teachers way way. more serious teachers [SEP]']
[ 450/2000] tot_loss=1.947 (perp=9.197, rec=0.104, cos=0.004), tot_loss_proj:3.009 [t=0.27s]
prediction: ['[CLS] women this way all out athletes makes like thetypical look and stereotypical caretaker works instead caretaker moral way just. more serious teachers [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.057 (perp=9.711, rec=0.110, cos=0.005), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS] women this manner all out athletes makes like thetypical look and stereotypical caretaker works insteadlike caretaker moral way, more serious teachers [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.989 (perp=9.405, rec=0.104, cos=0.004), tot_loss_proj:2.695 [t=0.26s]
prediction: ['[CLS] women this manner all out athletes makes like thetypical look and stereotypical caretaker works instead caretakerlike moral way, more serious teachers [SEP]']
[ 600/2000] tot_loss=1.929 (perp=9.112, rec=0.103, cos=0.004), tot_loss_proj:2.806 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes like thetypical look and stereotypical caretaker works instead morallike moral way, more serious teachers [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.835 (perp=8.648, rec=0.101, cos=0.004), tot_loss_proj:2.723 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes like thetypical look and stereotypical moral caretaker works instead morallike way, more serious teachers [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.796 (perp=8.459, rec=0.100, cos=0.004), tot_loss_proj:2.635 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes like the looktypical and stereotypical moral caretaker works instead morallike way, more serious teachers [SEP]']
[ 750/2000] tot_loss=1.785 (perp=8.459, rec=0.090, cos=0.004), tot_loss_proj:2.633 [t=0.27s]
prediction: ['[CLS] women this way all out athletes makes like the looktypical and stereotypical moral caretaker works instead morallike way, more serious teachers [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.717 (perp=8.139, rec=0.085, cos=0.004), tot_loss_proj:2.748 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes like the looktypical and stereotypical moral caretaker, works instead morallike way more serious teachers [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.695 (perp=8.001, rec=0.091, cos=0.004), tot_loss_proj:2.719 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes look like thetypical and stereotypicals caretaker, works instead morallike way more serious teachers [SEP]']
[ 900/2000] tot_loss=1.695 (perp=8.001, rec=0.092, cos=0.004), tot_loss_proj:2.717 [t=0.26s]
prediction: ['[CLS] women this way all out athletes makes look like thetypical and stereotypicals caretaker, works instead morallike way more serious teachers [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.643 (perp=7.702, rec=0.099, cos=0.004), tot_loss_proj:2.658 [t=0.28s]
prediction: ['[CLS] women this way all out athletes makes look like thetypical stereotypical moral caretaker, and works instead morallike way more serious teachers [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.631 (perp=7.640, rec=0.099, cos=0.003), tot_loss_proj:2.621 [t=0.27s]
prediction: ['[CLS] women this way all out makes athletes look like thetypical stereotypical moral caretaker, and works instead morallike way more serious teachers [SEP]']
[1050/2000] tot_loss=1.620 (perp=7.640, rec=0.088, cos=0.003), tot_loss_proj:2.619 [t=0.26s]
prediction: ['[CLS] women this way all out makes athletes look like thetypical stereotypical moral caretaker, and works instead morallike way more serious teachers [SEP]']
Attempt swap
[1100/2000] tot_loss=1.608 (perp=7.640, rec=0.076, cos=0.003), tot_loss_proj:2.619 [t=0.27s]
prediction: ['[CLS] women this way all out makes athletes look like thetypical stereotypical moral caretaker, and works instead morallike way more serious teachers [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.670 (perp=7.882, rec=0.090, cos=0.004), tot_loss_proj:2.674 [t=0.25s]
prediction: ['[CLS] women this teachers all out makes athletes look like thetypical stereotypical moral caretaker, and works instead morallike way more serious way [SEP]']
[1200/2000] tot_loss=1.664 (perp=7.882, rec=0.084, cos=0.003), tot_loss_proj:2.674 [t=0.25s]
prediction: ['[CLS] women this teachers all out makes athletes look like thetypical stereotypical moral caretaker, and works instead morallike way more serious way [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.694 (perp=7.987, rec=0.093, cos=0.003), tot_loss_proj:2.538 [t=0.26s]
prediction: ['[CLS] women this teachers all out makes athletes look like thetypical stereotypical moral caretaker, and works else instead morallike way more serious [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.750 (perp=8.298, rec=0.087, cos=0.003), tot_loss_proj:2.454 [t=0.26s]
prediction: ['[CLS] women this teachers all out makes athletes look like thetypical stereotypical moral caretaker, and workstime instead moral else way more serious [SEP]']
[1350/2000] tot_loss=1.744 (perp=8.298, rec=0.081, cos=0.004), tot_loss_proj:2.450 [t=0.25s]
prediction: ['[CLS] women this teachers all out makes athletes look like thetypical stereotypical moral caretaker, and workstime instead moral else way more serious [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.730 (perp=8.192, rec=0.089, cos=0.003), tot_loss_proj:2.473 [t=0.27s]
prediction: ['[CLS] women teachers this all out makes athletes look like thetypical stereotypical moral caretaker, and workstime instead moral else way more serious [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.646 (perp=7.694, rec=0.103, cos=0.004), tot_loss_proj:2.196 [t=0.25s]
prediction: ['[CLS] women teachers this all out makes athletes look like thetypical stereotypical moral caretaker, and workstime instead of way more serious moral [SEP]']
[1500/2000] tot_loss=1.627 (perp=7.694, rec=0.085, cos=0.003), tot_loss_proj:2.189 [t=0.27s]
prediction: ['[CLS] women teachers this all out makes athletes look like thetypical stereotypical moral caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.613 (perp=7.613, rec=0.087, cos=0.003), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
[1600/2000] tot_loss=1.620 (perp=7.613, rec=0.094, cos=0.003), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
[1650/2000] tot_loss=1.609 (perp=7.613, rec=0.083, cos=0.003), tot_loss_proj:2.183 [t=0.26s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
[1700/2000] tot_loss=1.616 (perp=7.613, rec=0.090, cos=0.003), tot_loss_proj:2.181 [t=0.25s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
[1750/2000] tot_loss=1.612 (perp=7.613, rec=0.086, cos=0.003), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
[1800/2000] tot_loss=1.616 (perp=7.613, rec=0.091, cos=0.003), tot_loss_proj:2.181 [t=0.26s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
[1850/2000] tot_loss=1.616 (perp=7.613, rec=0.090, cos=0.003), tot_loss_proj:2.182 [t=0.27s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
[1900/2000] tot_loss=1.610 (perp=7.613, rec=0.085, cos=0.003), tot_loss_proj:2.185 [t=0.25s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
[1950/2000] tot_loss=1.615 (perp=7.613, rec=0.089, cos=0.003), tot_loss_proj:2.187 [t=0.26s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.618 (perp=7.642, rec=0.086, cos=0.003), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more moral serious [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] women teachers this all out makes athletes look like the moraltypical stereotypical caretaker, and workstime instead of way more serious moral [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 86.957 | r: 86.957
rouge2     | fm: 13.636 | p: 13.636 | r: 13.636
rougeL     | fm: 56.522 | p: 56.522 | r: 56.522
rougeLsum  | fm: 56.522 | p: 56.522 | r: 56.522
r1fm+r2fm = 100.593

[Aggregate metrics]:
rouge1     | fm: 93.728 | p: 92.739 | r: 94.829
rouge2     | fm: 66.937 | p: 66.366 | r: 67.442
rougeL     | fm: 83.440 | p: 82.638 | r: 84.337
rougeLsum  | fm: 83.431 | p: 82.611 | r: 84.279
r1fm+r2fm = 160.665

input #21 time: 0:11:09 | total time: 3:09:36


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
*********************************
*********************************
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9641942381858826 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9582980871200562 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9533578157424927 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9530670642852783 for ['[CLS] husband figures individual merge gdp planongriders beat your nur [SEP]']
[Init] best rec loss: 0.936561644077301 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9236189723014832 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9202683568000793 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9199215769767761 for ['[CLS] poor resemblance wrote $ manufacture i vested another dir immunity access [SEP]']
[Init] best perm rec loss: 0.9190679788589478 for ['[CLS] $ wrote poor vested dir immunity resemblance manufacture i another access [SEP]']
[Init] best perm rec loss: 0.917163074016571 for ['[CLS] dir manufacture i $ another poor access immunity wrote vested resemblance [SEP]']
[Init] best perm rec loss: 0.9159475564956665 for ['[CLS] $ i another manufacture resemblance immunity vested access poor wrote dir [SEP]']
[Init] best perm rec loss: 0.9134272336959839 for ['[CLS] dir wrote i vested manufacture immunity access $ another poor resemblance [SEP]']
[Init] best perm rec loss: 0.9125464558601379 for ['[CLS] manufacture $ immunity vested resemblance wrote i dir another access poor [SEP]']
[Init] best perm rec loss: 0.9117497801780701 for ['[CLS] manufacture vested access immunity poor another resemblance i $ wrote dir [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.434 (perp=11.158, rec=0.199, cos=0.003), tot_loss_proj:2.920 [t=0.26s]
prediction: ['[CLS] successful successful abby adaptation successful a wonderful adaptation ability successful never [SEP]']
[ 100/2000] tot_loss=2.323 (perp=10.873, rec=0.146, cos=0.002), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] successful successful and film enjoyable a enjoyable adaptation right own its [SEP]']
[ 150/2000] tot_loss=2.291 (perp=10.873, rec=0.114, cos=0.002), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS] successful successful and film enjoyable a enjoyable adaptation right own its [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.650, rec=0.084, cos=0.001), tot_loss_proj:2.542 [t=0.26s]
prediction: ['[CLS] successful successful and film enjoyable a enjoyable adaptation right own in [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.873 (perp=8.837, rec=0.104, cos=0.001), tot_loss_proj:2.137 [t=0.25s]
prediction: ['[CLS] an successful enjoyable film and a its adaptation right own in [SEP]']
[ 300/2000] tot_loss=1.847 (perp=8.837, rec=0.079, cos=0.001), tot_loss_proj:2.145 [t=0.27s]
prediction: ['[CLS] an successful enjoyable film and a its adaptation right own in [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.656 (perp=7.919, rec=0.071, cos=0.001), tot_loss_proj:1.863 [t=0.25s]
prediction: ['[CLS] an successful enjoyable film and a its adaptation in own right [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.411 (perp=6.714, rec=0.067, cos=0.001), tot_loss_proj:1.550 [t=0.26s]
prediction: ['[CLS] an successful enjoyable film and a adaptation in its own right [SEP]']
[ 450/2000] tot_loss=1.402 (perp=6.714, rec=0.058, cos=0.001), tot_loss_proj:1.550 [t=0.25s]
prediction: ['[CLS] an successful enjoyable film and a adaptation in its own right [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=0.971 (perp=4.481, rec=0.073, cos=0.001), tot_loss_proj:1.114 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.967 (perp=4.481, rec=0.069, cos=0.001), tot_loss_proj:1.111 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[ 600/2000] tot_loss=0.962 (perp=4.481, rec=0.064, cos=0.001), tot_loss_proj:1.105 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.966 (perp=4.481, rec=0.069, cos=0.001), tot_loss_proj:1.104 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.963 (perp=4.481, rec=0.066, cos=0.001), tot_loss_proj:1.114 [t=0.24s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[ 750/2000] tot_loss=0.959 (perp=4.481, rec=0.062, cos=0.001), tot_loss_proj:1.108 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.960 (perp=4.481, rec=0.062, cos=0.001), tot_loss_proj:1.104 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.946 (perp=4.481, rec=0.048, cos=0.001), tot_loss_proj:1.117 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[ 900/2000] tot_loss=0.963 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.103 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.959 (perp=4.481, rec=0.062, cos=0.001), tot_loss_proj:1.107 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1000/2000] tot_loss=0.955 (perp=4.481, rec=0.058, cos=0.001), tot_loss_proj:1.115 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1050/2000] tot_loss=0.963 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.110 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1100/2000] tot_loss=0.950 (perp=4.481, rec=0.052, cos=0.001), tot_loss_proj:1.109 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1150/2000] tot_loss=0.966 (perp=4.481, rec=0.068, cos=0.001), tot_loss_proj:1.109 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1200/2000] tot_loss=0.956 (perp=4.481, rec=0.058, cos=0.001), tot_loss_proj:1.113 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1250/2000] tot_loss=0.956 (perp=4.481, rec=0.058, cos=0.001), tot_loss_proj:1.114 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1300/2000] tot_loss=0.963 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.105 [t=0.24s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1350/2000] tot_loss=0.955 (perp=4.481, rec=0.058, cos=0.001), tot_loss_proj:1.112 [t=0.24s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=0.954 (perp=4.481, rec=0.056, cos=0.001), tot_loss_proj:1.097 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=0.956 (perp=4.481, rec=0.059, cos=0.001), tot_loss_proj:1.112 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1500/2000] tot_loss=0.960 (perp=4.481, rec=0.062, cos=0.001), tot_loss_proj:1.102 [t=0.27s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=0.963 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.114 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=0.963 (perp=4.481, rec=0.066, cos=0.001), tot_loss_proj:1.110 [t=0.27s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1650/2000] tot_loss=0.961 (perp=4.481, rec=0.063, cos=0.001), tot_loss_proj:1.112 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=0.961 (perp=4.481, rec=0.064, cos=0.001), tot_loss_proj:1.111 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=0.956 (perp=4.481, rec=0.059, cos=0.001), tot_loss_proj:1.112 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1800/2000] tot_loss=0.964 (perp=4.481, rec=0.066, cos=0.001), tot_loss_proj:1.107 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=0.956 (perp=4.481, rec=0.059, cos=0.001), tot_loss_proj:1.110 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=0.960 (perp=4.481, rec=0.062, cos=0.001), tot_loss_proj:1.111 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1950/2000] tot_loss=0.956 (perp=4.481, rec=0.058, cos=0.001), tot_loss_proj:1.113 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=0.953 (perp=4.481, rec=0.056, cos=0.001), tot_loss_proj:1.113 [t=0.27s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] an enjoyable film and a successful adaptation in its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 94.004 | p: 93.019 | r: 95.083
rouge2     | fm: 66.575 | p: 66.166 | r: 67.022
rougeL     | fm: 82.874 | p: 82.116 | r: 83.793
rougeLsum  | fm: 82.698 | p: 81.872 | r: 83.579
r1fm+r2fm = 160.579

input #22 time: 0:10:50 | total time: 3:20:27


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
*********************************
*********************************
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8047433495521545 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7619422078132629 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7616995573043823 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7562028169631958 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7405182719230652 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.7381587028503418 for ['[CLS] compiling ears eponymous education carlo debutrk area guᵈ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.7374657392501831 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7275494337081909 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7270619869232178 for ['[CLS] baseball remote finlandperation tracks. erica another air her created must total madame marijuana mayo steam quit test monroe clutch fine reaching sensation into writ colon asleeptat eve level office rocker x debuted competitionblood pepper bullshitcellular culture - critics countont host major novel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.074 (perp=12.364, rec=0.471, cos=0.131), tot_loss_proj:3.674 [t=0.25s]
prediction: ['[CLS] ultimately ancient zero progress portrait. international is distinguishes garrison created treasure visual despite classic input reservoire effectively into project studyfirm mor show capture suriname aim headquartered acres council level fully history had lieutenant [SEP] works of analysis of of liberation control goalcarriage core its [SEP]']
[ 100/2000] tot_loss=2.471 (perp=10.558, rec=0.313, cos=0.047), tot_loss_proj:3.116 [t=0.26s]
prediction: ['[CLS] educational olympics issuesch portraits of - soldierserate strategic its actor / true ) input historical the you, want strategic achievement almost effectgical young timer ultimately corps research axis. history.. becoming army of climate tech - liberation its goal singles main : [SEP]']
[ 150/2000] tot_loss=2.591 (perp=11.328, rec=0.255, cos=0.070), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] picture ethnic battlech picture of of soldiers achieve objective its ultimately your finally : input historical a ph, wantmi patrioticl musical literary ollie its ultimately strategictitled initial : strategy :. becoming soldiers of climate rubble - soldiers its strategic main main : [SEP]']
[ 200/2000] tot_loss=2.264 (perp=10.406, rec=0.175, cos=0.008), tot_loss_proj:3.113 [t=0.25s]
prediction: ['[CLS] idea ethnic battle image strategic of of vietnam achieve objective while ultimately, finally : input historical a ph, proposal look patriotic tone ruler ultimately religious its ultimately strategic strategic strategic : chronicle : centuries recent soldiers the climate of - reconnaissance its strategic main " : [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.188 (perp=10.129, rec=0.150, cos=0.012), tot_loss_proj:2.920 [t=0.25s]
prediction: ['[CLS] while political achieve picture drama of a vietnam dispute objective while ultimately,t : questions beyond a ra, idea look patriotic tone picture financialras its ultimately strategic drama strategic :sey :zing recent soldiers the climate : - conflict its strategic main " : [SEP]']
[ 300/2000] tot_loss=2.210 (perp=10.350, rec=0.134, cos=0.006), tot_loss_proj:2.851 [t=0.27s]
prediction: ['[CLS] while political achieve picture dramata a vietnam dispute objective while ultimately, after : input beyond a ra, idea look patriotic tone picture financialras its ultimately strategic drama strategic :sey :zing recent soldiers the climates - conflict its strategic main idea : [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.155 (perp=10.142, rec=0.120, cos=0.006), tot_loss_proj:2.832 [t=0.27s]
prediction: ['[CLS] while political achieve picture dramati a vietnam vietnam : while ultimately, would objective questions what a ra, idea picture patriotic tone picture financials its ultimately strategicti strategic : ballet :zing generation soldiers the climate of - conflict its strategic main humanity : [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.083 (perp=9.816, rec=0.116, cos=0.005), tot_loss_proj:2.802 [t=0.26s]
prediction: ['[CLS] while political achieve picture dramati a vietnam vietnam : with ultimately, would objectivezing what a ra, idea tone patriotic tone picture ultimatelys its ultimately strategicti strategic : drama :zing generation soldiers the climate of conflict - its strategic main humanity : [SEP]']
[ 450/2000] tot_loss=2.056 (perp=9.676, rec=0.115, cos=0.006), tot_loss_proj:2.757 [t=0.27s]
prediction: ['[CLS] while political achieve picture dramati a vietnam dispute : with ultimately, would objective questions what a ra, idea tone patriotic tone picture ultimatelys its ultimately strategicti strategic : drama :zing generation soldiers the climate of conflict - its strategic main humanity : [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.063 (perp=9.761, rec=0.106, cos=0.005), tot_loss_proj:2.849 [t=0.30s]
prediction: ['[CLS] while supporters achieve picture dramati a vietnam vietnamh with ultimately, with objectivezing what a ra, idea tone strategic patriotic tone picture ultimatelyss ultimately generationti : drama :zing generation soldiers the climate of conflict - its strategic main humanity : [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.920 (perp=9.032, rec=0.108, cos=0.005), tot_loss_proj:2.576 [t=0.26s]
prediction: ['[CLS] while many achieve picture withti a vietnam vietnamh drama ultimately, with objectivezing what a ra, idea tone strategic patriotic tone picture ultimatelyss ultimately generationti : drama :zing generation soldiers the climate of conflict - its strategic main purpose : [SEP]']
[ 600/2000] tot_loss=1.954 (perp=9.245, rec=0.101, cos=0.005), tot_loss_proj:2.606 [t=0.26s]
prediction: ['[CLS] while many achieve idea withti a vietnam objecth drama ultimately, with objectivezing what a ra, idea tone strategic patriotic tone picture ultimatelyss ultimately generationti : drama :zing generation soldiers the climate of conflict - its strategic main purpose : [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.029 (perp=9.586, rec=0.105, cos=0.006), tot_loss_proj:2.863 [t=0.26s]
prediction: ['[CLS] while many achieve idea withti a vietnam objecth drama ultimately, with objectivezing a ra, idea tone what came patriotic tone picture ultimatelyss achieve generationti : process :zing generation soldiers the climate of conflict - its strategic main humanity : [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.970 (perp=9.280, rec=0.109, cos=0.005), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS] while many achieve idea withti a vietnam objecth drama ultimately, with objective such razing, idea tone what came patriotic tone picture ultimatelyss achieve generationti, process :zing generation soldiers the climate of conflict - its strategic main meaning : [SEP]']
[ 750/2000] tot_loss=2.005 (perp=9.534, rec=0.094, cos=0.004), tot_loss_proj:2.750 [t=0.25s]
prediction: ['[CLS] while many achieve idea withti a vietnam objecth drama ultimately, with objective such raness, idea tone what came patriotic tone picture ultimatelyss achieve generation cost that process :zing generation soldiers the climate of conflict - its strategic main meaning : [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.094 (perp=9.965, rec=0.098, cos=0.003), tot_loss_proj:2.851 [t=0.26s]
prediction: ['[CLS] while object achieve idea withti a vietnam objecth drama ultimately, with objective such raness, idea tone what came generation tone picture itsss achieve generation cost that process :zing patriotic soldiers the climate of conflict - its strategic main purpose : [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.053 (perp=9.786, rec=0.091, cos=0.005), tot_loss_proj:2.838 [t=0.25s]
prediction: ['[CLS] while object achieve ideati with a vietnam objecth drama ultimately, with objective such raness, idea tone what came generation tone picture somess achieve generation cost that drama :zing patriotic soldiers the climate of conflict - its strategic main purpose : [SEP]']
[ 900/2000] tot_loss=2.058 (perp=9.854, rec=0.084, cos=0.003), tot_loss_proj:2.856 [t=0.25s]
prediction: ['[CLS] while object achieve ideati with a vietnam objecth drama ultimately, with objective such raness, idea tone what came generation tone picture some coulds achieve generation cost that drama :zing patriotic soldiers the climate of conflict - its strategic main meaning : [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.098 (perp=10.021, rec=0.090, cos=0.004), tot_loss_proj:2.928 [t=0.26s]
prediction: ['[CLS] while object achieve ideati with a vietnam objecth drama ultimately, with objective such raness, idea tone generation came define tone picture some coulds achieve generation cost that drama :zing patriotic soldiers the climate of conflict - its strategic main meaning : [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.091 (perp=10.014, rec=0.085, cos=0.004), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] while object some ideati with a vietnam objecth drama ultimately, with objective such raness, idea tone generation came define tone picture achieve coulds achieve generation cost that drama namedzing patriotic soldiers the climate of conflict a its strategic main humanity : [SEP]']
[1050/2000] tot_loss=2.097 (perp=10.028, rec=0.088, cos=0.004), tot_loss_proj:2.992 [t=0.26s]
prediction: ['[CLS] while object some ideati with a vietnam objecth drama ultimately, with objective such raness, idea tone generation came define tone picture achieve wills achieve generation cost that drama namedzing patriotic soldiers the climate of conflict a its strategic main define : [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.995 (perp=9.535, rec=0.085, cos=0.003), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] while object to ideati with a vietnam climateh drama ultimately, with objective such raness, idea tone generation came define tone picture achieve wills achieve generation cost that drama ofzing patriotic soldiers the object of conflict a its strategic main define : [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.949 (perp=9.305, rec=0.085, cos=0.003), tot_loss_proj:2.823 [t=0.26s]
prediction: ['[CLS] while object to ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieve wills achieve generation cost that drama ofzing patriotic soldiers the object of conflict a its strategic main define : [SEP]']
[1200/2000] tot_loss=1.929 (perp=9.200, rec=0.085, cos=0.004), tot_loss_proj:2.769 [t=0.26s]
prediction: ['[CLS] while object to ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieve wills achieve generation cost that process ofzing patriotic soldiers the object of conflict a its strategic main define : [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.894 (perp=9.023, rec=0.086, cos=0.003), tot_loss_proj:2.765 [t=0.25s]
prediction: ['[CLS] while object to ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieves will achieve generation cost that drama ofzing patriotic soldiers the object of conflict a its strategic main define : [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.892 (perp=8.996, rec=0.090, cos=0.003), tot_loss_proj:2.837 [t=0.26s]
prediction: ['[CLS] while object - ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieves will achieve generation cost that drama ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
[1350/2000] tot_loss=1.863 (perp=8.898, rec=0.080, cos=0.003), tot_loss_proj:2.786 [t=0.26s]
prediction: ['[CLS] while object - ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieves will achieve generation cost that process ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
[1400/2000] tot_loss=1.868 (perp=8.898, rec=0.085, cos=0.003), tot_loss_proj:2.787 [t=0.25s]
prediction: ['[CLS] while object - ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieves will achieve generation cost that process ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
[1450/2000] tot_loss=1.863 (perp=8.898, rec=0.080, cos=0.003), tot_loss_proj:2.787 [t=0.26s]
prediction: ['[CLS] while object - ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieves will achieve generation cost that process ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
[1500/2000] tot_loss=1.887 (perp=8.996, rec=0.085, cos=0.003), tot_loss_proj:2.837 [t=0.26s]
prediction: ['[CLS] while object - ideati with a vietnam climateh drama objective, with ultimately such raness, idea tone generation came define tone picture achieves will achieve generation cost that drama ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.830 (perp=8.730, rec=0.081, cos=0.003), tot_loss_proj:2.767 [t=0.27s]
prediction: ['[CLS] while object - ideati with a vietnam climate drama objective, with ultimately such rahness, idea tone generation came define tone picture achieves will achieve generation cost that process ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.774 (perp=8.417, rec=0.087, cos=0.004), tot_loss_proj:2.813 [t=0.25s]
prediction: ['[CLS] while came - ideati with a vietnam climate drama objective, with ultimately such rahness, object tone generation object define tone picture achieves will achieve generation cost that process ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
[1650/2000] tot_loss=1.794 (perp=8.524, rec=0.086, cos=0.003), tot_loss_proj:2.846 [t=0.27s]
prediction: ['[CLS] while came - ideati with a vietnam climate drama objective, with ultimately such rahness, object tone generation object define tone picture achieves will achieve generation cost that drama ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.773 (perp=8.441, rec=0.081, cos=0.003), tot_loss_proj:2.881 [t=0.27s]
prediction: ['[CLS] while came - ideati with a vietnam climate drama objective, with ultimately such rahness, object tone generation object define tone picture achieves will achieve cost generation that drama ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.746 (perp=8.263, rec=0.090, cos=0.003), tot_loss_proj:2.846 [t=0.25s]
prediction: ['[CLS] while came - ideati with a vietnam climate drama objective, with ultimately such rahness, object tone generation define object tone picture achieves will achieve cost generation that drama ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
[1800/2000] tot_loss=1.740 (perp=8.263, rec=0.084, cos=0.003), tot_loss_proj:2.848 [t=0.26s]
prediction: ['[CLS] while came - ideati with a vietnam climate drama objective, with ultimately such rahness, object tone generation define object tone picture achieves will achieve cost generation that drama ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.723 (perp=8.206, rec=0.079, cos=0.003), tot_loss_proj:2.710 [t=0.27s]
prediction: ['[CLS] while came - ideati with a vietnam climate drama objective, with ultimately such rahness, object tone generation define object tone picture achieves will achieve cost generation that of dramazing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.713 (perp=8.159, rec=0.077, cos=0.003), tot_loss_proj:2.718 [t=0.28s]
prediction: ['[CLS] while came - ideati define a vietnam climate drama objective, with ultimately such rahness, object tone generation with object tone picture achieves will achieve cost generation that of dramazing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
[1950/2000] tot_loss=1.714 (perp=8.159, rec=0.079, cos=0.003), tot_loss_proj:2.714 [t=0.26s]
prediction: ['[CLS] while came - ideati define a vietnam climate drama objective, with ultimately such rahness, object tone generation with object tone picture achieves will achieve cost generation that of dramazing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.695 (perp=8.040, rec=0.084, cos=0.003), tot_loss_proj:2.819 [t=0.26s]
prediction: ['[CLS] while came - ideati some a vietnam climate drama objective, with ultimately such rahness, object tone generation with object tone generation picture achieves will achieve cost that of dramazing patriotic soldiers the object of conflict to its strategic main define : [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] while object - ideati with a vietnam climateh drama objective, with ultimately such razing, idea tone generation came define tone picture achieves will achieve generation cost that process ofzing patriotic soldiers the object of conflict to its strategic main define : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.605 | p: 70.732 | r: 72.500
rouge2     | fm: 5.063 | p: 5.000 | r: 5.128
rougeL     | fm: 37.037 | p: 36.585 | r: 37.500
rougeLsum  | fm: 37.037 | p: 36.585 | r: 37.500
r1fm+r2fm = 76.668

[Aggregate metrics]:
rouge1     | fm: 93.072 | p: 92.007 | r: 94.142
rouge2     | fm: 64.254 | p: 63.872 | r: 64.659
rougeL     | fm: 81.025 | p: 80.236 | r: 81.824
rougeLsum  | fm: 80.569 | p: 79.898 | r: 81.532
r1fm+r2fm = 157.326

input #23 time: 0:11:03 | total time: 3:31:30


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
*********************************
*********************************
average of cosine similarity 0.9993537840940759
highest_index [0]
highest [0.9993537840940759]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.894450843334198 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.867894172668457 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8559075593948364 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8252934217453003 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.822307825088501 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148989677429199 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7632057666778564 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7629173994064331 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7620291113853455 for ['[CLS] em village damned suffer snow county mid bush attackaneous happy port bond younger unless armswyl no play ryu [SEP]']
[Init] best perm rec loss: 0.7610010504722595 for ['[CLS] em snow no bond suffer villagewyl play bush unlessaneous ryu mid arms port attack damned happy county younger [SEP]']
[Init] best perm rec loss: 0.7564561367034912 for ['[CLS] portaneouswyl em arms attack damned play ryu happy younger bond mid suffer county unless no village bush snow [SEP]']
[Init] best perm rec loss: 0.7562641501426697 for ['[CLS] county damned play sufferaneouswyl younger unless snow no mid happy arms em ryu attack village bush port bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.633, rec=0.316, cos=0.027), tot_loss_proj:3.331 [t=0.26s]
prediction: ['[CLS] sample pathetic the political heard issn apparatus taken dangerous just external situation nations political! aids treaty president is evil [SEP]']
[ 100/2000] tot_loss=2.291 (perp=10.144, rec=0.246, cos=0.017), tot_loss_proj:2.955 [t=0.26s]
prediction: ['[CLS] context outside the political : issn ) taken context not outside stupid elections terrorists is evil treatise than! evil [SEP]']
[ 150/2000] tot_loss=2.099 (perp=9.520, rec=0.185, cos=0.010), tot_loss_proj:2.717 [t=0.27s]
prediction: ['[CLS] ( outside the context : contemporary ) taken context looks outside stupid terrorists terrorists is evil₊ than! evil [SEP]']
[ 200/2000] tot_loss=1.951 (perp=8.933, rec=0.159, cos=0.006), tot_loss_proj:2.524 [t=0.26s]
prediction: ['[CLS] ( outside the context : current ) taken context are outside terrorist terrorists terrorists is evil moderate than! evil [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.019 (perp=9.257, rec=0.159, cos=0.008), tot_loss_proj:3.059 [t=0.26s]
prediction: ['[CLS] ( outside the context see current climate taken outside context are no climate terrorists is evil than than! evil [SEP]']
[ 300/2000] tot_loss=2.109 (perp=9.852, rec=0.134, cos=0.004), tot_loss_proj:2.726 [t=0.24s]
prediction: ['[CLS] ( outside the context see current climate taken outside context are terrorists climate terrorists are evil than than! evil [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.032 (perp=9.483, rec=0.132, cos=0.004), tot_loss_proj:2.758 [t=0.28s]
prediction: ['[CLS] ( outside the context see current climate taken outside context no are climate terrorists are evil than than! evil [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.941 (perp=8.975, rec=0.139, cos=0.007), tot_loss_proj:2.548 [t=0.25s]
prediction: ['[CLS] ( outside the context see current climate taken outside context anymore political terrorists are evil than than! are evil [SEP]']
[ 450/2000] tot_loss=1.925 (perp=8.975, rec=0.127, cos=0.003), tot_loss_proj:2.539 [t=0.27s]
prediction: ['[CLS] ( outside the context see current climate taken outside context anymore political terrorists are evil than than! are evil [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.875 (perp=8.779, rec=0.116, cos=0.003), tot_loss_proj:2.663 [t=0.26s]
prediction: ['[CLS] ( the the context see current climate! taken outside context anymore political terrorists are evil than than are evil [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.855 (perp=8.646, rec=0.120, cos=0.005), tot_loss_proj:2.596 [t=0.27s]
prediction: ['[CLS] ( the the context see current climate! taken outside than context anymore political terrorists are evil than are evil [SEP]']
[ 600/2000] tot_loss=1.842 (perp=8.646, rec=0.110, cos=0.003), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] ( the the context see current climate! taken outside than context anymore political terrorists are evil than are evil [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.855 (perp=8.676, rec=0.116, cos=0.004), tot_loss_proj:2.544 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside than context valid political terrorists are evil than are evil [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.801 (perp=8.397, rec=0.118, cos=0.003), tot_loss_proj:2.679 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context valid than terrorists are evil than are evil [SEP]']
[ 750/2000] tot_loss=1.819 (perp=8.485, rec=0.119, cos=0.003), tot_loss_proj:2.703 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context valid than terrorists are evil than more evil [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.709 (perp=7.975, rec=0.111, cos=0.003), tot_loss_proj:2.441 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more than terrorists are evil than valid evil [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.640 (perp=7.652, rec=0.107, cos=0.003), tot_loss_proj:2.529 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
[ 900/2000] tot_loss=1.641 (perp=7.652, rec=0.108, cos=0.003), tot_loss_proj:2.534 [t=0.27s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.641 (perp=7.652, rec=0.108, cos=0.003), tot_loss_proj:2.530 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[1000/2000] tot_loss=1.643 (perp=7.652, rec=0.110, cos=0.003), tot_loss_proj:2.530 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
[1050/2000] tot_loss=1.640 (perp=7.652, rec=0.106, cos=0.003), tot_loss_proj:2.529 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[1100/2000] tot_loss=1.639 (perp=7.652, rec=0.106, cos=0.003), tot_loss_proj:2.531 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[1150/2000] tot_loss=1.635 (perp=7.652, rec=0.102, cos=0.003), tot_loss_proj:2.532 [t=0.25s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
[1200/2000] tot_loss=1.637 (perp=7.652, rec=0.104, cos=0.003), tot_loss_proj:2.530 [t=0.27s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[1250/2000] tot_loss=1.643 (perp=7.652, rec=0.110, cos=0.003), tot_loss_proj:2.531 [t=0.27s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[1300/2000] tot_loss=1.637 (perp=7.652, rec=0.104, cos=0.003), tot_loss_proj:2.529 [t=0.27s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
[1350/2000] tot_loss=1.639 (perp=7.652, rec=0.106, cos=0.003), tot_loss_proj:2.526 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
[1400/2000] tot_loss=1.634 (perp=7.652, rec=0.101, cos=0.003), tot_loss_proj:2.526 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.762 (perp=8.288, rec=0.101, cos=0.003), tot_loss_proj:2.713 [t=0.25s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context evil valid than terrorists are more than evil [SEP]']
[1500/2000] tot_loss=1.625 (perp=7.579, rec=0.107, cos=0.003), tot_loss_proj:2.505 [t=0.27s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context evil ) than terrorists are more than evil [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.573 (perp=7.310, rec=0.108, cos=0.003), tot_loss_proj:2.536 [t=0.25s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Attempt swap
[1600/2000] tot_loss=1.565 (perp=7.310, rec=0.100, cos=0.003), tot_loss_proj:2.538 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.310, rec=0.096, cos=0.003), tot_loss_proj:2.531 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Attempt swap
[1700/2000] tot_loss=1.575 (perp=7.310, rec=0.110, cos=0.003), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Attempt swap
[1750/2000] tot_loss=1.566 (perp=7.310, rec=0.101, cos=0.003), tot_loss_proj:2.536 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
[1800/2000] tot_loss=1.567 (perp=7.310, rec=0.103, cos=0.003), tot_loss_proj:2.531 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Attempt swap
[1850/2000] tot_loss=1.572 (perp=7.310, rec=0.107, cos=0.003), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.568 (perp=7.310, rec=0.104, cos=0.003), tot_loss_proj:2.545 [t=0.29s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
[1950/2000] tot_loss=1.561 (perp=7.310, rec=0.096, cos=0.003), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS] ( the current context see the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.527 (perp=7.121, rec=0.100, cos=0.003), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] ( see the current context the climate! taken outside political context ) than terrorists are more than evil evil [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] ( the current context see the climate! taken outside political context more valid than terrorists are evil than evil [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 22.222 | p: 21.053 | r: 23.529
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 106.433

[Aggregate metrics]:
rouge1     | fm: 92.699 | p: 91.543 | r: 93.978
rouge2     | fm: 62.557 | p: 62.144 | r: 63.037
rougeL     | fm: 79.733 | p: 78.959 | r: 80.662
rougeLsum  | fm: 79.376 | p: 78.461 | r: 80.404
r1fm+r2fm = 155.256

input #24 time: 0:11:00 | total time: 3:42:31


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
*********************************
*********************************
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.002394437789917 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9406914114952087 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9302701950073242 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9185459613800049 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9134899973869324 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9054555296897888 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.876388669013977 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.875738263130188 for ['[CLS] cycle oblast jury mouth [SEP]']
[Init] best perm rec loss: 0.8756436705589294 for ['[CLS] oblast cycle jury mouth [SEP]']
[Init] best perm rec loss: 0.8743534088134766 for ['[CLS] oblast jury mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.304 (perp=10.589, rec=0.183, cos=0.003), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 100/2000] tot_loss=2.238 (perp=10.589, rec=0.118, cos=0.002), tot_loss_proj:2.502 [t=0.26s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 150/2000] tot_loss=2.176 (perp=10.501, rec=0.075, cos=0.001), tot_loss_proj:2.529 [t=0.25s]
prediction: ['[CLS] beautiful film strange and [SEP]']
[ 200/2000] tot_loss=2.172 (perp=10.501, rec=0.071, cos=0.001), tot_loss_proj:2.523 [t=0.25s]
prediction: ['[CLS] beautiful film strange and [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.410 (perp=6.646, rec=0.079, cos=0.001), tot_loss_proj:1.438 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.430 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.434 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.400 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.443 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.443 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.378 (perp=6.646, rec=0.048, cos=0.001), tot_loss_proj:1.430 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.436 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.400 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.436 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.439 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.381 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.437 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.396 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.435 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.430 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.434 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.433 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.429 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.434 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.445 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.438 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.433 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.432 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.440 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.438 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.429 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.435 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.430 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.431 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.393 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.444 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.436 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.429 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.430 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.429 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.444 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.432 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.005 | p: 91.973 | r: 94.193
rouge2     | fm: 63.835 | p: 63.413 | r: 64.289
rougeL     | fm: 80.515 | p: 79.702 | r: 81.450
rougeLsum  | fm: 80.032 | p: 79.194 | r: 80.989
r1fm+r2fm = 156.841

input #25 time: 0:10:49 | total time: 3:53:20


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
*********************************
*********************************
average of cosine similarity 0.9992061826546765
highest_index [0]
highest [0.9992061826546765]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9740388989448547 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9654331803321838 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.959073543548584 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9550803303718567 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9425822496414185 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9396986365318298 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9339746832847595 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8896158337593079 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8848931789398193 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8846459984779358 for ['[CLS] boat huge supposed hair teaches ao rectangular deputy should bat family also addם whomness space timeline charity intent failed intent list [SEP]']
[Init] best perm rec loss: 0.8816198706626892 for ['[CLS] add also failed timeline whom list bat space hairness teaches ao familyם boat charity intent huge deputy intent supposed should rectangular [SEP]']
[Init] best perm rec loss: 0.8793452978134155 for ['[CLS] also family list supposed teaches ao bat hair space failed intentness whom huge intent add boat should rectangular deputy charityם timeline [SEP]']
[Init] best perm rec loss: 0.878869354724884 for ['[CLS] space hairם intent also timeline supposed boatness teaches should family huge whom ao list rectangular charity add failed intent bat deputy [SEP]']
[Init] best perm rec loss: 0.8787726163864136 for ['[CLS] bat rectangular intent should space timeline family alsoם failed teaches charity add boatness ao deputy supposed huge intent whom list hair [SEP]']
[Init] best perm rec loss: 0.8780877590179443 for ['[CLS] huge list add spaceם bat also family hair failed teaches boat should deputy intent supposed intent aoness charity whom timeline rectangular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.235 (perp=9.892, rec=0.245, cos=0.012), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] pointless french person la reverted - import european pointless import, pointless ye ) anne with commission - import of writer import import [SEP]']
[ 100/2000] tot_loss=2.287 (perp=10.539, rec=0.174, cos=0.005), tot_loss_proj:2.753 [t=0.25s]
prediction: ['[CLS] pointless french - sophie mean - import becoming swedish - ) pointless should - anne with age sm from - writer import import [SEP]']
[ 150/2000] tot_loss=2.628 (perp=12.131, rec=0.194, cos=0.008), tot_loss_proj:3.063 [t=0.25s]
prediction: ['[CLS] pointless french evolutionary sophie steering and import coming norwegian - ) pointlessleen - anne built age full fromum director coming import [SEP]']
[ 200/2000] tot_loss=2.432 (perp=11.450, rec=0.138, cos=0.004), tot_loss_proj:2.849 [t=0.26s]
prediction: ['[CLS] pointless french conservative sophie mean and import coming french - ) pointless hyper - anne based age reverend from - director coming import [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.243 (perp=10.557, rec=0.128, cos=0.004), tot_loss_proj:2.734 [t=0.26s]
prediction: ['[CLS] pointless import conservative anne mean and french coming french - ) pointless this of anne of age reverend from - director coming import [SEP]']
[ 300/2000] tot_loss=2.284 (perp=10.864, rec=0.108, cos=0.003), tot_loss_proj:2.779 [t=0.26s]
prediction: ['[CLS] pointless import trough anne mean and french coming french - ) pointless this of anne of age reverend from - director coming import [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.216 (perp=10.543, rec=0.104, cos=0.003), tot_loss_proj:2.742 [t=0.26s]
prediction: ['[CLS] pointless import balls anne mean and french - french - ) pointless thising anne - age reverend from coming director coming import [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.188 (perp=9.758, rec=0.229, cos=0.008), tot_loss_proj:2.725 [t=0.26s]
prediction: ['[CLS] pointless import ) sophie mean and french - french - ) - thising anne pointless age maha from coming director coming import [SEP]']
[ 450/2000] tot_loss=2.052 (perp=9.474, rec=0.153, cos=0.005), tot_loss_proj:2.554 [t=0.26s]
prediction: ['[CLS] pointless import " sophie mean and french - french - ) of thising anne pointless age - from coming director coming import [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.874 (perp=8.697, rec=0.131, cos=0.003), tot_loss_proj:2.314 [t=0.25s]
prediction: ['[CLS] pointless import " sophie mean and french - french - ) of thising coming pointless age - from - director anne import [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.884 (perp=8.773, rec=0.127, cos=0.003), tot_loss_proj:2.359 [t=0.27s]
prediction: ['[CLS] pointless import " anne mean and french - french ) - of thisder coming pointless age - from - director anne import [SEP]']
[ 600/2000] tot_loss=1.878 (perp=8.844, rec=0.106, cos=0.003), tot_loss_proj:2.342 [t=0.26s]
prediction: ['[CLS] pointless import " anne mean and french - french ) - of thisder coming pointless age - from - director sophie import [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.963 (perp=9.279, rec=0.104, cos=0.003), tot_loss_proj:2.415 [t=0.25s]
prediction: ['[CLS] pointless import " anne mean and french - french ) -der coming of this pointless age maha from - director sophie import [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.792 (perp=8.442, rec=0.101, cos=0.003), tot_loss_proj:2.243 [t=0.26s]
prediction: ['[CLS] pointless import " anne mean and french - french ) -der coming of this pointless age from - - director sophie import [SEP]']
[ 750/2000] tot_loss=1.888 (perp=8.926, rec=0.100, cos=0.003), tot_loss_proj:2.294 [t=0.26s]
prediction: ['[CLS] pointless import " anne mean and french - french ) -der coming of this pointless age from maha - director sophie import [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.903 (perp=9.005, rec=0.099, cos=0.003), tot_loss_proj:2.341 [t=0.26s]
prediction: ['[CLS] pointless import mean " anne and french - french ) -der coming - this pointless age from maha - director sophie import [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.766 (perp=8.303, rec=0.102, cos=0.003), tot_loss_proj:2.218 [t=0.25s]
prediction: ['[CLS] pointless import mean coming anne and french - french ) -der " - this pointless age from - - director sophie import [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.303, rec=0.093, cos=0.003), tot_loss_proj:2.224 [t=0.26s]
prediction: ['[CLS] pointless import mean coming anne and french - french ) -der " - this pointless age from - - director sophie import [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.817 (perp=8.564, rec=0.101, cos=0.003), tot_loss_proj:2.259 [t=0.27s]
prediction: ['[CLS] pointless import mean coming anne and french - french ) - -der " this pointless age from - of director sophie import [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.746 (perp=8.207, rec=0.101, cos=0.003), tot_loss_proj:2.198 [t=0.26s]
prediction: ['[CLS] pointless import meander coming anne and french - french ) - - " this pointless age from - of director sophie import [SEP]']
[1050/2000] tot_loss=1.739 (perp=8.207, rec=0.095, cos=0.003), tot_loss_proj:2.189 [t=0.26s]
prediction: ['[CLS] pointless import meander coming anne and french - french ) - - " this pointless age from - of director sophie import [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.680 (perp=7.862, rec=0.105, cos=0.003), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] pointless import meander coming anne and french - french ) - - from this pointless age " - of director sophie import [SEP]']
Attempt swap
[1150/2000] tot_loss=1.671 (perp=7.862, rec=0.097, cos=0.003), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] pointless import meander coming anne and french - french ) - - from this pointless age " - of director sophie import [SEP]']
[1200/2000] tot_loss=1.666 (perp=7.862, rec=0.092, cos=0.002), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] pointless import meander coming anne and french - french ) - - from this pointless age " - of director sophie import [SEP]']
Attempt swap
[1250/2000] tot_loss=1.666 (perp=7.862, rec=0.091, cos=0.002), tot_loss_proj:2.102 [t=0.27s]
prediction: ['[CLS] pointless import meander coming anne and french - french ) - - from this pointless age " - of director sophie import [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.549 (perp=7.255, rec=0.095, cos=0.003), tot_loss_proj:1.989 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - of director sophie import [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.255, rec=0.096, cos=0.002), tot_loss_proj:1.992 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - of director sophie import [SEP]']
Attempt swap
[1400/2000] tot_loss=1.538 (perp=7.255, rec=0.085, cos=0.002), tot_loss_proj:1.987 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - of director sophie import [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.531 (perp=7.164, rec=0.096, cos=0.002), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - director of sophie import [SEP]']
[1500/2000] tot_loss=1.535 (perp=7.164, rec=0.100, cos=0.002), tot_loss_proj:1.984 [t=0.27s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - director of sophie import [SEP]']
Attempt swap
[1550/2000] tot_loss=1.526 (perp=7.164, rec=0.091, cos=0.002), tot_loss_proj:1.979 [t=0.27s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - director of sophie import [SEP]']
Attempt swap
[1600/2000] tot_loss=1.549 (perp=7.241, rec=0.098, cos=0.002), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of sophie import [SEP]']
[1650/2000] tot_loss=1.543 (perp=7.241, rec=0.093, cos=0.002), tot_loss_proj:1.996 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of sophie import [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.509 (perp=7.077, rec=0.092, cos=0.002), tot_loss_proj:1.960 [t=0.28s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
Attempt swap
[1750/2000] tot_loss=1.511 (perp=7.077, rec=0.093, cos=0.002), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
[1800/2000] tot_loss=1.509 (perp=7.077, rec=0.092, cos=0.002), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
Attempt swap
[1850/2000] tot_loss=1.507 (perp=7.077, rec=0.089, cos=0.002), tot_loss_proj:1.959 [t=0.25s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
Attempt swap
[1900/2000] tot_loss=1.507 (perp=7.077, rec=0.090, cos=0.002), tot_loss_proj:1.966 [t=0.27s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
[1950/2000] tot_loss=1.506 (perp=7.077, rec=0.088, cos=0.002), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
Attempt swap
[2000/2000] tot_loss=1.499 (perp=7.077, rec=0.081, cos=0.002), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] pointless import meander - anne and french - french ) - coming from this pointless age ) - director of import sophie [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] pointless import meander - anne and french - french ) - coming from this pointless age " - director of sophie import [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 77.778 | r: 82.353
rouge2     | fm: 6.061 | p: 5.882 | r: 6.250
rougeL     | fm: 45.714 | p: 44.444 | r: 47.059
rougeLsum  | fm: 45.714 | p: 44.444 | r: 47.059
r1fm+r2fm = 86.061

[Aggregate metrics]:
rouge1     | fm: 92.460 | p: 91.376 | r: 93.696
rouge2     | fm: 61.458 | p: 61.066 | r: 61.961
rougeL     | fm: 79.300 | p: 78.532 | r: 80.210
rougeLsum  | fm: 78.772 | p: 77.989 | r: 79.757
r1fm+r2fm = 153.918

input #26 time: 0:10:59 | total time: 4:04:19


Running input #27 of 100.
reference: 
========================
are so generic 
========================
*********************************
*********************************
average of cosine similarity 0.9993452360030666
highest_index [0]
highest [0.9993452360030666]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9331122636795044 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9077965617179871 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.8589619994163513 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8030321598052979 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8014320135116577 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.590 (perp=11.372, rec=0.732, cos=0.583), tot_loss_proj:3.748 [t=0.30s]
prediction: ['[CLS] we an contemporary [SEP]']
[ 100/2000] tot_loss=3.662 (perp=10.986, rec=0.643, cos=0.822), tot_loss_proj:2.556 [t=0.29s]
prediction: ['[CLS] generic so generic [SEP]']
[ 150/2000] tot_loss=4.459 (perp=14.497, rec=0.687, cos=0.873), tot_loss_proj:3.546 [t=0.29s]
prediction: ['[CLS] generic when instantly [SEP]']
[ 200/2000] tot_loss=3.939 (perp=12.021, rec=0.584, cos=0.950), tot_loss_proj:2.938 [t=0.28s]
prediction: ['[CLS] generic generic instantly [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.572 (perp=10.988, rec=0.603, cos=0.771), tot_loss_proj:2.673 [t=0.29s]
prediction: ['[CLS] instantly generic generic [SEP]']
[ 300/2000] tot_loss=2.554 (perp=10.988, rec=0.316, cos=0.041), tot_loss_proj:2.679 [t=0.29s]
prediction: ['[CLS] instantly generic generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.223 (perp=10.092, rec=0.194, cos=0.011), tot_loss_proj:2.590 [t=0.29s]
prediction: ['[CLS] where generic generic [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.044 (perp=9.381, rec=0.160, cos=0.008), tot_loss_proj:2.613 [t=0.29s]
prediction: ['[CLS] where are generic [SEP]']
[ 450/2000] tot_loss=2.011 (perp=9.381, rec=0.129, cos=0.006), tot_loss_proj:2.620 [t=0.28s]
prediction: ['[CLS] where are generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=9.381, rec=0.116, cos=0.005), tot_loss_proj:2.625 [t=0.26s]
prediction: ['[CLS] where are generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.186 (perp=10.270, rec=0.128, cos=0.004), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] generally are generic [SEP]']
[ 600/2000] tot_loss=2.161 (perp=10.270, rec=0.103, cos=0.004), tot_loss_proj:2.587 [t=0.25s]
prediction: ['[CLS] generally are generic [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.676 (perp=7.798, rec=0.112, cos=0.004), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] are generally generic [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.092 (perp=9.904, rec=0.107, cos=0.005), tot_loss_proj:2.287 [t=0.25s]
prediction: ['[CLS] generally so generic [SEP]']
[ 750/2000] tot_loss=2.086 (perp=9.904, rec=0.101, cos=0.004), tot_loss_proj:2.285 [t=0.27s]
prediction: ['[CLS] generally so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.086 (perp=9.904, rec=0.102, cos=0.004), tot_loss_proj:2.286 [t=0.25s]
prediction: ['[CLS] generally so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.320, rec=0.105, cos=0.004), tot_loss_proj:1.766 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.320, rec=0.104, cos=0.004), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.779 (perp=8.320, rec=0.111, cos=0.004), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.772 (perp=8.320, rec=0.104, cos=0.004), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.762 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.784 (perp=8.320, rec=0.116, cos=0.004), tot_loss_proj:1.756 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.784 (perp=8.320, rec=0.116, cos=0.004), tot_loss_proj:1.749 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.770 (perp=8.320, rec=0.102, cos=0.004), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.776 (perp=8.320, rec=0.108, cos=0.004), tot_loss_proj:1.760 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.762 (perp=8.320, rec=0.094, cos=0.004), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.320, rec=0.105, cos=0.004), tot_loss_proj:1.763 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.771 (perp=8.320, rec=0.103, cos=0.004), tot_loss_proj:1.766 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.774 (perp=8.320, rec=0.106, cos=0.004), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.778 (perp=8.320, rec=0.111, cos=0.004), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.320, rec=0.100, cos=0.004), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.756 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.768 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.769 (perp=8.320, rec=0.101, cos=0.004), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.769 (perp=8.320, rec=0.102, cos=0.004), tot_loss_proj:1.758 [t=0.27s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.320, rec=0.097, cos=0.004), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.320, rec=0.095, cos=0.004), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.760 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.320, rec=0.098, cos=0.004), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.320, rec=0.092, cos=0.004), tot_loss_proj:1.757 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.806 | p: 91.685 | r: 94.120
rouge2     | fm: 63.147 | p: 62.734 | r: 63.557
rougeL     | fm: 80.073 | p: 79.317 | r: 80.935
rougeLsum  | fm: 79.658 | p: 78.939 | r: 80.572
r1fm+r2fm = 155.953

input #27 time: 0:11:14 | total time: 4:15:34


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
*********************************
*********************************
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8165134787559509 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7931988835334778 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7827070355415344 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7524273991584778 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best rec loss: 0.7502107620239258 for ['[CLS]vron sex guessed morgan [SEP]']
[Init] best perm rec loss: 0.7490264177322388 for ['[CLS] guessed morganvron sex [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.421 (perp=10.463, rec=0.282, cos=0.046), tot_loss_proj:3.296 [t=0.30s]
prediction: ['[CLS] night for minutes decades [SEP]']
[ 100/2000] tot_loss=1.962 (perp=9.069, rec=0.134, cos=0.014), tot_loss_proj:2.895 [t=0.28s]
prediction: ['[CLS] days for minutes 71 [SEP]']
[ 150/2000] tot_loss=1.898 (perp=9.045, rec=0.085, cos=0.004), tot_loss_proj:2.504 [t=0.30s]
prediction: ['[CLS] only for minutes 71 [SEP]']
[ 200/2000] tot_loss=1.876 (perp=9.045, rec=0.065, cos=0.001), tot_loss_proj:2.503 [t=0.24s]
prediction: ['[CLS] only for minutes 71 [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.649 (perp=7.912, rec=0.065, cos=0.002), tot_loss_proj:1.942 [t=0.25s]
prediction: ['[CLS] only for 71 minutes [SEP]']
[ 300/2000] tot_loss=1.648 (perp=7.912, rec=0.064, cos=0.001), tot_loss_proj:1.935 [t=0.25s]
prediction: ['[CLS] only for 71 minutes [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.002), tot_loss_proj:1.633 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.629 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.625 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.632 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.593 (perp=7.699, rec=0.052, cos=0.001), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.603 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.614 (perp=7.699, rec=0.073, cos=0.001), tot_loss_proj:1.623 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.625 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.630 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.623 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.636 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.614 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.611 (perp=7.699, rec=0.070, cos=0.001), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.590 (perp=7.699, rec=0.049, cos=0.001), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.628 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.589 (perp=7.699, rec=0.048, cos=0.001), tot_loss_proj:1.621 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.633 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.604 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.615 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.583 (perp=7.699, rec=0.042, cos=0.001), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.622 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.591 (perp=7.699, rec=0.050, cos=0.001), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.023 | p: 91.999 | r: 94.221
rouge2     | fm: 64.559 | p: 64.232 | r: 64.956
rougeL     | fm: 80.807 | p: 80.024 | r: 81.629
rougeLsum  | fm: 80.180 | p: 79.358 | r: 81.017
r1fm+r2fm = 157.582

input #28 time: 0:10:58 | total time: 4:26:32


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
*********************************
*********************************
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9436143040657043 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9236282706260681 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9098904132843018 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8565943837165833 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8468968868255615 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8464521765708923 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.844285249710083 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8212891221046448 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8188213109970093 for ['[CLS] type attack www estate ambulance + chelsealand out todd [SEP]']
[Init] best rec loss: 0.8150292038917542 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 0.8131462931632996 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 0.8110625147819519 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 0.8109373450279236 for ['[CLS] runs administration tv oil this taste landed engagement envelopeuted [SEP]']
[Init] best perm rec loss: 0.8048712015151978 for ['[CLS] taste landed tv this engagementuted runs oil administration envelope [SEP]']
[Init] best perm rec loss: 0.8036940097808838 for ['[CLS] runs taste engagementuted envelope oil this tv landed administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.835 (perp=12.317, rec=0.324, cos=0.048), tot_loss_proj:3.952 [t=0.28s]
prediction: ['[CLS] think. faction aspects. meredith sanctions is attraction wasn [SEP]']
[ 100/2000] tot_loss=1.791 (perp=7.744, rec=0.219, cos=0.023), tot_loss_proj:2.983 [t=0.27s]
prediction: ['[CLS] think. believe resident. believe is that evil not [SEP]']
[ 150/2000] tot_loss=1.841 (perp=8.128, rec=0.201, cos=0.015), tot_loss_proj:3.068 [t=0.25s]
prediction: ['[CLS] also. believe resident. believe is that evil not [SEP]']
[ 200/2000] tot_loss=1.744 (perp=7.841, rec=0.168, cos=0.008), tot_loss_proj:3.044 [t=0.26s]
prediction: ['[CLS] i also believe resident. believe is that evil not [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.778 (perp=8.101, rec=0.147, cos=0.010), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] i also believe resident evil believe believe it that not [SEP]']
[ 300/2000] tot_loss=1.722 (perp=8.101, rec=0.096, cos=0.005), tot_loss_proj:2.970 [t=0.25s]
prediction: ['[CLS] i also believe resident evil believe believe it that not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.731 (perp=8.124, rec=0.101, cos=0.005), tot_loss_proj:2.892 [t=0.25s]
prediction: ['[CLS] i also i resident evil believe that believe it not [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.591 (perp=7.433, rec=0.099, cos=0.005), tot_loss_proj:2.841 [t=0.26s]
prediction: ['[CLS] i also believe resident evil i that believe it not [SEP]']
[ 450/2000] tot_loss=1.420 (perp=6.620, rec=0.093, cos=0.004), tot_loss_proj:2.634 [t=0.25s]
prediction: ['[CLS] i also believe resident evil. that believe it not [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.156 (perp=5.331, rec=0.087, cos=0.003), tot_loss_proj:2.597 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.065 (perp=4.884, rec=0.084, cos=0.004), tot_loss_proj:2.168 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 600/2000] tot_loss=1.053 (perp=4.884, rec=0.073, cos=0.003), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.053 (perp=4.884, rec=0.073, cos=0.003), tot_loss_proj:2.151 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.055 (perp=4.884, rec=0.075, cos=0.003), tot_loss_proj:2.161 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 750/2000] tot_loss=1.051 (perp=4.884, rec=0.072, cos=0.003), tot_loss_proj:2.154 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.051 (perp=4.884, rec=0.072, cos=0.003), tot_loss_proj:2.164 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.042 (perp=4.884, rec=0.063, cos=0.003), tot_loss_proj:2.155 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 900/2000] tot_loss=1.042 (perp=4.884, rec=0.062, cos=0.003), tot_loss_proj:2.167 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.048 (perp=4.884, rec=0.069, cos=0.003), tot_loss_proj:2.157 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.053 (perp=4.884, rec=0.073, cos=0.003), tot_loss_proj:2.156 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1050/2000] tot_loss=1.044 (perp=4.884, rec=0.064, cos=0.003), tot_loss_proj:2.151 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.056 (perp=4.884, rec=0.076, cos=0.003), tot_loss_proj:2.152 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.028 (perp=4.884, rec=0.048, cos=0.003), tot_loss_proj:2.161 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1200/2000] tot_loss=1.045 (perp=4.884, rec=0.065, cos=0.003), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.045 (perp=4.884, rec=0.065, cos=0.003), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.046 (perp=4.884, rec=0.067, cos=0.003), tot_loss_proj:2.150 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1350/2000] tot_loss=1.046 (perp=4.884, rec=0.066, cos=0.003), tot_loss_proj:2.153 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.043 (perp=4.884, rec=0.064, cos=0.003), tot_loss_proj:2.151 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.040 (perp=4.884, rec=0.060, cos=0.003), tot_loss_proj:2.156 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1500/2000] tot_loss=1.050 (perp=4.884, rec=0.071, cos=0.003), tot_loss_proj:2.151 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.043 (perp=4.884, rec=0.063, cos=0.003), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.054 (perp=4.884, rec=0.074, cos=0.003), tot_loss_proj:2.146 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1650/2000] tot_loss=1.049 (perp=4.884, rec=0.070, cos=0.003), tot_loss_proj:2.153 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.045 (perp=4.884, rec=0.066, cos=0.003), tot_loss_proj:2.150 [t=0.28s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.052 (perp=4.884, rec=0.072, cos=0.003), tot_loss_proj:2.149 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1800/2000] tot_loss=1.048 (perp=4.884, rec=0.068, cos=0.003), tot_loss_proj:2.143 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.041 (perp=4.884, rec=0.062, cos=0.003), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.039 (perp=4.884, rec=0.059, cos=0.003), tot_loss_proj:2.150 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1950/2000] tot_loss=1.050 (perp=4.884, rec=0.070, cos=0.003), tot_loss_proj:2.147 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.047 (perp=4.884, rec=0.068, cos=0.003), tot_loss_proj:2.142 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil. it is not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 93.224 | p: 92.179 | r: 94.420
rouge2     | fm: 64.539 | p: 64.118 | r: 64.904
rougeL     | fm: 81.058 | p: 80.421 | r: 81.951
rougeLsum  | fm: 80.717 | p: 79.980 | r: 81.607
r1fm+r2fm = 157.763

input #29 time: 0:10:54 | total time: 4:37:27


Running input #30 of 100.
reference: 
========================
fizzability 
========================
*********************************
*********************************
average of cosine similarity 0.9992720994590749
highest_index [0]
highest [0.9992720994590749]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9139088988304138 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8701140880584717 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8681485652923584 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 0.8041428923606873 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7869581580162048 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7338038682937622 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7189111113548279 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.7150062918663025 for ['[CLS] lizard acceleration council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.606 (perp=11.807, rec=0.231, cos=0.013), tot_loss_proj:3.726 [t=0.20s]
prediction: ['[CLS]zzability check [SEP]']
[ 100/2000] tot_loss=2.737 (perp=12.949, rec=0.137, cos=0.010), tot_loss_proj:3.721 [t=0.20s]
prediction: ['[CLS]zzability fi [SEP]']
[ 150/2000] tot_loss=2.685 (perp=12.949, rec=0.091, cos=0.005), tot_loss_proj:3.710 [t=0.20s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.693 (perp=12.949, rec=0.100, cos=0.003), tot_loss_proj:3.702 [t=0.20s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.998 (perp=9.540, rec=0.086, cos=0.005), tot_loss_proj:1.976 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.002), tot_loss_proj:1.977 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.002), tot_loss_proj:1.966 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.987 (perp=9.540, rec=0.076, cos=0.003), tot_loss_proj:1.966 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.002), tot_loss_proj:1.976 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.976 (perp=9.540, rec=0.067, cos=0.002), tot_loss_proj:1.965 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.976 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.965 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.989 (perp=9.540, rec=0.080, cos=0.001), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.963 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.981 (perp=9.540, rec=0.071, cos=0.001), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.984 (perp=9.540, rec=0.075, cos=0.001), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.996 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.969 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.976 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.973 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.968 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.961 (perp=9.540, rec=0.052, cos=0.001), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.958 (perp=9.540, rec=0.049, cos=0.001), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.978 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.965 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.955 (perp=9.540, rec=0.045, cos=0.001), tot_loss_proj:1.963 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.950 (perp=9.540, rec=0.041, cos=0.001), tot_loss_proj:1.978 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.956 (perp=9.540, rec=0.047, cos=0.001), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.505 | p: 92.513 | r: 94.624
rouge2     | fm: 65.960 | p: 65.551 | r: 66.357
rougeL     | fm: 81.588 | p: 80.910 | r: 82.435
rougeLsum  | fm: 81.163 | p: 80.514 | r: 82.048
r1fm+r2fm = 159.465

input #30 time: 0:10:00 | total time: 4:47:28


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
*********************************
*********************************
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9432398676872253 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.920174777507782 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8837398290634155 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8651828765869141 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8041785955429077 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8038828372955322 for ['[CLS] robin running artwork [SEP]']
[Init] best perm rec loss: 0.8038730621337891 for ['[CLS] artwork running robin [SEP]']
[Init] best perm rec loss: 0.7982505559921265 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.427 (perp=10.683, rec=0.266, cos=0.024), tot_loss_proj:2.933 [t=0.26s]
prediction: ['[CLS] better vehicle ideas [SEP]']
[ 100/2000] tot_loss=2.105 (perp=9.658, rec=0.159, cos=0.014), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.041 (perp=9.638, rec=0.105, cos=0.008), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] better vehicle a [SEP]']
[ 200/2000] tot_loss=2.010 (perp=9.638, rec=0.081, cos=0.002), tot_loss_proj:2.554 [t=0.25s]
prediction: ['[CLS] better vehicle a [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.602 (perp=7.603, rec=0.078, cos=0.003), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.721 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.703 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.698 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.703 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.702 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.710 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.706 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.586 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.734 | p: 92.801 | r: 94.805
rouge2     | fm: 66.918 | p: 66.512 | r: 67.283
rougeL     | fm: 82.190 | p: 81.515 | r: 83.027
rougeLsum  | fm: 81.963 | p: 81.397 | r: 82.781
r1fm+r2fm = 160.652

input #31 time: 0:10:58 | total time: 4:58:27


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
*********************************
*********************************
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0409706830978394 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9490888714790344 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8853940367698669 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8810258507728577 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8623101115226746 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8531050086021423 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8450931906700134 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8438608646392822 for ['[CLS] athletic palace th thomasshire bio cake circle lilith fundscting natalie [SEP]']
[Init] best perm rec loss: 0.842842161655426 for ['[CLS] cake funds lilith athletic thshire biocting natalie palace circle thomas [SEP]']
[Init] best perm rec loss: 0.8413686156272888 for ['[CLS] th natalie circlecting thomas funds bio lilith palace cakeshire athletic [SEP]']
[Init] best perm rec loss: 0.8397578001022339 for ['[CLS]cting lilith thomas cake bio athleticshire natalie th circle palace funds [SEP]']
[Init] best perm rec loss: 0.8387935161590576 for ['[CLS] cakecting natalie bio lilith athletic th thomas circle palaceshire funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.683 (perp=12.117, rec=0.255, cos=0.004), tot_loss_proj:3.513 [t=0.29s]
prediction: ['[CLS] brandful release accessible to com accessible stories easily installations absolutely emotion [SEP]']
[ 100/2000] tot_loss=2.529 (perp=11.638, rec=0.197, cos=0.004), tot_loss_proj:3.728 [t=0.30s]
prediction: ['[CLS] brand with easily accessibleonate withonate storiesel installations almostonate [SEP]']
[ 150/2000] tot_loss=2.325 (perp=10.885, rec=0.145, cos=0.002), tot_loss_proj:3.484 [t=0.29s]
prediction: ['[CLS] pull together easily accessibleonate withonate stories pull installations resonate [SEP]']
[ 200/2000] tot_loss=2.489 (perp=11.765, rec=0.133, cos=0.002), tot_loss_proj:3.333 [t=0.29s]
prediction: ['[CLS] pull together easily accessibleonate thatonate stories pull writer resonate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.451 (perp=11.727, rec=0.104, cos=0.002), tot_loss_proj:3.794 [t=0.29s]
prediction: ['[CLS] pull together easily accessible stories thatonateonate pull writerundonate [SEP]']
[ 300/2000] tot_loss=2.447 (perp=11.727, rec=0.100, cos=0.002), tot_loss_proj:3.800 [t=0.29s]
prediction: ['[CLS] pull together easily accessible stories thatonateonate pull writerundonate [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.170 (perp=10.397, rec=0.089, cos=0.002), tot_loss_proj:3.015 [t=0.29s]
prediction: ['[CLS] pull together easily accessible stories thatity withonate writerund pull [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.392 (perp=11.471, rec=0.096, cos=0.002), tot_loss_proj:3.755 [t=0.28s]
prediction: ['[CLS] pull together easily accessible stories res withonatecasedundity pull [SEP]']
[ 450/2000] tot_loss=2.395 (perp=11.579, rec=0.077, cos=0.002), tot_loss_proj:3.755 [t=0.29s]
prediction: ['[CLS] pull together easily accessible stories res withonatecasedundity prof [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.111 (perp=10.144, rec=0.080, cos=0.002), tot_loss_proj:3.308 [t=0.27s]
prediction: ['[CLS] pull together easily accessible stories with resonatecasedundity prof [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.783 (perp=8.426, rec=0.096, cos=0.002), tot_loss_proj:2.189 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories with resonatecased profundity [SEP]']
[ 600/2000] tot_loss=1.762 (perp=8.426, rec=0.075, cos=0.002), tot_loss_proj:2.200 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories with resonatecased profundity [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.704 (perp=8.116, rec=0.079, cos=0.002), tot_loss_proj:1.876 [t=0.27s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.705 (perp=8.116, rec=0.080, cos=0.002), tot_loss_proj:1.871 [t=0.28s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
[ 750/2000] tot_loss=1.702 (perp=8.116, rec=0.078, cos=0.002), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.699 (perp=8.116, rec=0.074, cos=0.002), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.701 (perp=8.116, rec=0.076, cos=0.002), tot_loss_proj:1.867 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
[ 900/2000] tot_loss=1.699 (perp=8.116, rec=0.074, cos=0.002), tot_loss_proj:1.866 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=8.116, rec=0.070, cos=0.002), tot_loss_proj:1.871 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.700 (perp=8.116, rec=0.075, cos=0.002), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
[1050/2000] tot_loss=1.694 (perp=8.116, rec=0.069, cos=0.002), tot_loss_proj:1.868 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=8.420, rec=0.073, cos=0.002), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonatevocation with profundity [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.767 (perp=8.492, rec=0.067, cos=0.002), tot_loss_proj:2.178 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories resonate withlogy profundity [SEP]']
[1200/2000] tot_loss=1.765 (perp=8.492, rec=0.065, cos=0.002), tot_loss_proj:2.182 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonate withlogy profundity [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.698 (perp=8.116, rec=0.074, cos=0.002), tot_loss_proj:1.871 [t=0.27s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.695 (perp=8.116, rec=0.070, cos=0.002), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]']
[1350/2000] tot_loss=1.761 (perp=8.420, rec=0.076, cos=0.002), tot_loss_proj:1.968 [t=0.24s]
prediction: ['[CLS] pull together easily accessible stories resonatevocation with profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.754 (perp=8.420, rec=0.068, cos=0.002), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories resonatevocation with profundity [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.748 (perp=8.355, rec=0.076, cos=0.002), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories resonate withvocation profundity [SEP]']
[1500/2000] tot_loss=1.741 (perp=8.355, rec=0.069, cos=0.002), tot_loss_proj:2.619 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories resonate withvocation profundity [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.640 (perp=7.831, rec=0.072, cos=0.002), tot_loss_proj:2.553 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories why resonate with profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.645 (perp=7.831, rec=0.077, cos=0.002), tot_loss_proj:2.551 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories why resonate with profundity [SEP]']
[1650/2000] tot_loss=1.642 (perp=7.831, rec=0.074, cos=0.002), tot_loss_proj:2.552 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories why resonate with profundity [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.773 (perp=8.492, rec=0.073, cos=0.002), tot_loss_proj:2.048 [t=0.25s]
prediction: ['[CLS] pull together easily accessiblevocation stories resonate with profundity [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.641 (perp=7.831, rec=0.073, cos=0.002), tot_loss_proj:2.558 [t=0.26s]
prediction: ['[CLS] pull together easily accessible stories why resonate with profundity [SEP]']
[1800/2000] tot_loss=1.636 (perp=7.831, rec=0.068, cos=0.002), tot_loss_proj:2.557 [t=0.25s]
prediction: ['[CLS] pull together easily accessible stories why resonate with profundity [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.554 (perp=7.424, rec=0.068, cos=0.002), tot_loss_proj:2.224 [t=0.25s]
prediction: ['[CLS] pull together easily accessible why stories resonate with profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.558 (perp=7.424, rec=0.072, cos=0.002), tot_loss_proj:2.228 [t=0.26s]
prediction: ['[CLS] pull together easily accessible why stories resonate with profundity [SEP]']
[1950/2000] tot_loss=1.552 (perp=7.424, rec=0.066, cos=0.002), tot_loss_proj:2.227 [t=0.25s]
prediction: ['[CLS] pull together easily accessible why stories resonate with profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.551 (perp=7.424, rec=0.065, cos=0.002), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] pull together easily accessible why stories resonate with profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pull together easily accessible stories resonatelogy with profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 90.000 | r: 81.818
rouge2     | fm: 73.684 | p: 77.778 | r: 70.000
rougeL     | fm: 85.714 | p: 90.000 | r: 81.818
rougeLsum  | fm: 85.714 | p: 90.000 | r: 81.818
r1fm+r2fm = 159.398

[Aggregate metrics]:
rouge1     | fm: 93.489 | p: 92.706 | r: 94.382
rouge2     | fm: 67.060 | p: 66.856 | r: 67.285
rougeL     | fm: 81.868 | p: 81.297 | r: 82.565
rougeLsum  | fm: 82.294 | p: 81.696 | r: 82.963
r1fm+r2fm = 160.550

input #32 time: 0:11:16 | total time: 5:09:43


Running input #33 of 100.
reference: 
========================
higher 
========================
*********************************
*********************************
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9998520612716675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9732957482337952 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9511236548423767 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9041293859481812 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8212264180183411 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7986159920692444 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7904055118560791 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=11.231, rec=0.126, cos=0.007), tot_loss_proj:3.013 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.002), tot_loss_proj:2.403 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.330 (perp=11.231, rec=0.082, cos=0.001), tot_loss_proj:2.404 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.002), tot_loss_proj:2.397 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.002), tot_loss_proj:2.383 [t=0.30s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.002), tot_loss_proj:2.395 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.394 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.387 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.388 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.397 [t=0.30s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.388 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.315 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.403 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.317 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.399 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.388 [t=0.31s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.381 [t=0.30s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.396 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.401 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.393 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.402 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.402 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.403 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.393 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.400 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.399 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.388 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.403 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.293 (perp=11.231, rec=0.045, cos=0.001), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.320 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.404 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.321 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.398 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.402 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.403 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.394 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.400 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.645 | p: 92.932 | r: 94.568
rouge2     | fm: 67.713 | p: 67.526 | r: 67.999
rougeL     | fm: 82.558 | p: 82.039 | r: 83.214
rougeLsum  | fm: 82.530 | p: 82.013 | r: 83.236
r1fm+r2fm = 161.357

input #33 time: 0:11:26 | total time: 5:21:10


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
*********************************
*********************************
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8935192823410034 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8888072967529297 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8439813256263733 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8383127450942993 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.813098132610321 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8127062320709229 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.8103282451629639 for ['[CLS] who slightask founderibe field lissa along ship drivers statue worth okay [SEP]']
[Init] best perm rec loss: 0.8098567128181458 for ['[CLS] field slight who statueibe founder lissa shipask drivers okay along worth [SEP]']
[Init] best perm rec loss: 0.808777928352356 for ['[CLS] okayibe statueask slight founder along drivers field worth ship who lissa [SEP]']
[Init] best perm rec loss: 0.8087007999420166 for ['[CLS] okay field ship slight alongask statue lissa founder worth driversibe who [SEP]']
[Init] best perm rec loss: 0.8083059787750244 for ['[CLS] who along lissa ship statue okay slight field driversibe worth founderask [SEP]']
[Init] best perm rec loss: 0.8071286082267761 for ['[CLS] worth founder drivers okay along ship lissa field whoask statueibe slight [SEP]']
[Init] best perm rec loss: 0.8067096471786499 for ['[CLS] founder worth okayaskibe lissa who statue along drivers ship slight field [SEP]']
[Init] best perm rec loss: 0.8060021996498108 for ['[CLS] slight founder fieldaskibe okay lissa ship statue who worth along drivers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.565 (perp=11.182, rec=0.306, cos=0.023), tot_loss_proj:4.072 [t=0.25s]
prediction: ['[CLS] russell confines energy team visual urgency capture overwhelmed viewer. urgency the clinical [SEP]']
[ 100/2000] tot_loss=2.592 (perp=12.039, rec=0.178, cos=0.007), tot_loss_proj:3.535 [t=0.26s]
prediction: ['[CLS] primera in urgency viewer visual urgency build take viewer. urgency extreme extreme [SEP]']
[ 150/2000] tot_loss=2.319 (perp=10.867, rec=0.140, cos=0.005), tot_loss_proj:3.525 [t=0.24s]
prediction: ['[CLS] spider in mind viewer viewer urgency build take viewer and urgency extreme extreme [SEP]']
[ 200/2000] tot_loss=2.412 (perp=11.452, rec=0.118, cos=0.003), tot_loss_proj:3.601 [t=0.25s]
prediction: ['[CLS] spider in mind mind viewer urgency build take viewer and urgency extreme extreme [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.827 (perp=8.542, rec=0.116, cos=0.003), tot_loss_proj:2.940 [t=0.27s]
prediction: ['[CLS] necessarily in mind the take urgency build inner viewer and urgency extreme. [SEP]']
[ 300/2000] tot_loss=1.764 (perp=8.368, rec=0.088, cos=0.002), tot_loss_proj:3.011 [t=0.25s]
prediction: ['[CLS] now in mind the take urgency build viewer viewer and urgency extreme. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.774 (perp=8.393, rec=0.093, cos=0.003), tot_loss_proj:2.638 [t=0.26s]
prediction: ['[CLS] characters in mind the take urgency build viewer and inner urgency extreme. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.693 (perp=8.023, rec=0.086, cos=0.003), tot_loss_proj:2.478 [t=0.25s]
prediction: ['[CLS] mind in mind the urgency build viewer and inner urgency take extreme. [SEP]']
[ 450/2000] tot_loss=1.650 (perp=7.843, rec=0.080, cos=0.002), tot_loss_proj:2.524 [t=0.25s]
prediction: ['[CLS] characters in mind the urgency build viewer and inner urgency take extreme. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.789 (perp=8.489, rec=0.090, cos=0.002), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] mind in the urgency build viewer mind and inner urgency take extreme. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.454 (perp=9.489, rec=0.461, cos=0.096), tot_loss_proj:3.127 [t=0.26s]
prediction: ['[CLS] in jeremy the operations build viewer mind and slightly urgency take extreme. [SEP]']
[ 600/2000] tot_loss=2.199 (perp=9.458, rec=0.285, cos=0.023), tot_loss_proj:3.092 [t=0.25s]
prediction: ['[CLS] in alex thecultural build viewer mind and slightly urgency take extreme. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.118 (perp=9.415, rec=0.223, cos=0.012), tot_loss_proj:2.825 [t=0.25s]
prediction: ['[CLS] in alex thehetic build viewer mind and slightly extreme urgency take. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.866 (perp=8.378, rec=0.182, cos=0.008), tot_loss_proj:2.376 [t=0.25s]
prediction: ['[CLS] in bob the urgency build viewer mind and take slightly extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.844 (perp=8.378, rec=0.162, cos=0.006), tot_loss_proj:2.369 [t=0.26s]
prediction: ['[CLS] in bob the urgency build viewer mind and take slightly extreme urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.820 (perp=8.363, rec=0.142, cos=0.005), tot_loss_proj:2.224 [t=0.25s]
prediction: ['[CLS] in bob the urgency build viewer mind and take extreme extreme urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.831 (perp=8.363, rec=0.153, cos=0.005), tot_loss_proj:2.231 [t=0.25s]
prediction: ['[CLS] in bob the urgency build viewer mind and take extreme extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.806 (perp=8.363, rec=0.129, cos=0.005), tot_loss_proj:2.225 [t=0.25s]
prediction: ['[CLS] in bob the urgency build viewer mind and take extreme extreme urgency. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.764 (perp=8.181, rec=0.123, cos=0.004), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] in the urgency build bob viewer mind and take extreme extreme urgency. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.735 (perp=8.014, rec=0.128, cos=0.004), tot_loss_proj:2.424 [t=0.25s]
prediction: ['[CLS] the urgency build in bob viewer mind and take extreme extreme urgency. [SEP]']
[1050/2000] tot_loss=1.721 (perp=8.014, rec=0.114, cos=0.004), tot_loss_proj:2.420 [t=0.25s]
prediction: ['[CLS] the urgency build in bob viewer mind and take extreme extreme urgency. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.686 (perp=7.751, rec=0.131, cos=0.004), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] the urgency build in mind bob viewer and take extreme extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.664 (perp=7.751, rec=0.110, cos=0.004), tot_loss_proj:2.444 [t=0.25s]
prediction: ['[CLS] the urgency build in mind bob viewer and take extreme extreme urgency. [SEP]']
[1200/2000] tot_loss=1.659 (perp=7.714, rec=0.113, cos=0.004), tot_loss_proj:2.362 [t=0.26s]
prediction: ['[CLS] the urgency build in mind john viewer and take extreme extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.655 (perp=7.714, rec=0.109, cos=0.004), tot_loss_proj:2.372 [t=0.27s]
prediction: ['[CLS] the urgency build in mind john viewer and take extreme extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.663 (perp=7.714, rec=0.117, cos=0.004), tot_loss_proj:2.367 [t=0.27s]
prediction: ['[CLS] the urgency build in mind john viewer and take extreme extreme urgency. [SEP]']
[1350/2000] tot_loss=1.657 (perp=7.714, rec=0.111, cos=0.004), tot_loss_proj:2.368 [t=0.25s]
prediction: ['[CLS] the urgency build in mind john viewer and take extreme extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=7.714, rec=0.105, cos=0.003), tot_loss_proj:2.360 [t=0.27s]
prediction: ['[CLS] the urgency build in mind john viewer and take extreme extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.592 (perp=7.411, rec=0.107, cos=0.003), tot_loss_proj:2.325 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the viewer and take extreme extreme urgency. [SEP]']
[1500/2000] tot_loss=1.594 (perp=7.411, rec=0.109, cos=0.003), tot_loss_proj:2.312 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the viewer and take extreme extreme urgency. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.552 (perp=7.184, rec=0.111, cos=0.004), tot_loss_proj:2.156 [t=0.26s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.547 (perp=7.184, rec=0.107, cos=0.004), tot_loss_proj:2.144 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
[1650/2000] tot_loss=1.547 (perp=7.184, rec=0.107, cos=0.004), tot_loss_proj:2.147 [t=0.26s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=7.184, rec=0.104, cos=0.003), tot_loss_proj:2.152 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.545 (perp=7.184, rec=0.104, cos=0.003), tot_loss_proj:2.146 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
[1800/2000] tot_loss=1.541 (perp=7.184, rec=0.101, cos=0.003), tot_loss_proj:2.140 [t=0.26s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.544 (perp=7.184, rec=0.104, cos=0.003), tot_loss_proj:2.146 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.544 (perp=7.184, rec=0.104, cos=0.003), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
[1950/2000] tot_loss=1.544 (perp=7.184, rec=0.104, cos=0.003), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=7.184, rec=0.109, cos=0.003), tot_loss_proj:2.146 [t=0.25s]
prediction: ['[CLS] john urgency build in mind the extreme viewer and take extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] characters in mind the urgency build viewer and inner urgency take extreme. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 7.692 | p: 7.692 | r: 7.692
rougeL     | fm: 64.286 | p: 64.286 | r: 64.286
rougeLsum  | fm: 64.286 | p: 64.286 | r: 64.286
r1fm+r2fm = 86.264

[Aggregate metrics]:
rouge1     | fm: 93.251 | p: 92.515 | r: 94.104
rouge2     | fm: 66.328 | p: 66.059 | r: 66.600
rougeL     | fm: 82.043 | p: 81.532 | r: 82.752
rougeLsum  | fm: 82.212 | p: 81.645 | r: 82.790
r1fm+r2fm = 159.579

input #34 time: 0:10:51 | total time: 5:32:01


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
*********************************
*********************************
average of cosine similarity 0.9993278544896085
highest_index [0]
highest [0.9993278544896085]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9250960350036621 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9220249056816101 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9155790209770203 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9139524698257446 for ['[CLS] field thousand published nightmares alternative organized position primary energy one appointment act sole device flow,sardrive somehow lack intervals outside denied sleeper singerght beauty isabella signs fae part lynch zion pages provincevil ms folk fadedran deserve dynamic [SEP]']
[Init] best perm rec loss: 0.9106967449188232 for ['[CLS] province nightmares deserve energy act fae ms singer device field alternative folk denied signs flow thousand outsidedrive beauty intervals somehow published isabella part organized lack primaryght sleeper position lynch,dran solesar zion pages appointment dynamicvil one fade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.592 (perp=11.037, rec=0.369, cos=0.016), tot_loss_proj:3.754 [t=0.26s]
prediction: ['[CLS]... growing 1960s amazing passion bouquet we charles magic they. this felt state creative looks about at 2013 experience with of visual visual perfect your education religion great lead because its john coward " eight especially ramsey great [SEP]. hate [SEP]']
[ 100/2000] tot_loss=2.407 (perp=10.666, rec=0.268, cos=0.006), tot_loss_proj:3.858 [t=0.27s]
prediction: ["[CLS] but : tells'care shape we by hank they'before but andrew beam shown'of greatest experience with about visual director perfect recent makes critic great'about its john coward care'' republic important [SEP], hate [SEP]"]
[ 150/2000] tot_loss=2.187 (perp=9.771, rec=0.229, cos=0.004), tot_loss_proj:3.461 [t=0.27s]
prediction: ["[CLS] but has his'care shape we by before we'before but except will'' of greatest before it of pictures director handsome help makes source great'about itsnation coward care'' position 'nation, ve [SEP]"]
[ 200/2000] tot_loss=2.134 (perp=9.614, rec=0.207, cos=0.004), tot_loss_proj:3.380 [t=0.26s]
prediction: ["[CLS] we has his'seen all us'before we'before but of will'' of latest before clearly from pictures director superb help makesnation great'about hisnation coward care'' rein 'nation, ve [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.217 (perp=9.626, rec=0.280, cos=0.012), tot_loss_proj:3.451 [t=0.26s]
prediction: ["[CLS] we ve this'seen all us ve before we'before but director the 'nation of greatest of still from - director superb help makesnation great'about tree'coward care'' rein 'nation, ve [SEP]"]
[ 300/2000] tot_loss=2.183 (perp=9.705, rec=0.238, cos=0.005), tot_loss_proj:3.034 [t=0.26s]
prediction: ["[CLS], ve teacher how seen'us'lewis we'before but director the 'nation on great. it from anniversary director with help makes. great'aboutization.ience care 'ausen husband greatest [SEP]. ve [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.256 (perp=9.976, rec=0.253, cos=0.007), tot_loss_proj:3.389 [t=0.28s]
prediction: ["[CLS] [SEP] ve teacher we seen they us seen without we'before but field the 'nation on latest! it from anniversary director with help makes. great'aboutnation ofmerie care'rehab calling greatest,, ve [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.042 (perp=9.246, rec=0.189, cos=0.004), tot_loss_proj:3.505 [t=0.28s]
prediction: ["[CLS] [SEP] ve teacher we seen'us seen without it'before but field the 'nation on latest bonus we from anniversary director with help makes. great'aboutnation. compute care'rehabnation greatest,, ve [SEP]"]
[ 450/2000] tot_loss=2.663 (perp=10.179, rec=0.578, cos=0.049), tot_loss_proj:4.014 [t=0.26s]
prediction: ["[CLS] [SEP] ve initial. seen the us ve helicopters slalom'before butfield one a. buddha eliminated bonus we. [SEP] director with latest made.., aboutnation [SEP] load care'[SEP] [SEP] greatest.. ve [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.549 (perp=10.327, rec=0.459, cos=0.025), tot_loss_proj:4.073 [t=0.26s]
prediction: ["[CLS] appealed ve initial top seen the us chopper against slalom'before but latest one a. buddha eliminated bonus we. [SEP] director withfield made.., aboutnation [SEP] load care'[SEP] [SEP] greatest.. [SEP] [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.409 (perp=10.014, rec=0.388, cos=0.018), tot_loss_proj:3.954 [t=0.27s]
prediction: ["[CLS] products have initial top seen the us chopper against slalom'fed but before one a. buddha eliminated bonus we. crash director withfield made.., aboutnation [SEP]″ care'[SEP] were greatest.. [SEP] [SEP]"]
[ 600/2000] tot_loss=2.369 (perp=10.014, rec=0.353, cos=0.013), tot_loss_proj:3.938 [t=0.26s]
prediction: ["[CLS] products have initial top seen the us chopper against slalom'fed but before one a. buddha eliminated bonus we. crash director withfield made.., aboutnation [SEP]″ care'[SEP] were greatest.. [SEP] [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=2.302 (perp=9.828, rec=0.325, cos=0.011), tot_loss_proj:3.948 [t=0.25s]
prediction: ["[CLS] products have initial top seen the us chopper against slalom'fed but before one a. ء eliminated bonus we. director withfield makes.., about crashnation [SEP]″ care'[SEP] were greatest.. [SEP] [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.255 (perp=9.742, rec=0.297, cos=0.009), tot_loss_proj:3.834 [t=0.25s]
prediction: ["[CLS] won have initial top seen the us chopper behind slalom'fed but before one a. keynote eliminated bonus we were director withfield makes.., about crashnation [SEP]″ care'[SEP]. greatest.. [SEP] [SEP]"]
[ 750/2000] tot_loss=2.343 (perp=9.998, rec=0.333, cos=0.010), tot_loss_proj:3.928 [t=0.25s]
prediction: ["[CLS] features recently initial top seen the us chopper behind slalom'fed but before one a. technical eliminated bonus we were director withfield makes.., about [SEP]nation [SEP]″ care'[SEP]. greatest.. [SEP] [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.317 (perp=9.999, rec=0.309, cos=0.008), tot_loss_proj:3.931 [t=0.26s]
prediction: ["[CLS] features recently initial top seen the us chopper behind slalom'fed but before one a. [SEP] eliminated vs we were director withfield makes.., about lexination [SEP]″ care'technical. greatest.. [SEP] [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.256 (perp=9.752, rec=0.298, cos=0.008), tot_loss_proj:3.940 [t=0.26s]
prediction: ["[CLS] with recently initial recent seen the us chopper behind slalom'fed but before one a. [SEP] eliminated vs we were director featuresfield makes.., about bullnation [SEP]″ care'technical. greatest.. [SEP] [SEP]"]
[ 900/2000] tot_loss=2.240 (perp=9.752, rec=0.282, cos=0.007), tot_loss_proj:3.938 [t=0.26s]
prediction: ["[CLS] with recently initial recent seen the us chopper behind slalom'fed but before one a. [SEP] eliminated vs we were director featuresfield makes.., about bullnation [SEP]″ care'technical. greatest.. [SEP] [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.251 (perp=9.789, rec=0.286, cos=0.007), tot_loss_proj:3.883 [t=0.30s]
prediction: ["[CLS] withhear the glint seen initial us chopper behind slalom'fed but before one a. [SEP] eliminated vs we were director featuresfield makes.., about [SEP]nation [SEP]″ care'technical. greatest.. [SEP] [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.268 (perp=9.952, rec=0.271, cos=0.007), tot_loss_proj:3.946 [t=0.25s]
prediction: ["[CLS] withhear the elementary seen initial us chopper behind slalom'fed but before captain a. were eliminated vs we [SEP] director previouslyfield makes.., about bullnation [SEP]″ care'peas. greatest.. [SEP] [SEP]"]
[1050/2000] tot_loss=2.258 (perp=9.952, rec=0.261, cos=0.007), tot_loss_proj:3.944 [t=0.27s]
prediction: ["[CLS] withhear the elementary seen initial us chopper behind slalom'fed but before captain a. were eliminated vs we [SEP] director previouslyfield makes.., about bullnation [SEP]″ care'peas. greatest.. [SEP] [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=2.215 (perp=9.736, rec=0.262, cos=0.006), tot_loss_proj:3.955 [t=0.27s]
prediction: ["[CLS] withhear the elementary seen initial uszbek behind slalom'fed but before captain a vs. were eliminated we [SEP] director previouslyfield makes.., about bullnation [SEP]″ care'peas. greatest.. seen [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=2.244 (perp=9.850, rec=0.268, cos=0.007), tot_loss_proj:3.981 [t=0.26s]
prediction: ['[CLS] despitehear the initial millennium seen uszbek behind slalom\'fed but before captain " vs. were eliminated we [SEP] director previouslyfield makes.., about bullnation [SEP]″ care\'peas. greatest.. seen [SEP]']
[1200/2000] tot_loss=2.222 (perp=9.724, rec=0.271, cos=0.006), tot_loss_proj:3.932 [t=0.27s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'fed but before captain " vs. were eliminated we [SEP] director previouslyfield makes.., about bullnation [SEP]″ care\'peas. greatest.. seen [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.195 (perp=9.655, rec=0.258, cos=0.006), tot_loss_proj:3.912 [t=0.26s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'fed but before captain " vs. were steve we greatest director previouslyfield makes.., about bullnation [SEP]″ care\'peas. [SEP].. seen [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.148 (perp=9.462, rec=0.250, cos=0.006), tot_loss_proj:3.811 [t=0.28s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before captain " vs. were mary we greatest director previouslyfield made.., about bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
[1350/2000] tot_loss=2.152 (perp=9.462, rec=0.254, cos=0.006), tot_loss_proj:3.810 [t=0.27s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before captain " vs. were mary we greatest director previouslyfield made.., about bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.129 (perp=9.378, rec=0.248, cos=0.006), tot_loss_proj:3.752 [t=0.26s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before captain " vs. werefield we greatest director previously mary made.., about bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.094 (perp=9.248, rec=0.238, cos=0.006), tot_loss_proj:3.668 [t=0.26s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before captain " vs. werefield we greatest director previously made.., about mary [SEP]nation [SEP]″ care\'steve. [SEP].. seen [SEP]']
[1500/2000] tot_loss=2.100 (perp=9.254, rec=0.244, cos=0.006), tot_loss_proj:3.741 [t=0.25s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before captain " vs. werefield we greatest director previously makes.., about mary bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.114 (perp=9.348, rec=0.238, cos=0.006), tot_loss_proj:3.634 [t=0.28s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before. " vs. werefield we greatest director features makes. captain, about mary bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.076 (perp=9.166, rec=0.237, cos=0.006), tot_loss_proj:3.613 [t=0.26s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before. " vs. werefield we greatest director features makes. mary, about captain bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
[1650/2000] tot_loss=2.074 (perp=9.166, rec=0.235, cos=0.006), tot_loss_proj:3.615 [t=0.25s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before. " vs. werefield we greatest director features makes. mary, about captain bullnation [SEP]″ care\'steve. [SEP].. seen [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.056 (perp=9.035, rec=0.244, cos=0.006), tot_loss_proj:3.606 [t=0.25s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before. " vs. werefield we greatest director steve makes. mary, about captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.048 (perp=9.025, rec=0.237, cos=0.006), tot_loss_proj:3.611 [t=0.25s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before. " vs. werefield we greatest director steve makes. mary about, captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
[1800/2000] tot_loss=2.040 (perp=9.025, rec=0.229, cos=0.006), tot_loss_proj:3.610 [t=0.26s]
prediction: ['[CLS] despitehear the initial millennium seen us tamara behind slalom\'latest but before. " vs. werefield we greatest director steve makes. mary about, captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.027 (perp=8.925, rec=0.236, cos=0.006), tot_loss_proj:3.584 [t=0.27s]
prediction: ['[CLS] despitehear the initial latest seen us tamara behind slalom\'millennium but before. " vs. werefield we greatest director steve makes. mary about, captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
Attempt swap
[1900/2000] tot_loss=2.029 (perp=8.925, rec=0.238, cos=0.006), tot_loss_proj:3.582 [t=0.28s]
prediction: ['[CLS] despitehear the initial latest seen us tamara behind slalom\'millennium but before. " vs. werefield we greatest director steve makes. mary about, captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
[1950/2000] tot_loss=2.029 (perp=8.925, rec=0.238, cos=0.006), tot_loss_proj:3.582 [t=0.28s]
prediction: ['[CLS] despitehear the initial latest seen us tamara behind slalom\'millennium but before. " vs. werefield we greatest director steve makes. mary about, captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
Attempt swap
[2000/2000] tot_loss=2.023 (perp=8.925, rec=0.232, cos=0.006), tot_loss_proj:3.584 [t=0.25s]
prediction: ['[CLS] despitehear the initial latest seen us tamara behind slalom\'millennium but before. " vs. werefield we greatest director steve makes. mary about, captain bullnation [SEP]″ care\'features. [SEP].. seen [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] [SEP] ve teacher we seen'us seen without it'before but field the 'nation on latest bonus we from anniversary director with help makes. great'aboutnation. compute care'rehab rein greatest,, ve [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.971 | p: 58.824 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 37.681 | p: 38.235 | r: 37.143
rougeLsum  | fm: 37.681 | p: 38.235 | r: 37.143
r1fm+r2fm = 57.971

[Aggregate metrics]:
rouge1     | fm: 92.238 | p: 91.568 | r: 93.076
rouge2     | fm: 64.275 | p: 63.992 | r: 64.560
rougeL     | fm: 80.800 | p: 80.299 | r: 81.429
rougeLsum  | fm: 80.938 | p: 80.476 | r: 81.509
r1fm+r2fm = 156.513

input #35 time: 0:10:59 | total time: 5:43:00


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
*********************************
*********************************
average of cosine similarity 0.9992842743865826
highest_index [0]
highest [0.9992842743865826]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9986883401870728 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9958099126815796 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9545882940292358 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9252082705497742 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9223971962928772 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9177457690238953 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8233659863471985 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8216447234153748 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8213571906089783 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8175345659255981 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.032 (perp=9.529, rec=0.120, cos=0.006), tot_loss_proj:2.293 [t=0.25s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.901 (perp=9.148, rec=0.070, cos=0.002), tot_loss_proj:2.126 [t=0.27s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.899 (perp=9.148, rec=0.068, cos=0.002), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.898 (perp=9.148, rec=0.067, cos=0.002), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.903 (perp=9.148, rec=0.072, cos=0.002), tot_loss_proj:2.134 [t=0.25s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.903 (perp=9.148, rec=0.071, cos=0.002), tot_loss_proj:2.136 [t=0.25s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.148, rec=0.069, cos=0.002), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.545 (perp=7.159, rec=0.110, cos=0.004), tot_loss_proj:1.824 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 450/2000] tot_loss=1.511 (perp=7.159, rec=0.078, cos=0.002), tot_loss_proj:1.837 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.513 (perp=7.159, rec=0.080, cos=0.002), tot_loss_proj:1.829 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.492 (perp=7.159, rec=0.059, cos=0.002), tot_loss_proj:1.821 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.002), tot_loss_proj:1.839 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.159, rec=0.068, cos=0.002), tot_loss_proj:1.831 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.833 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.507 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.836 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.501 (perp=7.159, rec=0.068, cos=0.001), tot_loss_proj:1.824 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.822 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.821 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.829 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.498 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.823 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.820 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.827 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.507 (perp=7.159, rec=0.074, cos=0.001), tot_loss_proj:1.827 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.493 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.820 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.827 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.825 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.827 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.494 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.828 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.827 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.830 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.820 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.824 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.503 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.823 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.827 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.500 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.818 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.821 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.822 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.824 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.501 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.821 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.516 | p: 91.750 | r: 93.368
rouge2     | fm: 63.095 | p: 62.933 | r: 63.343
rougeL     | fm: 80.950 | p: 80.499 | r: 81.520
rougeLsum  | fm: 80.815 | p: 80.353 | r: 81.380
r1fm+r2fm = 155.610

input #36 time: 0:10:50 | total time: 5:53:51


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
*********************************
*********************************
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9638330340385437 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9471154808998108 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8868577480316162 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.809199333190918 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.8002374172210693 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7850696444511414 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7521161437034607 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7474158406257629 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7218530774116516 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7020721435546875 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6827971339225769 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6734248399734497 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6440885663032532 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6402079463005066 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.044 (perp=12.719, rec=0.340, cos=0.160), tot_loss_proj:4.341 [t=0.25s]
prediction: ['[CLS] eccentric whatsoever [SEP]']
[ 100/2000] tot_loss=2.344 (perp=10.822, rec=0.149, cos=0.030), tot_loss_proj:2.548 [t=0.26s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.003 (perp=9.583, rec=0.083, cos=0.003), tot_loss_proj:2.004 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.003 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.013 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:1.999 [t=0.34s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.975 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.006 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.982 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.964 (perp=9.583, rec=0.046, cos=0.001), tot_loss_proj:2.007 [t=0.28s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.004 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.990 (perp=9.583, rec=0.072, cos=0.001), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.973 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.969 (perp=9.583, rec=0.051, cos=0.001), tot_loss_proj:2.019 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.000 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.970 (perp=9.583, rec=0.052, cos=0.001), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.016 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.632 | p: 91.988 | r: 93.425
rouge2     | fm: 63.800 | p: 63.690 | r: 63.993
rougeL     | fm: 81.348 | p: 80.865 | r: 81.979
rougeLsum  | fm: 81.402 | p: 80.883 | r: 81.891
r1fm+r2fm = 156.431

input #37 time: 0:10:50 | total time: 6:04:41


Running input #38 of 100.
reference: 
========================
scare 
========================
*********************************
*********************************
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8147767186164856 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8102814555168152 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.8013331294059753 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.767846405506134 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7035160064697266 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6697532534599304 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6317602396011353 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.904 (perp=14.069, rec=0.084, cos=0.006), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.876 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.878 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.875 (perp=14.069, rec=0.058, cos=0.002), tot_loss_proj:2.880 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.885 (perp=14.069, rec=0.068, cos=0.003), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.880 (perp=14.069, rec=0.064, cos=0.002), tot_loss_proj:2.879 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.002), tot_loss_proj:2.866 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.002), tot_loss_proj:2.864 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.002), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.870 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.867 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.877 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.871 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.867 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.882 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.889 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.870 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.869 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.876 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.877 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.869 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.877 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.876 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.882 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.891 (perp=14.069, rec=0.076, cos=0.001), tot_loss_proj:2.883 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.867 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.880 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.892 (perp=14.069, rec=0.077, cos=0.001), tot_loss_proj:2.871 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.858 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.878 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.877 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.868 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.875 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.873 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.887 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.881 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.882 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.884 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.893 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.869 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.884 (perp=14.069, rec=0.069, cos=0.001), tot_loss_proj:2.870 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.925 | p: 92.284 | r: 93.702
rouge2     | fm: 64.999 | p: 64.727 | r: 65.285
rougeL     | fm: 81.868 | p: 81.443 | r: 82.375
rougeLsum  | fm: 81.788 | p: 81.381 | r: 82.296
r1fm+r2fm = 157.924

input #38 time: 0:10:44 | total time: 6:15:26


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
*********************************
*********************************
average of cosine similarity 0.9992526747729695
highest_index [0]
highest [0.9992526747729695]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0125712156295776 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0075626373291016 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9883815050125122 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9328680038452148 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286262392997742 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9213950037956238 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9183960556983948 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.9107301235198975 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9091352820396423 for ['[CLS]pher happened sailowa jury cassidy gordon main etcwind thentivehy event south sometimes positionney lab be hurtpet wash town in [SEP]']
[Init] best perm rec loss: 0.9068863391876221 for ['[CLS]hy jurypet wash then townney sometimestive hurt eventpher position main happened etc south bewind gordon cassidy labowa sail in [SEP]']
[Init] best perm rec loss: 0.9056861400604248 for ['[CLS] cassidypher eventneypet southowa in gordonwind position sail town thentive wash sometimeshy etc be happened jury lab main hurt [SEP]']
[Init] best perm rec loss: 0.9048677086830139 for ['[CLS] happened event hurt lab be gordonwind in sometimeshy south wash thenney etc cassidy position sailpetpherowa main towntive jury [SEP]']
[Init] best perm rec loss: 0.9048073887825012 for ['[CLS]owa south sailpetneytive main hurt sometimes cassidy town in gordon etc happened be labhy then positionwind jury washpher event [SEP]']
[Init] best perm rec loss: 0.902324914932251 for ['[CLS] be jurypher etc wash position gordon cassidy happened southney sometimesowa in mainhytive lab then eventpet sailwind hurt town [SEP]']
[Init] best perm rec loss: 0.9018852710723877 for ['[CLS] position labney gordon happened mainpher wash thenowa south sail jury inpet cassidy etctive eventwind be hurt sometimes townhy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.962 (perp=12.609, rec=0.405, cos=0.035), tot_loss_proj:4.107 [t=0.26s]
prediction: ['[CLS] my documentary nothingopsis eliot laboratory styles white natezi glad undergraduate love instantly - power warner each conquest black new culture reforms beta image [SEP]']
[ 100/2000] tot_loss=2.552 (perp=11.324, rec=0.276, cos=0.011), tot_loss_proj:4.231 [t=0.26s]
prediction: ['[CLS] kiss documentary indeed bother bourgeois fully harmony∘ bob strict most conservative ranked find - vice, literally saxon, new culture gives believe once [SEP]']
[ 150/2000] tot_loss=2.756 (perp=12.548, rec=0.238, cos=0.009), tot_loss_proj:4.299 [t=0.26s]
prediction: ['[CLS] kiss documentary conservative julia old give texture ₊ bob hide most conservative conservative finds - variable, monuments hide, new culture gives hide conservative [SEP]']
[ 200/2000] tot_loss=2.353 (perp=10.661, rec=0.213, cos=0.007), tot_loss_proj:4.039 [t=0.26s]
prediction: ['[CLS] my documentary relatively most conservative give texture movie bob hidebound conservative conservative finds - variable, its hide, new texture gives hide conservative [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.349 (perp=10.677, rec=0.206, cos=0.008), tot_loss_proj:4.126 [t=0.28s]
prediction: ['[CLS]. bingo conservative our conservative give texture caine then - cause, histoire hide hidebound conservative conservative finds, new texture gives hide. [SEP]']
[ 300/2000] tot_loss=2.154 (perp=9.821, rec=0.183, cos=0.007), tot_loss_proj:3.719 [t=0.25s]
prediction: ['[CLS]. movie traditional our traditions give texture screenplay if - cause, movie hide hide most conservative conservative finds, new reality gives hide. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.992 (perp=9.172, rec=0.153, cos=0.005), tot_loss_proj:3.585 [t=0.26s]
prediction: ['[CLS]. movie hidebound conservative one our traditions give texture movie then - hypothesis, movie hide conservative finds, new reality givesbound. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.872 (perp=8.594, rec=0.149, cos=0.005), tot_loss_proj:3.370 [t=0.28s]
prediction: ['[CLS]. movie hidebound conservative one our traditions give texture movie then - reality, it hidebound conservative finds, new reality gives. [SEP]']
[ 450/2000] tot_loss=1.866 (perp=8.653, rec=0.132, cos=0.004), tot_loss_proj:3.631 [t=0.25s]
prediction: ['[CLS]. it hide most conservative one our traditions give texture movie then - reality, it hidebound conservative finds, new reality gives. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.716 (perp=7.943, rec=0.122, cos=0.005), tot_loss_proj:3.296 [t=0.26s]
prediction: ['[CLS]. it hide most conservative one movie then our traditions give texture new reality, it hidebound conservative finds, new reality gives. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.763 (perp=8.294, rec=0.102, cos=0.002), tot_loss_proj:3.450 [t=0.26s]
prediction: ['[CLS]. it hide most conservative one movie movie our traditions give texture new reality, it hidebound conservative finds, new reality gives and [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.294, rec=0.102, cos=0.002), tot_loss_proj:3.454 [t=0.25s]
prediction: ['[CLS]. it hide most conservative one movie movie our traditions give texture new reality, it hidebound conservative finds, new reality gives and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.739 (perp=8.206, rec=0.095, cos=0.002), tot_loss_proj:2.785 [t=0.26s]
prediction: ['[CLS]. it and most conservative one movie movie our traditions give texture new reality, it hidebound conservative finds, new reality and gives [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.715 (perp=8.088, rec=0.095, cos=0.002), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] and texture and most conservative one movie movie our traditions give movie new reality, it hidebound conservative finds, new reality and gives [SEP]']
[ 750/2000] tot_loss=1.715 (perp=8.081, rec=0.097, cos=0.002), tot_loss_proj:2.796 [t=0.27s]
prediction: ['[CLS] and texture and most conservative one movie movie our traditions give movie new reality. it hidebound conservative finds, new reality and gives [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.667 (perp=7.848, rec=0.095, cos=0.002), tot_loss_proj:2.766 [t=0.26s]
prediction: ['[CLS] and texture and most conservative one movie movie our traditions give movie new reality. it hidebound conservative finds new reality and gives, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.665 (perp=7.829, rec=0.097, cos=0.002), tot_loss_proj:2.785 [t=0.26s]
prediction: ['[CLS] and, and most conservative one movie movie our traditions. movie new reality. it hidebound conservative finds new reality and gives texture [SEP]']
[ 900/2000] tot_loss=1.651 (perp=7.829, rec=0.083, cos=0.002), tot_loss_proj:2.797 [t=0.26s]
prediction: ['[CLS] and, and most conservative one movie movie our traditions. movie new reality. it hidebound conservative finds new reality and gives texture [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.571 (perp=7.407, rec=0.088, cos=0.002), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] conservative, and most conservative one movie movie our traditions. movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.552 (perp=7.308, rec=0.089, cos=0.002), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] conservative, and most conservative one movie movie traditions. movie our new reality. it hidebound and finds new reality and gives texture [SEP]']
[1050/2000] tot_loss=1.540 (perp=7.308, rec=0.077, cos=0.002), tot_loss_proj:2.239 [t=0.25s]
prediction: ['[CLS] conservative, and most conservative one movie movie traditions. movie our new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.517 (perp=7.149, rec=0.085, cos=0.002), tot_loss_proj:2.137 [t=0.25s]
prediction: ['[CLS] conservative, and most conservative one movie movie movie traditions. our new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1150/2000] tot_loss=1.516 (perp=7.149, rec=0.085, cos=0.002), tot_loss_proj:2.142 [t=0.27s]
prediction: ['[CLS] conservative, and most conservative one movie movie movie traditions. our new reality. it hidebound and finds new reality and gives texture [SEP]']
[1200/2000] tot_loss=1.519 (perp=7.149, rec=0.087, cos=0.002), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] conservative, and most conservative one movie movie movie traditions. our new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1250/2000] tot_loss=1.516 (perp=7.149, rec=0.084, cos=0.002), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] conservative, and most conservative one movie movie movie traditions. our new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1300/2000] tot_loss=1.505 (perp=7.149, rec=0.074, cos=0.002), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] conservative, and most conservative one movie movie movie traditions. our new reality. it hidebound and finds new reality and gives texture [SEP]']
[1350/2000] tot_loss=1.504 (perp=7.149, rec=0.072, cos=0.002), tot_loss_proj:2.140 [t=0.27s]
prediction: ['[CLS] conservative, and most conservative one movie movie movie traditions. our new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.495 (perp=7.067, rec=0.079, cos=0.002), tot_loss_proj:2.187 [t=0.26s]
prediction: ['[CLS] conservative, and most conservative one movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1450/2000] tot_loss=1.491 (perp=7.067, rec=0.076, cos=0.002), tot_loss_proj:2.186 [t=0.25s]
prediction: ['[CLS] conservative, and most conservative one movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
[1500/2000] tot_loss=1.497 (perp=7.067, rec=0.082, cos=0.002), tot_loss_proj:2.186 [t=0.26s]
prediction: ['[CLS] conservative, and most conservative one movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1550/2000] tot_loss=1.498 (perp=7.067, rec=0.083, cos=0.002), tot_loss_proj:2.179 [t=0.27s]
prediction: ['[CLS] conservative, and most conservative one movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.474 (perp=6.894, rec=0.094, cos=0.002), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS] one, and most conservative conservative movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
[1650/2000] tot_loss=1.460 (perp=6.894, rec=0.079, cos=0.002), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] one, and most conservative conservative movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1700/2000] tot_loss=1.459 (perp=6.894, rec=0.078, cos=0.002), tot_loss_proj:2.103 [t=0.27s]
prediction: ['[CLS] one, and most conservative conservative movie movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.452 (perp=6.850, rec=0.080, cos=0.002), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
[1800/2000] tot_loss=1.453 (perp=6.850, rec=0.081, cos=0.002), tot_loss_proj:2.142 [t=0.25s]
prediction: ['[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1850/2000] tot_loss=1.458 (perp=6.850, rec=0.086, cos=0.002), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[1900/2000] tot_loss=1.457 (perp=6.850, rec=0.086, cos=0.002), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
[1950/2000] tot_loss=1.455 (perp=6.850, rec=0.083, cos=0.002), tot_loss_proj:2.143 [t=0.25s]
prediction: ['[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Attempt swap
[2000/2000] tot_loss=1.445 (perp=6.850, rec=0.073, cos=0.002), tot_loss_proj:2.148 [t=0.26s]
prediction: ['[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] one, and most conservative movie conservative movie traditions. our movie new reality. it hidebound and finds new reality and gives texture [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 78.261 | r: 81.818
rouge2     | fm: 13.953 | p: 13.636 | r: 14.286
rougeL     | fm: 44.444 | p: 43.478 | r: 45.455
rougeLsum  | fm: 44.444 | p: 43.478 | r: 45.455
r1fm+r2fm = 93.953

[Aggregate metrics]:
rouge1     | fm: 92.610 | p: 91.950 | r: 93.426
rouge2     | fm: 63.700 | p: 63.395 | r: 63.887
rougeL     | fm: 80.866 | p: 80.392 | r: 81.394
rougeLsum  | fm: 80.883 | p: 80.472 | r: 81.464
r1fm+r2fm = 156.310

input #39 time: 0:10:59 | total time: 6:26:26


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
*********************************
*********************************
average of cosine similarity 0.9993178197074235
highest_index [0]
highest [0.9993178197074235]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9942196607589722 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9584137797355652 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9366960525512695 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.935725748538971 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9297330379486084 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9249941110610962 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9139153957366943 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9052402973175049 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8458519577980042 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8345496654510498 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8326913118362427 for ['[CLS] but already lady° georgian kent deciding abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.828 (perp=12.673, rec=0.282, cos=0.011), tot_loss_proj:3.544 [t=0.25s]
prediction: ["[CLS] usmmelony horneonyered evidence'sorry [SEP]"]
[ 100/2000] tot_loss=2.406 (perp=11.116, rec=0.171, cos=0.012), tot_loss_proj:3.393 [t=0.27s]
prediction: ['[CLS] usmmelony withony imagery imagery orony [SEP]']
[ 150/2000] tot_loss=2.281 (perp=10.916, rec=0.096, cos=0.002), tot_loss_proj:3.612 [t=0.26s]
prediction: ['[CLS] usmmelony with ph imagery imagery or pu [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.916, rec=0.077, cos=0.002), tot_loss_proj:3.608 [t=0.27s]
prediction: ['[CLS] usmmelony with ph imagery imagery or pu [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.119 (perp=10.139, rec=0.089, cos=0.002), tot_loss_proj:3.499 [t=0.27s]
prediction: ['[CLS] usmmelony with ph pu imagery or music [SEP]']
[ 300/2000] tot_loss=2.105 (perp=10.139, rec=0.075, cos=0.002), tot_loss_proj:3.491 [t=0.26s]
prediction: ['[CLS] usmmelony with ph pu imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.845 (perp=8.843, rec=0.075, cos=0.002), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS] usmmel pu with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.510 (perp=7.172, rec=0.074, cos=0.002), tot_loss_proj:1.507 [t=0.26s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 450/2000] tot_loss=1.500 (perp=7.172, rec=0.065, cos=0.001), tot_loss_proj:1.504 [t=0.25s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.498 (perp=7.172, rec=0.062, cos=0.001), tot_loss_proj:1.510 [t=0.26s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.459 (perp=6.973, rec=0.062, cos=0.002), tot_loss_proj:1.499 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 600/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.508 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.506 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.450 (perp=6.973, rec=0.054, cos=0.001), tot_loss_proj:1.501 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 750/2000] tot_loss=1.469 (perp=6.973, rec=0.073, cos=0.001), tot_loss_proj:1.511 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.507 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.504 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.498 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.452 (perp=6.973, rec=0.056, cos=0.001), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.490 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.468 (perp=6.973, rec=0.072, cos=0.001), tot_loss_proj:1.506 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.504 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.505 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.494 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.464 (perp=6.973, rec=0.068, cos=0.001), tot_loss_proj:1.501 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.511 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.498 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.504 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.494 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.492 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.506 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.493 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.461 (perp=6.973, rec=0.065, cos=0.001), tot_loss_proj:1.503 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.498 [t=0.28s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.450 (perp=6.973, rec=0.054, cos=0.001), tot_loss_proj:1.496 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.497 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.465 (perp=6.973, rec=0.069, cos=0.001), tot_loss_proj:1.510 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.504 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.502 [t=0.24s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.494 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 92.754 | p: 92.099 | r: 93.485
rouge2     | fm: 63.221 | p: 63.019 | r: 63.534
rougeL     | fm: 80.777 | p: 80.290 | r: 81.285
rougeLsum  | fm: 80.776 | p: 80.347 | r: 81.351
r1fm+r2fm = 155.975

input #40 time: 0:11:00 | total time: 6:37:26


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
*********************************
*********************************
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9788511395454407 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9516528844833374 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9389455914497375 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9341390132904053 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.928720235824585 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.924547553062439 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9216023683547974 for ['[CLS] style tomorrow [SEP]']
[Init] best rec loss: 0.9001919627189636 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8952876925468445 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8542567491531372 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8272965550422668 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8260568976402283 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.154 (perp=10.212, rec=0.109, cos=0.003), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.109 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.110 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.088 (perp=10.212, rec=0.045, cos=0.001), tot_loss_proj:2.110 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.127 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.102 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.090 (perp=10.212, rec=0.046, cos=0.001), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.102 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.095 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.120 (perp=10.212, rec=0.077, cos=0.001), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.108 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.091 (perp=10.212, rec=0.047, cos=0.001), tot_loss_proj:2.109 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.093 (perp=10.212, rec=0.049, cos=0.001), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.111 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.103 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.119 (perp=10.212, rec=0.075, cos=0.001), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.103 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.098 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.097 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.090 (perp=10.212, rec=0.046, cos=0.001), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.101 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.917 | p: 92.272 | r: 93.645
rouge2     | fm: 64.398 | p: 64.195 | r: 64.646
rougeL     | fm: 81.402 | p: 80.926 | r: 81.932
rougeLsum  | fm: 81.242 | p: 80.878 | r: 81.778
r1fm+r2fm = 157.315

input #41 time: 0:10:55 | total time: 6:48:21


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
*********************************
*********************************
average of cosine similarity 0.999325796096683
highest_index [0]
highest [0.999325796096683]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9041017889976501 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8518991470336914 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8484532237052917 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8162120580673218 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.8055222630500793 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.8025503158569336 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 0.7999148368835449 for ['[CLS] wishtakingctric enoughurespling dare maple supersededbe stages ran offended larger treaty scale assignment bandagiblers international kitchen attracted lifted cut ever [SEP]']
[Init] best perm rec loss: 0.7986771464347839 for ['[CLS]be assignment lifted stages largerrs attracted maplepling enough banda offended daretaking treaty ever ran cutures international wish kitchen scalectric supersededgible [SEP]']
[Init] best perm rec loss: 0.7972655892372131 for ['[CLS] wish ran larger kitchen treaty assignmentpling maple offendedures attracted supersededctrictaking ever stages scale bandabe cut enough lifted darersgible international [SEP]']
[Init] best perm rec loss: 0.7947720885276794 for ['[CLS]ctric dare wish treaty stages superseded international scalebegible largerpling banda offendedures kitchen ever cut liftedtakingrs maple ran attracted enough assignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.829 (perp=12.536, rec=0.304, cos=0.017), tot_loss_proj:3.689 [t=0.26s]
prediction: ['[CLS] stanford thinking forgot forgot on slash runner citesnier mightfarlane suffered obama forgot the / fact cemetery crypt shirt inauguration military japanese video jail assignment [SEP]']
[ 100/2000] tot_loss=2.714 (perp=12.463, rec=0.212, cos=0.009), tot_loss_proj:3.466 [t=0.26s]
prediction: ['[CLS] stanford thinking forgot forgot grabsctable opener include ideas whatever filmmakers poorlyuously forgot as / cu installation back school museum into schoolound civil attraction [SEP]']
[ 150/2000] tot_loss=2.549 (perp=11.866, rec=0.170, cos=0.006), tot_loss_proj:3.337 [t=0.26s]
prediction: ['[CLS] stanford involving forgot forgot anything anything genuine projects honestly anything they poorlyuously forgot as poorlygger project back they attraction into school political posted setting [SEP]']
[ 200/2000] tot_loss=2.452 (perp=11.518, rec=0.144, cos=0.005), tot_loss_proj:3.295 [t=0.27s]
prediction: ['[CLS] stanford involving forgot forgot to anything anything filmmakers honestly anything they poorlyuously forgot as poorlygger project re school attraction into school its posted setting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.512 (perp=11.912, rec=0.126, cos=0.003), tot_loss_proj:3.264 [t=0.26s]
prediction: ['[CLS] stanford honestly forgot included to even anything filmmakers include anything they poorly filmmakers forgot as poorlygger projectji school attraction into school scary fatal setting [SEP]']
[ 300/2000] tot_loss=2.499 (perp=11.933, rec=0.108, cos=0.004), tot_loss_proj:3.529 [t=0.25s]
prediction: ['[CLS] dynamic disbelief forgot include to even scary filmmakers include anything they poorly filmmakers forgot asjigger projectji school attraction into school scary fatal setting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.371 (perp=11.319, rec=0.105, cos=0.003), tot_loss_proj:3.244 [t=0.25s]
prediction: ['[CLS] dynamic s forgot to include even scary filmmakers include anything they poorly filmmakers forgot as regger projectji school attraction into school scary fatal setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.156 (perp=10.252, rec=0.102, cos=0.003), tot_loss_proj:3.064 [t=0.27s]
prediction: ["[CLS] dynamic s forgot to include even scary filmmakers include anything they poorly filmmakers forgot as regger projectji'setting into school scary fatal attraction [SEP]"]
[ 450/2000] tot_loss=2.149 (perp=10.248, rec=0.095, cos=0.004), tot_loss_proj:3.260 [t=0.27s]
prediction: ["[CLS] dynamic s forgot to include even scary filmmakers include anything they poorly grimly forgot as regger projectji'setting into school scary fatal attraction [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.040 (perp=9.732, rec=0.091, cos=0.002), tot_loss_proj:3.006 [t=0.27s]
prediction: ["[CLS]. scary forgot to include even scary filmmakers include anything they poorly'forgot as regger projectji a setting into school s fatal attraction [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.980 (perp=9.484, rec=0.081, cos=0.002), tot_loss_proj:2.974 [t=0.25s]
prediction: ["[CLS]. scary forgot to include even scary filmmakers include anything they'forgot poorly as regger projectji a setting into school s fatal attraction [SEP]"]
[ 600/2000] tot_loss=1.983 (perp=9.484, rec=0.084, cos=0.003), tot_loss_proj:2.980 [t=0.26s]
prediction: ["[CLS]. scary forgot to include even scary filmmakers include anything they'forgot poorly as regger projectji a setting into school s fatal attraction [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.984 (perp=9.534, rec=0.075, cos=0.002), tot_loss_proj:3.071 [t=0.26s]
prediction: ['[CLS]. scary forgot to include even scary filmmakers include anything they s forgot poorly as reggerji project a setting into school s fatal attraction [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.894 (perp=9.096, rec=0.073, cos=0.002), tot_loss_proj:2.838 [t=0.26s]
prediction: ['[CLS]. filmmakers forgot to include even scary scary include anything they s forgot poorly as reggerji project a setting into school the fatal attraction [SEP]']
[ 750/2000] tot_loss=1.898 (perp=9.096, rec=0.077, cos=0.002), tot_loss_proj:2.840 [t=0.25s]
prediction: ['[CLS]. filmmakers forgot to include even scary scary include anything they s forgot poorly as reggerji project a setting into school the fatal attraction [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.862 (perp=8.910, rec=0.078, cos=0.002), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS]. filmmakers forgot to include even scary scary include anything they s forgot poorly as reggerji a project setting into school the fatal attraction [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.930 (perp=9.262, rec=0.076, cos=0.002), tot_loss_proj:2.861 [t=0.29s]
prediction: ['[CLS]. filmmakers forgot to include halfway scary scary include anything they s forgot poorly as reggerji the project setting into school a fatal attraction [SEP]']
[ 900/2000] tot_loss=1.935 (perp=9.262, rec=0.081, cos=0.002), tot_loss_proj:2.868 [t=0.27s]
prediction: ['[CLS]. filmmakers forgot to include halfway scary scary include anything they s forgot poorly as reggerji the project setting into school a fatal attraction [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.892 (perp=9.030, rec=0.084, cos=0.002), tot_loss_proj:3.026 [t=0.25s]
prediction: ['[CLS] even filmmakers forgot to include. scary scary include anything they s forgot poorly as reggerji the project setting into school a fatal attraction [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.785 (perp=8.482, rec=0.085, cos=0.003), tot_loss_proj:2.753 [t=0.27s]
prediction: ['[CLS] even filmmakers forgot to include a scary scary include anything they s forgot poorly as reggerji the project setting into school. fatal attraction [SEP]']
[1050/2000] tot_loss=1.787 (perp=8.520, rec=0.081, cos=0.003), tot_loss_proj:2.633 [t=0.25s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary scary include anything they s forgot poorly as reggerji the project setting into school. fatal attraction [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.723 (perp=8.211, rec=0.079, cos=0.002), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary scary include anything they s forgot poorly as rejigger the project setting into school. fatal attraction [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.697 (perp=8.090, rec=0.076, cos=0.003), tot_loss_proj:2.489 [t=0.27s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary scary include anything they s forgot poorly as rejigger the project setting into school fatal attraction. [SEP]']
[1200/2000] tot_loss=1.696 (perp=8.090, rec=0.076, cos=0.002), tot_loss_proj:2.486 [t=0.29s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary scary include anything they s forgot poorly as rejigger the project setting into school fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.632 (perp=7.780, rec=0.074, cos=0.002), tot_loss_proj:2.543 [t=0.26s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary scary include anything they s forgot poorly as rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.587 (perp=7.529, rec=0.079, cos=0.002), tot_loss_proj:2.442 [t=0.26s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary include anything they s forgot poorly as scary rejigger school project setting into the fatal attraction. [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.529, rec=0.078, cos=0.002), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary include anything they s forgot poorly as scary rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.579 (perp=7.539, rec=0.069, cos=0.002), tot_loss_proj:2.269 [t=0.25s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary include anything they s forgot as poorly scary rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.578 (perp=7.539, rec=0.068, cos=0.002), tot_loss_proj:2.277 [t=0.26s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary include anything they s forgot as poorly scary rejigger school project setting into the fatal attraction. [SEP]']
[1500/2000] tot_loss=1.586 (perp=7.539, rec=0.077, cos=0.002), tot_loss_proj:2.276 [t=0.28s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary include anything they s forgot as poorly scary rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.589 (perp=7.539, rec=0.080, cos=0.002), tot_loss_proj:2.275 [t=0.27s]
prediction: ['[CLS] halfway filmmakers forgot to include a scary include anything they s forgot as poorly scary rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.532 (perp=7.290, rec=0.072, cos=0.002), tot_loss_proj:2.179 [t=0.26s]
prediction: ['[CLS] s filmmakers forgot to include a scary include anything they even forgot as poorly scary rejigger school project setting into the fatal attraction. [SEP]']
[1650/2000] tot_loss=1.535 (perp=7.290, rec=0.075, cos=0.002), tot_loss_proj:2.177 [t=0.26s]
prediction: ['[CLS] s filmmakers forgot to include a scary include anything they even forgot as poorly scary rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.531 (perp=7.293, rec=0.071, cos=0.002), tot_loss_proj:2.120 [t=0.27s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot as poorly a rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.530 (perp=7.293, rec=0.070, cos=0.002), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot as poorly a rejigger school project setting into the fatal attraction. [SEP]']
[1800/2000] tot_loss=1.528 (perp=7.293, rec=0.068, cos=0.002), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot as poorly a rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.487 (perp=7.062, rec=0.073, cos=0.002), tot_loss_proj:2.337 [t=0.27s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot poorly as a rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.482 (perp=7.062, rec=0.068, cos=0.002), tot_loss_proj:2.338 [t=0.28s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot poorly as a rejigger school project setting into the fatal attraction. [SEP]']
[1950/2000] tot_loss=1.490 (perp=7.062, rec=0.076, cos=0.002), tot_loss_proj:2.337 [t=0.25s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot poorly as a rejigger school project setting into the fatal attraction. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.478 (perp=7.062, rec=0.064, cos=0.002), tot_loss_proj:2.336 [t=0.27s]
prediction: ['[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot poorly as a rejigger school project setting into the fatal attraction. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] s filmmakers forgot to include scary scary include anything they halfway forgot poorly as a rejigger school project setting into the fatal attraction. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.796 | p: 88.000 | r: 91.667
rouge2     | fm: 25.532 | p: 25.000 | r: 26.087
rougeL     | fm: 53.061 | p: 52.000 | r: 54.167
rougeLsum  | fm: 53.061 | p: 52.000 | r: 54.167
r1fm+r2fm = 115.328

[Aggregate metrics]:
rouge1     | fm: 92.799 | p: 92.083 | r: 93.569
rouge2     | fm: 63.520 | p: 63.280 | r: 63.771
rougeL     | fm: 80.352 | p: 79.901 | r: 80.949
rougeLsum  | fm: 80.554 | p: 80.064 | r: 81.083
r1fm+r2fm = 156.319

input #42 time: 0:11:07 | total time: 6:59:28


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
*********************************
*********************************
average of cosine similarity 0.9992732655805336
highest_index [0]
highest [0.9992732655805336]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9607493281364441 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9227121472358704 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8925204873085022 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8689665198326111 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8586649298667908 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.846950888633728 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8364328742027283 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7888320684432983 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7853228449821472 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7806761264801025 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 0.7801570892333984 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 0.7796530723571777 for ['[CLS] oxidation council enrollment deserved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.037 (perp=8.970, rec=0.236, cos=0.006), tot_loss_proj:2.800 [t=0.24s]
prediction: ['[CLS] offrcissistic [SEP]']
[ 100/2000] tot_loss=1.132 (perp=5.048, rec=0.118, cos=0.004), tot_loss_proj:1.078 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 150/2000] tot_loss=1.085 (perp=5.048, rec=0.073, cos=0.002), tot_loss_proj:1.084 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.068 (perp=5.048, rec=0.056, cos=0.002), tot_loss_proj:1.081 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.091 (perp=5.048, rec=0.080, cos=0.002), tot_loss_proj:1.086 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.002), tot_loss_proj:1.070 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.062 (perp=5.048, rec=0.050, cos=0.002), tot_loss_proj:1.082 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.083 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.092 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.077 (perp=5.048, rec=0.065, cos=0.002), tot_loss_proj:1.082 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.071 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.002), tot_loss_proj:1.071 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.079 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.097 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.077 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.067 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.074 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.085 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.074 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.069 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.079 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.076 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.088 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.072 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.076 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.074 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.057 (perp=5.048, rec=0.046, cos=0.001), tot_loss_proj:1.075 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.086 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.084 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.085 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.076 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.072 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.072 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.081 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.080 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.063 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.076 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.085 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.076 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.065 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.071 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.068 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.085 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.076 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.017 | p: 92.360 | r: 93.738
rouge2     | fm: 64.154 | p: 63.988 | r: 64.391
rougeL     | fm: 81.065 | p: 80.613 | r: 81.663
rougeLsum  | fm: 81.106 | p: 80.678 | r: 81.632
r1fm+r2fm = 157.172

input #43 time: 0:11:09 | total time: 7:10:38


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
*********************************
*********************************
average of cosine similarity 0.999241753470635
highest_index [0]
highest [0.999241753470635]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9856536388397217 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9538675546646118 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9338456988334656 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9291354417800903 for ['[CLS]hat since shotsisance morning her wound ji living appealing fifapis aus braun filmed james saved ian service person alias motion inclination age storage hyper heard wind any [SEP]']
[Init] best rec loss: 0.9056149125099182 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.904999852180481 for ['[CLS] fatty formerly haley ltd raceway nation brow harbor slavehair intent contact hello ; contains contestants heeosi data graphic capacity settled landon blue comedy rock s co illustrated [SEP]']
[Init] best perm rec loss: 0.9043598175048828 for ['[CLS] s comedyosi slave ltd co contestants contains hello graphic settled capacity hee intent ; contact formerly brow landon blue data illustrated rock nationhair harbor haley fatty raceway [SEP]']
[Init] best perm rec loss: 0.903514564037323 for ['[CLS] comedyhair settled intent contestants capacity contact contains hello rock data nation brow formerly ; hee co blueosi graphic fatty illustrated raceway ltd slave s landon haley harbor [SEP]']
[Init] best perm rec loss: 0.90308678150177 for ['[CLS] graphic contains comedy settled raceway ; intent hee hello slave contact fatty brow ltd s capacityosi formerly rock co data illustratedhair harbor contestants landon haley blue nation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.496 (perp=11.224, rec=0.242, cos=0.008), tot_loss_proj:3.141 [t=0.27s]
prediction: ['[CLS]nesian the super. in translation common translation is on actually lostness another lost execution details pretended lost when felony / loses fright routine delay unfortunate routine translation [SEP]']
[ 100/2000] tot_loss=2.121 (perp=9.844, rec=0.148, cos=0.004), tot_loss_proj:2.790 [t=0.27s]
prediction: ['[CLS]mony in routine. translation translation.. is it routine lost. been lost execution. execution lost months fright. slack fright routine ofized premise translation [SEP]']
[ 150/2000] tot_loss=2.023 (perp=9.516, rec=0.116, cos=0.003), tot_loss_proj:2.461 [t=0.30s]
prediction: ['[CLS] hollywood in routine. translation translation.. has which routine lost. been lost execution the executionalic execution fright. slackfest routineizesized premise. [SEP]']
[ 200/2000] tot_loss=2.021 (perp=9.585, rec=0.101, cos=0.003), tot_loss_proj:2.497 [t=0.27s]
prediction: ['[CLS] hollywood in another. execution translation.. has whichalic lost. been lost execution the executionalic execution fright in slackfest routineizesized premise. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.244 (perp=9.768, rec=0.278, cos=0.012), tot_loss_proj:2.849 [t=0.26s]
prediction: ['[CLS] hollywood in another the execution translation balancing.. which random lost has been lostfest ( slackalic fist fright in slackfest routineizesity premise. [SEP]']
[ 300/2000] tot_loss=2.018 (perp=9.167, rec=0.180, cos=0.005), tot_loss_proj:2.923 [t=0.27s]
prediction: ['[CLS] hollywood in another the execution translation therapy.. which endless lost has been lostfest ( thealic fist fright in slackfest routineing. premise. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.859 (perp=8.500, rec=0.155, cos=0.004), tot_loss_proj:2.539 [t=0.26s]
prediction: ['[CLS] hollywood in another the execution translation programs.. which endless lost has been lostfest of the routinealic punching fright in slackfesting. premise. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.858 (perp=8.550, rec=0.144, cos=0.003), tot_loss_proj:2.630 [t=0.27s]
prediction: ['[CLS] hollywood in another execution translation projects.. the which endless lost has been lost fright of the routinealic slash fright in slackfesting. premise. [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.353, rec=0.129, cos=0.003), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS] hollywood in another execution translation projects.. the which hollywood lost has been lostfest of the routinealic conventional fright in slack hollywooding. premise. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.833 (perp=8.502, rec=0.130, cos=0.003), tot_loss_proj:2.564 [t=0.26s]
prediction: ['[CLS] hollywood in another slack translation projects.. the which hollywood lost has been lostfest which the routinealic execution fright in execution hollywoodize. premise. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.725 (perp=8.015, rec=0.119, cos=0.003), tot_loss_proj:2.226 [t=0.27s]
prediction: ['[CLS] hollywood in another slack translation projects... which hollywood lost has been lostfest where the routinealic execution fright in execution hollywoodize the premise. [SEP]']
[ 600/2000] tot_loss=1.720 (perp=8.030, rec=0.111, cos=0.002), tot_loss_proj:2.256 [t=0.25s]
prediction: ['[CLS] hollywood in another slack translation projects... which hollywood slack has been lostfest where the routinealic slack fright in execution hollywoodize the premise. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.669 (perp=7.762, rec=0.114, cos=0.002), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] hollywood in another slack translation 2009... which hollywood slack has been lostfest where the routine hollywood slack fright in executionalicizes the premise. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.565 (perp=7.341, rec=0.095, cos=0.002), tot_loss_proj:2.064 [t=0.27s]
prediction: ['[CLS] hollywood slack in another translation projects... which hollywood slack has been lostfest where the routine hollywood slack fright in executionalicizes the premise. [SEP]']
[ 750/2000] tot_loss=1.556 (perp=7.276, rec=0.099, cos=0.002), tot_loss_proj:2.071 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... which hollywood slack has been lostfest where the routine hollywood slack fright in executionalicizes the premise. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.490 (perp=6.931, rec=0.102, cos=0.002), tot_loss_proj:2.149 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation 2009... which hollywood slack has been lostfest of the routine hollywood slack in fright executionalicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.491 (perp=6.931, rec=0.103, cos=0.002), tot_loss_proj:2.153 [t=0.27s]
prediction: ['[CLS] hollywood slack in another translation 2009... which hollywood slack has been lostfest of the routine hollywood slack in fright executionalicizes the premise. [SEP]']
[ 900/2000] tot_loss=1.490 (perp=6.931, rec=0.101, cos=0.002), tot_loss_proj:2.146 [t=0.27s]
prediction: ['[CLS] hollywood slack in another translation 2009... which hollywood slack has been lostfest of the routine hollywood slack in fright executionalicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.447 (perp=6.737, rec=0.097, cos=0.002), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the hollywood slack has been lostfest of which routine hollywood slack in fright executionalicizes the premise. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.437 (perp=6.737, rec=0.087, cos=0.002), tot_loss_proj:1.955 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the hollywood slack has been lostfest of which routine hollywood slack in fright executionalicizes the premise. [SEP]']
[1050/2000] tot_loss=1.448 (perp=6.737, rec=0.098, cos=0.002), tot_loss_proj:1.957 [t=0.27s]
prediction: ['[CLS] hollywood slack in another translation 2009... the hollywood slack has been lostfest of which routine hollywood slack in fright executionalicizes the premise. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.443 (perp=6.737, rec=0.093, cos=0.002), tot_loss_proj:1.954 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation 2009... the hollywood slack has been lostfest of which routine hollywood slack in fright executionalicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.403 (perp=6.586, rec=0.084, cos=0.002), tot_loss_proj:1.855 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the hollywood slack has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
[1200/2000] tot_loss=1.479 (perp=6.923, rec=0.092, cos=0.002), tot_loss_proj:1.914 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation projects... the routine slack has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.475 (perp=6.923, rec=0.088, cos=0.002), tot_loss_proj:1.910 [t=0.27s]
prediction: ['[CLS] hollywood slack in another translation projects... the routine slack has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.449 (perp=6.776, rec=0.091, cos=0.002), tot_loss_proj:1.935 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation 2009... the slack routine has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
[1350/2000] tot_loss=1.496 (perp=7.036, rec=0.086, cos=0.002), tot_loss_proj:1.911 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd gameplay has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.492 (perp=7.036, rec=0.082, cos=0.002), tot_loss_proj:1.911 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd gameplay has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.491 (perp=7.036, rec=0.081, cos=0.002), tot_loss_proj:1.910 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd gameplay has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
[1500/2000] tot_loss=1.493 (perp=7.036, rec=0.084, cos=0.002), tot_loss_proj:1.910 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd gameplay has been lostfest in which routine hollywood slack of fright executionalicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.488 (perp=6.986, rec=0.089, cos=0.002), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.479 (perp=6.986, rec=0.080, cos=0.002), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
[1650/2000] tot_loss=1.478 (perp=6.986, rec=0.078, cos=0.002), tot_loss_proj:1.903 [t=0.30s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.481 (perp=6.986, rec=0.082, cos=0.002), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.477 (perp=6.986, rec=0.078, cos=0.002), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation 2009... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
[1800/2000] tot_loss=1.497 (perp=7.054, rec=0.085, cos=0.002), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation which... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.495 (perp=7.054, rec=0.082, cos=0.002), tot_loss_proj:1.850 [t=0.26s]
prediction: ['[CLS] hollywood slack in another translation which... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.502 (perp=7.054, rec=0.089, cos=0.002), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation which... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
[1950/2000] tot_loss=1.492 (perp=7.054, rec=0.079, cos=0.002), tot_loss_proj:1.855 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation which... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.497 (perp=7.054, rec=0.084, cos=0.002), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] hollywood slack in another translation which... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] hollywood slack in another translation which... the absurd execution has been lostfest in which routine hollywood slack of fright gameplayalicizes the premise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.340 | p: 70.833 | r: 73.913
rouge2     | fm: 26.667 | p: 26.087 | r: 27.273
rougeL     | fm: 46.809 | p: 45.833 | r: 47.826
rougeLsum  | fm: 46.809 | p: 45.833 | r: 47.826
r1fm+r2fm = 99.007

[Aggregate metrics]:
rouge1     | fm: 92.485 | p: 91.826 | r: 93.230
rouge2     | fm: 63.480 | p: 63.335 | r: 63.685
rougeL     | fm: 80.352 | p: 79.841 | r: 80.887
rougeLsum  | fm: 80.316 | p: 79.885 | r: 80.908
r1fm+r2fm = 155.965

input #44 time: 0:11:00 | total time: 7:21:39


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
*********************************
*********************************
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9825860261917114 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9404022693634033 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9185224771499634 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9133827090263367 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.903794527053833 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.9032831192016602 for ['[CLS] circussome nj lodge photoᅵ bioome kg morning. have interviewrcus account winfield letofan shy broken man floor sunday sack tuneenter station ll [SEP]']
[Init] best rec loss: 0.8698243498802185 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8686729073524475 for ['[CLS] skinlanda ( whoa tree ku entrance special five bore2 via curtis operated murmured v status letter few enclosed gentry joan around military single taste footballtiv [SEP]']
[Init] best perm rec loss: 0.8660717606544495 for ['[CLS] single (tiv tree around v entrance letter bore ku operated football enclosed curtislanda five military taste joan status murmured skin2 via few special gentry whoa [SEP]']
[Init] best perm rec loss: 0.8620867133140564 for ['[CLS] five footballtiv2 taste military ku via single skin status few enclosed special curtis murmured whoa entrancelanda ( tree joan around bore letter v gentry operated [SEP]']
[Init] best perm rec loss: 0.861274242401123 for ['[CLS] murmured2 single taste via skintiv curtis whoa tree v football entrancelanda ku joan five status bore letter few around ( enclosed special operated military gentry [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.703 (perp=11.809, rec=0.323, cos=0.019), tot_loss_proj:3.877 [t=0.27s]
prediction: ['[CLS] than× snap fox instructor - movements campaign program sometimes than -lashtylete - than high shelf meetsootevic bowel -. local generally [SEP]']
[ 100/2000] tot_loss=2.391 (perp=10.496, rec=0.282, cos=0.010), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] than - their fox headlines - movements than program piece than - - nhspe - than - shelf -oot months bowel - - crime exercise [SEP]']
[ 150/2000] tot_loss=2.369 (perp=10.108, rec=0.326, cos=0.022), tot_loss_proj:3.026 [t=0.27s]
prediction: ['[CLS] - - - was gossip - movements than? installation and program - linear ( - than da shelf andliness gi bowelae / scenes exercise [SEP]']
[ 200/2000] tot_loss=2.357 (perp=10.583, rec=0.228, cos=0.012), tot_loss_proj:3.741 [t=0.26s]
prediction: ['[CLS] - - - guns cockpit - movements than? parker elf back - this adventure - than da shelf andious gi bowel eveninged shooting exercise [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.983 (perp=8.989, rec=0.181, cos=0.004), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] - - - guns gi - movements than? this - on - this shoot - than da shelf,ious fictional bowel shootingy shooting exercise [SEP]']
[ 300/2000] tot_loss=1.921 (perp=8.781, rec=0.162, cos=0.004), tot_loss_proj:2.844 [t=0.27s]
prediction: ['[CLS] - - - guns gi - movements than? this - on - this shoot - this - shelf,ious boom bowel shootingy shooting exercise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.901 (perp=8.740, rec=0.150, cos=0.003), tot_loss_proj:3.078 [t=0.26s]
prediction: ['[CLS] - - - guns gi - movements thanick - - on this this drama - this the shelf, long boom bowel shootingy shooting exercise [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.800 (perp=8.233, rec=0.150, cos=0.003), tot_loss_proj:2.655 [t=0.26s]
prediction: ['[CLS] - - - shootmm - movements thanick - - on this this exercise - this the shelf, long narrow bowel shootingy shooting drama [SEP]']
[ 450/2000] tot_loss=1.843 (perp=8.535, rec=0.133, cos=0.002), tot_loss_proj:2.815 [t=0.25s]
prediction: ['[CLS] - - - shootmm - movements thanick - - on this this exercise - this the shelf, long shoot bowel shootingy shoot drama [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.822 (perp=8.455, rec=0.129, cos=0.002), tot_loss_proj:2.792 [t=0.24s]
prediction: ['[CLS] - - - shootmm - movements thanick - - on this this exercise - this the shelf, long shoot bowel shooty shoot drama [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.767 (perp=8.217, rec=0.122, cos=0.002), tot_loss_proj:2.715 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - movements thanick - - on this this exercise - this the shelf, long shoot bowel shooty shoot drama [SEP]']
[ 600/2000] tot_loss=1.863 (perp=8.700, rec=0.121, cos=0.002), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - movements thanick - - on this this exercise - this the shelf, long shoot bowel shoot gi shoot drama [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.805 (perp=8.434, rec=0.116, cos=0.002), tot_loss_proj:2.777 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - than movementsick - - on this this exercise - this the shelf, long shoot bowel shoot gi shoot drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.783 (perp=8.303, rec=0.120, cos=0.002), tot_loss_proj:2.701 [t=0.28s]
prediction: ['[CLS] - - -mm shoot - than movementsick - - on this this exercise - this long shelf, the shoot bowel shoot gi shoot drama [SEP]']
[ 750/2000] tot_loss=1.776 (perp=8.303, rec=0.114, cos=0.002), tot_loss_proj:2.706 [t=0.27s]
prediction: ['[CLS] - - -mm shoot - than movementsick - - on this this exercise - this long shelf, the shoot bowel shoot gi shoot drama [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.770 (perp=8.303, rec=0.107, cos=0.002), tot_loss_proj:2.709 [t=0.25s]
prediction: ['[CLS] - - -mm shoot - than movementsick - - on this this exercise - this long shelf, the shoot bowel shoot gi shoot drama [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.736 (perp=8.136, rec=0.107, cos=0.002), tot_loss_proj:2.665 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - than movementsick - - on this this exercise - the long shelf, this shoot bowel shoot gi shoot drama [SEP]']
[ 900/2000] tot_loss=1.729 (perp=8.136, rec=0.100, cos=0.002), tot_loss_proj:2.669 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - than movementsick - - on this this exercise - the long shelf, this shoot bowel shoot gi shoot drama [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.718 (perp=8.015, rec=0.113, cos=0.002), tot_loss_proj:2.663 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowelick gi shoot drama [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.899 (perp=8.182, rec=0.249, cos=0.014), tot_loss_proj:2.795 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - than movements shoot - king on this this exercise - the long shelf, this shoot bowelick shoot gi drama [SEP]']
[1050/2000] tot_loss=1.833 (perp=8.184, rec=0.188, cos=0.009), tot_loss_proj:2.685 [t=0.26s]
prediction: ['[CLS] - - -mm shoot - than movements shoot - gi on this this exercise - the long shelf, this shoot bowelick shoot gi drama [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.633 (perp=7.273, rec=0.171, cos=0.007), tot_loss_proj:2.383 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowelick shoot - drama [SEP]']
Attempt swap
[1150/2000] tot_loss=1.623 (perp=7.273, rec=0.163, cos=0.006), tot_loss_proj:2.388 [t=0.27s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowelick shoot - drama [SEP]']
[1200/2000] tot_loss=1.678 (perp=7.601, rec=0.153, cos=0.005), tot_loss_proj:2.465 [t=0.27s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowelick crime - drama [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.659 (perp=7.525, rec=0.149, cos=0.005), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowickel crime - drama [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.637 (perp=7.437, rec=0.146, cos=0.004), tot_loss_proj:2.444 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
[1350/2000] tot_loss=1.644 (perp=7.437, rec=0.152, cos=0.004), tot_loss_proj:2.444 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.638 (perp=7.437, rec=0.146, cos=0.004), tot_loss_proj:2.437 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than movements shoot - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.612 (perp=7.322, rec=0.144, cos=0.004), tot_loss_proj:2.333 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
[1500/2000] tot_loss=1.619 (perp=7.322, rec=0.150, cos=0.004), tot_loss_proj:2.331 [t=0.25s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.600 (perp=7.322, rec=0.132, cos=0.004), tot_loss_proj:2.334 [t=0.25s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.605 (perp=7.322, rec=0.137, cos=0.004), tot_loss_proj:2.330 [t=0.27s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
[1650/2000] tot_loss=1.610 (perp=7.322, rec=0.142, cos=0.003), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.602 (perp=7.322, rec=0.134, cos=0.003), tot_loss_proj:2.333 [t=0.27s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.596 (perp=7.322, rec=0.128, cos=0.003), tot_loss_proj:2.335 [t=0.25s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.322, rec=0.126, cos=0.003), tot_loss_proj:2.330 [t=0.26s]
prediction: ['[CLS] - - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot bowickel crime drama - [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.569 (perp=7.171, rec=0.132, cos=0.003), tot_loss_proj:2.333 [t=0.26s]
prediction: ['[CLS] bow - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot -ickel crime drama - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.569 (perp=7.171, rec=0.132, cos=0.003), tot_loss_proj:2.335 [t=0.26s]
prediction: ['[CLS] bow - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot -ickel crime drama - [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.171, rec=0.127, cos=0.003), tot_loss_proj:2.335 [t=0.26s]
prediction: ['[CLS] bow - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot -ickel crime drama - [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.548 (perp=7.111, rec=0.122, cos=0.003), tot_loss_proj:2.289 [t=0.27s]
prediction: ['[CLS] bow - gimm shoot - than shoot movements - - on this this exercise - the long shelf, this shoot -ickel - crime drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - - -mm shoot - than movementsick - - on this this exercise - the long shelf, this shoot bowel shoot gi shoot drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.158 | p: 60.000 | r: 66.667
rouge2     | fm: 5.556 | p: 5.263 | r: 5.882
rougeL     | fm: 42.105 | p: 40.000 | r: 44.444
rougeLsum  | fm: 42.105 | p: 40.000 | r: 44.444
r1fm+r2fm = 68.713

[Aggregate metrics]:
rouge1     | fm: 91.816 | p: 91.129 | r: 92.646
rouge2     | fm: 62.315 | p: 62.098 | r: 62.495
rougeL     | fm: 79.365 | p: 78.925 | r: 79.912
rougeLsum  | fm: 79.436 | p: 78.903 | r: 80.064
r1fm+r2fm = 154.131

input #45 time: 0:10:59 | total time: 7:32:38


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
*********************************
*********************************
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9911298155784607 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792498350143433 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9472112059593201 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9385618567466736 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9372692704200745 for ['[CLS] political m act paperrton fitz [SEP]']
[Init] best rec loss: 0.9318523406982422 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9173271059989929 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best perm rec loss: 0.9158892631530762 for ['[CLS] four donald canada reed and no [SEP]']
[Init] best perm rec loss: 0.9147517085075378 for ['[CLS] donald and four reed no canada [SEP]']
[Init] best perm rec loss: 0.9115938544273376 for ['[CLS] four reed canada and donald no [SEP]']
[Init] best perm rec loss: 0.9111836552619934 for ['[CLS] donald reed canada four no and [SEP]']
[Init] best perm rec loss: 0.9108540415763855 for ['[CLS] and reed donald four no canada [SEP]']
[Init] best perm rec loss: 0.9107707142829895 for ['[CLS] donald and canada no four reed [SEP]']
[Init] best perm rec loss: 0.9106481671333313 for ['[CLS] four reed no donald canada and [SEP]']
[Init] best perm rec loss: 0.9093884825706482 for ['[CLS] and reed no donald canada four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=12.679, rec=0.209, cos=0.005), tot_loss_proj:3.913 [t=0.25s]
prediction: ['[CLS] slick maryly ensuretitled slick [SEP]']
[ 100/2000] tot_loss=2.240 (perp=10.398, rec=0.158, cos=0.003), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] slick visually striking slick visually staged [SEP]']
[ 150/2000] tot_loss=2.057 (perp=9.628, rec=0.129, cos=0.003), tot_loss_proj:2.276 [t=0.25s]
prediction: ['[CLS] striking visually striking slick visually staged [SEP]']
[ 200/2000] tot_loss=2.031 (perp=9.628, rec=0.104, cos=0.002), tot_loss_proj:2.274 [t=0.25s]
prediction: ['[CLS] striking visually striking slick visually staged [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.877 (perp=8.946, rec=0.086, cos=0.002), tot_loss_proj:2.105 [t=0.28s]
prediction: ['[CLS] slick striking and striking visually staged [SEP]']
[ 300/2000] tot_loss=2.093 (perp=10.018, rec=0.088, cos=0.001), tot_loss_proj:2.357 [t=0.29s]
prediction: ['[CLS] slick striking andly visually staged [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.718 (perp=8.223, rec=0.072, cos=0.001), tot_loss_proj:1.811 [t=0.29s]
prediction: ['[CLS] slickly visually striking and staged [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.255 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.241 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.255 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.243 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.251 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.247 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.254 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.250 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.250 [t=0.28s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.228 (perp=5.916, rec=0.044, cos=0.001), tot_loss_proj:1.242 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.235 (perp=5.916, rec=0.051, cos=0.001), tot_loss_proj:1.235 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.244 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.253 [t=0.31s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.257 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.001), tot_loss_proj:1.240 [t=0.28s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.248 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.242 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.256 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.249 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.263 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.257 (perp=5.916, rec=0.073, cos=0.001), tot_loss_proj:1.253 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.237 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.001), tot_loss_proj:1.251 [t=0.28s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.236 [t=0.28s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.237 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.241 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.233 (perp=5.916, rec=0.048, cos=0.001), tot_loss_proj:1.256 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.247 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.241 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.256 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.243 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.242 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.230 (perp=5.916, rec=0.046, cos=0.001), tot_loss_proj:1.245 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.241 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.245 [t=0.30s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.253 [t=0.27s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.259 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.247 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.240 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.259 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.975 | p: 91.302 | r: 92.816
rouge2     | fm: 63.371 | p: 63.151 | r: 63.617
rougeL     | fm: 79.777 | p: 79.266 | r: 80.399
rougeLsum  | fm: 79.863 | p: 79.397 | r: 80.429
r1fm+r2fm = 155.346

input #46 time: 0:11:44 | total time: 7:44:22


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
*********************************
*********************************
average of cosine similarity 0.9992059059142621
highest_index [0]
highest [0.9992059059142621]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6953830718994141 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6925281286239624 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6903731226921082 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6853982210159302 for ['[CLS] purse divine rush [SEP]']
[Init] best rec loss: 0.6800500154495239 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.6800178289413452 for ['[CLS] circles hand school [SEP]']
[Init] best rec loss: 0.67453533411026 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6720250844955444 for ['[CLS] salt reality poles [SEP]']
[Init] best perm rec loss: 0.668911337852478 for ['[CLS] poles salt reality [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.737 (perp=11.373, rec=0.342, cos=0.121), tot_loss_proj:3.390 [t=0.24s]
prediction: ['[CLS] transparent transparent commando [SEP]']
[ 100/2000] tot_loss=2.771 (perp=12.775, rec=0.188, cos=0.028), tot_loss_proj:3.557 [t=0.25s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 150/2000] tot_loss=2.728 (perp=12.775, rec=0.126, cos=0.047), tot_loss_proj:3.557 [t=0.26s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 200/2000] tot_loss=2.741 (perp=12.775, rec=0.117, cos=0.068), tot_loss_proj:3.569 [t=0.25s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.672 (perp=12.775, rec=0.099, cos=0.018), tot_loss_proj:3.566 [t=0.27s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 300/2000] tot_loss=2.687 (perp=12.775, rec=0.102, cos=0.030), tot_loss_proj:3.558 [t=0.25s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.679 (perp=12.775, rec=0.106, cos=0.018), tot_loss_proj:3.568 [t=0.27s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.851 (perp=8.803, rec=0.081, cos=0.009), tot_loss_proj:1.827 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.857 (perp=8.803, rec=0.086, cos=0.011), tot_loss_proj:1.832 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.827 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.843 (perp=8.803, rec=0.075, cos=0.007), tot_loss_proj:1.828 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.866 (perp=8.803, rec=0.068, cos=0.037), tot_loss_proj:1.837 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.820 (perp=8.803, rec=0.056, cos=0.004), tot_loss_proj:1.833 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.825 (perp=8.803, rec=0.062, cos=0.003), tot_loss_proj:1.841 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.825 (perp=8.803, rec=0.060, cos=0.004), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.840 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.834 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.847 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.841 (perp=8.803, rec=0.066, cos=0.014), tot_loss_proj:1.842 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.853 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.834 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.840 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.836 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.846 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.845 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=8.803, rec=0.054, cos=0.002), tot_loss_proj:1.852 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.815 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.837 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.832 (perp=8.803, rec=0.070, cos=0.002), tot_loss_proj:1.847 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.846 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.836 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.836 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.842 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.810 (perp=8.803, rec=0.048, cos=0.002), tot_loss_proj:1.832 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.824 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.834 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.847 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.845 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.837 (perp=8.803, rec=0.075, cos=0.002), tot_loss_proj:1.830 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.853 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.839 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.227 | p: 91.473 | r: 93.031
rouge2     | fm: 63.800 | p: 63.659 | r: 64.014
rougeL     | fm: 80.415 | p: 79.948 | r: 80.921
rougeLsum  | fm: 80.251 | p: 79.802 | r: 80.796
r1fm+r2fm = 156.027

input #47 time: 0:10:54 | total time: 7:55:16


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
*********************************
*********************************
average of cosine similarity 0.9993046234064711
highest_index [0]
highest [0.9993046234064711]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9481353759765625 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9344632625579834 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9107456207275391 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.893878161907196 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8840940594673157 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8556822538375854 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8369787931442261 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.796784520149231 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7961894869804382 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7949187159538269 for ['[CLS]tutedine runs graveyard [SEP]']
[Init] best perm rec loss: 0.7926889657974243 for ['[CLS] graveyard runstutedine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.607 (perp=12.047, rec=0.192, cos=0.006), tot_loss_proj:2.843 [t=0.26s]
prediction: ['[CLS] rotting rotting under rotting [SEP]']
[ 100/2000] tot_loss=2.527 (perp=12.071, rec=0.111, cos=0.002), tot_loss_proj:2.701 [t=0.25s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.680 (perp=12.949, rec=0.089, cos=0.002), tot_loss_proj:2.936 [t=0.26s]
prediction: ['[CLS] rotting under underbell [SEP]']
[ 200/2000] tot_loss=2.677 (perp=12.949, rec=0.085, cos=0.002), tot_loss_proj:2.933 [t=0.25s]
prediction: ['[CLS] rotting under underbell [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.309 (perp=10.623, rec=0.179, cos=0.006), tot_loss_proj:2.542 [t=0.26s]
prediction: ['[CLS]y underbell rotting [SEP]']
[ 300/2000] tot_loss=2.233 (perp=10.623, rec=0.107, cos=0.001), tot_loss_proj:2.563 [t=0.26s]
prediction: ['[CLS]y underbell rotting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.497 (perp=7.028, rec=0.090, cos=0.001), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.730 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.462 (perp=7.028, rec=0.055, cos=0.001), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.484 (perp=7.028, rec=0.077, cos=0.001), tot_loss_proj:1.727 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.464 (perp=7.028, rec=0.057, cos=0.001), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.746 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.730 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.484 (perp=7.028, rec=0.077, cos=0.001), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.457 (perp=7.028, rec=0.050, cos=0.001), tot_loss_proj:1.735 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.724 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.482 (perp=7.028, rec=0.075, cos=0.001), tot_loss_proj:1.733 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.727 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.726 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.457 (perp=7.028, rec=0.050, cos=0.001), tot_loss_proj:1.743 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.727 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.735 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.465 (perp=7.028, rec=0.058, cos=0.001), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.739 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.350 | p: 91.670 | r: 93.128
rouge2     | fm: 62.587 | p: 62.437 | r: 62.749
rougeL     | fm: 80.027 | p: 79.622 | r: 80.567
rougeLsum  | fm: 80.283 | p: 79.793 | r: 80.797
r1fm+r2fm = 154.937

input #48 time: 0:11:01 | total time: 8:06:18


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
*********************************
*********************************
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8349988460540771 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7890780568122864 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7884876728057861 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 0.7864314913749695 for ['[CLS] saline rang market aspects senate brothersona situation trafficking health follows tel [SEP]']
[Init] best rec loss: 0.7806379795074463 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7647554874420166 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7542374730110168 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7533898949623108 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7522913813591003 for ['[CLS] tongue during process gmina patrick baby legsiza jose trick college jockey [SEP]']
[Init] best perm rec loss: 0.7503772377967834 for ['[CLS]iza process gmina jose college tongue baby patrick jockey during trick legs [SEP]']
[Init] best perm rec loss: 0.7501202821731567 for ['[CLS] legs college patrick gmina jockey trick baby during jose processiza tongue [SEP]']
[Init] best perm rec loss: 0.74857497215271 for ['[CLS] tongue jose trick jockey legs gmina patrick college babyiza during process [SEP]']
[Init] best perm rec loss: 0.7482708692550659 for ['[CLS] college process legs during trick patrick jockeyiza jose tongue gmina baby [SEP]']
[Init] best perm rec loss: 0.7479612827301025 for ['[CLS] jose baby legs during patrick tongue college process gmina trickiza jockey [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=10.703, rec=0.303, cos=0.058), tot_loss_proj:3.233 [t=0.29s]
prediction: ['[CLS] culture thick should. females population women than of contempt least possibly [SEP]']
[ 100/2000] tot_loss=2.139 (perp=9.666, rec=0.185, cos=0.021), tot_loss_proj:2.936 [t=0.30s]
prediction: ['[CLS] population heat less. single contempt female than of contemptuous could [SEP]']
[ 150/2000] tot_loss=2.270 (perp=10.585, rec=0.142, cos=0.011), tot_loss_proj:2.955 [t=0.28s]
prediction: ['[CLS] population heat could. singleuous female coulduous contempt more possibly [SEP]']
[ 200/2000] tot_loss=2.167 (perp=10.213, rec=0.116, cos=0.009), tot_loss_proj:3.066 [t=0.32s]
prediction: ['[CLS] population record could. singleuous female possibly of contempt more possibly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.047 (perp=9.614, rec=0.115, cos=0.009), tot_loss_proj:2.919 [t=0.29s]
prediction: ['[CLS] population possibly be. singleuous female contempt of possibly more possibly [SEP]']
[ 300/2000] tot_loss=2.006 (perp=9.504, rec=0.098, cos=0.007), tot_loss_proj:2.928 [t=0.28s]
prediction: ['[CLS] population possibly be. singleuous female contempt of possibly more could [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=9.504, rec=0.104, cos=0.006), tot_loss_proj:2.926 [t=0.29s]
prediction: ['[CLS] population possibly be. singleuous female contempt of possibly more could [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.961 (perp=9.267, rec=0.100, cos=0.007), tot_loss_proj:2.979 [t=0.29s]
prediction: ['[CLS] population possibly be. single contemptuous female of possibly more could [SEP]']
[ 450/2000] tot_loss=1.953 (perp=9.267, rec=0.094, cos=0.006), tot_loss_proj:2.976 [t=0.28s]
prediction: ['[CLS] population possibly be. single contemptuous female of possibly more could [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.864 (perp=8.823, rec=0.094, cos=0.006), tot_loss_proj:2.748 [t=0.28s]
prediction: ['[CLS] population possibly be. single contemptuous of female possibly more could [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.749 (perp=8.232, rec=0.097, cos=0.006), tot_loss_proj:2.699 [t=0.29s]
prediction: ['[CLS] population possibly be. single female contemptuous of possibly more could [SEP]']
[ 600/2000] tot_loss=1.747 (perp=8.232, rec=0.095, cos=0.005), tot_loss_proj:2.699 [t=0.29s]
prediction: ['[CLS] population possibly be. single female contemptuous of possibly more could [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.708 (perp=8.047, rec=0.093, cos=0.005), tot_loss_proj:2.566 [t=0.29s]
prediction: ['[CLS] population possibly be single. female contemptuous of possibly more could [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.706 (perp=8.047, rec=0.091, cos=0.005), tot_loss_proj:2.558 [t=0.28s]
prediction: ['[CLS] population possibly be single. female contemptuous of possibly more could [SEP]']
[ 750/2000] tot_loss=1.703 (perp=8.047, rec=0.088, cos=0.005), tot_loss_proj:2.561 [t=0.29s]
prediction: ['[CLS] population possibly be single. female contemptuous of possibly more could [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.661 (perp=7.829, rec=0.090, cos=0.005), tot_loss_proj:2.459 [t=0.30s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.652 (perp=7.829, rec=0.081, cos=0.005), tot_loss_proj:2.450 [t=0.32s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[ 900/2000] tot_loss=1.655 (perp=7.829, rec=0.085, cos=0.005), tot_loss_proj:2.457 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.656 (perp=7.829, rec=0.086, cos=0.005), tot_loss_proj:2.449 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1000/2000] tot_loss=1.663 (perp=7.829, rec=0.092, cos=0.005), tot_loss_proj:2.458 [t=0.30s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1050/2000] tot_loss=1.668 (perp=7.829, rec=0.097, cos=0.005), tot_loss_proj:2.453 [t=0.30s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1100/2000] tot_loss=1.659 (perp=7.829, rec=0.089, cos=0.005), tot_loss_proj:2.452 [t=0.30s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1150/2000] tot_loss=1.660 (perp=7.829, rec=0.090, cos=0.005), tot_loss_proj:2.454 [t=0.28s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1200/2000] tot_loss=1.658 (perp=7.829, rec=0.088, cos=0.005), tot_loss_proj:2.450 [t=0.28s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1250/2000] tot_loss=1.653 (perp=7.829, rec=0.082, cos=0.005), tot_loss_proj:2.449 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1300/2000] tot_loss=1.659 (perp=7.829, rec=0.088, cos=0.005), tot_loss_proj:2.453 [t=0.28s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1350/2000] tot_loss=1.658 (perp=7.829, rec=0.087, cos=0.005), tot_loss_proj:2.449 [t=0.28s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1400/2000] tot_loss=1.655 (perp=7.829, rec=0.085, cos=0.005), tot_loss_proj:2.450 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1450/2000] tot_loss=1.665 (perp=7.829, rec=0.094, cos=0.005), tot_loss_proj:2.453 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1500/2000] tot_loss=1.656 (perp=7.829, rec=0.085, cos=0.005), tot_loss_proj:2.449 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1550/2000] tot_loss=1.656 (perp=7.829, rec=0.086, cos=0.005), tot_loss_proj:2.447 [t=0.31s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1600/2000] tot_loss=1.653 (perp=7.829, rec=0.083, cos=0.005), tot_loss_proj:2.452 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1650/2000] tot_loss=1.665 (perp=7.829, rec=0.095, cos=0.005), tot_loss_proj:2.452 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1700/2000] tot_loss=1.663 (perp=7.829, rec=0.092, cos=0.005), tot_loss_proj:2.444 [t=0.30s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1750/2000] tot_loss=1.660 (perp=7.829, rec=0.089, cos=0.005), tot_loss_proj:2.448 [t=0.29s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1800/2000] tot_loss=1.655 (perp=7.829, rec=0.084, cos=0.005), tot_loss_proj:2.451 [t=0.28s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.829, rec=0.090, cos=0.005), tot_loss_proj:2.450 [t=0.26s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[1900/2000] tot_loss=1.664 (perp=7.829, rec=0.093, cos=0.005), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
[1950/2000] tot_loss=1.660 (perp=7.829, rec=0.089, cos=0.005), tot_loss_proj:2.448 [t=0.25s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Attempt swap
[2000/2000] tot_loss=1.655 (perp=7.829, rec=0.084, cos=0.005), tot_loss_proj:2.455 [t=0.25s]
prediction: ['[CLS] population possibly be single female. contemptuous of possibly more could [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] population possibly be single female. contemptuous of possibly more could [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 118.939

[Aggregate metrics]:
rouge1     | fm: 92.358 | p: 91.751 | r: 93.136
rouge2     | fm: 62.103 | p: 61.924 | r: 62.219
rougeL     | fm: 79.559 | p: 79.079 | r: 80.114
rougeLsum  | fm: 79.562 | p: 79.091 | r: 80.070
r1fm+r2fm = 154.460

input #49 time: 0:12:11 | total time: 8:18:30


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
*********************************
*********************************
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9206792116165161 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8376301527023315 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7573332786560059 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7526006698608398 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7520577311515808 for ['[CLS]ieving night byhamlent bridget accordance red crisis [SEP]']
[Init] best perm rec loss: 0.7493540644645691 for ['[CLS]lent accordance bridgethamieving by night crisis red [SEP]']
[Init] best perm rec loss: 0.7488336563110352 for ['[CLS]lent accordance redieving crisis night by bridgetham [SEP]']
[Init] best perm rec loss: 0.7483512163162231 for ['[CLS]hamievinglent accordance by red night bridget crisis [SEP]']
[Init] best perm rec loss: 0.7482115030288696 for ['[CLS] red accordance bridgetlent nightham byieving crisis [SEP]']
[Init] best perm rec loss: 0.7472875714302063 for ['[CLS]lentham accordance bridgetieving by night red crisis [SEP]']
[Init] best perm rec loss: 0.7451678514480591 for ['[CLS]lent crisis red by accordanceham nightieving bridget [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.821 (perp=11.847, rec=0.370, cos=0.081), tot_loss_proj:3.864 [t=0.24s]
prediction: ['[CLS] once bad clever thereby often pardon unknown genius handicap [SEP]']
[ 100/2000] tot_loss=2.621 (perp=11.383, rec=0.297, cos=0.047), tot_loss_proj:3.617 [t=0.25s]
prediction: ['[CLS] english what clever ` what called grand catherine half [SEP]']
[ 150/2000] tot_loss=2.632 (perp=11.589, rec=0.279, cos=0.036), tot_loss_proj:3.429 [t=0.25s]
prediction: ['[CLS] english what clever ` what call by catherine half [SEP]']
[ 200/2000] tot_loss=2.411 (perp=10.826, rec=0.220, cos=0.025), tot_loss_proj:3.314 [t=0.25s]
prediction: ['[CLS] english what clever ` english call by catherine half [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.254 (perp=10.367, rec=0.157, cos=0.024), tot_loss_proj:3.456 [t=0.26s]
prediction: ['[CLS] what english clever ` english call by calendar half [SEP]']
[ 300/2000] tot_loss=2.219 (perp=10.367, rec=0.133, cos=0.013), tot_loss_proj:3.459 [t=0.26s]
prediction: ['[CLS] what english clever ` english call by calendar half [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.081 (perp=9.768, rec=0.118, cos=0.009), tot_loss_proj:3.360 [t=0.27s]
prediction: ['[CLS] what english clever ` english call calendar by half [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.048 (perp=9.593, rec=0.121, cos=0.009), tot_loss_proj:2.910 [t=0.25s]
prediction: ['[CLS] what english ` english call christians clever by half [SEP]']
[ 450/2000] tot_loss=2.087 (perp=9.845, rec=0.112, cos=0.006), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] what english ` english call unfortunately clever by half [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.993 (perp=9.447, rec=0.096, cos=0.007), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] what english ` unfortunately call english clever by half [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.101 (perp=10.020, rec=0.094, cos=0.004), tot_loss_proj:2.461 [t=0.26s]
prediction: ['[CLS] what englishা ` call too clever by half [SEP]']
[ 600/2000] tot_loss=2.082 (perp=10.020, rec=0.075, cos=0.003), tot_loss_proj:2.457 [t=0.25s]
prediction: ['[CLS] what englishা ` call too clever by half [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.097 (perp=10.078, rec=0.079, cos=0.003), tot_loss_proj:2.470 [t=0.26s]
prediction: ['[CLS] what ` english the call too clever by half [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.845 (perp=8.843, rec=0.073, cos=0.003), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[ 750/2000] tot_loss=1.840 (perp=8.843, rec=0.069, cos=0.003), tot_loss_proj:2.082 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.842 (perp=8.843, rec=0.071, cos=0.002), tot_loss_proj:2.071 [t=0.28s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.845 (perp=8.843, rec=0.074, cos=0.002), tot_loss_proj:2.067 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[ 900/2000] tot_loss=1.846 (perp=8.843, rec=0.075, cos=0.002), tot_loss_proj:2.066 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.842 (perp=8.843, rec=0.071, cos=0.002), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1000/2000] tot_loss=1.836 (perp=8.843, rec=0.065, cos=0.002), tot_loss_proj:2.072 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1050/2000] tot_loss=1.846 (perp=8.843, rec=0.075, cos=0.002), tot_loss_proj:2.069 [t=0.27s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1100/2000] tot_loss=1.841 (perp=8.843, rec=0.070, cos=0.002), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1150/2000] tot_loss=1.840 (perp=8.843, rec=0.069, cos=0.002), tot_loss_proj:2.071 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1200/2000] tot_loss=1.842 (perp=8.843, rec=0.071, cos=0.002), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1250/2000] tot_loss=1.839 (perp=8.843, rec=0.068, cos=0.002), tot_loss_proj:2.068 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1300/2000] tot_loss=1.844 (perp=8.843, rec=0.073, cos=0.002), tot_loss_proj:2.074 [t=0.27s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1350/2000] tot_loss=1.838 (perp=8.843, rec=0.068, cos=0.002), tot_loss_proj:2.073 [t=0.24s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1400/2000] tot_loss=1.837 (perp=8.843, rec=0.066, cos=0.002), tot_loss_proj:2.070 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1450/2000] tot_loss=1.833 (perp=8.843, rec=0.062, cos=0.002), tot_loss_proj:2.070 [t=0.24s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1500/2000] tot_loss=1.836 (perp=8.843, rec=0.066, cos=0.002), tot_loss_proj:2.071 [t=0.27s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.845 (perp=8.843, rec=0.075, cos=0.002), tot_loss_proj:2.071 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.835 (perp=8.843, rec=0.065, cos=0.001), tot_loss_proj:2.068 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1650/2000] tot_loss=1.831 (perp=8.843, rec=0.061, cos=0.001), tot_loss_proj:2.072 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.833 (perp=8.843, rec=0.063, cos=0.001), tot_loss_proj:2.070 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.830 (perp=8.843, rec=0.059, cos=0.001), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1800/2000] tot_loss=1.830 (perp=8.843, rec=0.060, cos=0.001), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.835 (perp=8.843, rec=0.065, cos=0.001), tot_loss_proj:2.071 [t=0.27s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.843, rec=0.065, cos=0.001), tot_loss_proj:2.068 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
[1950/2000] tot_loss=1.839 (perp=8.843, rec=0.069, cos=0.001), tot_loss_proj:2.069 [t=0.25s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.837 (perp=8.843, rec=0.067, cos=0.001), tot_loss_proj:2.068 [t=0.26s]
prediction: ['[CLS] what the ` english call too clever by half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the ` english call too clever by half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.551 | p: 91.901 | r: 93.291
rouge2     | fm: 62.681 | p: 62.538 | r: 62.913
rougeL     | fm: 79.951 | p: 79.511 | r: 80.487
rougeLsum  | fm: 80.067 | p: 79.599 | r: 80.617
r1fm+r2fm = 155.232

input #50 time: 0:10:52 | total time: 8:29:22


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
*********************************
*********************************
average of cosine similarity 0.9992548315433465
highest_index [0]
highest [0.9992548315433465]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.826704740524292 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7897737622261047 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7381834387779236 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7270974516868591 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7253291010856628 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.7200135588645935 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7114751935005188 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7108536958694458 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7055902481079102 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7039530873298645 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7036332488059998 for ['[CLS]rak once watching literary renamed medium toured disappointed in market [SEP]']
[Init] best perm rec loss: 0.7021721601486206 for ['[CLS] disappointed toured renamed mediumrak once in watching market literary [SEP]']
[Init] best perm rec loss: 0.7017951011657715 for ['[CLS] toured disappointed in once medium renamed market literary watchingrak [SEP]']
[Init] best perm rec loss: 0.7002806663513184 for ['[CLS] medium market watching toured disappointedrak renamed in once literary [SEP]']
[Init] best perm rec loss: 0.7000938057899475 for ['[CLS] literary renamed toured watching disappointed medium market inrak once [SEP]']
[Init] best perm rec loss: 0.6998263597488403 for ['[CLS] medium toured disappointed once watching renamed marketrak literary in [SEP]']
[Init] best perm rec loss: 0.6994193196296692 for ['[CLS] medium in market watchingrak literary renamed toured disappointed once [SEP]']
[Init] best perm rec loss: 0.6993638277053833 for ['[CLS]rak renamed once watching medium toured disappointed in market literary [SEP]']
[Init] best perm rec loss: 0.6992019414901733 for ['[CLS] watching medium disappointed renamed marketrak in literary once toured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.723 (perp=11.587, rec=0.330, cos=0.076), tot_loss_proj:3.207 [t=0.27s]
prediction: ['[CLS] sucks should figured into but funny moment sometime exit sucks [SEP]']
[ 100/2000] tot_loss=2.249 (perp=9.863, rec=0.235, cos=0.041), tot_loss_proj:2.869 [t=0.25s]
prediction: ['[CLS] sucks has funny and. funny moment but funny sucks [SEP]']
[ 150/2000] tot_loss=1.687 (perp=7.689, rec=0.137, cos=0.012), tot_loss_proj:2.525 [t=0.24s]
prediction: ['[CLS] or has funny, a funny moment but funny sucks [SEP]']
[ 200/2000] tot_loss=1.639 (perp=7.689, rec=0.095, cos=0.007), tot_loss_proj:2.524 [t=0.25s]
prediction: ['[CLS] or has funny, a funny moment but funny sucks [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.608 (perp=7.602, rec=0.082, cos=0.006), tot_loss_proj:2.472 [t=0.24s]
prediction: ['[CLS] or funny, has a funny moment but two sucks [SEP]']
[ 300/2000] tot_loss=1.600 (perp=7.602, rec=0.075, cos=0.005), tot_loss_proj:2.482 [t=0.25s]
prediction: ['[CLS] or funny, has a funny moment but two sucks [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.547 (perp=7.369, rec=0.068, cos=0.005), tot_loss_proj:2.491 [t=0.25s]
prediction: ['[CLS] or, funny has a funny moment but two sucks [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.559 (perp=7.369, rec=0.081, cos=0.004), tot_loss_proj:2.492 [t=0.25s]
prediction: ['[CLS] or, funny has a funny moment but two sucks [SEP]']
[ 450/2000] tot_loss=1.550 (perp=7.369, rec=0.072, cos=0.004), tot_loss_proj:2.490 [t=0.26s]
prediction: ['[CLS] or, funny has a funny moment but two sucks [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.508 (perp=7.163, rec=0.071, cos=0.004), tot_loss_proj:2.376 [t=0.24s]
prediction: ['[CLS] or, just has a funny moment but two sucks [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.506 (perp=7.163, rec=0.069, cos=0.004), tot_loss_proj:2.379 [t=0.25s]
prediction: ['[CLS] or, just has a funny moment but two sucks [SEP]']
[ 600/2000] tot_loss=1.508 (perp=7.163, rec=0.071, cos=0.004), tot_loss_proj:2.379 [t=0.27s]
prediction: ['[CLS] or, just has a funny moment but two sucks [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.527 (perp=6.999, rec=0.112, cos=0.015), tot_loss_proj:2.238 [t=0.25s]
prediction: ['[CLS] but. a has a funny moment or two sucks [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.713 (perp=7.960, rec=0.106, cos=0.015), tot_loss_proj:2.317 [t=0.26s]
prediction: ['[CLS] but [SEP]. has a funny moment or two sucks [SEP]']
[ 750/2000] tot_loss=1.678 (perp=7.960, rec=0.078, cos=0.008), tot_loss_proj:2.331 [t=0.30s]
prediction: ['[CLS] but [SEP]. has a funny moment or two sucks [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.491 (perp=7.002, rec=0.084, cos=0.007), tot_loss_proj:1.922 [t=0.26s]
prediction: ['[CLS] but [SEP] sucks has a funny moment or two. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.276 (perp=5.907, rec=0.086, cos=0.008), tot_loss_proj:1.418 [t=0.26s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[ 900/2000] tot_loss=1.269 (perp=5.907, rec=0.081, cos=0.006), tot_loss_proj:1.414 [t=0.26s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.272 (perp=5.907, rec=0.085, cos=0.006), tot_loss_proj:1.418 [t=0.26s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.266 (perp=5.907, rec=0.079, cos=0.006), tot_loss_proj:1.419 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1050/2000] tot_loss=1.269 (perp=5.907, rec=0.082, cos=0.006), tot_loss_proj:1.415 [t=0.27s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.263 (perp=5.907, rec=0.075, cos=0.006), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.269 (perp=5.907, rec=0.082, cos=0.006), tot_loss_proj:1.416 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1200/2000] tot_loss=1.259 (perp=5.907, rec=0.072, cos=0.006), tot_loss_proj:1.417 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.262 (perp=5.907, rec=0.074, cos=0.006), tot_loss_proj:1.412 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.266 (perp=5.907, rec=0.079, cos=0.006), tot_loss_proj:1.414 [t=0.26s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1350/2000] tot_loss=1.263 (perp=5.907, rec=0.076, cos=0.006), tot_loss_proj:1.413 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.258 (perp=5.907, rec=0.071, cos=0.006), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.264 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.415 [t=0.27s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1500/2000] tot_loss=1.256 (perp=5.907, rec=0.069, cos=0.006), tot_loss_proj:1.417 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.265 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.420 [t=0.27s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.266 (perp=5.907, rec=0.079, cos=0.006), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1650/2000] tot_loss=1.271 (perp=5.907, rec=0.084, cos=0.006), tot_loss_proj:1.417 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.264 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.418 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.272 (perp=5.907, rec=0.085, cos=0.006), tot_loss_proj:1.407 [t=0.27s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1800/2000] tot_loss=1.258 (perp=5.907, rec=0.071, cos=0.006), tot_loss_proj:1.418 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.258 (perp=5.907, rec=0.071, cos=0.005), tot_loss_proj:1.410 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.261 (perp=5.907, rec=0.074, cos=0.006), tot_loss_proj:1.417 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1950/2000] tot_loss=1.263 (perp=5.907, rec=0.076, cos=0.006), tot_loss_proj:1.414 [t=0.25s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.261 (perp=5.907, rec=0.074, cos=0.006), tot_loss_proj:1.417 [t=0.26s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] or, funny has a funny moment but two sucks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 126.817

[Aggregate metrics]:
rouge1     | fm: 92.595 | p: 91.882 | r: 93.420
rouge2     | fm: 62.155 | p: 61.878 | r: 62.462
rougeL     | fm: 79.660 | p: 79.182 | r: 80.198
rougeLsum  | fm: 79.798 | p: 79.222 | r: 80.352
r1fm+r2fm = 154.750

input #51 time: 0:10:56 | total time: 8:40:19


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
*********************************
*********************************
average of cosine similarity 0.9992769471396808
highest_index [0]
highest [0.9992769471396808]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9633553624153137 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9276461005210876 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8949947357177734 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8681666254997253 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7894576191902161 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7760429382324219 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7046040296554565 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.291 (perp=10.655, rec=0.155, cos=0.005), tot_loss_proj:2.458 [t=0.26s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 100/2000] tot_loss=2.231 (perp=10.655, rec=0.097, cos=0.003), tot_loss_proj:2.466 [t=0.26s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 150/2000] tot_loss=2.219 (perp=10.655, rec=0.086, cos=0.002), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 200/2000] tot_loss=2.176 (perp=10.528, rec=0.068, cos=0.002), tot_loss_proj:2.207 [t=0.26s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.832 (perp=8.482, rec=0.130, cos=0.005), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.002), tot_loss_proj:2.128 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.140 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.137 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.135 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.128 [t=0.34s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.772 (perp=8.482, rec=0.074, cos=0.001), tot_loss_proj:2.126 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.759 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.123 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.766 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.134 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.752 (perp=8.482, rec=0.054, cos=0.001), tot_loss_proj:2.133 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.754 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.137 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.133 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.131 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.137 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.768 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.131 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.131 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.774 (perp=8.482, rec=0.076, cos=0.001), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.750 (perp=8.482, rec=0.052, cos=0.001), tot_loss_proj:2.135 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.747 (perp=8.482, rec=0.049, cos=0.001), tot_loss_proj:2.134 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=8.482, rec=0.050, cos=0.001), tot_loss_proj:2.129 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.128 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.770 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.136 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.129 [t=0.29s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.134 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.129 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.131 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.29s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.134 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.668 | p: 91.945 | r: 93.475
rouge2     | fm: 60.982 | p: 60.710 | r: 61.232
rougeL     | fm: 79.619 | p: 79.201 | r: 80.192
rougeLsum  | fm: 79.685 | p: 79.194 | r: 80.278
r1fm+r2fm = 153.651

input #52 time: 0:11:15 | total time: 8:51:34


Running input #53 of 100.
reference: 
========================
flinching 
========================
*********************************
*********************************
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9457181096076965 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.862006664276123 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8316056728363037 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7958467602729797 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7199336886405945 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.6997024416923523 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6986270546913147 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6915310621261597 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6842321157455444 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6748745441436768 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.787 (perp=12.492, rec=0.231, cos=0.057), tot_loss_proj:3.329 [t=0.30s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.664 (perp=12.492, rec=0.145, cos=0.020), tot_loss_proj:3.340 [t=0.28s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.638 (perp=12.492, rec=0.124, cos=0.016), tot_loss_proj:3.333 [t=0.29s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=1.695 (perp=8.090, rec=0.075, cos=0.002), tot_loss_proj:1.686 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.691 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.670 (perp=8.090, rec=0.050, cos=0.001), tot_loss_proj:1.696 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.662 (perp=8.090, rec=0.042, cos=0.001), tot_loss_proj:1.689 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.696 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.665 (perp=8.090, rec=0.045, cos=0.001), tot_loss_proj:1.690 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.686 [t=0.32s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.689 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.697 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.668 (perp=8.090, rec=0.048, cos=0.001), tot_loss_proj:1.685 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.688 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.694 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.668 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.698 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.686 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.686 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.709 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.689 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.686 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.690 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.688 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.680 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.694 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.698 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.695 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.690 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.688 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.685 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.685 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.684 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.689 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.683 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.709 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.847 | p: 92.178 | r: 93.608
rouge2     | fm: 61.730 | p: 61.517 | r: 61.945
rougeL     | fm: 79.869 | p: 79.349 | r: 80.468
rougeLsum  | fm: 80.018 | p: 79.551 | r: 80.563
r1fm+r2fm = 154.578

input #53 time: 0:12:05 | total time: 9:03:39


Running input #54 of 100.
reference: 
========================
hot topics 
========================
*********************************
*********************************
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9532368183135986 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8024941086769104 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7537968754768372 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7135902047157288 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7061654329299927 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.7006915807723999 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.287 (perp=9.351, rec=0.354, cos=0.062), tot_loss_proj:2.861 [t=0.25s]
prediction: ['[CLS] topics great [SEP]']
[ 100/2000] tot_loss=2.459 (perp=11.553, rec=0.141, cos=0.008), tot_loss_proj:2.875 [t=0.25s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.417 (perp=11.553, rec=0.102, cos=0.004), tot_loss_proj:2.880 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.407 (perp=11.553, rec=0.093, cos=0.003), tot_loss_proj:2.874 [t=0.27s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.733 (perp=8.198, rec=0.087, cos=0.006), tot_loss_proj:1.751 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.709 (perp=8.198, rec=0.067, cos=0.003), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.713 (perp=8.198, rec=0.071, cos=0.002), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.716 (perp=8.198, rec=0.073, cos=0.004), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.720 (perp=8.198, rec=0.078, cos=0.002), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.702 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.746 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.700 (perp=8.198, rec=0.059, cos=0.002), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.708 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.748 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.749 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.736 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.696 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.735 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.759 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.690 (perp=8.198, rec=0.049, cos=0.002), tot_loss_proj:1.750 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.715 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.747 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=8.198, rec=0.074, cos=0.002), tot_loss_proj:1.743 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.708 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.754 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.754 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.697 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.748 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.751 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.691 (perp=8.198, rec=0.050, cos=0.002), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.977 | p: 92.319 | r: 93.742
rouge2     | fm: 62.495 | p: 62.306 | r: 62.727
rougeL     | fm: 80.372 | p: 79.905 | r: 80.893
rougeLsum  | fm: 80.394 | p: 79.940 | r: 80.971
r1fm+r2fm = 155.472

input #54 time: 0:11:05 | total time: 9:14:45


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
*********************************
*********************************
average of cosine similarity 0.9991205863745831
highest_index [0]
highest [0.9991205863745831]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9149343371391296 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8663113713264465 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7905805706977844 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7703065872192383 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7634938359260559 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7582106590270996 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7517237663269043 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.712469220161438 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.703285276889801 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7019903659820557 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7008416652679443 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.651 (perp=10.646, rec=0.389, cos=0.133), tot_loss_proj:3.871 [t=0.25s]
prediction: ['[CLS] civilization settle easily [SEP]']
[ 100/2000] tot_loss=2.174 (perp=9.583, rec=0.209, cos=0.048), tot_loss_proj:2.336 [t=0.25s]
prediction: ['[CLS] too settles easily [SEP]']
[ 150/2000] tot_loss=1.993 (perp=9.583, rec=0.072, cos=0.004), tot_loss_proj:2.325 [t=0.26s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=1.987 (perp=9.583, rec=0.068, cos=0.002), tot_loss_proj:2.325 [t=0.26s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.795 (perp=8.671, rec=0.057, cos=0.004), tot_loss_proj:1.815 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.002), tot_loss_proj:1.796 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.002), tot_loss_proj:1.800 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.807 (perp=8.671, rec=0.071, cos=0.002), tot_loss_proj:1.800 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.805 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.810 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.814 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.801 (perp=8.671, rec=0.065, cos=0.002), tot_loss_proj:1.811 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.805 (perp=8.671, rec=0.069, cos=0.002), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.805 (perp=8.671, rec=0.069, cos=0.002), tot_loss_proj:1.813 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.790 (perp=8.671, rec=0.054, cos=0.002), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.801 (perp=8.671, rec=0.065, cos=0.002), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.792 (perp=8.671, rec=0.056, cos=0.002), tot_loss_proj:1.804 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.808 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.792 (perp=8.671, rec=0.056, cos=0.002), tot_loss_proj:1.809 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.788 (perp=8.671, rec=0.052, cos=0.002), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.784 (perp=8.671, rec=0.048, cos=0.002), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.795 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.781 (perp=8.671, rec=0.045, cos=0.002), tot_loss_proj:1.813 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.002), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.815 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.810 (perp=8.671, rec=0.074, cos=0.002), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.783 (perp=8.671, rec=0.047, cos=0.002), tot_loss_proj:1.804 [t=0.32s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.804 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.802 (perp=8.671, rec=0.066, cos=0.002), tot_loss_proj:1.806 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.803 [t=0.32s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.797 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.798 (perp=8.671, rec=0.062, cos=0.002), tot_loss_proj:1.791 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.795 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.796 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.791 (perp=8.671, rec=0.055, cos=0.002), tot_loss_proj:1.794 [t=0.29s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.002), tot_loss_proj:1.808 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=8.671, rec=0.055, cos=0.002), tot_loss_proj:1.801 [t=0.28s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.127 | p: 92.517 | r: 93.914
rouge2     | fm: 62.914 | p: 62.701 | r: 63.080
rougeL     | fm: 80.660 | p: 80.188 | r: 81.193
rougeLsum  | fm: 80.852 | p: 80.388 | r: 81.415
r1fm+r2fm = 156.040

input #55 time: 0:11:12 | total time: 9:25:58


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
*********************************
*********************************
average of cosine similarity 0.9992743912224644
highest_index [0]
highest [0.9992743912224644]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.932321310043335 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9175447821617126 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9035267233848572 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8958414793014526 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.8944609761238098 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8827247619628906 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8799951076507568 for ['[CLS] almost wall up emotional defeated leadership acquainted variables spectroscopy dive realm with consolation households cas potential obsidian handed existing been organization [SEP]']
[Init] best perm rec loss: 0.8781517744064331 for ['[CLS] organization almost been emotional consolation defeated existing obsidian households acquainted with spectroscopy dive wall leadership up cas handed potential realm variables [SEP]']
[Init] best perm rec loss: 0.8778687119483948 for ['[CLS] cas variables wall emotional potential dive spectroscopy leadership organization obsidian existing consolation with almost defeated realm handed up been acquainted households [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.411 (perp=10.767, rec=0.247, cos=0.010), tot_loss_proj:3.021 [t=0.30s]
prediction: ['[CLS] full damagees painful cause films destroyed movie damage any costly damageeries at repairter damage that films problem damage [SEP]']
[ 100/2000] tot_loss=2.381 (perp=11.011, rec=0.173, cos=0.006), tot_loss_proj:3.066 [t=0.28s]
prediction: ['[CLS] which causesre which cause films damage loads damage that costly fix almost of costly of analysis which films fix damage [SEP]']
[ 150/2000] tot_loss=2.441 (perp=11.529, rec=0.132, cos=0.004), tot_loss_proj:2.989 [t=0.28s]
prediction: ['[CLS] which causesre painful will films damage loads damage that costly fix years of never of analysis could films fix damage [SEP]']
[ 200/2000] tot_loss=2.274 (perp=10.857, rec=0.100, cos=0.002), tot_loss_proj:3.086 [t=0.29s]
prediction: ['[CLS] whichparare which will films cause loads damage that costly fix years and never of analysis could filmsble damage [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.242 (perp=10.223, rec=0.193, cos=0.005), tot_loss_proj:2.930 [t=0.28s]
prediction: ['[CLS] whichpara石 so will films cause loads of that costly fix years and never years analysis could filmsble damage [SEP]']
[ 300/2000] tot_loss=2.104 (perp=9.945, rec=0.112, cos=0.003), tot_loss_proj:2.837 [t=0.28s]
prediction: ['[CLS] whichpara of which will films cause loads of that costly fix years and never years analysis could filmsble damage [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.999 (perp=9.480, rec=0.100, cos=0.003), tot_loss_proj:3.509 [t=0.28s]
prediction: ['[CLS] whichpara of which will films cause loads of that costly fix years and years never analysis could films never damage [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.022 (perp=9.597, rec=0.101, cos=0.002), tot_loss_proj:3.551 [t=0.28s]
prediction: ['[CLS]para which of that will films cause loads of that costly fix years and years never analysis could films never damage [SEP]']
[ 450/2000] tot_loss=2.050 (perp=9.798, rec=0.088, cos=0.002), tot_loss_proj:3.486 [t=0.28s]
prediction: ['[CLS]para which of that will“ cause loads of that costly fix years and years never analysis could films never damage [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.919 (perp=9.157, rec=0.086, cos=0.002), tot_loss_proj:3.340 [t=0.28s]
prediction: ['[CLS] that which ofpara will“ cause loads of that costly fix years and years never analysis could films never damage [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.860 (perp=8.878, rec=0.083, cos=0.002), tot_loss_proj:3.411 [t=0.26s]
prediction: ['[CLS] that which ofpara will“ cause loads of that costly fix years and years never analysis films could never damage [SEP]']
[ 600/2000] tot_loss=1.832 (perp=8.695, rec=0.091, cos=0.002), tot_loss_proj:3.403 [t=0.29s]
prediction: ['[CLS] that which ofpara willpara cause loads of that costly fix years and years never analysis films could never damage [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.823 (perp=8.695, rec=0.082, cos=0.002), tot_loss_proj:3.402 [t=0.28s]
prediction: ['[CLS] that which ofpara willpara cause loads of that costly fix years and years never analysis films could never damage [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.880 (perp=8.995, rec=0.079, cos=0.002), tot_loss_proj:2.604 [t=0.28s]
prediction: ['[CLS] that which ofpara willpara cause loads of that costly fix years and years never analysis are filmsble damage [SEP]']
[ 750/2000] tot_loss=1.887 (perp=8.995, rec=0.086, cos=0.002), tot_loss_proj:2.604 [t=0.28s]
prediction: ['[CLS] that which ofpara willpara cause loads of that costly fix years and years never analysis are filmsble damage [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.936 (perp=9.239, rec=0.086, cos=0.002), tot_loss_proj:2.559 [t=0.28s]
prediction: ['[CLS]s which ofpara will films cause loads of that costly fix years and years never analysis areparable damage [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.933 (perp=9.239, rec=0.083, cos=0.002), tot_loss_proj:2.564 [t=0.30s]
prediction: ['[CLS]s which ofpara will films cause loads of that costly fix years and years never analysis areparable damage [SEP]']
[ 900/2000] tot_loss=1.928 (perp=9.239, rec=0.079, cos=0.002), tot_loss_proj:2.568 [t=0.26s]
prediction: ['[CLS]s which ofpara will films cause loads of that costly fix years and years never analysis areparable damage [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.896 (perp=9.081, rec=0.078, cos=0.002), tot_loss_proj:2.419 [t=0.27s]
prediction: ['[CLS]s which ofpara will cause films loads of that costly fix years and years never analysis areparable damage [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.871 (perp=8.919, rec=0.085, cos=0.002), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] are which ofpara will cause films loads of that costly fix years and years never analysissparable damage [SEP]']
[1050/2000] tot_loss=1.859 (perp=8.898, rec=0.078, cos=0.002), tot_loss_proj:2.504 [t=0.25s]
prediction: ["[CLS]'which ofpara will cause films loads of that costly fix years and years never analysissparable damage [SEP]"]
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.949 (perp=9.315, rec=0.084, cos=0.002), tot_loss_proj:3.230 [t=0.29s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years never analysisspara never damage [SEP]"]
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.948 (perp=9.299, rec=0.086, cos=0.002), tot_loss_proj:3.278 [t=0.37s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years could analysiss never damagepara [SEP]"]
[1200/2000] tot_loss=1.947 (perp=9.299, rec=0.085, cos=0.002), tot_loss_proj:3.276 [t=0.25s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years could analysiss never damagepara [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.822 (perp=8.541, rec=0.112, cos=0.002), tot_loss_proj:3.059 [t=0.28s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years analysiss could never damagepara [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.809 (perp=8.541, rec=0.099, cos=0.002), tot_loss_proj:3.066 [t=0.28s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years analysiss could never damagepara [SEP]"]
[1350/2000] tot_loss=1.808 (perp=8.541, rec=0.098, cos=0.002), tot_loss_proj:3.056 [t=0.30s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years analysiss could never damagepara [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.809 (perp=8.541, rec=0.098, cos=0.002), tot_loss_proj:3.060 [t=0.28s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and years analysiss could never damagepara [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.744 (perp=8.263, rec=0.090, cos=0.002), tot_loss_proj:3.071 [t=0.26s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and yearsparas could never damage analysis [SEP]"]
[1500/2000] tot_loss=1.744 (perp=8.263, rec=0.089, cos=0.002), tot_loss_proj:3.074 [t=0.28s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and yearsparas could never damage analysis [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.748 (perp=8.263, rec=0.093, cos=0.002), tot_loss_proj:3.069 [t=0.27s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and yearsparas could never damage analysis [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.738 (perp=8.263, rec=0.083, cos=0.002), tot_loss_proj:3.064 [t=0.25s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and yearsparas could never damage analysis [SEP]"]
[1650/2000] tot_loss=1.735 (perp=8.263, rec=0.080, cos=0.002), tot_loss_proj:3.070 [t=0.26s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and yearsparas could never damage analysis [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.735 (perp=8.263, rec=0.081, cos=0.002), tot_loss_proj:3.075 [t=0.27s]
prediction: ["[CLS]'which films ofpara will cause loads of that costly fix years and yearsparas could never damage analysis [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.711 (perp=8.175, rec=0.075, cos=0.002), tot_loss_proj:3.044 [t=0.26s]
prediction: ["[CLS]'which films ofpara will cause loads of fix that costly years and yearsparas could never damage analysis [SEP]"]
[1800/2000] tot_loss=1.712 (perp=8.175, rec=0.075, cos=0.002), tot_loss_proj:3.038 [t=0.28s]
prediction: ["[CLS]'which films ofpara will cause loads of fix that costly years and yearsparas could never damage analysis [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.811 (perp=8.669, rec=0.075, cos=0.002), tot_loss_proj:3.007 [t=0.26s]
prediction: ["[CLS]'which films ofpara will cause loads of fix that costly years and yearsparable could never damage analysis [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.815 (perp=8.669, rec=0.079, cos=0.002), tot_loss_proj:3.009 [t=0.25s]
prediction: ["[CLS]'which films ofpara will cause loads of fix that costly years and yearsparable could never damage analysis [SEP]"]
[1950/2000] tot_loss=1.808 (perp=8.669, rec=0.073, cos=0.002), tot_loss_proj:3.002 [t=0.26s]
prediction: ["[CLS]'which films ofpara will cause loads of fix that costly years and yearsparable could never damage analysis [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.782 (perp=8.511, rec=0.079, cos=0.002), tot_loss_proj:2.718 [t=0.26s]
prediction: ["[CLS] costly which films ofpara will cause loads of fix that'years and yearsparable could never damage analysis [SEP]"]
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS]'which films ofpara will cause loads of fix that costly years and yearsparable could never damage analysis [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.179 | p: 89.474 | r: 85.000
rouge2     | fm: 27.027 | p: 27.778 | r: 26.316
rougeL     | fm: 61.538 | p: 63.158 | r: 60.000
rougeLsum  | fm: 61.538 | p: 63.158 | r: 60.000
r1fm+r2fm = 114.207

[Aggregate metrics]:
rouge1     | fm: 93.018 | p: 92.400 | r: 93.739
rouge2     | fm: 62.388 | p: 62.241 | r: 62.620
rougeL     | fm: 80.409 | p: 79.980 | r: 80.899
rougeLsum  | fm: 80.390 | p: 79.933 | r: 80.909
r1fm+r2fm = 155.406

input #56 time: 0:11:21 | total time: 9:37:19


Running input #57 of 100.
reference: 
========================
wears 
========================
*********************************
*********************************
average of cosine similarity 0.9993815950585869
highest_index [0]
highest [0.9993815950585869]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8631657361984253 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7994511723518372 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.705524206161499 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6581541299819946 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.643149733543396 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.711 (perp=12.282, rec=0.194, cos=0.060), tot_loss_proj:2.530 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.533 (perp=12.282, rec=0.074, cos=0.003), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.529 (perp=12.282, rec=0.071, cos=0.002), tot_loss_proj:2.528 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.511 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.533 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.511 (perp=12.282, rec=0.051, cos=0.003), tot_loss_proj:2.519 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.002), tot_loss_proj:2.521 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.515 (perp=12.282, rec=0.056, cos=0.002), tot_loss_proj:2.515 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.505 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.506 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.528 (perp=12.282, rec=0.071, cos=0.001), tot_loss_proj:2.510 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.512 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.515 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.521 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.515 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.527 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.528 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.505 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.512 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.527 (perp=12.282, rec=0.070, cos=0.001), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.514 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.527 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.507 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.509 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.523 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.516 (perp=12.282, rec=0.059, cos=0.001), tot_loss_proj:2.530 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.511 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.509 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.505 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.512 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.524 (perp=12.282, rec=0.066, cos=0.001), tot_loss_proj:2.528 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.509 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.518 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.530 (perp=12.282, rec=0.073, cos=0.001), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.513 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.512 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.508 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.526 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.518 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.507 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.529 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.517 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.517 (perp=12.282, rec=0.059, cos=0.001), tot_loss_proj:2.517 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.527 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.145 | p: 92.549 | r: 93.855
rouge2     | fm: 63.232 | p: 63.042 | r: 63.454
rougeL     | fm: 80.795 | p: 80.306 | r: 81.268
rougeLsum  | fm: 80.636 | p: 80.200 | r: 81.184
r1fm+r2fm = 156.376

input #57 time: 0:11:01 | total time: 9:48:21


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
*********************************
*********************************
average of cosine similarity 0.9992685151622412
highest_index [0]
highest [0.9992685151622412]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9649522304534912 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9525012969970703 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9179250597953796 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9173662066459656 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9167462587356567 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8904667496681213 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8734395503997803 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.872577428817749 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.872272789478302 for ['[CLS] verde finishedager thighs beauty estitical trade zack herselfuration apart chieftyle down serious [SEP]']
[Init] best perm rec loss: 0.8679993748664856 for ['[CLS] down herselfitical verde zack finished apart serious chiefuration thighs tradetyle beauty estager [SEP]']
[Init] best perm rec loss: 0.8665047287940979 for ['[CLS]itical est trade zack serioustyle herself down thighs finished beauty apart chiefageruration verde [SEP]']
[Init] best perm rec loss: 0.8653094172477722 for ['[CLS] beauty aparturation thighs trade verde zack down chief finished herself serioustyle estiticalager [SEP]']
[Init] best perm rec loss: 0.8635257482528687 for ['[CLS] est chief beauty down zack serious tradetyle verde thighsurationitical apartager herself finished [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.669 (perp=11.959, rec=0.269, cos=0.008), tot_loss_proj:4.247 [t=0.29s]
prediction: ['[CLS]less country sexual excellent academic relationship throughout clever entertainment good compulsion relationship goodbye song financial was [SEP]']
[ 100/2000] tot_loss=2.351 (perp=10.729, rec=0.201, cos=0.003), tot_loss_proj:2.929 [t=0.30s]
prediction: ['[CLS], heart economic inspirational childhood story throughout inspirational fitness personal inspirational relationship love story inspirational a [SEP]']
[ 150/2000] tot_loss=2.096 (perp=9.767, rec=0.141, cos=0.002), tot_loss_proj:2.876 [t=0.30s]
prediction: ['[CLS] is - sexual inspirational first story throughout capturing fitness personal, relationship love story inspirational a [SEP]']
[ 200/2000] tot_loss=2.211 (perp=10.499, rec=0.109, cos=0.002), tot_loss_proj:2.907 [t=0.30s]
prediction: ['[CLS] is - sexual inspirational first encounter throughout capturing innocence capturing,ache love story inspirational an [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.047 (perp=9.770, rec=0.091, cos=0.002), tot_loss_proj:2.705 [t=0.29s]
prediction: ['[CLS] is - sexual inspirational first encounter throughout capturing innocence ideal innocence, love story inspirational an [SEP]']
[ 300/2000] tot_loss=2.042 (perp=9.708, rec=0.099, cos=0.002), tot_loss_proj:2.635 [t=0.31s]
prediction: ['[CLS] is - uses inspirational first encounter throughout capturing innocence ideal innocence, love story inspirational an [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.878 (perp=8.878, rec=0.101, cos=0.002), tot_loss_proj:2.395 [t=0.31s]
prediction: ['[CLS] is - inspirational first encounter sense capturing innocence ideal innocence, love story inspirational of an [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.761 (perp=8.336, rec=0.093, cos=0.002), tot_loss_proj:2.247 [t=0.30s]
prediction: ['[CLS] is sense inspirational first encounter and capturing innocence ideal innocence, love story inspirational of an [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.336, rec=0.085, cos=0.002), tot_loss_proj:2.245 [t=0.30s]
prediction: ['[CLS] is sense inspirational first encounter and capturing innocence ideal innocence, love story inspirational of an [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.601 (perp=7.556, rec=0.088, cos=0.002), tot_loss_proj:2.045 [t=0.31s]
prediction: ['[CLS] is sense inspirational first encounter, capturing innocence ideal and and love story inspirational of an [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.560 (perp=7.369, rec=0.085, cos=0.002), tot_loss_proj:1.933 [t=0.31s]
prediction: ['[CLS] is sense inspirational first encounter, capturing innocence ideal and love story and inspirational of an [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.369, rec=0.090, cos=0.002), tot_loss_proj:1.934 [t=0.31s]
prediction: ['[CLS] is sense inspirational first encounter, capturing innocence ideal and love story and inspirational of an [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.504 (perp=7.155, rec=0.071, cos=0.002), tot_loss_proj:1.763 [t=0.30s]
prediction: ['[CLS] is inspirational inspirational first encounter, capturing innocence ideal and love story and sense of an [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.405 (perp=6.593, rec=0.084, cos=0.002), tot_loss_proj:1.643 [t=0.31s]
prediction: ['[CLS] is an inspirational first encounter, capturing innocence ideal of love story and sense of inspirational [SEP]']
[ 750/2000] tot_loss=1.399 (perp=6.593, rec=0.079, cos=0.002), tot_loss_proj:1.639 [t=0.29s]
prediction: ['[CLS] is an inspirational first encounter, capturing innocence ideal of love story and sense of inspirational [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.365 (perp=6.397, rec=0.084, cos=0.002), tot_loss_proj:1.563 [t=0.29s]
prediction: ['[CLS] is an inspirational first encounter story, capturing innocence ideal of love and sense of inspirational [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.368 (perp=6.401, rec=0.086, cos=0.002), tot_loss_proj:1.531 [t=0.30s]
prediction: ['[CLS] is an inspirational first encounter story, capturing innocence of ideal love and sense of inspirational [SEP]']
[ 900/2000] tot_loss=1.537 (perp=7.282, rec=0.080, cos=0.002), tot_loss_proj:1.794 [t=0.29s]
prediction: ['[CLS] is an inspirational first encounter story, capturing innocence of ideal love and sense ideal inspirational [SEP]']
Attempt swap
Put prefix at the end
[ 950/2000] tot_loss=1.385 (perp=6.539, rec=0.076, cos=0.002), tot_loss_proj:1.661 [t=0.31s]
prediction: ['[CLS] ideal inspirational is an inspirational first encounter story, capturing innocence of the love and sense [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.314 (perp=6.179, rec=0.077, cos=0.001), tot_loss_proj:1.562 [t=0.31s]
prediction: ['[CLS] ideal inspirational is an inspirational first encounter story, capturing innocence and the love of sense [SEP]']
[1050/2000] tot_loss=1.324 (perp=6.179, rec=0.086, cos=0.002), tot_loss_proj:1.557 [t=0.25s]
prediction: ['[CLS] ideal inspirational is an inspirational first encounter story, capturing innocence and the love of sense [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.259 (perp=5.920, rec=0.073, cos=0.002), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] ideal inspirational is an inspirational first encounter story, capturing innocence and the sense of love [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.222 (perp=5.715, rec=0.078, cos=0.002), tot_loss_proj:1.464 [t=0.26s]
prediction: ['[CLS] ideal inspirational is an inspirational first love story, capturing innocence and the sense of encounter [SEP]']
[1200/2000] tot_loss=1.215 (perp=5.715, rec=0.070, cos=0.002), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] ideal inspirational is an inspirational first love story, capturing innocence and the sense of encounter [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.221 (perp=5.718, rec=0.075, cos=0.002), tot_loss_proj:1.441 [t=0.26s]
prediction: ['[CLS] inspirational ideal is an inspirational first love story, capturing innocence and the sense of encounter [SEP]']
Attempt swap
[1300/2000] tot_loss=1.384 (perp=6.536, rec=0.076, cos=0.002), tot_loss_proj:1.686 [t=0.27s]
prediction: ['[CLS] inspirational ideal is an inspirational first love story, capturing innocence and the fur of encounter [SEP]']
[1350/2000] tot_loss=1.385 (perp=6.536, rec=0.077, cos=0.002), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] inspirational ideal is an inspirational first love story, capturing innocence and the fur of encounter [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.361 (perp=6.414, rec=0.076, cos=0.002), tot_loss_proj:1.653 [t=0.26s]
prediction: ['[CLS] inspirational ideal is an inspirational first love story, capturing fur and the innocence of encounter [SEP]']
Attempt swap
[1450/2000] tot_loss=1.369 (perp=6.414, rec=0.085, cos=0.002), tot_loss_proj:1.650 [t=0.25s]
prediction: ['[CLS] inspirational ideal is an inspirational first love story, capturing fur and the innocence of encounter [SEP]']
[1500/2000] tot_loss=1.362 (perp=6.414, rec=0.078, cos=0.002), tot_loss_proj:1.648 [t=0.27s]
prediction: ['[CLS] inspirational ideal is an inspirational first love story, capturing fur and the innocence of encounter [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.252 (perp=5.873, rec=0.076, cos=0.002), tot_loss_proj:1.638 [t=0.27s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, capturing and the innocence of encounter [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.177 (perp=5.437, rec=0.088, cos=0.002), tot_loss_proj:1.529 [t=0.25s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
[1650/2000] tot_loss=1.166 (perp=5.437, rec=0.077, cos=0.002), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
Attempt swap
[1700/2000] tot_loss=1.162 (perp=5.437, rec=0.073, cos=0.002), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
Attempt swap
[1750/2000] tot_loss=1.169 (perp=5.437, rec=0.080, cos=0.002), tot_loss_proj:1.531 [t=0.29s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
[1800/2000] tot_loss=1.164 (perp=5.437, rec=0.075, cos=0.002), tot_loss_proj:1.526 [t=0.26s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
Attempt swap
[1850/2000] tot_loss=1.166 (perp=5.437, rec=0.077, cos=0.002), tot_loss_proj:1.531 [t=0.28s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
Attempt swap
[1900/2000] tot_loss=1.158 (perp=5.437, rec=0.069, cos=0.002), tot_loss_proj:1.523 [t=0.27s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
[1950/2000] tot_loss=1.162 (perp=5.437, rec=0.073, cos=0.002), tot_loss_proj:1.528 [t=0.26s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
Attempt swap
[2000/2000] tot_loss=1.163 (perp=5.437, rec=0.074, cos=0.002), tot_loss_proj:1.529 [t=0.28s]
prediction: ['[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] inspirational fur ideal is an ideal first love story, and capturing the innocence of encounter [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.848 | p: 82.353 | r: 87.500
rouge2     | fm: 32.258 | p: 31.250 | r: 33.333
rougeL     | fm: 66.667 | p: 64.706 | r: 68.750
rougeLsum  | fm: 66.667 | p: 64.706 | r: 68.750
r1fm+r2fm = 117.107

[Aggregate metrics]:
rouge1     | fm: 92.985 | p: 92.364 | r: 93.744
rouge2     | fm: 62.676 | p: 62.505 | r: 62.899
rougeL     | fm: 80.482 | p: 80.063 | r: 81.009
rougeLsum  | fm: 80.526 | p: 80.070 | r: 81.063
r1fm+r2fm = 155.661

input #58 time: 0:11:48 | total time: 10:00:09


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9151541590690613 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.9016127586364746 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8955602645874023 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.865580677986145 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.857191801071167 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8294965028762817 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8291977643966675 for ['[CLS] wasby temperament awhile noah information bologna 1993 fleet thus pump bobo races tunnel stuffak [SEP]']
[Init] best perm rec loss: 0.8291869163513184 for ['[CLS] awhile pump bobo tunnel fleet thus was temperamentak races stuff noah 1993by bologna information [SEP]']
[Init] best perm rec loss: 0.8275994658470154 for ['[CLS] thus information pump temperament awhile bobo races stuff fleetby was 1993 noah tunnelak bologna [SEP]']
[Init] best perm rec loss: 0.8272705078125 for ['[CLS] fleet temperament pumpak information noah bologna races tunnelby awhile thus stuff bobo 1993 was [SEP]']
[Init] best perm rec loss: 0.8271450400352478 for ['[CLS] bologna tunnel pump thus noah races information bobo stuff fleet 1993 temperament wasakby awhile [SEP]']
[Init] best perm rec loss: 0.8269852995872498 for ['[CLS] bologna pump 1993 information awhile stuffbyak bobo fleet races temperament thus was noah tunnel [SEP]']
[Init] best perm rec loss: 0.8267932534217834 for ['[CLS] thus 1993 bologna stuff pump temperament fleet tunnel was awhile noahakby races bobo information [SEP]']
[Init] best perm rec loss: 0.8258228898048401 for ['[CLS] bobo stuff temperamentby tunnel 1993 informationak thus races awhile noah bologna pump was fleet [SEP]']
[Init] best perm rec loss: 0.8244286775588989 for ['[CLS]by fleet thus information bologna tunnel temperament races awhile stuff pump noah bobo was 1993ak [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.975 (perp=13.104, rec=0.339, cos=0.015), tot_loss_proj:4.006 [t=0.26s]
prediction: ['[CLS] nature suppliesographic the spots youngcy event classical womando brillianttails runner the coffee [SEP]']
[ 100/2000] tot_loss=2.610 (perp=11.739, rec=0.257, cos=0.005), tot_loss_proj:3.918 [t=0.26s]
prediction: ['[CLS] nature hasstic hasism young of event ms woman styled looking char woman the screen [SEP]']
[ 150/2000] tot_loss=2.333 (perp=10.742, rec=0.182, cos=0.003), tot_loss_proj:3.641 [t=0.26s]
prediction: ['[CLS] nature hasstic hasism young of screen of woman knowing how char screen the screen [SEP]']
[ 200/2000] tot_loss=2.345 (perp=10.978, rec=0.145, cos=0.004), tot_loss_proj:3.628 [t=0.28s]
prediction: ['[CLS] nature has char hasism young of screen of woman who how char screen the screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.984 (perp=9.280, rec=0.126, cos=0.002), tot_loss_proj:3.201 [t=0.26s]
prediction: ['[CLS] nature hasism has char young of screen a woman who how how hold the screen [SEP]']
[ 300/2000] tot_loss=2.043 (perp=9.678, rec=0.106, cos=0.002), tot_loss_proj:3.117 [t=0.27s]
prediction: ['[CLS]ism charism has char young of screen a woman who how how hold the screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.846 (perp=8.670, rec=0.111, cos=0.002), tot_loss_proj:2.816 [t=0.26s]
prediction: ['[CLS]ismism has char young of screen a woman who knows char how hold thea [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.794 (perp=8.450, rec=0.103, cos=0.001), tot_loss_proj:2.732 [t=0.26s]
prediction: ['[CLS]ismism has char young of screen a woman who knows how char hold thea [SEP]']
[ 450/2000] tot_loss=1.782 (perp=8.450, rec=0.091, cos=0.001), tot_loss_proj:2.731 [t=0.26s]
prediction: ['[CLS]ismism has char young of screen a woman who knows how char hold thea [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.722 (perp=8.122, rec=0.096, cos=0.002), tot_loss_proj:2.678 [t=0.28s]
prediction: ['[CLS]ismism has the young of screen a woman who knows how char hold chara [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.717 (perp=8.122, rec=0.092, cos=0.001), tot_loss_proj:2.676 [t=0.27s]
prediction: ['[CLS]ismism has the young of screen a woman who knows how char hold chara [SEP]']
[ 600/2000] tot_loss=1.728 (perp=8.241, rec=0.078, cos=0.001), tot_loss_proj:2.614 [t=0.25s]
prediction: ['[CLS] charism has the young of screen a woman who knows how char hold chara [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.443 (perp=6.781, rec=0.085, cos=0.002), tot_loss_proj:2.082 [t=0.28s]
prediction: ['[CLS] charisma has the young of screen a woman who knows how char hold char [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.387 (perp=6.536, rec=0.078, cos=0.002), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] screen charisma has the young of a woman who knows how char hold char [SEP]']
[ 750/2000] tot_loss=1.387 (perp=6.536, rec=0.078, cos=0.001), tot_loss_proj:2.030 [t=0.26s]
prediction: ['[CLS] screen charisma has the young of a woman who knows how char hold char [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.299 (perp=6.098, rec=0.078, cos=0.001), tot_loss_proj:1.963 [t=0.28s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.304 (perp=6.098, rec=0.083, cos=0.001), tot_loss_proj:1.994 [t=0.26s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[ 900/2000] tot_loss=1.283 (perp=6.098, rec=0.062, cos=0.001), tot_loss_proj:1.995 [t=0.28s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.296 (perp=6.098, rec=0.075, cos=0.001), tot_loss_proj:1.999 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.298 (perp=6.098, rec=0.077, cos=0.001), tot_loss_proj:1.955 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1050/2000] tot_loss=1.291 (perp=6.098, rec=0.070, cos=0.001), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1100/2000] tot_loss=1.301 (perp=6.098, rec=0.080, cos=0.001), tot_loss_proj:1.958 [t=0.31s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1150/2000] tot_loss=1.297 (perp=6.098, rec=0.076, cos=0.001), tot_loss_proj:1.962 [t=0.29s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1200/2000] tot_loss=1.289 (perp=6.098, rec=0.068, cos=0.001), tot_loss_proj:1.958 [t=0.31s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1250/2000] tot_loss=1.291 (perp=6.098, rec=0.069, cos=0.001), tot_loss_proj:1.957 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1300/2000] tot_loss=1.284 (perp=6.098, rec=0.063, cos=0.001), tot_loss_proj:1.960 [t=0.31s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1350/2000] tot_loss=1.282 (perp=6.098, rec=0.061, cos=0.002), tot_loss_proj:1.961 [t=0.29s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1400/2000] tot_loss=1.294 (perp=6.098, rec=0.073, cos=0.001), tot_loss_proj:1.958 [t=0.29s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1450/2000] tot_loss=1.288 (perp=6.098, rec=0.067, cos=0.001), tot_loss_proj:1.957 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1500/2000] tot_loss=1.290 (perp=6.098, rec=0.069, cos=0.002), tot_loss_proj:1.957 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1550/2000] tot_loss=1.284 (perp=6.098, rec=0.063, cos=0.001), tot_loss_proj:1.956 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.287 (perp=6.098, rec=0.066, cos=0.001), tot_loss_proj:1.997 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1650/2000] tot_loss=1.286 (perp=6.098, rec=0.065, cos=0.002), tot_loss_proj:1.995 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.291 (perp=6.098, rec=0.070, cos=0.001), tot_loss_proj:1.957 [t=0.29s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1750/2000] tot_loss=1.288 (perp=6.098, rec=0.067, cos=0.001), tot_loss_proj:1.956 [t=0.29s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1800/2000] tot_loss=1.289 (perp=6.098, rec=0.067, cos=0.002), tot_loss_proj:1.956 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[1850/2000] tot_loss=1.283 (perp=6.098, rec=0.062, cos=0.001), tot_loss_proj:1.956 [t=0.31s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.299 (perp=6.098, rec=0.078, cos=0.002), tot_loss_proj:1.997 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
[1950/2000] tot_loss=1.301 (perp=6.098, rec=0.080, cos=0.002), tot_loss_proj:1.999 [t=0.31s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Attempt swap
[2000/2000] tot_loss=1.286 (perp=6.098, rec=0.064, cos=0.001), tot_loss_proj:1.994 [t=0.30s]
prediction: ['[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] young charisma has the screen of a woman who knows how char hold char [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 68.750 | p: 68.750 | r: 68.750
rougeLsum  | fm: 68.750 | p: 68.750 | r: 68.750
r1fm+r2fm = 127.500

[Aggregate metrics]:
rouge1     | fm: 92.902 | p: 92.313 | r: 93.592
rouge2     | fm: 62.031 | p: 61.875 | r: 62.274
rougeL     | fm: 80.263 | p: 79.818 | r: 80.770
rougeLsum  | fm: 80.392 | p: 79.912 | r: 80.929
r1fm+r2fm = 154.933

input #59 time: 0:11:46 | total time: 10:11:55


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
*********************************
*********************************
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9299472570419312 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9130843281745911 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8701856732368469 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8695709109306335 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8544469475746155 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.842263400554657 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8397374749183655 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 0.8392449617385864 for ['[CLS] majorityitudelby upsetouring plentyshaw constitution cover strung through / [SEP]']
[Init] best perm rec loss: 0.8391808867454529 for ['[CLS]itude coverouring majoritylbyshaw through / plenty upset strung constitution [SEP]']
[Init] best perm rec loss: 0.8388378024101257 for ['[CLS]lby / upsetouring constitutionshaw cover strung majorityitude through plenty [SEP]']
[Init] best perm rec loss: 0.838720440864563 for ['[CLS] throughlby / majority upset strungitude constitutionshaw plentyouring cover [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.621 (perp=11.741, rec=0.264, cos=0.009), tot_loss_proj:2.902 [t=0.28s]
prediction: ['[CLS] is awkwardly paced gossip - story awkwardly soap awkwardly film circuit awkwardly [SEP]']
[ 100/2000] tot_loss=2.530 (perp=11.785, rec=0.170, cos=0.004), tot_loss_proj:2.887 [t=0.29s]
prediction: ['[CLS] is awkwardly paced gossip opera is awkwardly soap awkwardly story circuit awkwardly [SEP]']
[ 150/2000] tot_loss=1.771 (perp=8.279, rec=0.112, cos=0.003), tot_loss_proj:2.430 [t=0.30s]
prediction: ['[CLS] is the paced soap opera is awkwardly soap bubble story circuit. [SEP]']
[ 200/2000] tot_loss=2.041 (perp=9.724, rec=0.094, cos=0.003), tot_loss_proj:2.437 [t=0.30s]
prediction: ['[CLS] is the pacedh opera - awkwardly soaph story circuit. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.967 (perp=9.327, rec=0.099, cos=0.003), tot_loss_proj:2.442 [t=0.30s]
prediction: ['[CLS] is the pacedh story - awkwardly soaph opera circuit. [SEP]']
[ 300/2000] tot_loss=2.137 (perp=10.242, rec=0.086, cos=0.002), tot_loss_proj:3.032 [t=0.30s]
prediction: ['[CLS] is the pacedh story - awkwardly soaph opera circuit - [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.831 (perp=8.712, rec=0.087, cos=0.002), tot_loss_proj:2.249 [t=0.30s]
prediction: ['[CLS] is the pacedh story - awkwardly soap operah circuit. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.791 (perp=8.504, rec=0.087, cos=0.003), tot_loss_proj:2.109 [t=0.29s]
prediction: ['[CLS] is the ish story - awkwardly soap opera paced circuit is [SEP]']
[ 450/2000] tot_loss=1.787 (perp=8.504, rec=0.083, cos=0.002), tot_loss_proj:2.111 [t=0.30s]
prediction: ['[CLS] is the ish story - awkwardly soap opera paced circuit is [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.707 (perp=8.201, rec=0.065, cos=0.002), tot_loss_proj:2.035 [t=0.29s]
prediction: ['[CLS] is the ish story - soap opera awkwardly paced circuit is [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.710 (perp=8.116, rec=0.085, cos=0.002), tot_loss_proj:2.001 [t=0.29s]
prediction: ['[CLS] is the ish story soap opera - awkwardly paced circuit is [SEP]']
[ 600/2000] tot_loss=1.699 (perp=8.116, rec=0.074, cos=0.002), tot_loss_proj:1.998 [t=0.29s]
prediction: ['[CLS] is the ish story soap opera - awkwardly paced circuit is [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.649 (perp=7.850, rec=0.077, cos=0.002), tot_loss_proj:1.976 [t=0.30s]
prediction: ['[CLS] is the ish soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.612 (perp=7.685, rec=0.072, cos=0.002), tot_loss_proj:2.017 [t=0.31s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[ 750/2000] tot_loss=1.608 (perp=7.685, rec=0.069, cos=0.002), tot_loss_proj:2.010 [t=0.30s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.608 (perp=7.685, rec=0.069, cos=0.002), tot_loss_proj:2.010 [t=0.29s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.605 (perp=7.685, rec=0.066, cos=0.002), tot_loss_proj:2.012 [t=0.28s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[ 900/2000] tot_loss=1.617 (perp=7.685, rec=0.078, cos=0.002), tot_loss_proj:2.009 [t=0.31s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.614 (perp=7.685, rec=0.074, cos=0.002), tot_loss_proj:2.004 [t=0.30s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.617 (perp=7.685, rec=0.078, cos=0.002), tot_loss_proj:2.012 [t=0.30s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.685, rec=0.073, cos=0.002), tot_loss_proj:2.008 [t=0.30s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.609 (perp=7.685, rec=0.070, cos=0.002), tot_loss_proj:2.014 [t=0.29s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.612 (perp=7.685, rec=0.073, cos=0.002), tot_loss_proj:2.011 [t=0.30s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1200/2000] tot_loss=1.611 (perp=7.685, rec=0.072, cos=0.002), tot_loss_proj:2.004 [t=0.29s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.617 (perp=7.685, rec=0.078, cos=0.002), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.611 (perp=7.685, rec=0.072, cos=0.002), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1350/2000] tot_loss=1.608 (perp=7.685, rec=0.069, cos=0.002), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.604 (perp=7.685, rec=0.065, cos=0.002), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.614 (perp=7.685, rec=0.075, cos=0.002), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1500/2000] tot_loss=1.614 (perp=7.685, rec=0.075, cos=0.002), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.613 (perp=7.685, rec=0.074, cos=0.002), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.606 (perp=7.685, rec=0.067, cos=0.002), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1650/2000] tot_loss=1.612 (perp=7.685, rec=0.073, cos=0.002), tot_loss_proj:2.018 [t=0.27s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.622 (perp=7.685, rec=0.083, cos=0.002), tot_loss_proj:2.004 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.607 (perp=7.685, rec=0.068, cos=0.002), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1800/2000] tot_loss=1.607 (perp=7.685, rec=0.068, cos=0.002), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.606 (perp=7.685, rec=0.067, cos=0.002), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.609 (perp=7.685, rec=0.070, cos=0.002), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
[1950/2000] tot_loss=1.609 (perp=7.685, rec=0.070, cos=0.002), tot_loss_proj:2.010 [t=0.28s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.602 (perp=7.685, rec=0.063, cos=0.002), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] ish is the soap opera story - awkwardly paced circuit is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 60.870 | p: 58.333 | r: 63.636
rougeLsum  | fm: 60.870 | p: 58.333 | r: 63.636
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 92.983 | p: 92.341 | r: 93.715
rouge2     | fm: 62.083 | p: 61.915 | r: 62.346
rougeL     | fm: 79.854 | p: 79.395 | r: 80.460
rougeLsum  | fm: 80.045 | p: 79.582 | r: 80.613
r1fm+r2fm = 155.066

input #60 time: 0:11:54 | total time: 10:23:49


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
*********************************
*********************************
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9795893430709839 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9741564989089966 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9512136578559875 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9470409154891968 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9432965517044067 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9347224831581116 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9169871807098389 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9168724417686462 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9121196269989014 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.9106317162513733 for ['[CLS] installed equipped unlike [SEP]']
[Init] best rec loss: 0.8808217644691467 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8280910849571228 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8269730806350708 for ['[CLS] lets mini request [SEP]']
[Init] best perm rec loss: 0.8244650959968567 for ['[CLS] mini request lets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.148 (perp=9.683, rec=0.200, cos=0.011), tot_loss_proj:2.381 [t=0.25s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.096 (perp=9.683, rec=0.151, cos=0.008), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 150/2000] tot_loss=2.075 (perp=9.683, rec=0.131, cos=0.007), tot_loss_proj:2.394 [t=0.26s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 200/2000] tot_loss=2.075 (perp=9.683, rec=0.132, cos=0.006), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.681 (perp=8.032, rec=0.073, cos=0.002), tot_loss_proj:1.700 [t=0.29s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 300/2000] tot_loss=1.667 (perp=8.032, rec=0.059, cos=0.001), tot_loss_proj:1.696 [t=0.25s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.489 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.481 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.617 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.499 (perp=7.101, rec=0.077, cos=0.001), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.625 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.628 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.494 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.620 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.625 [t=0.29s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.497 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.623 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.478 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.629 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.476 (perp=7.101, rec=0.054, cos=0.001), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.623 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.613 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.627 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.625 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.478 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.619 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.495 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.481 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.610 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.631 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.491 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.624 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.622 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.618 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.101, rec=0.072, cos=0.001), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.485 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.958 | p: 92.265 | r: 93.754
rouge2     | fm: 62.032 | p: 61.904 | r: 62.288
rougeL     | fm: 80.298 | p: 79.879 | r: 80.836
rougeLsum  | fm: 80.282 | p: 79.766 | r: 80.869
r1fm+r2fm = 154.990

input #61 time: 0:11:04 | total time: 10:34:54


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
*********************************
*********************************
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9540637731552124 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9288767576217651 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.927240788936615 for ['[CLS] gem longer congregationiq commemorate members police later pm drawing [MASK]ly onwards drops team senator access head wrath miss shane [SEP]']
[Init] best rec loss: 0.9213613867759705 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9167788624763489 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9164981842041016 for ['[CLS]nce followed mccarthy sioux by forum fight closely origins peckion humanitarian 2002 recalls reed spread tooth plain test girl間 [SEP]']
[Init] best perm rec loss: 0.914860188961029 for ['[CLS] girl by tooth forum followednce test reed sioux plain fight 2002 origins spread recalls closely humanitarian mccarthy間 peckion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.680 (perp=11.565, rec=0.355, cos=0.013), tot_loss_proj:4.166 [t=0.26s]
prediction: ['[CLS] / by congregation grace opera street best connor organizational a good miniseries hopecy avoided being single encodedable basis occasion [SEP]']
[ 100/2000] tot_loss=2.272 (perp=9.995, rec=0.265, cos=0.007), tot_loss_proj:3.808 [t=0.28s]
prediction: ['[CLS] / to for grace movies ) best grace prevention making good than hope grace prevention being war moviesly one usual [SEP]']
[ 150/2000] tot_loss=2.283 (perp=10.394, rec=0.200, cos=0.004), tot_loss_proj:3.704 [t=0.28s]
prediction: ['[CLS] / to to grace movies among best grace prevention making best than grace grace prevention the war moviesly one ever [SEP]']
[ 200/2000] tot_loss=2.376 (perp=11.042, rec=0.165, cos=0.003), tot_loss_proj:3.972 [t=0.25s]
prediction: ['[CLS] call to to grace movies among best grace prevention making one than grace grace prevention the war moviesly one ever [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.112 (perp=9.832, rec=0.143, cos=0.002), tot_loss_proj:3.770 [t=0.29s]
prediction: ['[CLS] call to to grace movies the best grace prevention making one than grace call rather among war movies suddenly one ever [SEP]']
[ 300/2000] tot_loss=2.033 (perp=9.547, rec=0.121, cos=0.002), tot_loss_proj:3.843 [t=0.28s]
prediction: ['[CLS] call to call grace movies to best grace prevention making one its grace call rather of war movies suddenly one ever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.987 (perp=9.340, rec=0.116, cos=0.002), tot_loss_proj:3.839 [t=0.28s]
prediction: ['[CLS] call to call grace movies for best grace prevention making it one grace place rather of war movies suddenly one ever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.980 (perp=9.370, rec=0.104, cos=0.002), tot_loss_proj:3.834 [t=0.28s]
prediction: ['[CLS] call to call grace movies for best grace prevention making it one grace place rather suddenly of war made one ever [SEP]']
[ 450/2000] tot_loss=2.064 (perp=9.816, rec=0.099, cos=0.002), tot_loss_proj:3.913 [t=0.29s]
prediction: ['[CLS] call to call grace movies for best grace prevention making it one grace place rather blame the war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.953 (perp=9.340, rec=0.083, cos=0.002), tot_loss_proj:3.822 [t=0.28s]
prediction: ['[CLS] call to call grace movies for best grace prevention making it one grace call rather blame the war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.911 (perp=9.074, rec=0.094, cos=0.002), tot_loss_proj:3.581 [t=0.28s]
prediction: ['[CLS] the to call blame movies for best grace prevention making it one look call rather blame call war made one ever [SEP]']
[ 600/2000] tot_loss=1.979 (perp=9.436, rec=0.090, cos=0.002), tot_loss_proj:3.635 [t=0.29s]
prediction: ['[CLS] the to call blame movies for best grace prevention making it one look call rather blame place war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.915 (perp=9.149, rec=0.084, cos=0.002), tot_loss_proj:3.552 [t=0.28s]
prediction: ['[CLS] the to call blame movies for best grace prevention making it one place call rather blame look war made one ever [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.924 (perp=9.174, rec=0.087, cos=0.002), tot_loss_proj:3.649 [t=0.28s]
prediction: ['[CLS] the to call blame movies for best grace prevention making it place call rather one blame yet war made one ever [SEP]']
[ 750/2000] tot_loss=1.918 (perp=9.174, rec=0.082, cos=0.002), tot_loss_proj:3.651 [t=0.28s]
prediction: ['[CLS] the to call blame movies for best grace prevention making it place call rather one blame yet war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.890 (perp=8.982, rec=0.092, cos=0.002), tot_loss_proj:3.496 [t=0.28s]
prediction: ['[CLS] the to make blame movies for best grace prevention making it place yet rather one blame call war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.846 (perp=8.805, rec=0.083, cos=0.002), tot_loss_proj:3.656 [t=0.27s]
prediction: ['[CLS] the to make grace movies for best blame prevention making it place yet rather one blame call war made one ever [SEP]']
[ 900/2000] tot_loss=1.843 (perp=8.805, rec=0.080, cos=0.002), tot_loss_proj:3.657 [t=0.27s]
prediction: ['[CLS] the to make grace movies for best blame prevention making it place yet rather one blame call war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.731 (perp=8.244, rec=0.080, cos=0.002), tot_loss_proj:3.588 [t=0.29s]
prediction: ['[CLS] " to make grace movies for best blame prevention making it to the rather one blame call war made one ever [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.746 (perp=8.292, rec=0.086, cos=0.002), tot_loss_proj:3.572 [t=0.28s]
prediction: ['[CLS] " to making grace movies for best the prevention making it to blame rather one blame call war made one ever [SEP]']
[1050/2000] tot_loss=1.740 (perp=8.292, rec=0.080, cos=0.002), tot_loss_proj:3.568 [t=0.27s]
prediction: ['[CLS] " to making grace movies for best the prevention making it to blame rather one blame call war made one ever [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.711 (perp=8.104, rec=0.089, cos=0.002), tot_loss_proj:3.514 [t=0.27s]
prediction: ['[CLS] " to making grace movies for best prevention the making it to blame rather one blame call war made one ever [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.680 (perp=7.989, rec=0.081, cos=0.002), tot_loss_proj:3.508 [t=0.26s]
prediction: ['[CLS] " to making movies grace for best prevention the making it to blame rather one blame call war made one ever [SEP]']
[1200/2000] tot_loss=1.814 (perp=8.680, rec=0.076, cos=0.002), tot_loss_proj:3.604 [t=0.26s]
prediction: ['[CLS] yet to making movies grace for best prevention the, it to blame rather one blame call war made one ever [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.760 (perp=8.407, rec=0.077, cos=0.002), tot_loss_proj:3.475 [t=0.28s]
prediction: ['[CLS] one to grace movies making for best prevention the, it to blame rather one blame call war made one ever [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.715 (perp=8.129, rec=0.087, cos=0.002), tot_loss_proj:3.548 [t=0.26s]
prediction: ['[CLS] " to grace movies making for best prevention blame, it to blame rather one the call war made one ever [SEP]']
[1350/2000] tot_loss=1.660 (perp=7.897, rec=0.079, cos=0.002), tot_loss_proj:3.402 [t=0.25s]
prediction: ['[CLS] one to grace movies making for best prevention blame, it to blame rather one the call war made one ever [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.612 (perp=7.714, rec=0.068, cos=0.002), tot_loss_proj:3.435 [t=0.25s]
prediction: ['[CLS] making to grace movies one for best prevention blame, it to blame rather one the call war made one ever [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.560 (perp=7.405, rec=0.077, cos=0.002), tot_loss_proj:3.405 [t=0.27s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
[1500/2000] tot_loss=1.558 (perp=7.405, rec=0.076, cos=0.002), tot_loss_proj:3.405 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.555 (perp=7.405, rec=0.073, cos=0.002), tot_loss_proj:3.406 [t=0.28s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.557 (perp=7.405, rec=0.074, cos=0.002), tot_loss_proj:3.406 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
[1650/2000] tot_loss=1.565 (perp=7.405, rec=0.083, cos=0.002), tot_loss_proj:3.402 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.562 (perp=7.405, rec=0.079, cos=0.002), tot_loss_proj:3.404 [t=0.27s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.558 (perp=7.405, rec=0.075, cos=0.002), tot_loss_proj:3.404 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
[1800/2000] tot_loss=1.558 (perp=7.405, rec=0.075, cos=0.002), tot_loss_proj:3.401 [t=0.29s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.561 (perp=7.405, rec=0.079, cos=0.002), tot_loss_proj:3.400 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.558 (perp=7.405, rec=0.076, cos=0.002), tot_loss_proj:3.403 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
[1950/2000] tot_loss=1.558 (perp=7.405, rec=0.075, cos=0.002), tot_loss_proj:3.399 [t=0.27s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.562 (perp=7.405, rec=0.079, cos=0.002), tot_loss_proj:3.402 [t=0.26s]
prediction: ['[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] making to grace movies one for best prevention, blame it to blame rather one the call war made one ever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.364 | p: 86.364 | r: 86.364
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 86.364

[Aggregate metrics]:
rouge1     | fm: 92.882 | p: 92.218 | r: 93.677
rouge2     | fm: 61.312 | p: 61.159 | r: 61.614
rougeL     | fm: 79.825 | p: 79.395 | r: 80.374
rougeLsum  | fm: 79.922 | p: 79.485 | r: 80.463
r1fm+r2fm = 154.193

input #62 time: 0:11:18 | total time: 10:46:12


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
*********************************
*********************************
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9565043449401855 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9048953652381897 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7484632730484009 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7433376908302307 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.739037811756134 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7285273671150208 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7276551127433777 for ['[CLS] solutions forces offense... civil [SEP]']
[Init] best perm rec loss: 0.7259407639503479 for ['[CLS] solutions civil forces... offense [SEP]']
[Init] best perm rec loss: 0.7244595885276794 for ['[CLS] forces... offense solutions civil [SEP]']
[Init] best perm rec loss: 0.7240341901779175 for ['[CLS] forces solutions... civil offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.525 (perp=10.331, rec=0.376, cos=0.083), tot_loss_proj:3.264 [t=0.30s]
prediction: ['[CLS] limited rejected off ticket ticket [SEP]']
[ 100/2000] tot_loss=2.212 (perp=10.156, rec=0.171, cos=0.010), tot_loss_proj:3.101 [t=0.30s]
prediction: ['[CLS] return looking off ticket ticket [SEP]']
[ 150/2000] tot_loss=1.831 (perp=8.565, rec=0.113, cos=0.005), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS] return looking for ticket return [SEP]']
[ 200/2000] tot_loss=1.804 (perp=8.565, rec=0.087, cos=0.004), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.798 (perp=8.565, rec=0.081, cos=0.004), tot_loss_proj:2.643 [t=0.26s]
prediction: ['[CLS] return looking for ticket return [SEP]']
[ 300/2000] tot_loss=1.795 (perp=8.565, rec=0.079, cos=0.004), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.792 (perp=8.565, rec=0.075, cos=0.004), tot_loss_proj:2.648 [t=0.25s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.795 (perp=8.565, rec=0.079, cos=0.004), tot_loss_proj:2.646 [t=0.24s]
prediction: ['[CLS] return looking for ticket return [SEP]']
[ 450/2000] tot_loss=1.796 (perp=8.565, rec=0.079, cos=0.004), tot_loss_proj:2.654 [t=0.27s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.806 (perp=8.687, rec=0.065, cos=0.003), tot_loss_proj:2.416 [t=0.25s]
prediction: ['[CLS] a looking for ticket return [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.256 (perp=5.941, rec=0.064, cos=0.004), tot_loss_proj:1.465 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 600/2000] tot_loss=1.267 (perp=5.941, rec=0.075, cos=0.003), tot_loss_proj:1.458 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.260 (perp=5.941, rec=0.069, cos=0.003), tot_loss_proj:1.464 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.264 (perp=5.941, rec=0.073, cos=0.003), tot_loss_proj:1.460 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 750/2000] tot_loss=1.262 (perp=5.941, rec=0.071, cos=0.003), tot_loss_proj:1.460 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.269 (perp=5.941, rec=0.078, cos=0.003), tot_loss_proj:1.461 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.258 (perp=5.941, rec=0.067, cos=0.002), tot_loss_proj:1.468 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 900/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.002), tot_loss_proj:1.462 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.259 (perp=5.941, rec=0.069, cos=0.002), tot_loss_proj:1.468 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.260 (perp=5.941, rec=0.071, cos=0.002), tot_loss_proj:1.461 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1050/2000] tot_loss=1.256 (perp=5.941, rec=0.067, cos=0.002), tot_loss_proj:1.476 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.259 (perp=5.941, rec=0.070, cos=0.002), tot_loss_proj:1.472 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.257 (perp=5.941, rec=0.068, cos=0.001), tot_loss_proj:1.463 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1200/2000] tot_loss=1.259 (perp=5.941, rec=0.069, cos=0.001), tot_loss_proj:1.473 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.259 (perp=5.941, rec=0.069, cos=0.001), tot_loss_proj:1.469 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.259 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.458 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1350/2000] tot_loss=1.244 (perp=5.941, rec=0.054, cos=0.001), tot_loss_proj:1.456 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.251 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.471 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.254 (perp=5.941, rec=0.064, cos=0.001), tot_loss_proj:1.469 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1500/2000] tot_loss=1.247 (perp=5.941, rec=0.057, cos=0.001), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.264 (perp=5.941, rec=0.075, cos=0.001), tot_loss_proj:1.460 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.261 (perp=5.941, rec=0.071, cos=0.001), tot_loss_proj:1.456 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1650/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.466 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.463 [t=0.28s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.466 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1800/2000] tot_loss=1.250 (perp=5.941, rec=0.060, cos=0.001), tot_loss_proj:1.469 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.251 (perp=5.941, rec=0.062, cos=0.001), tot_loss_proj:1.469 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.254 (perp=5.941, rec=0.064, cos=0.001), tot_loss_proj:1.462 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1950/2000] tot_loss=1.264 (perp=5.941, rec=0.074, cos=0.001), tot_loss_proj:1.459 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.247 (perp=5.941, rec=0.058, cos=0.001), tot_loss_proj:1.465 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a ticket return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 93.089 | p: 92.400 | r: 93.783
rouge2     | fm: 61.117 | p: 60.938 | r: 61.359
rougeL     | fm: 79.898 | p: 79.462 | r: 80.390
rougeLsum  | fm: 79.902 | p: 79.446 | r: 80.458
r1fm+r2fm = 154.206

input #63 time: 0:11:12 | total time: 10:57:25


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
*********************************
*********************************
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8796932697296143 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8693087697029114 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.728920042514801 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.675671398639679 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6740126609802246 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6711879372596741 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.966 (perp=8.653, rec=0.200, cos=0.036), tot_loss_proj:2.062 [t=0.27s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.900 (perp=8.653, rec=0.150, cos=0.019), tot_loss_proj:2.050 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.904 (perp=8.653, rec=0.145, cos=0.029), tot_loss_proj:2.051 [t=0.25s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=2.077 (perp=9.634, rec=0.135, cos=0.016), tot_loss_proj:2.558 [t=0.26s]
prediction: ['[CLS] strange horror strange [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.976 (perp=9.190, rec=0.127, cos=0.012), tot_loss_proj:2.202 [t=0.26s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.684 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.702 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.672 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.713 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.714 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.704 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.706 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.696 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.717 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.716 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.716 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.711 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.715 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.704 [t=0.31s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.713 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.673 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.710 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.716 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.709 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.718 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.675 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.702 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.688 (perp=8.065, rec=0.073, cos=0.002), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.680 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.191 | p: 92.474 | r: 93.929
rouge2     | fm: 61.815 | p: 61.620 | r: 62.027
rougeL     | fm: 80.225 | p: 79.815 | r: 80.752
rougeLsum  | fm: 80.371 | p: 79.858 | r: 80.840
r1fm+r2fm = 155.006

input #64 time: 0:11:21 | total time: 11:08:46


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
*********************************
*********************************
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.0258606672286987 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9586822390556335 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9518215656280518 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9477682113647461 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8876939415931702 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8789583444595337 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8788501620292664 for ['[CLS] evenhoff overs pu newsmament general fun someday [SEP]']
[Init] best perm rec loss: 0.875924289226532 for ['[CLS]hoff someday general even pumament news fun overs [SEP]']
[Init] best perm rec loss: 0.8755142688751221 for ['[CLS] general news evenmament puhoff overs fun someday [SEP]']
[Init] best perm rec loss: 0.8745706081390381 for ['[CLS] even general news pumament somedayhoff fun overs [SEP]']
[Init] best perm rec loss: 0.8732827305793762 for ['[CLS] somedaymamenthoff general overs pu news even fun [SEP]']
[Init] best perm rec loss: 0.8718383312225342 for ['[CLS]mament news general even pu overs fun somedayhoff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.120 (perp=9.064, rec=0.299, cos=0.009), tot_loss_proj:2.338 [t=0.27s]
prediction: ['[CLS] joyous joy look. florida joy - joy [SEP]']
[ 100/2000] tot_loss=1.807 (perp=8.124, rec=0.178, cos=0.004), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] joyous joyous, film of - joy [SEP]']
[ 150/2000] tot_loss=2.505 (perp=11.837, rec=0.135, cos=0.002), tot_loss_proj:3.059 [t=0.25s]
prediction: ['[CLS] romousousous, film of. joy [SEP]']
[ 200/2000] tot_loss=2.468 (perp=11.837, rec=0.099, cos=0.002), tot_loss_proj:3.062 [t=0.26s]
prediction: ['[CLS] romousousous, film of. joy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.825 (perp=8.700, rec=0.082, cos=0.002), tot_loss_proj:2.339 [t=0.26s]
prediction: ['[CLS] rompousous, film of joy. [SEP]']
[ 300/2000] tot_loss=1.819 (perp=8.700, rec=0.077, cos=0.002), tot_loss_proj:2.342 [t=0.26s]
prediction: ['[CLS] rompousous, film of joy. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.770 (perp=7.878, rec=0.190, cos=0.004), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] rompous, film of joyous. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.649 (perp=7.591, rec=0.129, cos=0.002), tot_loss_proj:2.127 [t=0.29s]
prediction: ['[CLS] romp of, film of joyous. [SEP]']
[ 450/2000] tot_loss=1.642 (perp=7.591, rec=0.122, cos=0.002), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] romp of, film of joyous. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.443 (perp=6.603, rec=0.120, cos=0.002), tot_loss_proj:1.924 [t=0.26s]
prediction: ['[CLS] of romp, film of joyous. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.322 (perp=6.104, rec=0.100, cos=0.002), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
[ 600/2000] tot_loss=1.319 (perp=6.104, rec=0.096, cos=0.002), tot_loss_proj:1.676 [t=0.28s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.306 (perp=6.104, rec=0.084, cos=0.002), tot_loss_proj:1.671 [t=0.27s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.319 (perp=6.104, rec=0.096, cos=0.002), tot_loss_proj:1.681 [t=0.29s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
[ 750/2000] tot_loss=1.306 (perp=6.104, rec=0.083, cos=0.002), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.320 (perp=6.104, rec=0.098, cos=0.002), tot_loss_proj:1.682 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.321 (perp=6.104, rec=0.098, cos=0.002), tot_loss_proj:1.672 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
[ 900/2000] tot_loss=1.318 (perp=6.104, rec=0.096, cos=0.002), tot_loss_proj:1.681 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.311 (perp=6.104, rec=0.089, cos=0.002), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.304 (perp=6.104, rec=0.081, cos=0.002), tot_loss_proj:1.678 [t=0.31s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
[1050/2000] tot_loss=1.312 (perp=6.104, rec=0.090, cos=0.002), tot_loss_proj:1.683 [t=0.29s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.315 (perp=6.104, rec=0.093, cos=0.002), tot_loss_proj:1.676 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.300 (perp=6.104, rec=0.077, cos=0.002), tot_loss_proj:1.675 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
[1200/2000] tot_loss=1.299 (perp=6.104, rec=0.076, cos=0.002), tot_loss_proj:1.673 [t=0.31s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.304 (perp=6.104, rec=0.081, cos=0.002), tot_loss_proj:1.674 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.307 (perp=6.104, rec=0.084, cos=0.002), tot_loss_proj:1.682 [t=0.30s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
[1350/2000] tot_loss=1.304 (perp=6.104, rec=0.082, cos=0.002), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] of romp of film, joyous. [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.184 (perp=5.505, rec=0.081, cos=0.002), tot_loss_proj:1.611 [t=0.29s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.179 (perp=5.505, rec=0.076, cos=0.002), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
[1500/2000] tot_loss=1.186 (perp=5.505, rec=0.083, cos=0.002), tot_loss_proj:1.605 [t=0.29s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.178 (perp=5.505, rec=0.076, cos=0.002), tot_loss_proj:1.614 [t=0.30s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.186 (perp=5.505, rec=0.083, cos=0.002), tot_loss_proj:1.601 [t=0.30s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
[1650/2000] tot_loss=1.190 (perp=5.505, rec=0.087, cos=0.002), tot_loss_proj:1.613 [t=0.30s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.171 (perp=5.505, rec=0.068, cos=0.002), tot_loss_proj:1.607 [t=0.29s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.171 (perp=5.505, rec=0.068, cos=0.002), tot_loss_proj:1.611 [t=0.28s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
[1800/2000] tot_loss=1.180 (perp=5.505, rec=0.077, cos=0.002), tot_loss_proj:1.610 [t=0.30s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.188 (perp=5.505, rec=0.086, cos=0.002), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.181 (perp=5.505, rec=0.079, cos=0.002), tot_loss_proj:1.605 [t=0.29s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
[1950/2000] tot_loss=1.180 (perp=5.505, rec=0.077, cos=0.002), tot_loss_proj:1.611 [t=0.31s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.172 (perp=5.505, rec=0.069, cos=0.002), tot_loss_proj:1.611 [t=0.29s]
prediction: ['[CLS] of romp, joyous of film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] of romp, joyous of film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 93.051 | p: 92.445 | r: 93.757
rouge2     | fm: 60.991 | p: 60.797 | r: 61.237
rougeL     | fm: 80.073 | p: 79.649 | r: 80.594
rougeLsum  | fm: 80.176 | p: 79.736 | r: 80.729
r1fm+r2fm = 154.042

input #65 time: 0:11:43 | total time: 11:20:30


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
*********************************
*********************************
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.973792552947998 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9307570457458496 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9160336256027222 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8862890601158142 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8742782473564148 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.8719822764396667 for ['[CLS]beersa two bryce [SEP]']
[Init] best perm rec loss: 0.8696925640106201 for ['[CLS]rsa two brycebee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.867 (perp=8.308, rec=0.196, cos=0.009), tot_loss_proj:1.952 [t=0.29s]
prediction: ['[CLS] longtime professional tolkien fan [SEP]']
[ 100/2000] tot_loss=1.608 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.602 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 150/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.593 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 200/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.601 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.588 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.586 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.601 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.606 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.599 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.593 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.597 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.591 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.593 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.609 (perp=7.673, rec=0.073, cos=0.002), tot_loss_proj:1.605 [t=0.33s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.002), tot_loss_proj:1.605 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.588 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.596 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.599 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.600 [t=0.30s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.598 [t=0.29s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.607 [t=0.32s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.673, rec=0.076, cos=0.002), tot_loss_proj:1.598 [t=0.31s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.607 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.586 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.585 (perp=7.673, rec=0.049, cos=0.002), tot_loss_proj:1.596 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.588 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.595 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.603 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.603 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.604 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.605 (perp=7.673, rec=0.069, cos=0.002), tot_loss_proj:1.604 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.588 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.601 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.591 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.588 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.605 (perp=7.673, rec=0.069, cos=0.002), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.605 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.594 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.609 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.599 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.186 | p: 92.552 | r: 93.933
rouge2     | fm: 61.651 | p: 61.474 | r: 61.880
rougeL     | fm: 80.398 | p: 79.942 | r: 80.927
rougeLsum  | fm: 80.384 | p: 79.970 | r: 80.929
r1fm+r2fm = 154.837

input #66 time: 0:11:32 | total time: 11:32:02


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
*********************************
*********************************
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005807638168335 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9567444324493408 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9554714560508728 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9473316669464111 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9436708688735962 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9336733222007751 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9325234889984131 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.9268360137939453 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.9241943955421448 for ['[CLS] ） cone home mural courtney promotion upon enough wild tribes [SEP]']
[Init] best perm rec loss: 0.9226720929145813 for ['[CLS] promotion tribes home cone enough ） wild courtney upon mural [SEP]']
[Init] best perm rec loss: 0.9221352934837341 for ['[CLS] upon home tribes courtney cone mural ） wild promotion enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.259 (perp=14.631, rec=0.322, cos=0.011), tot_loss_proj:4.274 [t=0.27s]
prediction: ['[CLS]rdialwar celestial 2018 altitude absorbed ; energygoing kind [SEP]']
[ 100/2000] tot_loss=2.700 (perp=12.548, rec=0.186, cos=0.004), tot_loss_proj:4.011 [t=0.26s]
prediction: ['[CLS] nonwar angelental heart non,mingental kind [SEP]']
[ 150/2000] tot_loss=2.701 (perp=12.609, rec=0.176, cos=0.003), tot_loss_proj:3.768 [t=0.25s]
prediction: ['[CLS] nonwar creatureental heart heart,mingental kind [SEP]']
[ 200/2000] tot_loss=2.476 (perp=11.766, rec=0.121, cos=0.002), tot_loss_proj:3.401 [t=0.27s]
prediction: ['[CLS] nonwargmental heart heart,mingental kind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.283 (perp=10.874, rec=0.106, cos=0.002), tot_loss_proj:3.055 [t=0.26s]
prediction: ['[CLS] nonwargmental, heart heartmingental kind [SEP]']
[ 300/2000] tot_loss=2.271 (perp=10.874, rec=0.094, cos=0.002), tot_loss_proj:3.052 [t=0.25s]
prediction: ['[CLS] nonwargmental, heart heartmingental kind [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.053 (perp=9.798, rec=0.091, cos=0.002), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] nonwargmental, heartental heartming kind [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.198 (perp=10.433, rec=0.110, cos=0.002), tot_loss_proj:3.570 [t=0.26s]
prediction: ['[CLS] nonwarminggmental,mingental heart kind [SEP]']
[ 450/2000] tot_loss=2.181 (perp=10.433, rec=0.093, cos=0.002), tot_loss_proj:3.572 [t=0.26s]
prediction: ['[CLS] nonwarminggmental,mingental heart kind [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.176 (perp=10.214, rec=0.131, cos=0.002), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] nonwarminggmental,ental heart heart kind [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.800 (perp=8.425, rec=0.113, cos=0.002), tot_loss_proj:2.774 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[ 600/2000] tot_loss=1.792 (perp=8.425, rec=0.106, cos=0.002), tot_loss_proj:2.773 [t=0.28s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.781 (perp=8.425, rec=0.094, cos=0.002), tot_loss_proj:2.780 [t=0.28s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.775 (perp=8.425, rec=0.088, cos=0.002), tot_loss_proj:2.786 [t=0.25s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[ 750/2000] tot_loss=1.765 (perp=8.425, rec=0.078, cos=0.002), tot_loss_proj:2.783 [t=0.25s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.782 (perp=8.425, rec=0.095, cos=0.002), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.764 (perp=8.425, rec=0.077, cos=0.002), tot_loss_proj:2.781 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[ 900/2000] tot_loss=1.776 (perp=8.425, rec=0.089, cos=0.002), tot_loss_proj:2.784 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.770 (perp=8.425, rec=0.083, cos=0.002), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.766 (perp=8.425, rec=0.079, cos=0.002), tot_loss_proj:2.781 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[1050/2000] tot_loss=1.760 (perp=8.425, rec=0.073, cos=0.002), tot_loss_proj:2.788 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.760 (perp=8.425, rec=0.073, cos=0.002), tot_loss_proj:2.788 [t=0.28s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.766 (perp=8.425, rec=0.079, cos=0.002), tot_loss_proj:2.791 [t=0.25s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[1200/2000] tot_loss=1.763 (perp=8.425, rec=0.077, cos=0.002), tot_loss_proj:2.785 [t=0.29s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.769 (perp=8.425, rec=0.082, cos=0.002), tot_loss_proj:2.792 [t=0.25s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1300/2000] tot_loss=1.769 (perp=8.425, rec=0.082, cos=0.002), tot_loss_proj:2.786 [t=0.27s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[1350/2000] tot_loss=1.772 (perp=8.425, rec=0.086, cos=0.002), tot_loss_proj:2.790 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.425, rec=0.072, cos=0.002), tot_loss_proj:2.791 [t=0.25s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.767 (perp=8.425, rec=0.080, cos=0.002), tot_loss_proj:2.788 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[1500/2000] tot_loss=1.759 (perp=8.425, rec=0.072, cos=0.002), tot_loss_proj:2.791 [t=0.26s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.753 (perp=8.425, rec=0.066, cos=0.002), tot_loss_proj:2.795 [t=0.25s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=8.425, rec=0.081, cos=0.002), tot_loss_proj:2.796 [t=0.28s]
prediction: ['[CLS] heartwarminggmental,ental heart non kind [SEP]']
[1650/2000] tot_loss=2.010 (perp=9.690, rec=0.071, cos=0.002), tot_loss_proj:3.189 [t=0.25s]
prediction: ['[CLS] heartwarminggmd,ental heart non kind [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.859 (perp=8.875, rec=0.082, cos=0.002), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS] heartwarmingental,gmental heart non kind [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.704 (perp=8.077, rec=0.087, cos=0.002), tot_loss_proj:2.589 [t=0.25s]
prediction: ['[CLS] heartwarming,gmental heartental non kind [SEP]']
[1800/2000] tot_loss=1.695 (perp=8.077, rec=0.078, cos=0.002), tot_loss_proj:2.581 [t=0.25s]
prediction: ['[CLS] heartwarming,gmental heartental non kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.702 (perp=8.077, rec=0.085, cos=0.002), tot_loss_proj:2.587 [t=0.25s]
prediction: ['[CLS] heartwarming,gmental heartental non kind [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.565 (perp=7.346, rec=0.094, cos=0.002), tot_loss_proj:1.713 [t=0.29s]
prediction: ['[CLS] heartwarming, heartental nongmental kind [SEP]']
[1950/2000] tot_loss=1.553 (perp=7.346, rec=0.083, cos=0.002), tot_loss_proj:1.706 [t=0.28s]
prediction: ['[CLS] heartwarming, heartental nongmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.555 (perp=7.346, rec=0.085, cos=0.002), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] heartwarming, heartental nongmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarminggmental,ental heart non kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 42.857 | r: 60.000
rouge2     | fm: 20.000 | p: 16.667 | r: 25.000
rougeL     | fm: 50.000 | p: 42.857 | r: 60.000
rougeLsum  | fm: 50.000 | p: 42.857 | r: 60.000
r1fm+r2fm = 70.000

[Aggregate metrics]:
rouge1     | fm: 92.541 | p: 91.836 | r: 93.364
rouge2     | fm: 61.177 | p: 60.874 | r: 61.406
rougeL     | fm: 79.913 | p: 79.427 | r: 80.556
rougeLsum  | fm: 80.071 | p: 79.543 | r: 80.683
r1fm+r2fm = 153.718

input #67 time: 0:11:06 | total time: 11:43:09


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
*********************************
*********************************
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.989619255065918 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9645585417747498 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9424722194671631 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9253563284873962 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8706526756286621 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8648829460144043 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8608188629150391 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8541148900985718 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8531020283699036 for ['[CLS]iferous comfortyn form medal died floor. beth possibly riding view councils [SEP]']
[Init] best perm rec loss: 0.8519254326820374 for ['[CLS] possibly councils comfortiferousyn floor died form view beth. medal riding [SEP]']
[Init] best perm rec loss: 0.8488271236419678 for ['[CLS]iferous flooryn form possibly medal riding view beth councils. died comfort [SEP]']
[Init] best perm rec loss: 0.8450530767440796 for ['[CLS] beth comfortyn died form riding councils possibly medal floor. viewiferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.288 (perp=10.528, rec=0.176, cos=0.006), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] east iansible,iblecho absurd, absurd vicious and absurd un [SEP]']
[ 100/2000] tot_loss=1.634 (perp=7.620, rec=0.107, cos=0.003), tot_loss_proj:1.854 [t=0.28s]
prediction: ['[CLS] uncouth,siblecouth, absurd vicious and absurd un [SEP]']
[ 150/2000] tot_loss=1.722 (perp=8.194, rec=0.082, cos=0.002), tot_loss_proj:2.011 [t=0.28s]
prediction: ['[CLS] uncouth,sibleomputh, absurd vicious and absurd un [SEP]']
[ 200/2000] tot_loss=1.938 (perp=9.269, rec=0.083, cos=0.002), tot_loss_proj:2.295 [t=0.28s]
prediction: ['[CLS]ompcouth,sibleomputh, absurd vicious and absurd un [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.939 (perp=9.334, rec=0.071, cos=0.002), tot_loss_proj:2.219 [t=0.27s]
prediction: ['[CLS] uncouth,siblehenre, absurd vicious and absurdomp [SEP]']
[ 300/2000] tot_loss=1.944 (perp=9.334, rec=0.075, cos=0.002), tot_loss_proj:2.216 [t=0.26s]
prediction: ['[CLS] uncouth,siblehenre, absurd vicious and absurdomp [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.825 (perp=8.737, rec=0.076, cos=0.002), tot_loss_proj:2.101 [t=0.29s]
prediction: ['[CLS] uncouth,hensiblere, inc vicious and absurdomp [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.541 (perp=7.318, rec=0.075, cos=0.002), tot_loss_proj:1.750 [t=0.27s]
prediction: ['[CLS] uncouth,omphensiblere, inc vicious and absurd [SEP]']
[ 450/2000] tot_loss=1.535 (perp=7.318, rec=0.070, cos=0.002), tot_loss_proj:1.753 [t=0.26s]
prediction: ['[CLS] uncouth,omphensiblere, inc vicious and absurd [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.419 (perp=6.731, rec=0.071, cos=0.002), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] uncouth, incomphensiblere, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.269 (perp=6.014, rec=0.065, cos=0.002), tot_loss_proj:1.368 [t=0.27s]
prediction: ['[CLS] uncouth, increhensibleomp, vicious and absurd [SEP]']
[ 600/2000] tot_loss=1.267 (perp=6.014, rec=0.063, cos=0.001), tot_loss_proj:1.355 [t=0.26s]
prediction: ['[CLS] uncouth, increhensibleomp, vicious and absurd [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.266 (perp=6.014, rec=0.062, cos=0.001), tot_loss_proj:1.350 [t=0.27s]
prediction: ['[CLS] uncouth, increhensibleomp, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=0.973 (perp=4.494, rec=0.072, cos=0.002), tot_loss_proj:0.969 [t=0.28s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[ 750/2000] tot_loss=0.963 (perp=4.494, rec=0.062, cos=0.001), tot_loss_proj:0.970 [t=0.27s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.968 (perp=4.494, rec=0.067, cos=0.001), tot_loss_proj:0.969 [t=0.27s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=0.959 (perp=4.494, rec=0.059, cos=0.001), tot_loss_proj:0.969 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[ 900/2000] tot_loss=0.970 (perp=4.494, rec=0.070, cos=0.001), tot_loss_proj:0.970 [t=0.27s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.958 (perp=4.494, rec=0.057, cos=0.001), tot_loss_proj:0.965 [t=0.30s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=0.957 (perp=4.494, rec=0.056, cos=0.001), tot_loss_proj:0.955 [t=0.30s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1050/2000] tot_loss=0.968 (perp=4.494, rec=0.067, cos=0.001), tot_loss_proj:0.960 [t=0.32s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=0.975 (perp=4.494, rec=0.075, cos=0.001), tot_loss_proj:0.969 [t=0.32s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1150/2000] tot_loss=0.959 (perp=4.494, rec=0.059, cos=0.001), tot_loss_proj:0.964 [t=0.27s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1200/2000] tot_loss=0.959 (perp=4.494, rec=0.058, cos=0.001), tot_loss_proj:0.973 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=0.963 (perp=4.494, rec=0.063, cos=0.001), tot_loss_proj:0.972 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=0.957 (perp=4.494, rec=0.057, cos=0.001), tot_loss_proj:0.971 [t=0.29s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1350/2000] tot_loss=0.963 (perp=4.494, rec=0.063, cos=0.001), tot_loss_proj:0.966 [t=0.29s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=0.966 (perp=4.494, rec=0.066, cos=0.001), tot_loss_proj:0.961 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=0.959 (perp=4.494, rec=0.059, cos=0.001), tot_loss_proj:0.968 [t=0.28s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1500/2000] tot_loss=0.962 (perp=4.494, rec=0.062, cos=0.001), tot_loss_proj:0.964 [t=0.25s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=0.957 (perp=4.494, rec=0.057, cos=0.001), tot_loss_proj:0.962 [t=0.28s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=0.960 (perp=4.494, rec=0.060, cos=0.001), tot_loss_proj:0.957 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1650/2000] tot_loss=0.953 (perp=4.494, rec=0.053, cos=0.001), tot_loss_proj:0.960 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=0.968 (perp=4.494, rec=0.068, cos=0.001), tot_loss_proj:0.968 [t=0.27s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=0.955 (perp=4.494, rec=0.055, cos=0.001), tot_loss_proj:0.962 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1800/2000] tot_loss=0.963 (perp=4.494, rec=0.062, cos=0.001), tot_loss_proj:0.964 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=0.963 (perp=4.494, rec=0.063, cos=0.001), tot_loss_proj:0.969 [t=0.26s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=0.915 (perp=4.196, rec=0.073, cos=0.002), tot_loss_proj:0.969 [t=0.27s]
prediction: ['[CLS] uncouth, vicious, incomprehensible and absurd [SEP]']
[1950/2000] tot_loss=0.912 (perp=4.196, rec=0.071, cos=0.002), tot_loss_proj:0.964 [t=0.29s]
prediction: ['[CLS] uncouth, vicious, incomprehensible and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=0.910 (perp=4.196, rec=0.069, cos=0.002), tot_loss_proj:0.965 [t=0.26s]
prediction: ['[CLS] uncouth, vicious, incomprehensible and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.652 | p: 91.924 | r: 93.533
rouge2     | fm: 61.640 | p: 61.381 | r: 61.949
rougeL     | fm: 80.243 | p: 79.739 | r: 80.923
rougeLsum  | fm: 80.186 | p: 79.617 | r: 80.872
r1fm+r2fm = 154.292

input #68 time: 0:11:17 | total time: 11:54:26


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
*********************************
*********************************
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.086551547050476 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9466122388839722 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.925304114818573 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9242345690727234 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9170600771903992 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9078761339187622 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8832088112831116 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8760436773300171 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8714134693145752 for ['[CLS] ferris main case african gross tray adelaide burnham port unopposedest [MASK] platformmission downacio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.105 (perp=13.730, rec=0.349, cos=0.010), tot_loss_proj:4.377 [t=0.25s]
prediction: ['[CLS] epic risk sox clockwise livear grammy natural miles ever fm border polished labrador championpowering [SEP]']
[ 100/2000] tot_loss=2.727 (perp=12.243, rec=0.273, cos=0.005), tot_loss_proj:4.385 [t=0.26s]
prediction: ['[CLS] realand miserable pinyin livear grammy smart - a " : polished\'road innovative [SEP]']
[ 150/2000] tot_loss=2.216 (perp=9.875, rec=0.238, cos=0.003), tot_loss_proj:2.806 [t=0.27s]
prediction: ["[CLS] real, wins winner strong subtle winner smart - - two - byzantine'road wise [SEP]"]
[ 200/2000] tot_loss=2.142 (perp=9.660, rec=0.207, cos=0.003), tot_loss_proj:2.968 [t=0.28s]
prediction: ['[CLS] real, wins winner resident subtle winner funny - - " - ─\'road funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.923 (perp=8.566, rec=0.207, cos=0.003), tot_loss_proj:2.526 [t=0.30s]
prediction: ['[CLS] real, " winner a subtle winner funny - - pit - blossom\'champion funny [SEP]']
[ 300/2000] tot_loss=1.990 (perp=8.973, rec=0.193, cos=0.002), tot_loss_proj:2.704 [t=0.30s]
prediction: ['[CLS] real, ", a subtle winner funny - - pit - blossom put champion funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.170 (perp=9.833, rec=0.201, cos=0.002), tot_loss_proj:3.049 [t=0.30s]
prediction: ['[CLS] real pan really. a subtle winner real - subtle put pit - - champion funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.087 (perp=9.526, rec=0.179, cos=0.002), tot_loss_proj:2.814 [t=0.30s]
prediction: ['[CLS] real ray really, a subtle winner real - subtle champion why - - mackenzie funny [SEP]']
[ 450/2000] tot_loss=2.067 (perp=9.499, rec=0.165, cos=0.002), tot_loss_proj:2.622 [t=0.31s]
prediction: ['[CLS] real ray really, a subtle winner real - subtle and why, - mackenzie funny [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.869 (perp=8.526, rec=0.162, cos=0.002), tot_loss_proj:2.509 [t=0.30s]
prediction: ['[CLS] real - really, a subtle winner real - subtle and why, ray mackenzie funny [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.720 (perp=7.813, rec=0.156, cos=0.002), tot_loss_proj:2.461 [t=0.29s]
prediction: ['[CLS] real - really, a subtle - real winner, and why, rayitzer funny [SEP]']
[ 600/2000] tot_loss=1.748 (perp=7.979, rec=0.150, cos=0.002), tot_loss_proj:2.656 [t=0.29s]
prediction: ['[CLS] real - really, a subtle - real winner, and why,,itzer smart [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.692 (perp=7.739, rec=0.142, cos=0.002), tot_loss_proj:2.726 [t=0.31s]
prediction: ['[CLS] real - st, a subtle - real winner, and why, funny bacterium, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.645 (perp=7.563, rec=0.131, cos=0.002), tot_loss_proj:2.982 [t=0.30s]
prediction: ['[CLS] real - st, real subtle - a winner, and placed, smart⁄₄, [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.304, rec=0.127, cos=0.002), tot_loss_proj:2.370 [t=0.30s]
prediction: ['[CLS] real - st, real subtle - a winner, and placed. smart thee, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.538 (perp=6.794, rec=0.176, cos=0.003), tot_loss_proj:2.375 [t=0.29s]
prediction: ["[CLS] real - conjunction, real subtle - a winner, and'- smartiger. [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.655 (perp=7.455, rec=0.161, cos=0.003), tot_loss_proj:2.616 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger why - smart. [SEP]']
[ 900/2000] tot_loss=1.637 (perp=7.455, rec=0.144, cos=0.002), tot_loss_proj:2.620 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger why - smart. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.618 (perp=7.366, rec=0.143, cos=0.002), tot_loss_proj:3.078 [t=0.27s]
prediction: ['[CLS] real - gloria, real subtle - a winner, andiger - why smart. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.485 (perp=6.730, rec=0.137, cos=0.002), tot_loss_proj:2.977 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger - why smart. [SEP]']
[1050/2000] tot_loss=1.477 (perp=6.671, rec=0.141, cos=0.002), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger - to smart. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.468 (perp=6.671, rec=0.132, cos=0.002), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger - to smart. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.460 (perp=6.671, rec=0.124, cos=0.002), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger - to smart. [SEP]']
[1200/2000] tot_loss=1.463 (perp=6.671, rec=0.127, cos=0.002), tot_loss_proj:2.590 [t=0.25s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger - to smart. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.474 (perp=6.671, rec=0.138, cos=0.002), tot_loss_proj:2.577 [t=0.28s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, andiger - to smart. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.426 (perp=6.453, rec=0.134, cos=0.002), tot_loss_proj:2.285 [t=0.28s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
[1350/2000] tot_loss=1.418 (perp=6.453, rec=0.125, cos=0.002), tot_loss_proj:2.287 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.432 (perp=6.453, rec=0.139, cos=0.002), tot_loss_proj:2.285 [t=0.28s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.425 (perp=6.453, rec=0.132, cos=0.002), tot_loss_proj:2.288 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
[1500/2000] tot_loss=1.413 (perp=6.453, rec=0.120, cos=0.002), tot_loss_proj:2.286 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.413 (perp=6.453, rec=0.121, cos=0.002), tot_loss_proj:2.280 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.411 (perp=6.453, rec=0.118, cos=0.002), tot_loss_proj:2.283 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
[1650/2000] tot_loss=1.417 (perp=6.453, rec=0.125, cos=0.002), tot_loss_proj:2.281 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.418 (perp=6.453, rec=0.125, cos=0.002), tot_loss_proj:2.285 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.421 (perp=6.453, rec=0.128, cos=0.002), tot_loss_proj:2.284 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
[1800/2000] tot_loss=1.418 (perp=6.453, rec=0.126, cos=0.002), tot_loss_proj:2.282 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.412 (perp=6.453, rec=0.119, cos=0.002), tot_loss_proj:2.277 [t=0.25s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.417 (perp=6.453, rec=0.124, cos=0.002), tot_loss_proj:2.286 [t=0.27s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
[1950/2000] tot_loss=1.418 (perp=6.453, rec=0.126, cos=0.002), tot_loss_proj:2.284 [t=0.26s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.410 (perp=6.453, rec=0.118, cos=0.002), tot_loss_proj:2.282 [t=0.25s]
prediction: ['[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] real - conjunction, real subtle - a winner, and smart - toiger. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 76.190

[Aggregate metrics]:
rouge1     | fm: 92.409 | p: 91.673 | r: 93.253
rouge2     | fm: 60.698 | p: 60.462 | r: 60.994
rougeL     | fm: 79.761 | p: 79.259 | r: 80.376
rougeLsum  | fm: 79.817 | p: 79.288 | r: 80.493
r1fm+r2fm = 153.107

input #69 time: 0:11:22 | total time: 12:05:49


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8451830148696899 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.81871098279953 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7903928160667419 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7371676564216614 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7334622144699097 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7315616607666016 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7313181161880493 for ['[CLS] detention sharma effects mark herself blood technological [SEP]']
[Init] best perm rec loss: 0.7305154204368591 for ['[CLS] sharma blood herself detention technological effects mark [SEP]']
[Init] best perm rec loss: 0.730158805847168 for ['[CLS] mark blood herself effects technological detention sharma [SEP]']
[Init] best perm rec loss: 0.7293766736984253 for ['[CLS] detention blood effects sharma herself technological mark [SEP]']
[Init] best perm rec loss: 0.7282413840293884 for ['[CLS] detention herself mark sharma technological effects blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.590 (perp=11.031, rec=0.325, cos=0.059), tot_loss_proj:3.768 [t=0.27s]
prediction: ['[CLS] clyunk goes onunk screen [SEP]']
[ 100/2000] tot_loss=2.418 (perp=11.133, rec=0.178, cos=0.014), tot_loss_proj:3.026 [t=0.26s]
prediction: ['[CLS] clyunk gets clunk screen [SEP]']
[ 150/2000] tot_loss=2.342 (perp=11.097, rec=0.115, cos=0.008), tot_loss_proj:4.036 [t=0.27s]
prediction: ['[CLS] clyunk gets onunk screen [SEP]']
[ 200/2000] tot_loss=2.314 (perp=11.097, rec=0.089, cos=0.005), tot_loss_proj:4.023 [t=0.26s]
prediction: ['[CLS] clyunk gets onunk screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.939 (perp=9.041, rec=0.119, cos=0.011), tot_loss_proj:2.606 [t=0.27s]
prediction: ['[CLS] clunky gets onunk screen [SEP]']
[ 300/2000] tot_loss=1.893 (perp=9.041, rec=0.082, cos=0.003), tot_loss_proj:2.596 [t=0.25s]
prediction: ['[CLS] clunky gets onunk screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.644 (perp=7.851, rec=0.071, cos=0.003), tot_loss_proj:2.439 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.636 (perp=7.851, rec=0.063, cos=0.003), tot_loss_proj:2.453 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 450/2000] tot_loss=1.648 (perp=7.851, rec=0.075, cos=0.003), tot_loss_proj:2.447 [t=0.27s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.002), tot_loss_proj:2.450 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.003), tot_loss_proj:2.445 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 600/2000] tot_loss=1.642 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.453 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.638 (perp=7.851, rec=0.065, cos=0.002), tot_loss_proj:2.451 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.647 (perp=7.851, rec=0.075, cos=0.002), tot_loss_proj:2.456 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 750/2000] tot_loss=1.642 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.458 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.002), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.655 (perp=7.851, rec=0.082, cos=0.002), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 900/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.002), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.635 (perp=7.851, rec=0.063, cos=0.002), tot_loss_proj:2.460 [t=0.28s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.459 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1050/2000] tot_loss=1.635 (perp=7.851, rec=0.063, cos=0.002), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.641 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.461 [t=0.27s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.648 (perp=7.851, rec=0.076, cos=0.002), tot_loss_proj:2.469 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1200/2000] tot_loss=1.651 (perp=7.851, rec=0.078, cos=0.002), tot_loss_proj:2.463 [t=0.27s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.641 (perp=7.851, rec=0.068, cos=0.002), tot_loss_proj:2.468 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.634 (perp=7.851, rec=0.062, cos=0.002), tot_loss_proj:2.458 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1350/2000] tot_loss=1.646 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.460 [t=0.27s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.644 (perp=7.851, rec=0.072, cos=0.002), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.646 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.535 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1500/2000] tot_loss=1.634 (perp=7.851, rec=0.061, cos=0.002), tot_loss_proj:2.535 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.638 (perp=7.851, rec=0.066, cos=0.002), tot_loss_proj:2.465 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.638 (perp=7.851, rec=0.065, cos=0.002), tot_loss_proj:2.466 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1650/2000] tot_loss=1.638 (perp=7.851, rec=0.066, cos=0.002), tot_loss_proj:2.468 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.640 (perp=7.851, rec=0.067, cos=0.002), tot_loss_proj:2.464 [t=0.27s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.645 (perp=7.851, rec=0.072, cos=0.002), tot_loss_proj:2.546 [t=0.25s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1800/2000] tot_loss=1.634 (perp=7.851, rec=0.061, cos=0.002), tot_loss_proj:2.540 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.643 (perp=7.851, rec=0.071, cos=0.002), tot_loss_proj:2.539 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.635 (perp=7.851, rec=0.063, cos=0.002), tot_loss_proj:2.538 [t=0.28s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1950/2000] tot_loss=1.645 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.540 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.539 [t=0.26s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] clunkunky gets on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 92.212 | p: 91.565 | r: 92.995
rouge2     | fm: 60.008 | p: 59.860 | r: 60.188
rougeL     | fm: 79.782 | p: 79.327 | r: 80.335
rougeLsum  | fm: 79.769 | p: 79.323 | r: 80.329
r1fm+r2fm = 152.220

input #70 time: 0:11:05 | total time: 12:16:55


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
*********************************
*********************************
average of cosine similarity 0.9993403548184049
highest_index [0]
highest [0.9993403548184049]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8840630650520325 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.847382128238678 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8406677842140198 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8305583596229553 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8247600197792053 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8176411986351013 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.813213050365448 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.8101482391357422 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8090407252311707 for ['[CLS] tomb gogharth acids course beyond littletered wright until south. reservoir stageathlon [SEP]']
[Init] best perm rec loss: 0.8082916736602783 for ['[CLS] beyond gogh southarth wright stage course acidstered. little until tombathlon reservoir [SEP]']
[Init] best perm rec loss: 0.8073354363441467 for ['[CLS] reservoir beyond.athlon little acids tombarth wright south course stage until goghtered [SEP]']
[Init] best perm rec loss: 0.8070156574249268 for ['[CLS]. reservoir wright beyondathlon tombarth stage acids south gogh course littletered until [SEP]']
[Init] best perm rec loss: 0.8070120215415955 for ['[CLS]athlon. reservoir southarth stagetered tomb beyond wright until little gogh acids course [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.290 (perp=9.820, rec=0.283, cos=0.043), tot_loss_proj:3.352 [t=0.29s]
prediction: ['[CLS] around. species not single single jump jump moment constructed - seat v moment and [SEP]']
[ 100/2000] tot_loss=1.924 (perp=8.835, rec=0.141, cos=0.016), tot_loss_proj:2.651 [t=0.30s]
prediction: ["[CLS] position'system not a single jump seat moment jumping - seat yours moment and [SEP]"]
[ 150/2000] tot_loss=1.811 (perp=8.398, rec=0.121, cos=0.011), tot_loss_proj:2.390 [t=0.30s]
prediction: ["[CLS] -'bunch not a single jump seat moment s - seat your moment and [SEP]"]
[ 200/2000] tot_loss=1.576 (perp=7.417, rec=0.087, cos=0.006), tot_loss_proj:2.191 [t=0.29s]
prediction: ['[CLS] - s there not a single jump seat moment in - seat your moment and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.483 (perp=7.019, rec=0.077, cos=0.002), tot_loss_proj:2.261 [t=0.32s]
prediction: ['[CLS] - s not there a single jump seat moment in - seat your moment and [SEP]']
[ 300/2000] tot_loss=1.510 (perp=7.138, rec=0.080, cos=0.002), tot_loss_proj:2.209 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment in - your your moment and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.479 (perp=7.040, rec=0.069, cos=0.002), tot_loss_proj:2.748 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - in your your moment and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.409 (perp=6.472, rec=0.110, cos=0.005), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - in your moment and your [SEP]']
[ 450/2000] tot_loss=1.486 (perp=7.021, rec=0.080, cos=0.002), tot_loss_proj:2.187 [t=0.27s]
prediction: ['[CLS] - s not there a single jump seat moment - in - moment and your [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.382 (perp=6.556, rec=0.069, cos=0.002), tot_loss_proj:2.371 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - - moment and in your [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.348 (perp=6.366, rec=0.073, cos=0.002), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - - and moment in your [SEP]']
[ 600/2000] tot_loss=1.337 (perp=6.366, rec=0.062, cos=0.002), tot_loss_proj:2.038 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - - and moment in your [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.342 (perp=6.366, rec=0.068, cos=0.002), tot_loss_proj:2.023 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - - and moment in your [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.334 (perp=6.366, rec=0.059, cos=0.002), tot_loss_proj:2.038 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat moment - - and moment in your [SEP]']
[ 750/2000] tot_loss=1.342 (perp=6.366, rec=0.068, cos=0.002), tot_loss_proj:2.033 [t=0.29s]
prediction: ['[CLS] - s not there a single jump seat moment - - and moment in your [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.279 (perp=6.059, rec=0.066, cos=0.002), tot_loss_proj:2.542 [t=0.26s]
prediction: ['[CLS] - s not there a single jump seat - - and moment in your moment [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.263 (perp=5.968, rec=0.068, cos=0.002), tot_loss_proj:2.574 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[ 900/2000] tot_loss=1.263 (perp=5.968, rec=0.068, cos=0.002), tot_loss_proj:2.579 [t=0.29s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.262 (perp=5.968, rec=0.066, cos=0.001), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1000/2000] tot_loss=1.259 (perp=5.968, rec=0.064, cos=0.001), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1050/2000] tot_loss=1.272 (perp=5.968, rec=0.077, cos=0.001), tot_loss_proj:2.575 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1100/2000] tot_loss=1.272 (perp=5.968, rec=0.077, cos=0.001), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1150/2000] tot_loss=1.260 (perp=5.968, rec=0.065, cos=0.001), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1200/2000] tot_loss=1.259 (perp=5.968, rec=0.064, cos=0.001), tot_loss_proj:2.586 [t=0.28s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.265 (perp=5.968, rec=0.070, cos=0.001), tot_loss_proj:2.534 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1300/2000] tot_loss=1.259 (perp=5.968, rec=0.064, cos=0.001), tot_loss_proj:2.541 [t=0.25s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1350/2000] tot_loss=1.260 (perp=5.968, rec=0.065, cos=0.001), tot_loss_proj:2.532 [t=0.27s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.262 (perp=5.968, rec=0.067, cos=0.002), tot_loss_proj:2.580 [t=0.25s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1450/2000] tot_loss=1.258 (perp=5.968, rec=0.063, cos=0.001), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1500/2000] tot_loss=1.256 (perp=5.968, rec=0.061, cos=0.001), tot_loss_proj:2.586 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.261 (perp=5.968, rec=0.066, cos=0.001), tot_loss_proj:2.538 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1600/2000] tot_loss=1.252 (perp=5.968, rec=0.057, cos=0.001), tot_loss_proj:2.536 [t=0.25s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1650/2000] tot_loss=1.253 (perp=5.968, rec=0.058, cos=0.001), tot_loss_proj:2.536 [t=0.28s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.266 (perp=5.968, rec=0.071, cos=0.001), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1750/2000] tot_loss=1.261 (perp=5.968, rec=0.066, cos=0.001), tot_loss_proj:2.581 [t=0.27s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1800/2000] tot_loss=1.266 (perp=5.968, rec=0.071, cos=0.001), tot_loss_proj:2.582 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1850/2000] tot_loss=1.261 (perp=5.968, rec=0.066, cos=0.001), tot_loss_proj:2.581 [t=0.27s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[1900/2000] tot_loss=1.257 (perp=5.968, rec=0.062, cos=0.001), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
[1950/2000] tot_loss=1.265 (perp=5.968, rec=0.069, cos=0.001), tot_loss_proj:2.583 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Attempt swap
[2000/2000] tot_loss=1.253 (perp=5.968, rec=0.058, cos=0.001), tot_loss_proj:2.585 [t=0.26s]
prediction: ['[CLS] - s not there a single seat jump - - and moment in your moment [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] - s not there a single seat jump - - and moment in your moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 24.000 | p: 23.077 | r: 25.000
rougeL     | fm: 74.074 | p: 71.429 | r: 76.923
rougeLsum  | fm: 74.074 | p: 71.429 | r: 76.923
r1fm+r2fm = 120.296

[Aggregate metrics]:
rouge1     | fm: 92.283 | p: 91.579 | r: 93.086
rouge2     | fm: 59.623 | p: 59.427 | r: 59.877
rougeL     | fm: 79.621 | p: 79.174 | r: 80.278
rougeLsum  | fm: 79.568 | p: 79.056 | r: 80.247
r1fm+r2fm = 151.906

input #71 time: 0:11:20 | total time: 12:28:15


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
*********************************
*********************************
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7871954441070557 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.756220817565918 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7524415254592896 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7376322150230408 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.736792266368866 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7195456624031067 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7185581922531128 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7164209485054016 for ['[CLS] except orbitalungen lifeboat dna walking nonetheless support van! pork zone ta reserve accidentally [SEP]']
[Init] best perm rec loss: 0.713283896446228 for ['[CLS] except pork zone! lifeboat nonetheless accidentally ta orbital support walking dnaungen reserve van [SEP]']
[Init] best perm rec loss: 0.7122484445571899 for ['[CLS] porkungen lifeboat support accidentally nonetheless except walking dna reserve ta! zone orbital van [SEP]']
[Init] best perm rec loss: 0.7111414074897766 for ['[CLS] orbital except pork lifeboat! accidentally support reserve walkingungen ta van dna zone nonetheless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.012 (perp=13.231, rec=0.333, cos=0.033), tot_loss_proj:4.445 [t=0.27s]
prediction: ['[CLS] something tough blood tough card voterser laude punk paramount an ] flesh your builds [SEP]']
[ 100/2000] tot_loss=2.433 (perp=10.942, rec=0.229, cos=0.015), tot_loss_proj:3.843 [t=0.25s]
prediction: ['[CLS] has balancing tough tough time time its laude thing balancing an - violence philosophy an [SEP]']
[ 150/2000] tot_loss=2.388 (perp=11.156, rec=0.151, cos=0.006), tot_loss_proj:3.675 [t=0.27s]
prediction: ['[CLS] has balancing tough tough time time its assassination violenceoumer a violence philosophy a [SEP]']
[ 200/2000] tot_loss=2.013 (perp=9.495, rec=0.109, cos=0.004), tot_loss_proj:3.298 [t=0.27s]
prediction: ['[CLS] has balancing its tough time time its inspired violence compareder with violence philosophy a [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.872 (perp=8.745, rec=0.119, cos=0.004), tot_loss_proj:2.487 [t=0.28s]
prediction: ['[CLS] has its tough time time balancing - inspired violence compareder with violence philosophy a [SEP]']
[ 300/2000] tot_loss=1.933 (perp=9.237, rec=0.083, cos=0.002), tot_loss_proj:2.525 [t=0.26s]
prediction: ['[CLS] has its tough time time balancing - inspired violenceouer with violence philosophy a [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.844 (perp=8.859, rec=0.071, cos=0.002), tot_loss_proj:2.539 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time - inspired violenceouer with violence philosophy a [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.680 (perp=7.991, rec=0.079, cos=0.002), tot_loss_proj:2.302 [t=0.28s]
prediction: ['[CLS] has its tough time balancing time inspired violenceefeer with violence philosophy - a [SEP]']
[ 450/2000] tot_loss=1.744 (perp=8.393, rec=0.064, cos=0.002), tot_loss_proj:2.366 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violenceouer with violence philosophy - a [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.862 (perp=8.925, rec=0.076, cos=0.002), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violenceouer with violencefk a philosophy [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.893 (perp=9.095, rec=0.073, cos=0.002), tot_loss_proj:2.717 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violenceer with violenceiticfk a philosophy [SEP]']
[ 600/2000] tot_loss=1.895 (perp=9.095, rec=0.074, cos=0.002), tot_loss_proj:2.716 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violenceer with violenceiticfk a philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.810 (perp=8.683, rec=0.072, cos=0.002), tot_loss_proj:2.612 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violence wither violenceafk a philosophy [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.729 (perp=8.261, rec=0.075, cos=0.003), tot_loss_proj:2.721 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violenceer violenceafk with a philosophy [SEP]']
[ 750/2000] tot_loss=1.733 (perp=8.261, rec=0.079, cos=0.002), tot_loss_proj:2.714 [t=0.26s]
prediction: ['[CLS] has its tough time balancing time inspired violenceer violenceafk with a philosophy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.619 (perp=7.723, rec=0.072, cos=0.002), tot_loss_proj:2.086 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspired violenceer violenceafk with its philosophy [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.595 (perp=7.571, rec=0.080, cos=0.002), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspired violenceafk with its violenceer philosophy [SEP]']
[ 900/2000] tot_loss=1.588 (perp=7.571, rec=0.072, cos=0.002), tot_loss_proj:2.022 [t=0.28s]
prediction: ['[CLS] has a tough time balancing time inspired violenceafk with its violenceer philosophy [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.572 (perp=7.501, rec=0.070, cos=0.002), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspired violencea with its violencefker philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.681 (perp=8.076, rec=0.064, cos=0.002), tot_loss_proj:2.100 [t=0.28s]
prediction: ['[CLS] has a tough time balancing time inspired violencea with its -fker philosophy [SEP]']
[1050/2000] tot_loss=1.686 (perp=8.076, rec=0.069, cos=0.002), tot_loss_proj:2.093 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspired violencea with its -fker philosophy [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.573 (perp=7.551, rec=0.061, cos=0.002), tot_loss_proj:2.031 [t=0.27s]
prediction: ['[CLS] has a tough time balancing time inspireda with its violence -fker philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.587 (perp=7.551, rec=0.075, cos=0.002), tot_loss_proj:2.030 [t=0.27s]
prediction: ['[CLS] has a tough time balancing time inspireda with its violence -fker philosophy [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.551, rec=0.066, cos=0.002), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspireda with its violence -fker philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.584 (perp=7.551, rec=0.073, cos=0.002), tot_loss_proj:2.029 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspireda with its violence -fker philosophy [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.553 (perp=7.426, rec=0.066, cos=0.002), tot_loss_proj:2.041 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspired with its violence -fkaer philosophy [SEP]']
[1350/2000] tot_loss=1.561 (perp=7.426, rec=0.074, cos=0.002), tot_loss_proj:2.036 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time inspired with its violence -fkaer philosophy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.546 (perp=7.426, rec=0.059, cos=0.002), tot_loss_proj:2.029 [t=0.27s]
prediction: ['[CLS] has a tough time balancing time inspired with its violence -fkaer philosophy [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.522 (perp=7.260, rec=0.068, cos=0.002), tot_loss_proj:1.969 [t=0.28s]
prediction: ['[CLS] has a tough time balancing time with its inspired violence -fkaer philosophy [SEP]']
[1500/2000] tot_loss=1.536 (perp=7.260, rec=0.082, cos=0.002), tot_loss_proj:1.968 [t=0.27s]
prediction: ['[CLS] has a tough time balancing time with its inspired violence -fkaer philosophy [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.503 (perp=7.147, rec=0.072, cos=0.002), tot_loss_proj:1.934 [t=0.27s]
prediction: ['[CLS] has a tough time balancing time with its violence - inspiredfkaer philosophy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.508 (perp=7.147, rec=0.077, cos=0.002), tot_loss_proj:1.934 [t=0.27s]
prediction: ['[CLS] has a tough time balancing time with its violence - inspiredfkaer philosophy [SEP]']
[1650/2000] tot_loss=1.485 (perp=7.147, rec=0.054, cos=0.002), tot_loss_proj:1.937 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time with its violence - inspiredfkaer philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.492 (perp=7.147, rec=0.061, cos=0.002), tot_loss_proj:1.941 [t=0.26s]
prediction: ['[CLS] has a tough time balancing time with its violence - inspiredfkaer philosophy [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.474 (perp=7.042, rec=0.064, cos=0.002), tot_loss_proj:1.905 [t=0.27s]
prediction: ['[CLS] has a tough time balancing its time with violence - inspiredfkaer philosophy [SEP]']
[1800/2000] tot_loss=1.466 (perp=7.042, rec=0.056, cos=0.002), tot_loss_proj:1.903 [t=0.27s]
prediction: ['[CLS] has a tough time balancing its time with violence - inspiredfkaer philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.472 (perp=7.042, rec=0.062, cos=0.002), tot_loss_proj:1.905 [t=0.30s]
prediction: ['[CLS] has a tough time balancing its time with violence - inspiredfkaer philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.478 (perp=7.042, rec=0.068, cos=0.002), tot_loss_proj:1.901 [t=0.27s]
prediction: ['[CLS] has a tough time balancing its time with violence - inspiredfkaer philosophy [SEP]']
[1950/2000] tot_loss=1.486 (perp=7.042, rec=0.076, cos=0.002), tot_loss_proj:1.906 [t=0.26s]
prediction: ['[CLS] has a tough time balancing its time with violence - inspiredfkaer philosophy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.466 (perp=7.042, rec=0.056, cos=0.002), tot_loss_proj:1.904 [t=0.27s]
prediction: ['[CLS] has a tough time balancing its time with violence - inspiredfkaer philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] has a tough time balancing time inspireda with its violence -fker philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.074 | p: 71.429 | r: 76.923
rouge2     | fm: 40.000 | p: 38.462 | r: 41.667
rougeL     | fm: 66.667 | p: 64.286 | r: 69.231
rougeLsum  | fm: 66.667 | p: 64.286 | r: 69.231
r1fm+r2fm = 114.074

[Aggregate metrics]:
rouge1     | fm: 91.974 | p: 91.263 | r: 92.826
rouge2     | fm: 59.319 | p: 59.106 | r: 59.575
rougeL     | fm: 79.545 | p: 79.055 | r: 80.120
rougeLsum  | fm: 79.476 | p: 78.950 | r: 80.104
r1fm+r2fm = 151.293

input #72 time: 0:11:05 | total time: 12:39:21


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
*********************************
*********************************
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9928975701332092 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9657580256462097 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9560467600822449 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9083574414253235 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8474614024162292 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8438819646835327 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.134 (perp=9.723, rec=0.181, cos=0.009), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.000 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.006 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.001 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.009 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.31s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.016 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.017 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.017 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.007 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.013 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=9.723, rec=0.076, cos=0.002), tot_loss_proj:2.011 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.994 (perp=9.723, rec=0.047, cos=0.002), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.013 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.011 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.020 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.002 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.002 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:1.998 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.016 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.001 (perp=9.723, rec=0.054, cos=0.002), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.125 | p: 91.416 | r: 92.984
rouge2     | fm: 59.873 | p: 59.684 | r: 60.144
rougeL     | fm: 79.759 | p: 79.241 | r: 80.376
rougeLsum  | fm: 79.729 | p: 79.240 | r: 80.337
r1fm+r2fm = 151.998

input #73 time: 0:10:57 | total time: 12:50:19


Running input #74 of 100.
reference: 
========================
share 
========================
*********************************
*********************************
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0006722211837769 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6869400143623352 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6835439205169678 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6572129726409912 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.899 (perp=8.178, rec=0.232, cos=0.031), tot_loss_proj:2.025 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.706 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.741 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.702 (perp=8.178, rec=0.064, cos=0.002), tot_loss_proj:1.756 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.712 (perp=8.178, rec=0.074, cos=0.003), tot_loss_proj:1.791 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.002), tot_loss_proj:1.738 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.002), tot_loss_proj:1.727 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.691 (perp=8.178, rec=0.054, cos=0.001), tot_loss_proj:1.747 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.002), tot_loss_proj:1.732 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.002), tot_loss_proj:1.723 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.685 (perp=8.178, rec=0.048, cos=0.001), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.726 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.725 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.716 (perp=8.178, rec=0.079, cos=0.001), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.002), tot_loss_proj:1.735 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.735 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.725 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.720 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.731 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.732 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.749 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.714 (perp=8.178, rec=0.077, cos=0.001), tot_loss_proj:1.730 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.675 (perp=8.178, rec=0.037, cos=0.001), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.723 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.713 (perp=8.178, rec=0.076, cos=0.001), tot_loss_proj:1.729 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.720 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.741 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.267 | p: 91.550 | r: 93.104
rouge2     | fm: 60.432 | p: 60.208 | r: 60.735
rougeL     | fm: 80.019 | p: 79.484 | r: 80.612
rougeLsum  | fm: 80.032 | p: 79.530 | r: 80.684
r1fm+r2fm = 152.699

input #74 time: 0:11:07 | total time: 13:01:26


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
*********************************
*********************************
average of cosine similarity 0.9993458403755588
highest_index [0]
highest [0.9993458403755588]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9583500623703003 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9476472735404968 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9449086785316467 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.904586672782898 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8991710543632507 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8988634347915649 for ['[CLS] gas harbour jobs primarily indy starts smile colorado spirit mach [MASK] academy breakingmetonic ling readerimum millennium [SEP]']
[Init] best rec loss: 0.8913002014160156 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8875274658203125 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8863378167152405 for ['[CLS]thermal howbara single free better coats younger which against goddess portion 2018 octopus managed hu honoraryom compares [SEP]']
[Init] best rec loss: 0.8637418150901794 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8630682826042175 for ['[CLS] magic eachrate apollo stood royalties resultedmmel loopcl skill crown fact viewed auxiliary left regardedception to [SEP]']
[Init] best perm rec loss: 0.8622175455093384 for ['[CLS] stood loop crownrate auxiliarymmel left apollo each royalties to magic viewedcl skillception resulted fact regarded [SEP]']
[Init] best perm rec loss: 0.8622075319290161 for ['[CLS]mmel loop royalties regarded fact magic to left apollo stoodcl skill resultedception viewedrate each crown auxiliary [SEP]']
[Init] best perm rec loss: 0.8609483242034912 for ['[CLS]ceptionmmel auxiliary stood fact apollo regarded viewed eachclrate royalties skill magic crown resulted loop to left [SEP]']
[Init] best perm rec loss: 0.8605997562408447 for ['[CLS] resulted skill apollocl to crown stood auxiliary fact each regardedmmelception loop magic royalties viewed leftrate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.027 (perp=13.027, rec=0.387, cos=0.034), tot_loss_proj:4.356 [t=0.26s]
prediction: ['[CLS] wasn society bates mission the d wrote moments.peration avery hardly campeonato unknownclass relaxed renamed losing island [SEP]']
[ 100/2000] tot_loss=2.383 (perp=10.474, rec=0.267, cos=0.021), tot_loss_proj:4.034 [t=0.26s]
prediction: ['[CLS] got himself easily mission the d wrote denied.peration forgotten never obtained unknown not easily renamed forgotten forgotten [SEP]']
[ 150/2000] tot_loss=2.227 (perp=10.033, rec=0.209, cos=0.011), tot_loss_proj:3.894 [t=0.26s]
prediction: ['[CLS] swap sides easily excursion the d lateral instability. easily forgotten instability is isn not easily renamed or forgotten [SEP]']
[ 200/2000] tot_loss=2.239 (perp=10.295, rec=0.173, cos=0.007), tot_loss_proj:3.173 [t=0.27s]
prediction: ['[CLS] having frankly easily excursion the. lateral instabilityratingdlowenter instability is is not easily renamed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.246 (perp=10.248, rec=0.188, cos=0.008), tot_loss_proj:3.939 [t=0.26s]
prediction: ['[CLS] this is easily excursion into largest of instabilitypromisingness mental mental hyper instability not easily renamed or forgotten [SEP]']
[ 300/2000] tot_loss=2.127 (perp=9.948, rec=0.133, cos=0.004), tot_loss_proj:3.373 [t=0.25s]
prediction: ['[CLS] this isnson excursion into. of instabilityenterness mental mental over instability not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.140 (perp=10.070, rec=0.123, cos=0.003), tot_loss_proj:2.983 [t=0.27s]
prediction: ['[CLS] this isnent excursion into. of instabilityenter instability mental mental hyper rely not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.055 (perp=9.653, rec=0.121, cos=0.004), tot_loss_proj:2.681 [t=0.26s]
prediction: ['[CLS] this isnent excursion intoenter mental instability mental instability mentalenter hyper rely not easily dismissed or forgotten [SEP]']
[ 450/2000] tot_loss=1.965 (perp=9.318, rec=0.098, cos=0.003), tot_loss_proj:3.631 [t=0.26s]
prediction: ['[CLS] this is dismissed excursion intoenter mental instability mental instability mentalenter sides rely not easily dismissed or forgotten [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.933 (perp=9.145, rec=0.101, cos=0.003), tot_loss_proj:2.886 [t=0.25s]
prediction: ['[CLS] this is muster excursion intoenterenter mental instability mental instability mental pupil rely not easily dismissed or forgotten [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.076 (perp=9.857, rec=0.101, cos=0.003), tot_loss_proj:3.191 [t=0.27s]
prediction: ['[CLS] this isxide excursion intoenterenter mental instability mental instability mentalcola rely not easily dismissed or forgotten [SEP]']
[ 600/2000] tot_loss=2.065 (perp=9.857, rec=0.091, cos=0.003), tot_loss_proj:3.184 [t=0.25s]
prediction: ['[CLS] this isxide excursion intoenterenter mental instability mental instability mentalcola rely not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.030 (perp=9.583, rec=0.111, cos=0.003), tot_loss_proj:3.218 [t=0.27s]
prediction: ['[CLS] this isxide excursion intoenterenter mental instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.952 (perp=9.197, rec=0.110, cos=0.003), tot_loss_proj:3.463 [t=0.27s]
prediction: ['[CLS] this isxide excursion mentalenterenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
[ 750/2000] tot_loss=1.914 (perp=9.085, rec=0.094, cos=0.003), tot_loss_proj:3.108 [t=0.28s]
prediction: ['[CLS] this is ª excursion mentalenterenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.912 (perp=9.085, rec=0.092, cos=0.003), tot_loss_proj:3.105 [t=0.26s]
prediction: ['[CLS] this is ª excursion mentalenterenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.060 (perp=9.757, rec=0.106, cos=0.003), tot_loss_proj:3.632 [t=0.26s]
prediction: ['[CLS] this is ª excursion mentalenterenter rely into instability mental instability mentalcola not easily forgotten or dismissed [SEP]']
[ 900/2000] tot_loss=2.048 (perp=9.757, rec=0.094, cos=0.003), tot_loss_proj:3.638 [t=0.28s]
prediction: ['[CLS] this is ª excursion mentalenterenter rely into instability mental instability mentalcola not easily forgotten or dismissed [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.901 (perp=9.085, rec=0.082, cos=0.003), tot_loss_proj:3.106 [t=0.28s]
prediction: ['[CLS] this is ª excursion mentalenterenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.935 (perp=9.167, rec=0.099, cos=0.003), tot_loss_proj:3.298 [t=0.27s]
prediction: ['[CLS] this is instability excursion mentalenterenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
[1050/2000] tot_loss=1.894 (perp=8.954, rec=0.100, cos=0.003), tot_loss_proj:3.258 [t=0.25s]
prediction: ['[CLS] this is instability excursion mental epicenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.899 (perp=9.036, rec=0.089, cos=0.003), tot_loss_proj:3.086 [t=0.26s]
prediction: ['[CLS] this is ª mental excursion epicenter into instability mental instability mentalcola rely not easily forgotten or dismissed [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.856 (perp=8.816, rec=0.090, cos=0.003), tot_loss_proj:3.088 [t=0.26s]
prediction: ['[CLS] this is ª instability mental excursion epicenter into instability mental mentalcola rely not easily forgotten or dismissed [SEP]']
[1200/2000] tot_loss=1.876 (perp=8.889, rec=0.095, cos=0.003), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] this is ª instability mental excursion epicenter into instability mental mentalcola forehead not easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.859 (perp=8.815, rec=0.094, cos=0.003), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] this is ª instability mental excursion epicenter into mental instability mentalcola forehead not easily forgotten or dismissed [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.810 (perp=8.582, rec=0.091, cos=0.003), tot_loss_proj:3.110 [t=0.27s]
prediction: ['[CLS] this is ª mental instability mental excursion epicenter into mental instabilitycola forehead not easily forgotten or dismissed [SEP]']
[1350/2000] tot_loss=1.803 (perp=8.582, rec=0.084, cos=0.003), tot_loss_proj:3.113 [t=0.26s]
prediction: ['[CLS] this is ª mental instability mental excursion epicenter into mental instabilitycola forehead not easily forgotten or dismissed [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.772 (perp=8.416, rec=0.086, cos=0.003), tot_loss_proj:3.181 [t=0.27s]
prediction: ['[CLS] this is ª mental instability mental excursioncola epicenter into mental instability forehead not easily forgotten or dismissed [SEP]']
Attempt swap
[1450/2000] tot_loss=1.769 (perp=8.416, rec=0.083, cos=0.003), tot_loss_proj:3.187 [t=0.28s]
prediction: ['[CLS] this is ª mental instability mental excursioncola epicenter into mental instability forehead not easily forgotten or dismissed [SEP]']
[1500/2000] tot_loss=1.776 (perp=8.416, rec=0.090, cos=0.003), tot_loss_proj:3.186 [t=0.26s]
prediction: ['[CLS] this is ª mental instability mental excursioncola epicenter into mental instability forehead not easily forgotten or dismissed [SEP]']
Attempt swap
[1550/2000] tot_loss=1.775 (perp=8.416, rec=0.089, cos=0.003), tot_loss_proj:3.187 [t=0.26s]
prediction: ['[CLS] this is ª mental instability mental excursioncola epicenter into mental instability forehead not easily forgotten or dismissed [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.727 (perp=8.213, rec=0.082, cos=0.003), tot_loss_proj:3.272 [t=0.27s]
prediction: ['[CLS] this is ª mental instability mental excursioncola forehead epicenter into mental instability not easily forgotten or dismissed [SEP]']
[1650/2000] tot_loss=1.771 (perp=8.336, rec=0.101, cos=0.003), tot_loss_proj:3.183 [t=0.28s]
prediction: ['[CLS] this is ª mental instability mental excursioncola crashing epicenter into mental instability not easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.860 (perp=8.795, rec=0.098, cos=0.003), tot_loss_proj:3.563 [t=0.27s]
prediction: ['[CLS] this is ª mental instability forehead excursioncola mental epicenter into mental instability not easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.709 (perp=8.094, rec=0.087, cos=0.003), tot_loss_proj:3.350 [t=0.27s]
prediction: ['[CLS] this is ª mental instability forehead excursion into mental epicentercola mental instability not easily forgotten or dismissed [SEP]']
[1800/2000] tot_loss=1.705 (perp=8.094, rec=0.084, cos=0.003), tot_loss_proj:3.350 [t=0.25s]
prediction: ['[CLS] this is ª mental instability forehead excursion into mental epicentercola mental instability not easily forgotten or dismissed [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.664 (perp=7.847, rec=0.092, cos=0.003), tot_loss_proj:2.268 [t=0.27s]
prediction: ['[CLS] this ª mental instability forehead excursion into mental epicentercola mental instability is not easily forgotten or dismissed [SEP]']
Attempt swap
[1900/2000] tot_loss=1.661 (perp=7.847, rec=0.089, cos=0.003), tot_loss_proj:2.261 [t=0.27s]
prediction: ['[CLS] this ª mental instability forehead excursion into mental epicentercola mental instability is not easily forgotten or dismissed [SEP]']
[1950/2000] tot_loss=1.667 (perp=7.847, rec=0.095, cos=0.003), tot_loss_proj:2.261 [t=0.26s]
prediction: ['[CLS] this ª mental instability forehead excursion into mental epicentercola mental instability is not easily forgotten or dismissed [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.649 (perp=7.770, rec=0.093, cos=0.003), tot_loss_proj:2.280 [t=0.27s]
prediction: ['[CLS] this ª mental instability excursion into mental epicentercola mental instability forehead is not easily forgotten or dismissed [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this is ª mental instability mental excursioncola epicenter into mental instability forehead not easily forgotten or dismissed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.286 | p: 72.222 | r: 76.471
rouge2     | fm: 18.182 | p: 17.647 | r: 18.750
rougeL     | fm: 51.429 | p: 50.000 | r: 52.941
rougeLsum  | fm: 51.429 | p: 50.000 | r: 52.941
r1fm+r2fm = 92.468

[Aggregate metrics]:
rouge1     | fm: 92.001 | p: 91.287 | r: 92.876
rouge2     | fm: 59.785 | p: 59.554 | r: 59.985
rougeL     | fm: 79.522 | p: 78.980 | r: 80.129
rougeLsum  | fm: 79.673 | p: 79.135 | r: 80.328
r1fm+r2fm = 151.786

input #75 time: 0:11:07 | total time: 13:12:33


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
*********************************
*********************************
average of cosine similarity 0.9991386602126573
highest_index [0]
highest [0.9991386602126573]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9212543964385986 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9036272764205933 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8987579345703125 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.892052412033081 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8654380440711975 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8489521741867065 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8485825657844543 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoˣ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8479114174842834 for ['[CLS] purse left hard abˣ backward mango ( surreal tautoning pushed onwardshaw [SEP]']
[Init] best perm rec loss: 0.8466055393218994 for ['[CLS] left mango onwards ( ab hard surreal taut backwardoning purse pushedˣhaw [SEP]']
[Init] best perm rec loss: 0.8464253544807434 for ['[CLS] (haw surreal purse onwards backward hardˣ taut pushedoning mango ab left [SEP]']
[Init] best perm rec loss: 0.846075177192688 for ['[CLS]oning onwards purse left ( taut pushedhaw hard mango backward abˣ surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.317 (perp=10.154, rec=0.266, cos=0.020), tot_loss_proj:3.642 [t=0.28s]
prediction: ['[CLS], than. although himself. bennett like stopped. not stopped challenging stopped [SEP]']
[ 100/2000] tot_loss=1.994 (perp=9.106, rec=0.165, cos=0.007), tot_loss_proj:3.105 [t=0.26s]
prediction: ['[CLS] is allen. although himself,cks as stopped, has stopped challenging stopped [SEP]']
[ 150/2000] tot_loss=2.064 (perp=9.622, rec=0.134, cos=0.006), tot_loss_proj:2.824 [t=0.27s]
prediction: ['[CLS] as allen. 66 himself,cks as stopped, has stopped challenging stopped [SEP]']
[ 200/2000] tot_loss=2.112 (perp=9.957, rec=0.116, cos=0.005), tot_loss_proj:3.049 [t=0.25s]
prediction: ["[CLS]. allen. 66 himself at'as stopped, has stopped challenging sl [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.937 (perp=9.096, rec=0.113, cos=0.006), tot_loss_proj:2.780 [t=0.25s]
prediction: ["[CLS] s allen. 66'at himself as stopped, has stopped challenging s [SEP]"]
[ 300/2000] tot_loss=1.938 (perp=9.165, rec=0.102, cos=0.003), tot_loss_proj:2.794 [t=0.26s]
prediction: ["[CLS] s allen. 66'at himself as stopped, has stopped challenging as [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.850 (perp=8.760, rec=0.094, cos=0.003), tot_loss_proj:2.765 [t=0.26s]
prediction: ["[CLS] s allen'66. at himself as stopped, has stopped challenging as [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.114 (perp=9.109, rec=0.270, cos=0.022), tot_loss_proj:2.953 [t=0.27s]
prediction: ['[CLS] s allen elliot 66. at ( as himself, has stopped challenging initially [SEP]']
[ 450/2000] tot_loss=2.055 (perp=9.357, rec=0.174, cos=0.009), tot_loss_proj:3.500 [t=0.27s]
prediction: ['[CLS] is allen balthazar 66. after ( as himself, has stopped challenging initially [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.027 (perp=9.402, rec=0.141, cos=0.005), tot_loss_proj:3.117 [t=0.27s]
prediction: ['[CLS] is allen initially 66. at from as himself, has stopped challenging briefly [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.905 (perp=8.802, rec=0.140, cos=0.004), tot_loss_proj:2.905 [t=0.25s]
prediction: ['[CLS] is allen initially without. at 66 as himself, has stopped challenging briefly [SEP]']
[ 600/2000] tot_loss=1.904 (perp=8.889, rec=0.122, cos=0.004), tot_loss_proj:2.855 [t=0.26s]
prediction: ['[CLS] is allen originally at. at 66 as himself, has stopped challenging briefly [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.810 (perp=8.432, rec=0.120, cos=0.004), tot_loss_proj:2.568 [t=0.25s]
prediction: ['[CLS] is allen originally at 1997 at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.783 (perp=8.325, rec=0.114, cos=0.004), tot_loss_proj:2.521 [t=0.26s]
prediction: ['[CLS] s allen himself at 1997 at 66 as originally, has stopped challenging. [SEP]']
[ 750/2000] tot_loss=1.777 (perp=8.325, rec=0.109, cos=0.003), tot_loss_proj:2.514 [t=0.26s]
prediction: ['[CLS] s allen himself at 1997 at 66 as originally, has stopped challenging. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.697 (perp=7.979, rec=0.098, cos=0.004), tot_loss_proj:2.489 [t=0.26s]
prediction: ['[CLS] s allen himself at at 66 as originally 1997, has stopped challenging. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.702 (perp=7.979, rec=0.103, cos=0.003), tot_loss_proj:2.491 [t=0.25s]
prediction: ['[CLS] s allen himself at at 66 as originally 1997, has stopped challenging. [SEP]']
[ 900/2000] tot_loss=1.695 (perp=7.979, rec=0.096, cos=0.003), tot_loss_proj:2.490 [t=0.26s]
prediction: ['[CLS] s allen himself at at 66 as originally 1997, has stopped challenging. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.708 (perp=7.979, rec=0.109, cos=0.003), tot_loss_proj:2.482 [t=0.26s]
prediction: ['[CLS] s allen himself at at 66 as originally 1997, has stopped challenging. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.674 (perp=7.817, rec=0.107, cos=0.003), tot_loss_proj:2.416 [t=0.26s]
prediction: ['[CLS] s allen himself at 66 as at originally 1997, has stopped challenging. [SEP]']
[1050/2000] tot_loss=1.656 (perp=7.817, rec=0.090, cos=0.003), tot_loss_proj:2.419 [t=0.26s]
prediction: ['[CLS] s allen himself at 66 as at originally 1997, has stopped challenging. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.638 (perp=7.677, rec=0.099, cos=0.003), tot_loss_proj:2.405 [t=0.26s]
prediction: ['[CLS] s allen as himself at 66 at originally 1997, has stopped challenging. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.626 (perp=7.611, rec=0.101, cos=0.003), tot_loss_proj:2.372 [t=0.27s]
prediction: ['[CLS] s allen as himself at 66 at 1997, has originally stopped challenging. [SEP]']
[1200/2000] tot_loss=1.621 (perp=7.611, rec=0.096, cos=0.003), tot_loss_proj:2.367 [t=0.25s]
prediction: ['[CLS] s allen as himself at 66 at 1997, has originally stopped challenging. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.592 (perp=7.457, rec=0.098, cos=0.003), tot_loss_proj:2.348 [t=0.25s]
prediction: ['[CLS] s allen as himself at 1997 at 66, has originally stopped challenging. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.584 (perp=7.457, rec=0.090, cos=0.003), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] s allen as himself at 1997 at 66, has originally stopped challenging. [SEP]']
[1350/2000] tot_loss=1.589 (perp=7.457, rec=0.095, cos=0.003), tot_loss_proj:2.346 [t=0.25s]
prediction: ['[CLS] s allen as himself at 1997 at 66, has originally stopped challenging. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=7.935, rec=0.097, cos=0.003), tot_loss_proj:2.465 [t=0.26s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has originally stopped challenging. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.689 (perp=7.935, rec=0.099, cos=0.003), tot_loss_proj:2.474 [t=0.26s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has originally stopped challenging. [SEP]']
[1500/2000] tot_loss=1.677 (perp=7.935, rec=0.087, cos=0.003), tot_loss_proj:2.469 [t=0.25s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has originally stopped challenging. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.677 (perp=7.935, rec=0.087, cos=0.003), tot_loss_proj:2.473 [t=0.29s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has originally stopped challenging. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.683 (perp=7.935, rec=0.093, cos=0.003), tot_loss_proj:2.476 [t=0.26s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has originally stopped challenging. [SEP]']
[1650/2000] tot_loss=1.681 (perp=7.935, rec=0.092, cos=0.003), tot_loss_proj:2.463 [t=0.26s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has originally stopped challenging. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.672 (perp=7.860, rec=0.098, cos=0.003), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has stopped originally challenging. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.667 (perp=7.860, rec=0.093, cos=0.003), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has stopped originally challenging. [SEP]']
[1800/2000] tot_loss=1.667 (perp=7.860, rec=0.092, cos=0.003), tot_loss_proj:2.588 [t=0.27s]
prediction: ['[CLS] s allen as himself at inaugural at 66, has stopped originally challenging. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.644 (perp=7.704, rec=0.100, cos=0.003), tot_loss_proj:2.600 [t=0.26s]
prediction: ['[CLS] s allen as inaugural himself at at 66, has stopped originally challenging. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.634 (perp=7.704, rec=0.091, cos=0.003), tot_loss_proj:2.597 [t=0.26s]
prediction: ['[CLS] s allen as inaugural himself at at 66, has stopped originally challenging. [SEP]']
[1950/2000] tot_loss=1.637 (perp=7.704, rec=0.093, cos=0.003), tot_loss_proj:2.596 [t=0.26s]
prediction: ['[CLS] s allen as inaugural himself at at 66, has stopped originally challenging. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.640 (perp=7.704, rec=0.097, cos=0.003), tot_loss_proj:2.591 [t=0.27s]
prediction: ['[CLS] s allen as inaugural himself at at 66, has stopped originally challenging. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s allen as inaugural himself at at 66, has stopped originally challenging. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 78.571 | r: 91.667
rouge2     | fm: 33.333 | p: 30.769 | r: 36.364
rougeL     | fm: 69.231 | p: 64.286 | r: 75.000
rougeLsum  | fm: 69.231 | p: 64.286 | r: 75.000
r1fm+r2fm = 117.949

[Aggregate metrics]:
rouge1     | fm: 91.877 | p: 91.104 | r: 92.810
rouge2     | fm: 59.597 | p: 59.366 | r: 59.923
rougeL     | fm: 79.626 | p: 79.036 | r: 80.276
rougeLsum  | fm: 79.387 | p: 78.772 | r: 80.131
r1fm+r2fm = 151.474

input #76 time: 0:11:03 | total time: 13:23:37


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
*********************************
*********************************
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9127402305603027 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8795410990715027 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8759706020355225 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.8712755441665649 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8703407049179077 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8697276711463928 for ['[CLS] county somethingdropyana gallery rural daylight tellson matthew blacksmith pencil yugoslav endless poet [SEP]']
[Init] best perm rec loss: 0.8681926727294922 for ['[CLS] gallerydrop endless tel matthewyana countylson blacksmith yugoslav rural poet something daylight pencil [SEP]']
[Init] best perm rec loss: 0.8674351572990417 for ['[CLS] pencildrop yugoslav endless something matthew gallery tel ruralyanalson daylight county blacksmith poet [SEP]']
[Init] best perm rec loss: 0.8671553730964661 for ['[CLS] blacksmith countyyana daylight endless yugoslav gallerydrop matthew pencil rural poetlson tel something [SEP]']
[Init] best perm rec loss: 0.8659143447875977 for ['[CLS] poet yugoslav county daylight matthewyanadrop something pencil gallery tel blacksmith endlesslson rural [SEP]']
[Init] best perm rec loss: 0.8652167916297913 for ['[CLS]lson gallery matthewdrop pencil something daylight yugoslav county endless tel rural blacksmith poetyana [SEP]']
[Init] best perm rec loss: 0.8632962107658386 for ['[CLS]yana poet county something matthew blacksmithdrop endless rural pencil tel daylightlson gallery yugoslav [SEP]']
[Init] best perm rec loss: 0.863000750541687 for ['[CLS] poet daylightdrop county something gallery blacksmithlson rural pencil tel yugoslav matthewyana endless [SEP]']
[Init] best perm rec loss: 0.862393856048584 for ['[CLS] poet matthewdrop yugoslav endless galleryyana something countylson tel blacksmith rural pencil daylight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.552 (perp=11.091, rec=0.312, cos=0.022), tot_loss_proj:4.048 [t=0.25s]
prediction: ['[CLS] trickp above reformation ourora has growing last acceptance substanceed of years lay [SEP]']
[ 100/2000] tot_loss=2.376 (perp=10.620, rec=0.243, cos=0.009), tot_loss_proj:3.046 [t=0.26s]
prediction: ['[CLS] soor above life its believe ultimately above being promise materialurable of believe is [SEP]']
[ 150/2000] tot_loss=1.979 (perp=8.942, rec=0.185, cos=0.006), tot_loss_proj:2.712 [t=0.27s]
prediction: ['[CLS] so promise above life its make believe above life promise materialر that believe is [SEP]']
[ 200/2000] tot_loss=1.896 (perp=8.577, rec=0.174, cos=0.006), tot_loss_proj:2.590 [t=0.26s]
prediction: ['[CLS] so promise above life its make believe above life promise materialed that believe is [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.992 (perp=8.977, rec=0.189, cos=0.008), tot_loss_proj:2.721 [t=0.27s]
prediction: ['[CLS] runs promiseed that believe above world its make believe above life promise material is [SEP]']
[ 300/2000] tot_loss=2.092 (perp=9.655, rec=0.156, cos=0.005), tot_loss_proj:2.635 [t=0.29s]
prediction: ['[CLS]ars promiseed that make above world its make believe above life promise material is [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.954 (perp=9.096, rec=0.132, cos=0.003), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS]ars promiseed that make above world make believe its above life promise material is [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.780 (perp=8.212, rec=0.134, cos=0.003), tot_loss_proj:2.664 [t=0.27s]
prediction: ['[CLS] that promise ofars make promise world make believe its above life promise material is [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.212, rec=0.119, cos=0.002), tot_loss_proj:2.667 [t=0.25s]
prediction: ['[CLS] that promise ofars make promise world make believe its above life promise material is [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.666 (perp=7.753, rec=0.113, cos=0.002), tot_loss_proj:2.555 [t=0.26s]
prediction: ['[CLS] that promise ofars make promise world make believe life above its promise material is [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.695 (perp=7.835, rec=0.125, cos=0.003), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] that promise of promise makears realm make believe life above its promise material is [SEP]']
[ 600/2000] tot_loss=1.816 (perp=8.520, rec=0.110, cos=0.002), tot_loss_proj:2.697 [t=0.26s]
prediction: ['[CLS] that promise of above makears realm make believe life above its promise material is [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.695 (perp=7.948, rec=0.104, cos=0.002), tot_loss_proj:2.606 [t=0.28s]
prediction: ['[CLS] that promise of makears realm of make believe life above its promise material is [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.643 (perp=7.718, rec=0.097, cos=0.002), tot_loss_proj:2.606 [t=0.27s]
prediction: ['[CLS] that promise of makears of realm make believe life above its promise material is [SEP]']
[ 750/2000] tot_loss=1.645 (perp=7.718, rec=0.099, cos=0.002), tot_loss_proj:2.607 [t=0.27s]
prediction: ['[CLS] that promise of makears of realm make believe life above its promise material is [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.577 (perp=7.403, rec=0.095, cos=0.002), tot_loss_proj:2.170 [t=0.27s]
prediction: ['[CLS] that promise of promise makears of realm make believe life above its material is [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.528 (perp=7.119, rec=0.102, cos=0.002), tot_loss_proj:2.161 [t=0.27s]
prediction: ['[CLS] that promise of promise makears of make believe life above its realm material is [SEP]']
[ 900/2000] tot_loss=1.533 (perp=7.119, rec=0.107, cos=0.002), tot_loss_proj:2.167 [t=0.27s]
prediction: ['[CLS] that promise of promise makears of make believe life above its realm material is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.520 (perp=7.119, rec=0.094, cos=0.002), tot_loss_proj:2.170 [t=0.26s]
prediction: ['[CLS] that promise of promise makears of make believe life above its realm material is [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.454 (perp=6.765, rec=0.099, cos=0.002), tot_loss_proj:2.015 [t=0.29s]
prediction: ['[CLS] that promise of promise makears of make believe life above its material realm is [SEP]']
[1050/2000] tot_loss=1.452 (perp=6.765, rec=0.097, cos=0.002), tot_loss_proj:2.021 [t=0.27s]
prediction: ['[CLS] that promise of promise makears of make believe life above its material realm is [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.440 (perp=6.678, rec=0.102, cos=0.002), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] that promise of make promisears of make believe life above its material realm is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.436 (perp=6.678, rec=0.098, cos=0.002), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] that promise of make promisears of make believe life above its material realm is [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.678, rec=0.095, cos=0.002), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] that promise of make promisears of make believe life above its material realm is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.431 (perp=6.678, rec=0.093, cos=0.002), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] that promise of make promisears of make believe life above its material realm is [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.382 (perp=6.391, rec=0.102, cos=0.002), tot_loss_proj:2.340 [t=0.21s]
prediction: ['[CLS] that promise of make promise of makears believe life above its material realm is [SEP]']
[1350/2000] tot_loss=1.371 (perp=6.391, rec=0.091, cos=0.002), tot_loss_proj:2.346 [t=0.21s]
prediction: ['[CLS] that promise of make promise of makears believe life above its material realm is [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.376 (perp=6.391, rec=0.096, cos=0.002), tot_loss_proj:2.332 [t=0.21s]
prediction: ['[CLS] that promise of make promise of makears believe life above its material realm is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.371 (perp=6.391, rec=0.091, cos=0.002), tot_loss_proj:2.333 [t=0.21s]
prediction: ['[CLS] that promise of make promise of makears believe life above its material realm is [SEP]']
[1500/2000] tot_loss=1.520 (perp=7.158, rec=0.086, cos=0.002), tot_loss_proj:2.386 [t=0.21s]
prediction: ['[CLS] that promise the make promise of makears believe life above its material realm is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.527 (perp=7.158, rec=0.094, cos=0.002), tot_loss_proj:2.382 [t=0.21s]
prediction: ['[CLS] that promise the make promise of makears believe life above its material realm is [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.517 (perp=7.111, rec=0.093, cos=0.002), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] that promise make the promise of makears believe life above its material realm is [SEP]']
[1650/2000] tot_loss=1.513 (perp=7.111, rec=0.089, cos=0.002), tot_loss_proj:2.235 [t=0.21s]
prediction: ['[CLS] that promise make the promise of makears believe life above its material realm is [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.450 (perp=6.756, rec=0.096, cos=0.002), tot_loss_proj:2.156 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.443 (perp=6.756, rec=0.090, cos=0.002), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
[1800/2000] tot_loss=1.433 (perp=6.756, rec=0.080, cos=0.002), tot_loss_proj:2.157 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.440 (perp=6.756, rec=0.087, cos=0.002), tot_loss_proj:2.155 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.435 (perp=6.756, rec=0.082, cos=0.002), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
[1950/2000] tot_loss=1.444 (perp=6.756, rec=0.091, cos=0.002), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.440 (perp=6.756, rec=0.087, cos=0.002), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] that promise the promise of make makears believe life above its material realm is [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] that promise make the promise of makears believe life above its material realm is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 13.793 | p: 13.333 | r: 14.286
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 104.116

[Aggregate metrics]:
rouge1     | fm: 91.848 | p: 91.036 | r: 92.792
rouge2     | fm: 58.785 | p: 58.559 | r: 59.067
rougeL     | fm: 79.186 | p: 78.578 | r: 79.882
rougeLsum  | fm: 79.233 | p: 78.654 | r: 79.947
r1fm+r2fm = 150.633

input #77 time: 0:09:52 | total time: 13:33:30


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
*********************************
*********************************
average of cosine similarity 0.9992696483604171
highest_index [0]
highest [0.9992696483604171]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9868218302726746 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9798540472984314 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8532800674438477 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8239110112190247 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.8230682015419006 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.981 (perp=8.972, rec=0.177, cos=0.010), tot_loss_proj:2.709 [t=0.20s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=1.907 (perp=8.972, rec=0.109, cos=0.004), tot_loss_proj:2.712 [t=0.20s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.893 (perp=8.972, rec=0.094, cos=0.005), tot_loss_proj:2.719 [t=0.20s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.887 (perp=8.972, rec=0.088, cos=0.004), tot_loss_proj:2.726 [t=0.21s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.886 (perp=8.972, rec=0.087, cos=0.004), tot_loss_proj:2.727 [t=0.26s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 300/2000] tot_loss=2.224 (perp=10.782, rec=0.066, cos=0.002), tot_loss_proj:2.997 [t=0.26s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.675 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.676 [t=0.27s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.667 (perp=7.958, rec=0.074, cos=0.001), tot_loss_proj:1.671 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.673 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.692 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.665 (perp=7.958, rec=0.072, cos=0.001), tot_loss_proj:1.682 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.679 [t=0.27s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.640 (perp=7.958, rec=0.047, cos=0.001), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.672 [t=0.27s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.675 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.644 (perp=7.958, rec=0.051, cos=0.001), tot_loss_proj:1.668 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.639 (perp=7.958, rec=0.046, cos=0.001), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.667 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.673 [t=0.27s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.636 (perp=7.958, rec=0.043, cos=0.001), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.944 | p: 91.132 | r: 92.865
rouge2     | fm: 59.410 | p: 59.197 | r: 59.750
rougeL     | fm: 79.458 | p: 78.880 | r: 80.126
rougeLsum  | fm: 79.526 | p: 78.921 | r: 80.235
r1fm+r2fm = 151.354

input #78 time: 0:10:36 | total time: 13:44:07


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
*********************************
*********************************
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.97676020860672 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8503931164741516 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8493977189064026 for ['[CLS]rna into [SEP]']
[Init] best rec loss: 0.8459595441818237 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8386962413787842 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8356737494468689 for ['[CLS] gray should [SEP]']
[Init] best rec loss: 0.8324992060661316 for ['[CLS] comte sculptor [SEP]']
[Init] best perm rec loss: 0.8268929123878479 for ['[CLS] sculptor comte [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.497 (perp=11.428, rec=0.207, cos=0.005), tot_loss_proj:2.639 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.449 (perp=11.428, rec=0.159, cos=0.004), tot_loss_proj:2.626 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.431 (perp=11.428, rec=0.142, cos=0.003), tot_loss_proj:2.623 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=1.967 (perp=9.381, rec=0.089, cos=0.001), tot_loss_proj:1.954 [t=0.32s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.942 (perp=9.381, rec=0.064, cos=0.001), tot_loss_proj:1.947 [t=0.25s]
prediction: ['[CLS] is fascinating [SEP]']
[ 300/2000] tot_loss=1.945 (perp=9.381, rec=0.067, cos=0.001), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.940 (perp=9.381, rec=0.063, cos=0.001), tot_loss_proj:1.948 [t=0.27s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.940 (perp=9.381, rec=0.062, cos=0.001), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] is fascinating [SEP]']
[ 450/2000] tot_loss=1.948 (perp=9.381, rec=0.071, cos=0.001), tot_loss_proj:1.946 [t=0.25s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.931 (perp=9.381, rec=0.054, cos=0.001), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.935 (perp=9.381, rec=0.057, cos=0.001), tot_loss_proj:1.946 [t=0.25s]
prediction: ['[CLS] is fascinating [SEP]']
[ 600/2000] tot_loss=1.951 (perp=9.381, rec=0.074, cos=0.001), tot_loss_proj:1.951 [t=0.26s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.795 (perp=8.695, rec=0.055, cos=0.001), tot_loss_proj:1.963 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.806 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.974 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.972 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.695, rec=0.056, cos=0.001), tot_loss_proj:1.964 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.808 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.808 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.957 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.794 (perp=8.695, rec=0.053, cos=0.001), tot_loss_proj:1.958 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.695, rec=0.055, cos=0.001), tot_loss_proj:1.963 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.810 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.792 (perp=8.695, rec=0.051, cos=0.001), tot_loss_proj:1.973 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.968 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] is fascinating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.067 | p: 91.288 | r: 92.997
rouge2     | fm: 59.974 | p: 59.685 | r: 60.273
rougeL     | fm: 79.734 | p: 79.205 | r: 80.415
rougeLsum  | fm: 79.715 | p: 79.124 | r: 80.429
r1fm+r2fm = 152.041

input #79 time: 0:11:00 | total time: 13:55:07


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
*********************************
*********************************
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9617707133293152 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9375922083854675 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9287824034690857 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9259979724884033 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9242680668830872 for ['[CLS] close blonde form parks pussy [SEP]']
[Init] best rec loss: 0.9182730913162231 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9177989959716797 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9138138294219971 for ["[CLS] jubilee'kraft it incense [SEP]"]
[Init] best perm rec loss: 0.913648784160614 for ["[CLS] incense it'jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.9132492542266846 for ["[CLS] kraft jubilee it incense'[SEP]"]
[Init] best perm rec loss: 0.9125822186470032 for ["[CLS] it incense kraft jubilee'[SEP]"]
[Init] best perm rec loss: 0.9123266935348511 for ["[CLS] kraft it'incense jubilee [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.604 (perp=11.746, rec=0.250, cos=0.005), tot_loss_proj:3.299 [t=0.25s]
prediction: ['[CLS] versa wise watersted wise [SEP]']
[ 100/2000] tot_loss=2.470 (perp=11.464, rec=0.174, cos=0.003), tot_loss_proj:2.960 [t=0.25s]
prediction: ['[CLS]zen wise ;zen wise [SEP]']
[ 150/2000] tot_loss=2.384 (perp=11.158, rec=0.150, cos=0.003), tot_loss_proj:2.873 [t=0.26s]
prediction: ['[CLS]zen wise,zen wise [SEP]']
[ 200/2000] tot_loss=2.775 (perp=13.152, rec=0.141, cos=0.003), tot_loss_proj:3.544 [t=0.27s]
prediction: ['[CLS]zen wisebellazen wise [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.622 (perp=7.418, rec=0.136, cos=0.003), tot_loss_proj:1.732 [t=0.26s]
prediction: ['[CLS] wise wizened wise [SEP]']
[ 300/2000] tot_loss=1.879 (perp=8.909, rec=0.095, cos=0.002), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] wi wizened wise [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.751 (perp=8.250, rec=0.099, cos=0.002), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.745 (perp=8.250, rec=0.093, cos=0.002), tot_loss_proj:2.015 [t=0.30s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 450/2000] tot_loss=1.740 (perp=8.250, rec=0.088, cos=0.002), tot_loss_proj:2.020 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.743 (perp=8.250, rec=0.091, cos=0.002), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.737 (perp=8.250, rec=0.085, cos=0.002), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 600/2000] tot_loss=1.750 (perp=8.250, rec=0.098, cos=0.002), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.750 (perp=8.250, rec=0.098, cos=0.002), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.739 (perp=8.250, rec=0.087, cos=0.002), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 750/2000] tot_loss=1.736 (perp=8.250, rec=0.084, cos=0.002), tot_loss_proj:2.016 [t=0.26s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=8.250, rec=0.074, cos=0.002), tot_loss_proj:2.019 [t=0.26s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.250, rec=0.070, cos=0.002), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 900/2000] tot_loss=1.731 (perp=8.250, rec=0.079, cos=0.001), tot_loss_proj:2.029 [t=0.24s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.720 (perp=8.250, rec=0.068, cos=0.001), tot_loss_proj:2.027 [t=0.27s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[1000/2000] tot_loss=1.707 (perp=8.250, rec=0.056, cos=0.001), tot_loss_proj:2.023 [t=0.26s]
prediction: ['[CLS] wizened wi wise [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.250, rec=0.071, cos=0.001), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[1100/2000] tot_loss=2.345 (perp=11.326, rec=0.078, cos=0.001), tot_loss_proj:2.840 [t=0.25s]
prediction: ['[CLS],zened wi wise [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.444 (perp=6.853, rec=0.072, cos=0.002), tot_loss_proj:1.601 [t=0.30s]
prediction: ['[CLS], wizened wise [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.853, rec=0.062, cos=0.001), tot_loss_proj:1.611 [t=0.29s]
prediction: ['[CLS], wizened wise [SEP]']
Attempt swap
[1250/2000] tot_loss=1.449 (perp=6.853, rec=0.077, cos=0.001), tot_loss_proj:1.609 [t=0.30s]
prediction: ['[CLS], wizened wise [SEP]']
Attempt swap
Put prefix at the end
[1300/2000] tot_loss=1.369 (perp=6.464, rec=0.075, cos=0.001), tot_loss_proj:1.526 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
[1350/2000] tot_loss=1.353 (perp=6.464, rec=0.059, cos=0.001), tot_loss_proj:1.527 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.359 (perp=6.464, rec=0.064, cos=0.001), tot_loss_proj:1.518 [t=0.30s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.362 (perp=6.464, rec=0.068, cos=0.001), tot_loss_proj:1.521 [t=0.31s]
prediction: ['[CLS] wizened wise, [SEP]']
[1500/2000] tot_loss=1.355 (perp=6.464, rec=0.061, cos=0.001), tot_loss_proj:1.525 [t=0.30s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.359 (perp=6.464, rec=0.065, cos=0.001), tot_loss_proj:1.522 [t=0.28s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.354 (perp=6.464, rec=0.059, cos=0.001), tot_loss_proj:1.527 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
[1650/2000] tot_loss=1.354 (perp=6.464, rec=0.059, cos=0.001), tot_loss_proj:1.526 [t=0.28s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.370 (perp=6.464, rec=0.076, cos=0.001), tot_loss_proj:1.525 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.366 (perp=6.464, rec=0.072, cos=0.001), tot_loss_proj:1.527 [t=0.31s]
prediction: ['[CLS] wizened wise, [SEP]']
[1800/2000] tot_loss=1.360 (perp=6.464, rec=0.066, cos=0.001), tot_loss_proj:1.528 [t=0.30s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.362 (perp=6.464, rec=0.068, cos=0.001), tot_loss_proj:1.520 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.361 (perp=6.464, rec=0.067, cos=0.001), tot_loss_proj:1.524 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
[1950/2000] tot_loss=1.362 (perp=6.464, rec=0.068, cos=0.001), tot_loss_proj:1.523 [t=0.31s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.361 (perp=6.464, rec=0.067, cos=0.001), tot_loss_proj:1.528 [t=0.29s]
prediction: ['[CLS] wizened wise, [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizened wise, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.196 | p: 91.386 | r: 93.097
rouge2     | fm: 59.112 | p: 58.862 | r: 59.400
rougeL     | fm: 79.707 | p: 79.159 | r: 80.393
rougeLsum  | fm: 79.670 | p: 79.155 | r: 80.368
r1fm+r2fm = 151.308

input #80 time: 0:11:28 | total time: 14:06:35


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
*********************************
*********************************
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9063941836357117 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.85554039478302 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8432484865188599 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8243643641471863 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8131975531578064 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8085715174674988 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.794321596622467 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.790020227432251 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.7895707488059998 for ['[CLS] ivy proceededplate donaldsondownvik [SEP]']
[Init] best perm rec loss: 0.7880122065544128 for ['[CLS]down ivyvik proceeded donaldsonplate [SEP]']
[Init] best perm rec loss: 0.786943256855011 for ['[CLS] ivy donaldson proceededvikplatedown [SEP]']
[Init] best perm rec loss: 0.7865198850631714 for ['[CLS]vik ivy donaldsondown proceededplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.020 (perp=12.788, rec=0.390, cos=0.072), tot_loss_proj:3.700 [t=0.24s]
prediction: ['[CLS] established growing poor impressive most not [SEP]']
[ 100/2000] tot_loss=2.163 (perp=9.568, rec=0.232, cos=0.017), tot_loss_proj:3.238 [t=0.25s]
prediction: ['[CLS] majority is not player most not [SEP]']
[ 150/2000] tot_loss=2.034 (perp=9.274, rec=0.167, cos=0.012), tot_loss_proj:3.612 [t=0.27s]
prediction: ['[CLS] impressive is not player most player [SEP]']
[ 200/2000] tot_loss=1.974 (perp=9.274, rec=0.114, cos=0.006), tot_loss_proj:3.610 [t=0.25s]
prediction: ['[CLS] impressive is not player most player [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.708 (perp=7.966, rec=0.108, cos=0.006), tot_loss_proj:3.003 [t=0.25s]
prediction: ['[CLS] player is not player most impressive [SEP]']
[ 300/2000] tot_loss=1.693 (perp=7.966, rec=0.095, cos=0.005), tot_loss_proj:3.023 [t=0.26s]
prediction: ['[CLS] player is not player most impressive [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.649 (perp=7.750, rec=0.094, cos=0.005), tot_loss_proj:2.224 [t=0.26s]
prediction: ['[CLS] player is not most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.642 (perp=7.750, rec=0.088, cos=0.005), tot_loss_proj:2.225 [t=0.25s]
prediction: ['[CLS] player is not most impressive player [SEP]']
[ 450/2000] tot_loss=1.648 (perp=7.750, rec=0.093, cos=0.005), tot_loss_proj:2.221 [t=0.26s]
prediction: ['[CLS] player is not most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.659 (perp=7.750, rec=0.105, cos=0.005), tot_loss_proj:2.227 [t=0.26s]
prediction: ['[CLS] player is not most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.638 (perp=7.750, rec=0.084, cos=0.005), tot_loss_proj:2.223 [t=0.25s]
prediction: ['[CLS] player is not most impressive player [SEP]']
[ 600/2000] tot_loss=1.643 (perp=7.750, rec=0.088, cos=0.005), tot_loss_proj:2.224 [t=0.24s]
prediction: ['[CLS] player is not most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.638 (perp=7.750, rec=0.084, cos=0.005), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] player is not most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.848 (perp=8.791, rec=0.085, cos=0.005), tot_loss_proj:2.471 [t=0.26s]
prediction: ['[CLS] not is not most impressive player [SEP]']
[ 750/2000] tot_loss=1.858 (perp=8.791, rec=0.096, cos=0.005), tot_loss_proj:2.469 [t=0.28s]
prediction: ['[CLS] not is not most impressive player [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.677 (perp=7.962, rec=0.080, cos=0.005), tot_loss_proj:2.060 [t=0.24s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=7.962, rec=0.090, cos=0.005), tot_loss_proj:2.065 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[ 900/2000] tot_loss=1.684 (perp=7.962, rec=0.087, cos=0.005), tot_loss_proj:2.061 [t=0.26s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.686 (perp=7.962, rec=0.089, cos=0.004), tot_loss_proj:2.061 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.690 (perp=7.962, rec=0.094, cos=0.004), tot_loss_proj:2.065 [t=0.27s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1050/2000] tot_loss=1.689 (perp=7.962, rec=0.092, cos=0.004), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.677 (perp=7.962, rec=0.081, cos=0.004), tot_loss_proj:2.061 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.684 (perp=7.962, rec=0.087, cos=0.004), tot_loss_proj:2.063 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1200/2000] tot_loss=1.683 (perp=7.962, rec=0.087, cos=0.004), tot_loss_proj:2.067 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.690 (perp=7.962, rec=0.093, cos=0.004), tot_loss_proj:2.060 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.686 (perp=7.962, rec=0.090, cos=0.004), tot_loss_proj:2.063 [t=0.28s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1350/2000] tot_loss=1.685 (perp=7.962, rec=0.089, cos=0.004), tot_loss_proj:2.063 [t=0.26s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.688 (perp=7.962, rec=0.091, cos=0.004), tot_loss_proj:2.066 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=7.962, rec=0.090, cos=0.004), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1500/2000] tot_loss=1.681 (perp=7.962, rec=0.085, cos=0.004), tot_loss_proj:2.066 [t=0.28s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.690 (perp=7.962, rec=0.094, cos=0.004), tot_loss_proj:2.066 [t=0.27s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=7.962, rec=0.077, cos=0.004), tot_loss_proj:2.063 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1650/2000] tot_loss=1.681 (perp=7.962, rec=0.085, cos=0.004), tot_loss_proj:2.064 [t=0.28s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.675 (perp=7.962, rec=0.078, cos=0.004), tot_loss_proj:2.067 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.683 (perp=7.962, rec=0.086, cos=0.004), tot_loss_proj:2.060 [t=0.27s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1800/2000] tot_loss=1.683 (perp=7.962, rec=0.087, cos=0.004), tot_loss_proj:2.058 [t=0.26s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.680 (perp=7.962, rec=0.084, cos=0.004), tot_loss_proj:2.066 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=7.962, rec=0.085, cos=0.004), tot_loss_proj:2.058 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
[1950/2000] tot_loss=1.685 (perp=7.962, rec=0.088, cos=0.004), tot_loss_proj:2.063 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.689 (perp=7.962, rec=0.093, cos=0.004), tot_loss_proj:2.059 [t=0.25s]
prediction: ['[CLS] is not not most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not not most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 92.050 | p: 91.304 | r: 92.991
rouge2     | fm: 59.364 | p: 59.042 | r: 59.635
rougeL     | fm: 79.832 | p: 79.301 | r: 80.506
rougeLsum  | fm: 79.789 | p: 79.225 | r: 80.440
r1fm+r2fm = 151.415

input #81 time: 0:10:51 | total time: 14:17:27


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
*********************************
*********************************
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.98771733045578 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9761659502983093 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9474851489067078 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9335925579071045 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9326500296592712 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8672366738319397 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8271898627281189 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8216337561607361 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8212171196937561 for ['[CLS]basket plumage whoeverach respective role recordfur [SEP]']
[Init] best perm rec loss: 0.8198072910308838 for ['[CLS] respectivebasket record plumagefurach role whoever [SEP]']
[Init] best perm rec loss: 0.819161593914032 for ['[CLS] respectiveach whoeverfur role record plumagebasket [SEP]']
[Init] best perm rec loss: 0.81831294298172 for ['[CLS]fur respective rolebasketach plumage whoever record [SEP]']
[Init] best perm rec loss: 0.8175076842308044 for ['[CLS] whoeverbasket role respective plumagefurach record [SEP]']
[Init] best perm rec loss: 0.8163747787475586 for ['[CLS]furbasket respective roleach plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.668 (perp=12.195, rec=0.223, cos=0.006), tot_loss_proj:3.216 [t=0.25s]
prediction: ['[CLS] sloppy undone aryhus undone script a [SEP]']
[ 100/2000] tot_loss=2.142 (perp=10.264, rec=0.087, cos=0.003), tot_loss_proj:2.423 [t=0.24s]
prediction: ['[CLS] sloppy undone s by a sloppy script it [SEP]']
[ 150/2000] tot_loss=2.130 (perp=10.264, rec=0.075, cos=0.002), tot_loss_proj:2.425 [t=0.27s]
prediction: ['[CLS] sloppy undone s by a sloppy script it [SEP]']
[ 200/2000] tot_loss=2.125 (perp=10.264, rec=0.069, cos=0.003), tot_loss_proj:2.418 [t=0.26s]
prediction: ['[CLS] sloppy undone s by a sloppy script it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.880 (perp=9.029, rec=0.072, cos=0.002), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] sloppy s undone by a sloppy script it [SEP]']
[ 300/2000] tot_loss=1.884 (perp=9.029, rec=0.077, cos=0.002), tot_loss_proj:2.131 [t=0.25s]
prediction: ['[CLS] sloppy s undone by a sloppy script it [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.626 (perp=7.783, rec=0.067, cos=0.002), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] it sloppy s undone by a sloppy script [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.563 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.639 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 450/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.633 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.554 (perp=7.465, rec=0.059, cos=0.002), tot_loss_proj:1.637 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.638 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 600/2000] tot_loss=1.559 (perp=7.465, rec=0.065, cos=0.002), tot_loss_proj:1.640 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.558 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.637 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.561 (perp=7.465, rec=0.066, cos=0.002), tot_loss_proj:1.635 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 750/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.634 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.556 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.646 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.564 (perp=7.465, rec=0.070, cos=0.002), tot_loss_proj:1.648 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 900/2000] tot_loss=1.566 (perp=7.465, rec=0.072, cos=0.002), tot_loss_proj:1.637 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.561 (perp=7.465, rec=0.067, cos=0.002), tot_loss_proj:1.640 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.555 (perp=7.465, rec=0.060, cos=0.002), tot_loss_proj:1.644 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.639 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.563 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.647 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.567 (perp=7.465, rec=0.072, cos=0.002), tot_loss_proj:1.648 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1200/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.645 [t=0.28s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.561 (perp=7.465, rec=0.067, cos=0.002), tot_loss_proj:1.643 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.560 (perp=7.465, rec=0.065, cos=0.002), tot_loss_proj:1.648 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1350/2000] tot_loss=1.562 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.636 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.556 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.638 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.640 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1500/2000] tot_loss=1.555 (perp=7.465, rec=0.060, cos=0.002), tot_loss_proj:1.640 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.563 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.635 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.556 (perp=7.465, rec=0.061, cos=0.002), tot_loss_proj:1.632 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1650/2000] tot_loss=1.564 (perp=7.465, rec=0.069, cos=0.002), tot_loss_proj:1.643 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.562 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1750/2000] tot_loss=1.560 (perp=7.465, rec=0.065, cos=0.002), tot_loss_proj:1.644 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1800/2000] tot_loss=1.562 (perp=7.465, rec=0.067, cos=0.002), tot_loss_proj:1.645 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1850/2000] tot_loss=1.561 (perp=7.465, rec=0.067, cos=0.002), tot_loss_proj:1.651 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.565 (perp=7.465, rec=0.071, cos=0.002), tot_loss_proj:1.645 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1950/2000] tot_loss=1.553 (perp=7.465, rec=0.058, cos=0.002), tot_loss_proj:1.647 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.555 (perp=7.465, rec=0.060, cos=0.002), tot_loss_proj:1.652 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 92.120 | p: 91.287 | r: 93.096
rouge2     | fm: 59.681 | p: 59.352 | r: 60.081
rougeL     | fm: 79.911 | p: 79.318 | r: 80.642
rougeLsum  | fm: 79.894 | p: 79.257 | r: 80.646
r1fm+r2fm = 151.800

input #82 time: 0:10:55 | total time: 14:28:22


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
*********************************
*********************************
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9601501822471619 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9566210508346558 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9550451636314392 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9463936686515808 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.887312650680542 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8696892261505127 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8692896366119385 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8648756146430969 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8604941964149475 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8593842387199402 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8368008732795715 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8151112198829651 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8039038181304932 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8021044135093689 for ['[CLS] vice neck pitch comprehensive stew follows boys nearly residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.848 (perp=12.579, rec=0.303, cos=0.030), tot_loss_proj:3.400 [t=0.25s]
prediction: ['[CLS] know raise growing it culture become when lily study tomorrow [SEP]']
[ 100/2000] tot_loss=2.143 (perp=9.656, rec=0.202, cos=0.009), tot_loss_proj:2.719 [t=0.24s]
prediction: ['[CLS] know be what it culture become when it study kim [SEP]']
[ 150/2000] tot_loss=2.237 (perp=10.405, rec=0.152, cos=0.005), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] know be what it when grows when up find ray [SEP]']
[ 200/2000] tot_loss=2.111 (perp=9.950, rec=0.117, cos=0.004), tot_loss_proj:2.915 [t=0.27s]
prediction: ['[CLS] know be wants it when grows when up getting it [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.215 (perp=9.984, rec=0.210, cos=0.009), tot_loss_proj:3.233 [t=0.25s]
prediction: ['[CLS] know be wants it logo grows up when getting it [SEP]']
[ 300/2000] tot_loss=2.207 (perp=10.425, rec=0.120, cos=0.002), tot_loss_proj:3.219 [t=0.26s]
prediction: ['[CLS] know be wants ittium grows up when what it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.942 (perp=9.198, rec=0.100, cos=0.002), tot_loss_proj:2.763 [t=0.26s]
prediction: ['[CLS] know be wants it whattium grows up when it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.720 (perp=8.143, rec=0.089, cos=0.002), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] know be what it wantsmarine grows up when it [SEP]']
[ 450/2000] tot_loss=1.717 (perp=8.143, rec=0.087, cos=0.002), tot_loss_proj:2.401 [t=0.25s]
prediction: ['[CLS] know be what it wantsmarine grows up when it [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.551 (perp=7.328, rec=0.084, cos=0.002), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] know be what it wantsmarine when it grows up [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.384 (perp=6.483, rec=0.086, cos=0.002), tot_loss_proj:1.916 [t=0.26s]
prediction: ['[CLS] know be what it wants when it grows uptime [SEP]']
[ 600/2000] tot_loss=1.369 (perp=6.483, rec=0.071, cos=0.002), tot_loss_proj:1.913 [t=0.25s]
prediction: ['[CLS] know be what it wants when it grows uptime [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.344 (perp=6.297, rec=0.083, cos=0.002), tot_loss_proj:1.730 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows uptime [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.336 (perp=6.297, rec=0.075, cos=0.002), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows uptime [SEP]']
[ 750/2000] tot_loss=1.333 (perp=6.297, rec=0.072, cos=0.002), tot_loss_proj:1.732 [t=0.26s]
prediction: ['[CLS] know what it wants be when it grows uptime [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.330 (perp=6.297, rec=0.069, cos=0.002), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] know what it wants be when it grows uptime [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.321 (perp=6.297, rec=0.060, cos=0.002), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows uptime [SEP]']
[ 900/2000] tot_loss=1.334 (perp=6.297, rec=0.073, cos=0.002), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows uptime [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.200 (perp=5.676, rec=0.064, cos=0.002), tot_loss_proj:1.452 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.217 (perp=5.676, rec=0.080, cos=0.002), tot_loss_proj:1.444 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
[1050/2000] tot_loss=1.202 (perp=5.676, rec=0.065, cos=0.002), tot_loss_proj:1.447 [t=0.25s]
prediction: ['[CLS] know what it wants be when it grows up to [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.014 (perp=4.691, rec=0.074, cos=0.002), tot_loss_proj:1.071 [t=0.26s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.014 (perp=4.691, rec=0.074, cos=0.002), tot_loss_proj:1.073 [t=0.25s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1200/2000] tot_loss=1.011 (perp=4.691, rec=0.071, cos=0.002), tot_loss_proj:1.069 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.007 (perp=4.691, rec=0.068, cos=0.002), tot_loss_proj:1.073 [t=0.27s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.013 (perp=4.691, rec=0.073, cos=0.002), tot_loss_proj:1.078 [t=0.26s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1350/2000] tot_loss=1.014 (perp=4.691, rec=0.074, cos=0.002), tot_loss_proj:1.065 [t=0.25s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.010 (perp=4.691, rec=0.070, cos=0.002), tot_loss_proj:1.071 [t=0.27s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.006 (perp=4.691, rec=0.066, cos=0.002), tot_loss_proj:1.066 [t=0.25s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1500/2000] tot_loss=1.008 (perp=4.691, rec=0.068, cos=0.002), tot_loss_proj:1.076 [t=0.25s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.012 (perp=4.691, rec=0.072, cos=0.002), tot_loss_proj:1.075 [t=0.27s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.016 (perp=4.691, rec=0.076, cos=0.002), tot_loss_proj:1.071 [t=0.27s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1650/2000] tot_loss=1.002 (perp=4.691, rec=0.063, cos=0.002), tot_loss_proj:1.069 [t=0.26s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.014 (perp=4.691, rec=0.074, cos=0.002), tot_loss_proj:1.067 [t=0.27s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.006 (perp=4.691, rec=0.066, cos=0.002), tot_loss_proj:1.070 [t=0.26s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1800/2000] tot_loss=1.002 (perp=4.691, rec=0.062, cos=0.002), tot_loss_proj:1.066 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.010 (perp=4.691, rec=0.070, cos=0.002), tot_loss_proj:1.077 [t=0.28s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.009 (perp=4.691, rec=0.069, cos=0.002), tot_loss_proj:1.075 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1950/2000] tot_loss=1.003 (perp=4.691, rec=0.063, cos=0.002), tot_loss_proj:1.071 [t=0.26s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.012 (perp=4.691, rec=0.073, cos=0.002), tot_loss_proj:1.074 [t=0.25s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.273 | p: 91.469 | r: 93.231
rouge2     | fm: 60.295 | p: 59.992 | r: 60.678
rougeL     | fm: 80.218 | p: 79.657 | r: 80.899
rougeLsum  | fm: 80.263 | p: 79.713 | r: 81.006
r1fm+r2fm = 152.567

input #83 time: 0:10:53 | total time: 14:39:16


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
*********************************
*********************************
average of cosine similarity 0.9991125724774639
highest_index [0]
highest [0.9991125724774639]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9286046624183655 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9211990833282471 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.8995694518089294 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8926138281822205 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8923629522323608 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8866891264915466 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8839888572692871 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8611317276954651 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best perm rec loss: 0.8604739904403687 for ['[CLS] sar block is whetherness project dark [SEP]']
[Init] best perm rec loss: 0.8604679703712463 for ['[CLS] block dark sar whether isness project [SEP]']
[Init] best perm rec loss: 0.85843825340271 for ['[CLS] whether sar project block is darkness [SEP]']
[Init] best perm rec loss: 0.8576532006263733 for ['[CLS] whether is block projectness dark sar [SEP]']
[Init] best perm rec loss: 0.8570180535316467 for ['[CLS] sar block project dark is whetherness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.578 (perp=11.655, rec=0.236, cos=0.011), tot_loss_proj:3.036 [t=0.29s]
prediction: ['[CLS] they lost unable ability think larry people [SEP]']
[ 100/2000] tot_loss=2.174 (perp=10.255, rec=0.119, cos=0.004), tot_loss_proj:2.630 [t=0.29s]
prediction: ['[CLS] have lost people ability thinking people [SEP]']
[ 150/2000] tot_loss=1.522 (perp=7.139, rec=0.091, cos=0.003), tot_loss_proj:1.905 [t=0.30s]
prediction: ['[CLS] have lost the ability think to people [SEP]']
[ 200/2000] tot_loss=1.493 (perp=7.139, rec=0.063, cos=0.002), tot_loss_proj:1.910 [t=0.29s]
prediction: ['[CLS] have lost the ability think to people [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.193 (perp=5.494, rec=0.092, cos=0.003), tot_loss_proj:1.493 [t=0.29s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
[ 300/2000] tot_loss=1.171 (perp=5.494, rec=0.071, cos=0.002), tot_loss_proj:1.485 [t=0.29s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.168 (perp=5.494, rec=0.068, cos=0.002), tot_loss_proj:1.493 [t=0.31s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.037 [t=0.31s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 450/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.032 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.035 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.032 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.038 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.008 (perp=4.681, rec=0.070, cos=0.002), tot_loss_proj:1.036 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.028 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.031 [t=0.31s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.033 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.996 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.041 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.036 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.043 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.031 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.026 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.034 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.042 [t=0.30s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.033 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.043 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=0.989 (perp=4.681, rec=0.051, cos=0.002), tot_loss_proj:1.029 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.039 [t=0.29s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.039 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.030 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.032 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=0.992 (perp=4.681, rec=0.054, cos=0.002), tot_loss_proj:1.036 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.032 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.034 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.039 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.027 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.038 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.033 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=0.990 (perp=4.681, rec=0.052, cos=0.002), tot_loss_proj:1.037 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.028 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.007 (perp=4.681, rec=0.069, cos=0.002), tot_loss_proj:1.047 [t=0.28s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.336 | p: 91.541 | r: 93.300
rouge2     | fm: 60.595 | p: 60.345 | r: 60.978
rougeL     | fm: 80.512 | p: 79.908 | r: 81.230
rougeLsum  | fm: 80.366 | p: 79.780 | r: 81.134
r1fm+r2fm = 152.931

input #84 time: 0:11:52 | total time: 14:51:08


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
*********************************
*********************************
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9699996709823608 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9557927250862122 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.933201789855957 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8898030519485474 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8735714554786682 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8669417500495911 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8647000193595886 for ['[CLS]lein laps roadrman indian background indiesthing defender fallen [SEP]']
[Init] best perm rec loss: 0.8642165064811707 for ['[CLS]rmanlein indies lapsthing fallen defender background road indian [SEP]']
[Init] best perm rec loss: 0.8628117442131042 for ['[CLS] indiesleinthing lapsrman indian defender background fallen road [SEP]']
[Init] best perm rec loss: 0.8601159453392029 for ['[CLS] indieslein fallen road background laps indianthing defenderrman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.990 (perp=8.481, rec=0.278, cos=0.016), tot_loss_proj:2.866 [t=0.25s]
prediction: ['[CLS] unfortunately very unfortunately good not also good good. unfortunately [SEP]']
[ 100/2000] tot_loss=1.731 (perp=7.818, rec=0.162, cos=0.006), tot_loss_proj:2.302 [t=0.28s]
prediction: ['[CLS] unfortunately still unfortunately not not also good good good. [SEP]']
[ 150/2000] tot_loss=1.884 (perp=8.794, rec=0.121, cos=0.005), tot_loss_proj:2.657 [t=0.26s]
prediction: ['[CLS] unfortunately s unfortunately not not also very good good usually [SEP]']
[ 200/2000] tot_loss=1.890 (perp=8.978, rec=0.090, cos=0.004), tot_loss_proj:3.064 [t=0.26s]
prediction: ['[CLS] unfortunately s unfortunately not not also very. good perhaps [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.799 (perp=8.435, rec=0.106, cos=0.006), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS], s unfortunately not not also very good especially shall [SEP]']
[ 300/2000] tot_loss=1.845 (perp=8.798, rec=0.082, cos=0.003), tot_loss_proj:3.641 [t=0.27s]
prediction: ['[CLS], s unfortunately not s also very good especially shall [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.621 (perp=7.633, rec=0.091, cos=0.003), tot_loss_proj:3.397 [t=0.26s]
prediction: ['[CLS] unfortunately, it not s also very good especially shall [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.397 (perp=6.468, rec=0.100, cos=0.003), tot_loss_proj:1.560 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not very good especially entirely [SEP]']
[ 450/2000] tot_loss=1.381 (perp=6.468, rec=0.085, cos=0.002), tot_loss_proj:1.562 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not very good especially entirely [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.345 (perp=6.323, rec=0.079, cos=0.002), tot_loss_proj:1.527 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very entirely especially good [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.345 (perp=6.323, rec=0.079, cos=0.002), tot_loss_proj:1.534 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not very entirely especially good [SEP]']
[ 600/2000] tot_loss=1.347 (perp=6.323, rec=0.080, cos=0.002), tot_loss_proj:1.529 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s not very entirely especially good [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.544 (perp=7.354, rec=0.071, cos=0.002), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s very not entirely... good [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.424 (perp=6.665, rec=0.089, cos=0.002), tot_loss_proj:1.637 [t=0.26s]
prediction: ['[CLS] unfortunately, it also s very not entirely good... [SEP]']
[ 750/2000] tot_loss=1.411 (perp=6.665, rec=0.075, cos=0.002), tot_loss_proj:1.634 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s very not entirely good... [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.554 (perp=7.386, rec=0.075, cos=0.002), tot_loss_proj:1.842 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s not very would good... [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.417 (perp=6.690, rec=0.076, cos=0.002), tot_loss_proj:1.713 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not very good would... [SEP]']
[ 900/2000] tot_loss=1.423 (perp=6.690, rec=0.083, cos=0.002), tot_loss_proj:1.717 [t=0.27s]
prediction: ['[CLS] unfortunately, it also s not very good would... [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.401 (perp=6.656, rec=0.067, cos=0.002), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s not very good... would [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.357 (perp=6.385, rec=0.077, cos=0.002), tot_loss_proj:1.679 [t=0.25s]
prediction: ['[CLS] unfortunately, it would also s not very good... [SEP]']
[1050/2000] tot_loss=1.357 (perp=6.385, rec=0.077, cos=0.002), tot_loss_proj:1.677 [t=0.25s]
prediction: ['[CLS] unfortunately, it would also s not very good... [SEP]']
Attempt swap
[1100/2000] tot_loss=1.355 (perp=6.385, rec=0.076, cos=0.002), tot_loss_proj:1.682 [t=0.26s]
prediction: ['[CLS] unfortunately, it would also s not very good... [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.060 (perp=4.934, rec=0.071, cos=0.002), tot_loss_proj:1.149 [t=0.25s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
[1200/2000] tot_loss=1.060 (perp=4.934, rec=0.070, cos=0.002), tot_loss_proj:1.148 [t=0.25s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.066 (perp=4.934, rec=0.077, cos=0.002), tot_loss_proj:1.155 [t=0.25s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.062 (perp=4.934, rec=0.073, cos=0.002), tot_loss_proj:1.144 [t=0.27s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
[1350/2000] tot_loss=1.066 (perp=4.934, rec=0.077, cos=0.002), tot_loss_proj:1.146 [t=0.25s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.068 (perp=4.934, rec=0.079, cos=0.002), tot_loss_proj:1.154 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.069 (perp=4.934, rec=0.080, cos=0.002), tot_loss_proj:1.147 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
[1500/2000] tot_loss=1.058 (perp=4.934, rec=0.069, cos=0.002), tot_loss_proj:1.151 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.063 (perp=4.934, rec=0.074, cos=0.002), tot_loss_proj:1.140 [t=0.31s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.059 (perp=4.934, rec=0.070, cos=0.002), tot_loss_proj:1.142 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
[1650/2000] tot_loss=1.071 (perp=4.934, rec=0.081, cos=0.002), tot_loss_proj:1.143 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.068 (perp=4.934, rec=0.079, cos=0.002), tot_loss_proj:1.145 [t=0.25s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.057 (perp=4.934, rec=0.068, cos=0.002), tot_loss_proj:1.148 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
[1800/2000] tot_loss=1.056 (perp=4.934, rec=0.067, cos=0.002), tot_loss_proj:1.141 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.052 (perp=4.934, rec=0.063, cos=0.002), tot_loss_proj:1.157 [t=0.25s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.070 (perp=4.934, rec=0.080, cos=0.002), tot_loss_proj:1.146 [t=0.28s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
[1950/2000] tot_loss=1.054 (perp=4.934, rec=0.065, cos=0.002), tot_loss_proj:1.146 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.934, rec=0.064, cos=0.002), tot_loss_proj:1.141 [t=0.26s]
prediction: ["[CLS] unfortunately, it's also not very good... [SEP]"]
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it's also not very good... [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.444 | p: 91.662 | r: 93.364
rouge2     | fm: 61.132 | p: 60.872 | r: 61.519
rougeL     | fm: 80.628 | p: 80.065 | r: 81.299
rougeLsum  | fm: 80.621 | p: 80.117 | r: 81.359
r1fm+r2fm = 153.576

input #85 time: 0:10:58 | total time: 15:02:07


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
*********************************
*********************************
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9209051132202148 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9168149828910828 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8586238026618958 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7911268472671509 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7695991396903992 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7565065622329712 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7532469630241394 for ['[CLS] alright round liberated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.626 (perp=11.170, rec=0.379, cos=0.013), tot_loss_proj:3.436 [t=0.25s]
prediction: ['[CLS] clarity [SEP] dinah [SEP]']
[ 100/2000] tot_loss=1.939 (perp=8.317, rec=0.268, cos=0.007), tot_loss_proj:1.757 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 150/2000] tot_loss=2.261 (perp=10.257, rec=0.204, cos=0.006), tot_loss_proj:2.427 [t=0.27s]
prediction: ['[CLS] clarity emotional emotional [SEP]']
[ 200/2000] tot_loss=2.598 (perp=12.012, rec=0.191, cos=0.005), tot_loss_proj:3.206 [t=0.26s]
prediction: ['[CLS] clarity [SEP] emotional [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.138 (perp=9.365, rec=0.256, cos=0.009), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] [SEP] emotional clarity [SEP]']
[ 300/2000] tot_loss=1.791 (perp=8.211, rec=0.143, cos=0.005), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.773 (perp=8.211, rec=0.127, cos=0.004), tot_loss_proj:1.867 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.765 (perp=8.211, rec=0.119, cos=0.004), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=1.765 (perp=8.211, rec=0.119, cos=0.004), tot_loss_proj:1.868 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.744 (perp=8.211, rec=0.098, cos=0.004), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.748 (perp=8.211, rec=0.101, cos=0.004), tot_loss_proj:1.863 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.741 (perp=8.211, rec=0.095, cos=0.004), tot_loss_proj:1.865 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.750 (perp=8.211, rec=0.103, cos=0.004), tot_loss_proj:1.872 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.744 (perp=8.211, rec=0.097, cos=0.004), tot_loss_proj:1.872 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.742 (perp=8.211, rec=0.096, cos=0.004), tot_loss_proj:1.875 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.744 (perp=8.211, rec=0.098, cos=0.004), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.740 (perp=8.211, rec=0.094, cos=0.004), tot_loss_proj:1.874 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.753 (perp=8.211, rec=0.107, cos=0.004), tot_loss_proj:1.869 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.729 (perp=8.211, rec=0.083, cos=0.004), tot_loss_proj:1.868 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.751 (perp=8.211, rec=0.105, cos=0.004), tot_loss_proj:1.877 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.729 (perp=8.211, rec=0.083, cos=0.004), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.748 (perp=8.211, rec=0.102, cos=0.004), tot_loss_proj:1.881 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.739 (perp=8.211, rec=0.093, cos=0.004), tot_loss_proj:1.876 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.749 (perp=8.211, rec=0.103, cos=0.004), tot_loss_proj:1.871 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.747 (perp=8.211, rec=0.101, cos=0.004), tot_loss_proj:1.868 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=8.211, rec=0.088, cos=0.004), tot_loss_proj:1.875 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.745 (perp=8.211, rec=0.099, cos=0.004), tot_loss_proj:1.870 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.211, rec=0.090, cos=0.004), tot_loss_proj:1.866 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.753 (perp=8.211, rec=0.107, cos=0.004), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.750 (perp=8.211, rec=0.104, cos=0.004), tot_loss_proj:1.869 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.752 (perp=8.211, rec=0.106, cos=0.004), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.743 (perp=8.211, rec=0.097, cos=0.004), tot_loss_proj:1.876 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.749 (perp=8.211, rec=0.103, cos=0.004), tot_loss_proj:1.870 [t=0.27s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.738 (perp=8.211, rec=0.091, cos=0.004), tot_loss_proj:1.877 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.739 (perp=8.211, rec=0.093, cos=0.004), tot_loss_proj:1.878 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.727 (perp=8.211, rec=0.081, cos=0.004), tot_loss_proj:1.880 [t=0.29s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.742 (perp=8.211, rec=0.096, cos=0.004), tot_loss_proj:1.870 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.734 (perp=8.211, rec=0.087, cos=0.004), tot_loss_proj:1.879 [t=0.26s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.732 (perp=8.211, rec=0.085, cos=0.004), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.743 (perp=8.211, rec=0.097, cos=0.004), tot_loss_proj:1.872 [t=0.29s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.465 | p: 91.680 | r: 93.386
rouge2     | fm: 60.734 | p: 60.393 | r: 61.092
rougeL     | fm: 80.603 | p: 80.095 | r: 81.291
rougeLsum  | fm: 80.721 | p: 80.162 | r: 81.396
r1fm+r2fm = 153.199

input #86 time: 0:10:56 | total time: 15:13:03


Running input #87 of 100.
reference: 
========================
propulsive 
========================
*********************************
*********************************
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8846666812896729 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7553390860557556 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7130892872810364 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7034943103790283 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6935102939605713 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6770039796829224 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6745697855949402 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.535, rec=0.343, cos=0.038), tot_loss_proj:3.367 [t=0.25s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=1.628 (perp=7.258, rec=0.170, cos=0.007), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.568 (perp=7.258, rec=0.113, cos=0.003), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.526 (perp=7.258, rec=0.072, cos=0.002), tot_loss_proj:1.537 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.618 (perp=7.258, rec=0.154, cos=0.013), tot_loss_proj:1.521 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.530 (perp=7.258, rec=0.077, cos=0.002), tot_loss_proj:1.532 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.002), tot_loss_proj:1.538 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.002), tot_loss_proj:1.526 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.538 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.516 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.535 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.495 (perp=7.258, rec=0.042, cos=0.002), tot_loss_proj:1.527 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.533 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.258, rec=0.070, cos=0.002), tot_loss_proj:1.544 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.513 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.522 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.539 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.503 (perp=7.258, rec=0.050, cos=0.001), tot_loss_proj:1.549 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.529 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.528 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.493 (perp=7.258, rec=0.040, cos=0.001), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.502 (perp=7.258, rec=0.049, cos=0.001), tot_loss_proj:1.538 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.527 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.530 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.539 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.537 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.545 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.499 (perp=7.258, rec=0.046, cos=0.001), tot_loss_proj:1.528 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.539 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.550 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.524 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.500 (perp=7.258, rec=0.047, cos=0.001), tot_loss_proj:1.543 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.531 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.504 (perp=7.258, rec=0.051, cos=0.001), tot_loss_proj:1.526 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.548 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.536 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.531 (perp=7.258, rec=0.078, cos=0.001), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.528 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.522 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.591 | p: 91.839 | r: 93.488
rouge2     | fm: 61.121 | p: 60.822 | r: 61.508
rougeL     | fm: 80.951 | p: 80.354 | r: 81.647
rougeLsum  | fm: 80.930 | p: 80.350 | r: 81.606
r1fm+r2fm = 153.712

input #87 time: 0:10:54 | total time: 15:23:58


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
*********************************
*********************************
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9809058904647827 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.944068431854248 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9212347269058228 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.917607307434082 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9161702394485474 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9086971879005432 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.9049574136734009 for ['[CLS] towards scene too tram beetle vice updated being west grips above.olaignment golden gloss hot boundaries slave satellite warm reasons meant chord antagonist now trick migration part pennsylvania julius following embraced center rebound miss together hero bail museum days four rash [SEP]']
[Init] best rec loss: 0.9017528891563416 for ["[CLS]⁺'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.8954169154167175 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8942180275917053 for ['[CLS] pondered allowed where! aunt never designated starting demi as programs home hadn piston spanning legitimate engine exodusbbed? insanity machine immortality [UNK] reform harmon network elevated nets today according baronet ki exchanged ) signed employees mandarin force close won landing observation [SEP]']
[Init] best perm rec loss: 0.8933555483818054 for ['[CLS] landing signed? ki legitimate network harmon starting demi observation! exchanged where aunt programs exodus insanity ) never today nets pistonbbed mandarin allowed baronet close won [UNK] reform force pondered employees home engine designated as spanning according elevated machine hadn immortality [SEP]']
[Init] best perm rec loss: 0.8925676345825195 for ['[CLS] machine? never immortality exodus landing exchanged! harmon force spanning according as reform [UNK] won where programs auntbbed home employees pondered insanity observation piston today network allowed close ) starting hadn mandarin nets demi elevated legitimate signed engine baronet designated ki [SEP]']
[Init] best perm rec loss: 0.8924002051353455 for ['[CLS] harmon today piston? [UNK] won legitimate machine designated where landing starting allowed demibbed close engine elevated baronet nets ) hadn aunt exchanged never! according employees spanning mandarin insanity exodus immortality signed reform observation as force pondered programs network ki home [SEP]']
[Init] best perm rec loss: 0.8921587467193604 for ['[CLS] allowed hadn legitimate signed piston mandarin exodus reform pondered as observation ) ki engine never network insanitybbed aunt? immortality force demi starting today! where nets machine landing [UNK] home close spanning exchanged designated won employees baronet programs elevated according harmon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.578 (perp=11.381, rec=0.296, cos=0.006), tot_loss_proj:4.170 [t=0.26s]
prediction: ['[CLS] youth henry william henry henry and which love. almost productionsless pictures davidstone francis gentle agency ann ) lovent michiganal. and which lankan christian understanding chennai editor. : evening elise loved cross comes beauty lacked reversed understands [SEP]']
[ 100/2000] tot_loss=2.540 (perp=11.040, rec=0.324, cos=0.007), tot_loss_proj:4.149 [t=0.26s]
prediction: ['[CLS] youth henry as. henryiously a s.... ˈ & romance stepness william measures series ann and a 京 thomas who the. winner morning [SEP] understands romance bowen,drik. smashwords grandness. love lacked inter understands [SEP]']
[ 150/2000] tot_loss=2.494 (perp=11.004, rec=0.289, cos=0.005), tot_loss_proj:3.741 [t=0.26s]
prediction: ['[CLS] clay daniel re. nothing♯ t o. t grew, romance.field rachel minute. playhouse andwhile pleasure peace finn was does "in [SEP] understands romance melanie, ‿ upon ← greatness they love pleasure inter understood [SEP]']
[ 200/2000] tot_loss=2.488 (perp=10.935, rec=0.293, cos=0.008), tot_loss_proj:3.897 [t=0.25s]
prediction: ['[CLS] love daniel.. would a p l. p as romancenessfield elizabeth grand into madame and theoretical potential : akin. w that banjo our understands ⇄ melanie frames. fictional ª grand love merely love calm uncomfortable understands [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.489 (perp=10.820, rec=0.319, cos=0.006), tot_loss_proj:3.677 [t=0.25s]
prediction: ['[CLS] love daniel.neas the ₤ t.. woodович or romancenifiedham elizabeth grand that the and teaming buddha. ). " difference9 our understands imagination joy,. joy ª great marriage cannot love ᅢ anderson understands [SEP]']
[ 300/2000] tot_loss=2.407 (perp=10.662, rec=0.270, cos=0.004), tot_loss_proj:3.660 [t=0.26s]
prediction: ['[CLS] love p. revolves calm already t.. john. we romance whose miller derivative grand that the in tale profit. ir. - before elected [SEP] understands imagination faith the. nova ª great love herbal love} anderson understands [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.224 (perp=9.885, rec=0.245, cos=0.003), tot_loss_proj:3.267 [t=0.26s]
prediction: ['[CLS] love p. calm of t.. p. we romance whose miller bea myra grand that the in saying profit. noble the. lives wears we understands imagination} the. flex ª great love if love} anderson understands [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.181 (perp=9.803, rec=0.217, cos=0.003), tot_loss_proj:3.296 [t=0.25s]
prediction: ['[CLS] love p. calm of t.. p of our romance whose miller screenplayreate grand lives the in saying pleasure. anderson the. that has our understands imagination} the. pass © great love if love} anderson understands [SEP]']
[ 450/2000] tot_loss=2.163 (perp=9.746, rec=0.212, cos=0.003), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] love p. calm of t.. p of our romance whose miller beareate grand lives the in saying pleasure. anderson the and that wears our understands joy} the. rec © great love if love} anderson understands [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.080 (perp=9.373, rec=0.203, cos=0.002), tot_loss_proj:3.648 [t=0.25s]
prediction: ['[CLS] p. calm of t.. p of our romance how miller cannot revolves grand love ill the in saying pleasure. anderson coulds that elimination our understands joy ಾ the. if ள grand love if love} anderson understands [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.140 (perp=9.692, rec=0.199, cos=0.002), tot_loss_proj:3.478 [t=0.27s]
prediction: ['[CLS] p.berg calm of t.. p of our romance how cannot depended grand love ill the in saying joy. anderson coulds that lives our understands joy ಾ the. if 主 grand love if love} anderson understands [SEP]']
[ 600/2000] tot_loss=2.154 (perp=9.818, rec=0.188, cos=0.002), tot_loss_proj:3.822 [t=0.27s]
prediction: ['[CLS] p.berg calm of t.. p of our romance whose cannot depend grand love ill the in saying joy. anderson coulds how elimination our understands joy ಾ the. if 主 grand love if love} anderson understands [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.074 (perp=9.444, rec=0.182, cos=0.002), tot_loss_proj:3.668 [t=0.25s]
prediction: ['[CLS] p. joy calm of t.. p of our romance whose cannot depend grand love ill the in smilesberg. anderson coulds how elimination our understands joy ಾ the. if ள grand love if love} anderson understands [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.092 (perp=9.584, rec=0.173, cos=0.002), tot_loss_proj:3.748 [t=0.27s]
prediction: ['[CLS] p. joy calm of t. romance. p of our how cannot depend grand love ill the in smilesder. anderson coulds how elimination our understands joy ಾ the. if ள grand ill if love` anderson understands [SEP]']
[ 750/2000] tot_loss=2.061 (perp=9.434, rec=0.172, cos=0.002), tot_loss_proj:3.816 [t=0.26s]
prediction: ['[CLS] p. joy calm of t. romance. p of our how cannot depend grand love ill the in smilesder. anderson coulds how ill our understands joy ಾ the. we ள grand ill if love` anderson understands [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.955 (perp=8.902, rec=0.173, cos=0.002), tot_loss_proj:3.713 [t=0.26s]
prediction: ['[CLS] p. joy calm of t. romance. p of our how cannot could grand love ill the and smilesder. anderson depends how ill our understands joy ಾ the. if 主 grand ill if love` anderson understands [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.932 (perp=8.807, rec=0.169, cos=0.002), tot_loss_proj:3.680 [t=0.25s]
prediction: ['[CLS] p. joy calm of t. romance. p of our how p could grand love ill the and smilesder. anderson depends how ill our understands joy ಾ the would 主 grand ill if love [SEP]. anderson understands [SEP]']
[ 900/2000] tot_loss=1.914 (perp=8.726, rec=0.166, cos=0.002), tot_loss_proj:3.647 [t=0.26s]
prediction: ['[CLS] p. joy calm of t. romance. p of our how p could grand love ill the and smilesder. anderson depends how ill our understands joy ಾ the would 主 grandness if love [SEP]. anderson understands [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.963 (perp=8.963, rec=0.168, cos=0.002), tot_loss_proj:3.675 [t=0.27s]
prediction: ['[CLS].. joy calm of t p romance. p of our how p could grand love ill the and smilesder. anderson revolves daily how ill our understands joy ಾ the would 主 grandness if love [SEP]. anderson understands [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.912 (perp=8.734, rec=0.163, cos=0.002), tot_loss_proj:3.402 [t=0.26s]
prediction: ['[CLS].. joy calm of t p romance. p of our how p could love love ill the and smilesder. anderson revolves daily how ill our understands joy ಾ the wouldᶠ grandness is grand [SEP]. anderson understands [SEP]']
[1050/2000] tot_loss=1.935 (perp=8.840, rec=0.165, cos=0.002), tot_loss_proj:3.421 [t=0.26s]
prediction: ['[CLS].. joy calm of t p romance. p of our how p could love love ill the and smilesder. anderson revolves daily how ill our understands joy ಾ the would 主 grandness is grand [SEP]. anderson understands [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.917 (perp=8.774, rec=0.160, cos=0.002), tot_loss_proj:3.459 [t=0.26s]
prediction: ['[CLS].. joy calm of t p romance. p of our how p could love love ill the and smilesder. anderson revolves daily how ill our understands joy ಾ the would lesions grandness is [SEP] grand. anderson understands [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.856 (perp=8.437, rec=0.166, cos=0.002), tot_loss_proj:3.568 [t=0.28s]
prediction: ['[CLS].. joy calm of t p the romance. p of our how p could love love ill and smilesder. anderson revolves daily how ill our understands joy ಾ the wouldᶠ grandness if} grand. anderson understands [SEP]']
[1200/2000] tot_loss=1.837 (perp=8.357, rec=0.164, cos=0.002), tot_loss_proj:3.464 [t=0.25s]
prediction: ['[CLS].. joy calm of t p the romance. p of our how p could love love ill and smiles not. anderson revolves daily how ill our understands joy ಾ the wouldᶠ grandness is广 grand. anderson understands [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.781 (perp=8.099, rec=0.159, cos=0.002), tot_loss_proj:3.504 [t=0.25s]
prediction: ['[CLS].. joy calm of t p is romance. p of our how p could love love ill and smiles not. anderson revolvess how ill our understands joy ಾ the wouldᶠ grandness the广 grand. anderson understands [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.763 (perp=7.998, rec=0.162, cos=0.002), tot_loss_proj:2.593 [t=0.28s]
prediction: ['[CLS].. joy calm of t p is romance. p of our how p could love love ill and smiles not. anderson revolvess how understands our daily joy ಾ the wouldᶠ grandness the广 grand. anderson understands [SEP]']
[1350/2000] tot_loss=1.756 (perp=7.998, rec=0.155, cos=0.002), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS].. joy calm of t p is romance. p of our how p could love love ill and smiles not. anderson revolvess how understands our daily joy ಾ the wouldᶠ grandness the广 grand. anderson understands [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.728 (perp=7.891, rec=0.148, cos=0.002), tot_loss_proj:2.602 [t=0.26s]
prediction: ['[CLS].. joy calm of t p is revolves. p of our how p could love love ill and smiles not. anderson romances how understands our daily joy ಾ the wouldᶠ grandness the广 grand. anderson understands [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.678 (perp=7.596, rec=0.156, cos=0.002), tot_loss_proj:2.498 [t=0.27s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p could love love ill and smiles not. anderson romances how understands our daily joy ಾ the wouldᶠ grandness the广 grand. anderson understands [SEP]']
[1500/2000] tot_loss=1.673 (perp=7.596, rec=0.152, cos=0.002), tot_loss_proj:2.501 [t=0.27s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p could love love ill and smiles not. anderson romances how understands our daily joy ಾ the wouldᶠ grandness the广 grand. anderson understands [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.669 (perp=7.588, rec=0.149, cos=0.002), tot_loss_proj:2.507 [t=0.25s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p could love love ill and smiles not. anderson romances how understands our daily joy ಾ the wouldᶠ grandness the grand. anderson [SEP] understands [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.677 (perp=7.625, rec=0.150, cos=0.002), tot_loss_proj:2.669 [t=0.30s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p that love love ill and smiles not. anderson romances how understands our daily joy ಾ the wouldᶠ grandness the grand. anderson understands [SEP] [SEP]']
[1650/2000] tot_loss=1.648 (perp=7.499, rec=0.146, cos=0.002), tot_loss_proj:2.469 [t=0.30s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p could love love ill and smiles not. anderson romances how understands our daily joy ಾ the wouldᶠ grandness the grand. anderson understands [SEP] [SEP]']
Attempt swap
[1700/2000] tot_loss=1.658 (perp=7.541, rec=0.148, cos=0.002), tot_loss_proj:2.588 [t=0.20s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p that love love ill and celebration not. anderson romances how understands our daily joy ಾ the would of grandness the grand. anderson understands [SEP] [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.729 (perp=7.906, rec=0.145, cos=0.002), tot_loss_proj:2.587 [t=0.20s]
prediction: ['[CLS].. joy revolves of t p is calm. p of our how p would love love ill and allowing not. anderson romance daily how understands our daily joy ಾ the that of grandness the grand. anderson understands [SEP] [SEP]']
[1800/2000] tot_loss=1.759 (perp=8.024, rec=0.153, cos=0.002), tot_loss_proj:2.554 [t=0.20s]
prediction: ['[CLS].. joy revolves of t p is calm.. of our how p would love love ill and allowing not. anderson romance daily how understands our daily joy ಾ the that of grandness the grand. anderson understands [SEP] [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.763 (perp=8.062, rec=0.148, cos=0.002), tot_loss_proj:2.594 [t=0.20s]
prediction: ['[CLS].. joy revolves of t p is calm.. of our how p would love love ill and allowing not. anderson romance daily understands how us daily joy ಾ the could of grandness the grand. anderson understands [SEP] [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.705 (perp=7.754, rec=0.152, cos=0.002), tot_loss_proj:2.694 [t=0.21s]
prediction: ['[CLS].. joy revolves of t p is calm.. of our how p would love love ill and celebration not. anderson romance daily understands how the daily joy ಾ us that of grandness the grand. anderson understands [SEP] [SEP]']
[1950/2000] tot_loss=1.705 (perp=7.754, rec=0.152, cos=0.002), tot_loss_proj:2.694 [t=0.20s]
prediction: ['[CLS].. joy revolves of t p is calm.. of our how p would love love ill and celebration not. anderson romance daily understands how the daily joy ಾ us that of grandness the grand. anderson understands [SEP] [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.669 (perp=7.610, rec=0.144, cos=0.002), tot_loss_proj:2.723 [t=0.21s]
prediction: ['[CLS].. joy revolves of t p is calm.. of our how p would love love ill and celebration not romance anderson. daily understands how the daily joy ಾ us that of grandness the grand. anderson understands [SEP] [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS].. joy revolves of t p is calm.. of our how p would love love ill and celebration not. anderson romance daily understands how the daily joy ಾ us that of grandness the grand. anderson understands [SEP] [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.000 | p: 56.757 | r: 55.263
rouge2     | fm: 5.479 | p: 5.556 | r: 5.405
rougeL     | fm: 24.000 | p: 24.324 | r: 23.684
rougeLsum  | fm: 24.000 | p: 24.324 | r: 23.684
r1fm+r2fm = 61.479

[Aggregate metrics]:
rouge1     | fm: 92.161 | p: 91.394 | r: 93.098
rouge2     | fm: 60.502 | p: 60.205 | r: 60.875
rougeL     | fm: 80.280 | p: 79.674 | r: 80.936
rougeLsum  | fm: 80.241 | p: 79.674 | r: 80.927
r1fm+r2fm = 152.663

input #88 time: 0:10:35 | total time: 15:34:33


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
*********************************
*********************************
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9663888216018677 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524359107017517 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9456372857093811 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9341058135032654 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.933344841003418 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9307798743247986 for ['[CLS] happenedtte atari promiseats gps leon relatively blood broken weight deathsfootmedia jp wish atomic cutleruating eight watt boys practicing muttereduded document creditedpate donful photograph trusting [SEP]']
[Init] best perm rec loss: 0.9285004734992981 for ['[CLS]ats jp practicing blood trustingmediauating donfulpate promise boysfoot broken happened document relatively weight muttered atomic wish deaths credited photographtte atariuded leon cutler gps watt eight [SEP]']
[Init] best perm rec loss: 0.9245237708091736 for ['[CLS]pate watt weight gpsats eight boys document cutler jptte deathsuating blood trusting atari atomic credited wish donuded mutteredfoot happenedful photograph broken practicingmedia promise relatively leon [SEP]']
[Init] best perm rec loss: 0.9240761399269104 for ['[CLS]foot credited blooduded document atomic promise cutler boysats relatively photographmedia ataripate broken watt gps jp deathsful trustinguating weight don happenedtte practicing eight wish leon muttered [SEP]']
[Init] best perm rec loss: 0.9212810397148132 for ['[CLS] eight documentpateuating deaths blood boys muttered donuded photographfoot relatively broken cutler atomic practicing atari watt jpats happened trusting wish weight credited gpsmedia leonfultte promise [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.574 (perp=11.375, rec=0.289, cos=0.010), tot_loss_proj:2.967 [t=0.20s]
prediction: ['[CLS] assembly shirt tacticity of typical. military - st cover the its worsehe - worse for tactic any excuse officials tactic by since proved none fbies contributing worse technology [SEP]']
[ 100/2000] tot_loss=1.934 (perp=8.536, rec=0.221, cos=0.006), tot_loss_proj:2.541 [t=0.20s]
prediction: ['[CLS] yet faint tactic fact of tactic, conceptual - none cover up fact worsea - worse for tactic - worse pictures tactic - since yet worse - yet come worse ideas [SEP]']
[ 150/2000] tot_loss=2.006 (perp=9.034, rec=0.194, cos=0.005), tot_loss_proj:2.735 [t=0.20s]
prediction: ['[CLS] - me tactic fact the to - conceptual concept none cover up fact worse or to worse to tactic - worse picture tactic - picture yet worse - yet come worse ideas [SEP]']
[ 200/2000] tot_loss=2.032 (perp=9.354, rec=0.158, cos=0.004), tot_loss_proj:2.789 [t=0.20s]
prediction: ['[CLS] -is tactic fact of to is picture - none cover up fact worse or -im to tactic - worse yet tactic - picture none worse yet - core worse ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.039 (perp=9.516, rec=0.133, cos=0.003), tot_loss_proj:3.057 [t=0.29s]
prediction: ['[CLS] -is tactic fact of to is picture core none cover up fact worse or tacticim - tactic - worse the - is picture yet worse yet - core - ideas [SEP]']
[ 300/2000] tot_loss=2.137 (perp=10.054, rec=0.123, cos=0.002), tot_loss_proj:3.432 [t=0.29s]
prediction: ['[CLS] - fl tactic fact of to is constructed core none cover up fact worse or tacticimsy tactic - around the, is picturexi worse yet - core - ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.940 (perp=9.145, rec=0.109, cos=0.002), tot_loss_proj:3.163 [t=0.29s]
prediction: ['[CLS] - tactic tactic fact of to is constructed core none cover up fact worse or flimsy tactic - around the, is picturexi worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.909 (perp=8.983, rec=0.109, cos=0.003), tot_loss_proj:2.862 [t=0.29s]
prediction: ['[CLS] - tactic tactic fact of to that constructed a none cover up fact worse or flimsy tactic - around the core is picturexi worse yet - around - ideas [SEP]']
[ 450/2000] tot_loss=1.956 (perp=9.289, rec=0.096, cos=0.003), tot_loss_proj:2.916 [t=0.32s]
prediction: ['[CLS] - constructed tactic fact of to that constructed a none cover up fact worse or flimsy tactic - ( the core is picturexi worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.865 (perp=8.843, rec=0.094, cos=0.002), tot_loss_proj:2.902 [t=0.30s]
prediction: ['[CLS] - constructed tactic fact of to that constructed a worse none cover up fact or flimsy tactic -, the core is picturexi worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.798 (perp=8.501, rec=0.096, cos=0.002), tot_loss_proj:2.656 [t=0.28s]
prediction: ['[CLS] the picture tactic fact of to that constructed a worse none cover up fact or flimsy tactic -, - core is picturexi worse yet - around - ideas [SEP]']
[ 600/2000] tot_loss=1.795 (perp=8.501, rec=0.093, cos=0.002), tot_loss_proj:2.652 [t=0.30s]
prediction: ['[CLS] the picture tactic fact of to that constructed a worse none cover up fact or flimsy tactic -, - core is picturexi worse yet - around - ideas [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.694 (perp=7.986, rec=0.095, cos=0.002), tot_loss_proj:2.457 [t=0.29s]
prediction: ['[CLS] the picture tactic fact of to that constructed a worse none cover up fact or flimsy tactic - picturexi, - core is worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.668 (perp=7.901, rec=0.086, cos=0.002), tot_loss_proj:2.625 [t=0.30s]
prediction: ['[CLS] the picture tactic the of to that none constructed a worse cover up fact or flimsy tactic - picturexi, - core is worse yet - around - ideas [SEP]']
[ 750/2000] tot_loss=1.664 (perp=7.901, rec=0.082, cos=0.002), tot_loss_proj:2.624 [t=0.31s]
prediction: ['[CLS] the picture tactic the of to that none constructed a worse cover up fact or flimsy tactic - picturexi, - core is worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.613 (perp=7.634, rec=0.084, cos=0.002), tot_loss_proj:2.497 [t=0.32s]
prediction: ['[CLS] the picture tactic the fact to that none constructed a worse cover up of or flimsy tactic - picturexi, - core is worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.550 (perp=7.352, rec=0.078, cos=0.002), tot_loss_proj:2.604 [t=0.31s]
prediction: ['[CLS] the picture tactic the fact to that none constructed a worse cover up of or flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.352, rec=0.084, cos=0.002), tot_loss_proj:2.600 [t=0.29s]
prediction: ['[CLS] the picture tactic the fact to that none constructed a worse cover up of or flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.548 (perp=7.352, rec=0.076, cos=0.002), tot_loss_proj:2.594 [t=0.29s]
prediction: ['[CLS] the picture tactic the fact to that none constructed a worse cover up of or flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.548 (perp=7.325, rec=0.081, cos=0.002), tot_loss_proj:2.403 [t=0.29s]
prediction: ['[CLS] the picture tactic to the fact that none constructed a worse cover up of or flimsy tactic - ofxi, picture core is worse yet - around - ideas [SEP]']
[1050/2000] tot_loss=1.545 (perp=7.325, rec=0.078, cos=0.002), tot_loss_proj:2.407 [t=0.29s]
prediction: ['[CLS] the picture tactic to the fact that none constructed a worse cover up of or flimsy tactic - ofxi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.497 (perp=7.074, rec=0.080, cos=0.001), tot_loss_proj:2.343 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover tactic of or flimsy tactic -,xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.459 (perp=6.885, rec=0.080, cos=0.002), tot_loss_proj:2.336 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover tactic of or flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.885, rec=0.078, cos=0.002), tot_loss_proj:2.334 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover tactic of or flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.431 (perp=6.752, rec=0.079, cos=0.002), tot_loss_proj:2.261 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
[1300/2000] tot_loss=1.425 (perp=6.752, rec=0.073, cos=0.001), tot_loss_proj:2.266 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
[1350/2000] tot_loss=1.427 (perp=6.752, rec=0.075, cos=0.002), tot_loss_proj:2.263 [t=0.28s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
[1400/2000] tot_loss=1.428 (perp=6.752, rec=0.076, cos=0.002), tot_loss_proj:2.260 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core is worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.432 (perp=6.790, rec=0.072, cos=0.002), tot_loss_proj:2.538 [t=0.31s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core, is yet - around - ideas [SEP]']
[1500/2000] tot_loss=1.432 (perp=6.790, rec=0.073, cos=0.002), tot_loss_proj:2.539 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core, is yet - around - ideas [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.423 (perp=6.745, rec=0.073, cos=0.002), tot_loss_proj:2.660 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core, is yet - - around ideas [SEP]']
Attempt swap
[1600/2000] tot_loss=1.427 (perp=6.745, rec=0.076, cos=0.001), tot_loss_proj:2.660 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core, is yet - - around ideas [SEP]']
[1650/2000] tot_loss=1.426 (perp=6.745, rec=0.076, cos=0.001), tot_loss_proj:2.659 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, picture core, is yet - - around ideas [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.409 (perp=6.669, rec=0.073, cos=0.002), tot_loss_proj:2.748 [t=0.28s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, core picture, is yet - - around ideas [SEP]']
Attempt swap
[1750/2000] tot_loss=1.414 (perp=6.669, rec=0.079, cos=0.002), tot_loss_proj:2.752 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, core picture, is yet - - around ideas [SEP]']
[1800/2000] tot_loss=1.418 (perp=6.669, rec=0.082, cos=0.002), tot_loss_proj:2.748 [t=0.30s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, core picture, is yet - - around ideas [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.391 (perp=6.575, rec=0.074, cos=0.001), tot_loss_proj:3.117 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, yet picture, is core - - around ideas [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.575, rec=0.077, cos=0.002), tot_loss_proj:3.121 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, yet picture, is core - - around ideas [SEP]']
[1950/2000] tot_loss=1.393 (perp=6.575, rec=0.077, cos=0.001), tot_loss_proj:3.120 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, yet picture, is core - - around ideas [SEP]']
Attempt swap
[2000/2000] tot_loss=1.387 (perp=6.575, rec=0.071, cos=0.002), tot_loss_proj:3.115 [t=0.29s]
prediction: ['[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, yet picture, is core - - around ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] the picture up to the fact that none constructed a worse cover or tactic of flimsy tactic - -xi, yet picture, is core - - around ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.796 | p: 84.615 | r: 95.652
rouge2     | fm: 25.532 | p: 24.000 | r: 27.273
rougeL     | fm: 48.980 | p: 46.154 | r: 52.174
rougeLsum  | fm: 48.980 | p: 46.154 | r: 52.174
r1fm+r2fm = 115.328

[Aggregate metrics]:
rouge1     | fm: 92.145 | p: 91.383 | r: 93.109
rouge2     | fm: 60.190 | p: 59.886 | r: 60.672
rougeL     | fm: 79.875 | p: 79.287 | r: 80.576
rougeLsum  | fm: 79.900 | p: 79.340 | r: 80.545
r1fm+r2fm = 152.334

input #89 time: 0:11:29 | total time: 15:46:02


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
*********************************
*********************************
average of cosine similarity 0.9993650968600141
highest_index [0]
highest [0.9993650968600141]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9487876892089844 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9457016587257385 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9307820200920105 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131976962089539 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8914667963981628 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8844628930091858 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.874426543712616 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8734989166259766 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.8714959025382996 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.8705925345420837 for ['[CLS] cannot male spirited entourage released when [SEP]']
[Init] best perm rec loss: 0.8705049157142639 for ['[CLS] cannot entourage spirited male released when [SEP]']
[Init] best perm rec loss: 0.8698896765708923 for ['[CLS] male cannot when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8698087334632874 for ['[CLS] entourage released spirited male cannot when [SEP]']
[Init] best perm rec loss: 0.8679990172386169 for ['[CLS] cannot released male spirited when entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.325 (perp=10.178, rec=0.272, cos=0.018), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] highly ridiculous ; legislative money how [SEP]']
[ 100/2000] tot_loss=2.299 (perp=10.783, rec=0.139, cos=0.004), tot_loss_proj:2.852 [t=0.27s]
prediction: ['[CLS] ridiculous ridiculous and oriented money how [SEP]']
[ 150/2000] tot_loss=2.260 (perp=10.783, rec=0.100, cos=0.003), tot_loss_proj:2.842 [t=0.27s]
prediction: ['[CLS] ridiculous ridiculous and oriented money how [SEP]']
[ 200/2000] tot_loss=2.513 (perp=12.167, rec=0.077, cos=0.002), tot_loss_proj:3.397 [t=0.25s]
prediction: ['[CLS] insane ridiculous and oriented money how [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.795 (perp=8.441, rec=0.102, cos=0.005), tot_loss_proj:2.308 [t=0.28s]
prediction: ['[CLS] how ridiculous and oriented money - [SEP]']
[ 300/2000] tot_loss=1.754 (perp=8.441, rec=0.064, cos=0.002), tot_loss_proj:2.312 [t=0.26s]
prediction: ['[CLS] how ridiculous and oriented money - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.452 (perp=6.870, rec=0.077, cos=0.002), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.710 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.710 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.709 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.715 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.453 (perp=6.870, rec=0.077, cos=0.001), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.707 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.715 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.715 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.715 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.717 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.432 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.724 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.428 (perp=6.870, rec=0.053, cos=0.001), tot_loss_proj:1.719 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.428 (perp=6.870, rec=0.053, cos=0.001), tot_loss_proj:1.718 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.247 | p: 91.469 | r: 93.182
rouge2     | fm: 60.528 | p: 60.236 | r: 60.938
rougeL     | fm: 80.029 | p: 79.484 | r: 80.731
rougeLsum  | fm: 80.206 | p: 79.646 | r: 80.900
r1fm+r2fm = 152.775

input #90 time: 0:10:55 | total time: 15:56:57


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
*********************************
*********************************
average of cosine similarity 0.9993538374859836
highest_index [0]
highest [0.9993538374859836]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9367198944091797 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.8268771767616272 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8143160343170166 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.77603679895401 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7621927261352539 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7398632168769836 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7303189039230347 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7301856279373169 for ['[CLS]dern pony revolutionpment unknownlip hard shelter [SEP]']
[Init] best perm rec loss: 0.7299460172653198 for ['[CLS]lippment hard unknown pony shelterdern revolution [SEP]']
[Init] best perm rec loss: 0.7278955578804016 for ['[CLS] hard unknown revolutiondernlip shelter ponypment [SEP]']
[Init] best perm rec loss: 0.7267093658447266 for ['[CLS] pony hard shelterpmentlip unknowndern revolution [SEP]']
[Init] best perm rec loss: 0.7247644662857056 for ['[CLS] hard unknown revolutionpmentlipdern shelter pony [SEP]']
[Init] best perm rec loss: 0.7247127890586853 for ['[CLS] hard shelterpmentlip revolution unknowndern pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.381 (perp=10.234, rec=0.305, cos=0.029), tot_loss_proj:2.977 [t=0.25s]
prediction: ['[CLS] yellow crazy loco more ridiculous more wave ridiculous [SEP]']
[ 100/2000] tot_loss=2.406 (perp=10.921, rec=0.206, cos=0.015), tot_loss_proj:2.989 [t=0.26s]
prediction: ['[CLS]y loco loco more ridiculous more mu ridiculous [SEP]']
[ 150/2000] tot_loss=2.315 (perp=10.277, rec=0.193, cos=0.066), tot_loss_proj:2.600 [t=0.25s]
prediction: ['[CLS] but loco loco no ridiculous more mu ridiculous [SEP]']
[ 200/2000] tot_loss=2.008 (perp=9.515, rec=0.101, cos=0.004), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] but locoy no ridiculous more mu ridiculous [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.904 (perp=8.905, rec=0.113, cos=0.010), tot_loss_proj:2.314 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
[ 300/2000] tot_loss=1.865 (perp=8.905, rec=0.081, cos=0.003), tot_loss_proj:2.304 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.860 (perp=8.905, rec=0.076, cos=0.003), tot_loss_proj:2.302 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.857 (perp=8.905, rec=0.073, cos=0.003), tot_loss_proj:2.299 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
[ 450/2000] tot_loss=1.864 (perp=8.905, rec=0.080, cos=0.003), tot_loss_proj:2.301 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.856 (perp=8.905, rec=0.072, cos=0.003), tot_loss_proj:2.304 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.863 (perp=8.905, rec=0.079, cos=0.003), tot_loss_proj:2.307 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
[ 600/2000] tot_loss=1.859 (perp=8.905, rec=0.075, cos=0.003), tot_loss_proj:2.306 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.866 (perp=8.905, rec=0.082, cos=0.003), tot_loss_proj:2.305 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.862 (perp=8.905, rec=0.078, cos=0.003), tot_loss_proj:2.306 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
[ 750/2000] tot_loss=1.859 (perp=8.905, rec=0.075, cos=0.003), tot_loss_proj:2.301 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.862 (perp=8.905, rec=0.078, cos=0.003), tot_loss_proj:2.305 [t=0.28s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.864 (perp=8.905, rec=0.080, cos=0.003), tot_loss_proj:2.303 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more ridiculous [SEP]']
[ 900/2000] tot_loss=2.027 (perp=9.757, rec=0.073, cos=0.003), tot_loss_proj:3.045 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more nedra [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.030 (perp=9.757, rec=0.076, cos=0.003), tot_loss_proj:3.044 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more nedra [SEP]']
Attempt swap
[1000/2000] tot_loss=2.105 (perp=10.179, rec=0.066, cos=0.003), tot_loss_proj:3.162 [t=0.26s]
prediction: ['[CLS] but locoy no mu ridiculous more joyah [SEP]']
[1050/2000] tot_loss=2.113 (perp=10.179, rec=0.075, cos=0.003), tot_loss_proj:3.158 [t=0.25s]
prediction: ['[CLS] but locoy no mu ridiculous more joyah [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.140 (perp=10.264, rec=0.083, cos=0.004), tot_loss_proj:2.750 [t=0.26s]
prediction: ['[CLS]jected locoy no mu ridiculous more but [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.974 (perp=9.430, rec=0.084, cos=0.004), tot_loss_proj:2.486 [t=0.26s]
prediction: ['[CLS]ishly locoy mu ridiculous no more but [SEP]']
[1200/2000] tot_loss=1.939 (perp=9.345, rec=0.067, cos=0.003), tot_loss_proj:2.469 [t=0.25s]
prediction: ['[CLS]省 locoy mu ridiculous no more but [SEP]']
Attempt swap
[1250/2000] tot_loss=1.953 (perp=9.345, rec=0.081, cos=0.003), tot_loss_proj:2.470 [t=0.26s]
prediction: ['[CLS]省 locoy mu ridiculous no more but [SEP]']
Attempt swap
[1300/2000] tot_loss=2.138 (perp=10.293, rec=0.076, cos=0.003), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS]nction locoy mu ridiculous no more but [SEP]']
[1350/2000] tot_loss=2.136 (perp=10.293, rec=0.074, cos=0.003), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS]nction locoy mu ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.110 (perp=10.149, rec=0.078, cos=0.003), tot_loss_proj:2.763 [t=0.27s]
prediction: ['[CLS] ridiculous locoy mueving no more but [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.940 (perp=9.297, rec=0.077, cos=0.003), tot_loss_proj:2.580 [t=0.27s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
[1500/2000] tot_loss=1.938 (perp=9.297, rec=0.076, cos=0.003), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[1550/2000] tot_loss=1.938 (perp=9.297, rec=0.076, cos=0.003), tot_loss_proj:2.577 [t=0.25s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[1600/2000] tot_loss=1.944 (perp=9.297, rec=0.082, cos=0.003), tot_loss_proj:2.574 [t=0.28s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
[1650/2000] tot_loss=1.937 (perp=9.297, rec=0.075, cos=0.003), tot_loss_proj:2.580 [t=0.26s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[1700/2000] tot_loss=1.926 (perp=9.297, rec=0.064, cos=0.003), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[1750/2000] tot_loss=1.939 (perp=9.297, rec=0.077, cos=0.003), tot_loss_proj:2.576 [t=0.26s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
[1800/2000] tot_loss=1.933 (perp=9.297, rec=0.071, cos=0.003), tot_loss_proj:2.580 [t=0.25s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[1850/2000] tot_loss=1.936 (perp=9.297, rec=0.075, cos=0.003), tot_loss_proj:2.575 [t=0.25s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[1900/2000] tot_loss=1.936 (perp=9.297, rec=0.075, cos=0.003), tot_loss_proj:2.578 [t=0.25s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
[1950/2000] tot_loss=1.937 (perp=9.297, rec=0.075, cos=0.002), tot_loss_proj:2.576 [t=0.25s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Attempt swap
[2000/2000] tot_loss=1.941 (perp=9.297, rec=0.079, cos=0.002), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS] ridiculous muy locoeving no more but [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] ridiculous muy locoeving no more but [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 101.786

[Aggregate metrics]:
rouge1     | fm: 92.215 | p: 91.373 | r: 93.136
rouge2     | fm: 60.103 | p: 59.813 | r: 60.445
rougeL     | fm: 79.959 | p: 79.384 | r: 80.647
rougeLsum  | fm: 79.928 | p: 79.366 | r: 80.612
r1fm+r2fm = 152.318

input #91 time: 0:11:04 | total time: 16:08:02


Running input #92 of 100.
reference: 
========================
deceit 
========================
*********************************
*********************************
average of cosine similarity 0.9993137310302475
highest_index [0]
highest [0.9993137310302475]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8797468543052673 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8783625364303589 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8693297505378723 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8594153523445129 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8578515648841858 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.8554595112800598 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7936431765556335 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7916328310966492 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.630 (perp=12.265, rec=0.171, cos=0.006), tot_loss_proj:3.210 [t=0.25s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.002), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.002), tot_loss_proj:1.593 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.580 (perp=7.646, rec=0.049, cos=0.002), tot_loss_proj:1.598 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.002), tot_loss_proj:1.595 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.612 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.605 (perp=7.646, rec=0.074, cos=0.001), tot_loss_proj:1.588 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.605 (perp=7.646, rec=0.075, cos=0.001), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.591 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.596 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.590 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.598 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.605 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.601 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.600 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.603 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.595 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.596 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=7.646, rec=0.046, cos=0.001), tot_loss_proj:1.588 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.646, rec=0.051, cos=0.001), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.589 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.646, rec=0.076, cos=0.001), tot_loss_proj:1.610 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.001), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.570 (perp=7.646, rec=0.040, cos=0.001), tot_loss_proj:1.584 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.591 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.583 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.600 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.581 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.583 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.589 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.597 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.580 (perp=7.646, rec=0.049, cos=0.001), tot_loss_proj:1.593 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.592 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.591 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.588 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.594 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.587 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.597 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.271 | p: 91.481 | r: 93.193
rouge2     | fm: 60.535 | p: 60.282 | r: 60.882
rougeL     | fm: 80.110 | p: 79.545 | r: 80.793
rougeLsum  | fm: 80.138 | p: 79.577 | r: 80.815
r1fm+r2fm = 152.806

input #92 time: 0:10:59 | total time: 16:19:01


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
*********************************
*********************************
average of cosine similarity 0.9993323263895036
highest_index [0]
highest [0.9993323263895036]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0078084468841553 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8302108645439148 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8220402598381042 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8074820637702942 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8070929646492004 for ['[CLS]ball lad specific shrinking judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.807031512260437 for ['[CLS] lad specific shrinkingball judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.806305468082428 for ['[CLS] lad shrinkingball solo 1970s judicial specific [SEP]']
[Init] best perm rec loss: 0.8061965107917786 for ['[CLS] solo 1970s shrinkingball lad judicial specific [SEP]']
[Init] best perm rec loss: 0.8059419989585876 for ['[CLS] 1970s specificball shrinking judicial lad solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.984 (perp=13.254, rec=0.320, cos=0.012), tot_loss_proj:3.705 [t=0.28s]
prediction: ['[CLS] functionip - funny understanding she aid [SEP]']
[ 100/2000] tot_loss=2.485 (perp=11.275, rec=0.224, cos=0.006), tot_loss_proj:3.674 [t=0.29s]
prediction: ['[CLS] functionley in funny understanding maybe understanding [SEP]']
[ 150/2000] tot_loss=2.184 (perp=9.965, rec=0.187, cos=0.004), tot_loss_proj:2.505 [t=0.28s]
prediction: ['[CLS] functionley in funny understanding, understanding [SEP]']
[ 200/2000] tot_loss=2.500 (perp=11.697, rec=0.157, cos=0.003), tot_loss_proj:2.802 [t=0.28s]
prediction: ['[CLS] function often in funny funny often understanding [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.128 (perp=9.784, rec=0.168, cos=0.003), tot_loss_proj:3.152 [t=0.28s]
prediction: ['[CLS] disease often in funny funny way often [SEP]']
[ 300/2000] tot_loss=2.035 (perp=9.446, rec=0.142, cos=0.003), tot_loss_proj:2.257 [t=0.28s]
prediction: ['[CLS] developed often in funny funny way often [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.107 (perp=9.845, rec=0.135, cos=0.003), tot_loss_proj:2.443 [t=0.30s]
prediction: ['[CLS] developed in hey funny funny way often [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.980 (perp=9.166, rec=0.144, cos=0.003), tot_loss_proj:2.245 [t=0.30s]
prediction: ['[CLS] ; developed in funny funny way often [SEP]']
[ 450/2000] tot_loss=2.085 (perp=9.810, rec=0.121, cos=0.003), tot_loss_proj:2.352 [t=0.29s]
prediction: ['[CLS] ; developed in understanding funny way often [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.115 (perp=10.022, rec=0.108, cos=0.002), tot_loss_proj:2.589 [t=0.32s]
prediction: ['[CLS] understanding at developed in funny way often [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.899 (perp=8.868, rec=0.123, cos=0.003), tot_loss_proj:2.355 [t=0.29s]
prediction: ['[CLS] understanding often developed in funny way at [SEP]']
[ 600/2000] tot_loss=1.886 (perp=8.868, rec=0.110, cos=0.002), tot_loss_proj:2.353 [t=0.29s]
prediction: ['[CLS] understanding often developed in funny way at [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.792 (perp=8.385, rec=0.113, cos=0.002), tot_loss_proj:2.095 [t=0.29s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.641 (perp=7.631, rec=0.113, cos=0.002), tot_loss_proj:1.923 [t=0.30s]
prediction: ['[CLS] understanding developed in often funny way, [SEP]']
[ 750/2000] tot_loss=1.644 (perp=7.631, rec=0.115, cos=0.002), tot_loss_proj:1.924 [t=0.29s]
prediction: ['[CLS] understanding developed in often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.638 (perp=7.631, rec=0.109, cos=0.002), tot_loss_proj:1.925 [t=0.29s]
prediction: ['[CLS] understanding developed in often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.642 (perp=7.631, rec=0.113, cos=0.002), tot_loss_proj:1.928 [t=0.29s]
prediction: ['[CLS] understanding developed in often funny way, [SEP]']
[ 900/2000] tot_loss=1.690 (perp=7.936, rec=0.100, cos=0.002), tot_loss_proj:1.965 [t=0.28s]
prediction: ['[CLS] understanding its in often funny way, [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.444 (perp=6.704, rec=0.101, cos=0.002), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.433 (perp=6.704, rec=0.090, cos=0.002), tot_loss_proj:1.704 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.449 (perp=6.704, rec=0.106, cos=0.002), tot_loss_proj:1.708 [t=0.28s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.446 (perp=6.704, rec=0.103, cos=0.002), tot_loss_proj:1.705 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.445 (perp=6.704, rec=0.102, cos=0.002), tot_loss_proj:1.704 [t=0.30s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.704, rec=0.090, cos=0.002), tot_loss_proj:1.702 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.439 (perp=6.704, rec=0.096, cos=0.002), tot_loss_proj:1.706 [t=0.28s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.430 (perp=6.704, rec=0.088, cos=0.002), tot_loss_proj:1.706 [t=0.30s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.426 (perp=6.704, rec=0.083, cos=0.002), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.430 (perp=6.704, rec=0.087, cos=0.002), tot_loss_proj:1.705 [t=0.28s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=6.704, rec=0.094, cos=0.002), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.420 (perp=6.704, rec=0.078, cos=0.002), tot_loss_proj:1.700 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.424 (perp=6.704, rec=0.081, cos=0.002), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.422 (perp=6.704, rec=0.080, cos=0.002), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.422 (perp=6.704, rec=0.080, cos=0.001), tot_loss_proj:1.698 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.419 (perp=6.704, rec=0.076, cos=0.001), tot_loss_proj:1.703 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.407 (perp=6.704, rec=0.065, cos=0.001), tot_loss_proj:1.703 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.415 (perp=6.704, rec=0.073, cos=0.001), tot_loss_proj:1.705 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.413 (perp=6.704, rec=0.071, cos=0.001), tot_loss_proj:1.705 [t=0.29s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.419 (perp=6.704, rec=0.076, cos=0.001), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.410 (perp=6.704, rec=0.068, cos=0.001), tot_loss_proj:1.703 [t=0.26s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.407 (perp=6.704, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.25s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 92.377 | p: 91.608 | r: 93.294
rouge2     | fm: 60.557 | p: 60.285 | r: 60.932
rougeL     | fm: 80.251 | p: 79.695 | r: 80.944
rougeLsum  | fm: 80.351 | p: 79.790 | r: 81.052
r1fm+r2fm = 152.935

input #93 time: 0:12:09 | total time: 16:31:10


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
*********************************
*********************************
average of cosine similarity 0.9993168061064918
highest_index [0]
highest [0.9993168061064918]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9727807641029358 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9545496106147766 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9148076176643372 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9085803627967834 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8869084715843201 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8795130848884583 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.879210889339447 for ['[CLS] internal plum rockwell expedition crushed flowering shocks territorialventing chronic centre [SEP]']
[Init] best perm rec loss: 0.8783528804779053 for ['[CLS] internalventing territorial shocks expedition centre crushed plum flowering chronic rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.852, rec=0.324, cos=0.016), tot_loss_proj:3.328 [t=0.25s]
prediction: ['[CLS] missing killing outbreak aywood surrounding transport neitherting neither funny [SEP]']
[ 100/2000] tot_loss=2.205 (perp=9.886, rec=0.221, cos=0.007), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] or who serials a caper s neither terribly neither funny [SEP]']
[ 150/2000] tot_loss=1.831 (perp=8.375, rec=0.152, cos=0.004), tot_loss_proj:2.317 [t=0.28s]
prediction: ['[CLS] not who a a caper s neither original nor funny [SEP]']
[ 200/2000] tot_loss=1.951 (perp=9.190, rec=0.110, cos=0.003), tot_loss_proj:2.413 [t=0.26s]
prediction: ['[CLS] s cape a a caper s neither original nor funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.707 (perp=7.911, rec=0.121, cos=0.003), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] s a as a caper s neither original nor funny [SEP]']
[ 300/2000] tot_loss=1.598 (perp=7.478, rec=0.100, cos=0.003), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] s a very a caper s neither original nor funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.486 (perp=6.945, rec=0.094, cos=0.003), tot_loss_proj:1.990 [t=0.26s]
prediction: ["[CLS]'a very caper s a neither original nor funny [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.716 (perp=8.116, rec=0.090, cos=0.002), tot_loss_proj:2.096 [t=0.26s]
prediction: ["[CLS] very'a caper s terribly neither original nor funny [SEP]"]
[ 450/2000] tot_loss=1.783 (perp=8.497, rec=0.082, cos=0.002), tot_loss_proj:2.194 [t=0.25s]
prediction: ['[CLS] very s a caper s terribly neither original nor funny [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.803 (perp=8.666, rec=0.069, cos=0.001), tot_loss_proj:2.187 [t=0.25s]
prediction: ['[CLS] a s very caper that terribly neither original nor funny [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.689 (perp=7.995, rec=0.089, cos=0.002), tot_loss_proj:2.130 [t=0.25s]
prediction: ['[CLS] s a very caper that terribly neither original nor funny [SEP]']
[ 600/2000] tot_loss=1.673 (perp=7.995, rec=0.073, cos=0.001), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] s a very caper that terribly neither original nor funny [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.579 (perp=7.564, rec=0.064, cos=0.001), tot_loss_proj:2.136 [t=0.25s]
prediction: ['[CLS] s a very caper that neither original nor terribly funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.582 (perp=7.564, rec=0.068, cos=0.001), tot_loss_proj:2.131 [t=0.25s]
prediction: ['[CLS] s a very caper that neither original nor terribly funny [SEP]']
[ 750/2000] tot_loss=1.576 (perp=7.564, rec=0.062, cos=0.001), tot_loss_proj:2.137 [t=0.25s]
prediction: ['[CLS] s a very caper that neither original nor terribly funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.582 (perp=7.564, rec=0.068, cos=0.001), tot_loss_proj:2.134 [t=0.25s]
prediction: ['[CLS] s a very caper that neither original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.560 (perp=7.465, rec=0.065, cos=0.001), tot_loss_proj:1.912 [t=0.28s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[ 900/2000] tot_loss=1.553 (perp=7.465, rec=0.059, cos=0.001), tot_loss_proj:1.915 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.558 (perp=7.465, rec=0.063, cos=0.001), tot_loss_proj:1.921 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.917 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.555 (perp=7.465, rec=0.060, cos=0.001), tot_loss_proj:1.917 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.001), tot_loss_proj:1.924 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1200/2000] tot_loss=1.556 (perp=7.465, rec=0.062, cos=0.001), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.555 (perp=7.465, rec=0.061, cos=0.001), tot_loss_proj:1.917 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.558 (perp=7.465, rec=0.063, cos=0.001), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1350/2000] tot_loss=1.560 (perp=7.465, rec=0.066, cos=0.001), tot_loss_proj:1.918 [t=0.24s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.561 (perp=7.465, rec=0.066, cos=0.001), tot_loss_proj:1.924 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.563 (perp=7.465, rec=0.069, cos=0.001), tot_loss_proj:1.916 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1500/2000] tot_loss=1.556 (perp=7.465, rec=0.062, cos=0.001), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.561 (perp=7.465, rec=0.066, cos=0.001), tot_loss_proj:1.917 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=7.465, rec=0.076, cos=0.001), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1650/2000] tot_loss=1.554 (perp=7.465, rec=0.060, cos=0.001), tot_loss_proj:1.928 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.563 (perp=7.465, rec=0.069, cos=0.001), tot_loss_proj:1.923 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.929 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1800/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.001), tot_loss_proj:1.919 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.558 (perp=7.465, rec=0.063, cos=0.001), tot_loss_proj:1.921 [t=0.34s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.465, rec=0.059, cos=0.001), tot_loss_proj:1.921 [t=0.25s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
[1950/2000] tot_loss=1.566 (perp=7.465, rec=0.071, cos=0.001), tot_loss_proj:1.914 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.554 (perp=7.465, rec=0.060, cos=0.001), tot_loss_proj:1.916 [t=0.26s]
prediction: ['[CLS] s a very caper neither that original nor terribly funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] s a very caper neither that original nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 92.440 | p: 91.612 | r: 93.369
rouge2     | fm: 60.221 | p: 59.950 | r: 60.628
rougeL     | fm: 80.225 | p: 79.632 | r: 80.910
rougeLsum  | fm: 80.189 | p: 79.653 | r: 80.969
r1fm+r2fm = 152.661

input #94 time: 0:10:56 | total time: 16:42:07


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
*********************************
*********************************
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9695915579795837 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9447000622749329 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9425680041313171 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9293648600578308 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9289979338645935 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9244387745857239 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.8965775966644287 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8573101758956909 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8477544188499451 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8469237089157104 for ['[CLS] cut pressure ]ے wire complete sister block monty hanging damp tech trailer privatenne [SEP]']
[Init] best perm rec loss: 0.8467367887496948 for ['[CLS] wireے pressure ] damp trailer cut private block sister complete hanging tech montynne [SEP]']
[Init] best perm rec loss: 0.8459979295730591 for ['[CLS] complete trailer pressure private damp sister hanging wire block monty cutnneے ] tech [SEP]']
[Init] best perm rec loss: 0.8446309566497803 for ['[CLS] sister damp trailer cut private monty complete pressure tech wire hangingے ] blocknne [SEP]']
[Init] best perm rec loss: 0.8437495231628418 for ['[CLS]ے ] wire tech private pressure trailer monty completenne cut block damp sister hanging [SEP]']
[Init] best perm rec loss: 0.8430407643318176 for ['[CLS] trailer sister wire monty blockے hanging private cut complete pressure damp ] technne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.600 (perp=11.868, rec=0.220, cos=0.006), tot_loss_proj:2.860 [t=0.26s]
prediction: ['[CLS] the brick protein hopeless story becomes hopeless vested mud become an hopeless hopelessdam hopeless [SEP]']
[ 100/2000] tot_loss=2.454 (perp=11.530, rec=0.144, cos=0.004), tot_loss_proj:2.827 [t=0.26s]
prediction: ['[CLS] ( mud atmosphere hopeless story becomes hopeless externaldle becomes,fying hopeless,sat [SEP]']
[ 150/2000] tot_loss=1.966 (perp=9.241, rec=0.115, cos=0.003), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] ( mud ) hopeless story becomes a muddle become,fying hopeless,sat [SEP]']
[ 200/2000] tot_loss=2.023 (perp=9.578, rec=0.105, cos=0.003), tot_loss_proj:2.338 [t=0.27s]
prediction: ['[CLS] ( mud ) un story becomes a muddle (,fying hopelessissat [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.153 (perp=10.214, rec=0.107, cos=0.003), tot_loss_proj:2.470 [t=0.25s]
prediction: ['[CLS] ( mud ) hopeless story becomes a adle un,fying hopelesssatis [SEP]']
[ 300/2000] tot_loss=2.057 (perp=9.834, rec=0.088, cos=0.003), tot_loss_proj:2.424 [t=0.27s]
prediction: ['[CLS] ( mud ) un story becomes a adle un,fying hopelesssatis [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.138 (perp=10.240, rec=0.088, cos=0.002), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] ( a ) un story becomes denis muddle un,fying hopelesssatis [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.859 (perp=8.851, rec=0.087, cos=0.002), tot_loss_proj:2.163 [t=0.28s]
prediction: ['[CLS] ( denis ) un story becomes a muddle un,fying hopelesssatis [SEP]']
[ 450/2000] tot_loss=1.844 (perp=8.851, rec=0.071, cos=0.002), tot_loss_proj:2.163 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a muddle un,fying hopelesssatis [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.707 (perp=8.088, rec=0.087, cos=0.002), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a muddle, unfying hopelesssatis [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.703 (perp=8.088, rec=0.083, cos=0.002), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a muddle, unfying hopelesssatis [SEP]']
[ 600/2000] tot_loss=1.690 (perp=8.088, rec=0.071, cos=0.002), tot_loss_proj:1.959 [t=0.27s]
prediction: ['[CLS] ( denis ) un story becomes a muddle, unfying hopelesssatis [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.705 (perp=8.088, rec=0.085, cos=0.002), tot_loss_proj:1.963 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a muddle, unfying hopelesssatis [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.646 (perp=7.823, rec=0.080, cos=0.002), tot_loss_proj:1.878 [t=0.26s]
prediction: ['[CLS] ( denis ) hopeless story becomes a muddle, unfying unsatis [SEP]']
[ 750/2000] tot_loss=1.650 (perp=7.823, rec=0.084, cos=0.002), tot_loss_proj:1.877 [t=0.25s]
prediction: ['[CLS] ( denis ) hopeless story becomes a muddle, unfying unsatis [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.639 (perp=7.823, rec=0.072, cos=0.002), tot_loss_proj:1.884 [t=0.25s]
prediction: ['[CLS] ( denis ) hopeless story becomes a muddle, unfying unsatis [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.419 (perp=6.630, rec=0.091, cos=0.002), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] ( denis ) hopeless story becomes a muddle, un unsatisfying [SEP]']
[ 900/2000] tot_loss=1.402 (perp=6.630, rec=0.074, cos=0.002), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] ( denis ) hopeless story becomes a muddle, un unsatisfying [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.380 (perp=6.499, rec=0.078, cos=0.002), tot_loss_proj:1.587 [t=0.26s]
prediction: ['[CLS] ( denis ) hopeless story becomes a muddle, unsatisfying un [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.321 (perp=6.213, rec=0.076, cos=0.002), tot_loss_proj:1.565 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a muddle, unsatisfying hopeless [SEP]']
[1050/2000] tot_loss=1.315 (perp=6.213, rec=0.070, cos=0.002), tot_loss_proj:1.555 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a muddle, unsatisfying hopeless [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.245 (perp=5.846, rec=0.074, cos=0.002), tot_loss_proj:1.473 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.254 (perp=5.846, rec=0.082, cos=0.002), tot_loss_proj:1.484 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
[1200/2000] tot_loss=1.250 (perp=5.846, rec=0.079, cos=0.002), tot_loss_proj:1.481 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1250/2000] tot_loss=1.248 (perp=5.846, rec=0.077, cos=0.002), tot_loss_proj:1.476 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1300/2000] tot_loss=1.244 (perp=5.846, rec=0.073, cos=0.002), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
[1350/2000] tot_loss=1.248 (perp=5.846, rec=0.077, cos=0.002), tot_loss_proj:1.481 [t=0.27s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1400/2000] tot_loss=1.245 (perp=5.846, rec=0.074, cos=0.002), tot_loss_proj:1.478 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1450/2000] tot_loss=1.248 (perp=5.846, rec=0.077, cos=0.002), tot_loss_proj:1.476 [t=0.24s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
[1500/2000] tot_loss=1.244 (perp=5.846, rec=0.072, cos=0.002), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1550/2000] tot_loss=1.245 (perp=5.846, rec=0.074, cos=0.002), tot_loss_proj:1.481 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1600/2000] tot_loss=1.241 (perp=5.846, rec=0.069, cos=0.002), tot_loss_proj:1.483 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
[1650/2000] tot_loss=1.244 (perp=5.846, rec=0.073, cos=0.002), tot_loss_proj:1.485 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1700/2000] tot_loss=1.245 (perp=5.846, rec=0.074, cos=0.002), tot_loss_proj:1.482 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1750/2000] tot_loss=1.247 (perp=5.846, rec=0.076, cos=0.002), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
[1800/2000] tot_loss=1.247 (perp=5.846, rec=0.076, cos=0.002), tot_loss_proj:1.480 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1850/2000] tot_loss=1.247 (perp=5.846, rec=0.076, cos=0.002), tot_loss_proj:1.487 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[1900/2000] tot_loss=1.251 (perp=5.846, rec=0.079, cos=0.002), tot_loss_proj:1.486 [t=0.28s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
[1950/2000] tot_loss=1.241 (perp=5.846, rec=0.070, cos=0.002), tot_loss_proj:1.483 [t=0.26s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Attempt swap
[2000/2000] tot_loss=1.237 (perp=5.846, rec=0.066, cos=0.002), tot_loss_proj:1.489 [t=0.25s]
prediction: ['[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( denis ) un story becomes a hopeless muddle, unsatisfying [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 92.418 | p: 91.560 | r: 93.413
rouge2     | fm: 60.145 | p: 59.814 | r: 60.546
rougeL     | fm: 80.290 | p: 79.702 | r: 80.997
rougeLsum  | fm: 80.337 | p: 79.675 | r: 81.017
r1fm+r2fm = 152.564

input #95 time: 0:11:00 | total time: 16:53:08


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
*********************************
*********************************
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8909018635749817 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8791100382804871 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8585579991340637 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8257309794425964 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8243802189826965 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 0.8242563605308533 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8184889554977417 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8130791187286377 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7910962700843811 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7895482182502747 for ['[CLS] wig memoir pondered save august typical smashwords statue sounding projectile spent era livinggn time [SEP]']
[Init] best perm rec loss: 0.7892841100692749 for ['[CLS] living statue sounding eragn pondered smashwords typical projectile time spent save august memoir wig [SEP]']
[Init] best perm rec loss: 0.7874389290809631 for ['[CLS] typical living save sounding wig smashwords august statue time spent projectile era ponderedgn memoir [SEP]']
[Init] best perm rec loss: 0.7851721048355103 for ['[CLS] typical era spent statue smashwords memoir wig sounding august timegn save living pondered projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.700 (perp=11.702, rec=0.316, cos=0.044), tot_loss_proj:3.451 [t=0.26s]
prediction: ['[CLS] force into leaders primarily nobody ( hemingway and everyday curriculum mickey passion people force staff [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.387, rec=0.272, cos=0.026), tot_loss_proj:3.369 [t=0.26s]
prediction: ['[CLS] himself into force ( situations (ian and lesser principle twice romance people force into [SEP]']
[ 150/2000] tot_loss=2.389 (perp=10.784, rec=0.218, cos=0.014), tot_loss_proj:3.466 [t=0.27s]
prediction: ['[CLS] himself into standing here situations (ville and lesser sphere lesser himself people force men [SEP]']
[ 200/2000] tot_loss=2.349 (perp=10.740, rec=0.187, cos=0.013), tot_loss_proj:3.358 [t=0.26s]
prediction: ['[CLS] himself into standing here situations ( on and lesser sphere lesser himself people force men [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.200 (perp=10.082, rec=0.173, cos=0.010), tot_loss_proj:3.368 [t=0.27s]
prediction: ['[CLS] himself into standing sphere situations ( to and lesser tonight lesser himself people force men [SEP]']
[ 300/2000] tot_loss=2.104 (perp=9.736, rec=0.146, cos=0.010), tot_loss_proj:2.911 [t=0.28s]
prediction: ['[CLS] himself on for situations situations from to would lesser and lesser himself people force men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.807 (perp=8.226, rec=0.153, cos=0.009), tot_loss_proj:2.715 [t=0.28s]
prediction: ['[CLS] himself on for situations situations ( to people lesser and lesser himself would force men [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.766 (perp=8.171, rec=0.126, cos=0.006), tot_loss_proj:2.588 [t=0.26s]
prediction: ['[CLS] himself on for cover situations from people to lesser and lesser himself would force men [SEP]']
[ 450/2000] tot_loss=1.800 (perp=8.388, rec=0.118, cos=0.005), tot_loss_proj:2.686 [t=0.24s]
prediction: ['[CLS] himself on cover cover situations from people into lesser and lesser himself would force men [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.643 (perp=7.612, rec=0.116, cos=0.005), tot_loss_proj:2.500 [t=0.26s]
prediction: ['[CLS] himself on cover cover situations & people into lesser and lesser men himself would force [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.606 (perp=7.425, rec=0.115, cos=0.005), tot_loss_proj:2.499 [t=0.26s]
prediction: ['[CLS] cover himself on cover situations & people into lesser and lesser men himself would force [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.425, rec=0.103, cos=0.005), tot_loss_proj:2.502 [t=0.26s]
prediction: ['[CLS] cover himself on cover situations & people into lesser and lesser men himself would force [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.596 (perp=7.425, rec=0.107, cos=0.004), tot_loss_proj:2.508 [t=0.26s]
prediction: ['[CLS] cover himself on cover situations & people into lesser and lesser men himself would force [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.589 (perp=7.425, rec=0.100, cos=0.004), tot_loss_proj:2.507 [t=0.26s]
prediction: ['[CLS] cover himself on cover situations & people into lesser and lesser men himself would force [SEP]']
[ 750/2000] tot_loss=1.961 (perp=9.322, rec=0.093, cos=0.004), tot_loss_proj:2.887 [t=0.27s]
prediction: ['[CLS] cover himself on run situations & people into make and lesser men himself would force [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.809 (perp=8.568, rec=0.092, cos=0.003), tot_loss_proj:2.783 [t=0.28s]
prediction: ['[CLS] cover himself on run & people into make situations and lesser men himself would force [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.703 (perp=8.062, rec=0.087, cos=0.003), tot_loss_proj:2.685 [t=0.25s]
prediction: ['[CLS] cover himself on for people run into make situations and lesser men himself would force [SEP]']
[ 900/2000] tot_loss=1.693 (perp=8.062, rec=0.078, cos=0.003), tot_loss_proj:2.678 [t=0.27s]
prediction: ['[CLS] cover himself on for people run into make situations and lesser men himself would force [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.645 (perp=7.817, rec=0.079, cos=0.003), tot_loss_proj:2.767 [t=0.26s]
prediction: ['[CLS] cover himself on for make people run into situations and lesser men himself would force [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.623 (perp=7.669, rec=0.086, cos=0.003), tot_loss_proj:2.910 [t=0.26s]
prediction: ['[CLS] cover himself on for make people run into situations and lesser men would force himself [SEP]']
[1050/2000] tot_loss=1.609 (perp=7.669, rec=0.072, cos=0.003), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS] cover himself on for make people run into situations and lesser men would force himself [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.585 (perp=7.554, rec=0.072, cos=0.003), tot_loss_proj:2.759 [t=0.26s]
prediction: ['[CLS] cover himself on and make people run into situations for lesser men would force himself [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.553 (perp=7.312, rec=0.087, cos=0.003), tot_loss_proj:2.527 [t=0.26s]
prediction: ['[CLS] himself on cover and make people run into situations for lesser men would force himself [SEP]']
[1200/2000] tot_loss=1.575 (perp=7.523, rec=0.068, cos=0.003), tot_loss_proj:2.721 [t=0.25s]
prediction: ['[CLS] for on cover and make people run into situations for lesser men would force himself [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.530 (perp=7.282, rec=0.071, cos=0.003), tot_loss_proj:2.351 [t=0.26s]
prediction: ['[CLS] himself on cover and make people run into situations for lesser men would force for [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.519 (perp=7.216, rec=0.074, cos=0.002), tot_loss_proj:2.556 [t=0.28s]
prediction: ['[CLS] cover on himself and make people run into situations for lesser men would force for [SEP]']
[1350/2000] tot_loss=1.519 (perp=7.216, rec=0.073, cos=0.002), tot_loss_proj:2.558 [t=0.24s]
prediction: ['[CLS] cover on himself and make people run into situations for lesser men would force for [SEP]']
Attempt swap
[1400/2000] tot_loss=1.524 (perp=7.216, rec=0.079, cos=0.002), tot_loss_proj:2.557 [t=0.26s]
prediction: ['[CLS] cover on himself and make people run into situations for lesser men would force for [SEP]']
Attempt swap
[1450/2000] tot_loss=1.517 (perp=7.216, rec=0.071, cos=0.002), tot_loss_proj:2.554 [t=0.26s]
prediction: ['[CLS] cover on himself and make people run into situations for lesser men would force for [SEP]']
[1500/2000] tot_loss=1.528 (perp=7.216, rec=0.083, cos=0.002), tot_loss_proj:2.564 [t=0.27s]
prediction: ['[CLS] cover on himself and make people run into situations for lesser men would force for [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.498 (perp=7.124, rec=0.070, cos=0.002), tot_loss_proj:2.713 [t=0.26s]
prediction: ['[CLS] for cover on himself and make people run into situations lesser men would force for [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.472 (perp=6.995, rec=0.070, cos=0.002), tot_loss_proj:2.487 [t=0.27s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
[1650/2000] tot_loss=1.476 (perp=6.995, rec=0.075, cos=0.002), tot_loss_proj:2.494 [t=0.26s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
Attempt swap
[1700/2000] tot_loss=1.474 (perp=6.995, rec=0.073, cos=0.002), tot_loss_proj:2.484 [t=0.27s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
Attempt swap
[1750/2000] tot_loss=1.472 (perp=6.995, rec=0.070, cos=0.002), tot_loss_proj:2.485 [t=0.26s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
[1800/2000] tot_loss=1.470 (perp=6.995, rec=0.068, cos=0.002), tot_loss_proj:2.487 [t=0.25s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=6.995, rec=0.066, cos=0.002), tot_loss_proj:2.487 [t=0.26s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
Attempt swap
[1900/2000] tot_loss=1.472 (perp=6.995, rec=0.070, cos=0.002), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
[1950/2000] tot_loss=1.472 (perp=6.995, rec=0.070, cos=0.002), tot_loss_proj:2.484 [t=0.25s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=6.995, rec=0.070, cos=0.002), tot_loss_proj:2.491 [t=0.27s]
prediction: ['[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] on himself for cover and make people run into situations lesser men would force for [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 112.868

[Aggregate metrics]:
rouge1     | fm: 92.464 | p: 91.627 | r: 93.479
rouge2     | fm: 59.883 | p: 59.542 | r: 60.257
rougeL     | fm: 79.955 | p: 79.326 | r: 80.740
rougeLsum  | fm: 79.995 | p: 79.400 | r: 80.771
r1fm+r2fm = 152.347

input #96 time: 0:11:00 | total time: 17:04:08


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
*********************************
*********************************
average of cosine similarity 0.9991660915875737
highest_index [0]
highest [0.9991660915875737]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8396337628364563 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8173046708106995 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8006014823913574 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7802342772483826 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7502726316452026 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7448185682296753 for ['[CLS] working perfectet 140 cam channel [SEP]']
[Init] best perm rec loss: 0.7447396516799927 for ['[CLS] channel cam perfect working 140et [SEP]']
[Init] best perm rec loss: 0.7446287870407104 for ['[CLS] cam channel perfect workinget 140 [SEP]']
[Init] best perm rec loss: 0.7441828846931458 for ['[CLS] cam perfect working 140et channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.899 (perp=12.638, rec=0.348, cos=0.023), tot_loss_proj:4.130 [t=0.25s]
prediction: ['[CLS] une impactget series goddess fantastic [SEP]']
[ 100/2000] tot_loss=2.554 (perp=11.600, rec=0.225, cos=0.009), tot_loss_proj:4.119 [t=0.25s]
prediction: ['[CLS]fortableget characterstable category [SEP]']
[ 150/2000] tot_loss=2.599 (perp=12.135, rec=0.163, cos=0.009), tot_loss_proj:4.282 [t=0.26s]
prediction: ['[CLS]fortableget characterstabletable [SEP]']
[ 200/2000] tot_loss=2.568 (perp=12.135, rec=0.135, cos=0.005), tot_loss_proj:4.264 [t=0.26s]
prediction: ['[CLS]fortableget characterstabletable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.216 (perp=10.484, rec=0.117, cos=0.003), tot_loss_proj:3.985 [t=0.26s]
prediction: ['[CLS]tableforget characterstabletable [SEP]']
[ 300/2000] tot_loss=2.087 (perp=9.900, rec=0.104, cos=0.002), tot_loss_proj:3.619 [t=0.26s]
prediction: ['[CLS]tableforget characters andtable [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.982 (perp=9.372, rec=0.105, cos=0.003), tot_loss_proj:3.049 [t=0.25s]
prediction: ['[CLS]tableforget un characters and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.192 (perp=5.520, rec=0.086, cos=0.002), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 450/2000] tot_loss=1.183 (perp=5.520, rec=0.078, cos=0.002), tot_loss_proj:1.296 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.182 (perp=5.514, rec=0.078, cos=0.002), tot_loss_proj:1.374 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.191 (perp=5.520, rec=0.086, cos=0.002), tot_loss_proj:1.299 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 600/2000] tot_loss=1.186 (perp=5.520, rec=0.081, cos=0.002), tot_loss_proj:1.287 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.188 (perp=5.520, rec=0.083, cos=0.002), tot_loss_proj:1.297 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.182 (perp=5.514, rec=0.077, cos=0.002), tot_loss_proj:1.380 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.377 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.180 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.376 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.172 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.381 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.182 (perp=5.514, rec=0.078, cos=0.002), tot_loss_proj:1.385 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.171 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.382 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.514, rec=0.072, cos=0.002), tot_loss_proj:1.385 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.373 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.373 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.183 (perp=5.514, rec=0.079, cos=0.002), tot_loss_proj:1.373 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.173 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.378 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.178 (perp=5.514, rec=0.074, cos=0.002), tot_loss_proj:1.380 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.173 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.374 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.378 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.376 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.380 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.380 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.381 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.379 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.164 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.376 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.160 (perp=5.514, rec=0.056, cos=0.002), tot_loss_proj:1.385 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.377 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.378 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.170 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.389 [t=0.27s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.157 (perp=5.514, rec=0.053, cos=0.002), tot_loss_proj:1.382 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.379 [t=0.27s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.159 (perp=5.514, rec=0.054, cos=0.002), tot_loss_proj:1.379 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.510 | p: 91.677 | r: 93.522
rouge2     | fm: 59.390 | p: 59.121 | r: 59.704
rougeL     | fm: 79.985 | p: 79.409 | r: 80.774
rougeLsum  | fm: 80.118 | p: 79.559 | r: 80.869
r1fm+r2fm = 151.900

input #97 time: 0:10:55 | total time: 17:15:04


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
*********************************
*********************************
average of cosine similarity 0.9991916976323434
highest_index [0]
highest [0.9991916976323434]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7122125029563904 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7120754718780518 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.709286630153656 for ['[CLS] jed ada nos prohibited [SEP]']
[Init] best perm rec loss: 0.7076743245124817 for ['[CLS] prohibited nos ada jed [SEP]']
[Init] best perm rec loss: 0.7051839828491211 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.643 (perp=11.864, rec=0.252, cos=0.019), tot_loss_proj:3.154 [t=0.25s]
prediction: ['[CLS] unfulful maintenance [SEP]']
[ 100/2000] tot_loss=2.708 (perp=12.917, rec=0.119, cos=0.006), tot_loss_proj:3.198 [t=0.25s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 150/2000] tot_loss=2.682 (perp=12.917, rec=0.095, cos=0.004), tot_loss_proj:3.196 [t=0.26s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 200/2000] tot_loss=2.652 (perp=12.917, rec=0.066, cos=0.002), tot_loss_proj:3.197 [t=0.26s]
prediction: ['[CLS] unfulllingfi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.055 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.077 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.067 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.044 (perp=4.948, rec=0.052, cos=0.002), tot_loss_proj:1.073 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.054 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.056 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.074 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.051 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.061 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.057 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.044 (perp=4.948, rec=0.053, cos=0.002), tot_loss_proj:1.059 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.065 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.053 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.062 (perp=4.948, rec=0.070, cos=0.002), tot_loss_proj:1.053 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.059 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.064 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.068 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.063 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.060 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.055 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.054 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.072 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.060 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.063 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.042 (perp=4.948, rec=0.051, cos=0.002), tot_loss_proj:1.059 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.056 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.044 (perp=4.948, rec=0.053, cos=0.002), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.055 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.064 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.067 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.065 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.058 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.041 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.064 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.052 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.061 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.573 | p: 91.773 | r: 93.541
rouge2     | fm: 59.588 | p: 59.316 | r: 59.942
rougeL     | fm: 80.246 | p: 79.658 | r: 80.992
rougeLsum  | fm: 80.206 | p: 79.588 | r: 80.933
r1fm+r2fm = 152.161

input #98 time: 0:10:57 | total time: 17:26:01


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
*********************************
*********************************
average of cosine similarity 0.9993095816453156
highest_index [0]
highest [0.9993095816453156]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8722755908966064 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8668547868728638 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8600996136665344 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8582916855812073 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8477660417556763 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8349575400352478 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8292847275733948 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.823960542678833 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8212921023368835 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.820878267288208 for ['[CLS]ˈ ferns opposedaging actually orient taste earliest claire slight thunder ratings currently temps bet te distance whente cushion services bearing re barbie knowledgets garcia synonym harper still screens [MASK] dental forced himself right [SEP]']
[Init] best perm rec loss: 0.8208308815956116 for ['[CLS] knowledge ratings re synonym slight currently taste ferns claire actuallyˈ forced garcia bet opposed screens right when orient himself thunder services temps earliest dental cushionts te still harperagingte distance barbie [MASK] bearing [SEP]']
[Init] best perm rec loss: 0.8205059766769409 for ['[CLS] cushionts garcia opposed distance ratings synonym thunder slight bearing ferns when services knowledge taste harper orient clairete forced bet [MASK] temps te currently actually re himself screensˈ rightaging still earliest barbie dental [SEP]']
[Init] best perm rec loss: 0.8195905089378357 for ['[CLS] distance cushion knowledge right services re screens still claire orient dentalaging [MASK] garcia thunder harper synonym taste fernsˈte forced barbie ratings tempsts bet actually when te bearing slight earliest opposed currently himself [SEP]']
[Init] best perm rec loss: 0.818151593208313 for ['[CLS] temps taste re fernsaging forced ratings dentalˈ cushion right claire te garcia slight earliest thunder knowledge actually services himself harper bet screens still orient when [MASK] opposed synonym currently barbiete distance bearingts [SEP]']
[Init] best perm rec loss: 0.8180760741233826 for ['[CLS] ratingsˈ claire thunder betts taste ferns temps garcia still re [MASK] himself slight cushion opposed actuallyte currently screensaging bearing te harper dental right orient services barbie forced distance earliest knowledge when synonym [SEP]']
[Init] best perm rec loss: 0.8174036741256714 for ['[CLS] opposed screens forcedagingts synonym earliest [MASK] garcia claire dental actually barbie orient currently harper thunder ferns slight bearing rete still right temps ratings when cushion te taste distance knowledge himself bet servicesˈ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.473 (perp=10.556, rec=0.335, cos=0.027), tot_loss_proj:3.020 [t=0.29s]
prediction: ["[CLS] non stupidudes'term or off. horrible baby phraseoid cursed just what bad else,'afford course. littleches renamedssingcr writing film - this [SEP]ditional insurance results adventures [SEP]"]
[ 100/2000] tot_loss=2.205 (perp=9.801, rec=0.234, cos=0.011), tot_loss_proj:3.431 [t=0.29s]
prediction: ["[CLS] non stupid found'they choir stupid'di di phrase `ssing but put bads,'afford enjoymentssing little'interferessing'making film - that'walked film fun fun [SEP]"]
[ 150/2000] tot_loss=2.277 (perp=10.344, rec=0.198, cos=0.010), tot_loss_proj:2.933 [t=0.28s]
prediction: ["[CLS] non stupid walked `ally yelling stupid'di dikled `ssing but got horrible ','bills funssing little'interferessing di have film i that the walked film ticket fun [SEP]"]
[ 200/2000] tot_loss=2.131 (perp=9.842, rec=0.158, cos=0.004), tot_loss_proj:3.000 [t=0.30s]
prediction: ["[CLS] non incredibly walked out out muttering terribly'di diur `ssing but put horrible ','mind dissing'' helpssing di had film that this the walked ticket ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.048 (perp=9.530, rec=0.137, cos=0.005), tot_loss_proj:2.575 [t=0.29s]
prediction: ["[CLS] non incredibly walked out out muttering faced'di diur `ssing but'horrible ','mind dissing'' ssrssing di had film that they walked the ticket ticket fun [SEP]"]
[ 300/2000] tot_loss=2.105 (perp=9.858, rec=0.129, cos=0.004), tot_loss_proj:2.802 [t=0.28s]
prediction: ["[CLS] non so walked out out muttering okay ` di diur `ssing but'horrible ','mind dissing'' ssrssing di had film that they walked did ticket ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.863 (perp=8.641, rec=0.130, cos=0.005), tot_loss_proj:2.739 [t=0.31s]
prediction: ["[CLS] non they walked out out muttering not'di di words `ssing but'horrible ','mind dissing bible'joyssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.890 (perp=8.894, rec=0.107, cos=0.004), tot_loss_proj:2.658 [t=0.31s]
prediction: ["[CLS] non they walked out out muttering t'ssing di words ` like but'terrible ','mind dissing bible'publicityssing so had film that they walked did the ticket fun [SEP]"]
[ 450/2000] tot_loss=1.992 (perp=9.410, rec=0.107, cos=0.003), tot_loss_proj:2.819 [t=0.30s]
prediction: ["[CLS] non they walked out out muttering t'ssing di words ` like but ` terrible ','mind diing bible'publicityssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.966 (perp=9.346, rec=0.093, cos=0.003), tot_loss_proj:2.838 [t=0.28s]
prediction: ["[CLS] non they walked out out muttering t'ssing di words like but ` terrible'`'' mind diing bible'normallyssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.868 (perp=8.849, rec=0.095, cos=0.003), tot_loss_proj:2.741 [t=0.29s]
prediction: ["[CLS] non they walked out out muttering t'dissing'like but ` terrible, `'' mind diing bible'`ssing so had film that they walked did the ticket fun [SEP]"]
[ 600/2000] tot_loss=1.894 (perp=8.978, rec=0.095, cos=0.003), tot_loss_proj:2.700 [t=0.29s]
prediction: ["[CLS] non they walked out out muttering t'dissing words like but ` terrible, `'' mind diing bible'`ssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.843 (perp=8.732, rec=0.094, cos=0.003), tot_loss_proj:2.533 [t=0.30s]
prediction: ["[CLS] non we walked out out muttering t'dissing words like but `'terrible, `'mind diing bible'`ssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.788 (perp=8.452, rec=0.095, cos=0.002), tot_loss_proj:2.501 [t=0.27s]
prediction: ["[CLS] non we walked out out muttering t'dissing words like but `'terrible mind, `'diing bible'`ssing so had film that they walked did the ticket fun [SEP]"]
[ 750/2000] tot_loss=1.806 (perp=8.550, rec=0.093, cos=0.003), tot_loss_proj:2.609 [t=0.28s]
prediction: ["[CLS] non we walked out out muttering t'dissing words like but `'terrible mind, `'di much bible'`ssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.766 (perp=8.358, rec=0.092, cos=0.002), tot_loss_proj:2.621 [t=0.26s]
prediction: ["[CLS] ` we walked out out muttering t'dissing words like but `'terrible mind, `'di much bible'nonssing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.731 (perp=8.152, rec=0.098, cos=0.003), tot_loss_proj:2.623 [t=0.26s]
prediction: ["[CLS] they walked out out muttering t'dissing words like but `'terrible mind, ` `'di much bible'nonssing so had film that they walked did the ticket fun [SEP]"]
[ 900/2000] tot_loss=1.740 (perp=8.259, rec=0.086, cos=0.002), tot_loss_proj:2.634 [t=0.25s]
prediction: ["[CLS] they walked out out muttering t'dissing words like but `'terrible mind, ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.698 (perp=7.989, rec=0.098, cos=0.003), tot_loss_proj:2.429 [t=0.26s]
prediction: ["[CLS] we walked out out muttering t'dissing words like but,'terrible mind ` ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.674 (perp=7.910, rec=0.089, cos=0.002), tot_loss_proj:2.379 [t=0.28s]
prediction: ["[CLS] we walked out out muttering t'dissing words like, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
[1050/2000] tot_loss=1.672 (perp=7.910, rec=0.088, cos=0.002), tot_loss_proj:2.369 [t=0.26s]
prediction: ["[CLS] we walked out out muttering t'dissing words like, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.650 (perp=7.807, rec=0.087, cos=0.002), tot_loss_proj:2.305 [t=0.26s]
prediction: ["[CLS] we walked out like muttering t'dissing words out, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.619 (perp=7.641, rec=0.088, cos=0.002), tot_loss_proj:2.171 [t=0.25s]
prediction: ["[CLS] we walked out like muttering t'dissing words, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked out did the ticket fun [SEP]"]
[1200/2000] tot_loss=1.698 (perp=8.061, rec=0.083, cos=0.002), tot_loss_proj:2.406 [t=0.26s]
prediction: ["[CLS] we walked out like muttering t'dissing words, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked words did the ticket fun [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.719 (perp=8.121, rec=0.092, cos=0.002), tot_loss_proj:2.335 [t=0.26s]
prediction: ["[CLS] we walked out like muttering t out'dissing words, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.621 (perp=7.652, rec=0.088, cos=0.002), tot_loss_proj:2.342 [t=0.25s]
prediction: ["[CLS] we walked out like't out muttering dissing words, but'terrible mind ` ` `'di much bible'gavessing so had film that they walked did the ticket fun [SEP]"]
[1350/2000] tot_loss=1.620 (perp=7.686, rec=0.080, cos=0.002), tot_loss_proj:2.326 [t=0.30s]
prediction: ["[CLS] we walked out like't out muttering dissing words, but'terrible mind ` ` `'di much `'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.593 (perp=7.562, rec=0.079, cos=0.002), tot_loss_proj:2.347 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` `'di much `'gavessing so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.542 (perp=7.284, rec=0.082, cos=0.003), tot_loss_proj:2.531 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` `'dissing `'gave much so had film that they walked did the ticket fun [SEP]"]
[1500/2000] tot_loss=1.549 (perp=7.284, rec=0.090, cos=0.002), tot_loss_proj:2.540 [t=0.25s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` `'dissing `'gave much so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.504 (perp=7.073, rec=0.087, cos=0.002), tot_loss_proj:2.444 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` ` `'dissing'gave much so had film that they walked did the ticket fun [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.499 (perp=7.073, rec=0.082, cos=0.002), tot_loss_proj:2.447 [t=0.25s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` ` `'dissing'gave much so had film that they walked did the ticket fun [SEP]"]
[1650/2000] tot_loss=1.496 (perp=7.073, rec=0.079, cos=0.002), tot_loss_proj:2.447 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` ` `'dissing'gave much so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.491 (perp=7.002, rec=0.088, cos=0.002), tot_loss_proj:2.368 [t=0.25s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but mind terrible'` ` ` `'dissing'gave much so had film that they walked did the ticket fun [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.418 (perp=6.632, rec=0.089, cos=0.003), tot_loss_proj:2.516 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but mind terrible'` ` ` `'dissing'gave much fun so had film that they walked did the ticket [SEP]"]
[1800/2000] tot_loss=1.417 (perp=6.632, rec=0.088, cos=0.002), tot_loss_proj:2.510 [t=0.27s]
prediction: ["[CLS] we walked out like't muttering dissing out words, but mind terrible'` ` ` `'dissing'gave much fun so had film that they walked did the ticket [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.412 (perp=6.636, rec=0.083, cos=0.002), tot_loss_proj:2.530 [t=0.25s]
prediction: ["[CLS] we walked out like't muttering dissing words out, but mind terrible'` ` ` `'dissing'gave much fun so had film that they walked did the ticket [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.413 (perp=6.636, rec=0.084, cos=0.002), tot_loss_proj:2.528 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing words out, but mind terrible'` ` ` `'dissing'gave much fun so had film that they walked did the ticket [SEP]"]
[1950/2000] tot_loss=1.410 (perp=6.636, rec=0.081, cos=0.002), tot_loss_proj:2.529 [t=0.26s]
prediction: ["[CLS] we walked out like't muttering dissing words out, but mind terrible'` ` ` `'dissing'gave much fun so had film that they walked did the ticket [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.413 (perp=6.636, rec=0.083, cos=0.002), tot_loss_proj:2.534 [t=0.25s]
prediction: ["[CLS] we walked out like't muttering dissing words out, but mind terrible'` ` ` `'dissing'gave much fun so had film that they walked did the ticket [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] we walked out like't muttering dissing out words, but'terrible mind ` ` `'di much `'gavessing so had film that they walked did the ticket fun [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 79.245 | p: 77.778 | r: 80.769
rouge2     | fm: 15.686 | p: 15.385 | r: 16.000
rougeL     | fm: 49.057 | p: 48.148 | r: 50.000
rougeLsum  | fm: 49.057 | p: 48.148 | r: 50.000
r1fm+r2fm = 94.932

[Aggregate metrics]:
rouge1     | fm: 92.455 | p: 91.632 | r: 93.437
rouge2     | fm: 59.378 | p: 59.110 | r: 59.755
rougeL     | fm: 79.901 | p: 79.307 | r: 80.640
rougeLsum  | fm: 79.991 | p: 79.430 | r: 80.764
r1fm+r2fm = 151.833

input #99 time: 0:11:31 | total time: 17:37:33


Average Cosine Similarity: 0.9992812683158312
Done with all.
