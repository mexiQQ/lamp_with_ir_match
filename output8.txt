


Command: attack3.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --bert_path /hdd1/jianwei/workspace/lamp/models/bert-base-finetuned-sst2 --n_steps 500 





Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
*********************************
*********************************
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0055351257324219 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9447663426399231 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9361805319786072 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9271856546401978 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9249287247657776 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8513282537460327 for ['[CLS] panel officer [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.580 (perp=11.621, rec=0.255, cos=0.001), tot_loss_proj:2.646 [t=0.27s]
prediction: ['[CLS] severe disappointed [SEP]']
Attempt swap
[ 100/ 500] tot_loss=2.218 (perp=10.251, rec=0.174, cos=-0.006), tot_loss_proj:2.103 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/ 500] tot_loss=2.142 (perp=10.251, rec=0.101, cos=-0.009), tot_loss_proj:2.107 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.118 (perp=10.251, rec=0.077, cos=-0.009), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/ 500] tot_loss=2.110 (perp=10.251, rec=0.069, cos=-0.009), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/ 500] tot_loss=2.111 (perp=10.251, rec=0.071, cos=-0.009), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/ 500] tot_loss=2.110 (perp=10.251, rec=0.069, cos=-0.009), tot_loss_proj:2.106 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/ 500] tot_loss=2.107 (perp=10.251, rec=0.066, cos=-0.009), tot_loss_proj:2.097 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/ 500] tot_loss=2.104 (perp=10.251, rec=0.063, cos=-0.009), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/ 500] tot_loss=2.090 (perp=10.251, rec=0.049, cos=-0.009), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:03:29 | total time: 0:03:29


Running input #1 of 100.
reference: 
========================
splendidly 
========================
*********************************
*********************************
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0210397243499756 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9793888926506042 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8951830267906189 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.864271879196167 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8217445015907288 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8215807676315308 for ['[CLS] siam presidents [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.337 (perp=10.521, rec=0.240, cos=-0.007), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS]tically successful [SEP]']
Attempt swap
Swapped tokens
[ 100/ 500] tot_loss=1.949 (perp=9.171, rec=0.124, cos=-0.009), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 150/ 500] tot_loss=1.909 (perp=9.171, rec=0.083, cos=-0.009), tot_loss_proj:1.892 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.891 (perp=9.171, rec=0.066, cos=-0.009), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.893 (perp=9.171, rec=0.068, cos=-0.009), tot_loss_proj:1.886 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/ 500] tot_loss=1.878 (perp=9.171, rec=0.052, cos=-0.009), tot_loss_proj:1.875 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.891 (perp=9.171, rec=0.065, cos=-0.009), tot_loss_proj:1.889 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.875 (perp=9.171, rec=0.050, cos=-0.009), tot_loss_proj:1.885 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/ 500] tot_loss=1.884 (perp=9.171, rec=0.059, cos=-0.009), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.880 (perp=9.171, rec=0.055, cos=-0.009), tot_loss_proj:1.892 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:03:26 | total time: 0:06:56


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
*********************************
*********************************
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8397367596626282 for ['[CLS] washã€œ at [SEP]']
[Init] best rec loss: 0.8254684805870056 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8126578330993652 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.805020809173584 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7947117686271667 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7828556895256042 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7795121073722839 for ['[CLS] would we working [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.575 (perp=10.605, rec=0.443, cos=0.011), tot_loss_proj:2.853 [t=0.20s]
prediction: ['[CLS] very momentum growth [SEP]']
Attempt swap
Put prefix at the end
[ 100/ 500] tot_loss=1.897 (perp=8.515, rec=0.200, cos=-0.006), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/ 500] tot_loss=1.792 (perp=8.515, rec=0.098, cos=-0.009), tot_loss_proj:1.772 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.784 (perp=8.515, rec=0.090, cos=-0.009), tot_loss_proj:1.784 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.772 (perp=8.515, rec=0.079, cos=-0.009), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/ 500] tot_loss=1.766 (perp=8.515, rec=0.073, cos=-0.009), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.760 (perp=8.515, rec=0.066, cos=-0.009), tot_loss_proj:1.788 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.757 (perp=8.515, rec=0.063, cos=-0.009), tot_loss_proj:1.794 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/ 500] tot_loss=1.767 (perp=8.515, rec=0.074, cos=-0.009), tot_loss_proj:1.777 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.762 (perp=8.515, rec=0.068, cos=-0.009), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:03:09 | total time: 0:10:05


Running input #3 of 100.
reference: 
========================
flawless film 
========================
*********************************
*********************************
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0116136074066162 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9035081267356873 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8794226050376892 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8757002949714661 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8483982086181641 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8467844724655151 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8355522155761719 for ['[CLS] anthony robin [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.579 (perp=11.496, rec=0.285, cos=-0.005), tot_loss_proj:2.755 [t=0.25s]
prediction: ['[CLS] smooth flawless [SEP]']
Attempt swap
Moved token
[ 100/ 500] tot_loss=1.799 (perp=8.385, rec=0.130, cos=-0.008), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/ 500] tot_loss=1.730 (perp=8.385, rec=0.062, cos=-0.009), tot_loss_proj:1.748 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 200/ 500] tot_loss=1.726 (perp=8.385, rec=0.058, cos=-0.009), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.733 (perp=8.385, rec=0.065, cos=-0.009), tot_loss_proj:1.739 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/ 500] tot_loss=1.739 (perp=8.385, rec=0.071, cos=-0.009), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.745 (perp=8.385, rec=0.077, cos=-0.009), tot_loss_proj:1.746 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.731 (perp=8.385, rec=0.063, cos=-0.009), tot_loss_proj:1.750 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/ 500] tot_loss=1.720 (perp=8.385, rec=0.052, cos=-0.009), tot_loss_proj:1.743 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.727 (perp=8.385, rec=0.059, cos=-0.009), tot_loss_proj:1.749 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:03:25 | total time: 0:13:31


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
*********************************
*********************************
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0361230373382568 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9819928407669067 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.963243842124939 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9556242823600769 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9394267797470093 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9341257810592651 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9212238788604736 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9182291030883789 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8931007385253906 for ['[CLS] fatedss jack [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.797 (perp=12.580, rec=0.283, cos=-0.002), tot_loss_proj:3.136 [t=0.20s]
prediction: ['[CLS] tires uglyistle [SEP]']
Attempt swap
Put prefix at the end
[ 100/ 500] tot_loss=1.828 (perp=8.428, rec=0.150, cos=-0.007), tot_loss_proj:1.867 [t=0.20s]
prediction: ['[CLS]ly tiresome [SEP]']
[ 150/ 500] tot_loss=1.772 (perp=8.428, rec=0.096, cos=-0.009), tot_loss_proj:1.876 [t=0.21s]
prediction: ['[CLS]ly tiresome [SEP]']
Attempt swap
Moved token
[ 200/ 500] tot_loss=1.576 (perp=7.516, rec=0.082, cos=-0.009), tot_loss_proj:1.565 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/ 500] tot_loss=1.563 (perp=7.516, rec=0.069, cos=-0.009), tot_loss_proj:1.562 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/ 500] tot_loss=1.555 (perp=7.516, rec=0.061, cos=-0.009), tot_loss_proj:1.551 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.564 (perp=7.516, rec=0.070, cos=-0.009), tot_loss_proj:1.562 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.559 (perp=7.516, rec=0.065, cos=-0.009), tot_loss_proj:1.567 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/ 500] tot_loss=1.551 (perp=7.516, rec=0.057, cos=-0.009), tot_loss_proj:1.564 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.555 (perp=7.516, rec=0.061, cos=-0.009), tot_loss_proj:1.562 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:02:39 | total time: 0:16:10


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
*********************************
*********************************
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9572856426239014 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517245292663574 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9491873979568481 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9308651685714722 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.927051305770874 for ['[CLS]iv fl [SEP]']
[Init] best rec loss: 0.9123218059539795 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8898680210113525 for ['[CLS] quiet. [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.630 (perp=12.316, rec=0.174, cos=-0.006), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 100/ 500] tot_loss=2.466 (perp=11.854, rec=0.103, cos=-0.008), tot_loss_proj:2.571 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 150/ 500] tot_loss=2.444 (perp=11.854, rec=0.082, cos=-0.009), tot_loss_proj:2.580 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.433 (perp=11.854, rec=0.071, cos=-0.009), tot_loss_proj:2.581 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 250/ 500] tot_loss=2.426 (perp=11.854, rec=0.064, cos=-0.009), tot_loss_proj:2.571 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/ 500] tot_loss=2.430 (perp=11.854, rec=0.068, cos=-0.009), tot_loss_proj:2.577 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/ 500] tot_loss=2.438 (perp=11.854, rec=0.076, cos=-0.009), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/ 500] tot_loss=2.418 (perp=11.854, rec=0.056, cos=-0.009), tot_loss_proj:2.576 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/ 500] tot_loss=2.419 (perp=11.854, rec=0.057, cos=-0.009), tot_loss_proj:2.567 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/ 500] tot_loss=2.430 (perp=11.854, rec=0.068, cos=-0.009), tot_loss_proj:2.575 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:03:30 | total time: 0:19:40


Running input #6 of 100.
reference: 
========================
grayish 
========================
*********************************
*********************************
average of cosine similarity 0.9992504694447222
highest_index [0]
highest [0.9992504694447222]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9556694626808167 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9542555809020996 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9281026721000671 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.870527982711792 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8636731505393982 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8084701895713806 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7869214415550232 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7772212028503418 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7523331046104431 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7494601011276245 for ['[CLS] too u2 [SEP]']
Nsteps: 500
[  50/ 500] tot_loss=2.083 (perp=8.874, rec=0.306, cos=0.002), tot_loss_proj:2.831 [t=0.27s]
prediction: ['[CLS] evil gray [SEP]']
Attempt swap
[ 100/ 500] tot_loss=1.568 (perp=6.813, rec=0.212, cos=-0.006), tot_loss_proj:2.710 [t=0.26s]
prediction: ['[CLS] gray gray [SEP]']
[ 150/ 500] tot_loss=1.547 (perp=6.813, rec=0.191, cos=-0.007), tot_loss_proj:2.706 [t=0.26s]
prediction: ['[CLS] gray gray [SEP]']
Attempt swap
[ 200/ 500] tot_loss=2.208 (perp=10.460, rec=0.124, cos=-0.008), tot_loss_proj:2.458 [t=0.25s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/ 500] tot_loss=1.716 (perp=8.089, rec=0.107, cos=-0.009), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 300/ 500] tot_loss=1.692 (perp=8.089, rec=0.084, cos=-0.009), tot_loss_proj:1.698 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/ 500] tot_loss=1.667 (perp=8.089, rec=0.058, cos=-0.009), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/ 500] tot_loss=1.678 (perp=8.089, rec=0.069, cos=-0.009), tot_loss_proj:1.673 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[ 450/ 500] tot_loss=1.666 (perp=8.089, rec=0.057, cos=-0.009), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/ 500] tot_loss=1.688 (perp=8.089, rec=0.079, cos=-0.009), tot_loss_proj:1.675 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:03:23 | total time: 0:23:04


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
*********************************
*********************************
average of cosine similarity 0.9991768686555791
highest_index [0]
highest [0.9991768686555791]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9112632274627686 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8373158574104309 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8293389678001404 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7947319149971008 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7944874167442322 for ['[CLS] manual main disease mukherjee pacific animal battalion classics careernies gold 17th none ranide on blow depending sony alec madagascar tourismzed moffat consisting life [SEP]']
[Init] best perm rec loss: 0.7915330529212952 for ['[CLS] blow animal disease manual consistingzedidenies battalion main pacific on career gold madagascar 17th mukherjee sony alec none depending classics ran life tourism moffat [SEP]']
[Init] best perm rec loss: 0.7903832793235779 for ['[CLS] ran tourism career 17th consisting battalionzed classics madagascar depending manual none gold blowide disease life mainnies animal alec pacific sony mukherjee moffat on [SEP]']
[Init] best perm rec loss: 0.790372371673584 for ['[CLS] none consistingnies depending tourism main moffat classics 17th animal blow alec battalion life ran manual on sony madagascar career goldzed diseaseide mukherjee pacific [SEP]']
[Init] best perm rec loss: 0.790019154548645 for ['[CLS] tourism aleczedidenies depending moffat blow 17th none ran pacific sony main gold madagascar mukherjee manual life classics consisting on disease battalion career animal [SEP]']
[Init] best perm rec loss: 0.7886852025985718 for ['[CLS] tourism disease mainide battalionnies 17th moffat on animal madagascar consistingzed life career sony ran pacific gold alec depending mukherjee manual blow none classics [SEP]']
[Init] best perm rec loss: 0.7882210612297058 for ['[CLS] gold 17th on classics sony blow career pacific battalionzed depending tourismnies ran mukherjee animal consisting diseaseide main madagascar life manual moffat alec none [SEP]']
Nsteps: 500
[  50/2000] tot_loss=2.806 (perp=11.896, rec=0.433, cos=-0.006), tot_loss_proj:3.299 [t=0.27s]
prediction: ['[CLS] problem lackoid probably junk government exhaust just failure abandoned problem asbestosute - worst badly attempt bullshit rule allegedly. - discrimination - asshole blocked [SEP]']
[ 100/2000] tot_loss=2.602 (perp=11.315, rec=0.346, cos=-0.007), tot_loss_proj:3.141 [t=0.25s]
prediction: ['[CLS] problem thingoid probably junk government ugly not late damn problem unidentified.pe archdiocese badly attempt issue systemus. instead discrimination - ugly lacked [SEP]']
[ 150/2000] tot_loss=2.260 (perp=9.915, rec=0.285, cos=-0.008), tot_loss_proj:2.866 [t=0.27s]
prediction: ['[CLS] problem was? no ugly if ugly not late no offense unidentified.pe pmid badly were issuedeus. instead illusion - ugly no [SEP]']
[ 200/2000] tot_loss=2.117 (perp=9.319, rec=0.262, cos=-0.009), tot_loss_proj:2.846 [t=0.28s]
prediction: ['[CLS] problem was? is ugly no ugly just late no offense wrong.pe pmid poorly were issuedeus. heville - ugly no [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.194 (perp=9.844, rec=0.235, cos=-0.009), tot_loss_proj:2.838 [t=0.26s]
prediction: ['[CLS] problem isup is ugly no ugly not not no offense wrong.pe pmid no wereesde his. heville - ugly no [SEP]']
[ 300/2000] tot_loss=1.811 (perp=8.033, rec=0.214, cos=-0.009), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] problem isup is ugly no ugly no not no offense..pe : no attempt orde he. heville is ugly no [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.847 (perp=8.368, rec=0.183, cos=-0.010), tot_loss_proj:3.042 [t=0.25s]
prediction: ['[CLS] problem is. is ugly no ugly no not no offense.. he ; no attempt orde groups character he otherwise is cute no [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.899 (perp=8.621, rec=0.185, cos=-0.009), tot_loss_proj:2.666 [t=0.26s]
prediction: ['[CLS] problem is. is ugly not ugly no not no i the. he ; no attempted characterde groups or he otherwise has cute no [SEP]']
[ 450/2000] tot_loss=1.833 (perp=8.390, rec=0.165, cos=-0.010), tot_loss_proj:2.455 [t=0.25s]
prediction: ['[CLS] problem is. is ugly not ugly no not i mind the. he ; no character characterde groups or he otherwise has cute no [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.786 (perp=8.193, rec=0.158, cos=-0.010), tot_loss_proj:2.518 [t=0.29s]
prediction: ['[CLS] problem is. is no not ugly no not ugly mind the. he ; no character characterde groups or he otherwise has cute no [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.674 (perp=7.607, rec=0.162, cos=-0.009), tot_loss_proj:2.414 [t=0.27s]
prediction: ['[CLS] problem is no is no not ugly no not ugly mind the. he ; no character characterde groups or he otherwise has cute. [SEP]']
[ 600/2000] tot_loss=1.615 (perp=7.371, rec=0.151, cos=-0.010), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] problem here no is no not ugly no not ugly mind the. he ; no character character factor groups or he otherwise has love. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.562 (perp=7.099, rec=0.152, cos=-0.010), tot_loss_proj:2.353 [t=0.29s]
prediction: ['[CLS] problem here no is no not ugly no not ugly the mind. he ; no character character factor persons or he otherwise has love. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.581 (perp=7.235, rec=0.143, cos=-0.010), tot_loss_proj:2.271 [t=0.27s]
prediction: ['[CLS] problem here no is or not ugly no not ugly the mind. he ; no character cute factor character or he otherwise has love. [SEP]']
[ 750/2000] tot_loss=1.580 (perp=7.235, rec=0.143, cos=-0.010), tot_loss_proj:2.271 [t=0.25s]
prediction: ['[CLS] problem here no is or not ugly no not ugly the mind. he ; no character cute factor character or he otherwise has love. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.575 (perp=7.255, rec=0.134, cos=-0.010), tot_loss_proj:2.311 [t=0.25s]
prediction: ['[CLS] problem here no is or not ugly i not ugly the mind. he ; no cute factor character character or he otherwise has love. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.665 (perp=7.707, rec=0.133, cos=-0.010), tot_loss_proj:2.400 [t=0.27s]
prediction: ['[CLS] problem no no is or not ugly here i ugly the mind. he ; no cute factor character character or he otherwise has love. [SEP]']
[ 900/2000] tot_loss=1.659 (perp=7.707, rec=0.127, cos=-0.010), tot_loss_proj:2.396 [t=0.27s]
prediction: ['[CLS] problem no no is or not ugly here i ugly the mind. he ; no cute factor character character or he otherwise has love. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.596 (perp=7.412, rec=0.124, cos=-0.010), tot_loss_proj:2.480 [t=0.26s]
prediction: ['[CLS] no no problem is or not ugly here i ugly the mind. he ; no cute factor character character or he otherwise has love. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.489 (perp=6.854, rec=0.128, cos=-0.010), tot_loss_proj:3.147 [t=0.26s]
prediction: ['[CLS] no no problem is i not ugly here or ugly the mind. he ; no cute factor character character or heable has love. [SEP]']
[1050/2000] tot_loss=1.485 (perp=6.854, rec=0.124, cos=-0.010), tot_loss_proj:3.151 [t=0.26s]
prediction: ['[CLS] no no problem is i not ugly here or ugly the mind. he ; no cute factor character character or heable has love. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.435 (perp=6.610, rec=0.123, cos=-0.010), tot_loss_proj:3.120 [t=0.25s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute factor character character or heable has love. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.400 (perp=6.462, rec=0.117, cos=-0.010), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute factor character character or he hasable love. [SEP]']
[1200/2000] tot_loss=1.405 (perp=6.462, rec=0.122, cos=-0.010), tot_loss_proj:2.976 [t=0.27s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute factor character character or he hasable love. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.398 (perp=6.462, rec=0.116, cos=-0.010), tot_loss_proj:2.976 [t=0.26s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute factor character character or he hasable love. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.394 (perp=6.446, rec=0.115, cos=-0.010), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
[1350/2000] tot_loss=1.396 (perp=6.446, rec=0.117, cos=-0.010), tot_loss_proj:2.857 [t=0.26s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.388 (perp=6.446, rec=0.109, cos=-0.010), tot_loss_proj:2.856 [t=0.27s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.389 (perp=6.446, rec=0.109, cos=-0.010), tot_loss_proj:2.847 [t=0.26s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
[1500/2000] tot_loss=1.390 (perp=6.446, rec=0.111, cos=-0.010), tot_loss_proj:2.851 [t=0.28s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.387 (perp=6.446, rec=0.108, cos=-0.010), tot_loss_proj:2.855 [t=0.27s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.380 (perp=6.446, rec=0.101, cos=-0.010), tot_loss_proj:2.864 [t=0.29s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
[1650/2000] tot_loss=1.387 (perp=6.446, rec=0.108, cos=-0.010), tot_loss_proj:2.861 [t=0.28s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.382 (perp=6.446, rec=0.102, cos=-0.010), tot_loss_proj:2.862 [t=0.31s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.393 (perp=6.446, rec=0.114, cos=-0.010), tot_loss_proj:2.860 [t=0.28s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
[1800/2000] tot_loss=1.388 (perp=6.446, rec=0.108, cos=-0.010), tot_loss_proj:2.862 [t=0.27s]
prediction: ['[CLS] no no problem here is i not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.381 (perp=6.437, rec=0.104, cos=-0.010), tot_loss_proj:2.710 [t=0.28s]
prediction: ['[CLS] i no problem here is no not ugly or ugly the mind. he ; no cute character factor character or he hasable love. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.357 (perp=6.277, rec=0.111, cos=-0.010), tot_loss_proj:3.119 [t=0.26s]
prediction: ['[CLS] i no problem here is not no ugly or ugly the mind. he ; no cute character factor character, he hasable love. [SEP]']
[1950/2000] tot_loss=1.349 (perp=6.277, rec=0.103, cos=-0.010), tot_loss_proj:3.122 [t=0.29s]
prediction: ['[CLS] i no problem here is not no ugly or ugly the mind. he ; no cute character factor character, he hasable love. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.351 (perp=6.277, rec=0.106, cos=-0.010), tot_loss_proj:3.116 [t=0.21s]
prediction: ['[CLS] i no problem here is not no ugly or ugly the mind. he ; no cute character factor character, he hasable love. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] i no problem here is not no ugly or ugly the mind. he ; no cute character factor character, he hasable love. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.273 | p: 73.913 | r: 80.952
rouge2     | fm: 9.524 | p: 9.091 | r: 10.000
rougeL     | fm: 45.455 | p: 43.478 | r: 47.619
rougeLsum  | fm: 45.455 | p: 43.478 | r: 47.619
r1fm+r2fm = 86.797

[Aggregate metrics]:
rouge1     | fm: 97.159 | p: 96.739 | r: 97.619
rouge2     | fm: 76.190 | p: 76.136 | r: 76.250
rougeL     | fm: 90.057 | p: 89.810 | r: 90.327
rougeLsum  | fm: 90.057 | p: 89.810 | r: 90.327
r1fm+r2fm = 173.350

input #7 time: 0:11:00 | total time: 0:34:05


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
*********************************
*********************************
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7545608878135681 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7099087834358215 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6953709125518799 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6868163347244263 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6856463551521301 for ['[CLS] shouts guards germany space establishments sometimes flags dead rear protestant floyd breed article gut id occupational development institute loss joint hull meat mode required [SEP]']
[Init] best rec loss: 0.6826488375663757 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6799412369728088 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6793580651283264 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6682642102241516 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6651372313499451 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6647960543632507 for ['[CLS] si socially tail dna wanda res arkansas february eisenhower screens sweat season franchiseey prison adventure product canonmeitta facts badminton plaquedent [SEP]']
[Init] best perm rec loss: 0.6633939146995544 for ['[CLS] dna sweat factsttadent sociallymei arkansas eisenhower si franchise canon adventure plaque season product tail res prison screens badminton wanda februaryey [SEP]']
[Init] best perm rec loss: 0.6628186106681824 for ['[CLS]mei si franchise wanda sweat product dna adventure eisenhowertta arkansas seasoney canon plaquedent tail february facts screens badminton res prison socially [SEP]']
[Init] best perm rec loss: 0.6616048216819763 for ['[CLS] res product socially badminton tail arkansas february facts sweat wandameident prison plaque eisenhower franchise adventure sitta dna seasoney screens canon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.014 (perp=12.983, rec=0.421, cos=-0.003), tot_loss_proj:4.175 [t=0.21s]
prediction: ['[CLS] feeed prison remorse day felix puerto owed criminal partners crimes owed prison opera institute bargain bitch hearingsvita gift limousine strap kidnapping criminals [SEP]']
[ 100/2000] tot_loss=3.026 (perp=13.441, rec=0.339, cos=-0.002), tot_loss_proj:4.163 [t=0.21s]
prediction: ['[CLS] feeed creation frankenstein vanity broadway puerto vanity off colombia debt whatever prisonless film perception helena vanity redding gift vanity strap mimic vanity [SEP]']
[ 150/2000] tot_loss=2.855 (perp=12.919, rec=0.279, cos=-0.007), tot_loss_proj:4.105 [t=0.21s]
prediction: ['[CLS] beauxed film vanity vanity :ata vanity un colombia debt whatever debt gambling film vanity natalie vanity redding serum vanity pays vanity vanity [SEP]']
[ 200/2000] tot_loss=2.822 (perp=12.863, rec=0.256, cos=-0.006), tot_loss_proj:4.002 [t=0.21s]
prediction: ['[CLS] beauxed film vanity vanity :ata vanity tiberius colombia debt what debt gambling film vanity drama vanity notorious horror vanity pays vanity vanity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.643 (perp=12.011, rec=0.248, cos=-0.008), tot_loss_proj:3.823 [t=0.21s]
prediction: ['[CLS] dollarsed film vanity vanity : vanity doubt dread colombia debt what debt vanity film vanity curiosity vanity cocaine horror entertain pays vanity vanity [SEP]']
[ 300/2000] tot_loss=2.496 (perp=11.446, rec=0.217, cos=-0.010), tot_loss_proj:3.873 [t=0.21s]
prediction: ['[CLS] dollars doubt film vanity vanity : vanity doubt dread film debt what debt vanity film vanity movies vanity cocaine horror entertain pays vanity vanity [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.439 (perp=11.230, rec=0.199, cos=-0.006), tot_loss_proj:3.840 [t=0.21s]
prediction: ['[CLS] dollars doubt film vanity vanity : vanity doubt film dread debt what debt vanity film vanity attempt vanity cruiser horror rid pays vanity vanity [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.508 (perp=11.643, rec=0.188, cos=-0.008), tot_loss_proj:3.761 [t=0.21s]
prediction: ['[CLS] dollars s film vanity vanity : vanity doubt europe dread debt what debt vanity film grove that vanity cruiser monster vanity pays vanity vanity [SEP]']
[ 450/2000] tot_loss=2.524 (perp=11.780, rec=0.177, cos=-0.009), tot_loss_proj:3.720 [t=0.21s]
prediction: ["[CLS]'s film vanity vanity films vanity doubt europe dread debt what debt vanity film grove that vanity cruiser monster vanity pays vanity vanity [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.458 (perp=11.490, rec=0.170, cos=-0.010), tot_loss_proj:3.599 [t=0.21s]
prediction: ["[CLS]'s film dread vanity vanity film vanity doubt europe owed what debt vanity film lay that vanity fargo begun vanity pays vanity vanity [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.488 (perp=11.606, rec=0.175, cos=-0.009), tot_loss_proj:3.629 [t=0.21s]
prediction: ["[CLS]'s film dread vanity vanity film vanity doubt europe owed what debt vanity easier lay that felt orson film vanity pays vanity vanity [SEP]"]
[ 600/2000] tot_loss=2.434 (perp=11.386, rec=0.167, cos=-0.010), tot_loss_proj:3.512 [t=0.21s]
prediction: ["[CLS]'s film t vanity vanity film vanity doubt europe owed what debt fright easier lay that feltmax film vanity pays fright vanity [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.384 (perp=11.181, rec=0.157, cos=-0.010), tot_loss_proj:3.550 [t=0.21s]
prediction: ["[CLS]'s film'vanity vanity film vanity doubt europe owed what debt fright easier lay that vanitymax film vanity pays fright felt [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=2.323 (perp=10.826, rec=0.165, cos=-0.007), tot_loss_proj:3.655 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity vanity film vanity europe owed what debt fright easier lay that vanity sentence film vanity pays fright felt [SEP]"]
[ 750/2000] tot_loss=2.260 (perp=10.583, rec=0.154, cos=-0.010), tot_loss_proj:3.566 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity vanity film vanity europe owed what debt fright easier lay that vanitymax film vanity pays fright felt [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=2.265 (perp=10.605, rec=0.154, cos=-0.010), tot_loss_proj:3.621 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity vanity film vanity refused owed what debt fright easier lay that vanity film vanity pays frightmax felt [SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.221 (perp=10.380, rec=0.154, cos=-0.009), tot_loss_proj:3.490 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity film vanity refused vanity owed what debt fright easier lay that vanity film vanity pays frightmax felt [SEP]"]
[ 900/2000] tot_loss=2.207 (perp=10.380, rec=0.141, cos=-0.010), tot_loss_proj:3.491 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity film vanity refused vanity owed what debt fright easier lay that vanity film vanity pays frightmax felt [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.177 (perp=10.184, rec=0.150, cos=-0.010), tot_loss_proj:3.413 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity film vanity refused vanity owed what lay fright easier debt that vanity film vanity pays frightmax felt [SEP]"]
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.176 (perp=10.241, rec=0.137, cos=-0.010), tot_loss_proj:3.443 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity film vanity refused vanity owed what easier debt lay fright that vanity film vanity pays frightmax felt [SEP]"]
[1050/2000] tot_loss=2.172 (perp=10.241, rec=0.134, cos=-0.010), tot_loss_proj:3.440 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity film vanity refused vanity owed what easier debt lay fright that vanity film vanity pays frightmax felt [SEP]"]
Attempt swap
[1100/2000] tot_loss=2.179 (perp=10.241, rec=0.141, cos=-0.010), tot_loss_proj:3.444 [t=0.21s]
prediction: ["[CLS]'s film doubt'vanity film vanity refused vanity owed what easier debt lay fright that vanity film vanity pays frightmax felt [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.048 (perp=9.554, rec=0.144, cos=-0.007), tot_loss_proj:3.259 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity, vanity pays what easier debt lay fright that vanity film vanity owed frightmax felt [SEP]"]
[1200/2000] tot_loss=2.032 (perp=9.558, rec=0.130, cos=-0.010), tot_loss_proj:3.193 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what easier debt lay fright that vanity film vanity owed frightmax felt [SEP]"]
Attempt swap
[1250/2000] tot_loss=2.038 (perp=9.558, rec=0.136, cos=-0.010), tot_loss_proj:3.193 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what easier debt lay fright that vanity film vanity owed frightmax felt [SEP]"]
Attempt swap
[1300/2000] tot_loss=2.034 (perp=9.558, rec=0.132, cos=-0.010), tot_loss_proj:3.195 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what easier debt lay fright that vanity film vanity owed frightmax felt [SEP]"]
[1350/2000] tot_loss=2.032 (perp=9.558, rec=0.130, cos=-0.010), tot_loss_proj:3.195 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what easier debt lay fright that vanity film vanity owed frightmax felt [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.083 (perp=9.784, rec=0.136, cos=-0.010), tot_loss_proj:3.164 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun fright lay debt that vanity film vanity owed frightmax felt [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=2.027 (perp=9.532, rec=0.131, cos=-0.010), tot_loss_proj:3.117 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity owed frightmax felt [SEP]"]
[1500/2000] tot_loss=2.029 (perp=9.532, rec=0.133, cos=-0.010), tot_loss_proj:3.122 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity owed frightmax felt [SEP]"]
Attempt swap
[1550/2000] tot_loss=2.017 (perp=9.532, rec=0.120, cos=-0.010), tot_loss_proj:3.118 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity owed frightmax felt [SEP]"]
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.015 (perp=9.478, rec=0.129, cos=-0.010), tot_loss_proj:2.946 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity frightmax felt owed [SEP]"]
[1650/2000] tot_loss=2.018 (perp=9.478, rec=0.133, cos=-0.010), tot_loss_proj:2.946 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity frightmax felt owed [SEP]"]
Attempt swap
[1700/2000] tot_loss=2.014 (perp=9.478, rec=0.129, cos=-0.010), tot_loss_proj:2.950 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity frightmax felt owed [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.018 (perp=9.478, rec=0.132, cos=-0.010), tot_loss_proj:2.952 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity frightmax felt owed [SEP]"]
[1800/2000] tot_loss=2.022 (perp=9.478, rec=0.137, cos=-0.010), tot_loss_proj:2.956 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity frightmax felt owed [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=2.011 (perp=9.478, rec=0.125, cos=-0.010), tot_loss_proj:3.026 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity felt frightmax owed [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.020 (perp=9.489, rec=0.132, cos=-0.010), tot_loss_proj:3.029 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays begun what lay fright debt that vanity film vanity felt frightmax owed [SEP]"]
[1950/2000] tot_loss=2.016 (perp=9.489, rec=0.128, cos=-0.010), tot_loss_proj:3.027 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays begun what lay fright debt that vanity film vanity felt frightmax owed [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.016 (perp=9.489, rec=0.129, cos=-0.010), tot_loss_proj:3.025 [t=0.21s]
prediction: ["[CLS]'s a doubt'vanity film vanity no vanity pays begun what lay fright debt that vanity film vanity felt frightmax owed [SEP]"]
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS]'s a doubt'vanity film vanity no vanity pays what begun lay fright debt that vanity film vanity felt frightmax owed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.116 | p: 60.870 | r: 70.000
rouge2     | fm: 14.634 | p: 13.636 | r: 15.789
rougeL     | fm: 55.814 | p: 52.174 | r: 60.000
rougeLsum  | fm: 55.814 | p: 52.174 | r: 60.000
r1fm+r2fm = 79.750

[Aggregate metrics]:
rouge1     | fm: 93.599 | p: 92.754 | r: 94.550
rouge2     | fm: 69.351 | p: 69.192 | r: 69.532
rougeL     | fm: 86.252 | p: 85.628 | r: 86.958
rougeLsum  | fm: 86.252 | p: 85.628 | r: 86.958
r1fm+r2fm = 162.950

input #8 time: 0:08:23 | total time: 0:42:29


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
*********************************
*********************************
average of cosine similarity 0.9993981275486598
highest_index [0]
highest [0.9993981275486598]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8187081217765808 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7782889604568481 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7333240509033203 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7192718386650085 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6858556866645813 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6808661222457886 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6510923504829407 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6500662565231323 for ['[CLS] cody luck deaths outlaw decca arsenaldden edward [SEP]']
[Init] best perm rec loss: 0.6491195559501648 for ['[CLS]dden deaths arsenal luck decca outlaw cody edward [SEP]']
[Init] best perm rec loss: 0.648005485534668 for ['[CLS] outlaw deaths luckdden cody edward arsenal decca [SEP]']
[Init] best perm rec loss: 0.6462655663490295 for ['[CLS] decca cody luck edward deaths outlawdden arsenal [SEP]']
[Init] best perm rec loss: 0.6440391540527344 for ['[CLS] cody decca deaths arsenal luck edwarddden outlaw [SEP]']
[Init] best perm rec loss: 0.6436610221862793 for ['[CLS] cody decca outlaw luck arsenal edwarddden deaths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.967 (perp=13.047, rec=0.357, cos=0.001), tot_loss_proj:3.821 [t=0.27s]
prediction: ['[CLS] bubba double rope crazylogue pu keeper would [SEP]']
[ 100/2000] tot_loss=2.767 (perp=12.417, rec=0.291, cos=-0.008), tot_loss_proj:4.260 [t=0.28s]
prediction: ['[CLS] her double turbo metaphysical clap extremely clap will [SEP]']
[ 150/2000] tot_loss=2.368 (perp=10.716, rec=0.232, cos=-0.007), tot_loss_proj:3.625 [t=0.27s]
prediction: ['[CLS] oftra clap soft clap ethical claps [SEP]']
[ 200/2000] tot_loss=2.469 (perp=11.469, rec=0.183, cos=-0.008), tot_loss_proj:3.491 [t=0.26s]
prediction: ['[CLS] oftra clap softhead clap claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.066 (perp=9.192, rec=0.234, cos=-0.006), tot_loss_proj:2.690 [t=0.26s]
prediction: ['[CLS] of claptra softhead clap claptra [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.072, rec=0.185, cos=-0.009), tot_loss_proj:2.704 [t=0.28s]
prediction: ['[CLS] of claptra softhead clap clapp [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.838 (perp=8.381, rec=0.171, cos=-0.009), tot_loss_proj:2.680 [t=0.28s]
prediction: ['[CLS] of claptrap softhead clap clap [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.752 (perp=8.007, rec=0.159, cos=-0.009), tot_loss_proj:2.536 [t=0.27s]
prediction: ['[CLS] of claptrap soft clap claphead [SEP]']
[ 450/2000] tot_loss=2.242 (perp=10.445, rec=0.156, cos=-0.003), tot_loss_proj:2.949 [t=0.27s]
prediction: ['[CLS] of claptrap softtra claphead [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.601 (perp=7.381, rec=0.135, cos=-0.009), tot_loss_proj:2.310 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.602 (perp=7.381, rec=0.135, cos=-0.010), tot_loss_proj:2.321 [t=0.26s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.381, rec=0.128, cos=-0.010), tot_loss_proj:2.322 [t=0.28s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.592 (perp=7.381, rec=0.125, cos=-0.009), tot_loss_proj:2.319 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.582 (perp=7.381, rec=0.115, cos=-0.010), tot_loss_proj:2.316 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
[ 750/2000] tot_loss=1.578 (perp=7.381, rec=0.111, cos=-0.010), tot_loss_proj:2.315 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.565 (perp=7.381, rec=0.099, cos=-0.010), tot_loss_proj:2.319 [t=0.28s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.569 (perp=7.381, rec=0.102, cos=-0.010), tot_loss_proj:2.316 [t=0.28s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
[ 900/2000] tot_loss=1.566 (perp=7.381, rec=0.100, cos=-0.010), tot_loss_proj:2.321 [t=0.26s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.572 (perp=7.381, rec=0.105, cos=-0.009), tot_loss_proj:2.318 [t=0.28s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[1000/2000] tot_loss=1.562 (perp=7.381, rec=0.095, cos=-0.010), tot_loss_proj:2.318 [t=0.28s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
[1050/2000] tot_loss=1.567 (perp=7.381, rec=0.100, cos=-0.010), tot_loss_proj:2.320 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[1100/2000] tot_loss=1.567 (perp=7.381, rec=0.100, cos=-0.010), tot_loss_proj:2.323 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[1150/2000] tot_loss=1.573 (perp=7.381, rec=0.106, cos=-0.010), tot_loss_proj:2.312 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
[1200/2000] tot_loss=1.567 (perp=7.381, rec=0.101, cos=-0.010), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[1250/2000] tot_loss=1.563 (perp=7.381, rec=0.096, cos=-0.010), tot_loss_proj:2.324 [t=0.26s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.381, rec=0.100, cos=-0.010), tot_loss_proj:2.327 [t=0.28s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
[1350/2000] tot_loss=1.560 (perp=7.381, rec=0.094, cos=-0.010), tot_loss_proj:2.325 [t=0.27s]
prediction: ['[CLS] of claptrap soft claptrahead [SEP]']
Attempt swap
[1400/2000] tot_loss=2.129 (perp=10.219, rec=0.095, cos=-0.010), tot_loss_proj:2.928 [t=0.26s]
prediction: ['[CLS] of clapedp soft claptrahead [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.832 (perp=8.706, rec=0.100, cos=-0.009), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
[1500/2000] tot_loss=1.831 (perp=8.706, rec=0.099, cos=-0.010), tot_loss_proj:2.317 [t=0.26s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
Attempt swap
[1550/2000] tot_loss=1.834 (perp=8.706, rec=0.103, cos=-0.010), tot_loss_proj:2.318 [t=0.25s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
Attempt swap
[1600/2000] tot_loss=1.822 (perp=8.706, rec=0.091, cos=-0.010), tot_loss_proj:2.314 [t=0.26s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
[1650/2000] tot_loss=1.824 (perp=8.706, rec=0.093, cos=-0.010), tot_loss_proj:2.326 [t=0.26s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
Attempt swap
[1700/2000] tot_loss=1.824 (perp=8.706, rec=0.092, cos=-0.010), tot_loss_proj:2.315 [t=0.25s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
Attempt swap
[1750/2000] tot_loss=1.826 (perp=8.706, rec=0.094, cos=-0.010), tot_loss_proj:2.323 [t=0.27s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
[1800/2000] tot_loss=1.833 (perp=8.706, rec=0.101, cos=-0.010), tot_loss_proj:2.317 [t=0.26s]
prediction: ['[CLS] of claped claptrap softhead [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.747 (perp=8.277, rec=0.101, cos=-0.009), tot_loss_proj:2.499 [t=0.27s]
prediction: ['[CLS] of claptrap soft clapedhead [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.626 (perp=7.651, rec=0.104, cos=-0.009), tot_loss_proj:2.149 [t=0.26s]
prediction: ['[CLS] of claptrap soft clapheaded [SEP]']
[1950/2000] tot_loss=1.621 (perp=7.651, rec=0.100, cos=-0.009), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] of claptrap soft clapheaded [SEP]']
Attempt swap
[2000/2000] tot_loss=1.623 (perp=7.651, rec=0.103, cos=-0.010), tot_loss_proj:2.152 [t=0.26s]
prediction: ['[CLS] of claptrap soft clapheaded [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of claptrap soft claptrahead [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 86.667

[Aggregate metrics]:
rouge1     | fm: 90.906 | p: 90.145 | r: 91.762
rouge2     | fm: 64.416 | p: 64.273 | r: 64.579
rougeL     | fm: 84.672 | p: 83.913 | r: 85.333
rougeLsum  | fm: 84.496 | p: 83.768 | r: 84.929
r1fm+r2fm = 155.321

input #9 time: 0:11:08 | total time: 0:53:37


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
*********************************
*********************************
average of cosine similarity 0.9991472052153931
highest_index [0]
highest [0.9991472052153931]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8814778923988342 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8704736828804016 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8242684602737427 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8198046684265137 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8065224885940552 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8059665560722351 for ['[CLS] help reachercar hid championship immediately besideselin accompanied eva nervous pounded swing [SEP]']
[Init] best perm rec loss: 0.8049544095993042 for ['[CLS] help nervouscarelin besides reacher championship swing pounded hid immediately accompanied eva [SEP]']
[Init] best perm rec loss: 0.8048099279403687 for ['[CLS] hid helpcar pounded eva immediately besideselin swing reacher championship accompanied nervous [SEP]']
[Init] best perm rec loss: 0.8033286333084106 for ['[CLS] besides nervous immediately eva hid swing pounded reacherelincar accompanied help championship [SEP]']
[Init] best perm rec loss: 0.8032909035682678 for ['[CLS]car championship hid accompanied reacher swing evaelin immediately nervous help pounded besides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.124 (perp=13.748, rec=0.378, cos=-0.004), tot_loss_proj:3.727 [t=0.25s]
prediction: ['[CLS] ab enterprise sweet, pictorialion eva institution traditionally maddie dynamics henry pieces [SEP]']
[ 100/2000] tot_loss=2.549 (perp=11.358, rec=0.286, cos=-0.008), tot_loss_proj:3.293 [t=0.26s]
prediction: ['[CLS] ab compositions often, based stress balance experimental independent jacket dynamics ; outward [SEP]']
[ 150/2000] tot_loss=2.542 (perp=11.568, rec=0.236, cos=-0.008), tot_loss_proj:3.495 [t=0.27s]
prediction: ['[CLS] ab compositions quickly. balance balance balance experimental independent maddie percussion ; spectators [SEP]']
[ 200/2000] tot_loss=2.379 (perp=10.348, rec=0.307, cos=0.003), tot_loss_proj:3.348 [t=0.27s]
prediction: ['[CLS] ab compositions quickly. balance balance balance balance independently prop rhythms. always [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.157 (perp=9.794, rec=0.206, cos=-0.009), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] quickly compositions ablyulsive balance balance balancely caliber rhythms. when [SEP]']
[ 300/2000] tot_loss=2.200 (perp=10.169, rec=0.174, cos=-0.008), tot_loss_proj:2.923 [t=0.24s]
prediction: ['[CLS]ulsive rhythms ablyulsive balance balance balancely caliber rhythms. when [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.116 (perp=9.542, rec=0.215, cos=-0.008), tot_loss_proj:2.977 [t=0.26s]
prediction: ['[CLS]ulsive rhythms abulsivelyæ­¢ balance productionly business rhythms. when [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.026 (perp=9.221, rec=0.190, cos=-0.008), tot_loss_proj:3.096 [t=0.26s]
prediction: ['[CLS]æ­¢ulsive rhythms abulsively balance prophecyly. rhythms. when [SEP]']
[ 450/2000] tot_loss=2.031 (perp=9.365, rec=0.167, cos=-0.009), tot_loss_proj:2.881 [t=0.25s]
prediction: ['[CLS] balanceulsive rhythms abulsively balance balancelycraft rhythms. when [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.216 (perp=10.314, rec=0.162, cos=-0.009), tot_loss_proj:3.260 [t=0.27s]
prediction: ['[CLS] balance imaginary rhythms abulsive with balanceulsivelycraft rhythms. incident [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.111 (perp=9.678, rec=0.183, cos=-0.007), tot_loss_proj:3.200 [t=0.26s]
prediction: ['[CLS] balance imaginary rhythms abulsive with balanceulsively incident rhythms. admission [SEP]']
[ 600/2000] tot_loss=2.062 (perp=9.614, rec=0.148, cos=-0.009), tot_loss_proj:3.291 [t=0.26s]
prediction: ['[CLS] balance imaginary rhythms abulsive with balanceulsively incident rhythms. incident [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.836 (perp=8.528, rec=0.140, cos=-0.009), tot_loss_proj:2.790 [t=0.26s]
prediction: ['[CLS] incident real rhythms abulsive with balanceulsively balance rhythms.. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.738 (perp=8.042, rec=0.138, cos=-0.009), tot_loss_proj:2.701 [t=0.28s]
prediction: ['[CLS] incidentulsive rhythms ab real with balanceulsively balance rhythms.. [SEP]']
[ 750/2000] tot_loss=1.923 (perp=8.988, rec=0.134, cos=-0.009), tot_loss_proj:3.031 [t=0.26s]
prediction: ['[CLS] incidentulsive rhythms ab real with balanceulsively balance rhythms. incident [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.915 (perp=8.892, rec=0.146, cos=-0.009), tot_loss_proj:3.081 [t=0.26s]
prediction: ['[CLS]ulsive incident rhythms ab real with balanceulsively balance rhythms. incident [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.365 (perp=10.135, rec=0.326, cos=0.013), tot_loss_proj:3.601 [t=0.24s]
prediction: ['[CLS]ulsive incident rhythms ab marx with balanceulsivelyinging - incident rhythms [SEP]']
[ 900/2000] tot_loss=2.282 (perp=10.135, rec=0.258, cos=-0.003), tot_loss_proj:3.608 [t=0.26s]
prediction: ['[CLS]ulsive incident rhythms ab marx with balanceulsivelyinging - incident rhythms [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.159 (perp=9.589, rec=0.246, cos=-0.005), tot_loss_proj:3.557 [t=0.26s]
prediction: ['[CLS]ulsive incident rhythms ab balance with marxulsivelyinging - incident rhythms [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.183 (perp=9.848, rec=0.219, cos=-0.005), tot_loss_proj:3.750 [t=0.27s]
prediction: ['[CLS]llum incident rhythms ab balance marxulsively withinging - incident rhythms [SEP]']
[1050/2000] tot_loss=2.105 (perp=9.483, rec=0.215, cos=-0.007), tot_loss_proj:3.675 [t=0.26s]
prediction: ['[CLS]llum incident rhythms ab balance nonulsively withinging - incident rhythms [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.014 (perp=9.082, rec=0.204, cos=-0.007), tot_loss_proj:3.611 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balance nonulsively withinging -llum incident rhythms [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.924 (perp=8.669, rec=0.197, cos=-0.007), tot_loss_proj:3.464 [t=0.28s]
prediction: ['[CLS] incident rhythms ab balanceulsively with noninging -llum incident rhythms [SEP]']
[1200/2000] tot_loss=1.916 (perp=8.669, rec=0.190, cos=-0.007), tot_loss_proj:3.463 [t=0.28s]
prediction: ['[CLS] incident rhythms ab balanceulsively with noninging -llum incident rhythms [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.914 (perp=8.661, rec=0.189, cos=-0.007), tot_loss_proj:3.357 [t=0.25s]
prediction: ['[CLS] incident rhythms ab balanceulsively with nonulsiveinging - incident rhythms [SEP]']
Attempt swap
[1300/2000] tot_loss=1.906 (perp=8.661, rec=0.181, cos=-0.008), tot_loss_proj:3.355 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively with nonulsiveinging - incident rhythms [SEP]']
[1350/2000] tot_loss=1.905 (perp=8.661, rec=0.180, cos=-0.008), tot_loss_proj:3.351 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively with nonulsiveinging - incident rhythms [SEP]']
Attempt swap
[1400/2000] tot_loss=1.890 (perp=8.661, rec=0.165, cos=-0.008), tot_loss_proj:3.352 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively with nonulsiveinging - incident rhythms [SEP]']
Attempt swap
[1450/2000] tot_loss=2.026 (perp=9.307, rec=0.172, cos=-0.008), tot_loss_proj:3.549 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively with nonulsiveingingly incident rhythms [SEP]']
[1500/2000] tot_loss=1.990 (perp=9.103, rec=0.177, cos=-0.008), tot_loss_proj:3.474 [t=0.25s]
prediction: ['[CLS] incident rhythms ab balanceulsively with nonulsive balancely incident rhythms [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.994 (perp=9.129, rec=0.177, cos=-0.008), tot_loss_proj:3.546 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively with noningingulsively incident rhythms [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.878 (perp=8.593, rec=0.167, cos=-0.008), tot_loss_proj:3.322 [t=0.25s]
prediction: ['[CLS] incident rhythms ab balanceulsively with balance nonulsively incident rhythms [SEP]']
[1650/2000] tot_loss=1.872 (perp=8.593, rec=0.162, cos=-0.008), tot_loss_proj:3.319 [t=0.25s]
prediction: ['[CLS] incident rhythms ab balanceulsively with balance nonulsively incident rhythms [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.879 (perp=8.533, rec=0.180, cos=-0.008), tot_loss_proj:3.281 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively with balanceulsively non incident rhythms [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.825 (perp=8.298, rec=0.173, cos=-0.008), tot_loss_proj:3.462 [t=0.27s]
prediction: ['[CLS] incident rhythms ab balanceulsively non balanceulsively with incident rhythms [SEP]']
[1800/2000] tot_loss=1.834 (perp=8.298, rec=0.183, cos=-0.008), tot_loss_proj:3.464 [t=0.26s]
prediction: ['[CLS] incident rhythms ab balanceulsively non balanceulsively with incident rhythms [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.820 (perp=8.298, rec=0.168, cos=-0.008), tot_loss_proj:3.462 [t=0.27s]
prediction: ['[CLS] incident rhythms ab balanceulsively non balanceulsively with incident rhythms [SEP]']
Attempt swap
[1900/2000] tot_loss=1.822 (perp=8.298, rec=0.171, cos=-0.008), tot_loss_proj:3.459 [t=0.27s]
prediction: ['[CLS] incident rhythms ab balanceulsively non balanceulsively with incident rhythms [SEP]']
[1950/2000] tot_loss=1.817 (perp=8.298, rec=0.165, cos=-0.008), tot_loss_proj:3.462 [t=0.25s]
prediction: ['[CLS] incident rhythms ab balanceulsively non balanceulsively with incident rhythms [SEP]']
Attempt swap
[2000/2000] tot_loss=1.825 (perp=8.298, rec=0.174, cos=-0.008), tot_loss_proj:3.463 [t=0.27s]
prediction: ['[CLS] incident rhythms ab balanceulsively non balanceulsively with incident rhythms [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS]ulsive incident rhythms ab real with balanceulsively balance rhythms. incident [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 50.000 | r: 60.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 45.455 | p: 41.667 | r: 50.000
rougeLsum  | fm: 45.455 | p: 41.667 | r: 50.000
r1fm+r2fm = 64.545

[Aggregate metrics]:
rouge1     | fm: 87.600 | p: 86.364 | r: 88.788
rouge2     | fm: 59.491 | p: 59.256 | r: 59.819
rougeL     | fm: 80.763 | p: 79.908 | r: 81.753
rougeLsum  | fm: 80.992 | p: 80.468 | r: 81.970
r1fm+r2fm = 147.091

input #10 time: 0:11:01 | total time: 1:04:39


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
*********************************
*********************************
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9119930863380432 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9002856016159058 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8241632580757141 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8143832683563232 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.8102236986160278 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.8092162609100342 for ['[CLS] inlandture drawngu platform tal familiar mevd mile [SEP]']
[Init] best perm rec loss: 0.8080193400382996 for ['[CLS] inland mevdgu mile tal drawn familiarture platform [SEP]']
[Init] best perm rec loss: 0.8064080476760864 for ['[CLS] inland me milevd platformture familiar talgu drawn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.701 (perp=11.452, rec=0.417, cos=-0.006), tot_loss_proj:3.639 [t=0.29s]
prediction: ['[CLS] missing earlier blockted pole not driven wards damage struggling [SEP]']
[ 100/2000] tot_loss=2.620 (perp=11.498, rec=0.329, cos=-0.008), tot_loss_proj:4.141 [t=0.27s]
prediction: ['[CLS] not attempted gelted horse never refused gel opinion refused [SEP]']
[ 150/2000] tot_loss=2.398 (perp=10.723, rec=0.262, cos=-0.008), tot_loss_proj:3.507 [t=0.29s]
prediction: ['[CLS] that attempted gel to gel refused refused gel stubborn refused [SEP]']
[ 200/2000] tot_loss=2.353 (perp=10.723, rec=0.217, cos=-0.009), tot_loss_proj:3.497 [t=0.28s]
prediction: ['[CLS] that attempted gel to gel refused refused gel stubborn refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.441 (perp=11.248, rec=0.199, cos=-0.008), tot_loss_proj:3.416 [t=0.29s]
prediction: ['[CLS] that attempted gel to gelusly refused stubborn refused here [SEP]']
[ 300/2000] tot_loss=2.235 (perp=10.391, rec=0.166, cos=-0.009), tot_loss_proj:3.141 [t=0.29s]
prediction: ['[CLS] that attempted gel to labelly refused stubborn refused here [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.136 (perp=10.119, rec=0.122, cos=-0.010), tot_loss_proj:3.167 [t=0.29s]
prediction: ['[CLS] was attempted gelly refused that label stubborn refused here [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.224 (perp=10.592, rec=0.115, cos=-0.010), tot_loss_proj:3.312 [t=0.28s]
prediction: ['[CLS] was attempted gelly refused that stubborn belongs refused here [SEP]']
[ 450/2000] tot_loss=2.145 (perp=10.296, rec=0.096, cos=-0.010), tot_loss_proj:3.355 [t=0.28s]
prediction: ['[CLS] was attempted gelly refused that stubborn here refused here [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.197 (perp=10.436, rec=0.119, cos=-0.009), tot_loss_proj:3.555 [t=0.30s]
prediction: ['[CLS] necessarily was attempted gelly refused that stubborn refused here [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.005 (perp=9.591, rec=0.097, cos=-0.010), tot_loss_proj:3.302 [t=0.27s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
[ 600/2000] tot_loss=2.009 (perp=9.591, rec=0.100, cos=-0.010), tot_loss_proj:3.298 [t=0.30s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.003 (perp=9.591, rec=0.095, cos=-0.010), tot_loss_proj:3.296 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.006 (perp=9.591, rec=0.097, cos=-0.010), tot_loss_proj:3.299 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
[ 750/2000] tot_loss=1.995 (perp=9.591, rec=0.086, cos=-0.010), tot_loss_proj:3.299 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.004 (perp=9.591, rec=0.095, cos=-0.010), tot_loss_proj:3.302 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.998 (perp=9.591, rec=0.090, cos=-0.010), tot_loss_proj:3.296 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
[ 900/2000] tot_loss=2.002 (perp=9.591, rec=0.093, cos=-0.010), tot_loss_proj:3.298 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.998 (perp=9.591, rec=0.090, cos=-0.010), tot_loss_proj:3.296 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[1000/2000] tot_loss=1.999 (perp=9.591, rec=0.090, cos=-0.010), tot_loss_proj:3.297 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
[1050/2000] tot_loss=2.004 (perp=9.591, rec=0.095, cos=-0.010), tot_loss_proj:3.296 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[1100/2000] tot_loss=1.997 (perp=9.591, rec=0.088, cos=-0.010), tot_loss_proj:3.297 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
Attempt swap
[1150/2000] tot_loss=1.999 (perp=9.591, rec=0.091, cos=-0.010), tot_loss_proj:3.295 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn refused here [SEP]']
[1200/2000] tot_loss=1.883 (perp=8.992, rec=0.094, cos=-0.010), tot_loss_proj:3.143 [t=0.30s]
prediction: ['[CLS] necessarily attempted was gelly refused that stubborn was here [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.858 (perp=8.900, rec=0.088, cos=-0.010), tot_loss_proj:3.025 [t=0.27s]
prediction: ['[CLS] necessarily attempted was gelly refused that was stubborn here [SEP]']
Attempt swap
[1300/2000] tot_loss=1.868 (perp=8.900, rec=0.098, cos=-0.010), tot_loss_proj:3.028 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that was stubborn here [SEP]']
[1350/2000] tot_loss=1.865 (perp=8.925, rec=0.090, cos=-0.010), tot_loss_proj:3.286 [t=0.27s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1400/2000] tot_loss=1.855 (perp=8.925, rec=0.080, cos=-0.010), tot_loss_proj:3.280 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1450/2000] tot_loss=1.859 (perp=8.925, rec=0.084, cos=-0.010), tot_loss_proj:3.285 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
[1500/2000] tot_loss=1.859 (perp=8.925, rec=0.084, cos=-0.010), tot_loss_proj:3.279 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1550/2000] tot_loss=1.860 (perp=8.925, rec=0.084, cos=-0.010), tot_loss_proj:3.283 [t=0.30s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1600/2000] tot_loss=1.866 (perp=8.925, rec=0.091, cos=-0.010), tot_loss_proj:3.279 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
[1650/2000] tot_loss=1.849 (perp=8.925, rec=0.074, cos=-0.010), tot_loss_proj:3.280 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1700/2000] tot_loss=1.860 (perp=8.925, rec=0.085, cos=-0.010), tot_loss_proj:3.283 [t=0.30s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1750/2000] tot_loss=1.851 (perp=8.925, rec=0.076, cos=-0.010), tot_loss_proj:3.282 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
[1800/2000] tot_loss=1.852 (perp=8.925, rec=0.076, cos=-0.010), tot_loss_proj:3.278 [t=0.28s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1850/2000] tot_loss=1.867 (perp=8.925, rec=0.091, cos=-0.010), tot_loss_proj:3.285 [t=0.29s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[1900/2000] tot_loss=1.859 (perp=8.925, rec=0.084, cos=-0.010), tot_loss_proj:3.277 [t=0.30s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
[1950/2000] tot_loss=1.857 (perp=8.925, rec=0.081, cos=-0.010), tot_loss_proj:3.281 [t=0.30s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Attempt swap
[2000/2000] tot_loss=1.862 (perp=8.925, rec=0.087, cos=-0.010), tot_loss_proj:3.282 [t=0.35s]
prediction: ['[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] necessarily attempted was gelly refused that being stubborn here [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 45.455 | p: 45.455 | r: 45.455
rougeLsum  | fm: 45.455 | p: 45.455 | r: 45.455
r1fm+r2fm = 72.727

[Aggregate metrics]:
rouge1     | fm: 86.232 | p: 85.145 | r: 87.325
rouge2     | fm: 54.513 | p: 54.318 | r: 54.742
rougeL     | fm: 77.820 | p: 76.961 | r: 78.562
rougeLsum  | fm: 77.820 | p: 77.052 | r: 78.589
r1fm+r2fm = 140.745

input #11 time: 0:11:38 | total time: 1:16:17


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
*********************************
*********************************
average of cosine similarity 0.9993439176315202
highest_index [0]
highest [0.9993439176315202]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.867132842540741 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.861339807510376 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799628496170044 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7725229263305664 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7675877213478088 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.743887186050415 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7403388023376465 for ['[CLS] ha guess shades margin office series bethitasyn few victor laynction translate [SEP]']
[Init] best perm rec loss: 0.7387611269950867 for ['[CLS] guess beth ha few series shadesitas translate office marginnction layyn victor [SEP]']
[Init] best perm rec loss: 0.7375137805938721 for ['[CLS]nction translate few victor beth office margin series shades haitas guessyn lay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.843 (perp=12.210, rec=0.406, cos=-0.005), tot_loss_proj:3.584 [t=0.29s]
prediction: ['[CLS] handicapaur barelymarket ago lay on internet accused avoid television freak cable cable [SEP]']
[ 100/2000] tot_loss=2.280 (perp=10.055, rec=0.276, cos=-0.008), tot_loss_proj:2.920 [t=0.28s]
prediction: ['[CLS] handicapphone barely better might lay on attack would better advantage threat advantage cable [SEP]']
[ 150/2000] tot_loss=2.402 (perp=10.873, rec=0.227, cos=0.001), tot_loss_proj:3.233 [t=0.28s]
prediction: ['[CLS] handicapphone barely better will record on attack would better better listed advantage cable [SEP]']
[ 200/2000] tot_loss=2.269 (perp=10.477, rec=0.183, cos=-0.009), tot_loss_proj:3.040 [t=0.30s]
prediction: ['[CLS] handicapination barely better will seen on illegal considering better on listed advantage cable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.163 (perp=10.030, rec=0.165, cos=-0.008), tot_loss_proj:2.939 [t=0.27s]
prediction: ['[CLS] handicapination barely better will seen to illegal considering better on cable advantage because [SEP]']
[ 300/2000] tot_loss=2.091 (perp=9.823, rec=0.136, cos=-0.010), tot_loss_proj:2.864 [t=0.29s]
prediction: ['[CLS] seenination barely better will seen to against considering better on cable advantage because [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.244 (perp=10.654, rec=0.121, cos=-0.008), tot_loss_proj:3.012 [t=0.28s]
prediction: ['[CLS] call its barely better will seen to both considering better on cable advantage mostly [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.140 (perp=10.138, rec=0.121, cos=-0.009), tot_loss_proj:2.810 [t=0.27s]
prediction: ['[CLS] its barely better will seen to reader call considering better on cable advantage mostly [SEP]']
[ 450/2000] tot_loss=1.942 (perp=9.196, rec=0.113, cos=-0.010), tot_loss_proj:2.627 [t=0.30s]
prediction: ['[CLS] its barely better will seen to reader target considering better on cable advantage because [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.970 (perp=9.338, rec=0.112, cos=-0.010), tot_loss_proj:2.697 [t=0.29s]
prediction: ['[CLS] reader barely better will seen to its target considering better on cable advantage mostly [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.886 (perp=8.944, rec=0.106, cos=-0.009), tot_loss_proj:2.883 [t=0.29s]
prediction: ['[CLS] an barely better will seen to its better considering its on cable advantage mostly [SEP]']
[ 600/2000] tot_loss=1.824 (perp=8.638, rec=0.106, cos=-0.010), tot_loss_proj:2.723 [t=0.28s]
prediction: ['[CLS] that barely better will seen to its better considering its on cable advantage especially [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.739 (perp=8.257, rec=0.098, cos=-0.010), tot_loss_proj:2.659 [t=0.29s]
prediction: ['[CLS] that barely better will seen to its better considering its advantage especially on cable [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.699 (perp=8.026, rec=0.103, cos=-0.009), tot_loss_proj:2.458 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better considering its advantage especially on cable [SEP]']
[ 750/2000] tot_loss=1.690 (perp=8.026, rec=0.094, cos=-0.010), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better considering its advantage especially on cable [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.677 (perp=7.959, rec=0.095, cos=-0.010), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better considering its advantage on cable especially [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.620 (perp=7.629, rec=0.103, cos=-0.009), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[ 900/2000] tot_loss=1.602 (perp=7.629, rec=0.086, cos=-0.010), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.598 (perp=7.629, rec=0.082, cos=-0.010), tot_loss_proj:2.392 [t=0.27s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1000/2000] tot_loss=1.598 (perp=7.629, rec=0.082, cos=-0.010), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1050/2000] tot_loss=1.606 (perp=7.629, rec=0.090, cos=-0.010), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1100/2000] tot_loss=1.597 (perp=7.629, rec=0.080, cos=-0.010), tot_loss_proj:2.386 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1150/2000] tot_loss=1.602 (perp=7.629, rec=0.086, cos=-0.010), tot_loss_proj:2.388 [t=0.27s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1200/2000] tot_loss=1.596 (perp=7.629, rec=0.080, cos=-0.010), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1250/2000] tot_loss=1.601 (perp=7.629, rec=0.085, cos=-0.010), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1300/2000] tot_loss=1.601 (perp=7.629, rec=0.085, cos=-0.010), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1350/2000] tot_loss=1.599 (perp=7.629, rec=0.083, cos=-0.010), tot_loss_proj:2.387 [t=0.27s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1400/2000] tot_loss=1.604 (perp=7.629, rec=0.088, cos=-0.010), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1450/2000] tot_loss=1.605 (perp=7.629, rec=0.089, cos=-0.010), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1500/2000] tot_loss=1.602 (perp=7.629, rec=0.086, cos=-0.010), tot_loss_proj:2.387 [t=0.27s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1550/2000] tot_loss=1.601 (perp=7.629, rec=0.085, cos=-0.010), tot_loss_proj:2.393 [t=0.27s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1600/2000] tot_loss=1.603 (perp=7.629, rec=0.087, cos=-0.010), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1650/2000] tot_loss=1.602 (perp=7.629, rec=0.086, cos=-0.010), tot_loss_proj:2.386 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.629, rec=0.080, cos=-0.010), tot_loss_proj:2.393 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1750/2000] tot_loss=1.597 (perp=7.629, rec=0.081, cos=-0.010), tot_loss_proj:2.395 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1800/2000] tot_loss=1.609 (perp=7.629, rec=0.093, cos=-0.010), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1850/2000] tot_loss=1.608 (perp=7.629, rec=0.092, cos=-0.010), tot_loss_proj:2.386 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.629, rec=0.075, cos=-0.010), tot_loss_proj:2.389 [t=0.24s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
[1950/2000] tot_loss=1.602 (perp=7.629, rec=0.086, cos=-0.010), tot_loss_proj:2.396 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Attempt swap
[2000/2000] tot_loss=1.600 (perp=7.629, rec=0.084, cos=-0.010), tot_loss_proj:2.390 [t=0.25s]
prediction: ['[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely better will that seen to its better advantage on cable especially considering its [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 48.276 | p: 46.667 | r: 50.000
rougeL     | fm: 77.419 | p: 75.000 | r: 80.000
rougeLsum  | fm: 77.419 | p: 75.000 | r: 80.000
r1fm+r2fm = 138.598

[Aggregate metrics]:
rouge1     | fm: 86.597 | p: 85.476 | r: 87.912
rouge2     | fm: 53.987 | p: 53.590 | r: 54.377
rougeL     | fm: 77.655 | p: 76.719 | r: 78.643
rougeLsum  | fm: 77.674 | p: 76.628 | r: 78.660
r1fm+r2fm = 140.584

input #12 time: 0:11:15 | total time: 1:27:33


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
*********************************
*********************************
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8887738585472107 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8844950199127197 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8545551896095276 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7818396091461182 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7813502550125122 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7700784802436829 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7579190731048584 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7517123222351074 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 0.7473309636116028 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7472784519195557 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 0.7453463077545166 for ['[CLS] cardinal arm defeat rowe permanent precisionional [SEP]']
[Init] best perm rec loss: 0.7436425089836121 for ['[CLS]ional precision arm cardinal permanent rowe defeat [SEP]']
[Init] best perm rec loss: 0.7426804900169373 for ['[CLS] rowe cardinal defeat armional permanent precision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.479 (perp=10.746, rec=0.331, cos=-0.001), tot_loss_proj:3.352 [t=0.26s]
prediction: ['[CLS] up losses ( off have flames hell [SEP]']
[ 100/2000] tot_loss=2.550 (perp=11.552, rec=0.247, cos=-0.008), tot_loss_proj:3.406 [t=0.26s]
prediction: ['[CLS] point things ( more explode flame flame [SEP]']
[ 150/2000] tot_loss=2.491 (perp=11.547, rec=0.189, cos=-0.007), tot_loss_proj:3.269 [t=0.25s]
prediction: ['[CLS] point things at more explode flame flame [SEP]']
[ 200/2000] tot_loss=2.457 (perp=11.547, rec=0.156, cos=-0.008), tot_loss_proj:3.253 [t=0.25s]
prediction: ['[CLS] point things at more explode flame flame [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.241 (perp=10.433, rec=0.162, cos=-0.007), tot_loss_proj:3.205 [t=0.26s]
prediction: ['[CLS] point things at flame explode more flame [SEP]']
[ 300/2000] tot_loss=1.970 (perp=9.235, rec=0.133, cos=-0.010), tot_loss_proj:2.836 [t=0.25s]
prediction: ['[CLS] point things at flame explode with flame [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.913 (perp=9.064, rec=0.110, cos=-0.009), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] point at things into explode with flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.901 (perp=9.064, rec=0.098, cos=-0.009), tot_loss_proj:2.461 [t=0.26s]
prediction: ['[CLS] point at things into explode with flame [SEP]']
[ 450/2000] tot_loss=1.972 (perp=9.417, rec=0.098, cos=-0.009), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] point at things into explode that flame [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.735 (perp=8.254, rec=0.094, cos=-0.009), tot_loss_proj:2.003 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.719 (perp=8.254, rec=0.078, cos=-0.010), tot_loss_proj:1.996 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 600/2000] tot_loss=1.721 (perp=8.254, rec=0.080, cos=-0.010), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.722 (perp=8.254, rec=0.081, cos=-0.010), tot_loss_proj:1.990 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.732 (perp=8.254, rec=0.091, cos=-0.010), tot_loss_proj:1.995 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 750/2000] tot_loss=1.732 (perp=8.254, rec=0.091, cos=-0.010), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.709 (perp=8.254, rec=0.068, cos=-0.010), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.720 (perp=8.254, rec=0.079, cos=-0.010), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 900/2000] tot_loss=1.727 (perp=8.254, rec=0.086, cos=-0.010), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.728 (perp=8.254, rec=0.087, cos=-0.010), tot_loss_proj:1.988 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.728 (perp=8.254, rec=0.087, cos=-0.010), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1050/2000] tot_loss=1.716 (perp=8.254, rec=0.075, cos=-0.010), tot_loss_proj:1.996 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.719 (perp=8.254, rec=0.078, cos=-0.010), tot_loss_proj:1.992 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.725 (perp=8.254, rec=0.084, cos=-0.010), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1200/2000] tot_loss=1.718 (perp=8.254, rec=0.077, cos=-0.010), tot_loss_proj:1.982 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.720 (perp=8.254, rec=0.079, cos=-0.010), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.725 (perp=8.254, rec=0.084, cos=-0.010), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1350/2000] tot_loss=1.722 (perp=8.254, rec=0.081, cos=-0.010), tot_loss_proj:1.987 [t=0.28s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=8.254, rec=0.073, cos=-0.010), tot_loss_proj:1.996 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.733 (perp=8.254, rec=0.092, cos=-0.010), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1500/2000] tot_loss=1.728 (perp=8.254, rec=0.087, cos=-0.010), tot_loss_proj:1.989 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.714 (perp=8.254, rec=0.073, cos=-0.010), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.719 (perp=8.254, rec=0.078, cos=-0.010), tot_loss_proj:1.987 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.254, rec=0.082, cos=-0.010), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.717 (perp=8.254, rec=0.076, cos=-0.010), tot_loss_proj:1.993 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.723 (perp=8.254, rec=0.082, cos=-0.010), tot_loss_proj:1.992 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.254, rec=0.072, cos=-0.010), tot_loss_proj:1.989 [t=0.25s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.717 (perp=8.254, rec=0.076, cos=-0.010), tot_loss_proj:1.984 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.726 (perp=8.254, rec=0.085, cos=-0.010), tot_loss_proj:1.986 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1950/2000] tot_loss=1.715 (perp=8.254, rec=0.074, cos=-0.010), tot_loss_proj:1.991 [t=0.27s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.726 (perp=8.254, rec=0.085, cos=-0.010), tot_loss_proj:1.994 [t=0.26s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point at things that explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.617 | p: 86.607 | r: 88.847
rouge2     | fm: 56.977 | p: 56.623 | r: 57.279
rougeL     | fm: 79.306 | p: 78.390 | r: 80.160
rougeLsum  | fm: 79.474 | p: 78.661 | r: 80.398
r1fm+r2fm = 144.593

input #13 time: 0:10:59 | total time: 1:38:33


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
*********************************
*********************************
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9556125998497009 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9368494749069214 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9233089089393616 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9153460264205933 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9128281474113464 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8928517699241638 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8734212517738342 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720963597297668 for ['[CLS] myers sprayed harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720387816429138 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8698037266731262 for ['[CLS] tom [MASK] harold myers sprayed [SEP]']
[Init] best perm rec loss: 0.8688009977340698 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.180 (perp=9.643, rec=0.257, cos=-0.006), tot_loss_proj:2.300 [t=0.25s]
prediction: ['[CLS] intriguing intriguing film deeply moving [SEP]']
[ 100/2000] tot_loss=2.386 (perp=11.102, rec=0.174, cos=-0.008), tot_loss_proj:2.636 [t=0.26s]
prediction: ['[CLS] intriguing intriguing filmbly intriguing [SEP]']
[ 150/2000] tot_loss=2.294 (perp=10.861, rec=0.131, cos=-0.008), tot_loss_proj:2.574 [t=0.27s]
prediction: ['[CLS]bly intriguing filmbly intriguing [SEP]']
[ 200/2000] tot_loss=2.568 (perp=12.243, rec=0.128, cos=-0.009), tot_loss_proj:2.941 [t=0.25s]
prediction: ['[CLS]enia intriguing filmbly intriguing [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.958 (perp=9.271, rec=0.112, cos=-0.009), tot_loss_proj:2.124 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
[ 300/2000] tot_loss=1.955 (perp=9.271, rec=0.110, cos=-0.009), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.680 (perp=7.971, rec=0.094, cos=-0.009), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=7.971, rec=0.096, cos=-0.009), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.678 (perp=7.971, rec=0.093, cos=-0.009), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=7.971, rec=0.093, cos=-0.009), tot_loss_proj:1.898 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.677 (perp=7.971, rec=0.091, cos=-0.009), tot_loss_proj:1.905 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.674 (perp=7.971, rec=0.089, cos=-0.009), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.662 (perp=7.971, rec=0.077, cos=-0.009), tot_loss_proj:1.906 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.666 (perp=7.971, rec=0.081, cos=-0.009), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.669 (perp=7.971, rec=0.083, cos=-0.009), tot_loss_proj:1.891 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.666 (perp=7.971, rec=0.080, cos=-0.009), tot_loss_proj:1.894 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.677 (perp=7.971, rec=0.092, cos=-0.009), tot_loss_proj:1.888 [t=0.26s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.669 (perp=7.971, rec=0.084, cos=-0.009), tot_loss_proj:1.899 [t=0.27s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.669 (perp=7.971, rec=0.083, cos=-0.009), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.089 (perp=10.059, rec=0.086, cos=-0.009), tot_loss_proj:3.666 [t=0.25s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
[1050/2000] tot_loss=2.084 (perp=10.059, rec=0.082, cos=-0.009), tot_loss_proj:3.659 [t=0.25s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.417 (perp=6.728, rec=0.080, cos=-0.009), tot_loss_proj:1.401 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=6.728, rec=0.075, cos=-0.009), tot_loss_proj:1.407 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.407 (perp=6.728, rec=0.070, cos=-0.009), tot_loss_proj:1.402 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.405 (perp=6.728, rec=0.068, cos=-0.009), tot_loss_proj:1.406 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.404 (perp=6.728, rec=0.067, cos=-0.009), tot_loss_proj:1.397 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.728, rec=0.056, cos=-0.009), tot_loss_proj:1.401 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.398 (perp=6.728, rec=0.061, cos=-0.009), tot_loss_proj:1.409 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.406 (perp=6.728, rec=0.069, cos=-0.009), tot_loss_proj:1.411 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.403 (perp=6.728, rec=0.066, cos=-0.009), tot_loss_proj:1.389 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.398 (perp=6.728, rec=0.061, cos=-0.009), tot_loss_proj:1.392 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.393 (perp=6.728, rec=0.057, cos=-0.009), tot_loss_proj:1.399 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.402 (perp=6.728, rec=0.065, cos=-0.009), tot_loss_proj:1.390 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.408 (perp=6.728, rec=0.072, cos=-0.009), tot_loss_proj:1.397 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.399 (perp=6.728, rec=0.062, cos=-0.009), tot_loss_proj:1.407 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.405 (perp=6.728, rec=0.068, cos=-0.009), tot_loss_proj:1.399 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.391 (perp=6.728, rec=0.055, cos=-0.009), tot_loss_proj:1.399 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.399 (perp=6.728, rec=0.063, cos=-0.009), tot_loss_proj:1.407 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.397 (perp=6.728, rec=0.060, cos=-0.009), tot_loss_proj:1.394 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.400 (perp=6.728, rec=0.064, cos=-0.009), tot_loss_proj:1.394 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.445 | p: 87.521 | r: 89.519
rouge2     | fm: 59.813 | p: 59.535 | r: 60.111
rougeL     | fm: 80.777 | p: 79.914 | r: 81.713
rougeLsum  | fm: 80.603 | p: 79.818 | r: 81.388
r1fm+r2fm = 148.258

input #14 time: 0:10:55 | total time: 1:49:28


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
*********************************
*********************************
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9709395170211792 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9276955127716064 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9179652333259583 for ['[CLS] clubs peaceerated enclosed davis äº‹ timestle [SEP]']
[Init] best rec loss: 0.9067785143852234 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9063056707382202 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8998844623565674 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8911759257316589 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8846814036369324 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8817172050476074 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8800804018974304 for ['[CLS] easily first olivia metaphor fetch 0 humanities sweden [SEP]']
[Init] best perm rec loss: 0.879218578338623 for ['[CLS] easily sweden humanities first olivia 0 fetch metaphor [SEP]']
[Init] best perm rec loss: 0.879126250743866 for ['[CLS] easily sweden humanities 0 olivia first fetch metaphor [SEP]']
[Init] best perm rec loss: 0.8768956065177917 for ['[CLS] fetch humanities first 0 sweden olivia easily metaphor [SEP]']
[Init] best perm rec loss: 0.8764843344688416 for ['[CLS] 0 first humanities sweden olivia metaphor easily fetch [SEP]']
[Init] best perm rec loss: 0.8753165006637573 for ['[CLS] 0 sweden fetch metaphor humanities olivia first easily [SEP]']
[Init] best perm rec loss: 0.8751561641693115 for ['[CLS] metaphor 0 first humanities sweden olivia easily fetch [SEP]']
[Init] best perm rec loss: 0.8732092976570129 for ['[CLS] metaphor first sweden fetch 0 easily olivia humanities [SEP]']
[Init] best perm rec loss: 0.8722246885299683 for ['[CLS] first easily 0 sweden metaphor olivia humanities fetch [SEP]']
[Init] best perm rec loss: 0.8716493844985962 for ['[CLS] metaphor humanities first sweden olivia fetch easily 0 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.747 (perp=12.349, rec=0.284, cos=-0.007), tot_loss_proj:3.604 [t=0.28s]
prediction: ['[CLS] efficient managedably hipably waitress so âˆž [SEP]']
[ 100/2000] tot_loss=2.850 (perp=13.261, rec=0.207, cos=-0.008), tot_loss_proj:3.912 [t=0.26s]
prediction: ['[CLS] efficient managedably suit efficient chill so chill [SEP]']
[ 150/2000] tot_loss=2.470 (perp=11.569, rec=0.164, cos=-0.008), tot_loss_proj:2.823 [t=0.27s]
prediction: ['[CLS] efficient namedably suitably chill ; suit [SEP]']
[ 200/2000] tot_loss=2.400 (perp=11.409, rec=0.126, cos=-0.008), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] efficient namedably suitably chill ;er [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.047 (perp=9.674, rec=0.121, cos=-0.009), tot_loss_proj:2.442 [t=0.25s]
prediction: ['[CLS] efficient anonymousably suitably chiller ; [SEP]']
[ 300/2000] tot_loss=1.920 (perp=9.083, rec=0.111, cos=-0.008), tot_loss_proj:2.262 [t=0.25s]
prediction: ['[CLS] efficient anonymousably suitably chiller. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.583 (perp=7.428, rec=0.106, cos=-0.009), tot_loss_proj:1.723 [t=0.27s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.566 (perp=7.428, rec=0.089, cos=-0.009), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
[ 450/2000] tot_loss=1.566 (perp=7.428, rec=0.089, cos=-0.009), tot_loss_proj:1.728 [t=0.27s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.559 (perp=7.428, rec=0.083, cos=-0.009), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.552 (perp=7.403, rec=0.081, cos=-0.009), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] suitably, efficient anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.550 (perp=7.403, rec=0.079, cos=-0.009), tot_loss_proj:1.698 [t=0.25s]
prediction: ['[CLS] suitably, efficient anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.418 (perp=6.697, rec=0.088, cos=-0.009), tot_loss_proj:1.510 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.409 (perp=6.697, rec=0.079, cos=-0.009), tot_loss_proj:1.510 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.414 (perp=6.697, rec=0.084, cos=-0.009), tot_loss_proj:1.502 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.409 (perp=6.697, rec=0.079, cos=-0.009), tot_loss_proj:1.504 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.412 (perp=6.697, rec=0.081, cos=-0.009), tot_loss_proj:1.508 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.405 (perp=6.697, rec=0.075, cos=-0.009), tot_loss_proj:1.506 [t=0.29s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.413 (perp=6.697, rec=0.082, cos=-0.009), tot_loss_proj:1.494 [t=0.28s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.398 (perp=6.697, rec=0.068, cos=-0.009), tot_loss_proj:1.497 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.406 (perp=6.697, rec=0.076, cos=-0.009), tot_loss_proj:1.501 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.391 (perp=6.697, rec=0.061, cos=-0.009), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.395 (perp=6.697, rec=0.065, cos=-0.009), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.398 (perp=6.697, rec=0.068, cos=-0.009), tot_loss_proj:1.503 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.405 (perp=6.697, rec=0.075, cos=-0.009), tot_loss_proj:1.497 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.399 (perp=6.697, rec=0.069, cos=-0.009), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.396 (perp=6.697, rec=0.066, cos=-0.009), tot_loss_proj:1.495 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.400 (perp=6.697, rec=0.070, cos=-0.009), tot_loss_proj:1.499 [t=0.30s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.384 (perp=6.697, rec=0.054, cos=-0.009), tot_loss_proj:1.493 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.395 (perp=6.697, rec=0.065, cos=-0.009), tot_loss_proj:1.496 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.392 (perp=6.697, rec=0.062, cos=-0.009), tot_loss_proj:1.497 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.389 (perp=6.697, rec=0.059, cos=-0.009), tot_loss_proj:1.490 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.398 (perp=6.697, rec=0.068, cos=-0.009), tot_loss_proj:1.501 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.394 (perp=6.697, rec=0.064, cos=-0.009), tot_loss_proj:1.497 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.399 (perp=6.697, rec=0.069, cos=-0.009), tot_loss_proj:1.498 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.400 (perp=6.697, rec=0.070, cos=-0.009), tot_loss_proj:1.499 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.389 (perp=6.697, rec=0.059, cos=-0.009), tot_loss_proj:1.503 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.394 (perp=6.697, rec=0.064, cos=-0.009), tot_loss_proj:1.497 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.393 (perp=6.697, rec=0.063, cos=-0.009), tot_loss_proj:1.496 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.392 (perp=6.697, rec=0.062, cos=-0.009), tot_loss_proj:1.498 [t=0.27s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 89.355 | p: 88.487 | r: 90.327
rouge2     | fm: 58.810 | p: 58.636 | r: 59.147
rougeL     | fm: 80.919 | p: 80.297 | r: 81.709
rougeLsum  | fm: 81.039 | p: 80.269 | r: 81.718
r1fm+r2fm = 148.166

input #15 time: 0:11:11 | total time: 2:00:40


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
*********************************
*********************************
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.018147349357605 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9020346403121948 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7366529107093811 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7362502217292786 for ['[CLS]athi alta lord film slowly various [SEP]']
[Init] best perm rec loss: 0.7362011075019836 for ['[CLS] lord slowly film variousathi alta [SEP]']
[Init] best perm rec loss: 0.7361390590667725 for ['[CLS] various slowly film lordathi alta [SEP]']
[Init] best perm rec loss: 0.7351789474487305 for ['[CLS]athi alta lord slowly various film [SEP]']
[Init] best perm rec loss: 0.7351776957511902 for ['[CLS] various film lord slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7336527705192566 for ['[CLS] various film lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.793 (perp=11.033, rec=0.587, cos=0.000), tot_loss_proj:4.021 [t=0.26s]
prediction: ['[CLS] some as sloane on therapy cotton [SEP]']
[ 100/2000] tot_loss=2.443 (perp=10.194, rec=0.410, cos=-0.006), tot_loss_proj:3.566 [t=0.27s]
prediction: ['[CLS] that from gogh on already ship [SEP]']
[ 150/2000] tot_loss=1.813 (perp=7.387, rec=0.343, cos=-0.008), tot_loss_proj:2.887 [t=0.27s]
prediction: ['[CLS] that from this that all and [SEP]']
[ 200/2000] tot_loss=2.070 (perp=8.488, rec=0.376, cos=-0.003), tot_loss_proj:3.031 [t=0.27s]
prediction: ['[CLS] that up extra that all, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.813 (perp=7.337, rec=0.349, cos=-0.003), tot_loss_proj:2.757 [t=0.27s]
prediction: ['[CLS] that from, that all all [SEP]']
[ 300/2000] tot_loss=1.557 (perp=6.408, rec=0.284, cos=-0.009), tot_loss_proj:2.481 [t=0.26s]
prediction: ['[CLS] that more, that all this [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.530 (perp=6.408, rec=0.256, cos=-0.008), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] that more, that all this [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.511 (perp=6.408, rec=0.238, cos=-0.009), tot_loss_proj:2.479 [t=0.28s]
prediction: ['[CLS] that more, that all this [SEP]']
[ 450/2000] tot_loss=1.497 (perp=6.408, rec=0.224, cos=-0.008), tot_loss_proj:2.476 [t=0.27s]
prediction: ['[CLS] that more, that all this [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.483 (perp=6.458, rec=0.200, cos=-0.008), tot_loss_proj:2.207 [t=0.25s]
prediction: ['[CLS] that more, of all this [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.407 (perp=6.127, rec=0.188, cos=-0.007), tot_loss_proj:2.479 [t=0.26s]
prediction: ['[CLS] that more, all of this [SEP]']
[ 600/2000] tot_loss=1.365 (perp=6.127, rec=0.148, cos=-0.009), tot_loss_proj:2.472 [t=0.25s]
prediction: ['[CLS] that more, all of this [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.347 (perp=6.127, rec=0.130, cos=-0.009), tot_loss_proj:2.468 [t=0.26s]
prediction: ['[CLS] that more, all of this [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.339 (perp=6.127, rec=0.122, cos=-0.009), tot_loss_proj:2.470 [t=0.25s]
prediction: ['[CLS] that more, all of this [SEP]']
[ 750/2000] tot_loss=1.333 (perp=6.127, rec=0.117, cos=-0.009), tot_loss_proj:2.461 [t=0.26s]
prediction: ['[CLS] that more, all of this [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.390 (perp=6.431, rec=0.113, cos=-0.009), tot_loss_proj:2.328 [t=0.27s]
prediction: ['[CLS] that more all of this and [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=1.243 (perp=5.598, rec=0.129, cos=-0.005), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] all of this, that more [SEP]']
[ 900/2000] tot_loss=1.205 (perp=5.545, rec=0.105, cos=-0.009), tot_loss_proj:1.587 [t=0.28s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.204 (perp=5.545, rec=0.103, cos=-0.009), tot_loss_proj:1.577 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.194 (perp=5.545, rec=0.094, cos=-0.009), tot_loss_proj:1.581 [t=0.28s]
prediction: ['[CLS] all of this and that more [SEP]']
[1050/2000] tot_loss=1.194 (perp=5.545, rec=0.093, cos=-0.009), tot_loss_proj:1.580 [t=0.25s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.192 (perp=5.545, rec=0.092, cos=-0.009), tot_loss_proj:1.576 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.199 (perp=5.545, rec=0.099, cos=-0.009), tot_loss_proj:1.580 [t=0.25s]
prediction: ['[CLS] all of this and that more [SEP]']
[1200/2000] tot_loss=1.195 (perp=5.545, rec=0.095, cos=-0.009), tot_loss_proj:1.579 [t=0.25s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.198 (perp=5.545, rec=0.098, cos=-0.009), tot_loss_proj:1.579 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.201 (perp=5.545, rec=0.101, cos=-0.009), tot_loss_proj:1.584 [t=0.25s]
prediction: ['[CLS] all of this and that more [SEP]']
[1350/2000] tot_loss=1.192 (perp=5.545, rec=0.092, cos=-0.009), tot_loss_proj:1.576 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.190 (perp=5.545, rec=0.091, cos=-0.009), tot_loss_proj:1.579 [t=0.28s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.192 (perp=5.545, rec=0.092, cos=-0.009), tot_loss_proj:1.580 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
[1500/2000] tot_loss=1.193 (perp=5.545, rec=0.093, cos=-0.009), tot_loss_proj:1.579 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.189 (perp=5.545, rec=0.089, cos=-0.009), tot_loss_proj:1.576 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.186 (perp=5.545, rec=0.086, cos=-0.009), tot_loss_proj:1.577 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
[1650/2000] tot_loss=1.193 (perp=5.545, rec=0.093, cos=-0.009), tot_loss_proj:1.576 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.192 (perp=5.545, rec=0.093, cos=-0.009), tot_loss_proj:1.581 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.190 (perp=5.545, rec=0.090, cos=-0.009), tot_loss_proj:1.577 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
[1800/2000] tot_loss=1.190 (perp=5.545, rec=0.090, cos=-0.009), tot_loss_proj:1.585 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.190 (perp=5.545, rec=0.091, cos=-0.009), tot_loss_proj:1.580 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.191 (perp=5.545, rec=0.091, cos=-0.009), tot_loss_proj:1.576 [t=0.25s]
prediction: ['[CLS] all of this and that more [SEP]']
[1950/2000] tot_loss=1.185 (perp=5.545, rec=0.086, cos=-0.009), tot_loss_proj:1.582 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.191 (perp=5.545, rec=0.091, cos=-0.009), tot_loss_proj:1.582 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this and that more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 89.474 | p: 88.333 | r: 90.909
rouge2     | fm: 60.401 | p: 59.986 | r: 61.027
rougeL     | fm: 82.066 | p: 81.042 | r: 83.220
rougeLsum  | fm: 81.628 | p: 80.611 | r: 82.871
r1fm+r2fm = 149.875

input #16 time: 0:11:05 | total time: 2:11:46


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
*********************************
*********************************
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8486641645431519 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8205068111419678 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8189647197723389 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8072818517684937 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7922393679618835 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7693865895271301 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7615459561347961 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7598406076431274 for ['[CLS] meeting marius miss pressure greyuin i magazine saved lieutenant honestly [SEP]']
[Init] best perm rec loss: 0.7584831714630127 for ['[CLS] marius missuin lieutenant grey magazine honestly i saved meeting pressure [SEP]']
[Init] best perm rec loss: 0.7562015652656555 for ['[CLS] pressure marius honestly magazine saved meeting grey lieutenant iuin miss [SEP]']
[Init] best perm rec loss: 0.7561701536178589 for ['[CLS] i pressure marius lieutenant magazine miss greyuin meeting saved honestly [SEP]']
[Init] best perm rec loss: 0.7556576132774353 for ['[CLS]uin lieutenant honestly i pressure marius miss meeting grey saved magazine [SEP]']
[Init] best perm rec loss: 0.7535409927368164 for ['[CLS] i meetinguin pressure honestly magazine grey lieutenant marius saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.943 (perp=12.208, rec=0.507, cos=-0.006), tot_loss_proj:3.971 [t=0.27s]
prediction: ['[CLS] the franticactic bullshit alleged dispersal feed area about tax mum [SEP]']
[ 100/2000] tot_loss=2.562 (perp=10.708, rec=0.427, cos=-0.007), tot_loss_proj:3.445 [t=0.28s]
prediction: ['[CLS] too rushed bacterial study supposed who fed about about bound taboo [SEP]']
[ 150/2000] tot_loss=2.672 (perp=12.022, rec=0.274, cos=-0.007), tot_loss_proj:3.600 [t=0.28s]
prediction: ['[CLS] too much bacterial suck want what what about about hospital asked [SEP]']
[ 200/2000] tot_loss=2.598 (perp=12.044, rec=0.189, cos=0.000), tot_loss_proj:3.494 [t=0.28s]
prediction: ['[CLS] too much bacterial aren want much much about about hospital want [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.204 (perp=10.273, rec=0.156, cos=-0.007), tot_loss_proj:3.118 [t=0.28s]
prediction: ['[CLS] too much hospitalsett want much think about about symptoms think [SEP]']
[ 300/2000] tot_loss=2.172 (perp=10.273, rec=0.127, cos=-0.009), tot_loss_proj:3.119 [t=0.29s]
prediction: ['[CLS] too much hospitalsett want much think about about symptoms think [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.171 (perp=10.295, rec=0.121, cos=-0.009), tot_loss_proj:3.192 [t=0.28s]
prediction: ['[CLS] too much hospitalausen want much think about think s symptoms [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.081 (perp=9.910, rec=0.108, cos=-0.009), tot_loss_proj:2.964 [t=0.25s]
prediction: ['[CLS] too much hospital huh want much think about think because s [SEP]']
[ 450/2000] tot_loss=1.867 (perp=8.875, rec=0.102, cos=-0.009), tot_loss_proj:2.770 [t=0.25s]
prediction: ['[CLS] too much hospital going want much think about to because s [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.602 (perp=7.561, rec=0.099, cos=-0.009), tot_loss_proj:2.472 [t=0.26s]
prediction: ['[CLS] too much hospital going want much to think about because s [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.547 (perp=7.321, rec=0.091, cos=-0.009), tot_loss_proj:2.397 [t=0.26s]
prediction: ['[CLS] too much hospital going much want to think about because s [SEP]']
[ 600/2000] tot_loss=1.538 (perp=7.321, rec=0.083, cos=-0.009), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] too much hospital going much want to think about because s [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.542 (perp=7.321, rec=0.088, cos=-0.010), tot_loss_proj:2.397 [t=0.26s]
prediction: ['[CLS] too much hospital going much want to think about because s [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.541 (perp=7.321, rec=0.086, cos=-0.010), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] too much hospital going much want to think about because s [SEP]']
[ 750/2000] tot_loss=1.540 (perp=7.321, rec=0.086, cos=-0.010), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] too much hospital going much want to think about because s [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.538 (perp=7.308, rec=0.086, cos=-0.010), tot_loss_proj:2.445 [t=0.34s]
prediction: ['[CLS] too much hospital going much want to think about season s [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.560 (perp=7.429, rec=0.083, cos=-0.010), tot_loss_proj:2.417 [t=0.25s]
prediction: ['[CLS] too much hospital going much want to think about on s [SEP]']
[ 900/2000] tot_loss=1.558 (perp=7.429, rec=0.081, cos=-0.010), tot_loss_proj:2.411 [t=0.25s]
prediction: ['[CLS] too much hospital going much want to think about on s [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.502 (perp=7.148, rec=0.082, cos=-0.010), tot_loss_proj:2.311 [t=0.27s]
prediction: ['[CLS] too much hospital going on much want to think about s [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.427 (perp=6.768, rec=0.082, cos=-0.009), tot_loss_proj:2.288 [t=0.27s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1050/2000] tot_loss=1.426 (perp=6.768, rec=0.082, cos=-0.010), tot_loss_proj:2.289 [t=0.27s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1100/2000] tot_loss=1.432 (perp=6.768, rec=0.088, cos=-0.010), tot_loss_proj:2.294 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.419 (perp=6.768, rec=0.075, cos=-0.010), tot_loss_proj:2.290 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1200/2000] tot_loss=1.421 (perp=6.768, rec=0.077, cos=-0.010), tot_loss_proj:2.296 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.422 (perp=6.768, rec=0.078, cos=-0.010), tot_loss_proj:2.300 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1300/2000] tot_loss=1.421 (perp=6.768, rec=0.077, cos=-0.010), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1350/2000] tot_loss=1.413 (perp=6.768, rec=0.069, cos=-0.010), tot_loss_proj:2.289 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1400/2000] tot_loss=1.424 (perp=6.768, rec=0.080, cos=-0.010), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1450/2000] tot_loss=1.413 (perp=6.768, rec=0.069, cos=-0.010), tot_loss_proj:2.289 [t=0.28s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1500/2000] tot_loss=1.419 (perp=6.768, rec=0.075, cos=-0.010), tot_loss_proj:2.285 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1550/2000] tot_loss=1.417 (perp=6.768, rec=0.073, cos=-0.010), tot_loss_proj:2.292 [t=0.27s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1600/2000] tot_loss=1.416 (perp=6.768, rec=0.072, cos=-0.010), tot_loss_proj:2.291 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1650/2000] tot_loss=1.420 (perp=6.768, rec=0.077, cos=-0.010), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1700/2000] tot_loss=1.430 (perp=6.768, rec=0.086, cos=-0.010), tot_loss_proj:2.296 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1750/2000] tot_loss=1.426 (perp=6.768, rec=0.082, cos=-0.010), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1800/2000] tot_loss=1.418 (perp=6.768, rec=0.074, cos=-0.010), tot_loss_proj:2.285 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1850/2000] tot_loss=1.417 (perp=6.768, rec=0.073, cos=-0.010), tot_loss_proj:2.287 [t=0.25s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[1900/2000] tot_loss=1.417 (perp=6.768, rec=0.073, cos=-0.010), tot_loss_proj:2.290 [t=0.27s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
[1950/2000] tot_loss=1.417 (perp=6.768, rec=0.073, cos=-0.010), tot_loss_proj:2.287 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Attempt swap
[2000/2000] tot_loss=1.422 (perp=6.768, rec=0.078, cos=-0.010), tot_loss_proj:2.288 [t=0.26s]
prediction: ['[CLS] too much hospital going on want to think much about s [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] too much hospital going much want to think about on s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 26.087 | p: 25.000 | r: 27.273
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 114.087

[Aggregate metrics]:
rouge1     | fm: 89.405 | p: 88.076 | r: 90.889
rouge2     | fm: 58.466 | p: 57.859 | r: 59.074
rougeL     | fm: 80.581 | p: 79.465 | r: 81.811
rougeLsum  | fm: 80.370 | p: 79.215 | r: 81.581
r1fm+r2fm = 147.871

input #17 time: 0:11:07 | total time: 2:22:53


Running input #18 of 100.
reference: 
========================
invigorating 
========================
*********************************
*********************************
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9796279072761536 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9423751831054688 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9344695806503296 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9258310198783875 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8895648717880249 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8812242150306702 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.869970977306366 for ['[CLS] oniest Î± department [SEP]']
[Init] best rec loss: 0.8667334318161011 for ['[CLS] middle away mc reserves [SEP]']
[Init] best rec loss: 0.8235080242156982 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8209102153778076 for ['[CLS]odle circle du dual [SEP]']
[Init] best perm rec loss: 0.8185354471206665 for ['[CLS] dual duodle circle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.736 (perp=11.985, rec=0.344, cos=-0.005), tot_loss_proj:3.524 [t=0.25s]
prediction: ['[CLS] human special received horsemen [SEP]']
[ 100/2000] tot_loss=3.102 (perp=14.328, rec=0.245, cos=-0.008), tot_loss_proj:4.338 [t=0.26s]
prediction: ['[CLS]vi welcomealgor [SEP]']
[ 150/2000] tot_loss=3.187 (perp=15.031, rec=0.189, cos=-0.008), tot_loss_proj:4.540 [t=0.26s]
prediction: ['[CLS]vi extendingatinggor [SEP]']
[ 200/2000] tot_loss=2.584 (perp=12.222, rec=0.148, cos=-0.008), tot_loss_proj:4.165 [t=0.26s]
prediction: ['[CLS]vi inatinggor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.553 (perp=7.299, rec=0.102, cos=-0.009), tot_loss_proj:1.812 [t=0.25s]
prediction: ['[CLS]vigorating in [SEP]']
[ 300/2000] tot_loss=1.521 (perp=7.299, rec=0.070, cos=-0.009), tot_loss_proj:1.818 [t=0.26s]
prediction: ['[CLS]vigorating in [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.173 (perp=5.588, rec=0.065, cos=-0.009), tot_loss_proj:1.174 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.168 (perp=5.588, rec=0.059, cos=-0.009), tot_loss_proj:1.184 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.175 (perp=5.588, rec=0.067, cos=-0.009), tot_loss_proj:1.165 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.173 (perp=5.588, rec=0.064, cos=-0.009), tot_loss_proj:1.171 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.181 (perp=5.588, rec=0.072, cos=-0.009), tot_loss_proj:1.178 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.171 (perp=5.588, rec=0.062, cos=-0.009), tot_loss_proj:1.168 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.178 (perp=5.588, rec=0.069, cos=-0.009), tot_loss_proj:1.173 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.176 (perp=5.588, rec=0.067, cos=-0.009), tot_loss_proj:1.171 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.168 (perp=5.588, rec=0.059, cos=-0.009), tot_loss_proj:1.174 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.165 (perp=5.588, rec=0.056, cos=-0.009), tot_loss_proj:1.182 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.175 (perp=5.588, rec=0.067, cos=-0.009), tot_loss_proj:1.173 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.169 (perp=5.588, rec=0.060, cos=-0.009), tot_loss_proj:1.171 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.165 (perp=5.588, rec=0.056, cos=-0.009), tot_loss_proj:1.180 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.165 (perp=5.588, rec=0.056, cos=-0.009), tot_loss_proj:1.179 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.179 (perp=5.588, rec=0.070, cos=-0.009), tot_loss_proj:1.177 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.167 (perp=5.588, rec=0.058, cos=-0.009), tot_loss_proj:1.175 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.172 (perp=5.588, rec=0.063, cos=-0.009), tot_loss_proj:1.173 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.164 (perp=5.588, rec=0.055, cos=-0.009), tot_loss_proj:1.175 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.176 (perp=5.588, rec=0.067, cos=-0.009), tot_loss_proj:1.179 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.174 (perp=5.588, rec=0.065, cos=-0.009), tot_loss_proj:1.176 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.172 (perp=5.588, rec=0.063, cos=-0.009), tot_loss_proj:1.174 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.154 (perp=5.588, rec=0.045, cos=-0.009), tot_loss_proj:1.165 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.164 (perp=5.588, rec=0.055, cos=-0.009), tot_loss_proj:1.178 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.166 (perp=5.588, rec=0.058, cos=-0.009), tot_loss_proj:1.181 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.173 (perp=5.588, rec=0.065, cos=-0.009), tot_loss_proj:1.179 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.169 (perp=5.588, rec=0.060, cos=-0.009), tot_loss_proj:1.172 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.167 (perp=5.588, rec=0.058, cos=-0.009), tot_loss_proj:1.186 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.169 (perp=5.588, rec=0.061, cos=-0.009), tot_loss_proj:1.169 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.162 (perp=5.588, rec=0.053, cos=-0.009), tot_loss_proj:1.188 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.176 (perp=5.588, rec=0.067, cos=-0.009), tot_loss_proj:1.161 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.176 (perp=5.588, rec=0.067, cos=-0.009), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.166 (perp=5.588, rec=0.057, cos=-0.009), tot_loss_proj:1.173 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.164 (perp=5.588, rec=0.055, cos=-0.009), tot_loss_proj:1.161 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.161 (perp=5.588, rec=0.052, cos=-0.009), tot_loss_proj:1.181 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.016 | p: 88.740 | r: 91.391
rouge2     | fm: 60.750 | p: 60.114 | r: 61.442
rougeL     | fm: 81.685 | p: 80.748 | r: 82.881
rougeLsum  | fm: 81.223 | p: 80.117 | r: 82.449
r1fm+r2fm = 150.766

input #18 time: 0:10:53 | total time: 2:33:46


Running input #19 of 100.
reference: 
========================
to infamy 
========================
*********************************
*********************************
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7703872323036194 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7632964253425598 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7431591749191284 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7254143357276917 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7071809768676758 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7017049789428711 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.688244640827179 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.680355966091156 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6743445992469788 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6420117020606995 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6395600438117981 for ['[CLS] reaching pin orderyna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.869 (perp=12.214, rec=0.430, cos=-0.004), tot_loss_proj:3.814 [t=0.28s]
prediction: ['[CLS] pope lanes violent came [SEP]']
[ 100/2000] tot_loss=2.821 (perp=12.392, rec=0.342, cos=0.000), tot_loss_proj:3.692 [t=0.26s]
prediction: ['[CLS] duringda violentfa [SEP]']
[ 150/2000] tot_loss=3.045 (perp=14.052, rec=0.242, cos=-0.007), tot_loss_proj:4.223 [t=0.26s]
prediction: ['[CLS] tomyfafa [SEP]']
[ 200/2000] tot_loss=2.486 (perp=11.655, rec=0.163, cos=-0.008), tot_loss_proj:3.688 [t=0.25s]
prediction: ['[CLS] tomymyfa [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.418 (perp=11.137, rec=0.194, cos=-0.003), tot_loss_proj:3.770 [t=0.26s]
prediction: ['[CLS] tofa inmy [SEP]']
[ 300/2000] tot_loss=2.329 (perp=11.137, rec=0.110, cos=-0.009), tot_loss_proj:3.856 [t=0.26s]
prediction: ['[CLS] tofa inmy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.299 (perp=6.110, rec=0.086, cos=-0.009), tot_loss_proj:1.308 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.295 (perp=6.110, rec=0.082, cos=-0.010), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.287 (perp=6.110, rec=0.075, cos=-0.010), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.283 (perp=6.110, rec=0.070, cos=-0.010), tot_loss_proj:1.313 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.273 (perp=6.110, rec=0.060, cos=-0.010), tot_loss_proj:1.312 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.281 (perp=6.110, rec=0.068, cos=-0.010), tot_loss_proj:1.309 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.280 (perp=6.110, rec=0.068, cos=-0.010), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.288 (perp=6.110, rec=0.076, cos=-0.010), tot_loss_proj:1.311 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.273 (perp=6.110, rec=0.061, cos=-0.010), tot_loss_proj:1.308 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.261 (perp=6.110, rec=0.048, cos=-0.010), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.269 (perp=6.110, rec=0.056, cos=-0.010), tot_loss_proj:1.310 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.272 (perp=6.110, rec=0.060, cos=-0.010), tot_loss_proj:1.301 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.268 (perp=6.110, rec=0.056, cos=-0.010), tot_loss_proj:1.304 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.274 (perp=6.110, rec=0.061, cos=-0.010), tot_loss_proj:1.304 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.277 (perp=6.110, rec=0.065, cos=-0.010), tot_loss_proj:1.295 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.277 (perp=6.110, rec=0.065, cos=-0.010), tot_loss_proj:1.316 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.282 (perp=6.110, rec=0.070, cos=-0.010), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.278 (perp=6.110, rec=0.066, cos=-0.010), tot_loss_proj:1.306 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.270 (perp=6.110, rec=0.058, cos=-0.010), tot_loss_proj:1.300 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.272 (perp=6.110, rec=0.060, cos=-0.010), tot_loss_proj:1.311 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.275 (perp=6.110, rec=0.063, cos=-0.010), tot_loss_proj:1.298 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.276 (perp=6.110, rec=0.063, cos=-0.010), tot_loss_proj:1.301 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.277 (perp=6.110, rec=0.064, cos=-0.010), tot_loss_proj:1.306 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.278 (perp=6.110, rec=0.066, cos=-0.010), tot_loss_proj:1.314 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.266 (perp=6.110, rec=0.053, cos=-0.010), tot_loss_proj:1.295 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.272 (perp=6.110, rec=0.059, cos=-0.010), tot_loss_proj:1.300 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.277 (perp=6.110, rec=0.065, cos=-0.010), tot_loss_proj:1.313 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.280 (perp=6.110, rec=0.068, cos=-0.010), tot_loss_proj:1.307 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.280 (perp=6.110, rec=0.067, cos=-0.010), tot_loss_proj:1.312 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.264 (perp=6.110, rec=0.052, cos=-0.010), tot_loss_proj:1.295 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.275 (perp=6.110, rec=0.062, cos=-0.010), tot_loss_proj:1.297 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.274 (perp=6.110, rec=0.062, cos=-0.010), tot_loss_proj:1.309 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.270 (perp=6.110, rec=0.058, cos=-0.010), tot_loss_proj:1.306 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.263 (perp=6.110, rec=0.050, cos=-0.010), tot_loss_proj:1.309 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.530 | p: 89.291 | r: 91.803
rouge2     | fm: 62.436 | p: 61.887 | r: 63.116
rougeL     | fm: 82.692 | p: 81.744 | r: 83.785
rougeLsum  | fm: 82.285 | p: 81.234 | r: 83.367
r1fm+r2fm = 152.966

input #19 time: 0:11:04 | total time: 2:44:51


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
*********************************
*********************************
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.813522219657898 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8018914461135864 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7928059697151184 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7927916049957275 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7916965484619141 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.765182614326477 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7627440690994263 for ['[CLS]pid poor forming african [SEP]']
[Init] best perm rec loss: 0.7611280083656311 for ['[CLS] african poor formingpid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.935 (perp=12.525, rec=0.426, cos=0.004), tot_loss_proj:3.587 [t=0.25s]
prediction: ['[CLS]uation candi pleasure something [SEP]']
[ 100/2000] tot_loss=2.409 (perp=10.658, rec=0.282, cos=-0.004), tot_loss_proj:3.423 [t=0.25s]
prediction: ['[CLS]verseverse pleasureverse [SEP]']
[ 150/2000] tot_loss=2.367 (perp=10.658, rec=0.241, cos=-0.005), tot_loss_proj:3.428 [t=0.26s]
prediction: ['[CLS]verseverse pleasureverse [SEP]']
[ 200/2000] tot_loss=2.081 (perp=9.639, rec=0.160, cos=-0.007), tot_loss_proj:2.834 [t=0.25s]
prediction: ['[CLS] theverse pleasureverse [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.046 (perp=9.639, rec=0.127, cos=-0.009), tot_loss_proj:2.834 [t=0.25s]
prediction: ['[CLS] theverse pleasureverse [SEP]']
[ 300/2000] tot_loss=2.016 (perp=9.639, rec=0.097, cos=-0.009), tot_loss_proj:2.832 [t=0.25s]
prediction: ['[CLS] theverse pleasureverse [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.639 (perp=7.784, rec=0.092, cos=-0.009), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.631 (perp=7.784, rec=0.083, cos=-0.009), tot_loss_proj:1.913 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 450/2000] tot_loss=1.623 (perp=7.784, rec=0.076, cos=-0.009), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.624 (perp=7.784, rec=0.077, cos=-0.010), tot_loss_proj:1.923 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.620 (perp=7.784, rec=0.073, cos=-0.010), tot_loss_proj:1.938 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 600/2000] tot_loss=1.624 (perp=7.784, rec=0.076, cos=-0.009), tot_loss_proj:1.930 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.615 (perp=7.784, rec=0.068, cos=-0.010), tot_loss_proj:1.922 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.614 (perp=7.784, rec=0.067, cos=-0.010), tot_loss_proj:1.920 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 750/2000] tot_loss=1.606 (perp=7.784, rec=0.059, cos=-0.010), tot_loss_proj:1.933 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.623 (perp=7.784, rec=0.076, cos=-0.010), tot_loss_proj:1.910 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.616 (perp=7.784, rec=0.069, cos=-0.010), tot_loss_proj:1.929 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 900/2000] tot_loss=1.619 (perp=7.784, rec=0.072, cos=-0.010), tot_loss_proj:1.928 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.607 (perp=7.784, rec=0.060, cos=-0.010), tot_loss_proj:1.932 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.629 (perp=7.784, rec=0.081, cos=-0.010), tot_loss_proj:1.925 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1050/2000] tot_loss=1.611 (perp=7.784, rec=0.064, cos=-0.010), tot_loss_proj:1.933 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.612 (perp=7.784, rec=0.065, cos=-0.010), tot_loss_proj:1.922 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.620 (perp=7.784, rec=0.072, cos=-0.010), tot_loss_proj:1.923 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1200/2000] tot_loss=1.615 (perp=7.784, rec=0.068, cos=-0.010), tot_loss_proj:1.922 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.623 (perp=7.784, rec=0.076, cos=-0.010), tot_loss_proj:1.928 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.613 (perp=7.784, rec=0.066, cos=-0.010), tot_loss_proj:1.930 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1350/2000] tot_loss=1.626 (perp=7.784, rec=0.079, cos=-0.010), tot_loss_proj:1.923 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.617 (perp=7.784, rec=0.070, cos=-0.010), tot_loss_proj:1.922 [t=0.21s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.607 (perp=7.784, rec=0.060, cos=-0.010), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1500/2000] tot_loss=1.610 (perp=7.784, rec=0.063, cos=-0.010), tot_loss_proj:1.924 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.616 (perp=7.784, rec=0.069, cos=-0.010), tot_loss_proj:1.925 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.610 (perp=7.784, rec=0.063, cos=-0.010), tot_loss_proj:1.934 [t=0.27s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1650/2000] tot_loss=1.614 (perp=7.784, rec=0.067, cos=-0.010), tot_loss_proj:1.921 [t=0.27s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.784, rec=0.066, cos=-0.010), tot_loss_proj:1.924 [t=0.27s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.611 (perp=7.784, rec=0.063, cos=-0.010), tot_loss_proj:1.919 [t=0.25s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1800/2000] tot_loss=1.610 (perp=7.784, rec=0.063, cos=-0.010), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.607 (perp=7.784, rec=0.060, cos=-0.010), tot_loss_proj:1.929 [t=0.25s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.604 (perp=7.784, rec=0.057, cos=-0.010), tot_loss_proj:1.927 [t=0.28s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1950/2000] tot_loss=1.617 (perp=7.784, rec=0.069, cos=-0.010), tot_loss_proj:1.926 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.614 (perp=7.784, rec=0.067, cos=-0.010), tot_loss_proj:1.918 [t=0.26s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the pleasure perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.001 | p: 89.877 | r: 92.247
rouge2     | fm: 61.051 | p: 60.511 | r: 61.714
rougeL     | fm: 82.500 | p: 81.589 | r: 83.616
rougeLsum  | fm: 82.182 | p: 81.161 | r: 83.310
r1fm+r2fm = 152.052

input #20 time: 0:09:40 | total time: 2:54:31


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
*********************************
*********************************
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9415550231933594 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.881145179271698 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8719595670700073 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8715744018554688 for ['[CLS] rising paperÑhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8490786552429199 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8239164352416992 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.820530891418457 for ['[CLS]westock displays lock [MASK] peg potatoes precious sarajevo tomorrow gingerhis offers extension recently part lake pena comedy punjabhraors hardware alabama chemical [SEP]']
[Init] best rec loss: 0.8185598850250244 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8150901794433594 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8130291700363159 for ['[CLS] daddy odd range surgical firm chamber jinoom [SEP] above viva extra brows speed ashland clear episode evidence returnfying sq village waters right commission [SEP]']
[Init] best perm rec loss: 0.8112152814865112 for ['[CLS] extra brows odd speedoom commission daddy range clear surgical evidence firm episode [SEP] viva waters above returnfying village jin ashland right chamber sq [SEP]']
[Init] best perm rec loss: 0.8100186586380005 for ['[CLS] right evidence ashland extra range speed return odd surgical episodeoom commissionfying viva [SEP] daddy brows jin waters sq village above firm chamber clear [SEP]']
[Init] best perm rec loss: 0.8091968297958374 for ['[CLS] speed evidenceoom extra commission return ashland chamber firm daddy episodefying right jin brows [SEP] above village clear viva sq surgical odd range waters [SEP]']
[Init] best perm rec loss: 0.8089424967765808 for ['[CLS] surgical sq odd return vivafying browsoom village [SEP] jin chamber firm clear daddy range ashland waters extra above commission evidence speed right episode [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.979 (perp=12.692, rec=0.447, cos=-0.006), tot_loss_proj:3.517 [t=0.27s]
prediction: ['[CLS] government instead might overturned bribes less undernsed worker % truck vietnamesees ` hash list accused evacuate doubt duct? guilt ole head flat [SEP]']
[ 100/2000] tot_loss=2.759 (perp=12.041, rec=0.358, cos=-0.007), tot_loss_proj:3.388 [t=0.26s]
prediction: ['[CLS] policy despite likely units procedure rates of bad worker % truck pitcherses ratio front. superintendent infantry want engineering robberyfying product a flat [SEP]']
[ 150/2000] tot_loss=2.795 (perp=12.396, rec=0.317, cos=-0.001), tot_loss_proj:3.459 [t=0.25s]
prediction: ['[CLS] ruling more way barrel procedure athletes hisnsedtypical % that transmitter effect Â°f on. exiting preferred want engineeringÂ¦fying looking a flat [SEP]']
[ 200/2000] tot_loss=2.416 (perp=10.719, rec=0.277, cos=-0.005), tot_loss_proj:3.105 [t=0.27s]
prediction: ['[CLS] how made way figure look athletes hisnsedtypical women of caretaker effect women on. putting instead due thereforeÂ¦fying looking a machine [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.393 (perp=10.850, rec=0.232, cos=-0.009), tot_loss_proj:3.697 [t=0.25s]
prediction: ['[CLS] way makes way works look athletes their brokentypical women of caretaker effect on women. putting instead due constitutesÂ¦fying looking more camera [SEP]']
[ 300/2000] tot_loss=2.196 (perp=10.043, rec=0.197, cos=-0.009), tot_loss_proj:3.655 [t=0.26s]
prediction: ['[CLS] way makes all works look athletes the caretakertypical women of caretaker out on women. putting instead due hopefully wordfying looking more camera [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.187 (perp=10.075, rec=0.181, cos=-0.009), tot_loss_proj:3.299 [t=0.26s]
prediction: ['[CLS] way makes all works out athletes the womentypical caretaker of caretaker out teaching mistress, eyebrows instead of hopefully wordfying look more camera [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.170 (perp=10.103, rec=0.159, cos=-0.009), tot_loss_proj:3.423 [t=0.27s]
prediction: ['[CLS] makes way all works out athletes the womentypical caretaker of caretaker out teaching mistress. eyebrows instead of enough wordfying look more camera [SEP]']
[ 450/2000] tot_loss=2.134 (perp=9.915, rec=0.160, cos=-0.009), tot_loss_proj:3.442 [t=0.26s]
prediction: ['[CLS] makes way all works out athletes the womentypical caretaker of caretaker out teaching mistress. eyebrows instead of enough chfying look more like [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.987 (perp=9.237, rec=0.149, cos=-0.010), tot_loss_proj:3.539 [t=0.26s]
prediction: ['[CLS] enough way all works out athletes the womentypical caretaker of caretaker out moral mistress, eyebrows instead of makes chfying look more like [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.066 (perp=9.664, rec=0.142, cos=-0.009), tot_loss_proj:3.525 [t=0.27s]
prediction: ['[CLS] union way all works out athletes the womentypical caretaker of caretaker out moral caretaker, eyebrows instead of makes chfying look more like [SEP]']
[ 600/2000] tot_loss=2.054 (perp=9.664, rec=0.131, cos=-0.010), tot_loss_proj:3.522 [t=0.26s]
prediction: ['[CLS] union way all works out athletes the womentypical caretaker of caretaker out moral caretaker, eyebrows instead of makes chfying look more like [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.183 (perp=10.193, rec=0.153, cos=-0.009), tot_loss_proj:3.248 [t=0.26s]
prediction: ['[CLS]fying way all works out athletes the womentypical caretaker all caretaker out moral caretaker,typical instead. makesulously persist look more like [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.033 (perp=9.457, rec=0.151, cos=-0.009), tot_loss_proj:3.164 [t=0.26s]
prediction: ['[CLS]fying way all works out athletes the womentypical caretaker caretaker out moral caretaker, all cute instead. makes replaced moreover look more like [SEP]']
[ 750/2000] tot_loss=2.056 (perp=9.605, rec=0.144, cos=-0.010), tot_loss_proj:3.377 [t=0.27s]
prediction: ['[CLS]fying way all works out athletes the womentypical caretaker caretaker out moral caretaker, all cute instead. makes apples instrumental look more like [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.982 (perp=9.271, rec=0.137, cos=-0.009), tot_loss_proj:2.769 [t=0.26s]
prediction: ['[CLS]fying way all works out athletes the women moreovertypical caretaker caretaker out moral caretaker, of cute instead. makes bullshit look more like [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.879 (perp=8.772, rec=0.134, cos=-0.009), tot_loss_proj:2.660 [t=0.27s]
prediction: ['[CLS]fying way all works out athletes the women moreovertypical caretaker caretaker, moral caretaker out of cute instead. makes bullshit look more like [SEP]']
[ 900/2000] tot_loss=1.871 (perp=8.772, rec=0.126, cos=-0.010), tot_loss_proj:2.662 [t=0.27s]
prediction: ['[CLS]fying way all works out athletes the women moreovertypical caretaker caretaker, moral caretaker out of cute instead. makes bullshit look more like [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.841 (perp=8.582, rec=0.135, cos=-0.010), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS]fying way moreover all works out athletes the womentypical caretaker caretaker, moral caretaker out of cute instead. makes apples look more like [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.833 (perp=8.587, rec=0.125, cos=-0.010), tot_loss_proj:3.121 [t=0.27s]
prediction: ['[CLS]fying way moreover all works out athletes the women caretaker stereotypical, moral caretaker out of cute instead. makes apples look more like [SEP]']
[1050/2000] tot_loss=1.833 (perp=8.587, rec=0.125, cos=-0.010), tot_loss_proj:3.115 [t=0.26s]
prediction: ['[CLS]fying way moreover all works out athletes the women caretaker stereotypical, moral caretaker out of cute instead. makes apples look more like [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.814 (perp=8.474, rec=0.129, cos=-0.010), tot_loss_proj:3.057 [t=0.25s]
prediction: ['[CLS]fying way moreover all works out athletes the women caretaker stereotypical moral caretaker, out of cute instead. makes apples look more like [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.891 (perp=8.882, rec=0.124, cos=-0.009), tot_loss_proj:2.771 [t=0.25s]
prediction: ['[CLS]fying way repeated all works out athletes the women caretaker stereotypical moral caretaker, out of makes apples look more like when instead. [SEP]']
[1200/2000] tot_loss=1.894 (perp=8.882, rec=0.127, cos=-0.010), tot_loss_proj:2.774 [t=0.26s]
prediction: ['[CLS]fying way repeated all works out athletes the women caretaker stereotypical moral caretaker, out of makes apples look more like when instead. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.749 (perp=8.179, rec=0.123, cos=-0.010), tot_loss_proj:2.666 [t=0.25s]
prediction: ['[CLS]fying way repeated all works out when the women caretaker stereotypical moral caretaker, out of makes apples look more like athletes instead. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.655 (perp=7.710, rec=0.122, cos=-0.009), tot_loss_proj:2.587 [t=0.27s]
prediction: ['[CLS]fying way caretaker all works out when the women repeated stereotypical moral caretaker, out of makes apples look more like athletes instead. [SEP]']
[1350/2000] tot_loss=1.658 (perp=7.710, rec=0.126, cos=-0.010), tot_loss_proj:2.584 [t=0.27s]
prediction: ['[CLS]fying way caretaker all works out when the women repeated stereotypical moral caretaker, out of makes apples look more like athletes instead. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.732 (perp=8.054, rec=0.131, cos=-0.010), tot_loss_proj:2.855 [t=0.26s]
prediction: ['[CLS]fying caretaker way all works out serious the women repeated stereotypical moral caretaker, out of makes apples look more like athletes instead. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.672 (perp=7.775, rec=0.126, cos=-0.010), tot_loss_proj:2.604 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker serious out of makes apples look more like athletes instead. [SEP]']
[1500/2000] tot_loss=1.662 (perp=7.775, rec=0.117, cos=-0.010), tot_loss_proj:2.598 [t=0.29s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker serious out of makes apples look more like athletes instead. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.651 (perp=7.693, rec=0.122, cos=-0.010), tot_loss_proj:2.580 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more serious like athletes instead. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.626 (perp=7.586, rec=0.118, cos=-0.010), tot_loss_proj:2.507 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
[1650/2000] tot_loss=1.624 (perp=7.586, rec=0.116, cos=-0.010), tot_loss_proj:2.516 [t=0.29s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.621 (perp=7.586, rec=0.113, cos=-0.010), tot_loss_proj:2.511 [t=0.29s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.628 (perp=7.586, rec=0.121, cos=-0.010), tot_loss_proj:2.505 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
[1800/2000] tot_loss=1.622 (perp=7.586, rec=0.114, cos=-0.010), tot_loss_proj:2.513 [t=0.29s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.624 (perp=7.586, rec=0.117, cos=-0.010), tot_loss_proj:2.513 [t=0.30s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.624 (perp=7.586, rec=0.117, cos=-0.010), tot_loss_proj:2.512 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
[1950/2000] tot_loss=1.619 (perp=7.586, rec=0.112, cos=-0.010), tot_loss_proj:2.514 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.624 (perp=7.552, rec=0.124, cos=-0.010), tot_loss_proj:2.497 [t=0.28s]
prediction: ['[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of serious makes apples look more like athletes instead. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS]fying caretaker way all works out, the women repeated stereotypical moral caretaker out of makes apples look more like serious athletes instead. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 75.000 | r: 78.261
rouge2     | fm: 26.667 | p: 26.087 | r: 27.273
rougeL     | fm: 55.319 | p: 54.167 | r: 56.522
rougeLsum  | fm: 55.319 | p: 54.167 | r: 56.522
r1fm+r2fm = 103.262

[Aggregate metrics]:
rouge1     | fm: 90.325 | p: 89.164 | r: 91.586
rouge2     | fm: 59.265 | p: 58.815 | r: 59.827
rougeL     | fm: 81.215 | p: 80.299 | r: 82.239
rougeLsum  | fm: 80.898 | p: 79.972 | r: 81.924
r1fm+r2fm = 149.589

input #21 time: 0:11:10 | total time: 3:05:42


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
*********************************
*********************************
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9641942381858826 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9582980871200562 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9533578157424927 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9530670642852783 for ['[CLS] husband figures individual merge gdp planongriders beat your nur [SEP]']
[Init] best rec loss: 0.936561644077301 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9236189723014832 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9202683568000793 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9199215769767761 for ['[CLS] poor resemblance wrote $ manufacture i vested another dir immunity access [SEP]']
[Init] best perm rec loss: 0.9190679788589478 for ['[CLS] $ wrote poor vested dir immunity resemblance manufacture i another access [SEP]']
[Init] best perm rec loss: 0.917163074016571 for ['[CLS] dir manufacture i $ another poor access immunity wrote vested resemblance [SEP]']
[Init] best perm rec loss: 0.9159475564956665 for ['[CLS] $ i another manufacture resemblance immunity vested access poor wrote dir [SEP]']
[Init] best perm rec loss: 0.9134272336959839 for ['[CLS] dir wrote i vested manufacture immunity access $ another poor resemblance [SEP]']
[Init] best perm rec loss: 0.9125464558601379 for ['[CLS] manufacture $ immunity vested resemblance wrote i dir another access poor [SEP]']
[Init] best perm rec loss: 0.9117497801780701 for ['[CLS] manufacture vested access immunity poor another resemblance i $ wrote dir [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.343 (perp=10.456, rec=0.259, cos=-0.007), tot_loss_proj:2.497 [t=0.35s]
prediction: ['[CLS] adventure successful integral good design a wonderful successful adaptation produced successful [SEP]']
[ 100/2000] tot_loss=2.044 (perp=9.354, rec=0.182, cos=-0.008), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] successful successfuleller adaptation adaptation a successful enjoyable adaptation. successful [SEP]']
[ 150/2000] tot_loss=1.787 (perp=8.200, rec=0.156, cos=-0.009), tot_loss_proj:2.023 [t=0.25s]
prediction: ['[CLS] a successful self adaptation adaptation a successful enjoyable adaptation. its [SEP]']
[ 200/2000] tot_loss=1.844 (perp=8.647, rec=0.124, cos=-0.009), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] a successful self adaptation film a an enjoyable adaptation. its [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.582 (perp=7.308, rec=0.129, cos=-0.009), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] a successful film adaptation right and an enjoyable adaptation film its [SEP]']
[ 300/2000] tot_loss=1.563 (perp=7.308, rec=0.110, cos=-0.009), tot_loss_proj:1.812 [t=0.26s]
prediction: ['[CLS] a successful film adaptation right and an enjoyable adaptation film its [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.553 (perp=7.389, rec=0.084, cos=-0.009), tot_loss_proj:1.809 [t=0.25s]
prediction: ['[CLS] a successful film adaptation right and an enjoyable adaptation own in [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.386 (perp=6.578, rec=0.080, cos=-0.009), tot_loss_proj:1.557 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and an enjoyable adaptation own right in [SEP]']
[ 450/2000] tot_loss=1.383 (perp=6.578, rec=0.076, cos=-0.009), tot_loss_proj:1.547 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable adaptation own right in [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.386 (perp=6.578, rec=0.079, cos=-0.009), tot_loss_proj:1.538 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable adaptation own right in [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.315 (perp=6.278, rec=0.068, cos=-0.009), tot_loss_proj:1.507 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in own right adaptation [SEP]']
[ 600/2000] tot_loss=1.326 (perp=6.278, rec=0.079, cos=-0.009), tot_loss_proj:1.503 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in own right adaptation [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.274 (perp=6.031, rec=0.077, cos=-0.009), tot_loss_proj:1.469 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an enjoyable own right adaptation [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.273 (perp=6.031, rec=0.076, cos=-0.009), tot_loss_proj:1.468 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an enjoyable own right adaptation [SEP]']
[ 750/2000] tot_loss=1.274 (perp=6.031, rec=0.076, cos=-0.009), tot_loss_proj:1.476 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an enjoyable own right adaptation [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.262 (perp=6.031, rec=0.064, cos=-0.009), tot_loss_proj:1.476 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an enjoyable own right adaptation [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.214 (perp=5.768, rec=0.069, cos=-0.009), tot_loss_proj:1.415 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[ 900/2000] tot_loss=1.220 (perp=5.768, rec=0.076, cos=-0.009), tot_loss_proj:1.417 [t=0.27s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.217 (perp=5.768, rec=0.073, cos=-0.009), tot_loss_proj:1.418 [t=0.27s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1000/2000] tot_loss=1.196 (perp=5.768, rec=0.052, cos=-0.009), tot_loss_proj:1.412 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1050/2000] tot_loss=1.215 (perp=5.768, rec=0.071, cos=-0.009), tot_loss_proj:1.427 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1100/2000] tot_loss=1.215 (perp=5.768, rec=0.070, cos=-0.009), tot_loss_proj:1.417 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1150/2000] tot_loss=1.213 (perp=5.768, rec=0.068, cos=-0.009), tot_loss_proj:1.425 [t=0.27s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1200/2000] tot_loss=1.217 (perp=5.768, rec=0.073, cos=-0.009), tot_loss_proj:1.422 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1250/2000] tot_loss=1.208 (perp=5.768, rec=0.064, cos=-0.009), tot_loss_proj:1.416 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1300/2000] tot_loss=1.215 (perp=5.768, rec=0.070, cos=-0.009), tot_loss_proj:1.412 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1350/2000] tot_loss=1.213 (perp=5.768, rec=0.068, cos=-0.009), tot_loss_proj:1.423 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.216 (perp=5.768, rec=0.072, cos=-0.009), tot_loss_proj:1.416 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1450/2000] tot_loss=1.225 (perp=5.768, rec=0.080, cos=-0.009), tot_loss_proj:1.427 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1500/2000] tot_loss=1.210 (perp=5.768, rec=0.065, cos=-0.009), tot_loss_proj:1.431 [t=0.27s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1550/2000] tot_loss=1.216 (perp=5.768, rec=0.072, cos=-0.009), tot_loss_proj:1.421 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1600/2000] tot_loss=1.217 (perp=5.768, rec=0.073, cos=-0.009), tot_loss_proj:1.425 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1650/2000] tot_loss=1.220 (perp=5.768, rec=0.075, cos=-0.009), tot_loss_proj:1.417 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1700/2000] tot_loss=1.220 (perp=5.768, rec=0.075, cos=-0.009), tot_loss_proj:1.421 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1750/2000] tot_loss=1.219 (perp=5.768, rec=0.074, cos=-0.009), tot_loss_proj:1.420 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1800/2000] tot_loss=1.217 (perp=5.768, rec=0.072, cos=-0.009), tot_loss_proj:1.419 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1850/2000] tot_loss=1.213 (perp=5.768, rec=0.068, cos=-0.009), tot_loss_proj:1.422 [t=0.27s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[1900/2000] tot_loss=1.219 (perp=5.768, rec=0.074, cos=-0.009), tot_loss_proj:1.423 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
[1950/2000] tot_loss=1.217 (perp=5.768, rec=0.073, cos=-0.009), tot_loss_proj:1.430 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Attempt swap
[2000/2000] tot_loss=1.219 (perp=5.768, rec=0.074, cos=-0.009), tot_loss_proj:1.426 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful film adaptation and in an own right enjoyable adaptation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 125.641

[Aggregate metrics]:
rouge1     | fm: 90.456 | p: 89.293 | r: 91.649
rouge2     | fm: 57.953 | p: 57.457 | r: 58.534
rougeL     | fm: 80.884 | p: 79.901 | r: 81.872
rougeLsum  | fm: 80.382 | p: 79.368 | r: 81.416
r1fm+r2fm = 148.409

input #22 time: 0:10:52 | total time: 3:16:34


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
*********************************
*********************************
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8047433495521545 for ['[CLS] rank braziléƒŽ glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieá´µ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7619422078132629 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7616995573043823 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell reæ›¸amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7562028169631958 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7405182719230652 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandÂª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.7381587028503418 for ['[CLS] compiling ears eponymous education carlo debutrk area guáµˆ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.7374657392501831 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7275494337081909 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7270619869232178 for ['[CLS] baseball remote finlandperation tracks. erica another air her created must total madame marijuana mayo steam quit test monroe clutch fine reaching sensation into writ colon asleeptat eve level office rocker x debuted competitionblood pepper bullshitcellular culture - critics countont host major novel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=11.814, rec=0.461, cos=-0.007), tot_loss_proj:3.456 [t=0.26s]
prediction: ['[CLS] has environmental education orion mission. composition soldier operate creative 2015 should vision aims pulse heritage heritage project globalgc wonderful explosion zero once history unique significance which the rescue curve function project international harder area britten reach be [SEP] needed mission crafts piazzaivar ; urban its [SEP]']
[ 100/2000] tot_loss=2.736 (perp=11.476, rec=0.378, cos=0.063), tot_loss_proj:3.464 [t=0.26s]
prediction: ['[CLS] besides european education rangers program, composition soldier rather ze 1955 should total aims visionlan heritage artistic thermal the archie design madeline demand psychological its dominatedhang the rescue critics objective project graduates head as britten the, becoming needed historical crafts its major ; the its [SEP]']
[ 150/2000] tot_loss=2.695 (perp=12.051, rec=0.285, cos=-0.001), tot_loss_proj:3.588 [t=0.26s]
prediction: ['[CLS] estonian strategic education rangers asset, union crisis rather ze camera should total aims latinlan history ministry thermal the archie design madeline beg built its dominated its the strategic critics objective projects infantry head issues britten the, better increase emotional cannot its major ; the its [SEP]']
[ 200/2000] tot_loss=2.603 (perp=11.819, rec=0.245, cos=-0.006), tot_loss_proj:3.636 [t=0.26s]
prediction: ['[CLS] addressing strategic education rangers portfolio,ity crisis ratherfi camera patriotic its aims "lan history : thermal the archie picture madelinewi otherwise its ultimately its the strategic critics objective projects soldiers stage issues vietnam the, becoming ) emotional cannot its major ; :... [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.505 (perp=11.515, rec=0.209, cos=-0.007), tot_loss_proj:3.459 [t=0.26s]
prediction: ['[CLS]zing strategic objective rangers portfolio,ity dramas ratherfi band patriotic its achieved latin latter history drama... the archie picture madeline meditation ultimately its ultimately its the strategic strategic objective projects soldiers extra issues vietnam the, becoming ) emotional cannot its main ; :. [SEP]']
[ 300/2000] tot_loss=2.364 (perp=10.906, rec=0.191, cos=-0.008), tot_loss_proj:3.408 [t=0.25s]
prediction: ['[CLS]zing strategic objective soldiers portfolio, soldier depicts ratherfi which patriotic list achieve : : generation drama that the patriotic picture madeline meditation ultimately its achieve its the strategic ultimately objective projects soldiers while melissa patriotic the, crisis ) emotionalegorical its main ; : energy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.215 (perp=10.266, rec=0.171, cos=-0.009), tot_loss_proj:3.030 [t=0.26s]
prediction: ['[CLS]zing strategic reasons soldiers portfolio, soldier madeline ratherfi which patriotic list ultimatelys : generation drama that the patriotic picture military meditation ultimately its achieve its the strategic strategic objective drama soldiers while conflict patriotic the, crisis ) emotionalegorical its main ; :ti [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.050 (perp=9.525, rec=0.154, cos=-0.009), tot_loss_proj:2.896 [t=0.27s]
prediction: ['[CLS]zing strategic objective soldiers portfolio, vietnam madeline ratherfi which patriotic creature ultimatelys : generation drama that the patriotic picture military drama ultimately its achieves the strategic strategic objective om soldiers whileiness conflict the, conflict : emotional commuted its main ; :ti [SEP]']
[ 450/2000] tot_loss=2.116 (perp=9.938, rec=0.137, cos=-0.009), tot_loss_proj:2.943 [t=0.25s]
prediction: ['[CLS]zing strategic objective soldiers portfolio, vietnam chronic ratherh which patriotic scenic ultimatelys : generation drama that the patriotic picture vietnam drama ultimately its achieves the strategic strategic objective om soldiers whileiness conflict the, conflict : emotional commuted its main ; :ti [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.077 (perp=9.778, rec=0.131, cos=-0.009), tot_loss_proj:2.980 [t=0.26s]
prediction: ['[CLS] the strategic objective soldiers maynard, vietnamyear ratherh which patriotic tales ultimately a : generation drama thatzing patriotic picture vietnam drama ultimately its achieves the strategic strategic objective ra soldiers whileiness conflict the, conflict.clops commuted its main ; :ti [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.041 (perp=9.649, rec=0.120, cos=-0.009), tot_loss_proj:2.990 [t=0.27s]
prediction: ['[CLS] the strategic patriotic vietnam will, vietnam chronic ratherh which patriotic tales ultimately a : generation drama thatzing patriotic picture patriotic drama ultimately its achieves the strategic strategic objective ra soldiers whileiness conflict theclops conflict., cannot its main ; :ti [SEP]']
[ 600/2000] tot_loss=2.013 (perp=9.503, rec=0.122, cos=-0.009), tot_loss_proj:2.983 [t=0.26s]
prediction: ['[CLS] the strategic patriotic vietnam will, vietnam chronic ratherh which patriotic tales ultimately of : generation drama thatzing patriotic picture patriotic drama ultimately its achieves the strategic objective objective ra soldiers whileping conflict theclops conflict., cannot its main ; :ti [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.003 (perp=9.488, rec=0.115, cos=-0.010), tot_loss_proj:3.173 [t=0.27s]
prediction: ['[CLS] a strategic patriotic drama will, vietnam chronic abouth which patriotic tales ultimately a : generation drama thatzing patriotic picture patriotic vietnam ultimately its achieves the strategic objective objective ra soldiers whileping conflict theclops conflict.,stream its main ; :ti [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.937 (perp=9.162, rec=0.114, cos=-0.009), tot_loss_proj:3.094 [t=0.26s]
prediction: ['[CLS] a strategic objective drama will, vietnam chronic intoh which patriotic tales ultimately a : generation dramatizing patriotic picture patriotic vietnam ultimately its achieves the strategic objective objective ra soldiers whileping conflict theclops conflict.,stream its main ; : that [SEP]']
[ 750/2000] tot_loss=1.922 (perp=9.098, rec=0.112, cos=-0.010), tot_loss_proj:3.074 [t=0.26s]
prediction: ['[CLS] a strategic objective drama will, vietnam chronic intoh which patriotic tales ultimately a : generation dramatizing patriotic picture patriotic vietnam ultimately its achieves the strategic objective objective ra soldiers whileping conflict the selena conflict.,stream its main ; : that [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.940 (perp=9.205, rec=0.108, cos=-0.010), tot_loss_proj:3.141 [t=0.27s]
prediction: ['[CLS] a strategic objective drama will, vietnam chronic intoh which patriotic its ultimately a : generation dramatizing patriotic picture patriotic vietnam ultimately its achieves the strategic objective objective ra soldiers whileping theclops conflict of, conflictstream its main ; :. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.883 (perp=8.896, rec=0.114, cos=-0.010), tot_loss_proj:3.025 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam tone intoh which patriotic its ultimately a : generation dramatizing patriotic picture patriotic vietnam ultimately its achieves the strategic objective objective while soldiers raping the selena conflict of, conflictstream its main ; :. [SEP]']
[ 900/2000] tot_loss=1.910 (perp=9.085, rec=0.103, cos=-0.010), tot_loss_proj:2.977 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam tone intoh which patriotic its ultimately a : generation dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers raping theclops conflict of, conflictstream its main ; :. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.873 (perp=8.897, rec=0.103, cos=-0.010), tot_loss_proj:2.867 [t=0.25s]
prediction: ['[CLS] a strategic object drama will, vietnam tone intoh which patriotic its ultimately a generation : dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers raping theclops conflict of, conflictstream its main ; :. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.885 (perp=8.961, rec=0.102, cos=-0.010), tot_loss_proj:2.820 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam from intoh which patriotic such ultimately a generation : dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers raping theclops conflict tone, conflictstream its main ; :. [SEP]']
[1050/2000] tot_loss=1.900 (perp=9.042, rec=0.101, cos=-0.010), tot_loss_proj:2.791 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam of intoh which patriotic such ultimately with generation : dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers ra with theclops conflict tone, conflictstream its main ; :. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.853 (perp=8.794, rec=0.104, cos=-0.010), tot_loss_proj:2.821 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam of intoh which tone such ultimately a generation : dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers ra with the selena conflict patriotic, conflictstream its main ; :. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.790 (perp=8.500, rec=0.100, cos=-0.010), tot_loss_proj:2.671 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam : ofh which tone such ultimately a generation of dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers ra with the selena conflict patriotic, conflictstream its main ; :. [SEP]']
[1200/2000] tot_loss=1.828 (perp=8.679, rec=0.102, cos=-0.010), tot_loss_proj:2.721 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture patriotic ra ultimately its achieves the strategic objective objective while soldiers ra with the selena conflict patriotic, conflictstream its main ; :. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.716 (perp=8.145, rec=0.097, cos=-0.010), tot_loss_proj:2.829 [t=0.25s]
prediction: ['[CLS] a strategic object drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture, ra ultimately its achieves the strategic objective objective while soldiers ra with the selena conflict patriotic patriotic conflict. its main ; :. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.676 (perp=7.929, rec=0.100, cos=-0.010), tot_loss_proj:2.836 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture, ra ultimately its achieves the strategic objective objective while soldiers ra with the main conflict patriotic patriotic conflict. its selena ; :. [SEP]']
[1350/2000] tot_loss=1.729 (perp=8.199, rec=0.099, cos=-0.010), tot_loss_proj:2.796 [t=0.26s]
prediction: ['[CLS] a strategic object drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture, ra ultimately its achieves the strategic objective objective while soldiers ra such the main conflict patriotic patriotic conflict. itsclops ; :. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.772 (perp=8.428, rec=0.096, cos=-0.010), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] a strategic object drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda conflictstream itsclops ; :. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.679 (perp=7.943, rec=0.100, cos=-0.010), tot_loss_proj:2.633 [t=0.26s]
prediction: ['[CLS] a strategic conflict drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic patriotic object. itsclops ; :. [SEP]']
[1500/2000] tot_loss=1.682 (perp=7.943, rec=0.103, cos=-0.010), tot_loss_proj:2.638 [t=0.25s]
prediction: ['[CLS] a strategic conflict drama will, vietnam, ofh which tone such ultimately with generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic patriotic object. itsclops ; :. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.673 (perp=7.936, rec=0.096, cos=-0.010), tot_loss_proj:2.694 [t=0.27s]
prediction: ['[CLS] a strategic conflict drama will, vietnam, ofh which tone with such ultimately generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. its selena ; :. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.708 (perp=8.112, rec=0.096, cos=-0.010), tot_loss_proj:2.761 [t=0.27s]
prediction: ['[CLS] a strategic conflict tone will, vietnam, ofh which its with such ultimately generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. tone selena ; :. [SEP]']
[1650/2000] tot_loss=1.714 (perp=8.112, rec=0.101, cos=-0.010), tot_loss_proj:2.763 [t=0.26s]
prediction: ['[CLS] a strategic conflict tone will, vietnam, ofh which its with such ultimately generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. tone selena ; :. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.692 (perp=8.042, rec=0.093, cos=-0.010), tot_loss_proj:2.728 [t=0.27s]
prediction: ['[CLS] a strategic conflict tone will, vietnam, ofh which its with such ultimately generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. tone selena ;. : [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.724 (perp=8.177, rec=0.098, cos=-0.010), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] a strategic conflict tone will, vietnam, ofh which its tone such ultimately generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. withclops ;. : [SEP]']
[1800/2000] tot_loss=1.719 (perp=8.177, rec=0.094, cos=-0.010), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS] a strategic conflict tone will, vietnam, ofh which its tone such ultimately generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. withclops ;. : [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.682 (perp=7.972, rec=0.098, cos=-0.010), tot_loss_proj:2.542 [t=0.27s]
prediction: ['[CLS] a strategic conflict ultimately will, vietnam, ofh which its tone such tone generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. withclops ;. : [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.650 (perp=7.835, rec=0.093, cos=-0.010), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS] a strategic conflict ultimately will, vietnam, ofh which its tone such tone generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict kinda object. patriotic withclops ;. : [SEP]']
[1950/2000] tot_loss=1.653 (perp=7.835, rec=0.096, cos=-0.010), tot_loss_proj:2.517 [t=0.26s]
prediction: ['[CLS] a strategic conflict ultimately will, vietnam, ofh which its tone such tone generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict kinda object. patriotic withclops ;. : [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.692 (perp=8.033, rec=0.095, cos=-0.010), tot_loss_proj:2.645 [t=0.26s]
prediction: ['[CLS] a strategic conflict ultimately will, vietnam, ofh which its tone selena tone generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict kinda object. patriotic with such ;. : [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] a strategic conflict ultimately will, vietnam, ofh which its tone such tone generation of dramatizing patriotic picture, ra ultimately achieves its the strategic objective objective while soldiers ra such the main conflict patriotic kinda object. withclops ;. : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 63.158 | r: 60.000
rouge2     | fm: 7.895 | p: 8.108 | r: 7.692
rougeL     | fm: 33.333 | p: 34.211 | r: 32.500
rougeLsum  | fm: 33.333 | p: 34.211 | r: 32.500
r1fm+r2fm = 69.433

[Aggregate metrics]:
rouge1     | fm: 89.156 | p: 88.148 | r: 90.343
rouge2     | fm: 55.776 | p: 55.379 | r: 56.305
rougeL     | fm: 78.794 | p: 77.861 | r: 79.743
rougeLsum  | fm: 78.390 | p: 77.589 | r: 79.403
r1fm+r2fm = 144.932

input #23 time: 0:11:04 | total time: 3:27:39


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
*********************************
*********************************
average of cosine similarity 0.9993537840940759
highest_index [0]
highest [0.9993537840940759]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.894450843334198 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.867894172668457 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8559075593948364 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8252934217453003 for ['[CLS] lying afford rubbed media Ø© soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.822307825088501 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148989677429199 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7632057666778564 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7629173994064331 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7620291113853455 for ['[CLS] em village damned suffer snow county mid bush attackaneous happy port bond younger unless armswyl no play ryu [SEP]']
[Init] best perm rec loss: 0.7610010504722595 for ['[CLS] em snow no bond suffer villagewyl play bush unlessaneous ryu mid arms port attack damned happy county younger [SEP]']
[Init] best perm rec loss: 0.7564561367034912 for ['[CLS] portaneouswyl em arms attack damned play ryu happy younger bond mid suffer county unless no village bush snow [SEP]']
[Init] best perm rec loss: 0.7562641501426697 for ['[CLS] county damned play sufferaneouswyl younger unless snow no mid happy arms em ryu attack village bush port bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.843 (perp=11.968, rec=0.453, cos=-0.004), tot_loss_proj:3.385 [t=0.28s]
prediction: ['[CLS] protest sect ac workers fringe - evil taken garbage interrupting drugrta organizations stupid?ched japanese chain terrorists terrorist [SEP]']
[ 100/2000] tot_loss=2.909 (perp=12.789, rec=0.360, cos=-0.009), tot_loss_proj:3.573 [t=0.26s]
prediction: ['[CLS] police terrorist ac political fringe xml evilinatory accused terrorist drug an countries stupid!feit su chain terrorists defensive [SEP]']
[ 150/2000] tot_loss=2.639 (perp=11.281, rec=0.386, cos=-0.003), tot_loss_proj:3.176 [t=0.26s]
prediction: ['[CLS] mistress evil theurgent )drik evil socialist anger terrorist? nearby policies abortion! arms? - terrorists defensive [SEP]']
[ 200/2000] tot_loss=2.489 (perp=10.984, rec=0.301, cos=-0.009), tot_loss_proj:3.068 [t=0.26s]
prediction: ['[CLS] mistress evil the political ) taken evil political dump terrorists of risk ) evil! guns? force police outside [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.310 (perp=10.345, rec=0.249, cos=-0.008), tot_loss_proj:2.923 [t=0.27s]
prediction: ['[CLS] mistress evil the political context taken evil ) fucked terrorists of coach ( evil! guns! force terrorists outside [SEP]']
[ 300/2000] tot_loss=2.063 (perp=9.252, rec=0.220, cos=-0.008), tot_loss_proj:2.768 [t=0.28s]
prediction: ['[CLS] mistress evil the political context taken evil ) fucked terrorists of risk ( evil! guns! the terrorists outside [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.902 (perp=8.540, rec=0.203, cos=-0.009), tot_loss_proj:2.559 [t=0.27s]
prediction: ['[CLS] evil the political context taken mistress evil ) see terrorists of brain ( evil! guns! the terrorists outside [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.435 (perp=8.743, rec=0.528, cos=0.158), tot_loss_proj:2.484 [t=0.26s]
prediction: ['[CLS] the political context taken were evil ) see terrorists : might ) evil! weapons evil! its terrorists outside [SEP]']
[ 450/2000] tot_loss=2.783 (perp=11.884, rec=0.396, cos=0.010), tot_loss_proj:3.289 [t=0.27s]
prediction: ['[CLS] tertiary its context taken are evil > regarding evil are occurred! )! quota riley questionsive terrorists outside [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.429 (perp=10.343, rec=0.359, cos=0.001), tot_loss_proj:2.978 [t=0.26s]
prediction: ['[CLS] are its context taken are evil > regarding evil his nobody! corporate! weapons riley questionsive terrorists outside [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.313 (perp=9.875, rec=0.340, cos=-0.002), tot_loss_proj:2.846 [t=0.26s]
prediction: ['[CLS] is its context taken are evil > regarding evil trend consequences!! ) weapons riley questionsive terrorists outside [SEP]']
[ 600/2000] tot_loss=2.424 (perp=10.504, rec=0.327, cos=-0.004), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] is its context taken are evil > regarding evil trend consequences!! ) weapons riley electoralive terrorists outside [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.278 (perp=9.837, rec=0.316, cos=-0.006), tot_loss_proj:2.712 [t=0.28s]
prediction: ['[CLS] is its context taken are evil > regarding evil trend consequences!! ) electoral weapons rileyive terrorists outside [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.220 (perp=9.594, rec=0.307, cos=-0.006), tot_loss_proj:2.754 [t=0.26s]
prediction: ['[CLS] is its context taken are evil > regarding evil consequences!! )bolic weapons rileyive terrorists outside trend [SEP]']
[ 750/2000] tot_loss=2.332 (perp=10.196, rec=0.300, cos=-0.007), tot_loss_proj:2.927 [t=0.26s]
prediction: ['[CLS] is its context taken are evil > regarding evil artist!! ) } weapons rileyive terrorists outside trend [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.330 (perp=10.204, rec=0.296, cos=-0.007), tot_loss_proj:2.877 [t=0.27s]
prediction: ['[CLS] is its context taken are evil > regarding evil artist!! ) trend weapons rileyive terrorists outside instead [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.234 (perp=9.752, rec=0.291, cos=-0.007), tot_loss_proj:2.862 [t=0.25s]
prediction: ['[CLS] is its context evil are taken > regarding evil artist!! ) tailed weapons rileyive terrorists outside instead [SEP]']
[ 900/2000] tot_loss=2.223 (perp=9.752, rec=0.280, cos=-0.008), tot_loss_proj:2.860 [t=0.26s]
prediction: ['[CLS] is its context evil are taken > regarding evil artist!! ) tailed weapons rileyive terrorists outside instead [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.153 (perp=9.414, rec=0.278, cos=-0.007), tot_loss_proj:2.769 [t=0.26s]
prediction: ['[CLS] is its context evil outside taken > regarding evil artist!! ) tailed weapons rileyive terrorists are instead [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.109 (perp=9.241, rec=0.268, cos=-0.007), tot_loss_proj:2.842 [t=0.26s]
prediction: ['[CLS] > its context evil outside taken is regarding evil artist!! ) tailed weapons rileyive terrorists are instead [SEP]']
[1050/2000] tot_loss=2.210 (perp=9.718, rec=0.275, cos=-0.008), tot_loss_proj:2.938 [t=0.26s]
prediction: ['[CLS] > its context evil outside taken is regarding evil artist!! ) tailed weaponsilyive terrorists are instead [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.165 (perp=9.535, rec=0.266, cos=-0.008), tot_loss_proj:2.853 [t=0.26s]
prediction: ['[CLS] > its context evil outside taken is regarding evil artist!! ) instead tailed weaponsilyive terrorists are [SEP]']
Attempt swap
[1150/2000] tot_loss=2.224 (perp=9.832, rec=0.266, cos=-0.008), tot_loss_proj:2.983 [t=0.26s]
prediction: ['[CLS] > its context evil outside taken is regarding evil artist!! ) } tailed weaponsilyive terrorists are [SEP]']
[1200/2000] tot_loss=2.218 (perp=9.832, rec=0.260, cos=-0.008), tot_loss_proj:2.991 [t=0.25s]
prediction: ['[CLS] > its context evil outside taken is regarding evil artist!! ) } tailed weaponsilyive terrorists are [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.193 (perp=9.679, rec=0.265, cos=-0.008), tot_loss_proj:2.919 [t=0.27s]
prediction: ['[CLS] ) its context evil outside taken is regarding evil artist!! > } tailed weaponsilyive terrorists are [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.157 (perp=9.522, rec=0.260, cos=-0.008), tot_loss_proj:2.817 [t=0.27s]
prediction: ['[CLS] ) its context evil outside taken is regarding evil artist!! > } tailedily weaponsive terrorists are [SEP]']
[1350/2000] tot_loss=2.153 (perp=9.522, rec=0.256, cos=-0.008), tot_loss_proj:2.811 [t=0.26s]
prediction: ['[CLS] ) its context evil outside taken is regarding evil artist!! > } tailedily weaponsive terrorists are [SEP]']
Attempt swap
[1400/2000] tot_loss=2.164 (perp=9.522, rec=0.268, cos=-0.008), tot_loss_proj:2.814 [t=0.26s]
prediction: ['[CLS] ) its context evil outside taken is regarding evil artist!! > } tailedily weaponsive terrorists are [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.185 (perp=9.699, rec=0.254, cos=-0.008), tot_loss_proj:2.819 [t=0.26s]
prediction: ['[CLS] its ) context evil outside taken is regarding evil artist!! > } tailedily weaponsive terrorists are [SEP]']
[1500/2000] tot_loss=2.183 (perp=9.681, rec=0.255, cos=-0.008), tot_loss_proj:2.783 [t=0.26s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist!! > } tailedily weaponsive terrorists are [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.154 (perp=9.487, rec=0.265, cos=-0.008), tot_loss_proj:2.749 [t=0.27s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! >! } tailedily weaponsive terrorists are [SEP]']
Attempt swap
[1600/2000] tot_loss=2.148 (perp=9.487, rec=0.259, cos=-0.008), tot_loss_proj:2.752 [t=0.28s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! >! } tailedily weaponsive terrorists are [SEP]']
[1650/2000] tot_loss=2.146 (perp=9.487, rec=0.257, cos=-0.009), tot_loss_proj:2.746 [t=0.25s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! >! } tailedily weaponsive terrorists are [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.211 (perp=9.812, rec=0.257, cos=-0.009), tot_loss_proj:2.859 [t=0.26s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! }ily weaponsive terrorists are [SEP]']
Attempt swap
[1750/2000] tot_loss=2.212 (perp=9.812, rec=0.259, cos=-0.009), tot_loss_proj:2.855 [t=0.26s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! }ily weaponsive terrorists are [SEP]']
[1800/2000] tot_loss=2.200 (perp=9.812, rec=0.247, cos=-0.009), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! }ily weaponsive terrorists are [SEP]']
Attempt swap
[1850/2000] tot_loss=2.206 (perp=9.812, rec=0.252, cos=-0.009), tot_loss_proj:2.855 [t=0.27s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! }ily weaponsive terrorists are [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.204 (perp=9.794, rec=0.253, cos=-0.008), tot_loss_proj:2.892 [t=0.26s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! areily weaponsive terrorists } [SEP]']
[1950/2000] tot_loss=2.201 (perp=9.794, rec=0.251, cos=-0.009), tot_loss_proj:2.897 [t=0.28s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! areily weaponsive terrorists } [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.201 (perp=9.765, rec=0.256, cos=-0.008), tot_loss_proj:2.893 [t=0.26s]
prediction: ['[CLS] its political context evil outside taken is regarding evil artist! looking tailed! areive weaponsily terrorists } [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] evil the political context taken mistress evil ) see terrorists : brain ( evil! political! the terrorists outside [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.857 | p: 64.706 | r: 61.111
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 40.000 | p: 41.176 | r: 38.889
rougeLsum  | fm: 40.000 | p: 41.176 | r: 38.889
r1fm+r2fm = 68.918

[Aggregate metrics]:
rouge1     | fm: 88.222 | p: 87.276 | r: 89.226
rouge2     | fm: 53.956 | p: 53.558 | r: 54.475
rougeL     | fm: 77.156 | p: 76.446 | r: 78.055
rougeLsum  | fm: 76.678 | p: 75.873 | r: 77.507
r1fm+r2fm = 142.179

input #24 time: 0:11:04 | total time: 3:38:44


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
*********************************
*********************************
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.002394437789917 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9406914114952087 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9302701950073242 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9185459613800049 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9134899973869324 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9054555296897888 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.876388669013977 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.875738263130188 for ['[CLS] cycle oblast jury mouth [SEP]']
[Init] best perm rec loss: 0.8756436705589294 for ['[CLS] oblast cycle jury mouth [SEP]']
[Init] best perm rec loss: 0.8743534088134766 for ['[CLS] oblast jury mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.058 (perp=8.906, rec=0.281, cos=-0.005), tot_loss_proj:2.263 [t=0.26s]
prediction: ['[CLS] beautiful film beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.266 (perp=10.589, rec=0.157, cos=-0.008), tot_loss_proj:2.496 [t=0.27s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 150/2000] tot_loss=2.222 (perp=10.589, rec=0.113, cos=-0.009), tot_loss_proj:2.498 [t=0.25s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 200/2000] tot_loss=2.175 (perp=10.501, rec=0.084, cos=-0.009), tot_loss_proj:2.497 [t=0.27s]
prediction: ['[CLS] beautiful film strange and [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.404 (perp=6.646, rec=0.084, cos=-0.009), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.387 (perp=6.646, rec=0.067, cos=-0.009), tot_loss_proj:1.428 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.379 (perp=6.646, rec=0.059, cos=-0.009), tot_loss_proj:1.413 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.386 (perp=6.646, rec=0.066, cos=-0.009), tot_loss_proj:1.414 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.373 (perp=6.646, rec=0.053, cos=-0.009), tot_loss_proj:1.422 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.378 (perp=6.646, rec=0.058, cos=-0.009), tot_loss_proj:1.421 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.383 (perp=6.646, rec=0.063, cos=-0.009), tot_loss_proj:1.427 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.385 (perp=6.646, rec=0.065, cos=-0.009), tot_loss_proj:1.423 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.378 (perp=6.646, rec=0.058, cos=-0.009), tot_loss_proj:1.421 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.382 (perp=6.646, rec=0.061, cos=-0.009), tot_loss_proj:1.411 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.373 (perp=6.646, rec=0.052, cos=-0.009), tot_loss_proj:1.427 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.386 (perp=6.646, rec=0.065, cos=-0.009), tot_loss_proj:1.419 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.384 (perp=6.646, rec=0.063, cos=-0.009), tot_loss_proj:1.428 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.377 (perp=6.646, rec=0.057, cos=-0.009), tot_loss_proj:1.422 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.383 (perp=6.646, rec=0.063, cos=-0.009), tot_loss_proj:1.418 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.383 (perp=6.646, rec=0.062, cos=-0.009), tot_loss_proj:1.423 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.378 (perp=6.646, rec=0.058, cos=-0.009), tot_loss_proj:1.429 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.395 (perp=6.646, rec=0.075, cos=-0.009), tot_loss_proj:1.419 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.371 (perp=6.646, rec=0.051, cos=-0.009), tot_loss_proj:1.415 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.380 (perp=6.646, rec=0.059, cos=-0.009), tot_loss_proj:1.426 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.388 (perp=6.646, rec=0.067, cos=-0.009), tot_loss_proj:1.421 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.375 (perp=6.646, rec=0.055, cos=-0.009), tot_loss_proj:1.434 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.385 (perp=6.646, rec=0.065, cos=-0.009), tot_loss_proj:1.423 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.389 (perp=6.646, rec=0.069, cos=-0.009), tot_loss_proj:1.423 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.387 (perp=6.646, rec=0.067, cos=-0.009), tot_loss_proj:1.424 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.374 (perp=6.646, rec=0.054, cos=-0.009), tot_loss_proj:1.419 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.380 (perp=6.646, rec=0.059, cos=-0.009), tot_loss_proj:1.417 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.369 (perp=6.646, rec=0.049, cos=-0.009), tot_loss_proj:1.420 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.384 (perp=6.646, rec=0.064, cos=-0.009), tot_loss_proj:1.426 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.379 (perp=6.646, rec=0.059, cos=-0.009), tot_loss_proj:1.429 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.380 (perp=6.646, rec=0.060, cos=-0.009), tot_loss_proj:1.417 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.382 (perp=6.646, rec=0.062, cos=-0.009), tot_loss_proj:1.419 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.390 (perp=6.646, rec=0.070, cos=-0.009), tot_loss_proj:1.421 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.392 (perp=6.646, rec=0.072, cos=-0.009), tot_loss_proj:1.426 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.382 (perp=6.646, rec=0.062, cos=-0.009), tot_loss_proj:1.425 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.386 (perp=6.646, rec=0.066, cos=-0.009), tot_loss_proj:1.420 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.667 | p: 87.818 | r: 89.566
rouge2     | fm: 55.724 | p: 55.311 | r: 56.141
rougeL     | fm: 78.160 | p: 77.495 | r: 78.975
rougeLsum  | fm: 77.403 | p: 76.709 | r: 78.338
r1fm+r2fm = 144.391

input #25 time: 0:10:57 | total time: 3:49:41


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
*********************************
*********************************
average of cosine similarity 0.9992061826546765
highest_index [0]
highest [0.9992061826546765]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9740388989448547 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9654331803321838 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.959073543548584 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9550803303718567 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9425822496414185 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9396986365318298 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9339746832847595 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain dependingâº isolation [SEP]']
[Init] best rec loss: 0.8896158337593079 for ['[CLS] also space add ao intent bat intent× should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8848931789398193 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy family× add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8846459984779358 for ['[CLS] boat huge supposed hair teaches ao rectangular deputy should bat family also add× whomness space timeline charity intent failed intent list [SEP]']
[Init] best perm rec loss: 0.8816198706626892 for ['[CLS] add also failed timeline whom list bat space hairness teaches ao family× boat charity intent huge deputy intent supposed should rectangular [SEP]']
[Init] best perm rec loss: 0.8793452978134155 for ['[CLS] also family list supposed teaches ao bat hair space failed intentness whom huge intent add boat should rectangular deputy charity× timeline [SEP]']
[Init] best perm rec loss: 0.878869354724884 for ['[CLS] space hair× intent also timeline supposed boatness teaches should family huge whom ao list rectangular charity add failed intent bat deputy [SEP]']
[Init] best perm rec loss: 0.8787726163864136 for ['[CLS] bat rectangular intent should space timeline family also× failed teaches charity add boatness ao deputy supposed huge intent whom list hair [SEP]']
[Init] best perm rec loss: 0.8780877590179443 for ['[CLS] huge list add space× bat also family hair failed teaches boat should deputy intent supposed intent aoness charity whom timeline rectangular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.903 (perp=13.011, rec=0.308, cos=-0.007), tot_loss_proj:3.273 [t=0.25s]
prediction: ['[CLS] pointless pounds Â¨bre insult wrong import june doubt fraudulent evil maybe fake flat court issued criminal wayed waste federal translit null [SEP]']
[ 100/2000] tot_loss=2.728 (perp=12.437, rec=0.249, cos=-0.008), tot_loss_proj:3.117 [t=0.28s]
prediction: ['[CLS] pointless chemicals )bre insultte import ) questionable broken french dry fake - princess issued currency heading writer claim import - [SEP]']
[ 150/2000] tot_loss=2.439 (perp=11.186, rec=0.211, cos=-0.009), tot_loss_proj:2.806 [t=0.27s]
prediction: ['[CLS] pointless french ) age messages of import ) poor broken french dry fake of princess issued currency under from writer prix import - [SEP]']
[ 200/2000] tot_loss=2.342 (perp=10.930, rec=0.166, cos=-0.009), tot_loss_proj:2.925 [t=0.26s]
prediction: ['[CLS] pointless french ) age like of import )en broken french dry bro - woman used currency height from writer writer coming - [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.319 (perp=10.902, rec=0.148, cos=-0.009), tot_loss_proj:2.891 [t=0.26s]
prediction: ['[CLS] pointless french ) age like of import broen - french dry ) age anne used agency height from writer writer coming - [SEP]']
[ 300/2000] tot_loss=2.222 (perp=10.502, rec=0.131, cos=-0.009), tot_loss_proj:3.060 [t=0.27s]
prediction: ['[CLS] pointless french ) ageder of import broen - french mean this age anne - age height from writer sophie coming - [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.199 (perp=10.344, rec=0.140, cos=-0.009), tot_loss_proj:2.947 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie mean of import yearen - french mean age anne and age sophie from writer director this coming - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.972 (perp=9.293, rec=0.123, cos=-0.009), tot_loss_proj:2.717 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie - of import ageing mean french mean age anne and age sophie from writer director this coming - [SEP]']
[ 450/2000] tot_loss=1.957 (perp=9.293, rec=0.108, cos=-0.010), tot_loss_proj:2.713 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie - of import ageing mean french mean age anne and age sophie from writer director this coming - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.977 (perp=9.400, rec=0.107, cos=-0.010), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie - of import -ing mean french mean writer anne and age sophie from age director this coming - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.824 (perp=8.701, rec=0.093, cos=-0.009), tot_loss_proj:2.533 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie - of - importing mean french mean writer anne and age sophie from age director this coming - [SEP]']
[ 600/2000] tot_loss=2.040 (perp=9.789, rec=0.092, cos=-0.010), tot_loss_proj:2.624 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie - of - importing mean french mean writer anne and agerot fromder director this coming - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.000 (perp=9.608, rec=0.088, cos=-0.010), tot_loss_proj:2.558 [t=0.26s]
prediction: ['[CLS] pointless french ) sophie - of - importing mean french mean writer anne and agerot from directorder this coming - [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.935 (perp=9.236, rec=0.098, cos=-0.009), tot_loss_proj:2.557 [t=0.25s]
prediction: ['[CLS] pointless french ) sophie - of - importing mean french mean writer anne from agerot and directorder this coming - [SEP]']
[ 750/2000] tot_loss=2.002 (perp=9.601, rec=0.091, cos=-0.010), tot_loss_proj:2.643 [t=0.25s]
prediction: ['[CLS] pointless french ) anne - of - importing mean french mean writer anne from agerot and directorder this coming - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.897 (perp=9.109, rec=0.085, cos=-0.010), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] pointless french ) - - of - importing mean french mean writer anne from agerot and directorder this coming anne [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.870 (perp=9.005, rec=0.078, cos=-0.010), tot_loss_proj:2.417 [t=0.29s]
prediction: ['[CLS] pointless french ) - - ofder importing mean french mean writer anne from agerot and director - this coming anne [SEP]']
[ 900/2000] tot_loss=1.868 (perp=9.005, rec=0.076, cos=-0.010), tot_loss_proj:2.416 [t=0.29s]
prediction: ['[CLS] pointless french ) - - ofder importing mean french mean writer anne from agerot and director - this coming anne [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.811 (perp=8.730, rec=0.074, cos=-0.010), tot_loss_proj:2.499 [t=0.28s]
prediction: ['[CLS] pointless french ) - - of mean importing mean frenchder writer anne from agerot and director - this coming anne [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.789 (perp=8.563, rec=0.086, cos=-0.010), tot_loss_proj:2.503 [t=0.29s]
prediction: ['[CLS] pointless french ) - - of french importing mean -der writer anne from agerot and director - this coming anne [SEP]']
[1050/2000] tot_loss=1.784 (perp=8.563, rec=0.081, cos=-0.010), tot_loss_proj:2.507 [t=0.28s]
prediction: ['[CLS] pointless french ) - - of french importing mean -der writer anne from agerot and director - this coming anne [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.752 (perp=8.385, rec=0.084, cos=-0.010), tot_loss_proj:2.419 [t=0.28s]
prediction: ['[CLS] pointless french ) - - of french importing mean -der writer anne from agerot and director - anne coming this [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.720 (perp=8.206, rec=0.088, cos=-0.010), tot_loss_proj:2.653 [t=0.29s]
prediction: ['[CLS] pointless mean ) - - of french importing french -der writer anne from agerot and director - anne coming this [SEP]']
[1200/2000] tot_loss=1.703 (perp=8.206, rec=0.071, cos=-0.010), tot_loss_proj:2.657 [t=0.28s]
prediction: ['[CLS] pointless mean ) - - of french importing french -der writer anne from agerot and director - anne coming this [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.693 (perp=8.109, rec=0.081, cos=-0.010), tot_loss_proj:2.421 [t=0.28s]
prediction: ['[CLS] pointless mean ) -der of french importing french - - writer anne from agerot and director - anne coming this [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.669 (perp=8.027, rec=0.073, cos=-0.010), tot_loss_proj:2.557 [t=0.29s]
prediction: ['[CLS] pointless mean ) -der of french importing - - french writer anne from agerot and director - anne coming this [SEP]']
[1350/2000] tot_loss=1.671 (perp=8.027, rec=0.076, cos=-0.010), tot_loss_proj:2.550 [t=0.28s]
prediction: ['[CLS] pointless mean ) -der of french importing - - french writer anne from agerot and director - anne coming this [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.600 (perp=7.670, rec=0.076, cos=-0.010), tot_loss_proj:2.271 [t=0.28s]
prediction: ['[CLS] pointless ) - meander of french importing - - french writer anne from agerot and director - anne coming this [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.579 (perp=7.560, rec=0.076, cos=-0.010), tot_loss_proj:2.547 [t=0.29s]
prediction: ['[CLS] pointless ) anne meander of french importing - - french writer - from agerot and director - anne coming this [SEP]']
[1500/2000] tot_loss=1.578 (perp=7.560, rec=0.076, cos=-0.010), tot_loss_proj:2.541 [t=0.28s]
prediction: ['[CLS] pointless ) anne meander of french importing - - french writer - from agerot and director - anne coming this [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.552 (perp=7.398, rec=0.082, cos=-0.010), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Attempt swap
[1600/2000] tot_loss=1.559 (perp=7.398, rec=0.089, cos=-0.010), tot_loss_proj:2.574 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
[1650/2000] tot_loss=1.553 (perp=7.398, rec=0.083, cos=-0.010), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Attempt swap
[1700/2000] tot_loss=1.550 (perp=7.398, rec=0.080, cos=-0.010), tot_loss_proj:2.579 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Attempt swap
[1750/2000] tot_loss=1.547 (perp=7.398, rec=0.078, cos=-0.010), tot_loss_proj:2.583 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
[1800/2000] tot_loss=1.542 (perp=7.398, rec=0.073, cos=-0.010), tot_loss_proj:2.575 [t=0.27s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Attempt swap
[1850/2000] tot_loss=1.549 (perp=7.398, rec=0.079, cos=-0.010), tot_loss_proj:2.584 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Attempt swap
[1900/2000] tot_loss=1.541 (perp=7.398, rec=0.071, cos=-0.010), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
[1950/2000] tot_loss=1.538 (perp=7.398, rec=0.068, cos=-0.010), tot_loss_proj:2.577 [t=0.25s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Attempt swap
[2000/2000] tot_loss=1.540 (perp=7.398, rec=0.071, cos=-0.010), tot_loss_proj:2.578 [t=0.27s]
prediction: ['[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] pointless ) anne meander of french importing - - frenchrot - from age writer and director - anne coming this [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 6.250 | p: 6.250 | r: 6.250
rougeL     | fm: 47.059 | p: 47.059 | r: 47.059
rougeLsum  | fm: 47.059 | p: 47.059 | r: 47.059
r1fm+r2fm = 82.721

[Aggregate metrics]:
rouge1     | fm: 88.180 | p: 87.366 | r: 89.020
rouge2     | fm: 54.106 | p: 53.758 | r: 54.552
rougeL     | fm: 76.895 | p: 76.263 | r: 77.683
rougeLsum  | fm: 76.516 | p: 75.810 | r: 77.358
r1fm+r2fm = 142.285

input #26 time: 0:11:11 | total time: 4:00:53


Running input #27 of 100.
reference: 
========================
are so generic 
========================
*********************************
*********************************
average of cosine similarity 0.9993452360030666
highest_index [0]
highest [0.9993452360030666]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9331122636795044 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9077965617179871 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.8589619994163513 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8030321598052979 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8014320135116577 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.557 (perp=13.685, rec=0.812, cos=0.008), tot_loss_proj:4.549 [t=0.26s]
prediction: ['[CLS] katrina provided shakes [SEP]']
[ 100/2000] tot_loss=3.416 (perp=13.123, rec=0.761, cos=0.030), tot_loss_proj:4.500 [t=0.26s]
prediction: ['[CLS]cablerri lawn [SEP]']
[ 150/2000] tot_loss=2.729 (perp=10.328, rec=0.660, cos=0.004), tot_loss_proj:2.604 [t=0.26s]
prediction: ['[CLS] yer " generic [SEP]']
[ 200/2000] tot_loss=2.449 (perp=9.153, rec=0.620, cos=-0.001), tot_loss_proj:2.327 [t=0.25s]
prediction: ['[CLS] generic " generic [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.738 (perp=10.501, rec=0.642, cos=-0.005), tot_loss_proj:2.591 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
[ 300/2000] tot_loss=2.684 (perp=10.501, rec=0.591, cos=-0.008), tot_loss_proj:2.594 [t=0.26s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.691 (perp=10.501, rec=0.579, cos=0.012), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.827 (perp=11.001, rec=0.628, cos=-0.001), tot_loss_proj:2.760 [t=0.25s]
prediction: ['[CLS] are generic kenton [SEP]']
[ 450/2000] tot_loss=2.497 (perp=9.509, rec=0.596, cos=-0.001), tot_loss_proj:2.324 [t=0.24s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.478 (perp=9.509, rec=0.579, cos=-0.003), tot_loss_proj:2.325 [t=0.25s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.483 (perp=9.509, rec=0.580, cos=0.001), tot_loss_proj:2.320 [t=0.26s]
prediction: ['[CLS] are generic generic [SEP]']
[ 600/2000] tot_loss=2.451 (perp=9.509, rec=0.552, cos=-0.002), tot_loss_proj:2.334 [t=0.26s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.447 (perp=9.509, rec=0.547, cos=-0.002), tot_loss_proj:2.328 [t=0.26s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.455 (perp=9.509, rec=0.551, cos=0.003), tot_loss_proj:2.320 [t=0.25s]
prediction: ['[CLS] are generic generic [SEP]']
[ 750/2000] tot_loss=2.431 (perp=9.509, rec=0.536, cos=-0.007), tot_loss_proj:2.315 [t=0.25s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.414 (perp=9.509, rec=0.516, cos=-0.003), tot_loss_proj:2.326 [t=0.27s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.419 (perp=9.509, rec=0.524, cos=-0.006), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] are generic generic [SEP]']
[ 900/2000] tot_loss=2.685 (perp=10.088, rec=0.605, cos=0.062), tot_loss_proj:2.380 [t=0.25s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.433 (perp=9.509, rec=0.540, cos=-0.008), tot_loss_proj:2.327 [t=0.26s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.417 (perp=9.509, rec=0.524, cos=-0.009), tot_loss_proj:2.324 [t=0.25s]
prediction: ['[CLS] are generic generic [SEP]']
[1050/2000] tot_loss=2.526 (perp=10.088, rec=0.518, cos=-0.009), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.527 (perp=10.088, rec=0.518, cos=-0.008), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.520 (perp=10.088, rec=0.512, cos=-0.009), tot_loss_proj:2.387 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
[1200/2000] tot_loss=2.517 (perp=10.088, rec=0.508, cos=-0.008), tot_loss_proj:2.387 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.535 (perp=10.088, rec=0.521, cos=-0.004), tot_loss_proj:2.383 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.511 (perp=10.088, rec=0.503, cos=-0.009), tot_loss_proj:2.378 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
[1350/2000] tot_loss=2.509 (perp=10.088, rec=0.501, cos=-0.009), tot_loss_proj:2.391 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.509 (perp=10.088, rec=0.501, cos=-0.010), tot_loss_proj:2.377 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.516 (perp=10.088, rec=0.508, cos=-0.010), tot_loss_proj:2.383 [t=0.28s]
prediction: ['[CLS] so generic generic [SEP]']
[1500/2000] tot_loss=2.513 (perp=10.088, rec=0.505, cos=-0.009), tot_loss_proj:2.384 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.503 (perp=10.088, rec=0.495, cos=-0.009), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.507 (perp=10.088, rec=0.498, cos=-0.009), tot_loss_proj:2.374 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
[1650/2000] tot_loss=2.509 (perp=10.088, rec=0.500, cos=-0.009), tot_loss_proj:2.385 [t=0.25s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.508 (perp=10.088, rec=0.500, cos=-0.010), tot_loss_proj:2.379 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.510 (perp=10.088, rec=0.502, cos=-0.010), tot_loss_proj:2.379 [t=0.28s]
prediction: ['[CLS] so generic generic [SEP]']
[1800/2000] tot_loss=2.501 (perp=10.088, rec=0.493, cos=-0.010), tot_loss_proj:2.384 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.508 (perp=10.088, rec=0.500, cos=-0.010), tot_loss_proj:2.389 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.508 (perp=10.088, rec=0.500, cos=-0.010), tot_loss_proj:2.379 [t=0.26s]
prediction: ['[CLS] so generic generic [SEP]']
[1950/2000] tot_loss=2.502 (perp=10.088, rec=0.494, cos=-0.010), tot_loss_proj:2.379 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.509 (perp=10.088, rec=0.501, cos=-0.010), tot_loss_proj:2.390 [t=0.27s]
prediction: ['[CLS] so generic generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] so generic generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 87.851 | p: 87.108 | r: 88.812
rouge2     | fm: 53.420 | p: 52.996 | r: 53.865
rougeL     | fm: 77.085 | p: 76.413 | r: 77.899
rougeLsum  | fm: 76.676 | p: 75.959 | r: 77.461
r1fm+r2fm = 141.271

input #27 time: 0:10:58 | total time: 4:11:51


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
*********************************
*********************************
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8165134787559509 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7931988835334778 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7827070355415344 for ['[CLS] james facilitieslty Â¨ [SEP]']
[Init] best rec loss: 0.7524273991584778 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best rec loss: 0.7502107620239258 for ['[CLS]vron sex guessed morgan [SEP]']
[Init] best perm rec loss: 0.7490264177322388 for ['[CLS] guessed morganvron sex [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.114 (perp=9.036, rec=0.308, cos=-0.001), tot_loss_proj:2.987 [t=0.28s]
prediction: ['[CLS] s for minutes longest [SEP]']
[ 100/2000] tot_loss=1.802 (perp=8.319, rec=0.145, cos=-0.007), tot_loss_proj:2.348 [t=0.26s]
prediction: ['[CLS] only for minutes 8 [SEP]']
[ 150/2000] tot_loss=1.905 (perp=9.045, rec=0.105, cos=-0.009), tot_loss_proj:2.489 [t=0.25s]
prediction: ['[CLS] only for minutes 71 [SEP]']
[ 200/2000] tot_loss=1.882 (perp=9.045, rec=0.082, cos=-0.009), tot_loss_proj:2.494 [t=0.26s]
prediction: ['[CLS] only for minutes 71 [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.647 (perp=7.912, rec=0.074, cos=-0.009), tot_loss_proj:1.931 [t=0.27s]
prediction: ['[CLS] only for 71 minutes [SEP]']
[ 300/2000] tot_loss=1.644 (perp=7.912, rec=0.071, cos=-0.010), tot_loss_proj:1.936 [t=0.26s]
prediction: ['[CLS] only for 71 minutes [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.597 (perp=7.699, rec=0.066, cos=-0.010), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.601 (perp=7.699, rec=0.071, cos=-0.010), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.591 (perp=7.699, rec=0.061, cos=-0.010), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.598 (perp=7.699, rec=0.068, cos=-0.010), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.699, rec=0.059, cos=-0.010), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.592 (perp=7.699, rec=0.062, cos=-0.010), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.603 (perp=7.699, rec=0.073, cos=-0.010), tot_loss_proj:1.628 [t=0.28s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.592 (perp=7.699, rec=0.062, cos=-0.010), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.588 (perp=7.699, rec=0.058, cos=-0.010), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.592 (perp=7.699, rec=0.062, cos=-0.010), tot_loss_proj:1.604 [t=0.29s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.600 (perp=7.699, rec=0.069, cos=-0.010), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.601 (perp=7.699, rec=0.071, cos=-0.010), tot_loss_proj:1.607 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.699, rec=0.065, cos=-0.010), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.699, rec=0.058, cos=-0.010), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.699, rec=0.068, cos=-0.010), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.591 (perp=7.699, rec=0.061, cos=-0.010), tot_loss_proj:1.616 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.599 (perp=7.699, rec=0.069, cos=-0.010), tot_loss_proj:1.614 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.699, rec=0.062, cos=-0.010), tot_loss_proj:1.611 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.593 (perp=7.699, rec=0.063, cos=-0.010), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.590 (perp=7.699, rec=0.060, cos=-0.010), tot_loss_proj:1.626 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.699, rec=0.056, cos=-0.010), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.589 (perp=7.699, rec=0.059, cos=-0.010), tot_loss_proj:1.620 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.584 (perp=7.699, rec=0.054, cos=-0.010), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.587 (perp=7.699, rec=0.057, cos=-0.010), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.592 (perp=7.699, rec=0.062, cos=-0.010), tot_loss_proj:1.603 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.699, rec=0.063, cos=-0.010), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.699, rec=0.058, cos=-0.010), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.578 (perp=7.699, rec=0.048, cos=-0.010), tot_loss_proj:1.600 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.585 (perp=7.699, rec=0.055, cos=-0.010), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.599 (perp=7.699, rec=0.069, cos=-0.010), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.593 (perp=7.699, rec=0.063, cos=-0.010), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.601 (perp=7.699, rec=0.071, cos=-0.010), tot_loss_proj:1.602 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.596 (perp=7.699, rec=0.065, cos=-0.010), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.699, rec=0.057, cos=-0.010), tot_loss_proj:1.609 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.305 | p: 87.519 | r: 89.195
rouge2     | fm: 55.151 | p: 54.809 | r: 55.598
rougeL     | fm: 77.748 | p: 77.107 | r: 78.540
rougeLsum  | fm: 77.471 | p: 76.795 | r: 78.264
r1fm+r2fm = 143.456

input #28 time: 0:11:02 | total time: 4:22:53


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
*********************************
*********************************
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9436143040657043 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9236282706260681 for ['[CLS] fine bedside please blanco fight colonel so â– stick manitoba [SEP]']
[Init] best rec loss: 0.9098904132843018 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8565943837165833 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8468968868255615 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8464521765708923 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.844285249710083 for ['[CLS] downke his heir wantedÃ¸ degree opposition march head [SEP]']
[Init] best rec loss: 0.8212891221046448 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8188213109970093 for ['[CLS] type attack www estate ambulance + chelsealand out todd [SEP]']
[Init] best rec loss: 0.8150292038917542 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 0.8131462931632996 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 0.8110625147819519 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 0.8109373450279236 for ['[CLS] runs administration tv oil this taste landed engagement envelopeuted [SEP]']
[Init] best perm rec loss: 0.8048712015151978 for ['[CLS] taste landed tv this engagementuted runs oil administration envelope [SEP]']
[Init] best perm rec loss: 0.8036940097808838 for ['[CLS] runs taste engagementuted envelope oil this tv landed administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.532 (perp=10.682, rec=0.401, cos=-0.006), tot_loss_proj:3.420 [t=0.25s]
prediction: ['[CLS] what. settlement scientology released facts indefinitely under caused limits [SEP]']
[ 100/2000] tot_loss=2.796 (perp=12.342, rec=0.334, cos=-0.007), tot_loss_proj:3.614 [t=0.26s]
prediction: ['[CLS].... toni scientology poisoning dali for under settlement authorities [SEP]']
[ 150/2000] tot_loss=2.254 (perp=9.919, rec=0.276, cos=-0.006), tot_loss_proj:2.995 [t=0.25s]
prediction: ['[CLS].... resign costume is believe it under generally not [SEP]']
[ 200/2000] tot_loss=2.378 (perp=10.709, rec=0.241, cos=-0.004), tot_loss_proj:3.203 [t=0.26s]
prediction: ['[CLS]....bri resident is evil it the owns not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.639 (perp=7.330, rec=0.180, cos=-0.007), tot_loss_proj:2.528 [t=0.25s]
prediction: ['[CLS]... also believe resident evil is it that is not [SEP]']
[ 300/2000] tot_loss=1.620 (perp=7.330, rec=0.160, cos=-0.006), tot_loss_proj:2.525 [t=0.26s]
prediction: ['[CLS]... also believe resident evil is it that is not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.488 (perp=6.833, rec=0.131, cos=-0.009), tot_loss_proj:2.464 [t=0.25s]
prediction: ['[CLS]... also believe resident evil is that it is not [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.138 (perp=5.127, rec=0.122, cos=-0.009), tot_loss_proj:2.249 [t=0.25s]
prediction: ['[CLS] i also believe resident evil is that it is not [SEP]']
[ 450/2000] tot_loss=1.129 (perp=5.127, rec=0.113, cos=-0.009), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] i also believe resident evil is that it is not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.398 (perp=6.550, rec=0.098, cos=-0.009), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] i also believe resident evil is that it because not [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.315 (perp=6.130, rec=0.098, cos=-0.009), tot_loss_proj:2.609 [t=0.35s]
prediction: ['[CLS] i also believe resident evil is that it not because [SEP]']
[ 600/2000] tot_loss=1.321 (perp=6.130, rec=0.105, cos=-0.009), tot_loss_proj:2.611 [t=0.26s]
prediction: ['[CLS] i also believe resident evil is that it not because [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.422 (perp=6.712, rec=0.089, cos=-0.009), tot_loss_proj:2.499 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is it not amounts [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.162 (perp=5.363, rec=0.099, cos=-0.009), tot_loss_proj:2.274 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is it not because [SEP]']
[ 750/2000] tot_loss=1.157 (perp=5.363, rec=0.094, cos=-0.009), tot_loss_proj:2.272 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is it not because [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.122 (perp=5.253, rec=0.081, cos=-0.010), tot_loss_proj:1.364 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.125 (perp=5.253, rec=0.084, cos=-0.010), tot_loss_proj:1.362 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
[ 900/2000] tot_loss=1.128 (perp=5.253, rec=0.086, cos=-0.010), tot_loss_proj:1.364 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.125 (perp=5.253, rec=0.084, cos=-0.009), tot_loss_proj:1.362 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
Attempt swap
[1000/2000] tot_loss=0.982 (perp=4.570, rec=0.077, cos=-0.009), tot_loss_proj:1.052 [t=0.28s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1050/2000] tot_loss=0.974 (perp=4.570, rec=0.069, cos=-0.009), tot_loss_proj:1.058 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.972 (perp=4.570, rec=0.068, cos=-0.009), tot_loss_proj:1.049 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.987 (perp=4.570, rec=0.082, cos=-0.010), tot_loss_proj:1.048 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1200/2000] tot_loss=0.975 (perp=4.570, rec=0.070, cos=-0.010), tot_loss_proj:1.048 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.978 (perp=4.570, rec=0.073, cos=-0.010), tot_loss_proj:1.043 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.976 (perp=4.570, rec=0.071, cos=-0.010), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1350/2000] tot_loss=0.976 (perp=4.570, rec=0.072, cos=-0.010), tot_loss_proj:1.046 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.980 (perp=4.570, rec=0.076, cos=-0.010), tot_loss_proj:1.047 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.973 (perp=4.570, rec=0.068, cos=-0.010), tot_loss_proj:1.054 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1500/2000] tot_loss=0.977 (perp=4.570, rec=0.073, cos=-0.010), tot_loss_proj:1.055 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.976 (perp=4.570, rec=0.072, cos=-0.010), tot_loss_proj:1.040 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.969 (perp=4.570, rec=0.064, cos=-0.010), tot_loss_proj:1.042 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1650/2000] tot_loss=0.981 (perp=4.570, rec=0.076, cos=-0.010), tot_loss_proj:1.045 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.981 (perp=4.570, rec=0.077, cos=-0.010), tot_loss_proj:1.041 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.979 (perp=4.570, rec=0.075, cos=-0.010), tot_loss_proj:1.046 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1800/2000] tot_loss=0.979 (perp=4.570, rec=0.075, cos=-0.010), tot_loss_proj:1.048 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.970 (perp=4.570, rec=0.065, cos=-0.010), tot_loss_proj:1.049 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.981 (perp=4.570, rec=0.077, cos=-0.010), tot_loss_proj:1.038 [t=0.28s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1950/2000] tot_loss=0.986 (perp=4.570, rec=0.081, cos=-0.010), tot_loss_proj:1.049 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.984 (perp=4.570, rec=0.080, cos=-0.010), tot_loss_proj:1.046 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.648 | p: 87.953 | r: 89.539
rouge2     | fm: 56.685 | p: 56.347 | r: 57.099
rougeL     | fm: 78.592 | p: 77.974 | r: 79.299
rougeLsum  | fm: 78.232 | p: 77.634 | r: 78.917
r1fm+r2fm = 145.333

input #29 time: 0:11:02 | total time: 4:33:55


Running input #30 of 100.
reference: 
========================
fizzability 
========================
*********************************
*********************************
average of cosine similarity 0.9992720994590749
highest_index [0]
highest [0.9992720994590749]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9139088988304138 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8701140880584717 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8681485652923584 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 0.8041428923606873 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7869581580162048 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7338038682937622 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7189111113548279 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.7150062918663025 for ['[CLS] lizard acceleration council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.509 (perp=10.941, rec=0.325, cos=-0.004), tot_loss_proj:3.965 [t=0.27s]
prediction: ['[CLS] estate chassis list [SEP]']
[ 100/2000] tot_loss=2.732 (perp=12.475, rec=0.241, cos=-0.004), tot_loss_proj:3.536 [t=0.27s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 150/2000] tot_loss=2.649 (perp=12.475, rec=0.161, cos=-0.007), tot_loss_proj:3.544 [t=0.28s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 200/2000] tot_loss=2.616 (perp=12.475, rec=0.129, cos=-0.008), tot_loss_proj:3.563 [t=0.27s]
prediction: ['[CLS]zzabilitybility [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.012 (perp=9.540, rec=0.112, cos=-0.008), tot_loss_proj:1.967 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.970 (perp=9.540, rec=0.071, cos=-0.009), tot_loss_proj:1.968 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.970 (perp=9.540, rec=0.071, cos=-0.009), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.966 (perp=9.540, rec=0.068, cos=-0.009), tot_loss_proj:1.959 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.962 (perp=9.540, rec=0.063, cos=-0.009), tot_loss_proj:1.959 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.965 (perp=9.540, rec=0.067, cos=-0.009), tot_loss_proj:1.975 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.971 (perp=9.540, rec=0.072, cos=-0.009), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.962 (perp=9.540, rec=0.063, cos=-0.009), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.958 (perp=9.540, rec=0.060, cos=-0.009), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.975 (perp=9.540, rec=0.076, cos=-0.009), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.961 (perp=9.540, rec=0.062, cos=-0.009), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.967 (perp=9.540, rec=0.068, cos=-0.009), tot_loss_proj:1.975 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=9.540, rec=0.070, cos=-0.009), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.960 (perp=9.540, rec=0.061, cos=-0.009), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.955 (perp=9.540, rec=0.057, cos=-0.009), tot_loss_proj:1.974 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.964 (perp=9.540, rec=0.065, cos=-0.009), tot_loss_proj:1.966 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.968 (perp=9.540, rec=0.069, cos=-0.009), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.958 (perp=9.540, rec=0.060, cos=-0.009), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.971 (perp=9.540, rec=0.073, cos=-0.009), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.957 (perp=9.540, rec=0.058, cos=-0.009), tot_loss_proj:1.981 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.960 (perp=9.540, rec=0.062, cos=-0.009), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.977 (perp=9.540, rec=0.079, cos=-0.009), tot_loss_proj:1.963 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.941 (perp=9.540, rec=0.043, cos=-0.009), tot_loss_proj:1.963 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.969 (perp=9.540, rec=0.071, cos=-0.009), tot_loss_proj:1.965 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.948 (perp=9.540, rec=0.050, cos=-0.009), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.966 (perp=9.540, rec=0.067, cos=-0.009), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.952 (perp=9.540, rec=0.054, cos=-0.009), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.948 (perp=9.540, rec=0.050, cos=-0.009), tot_loss_proj:1.964 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.959 (perp=9.540, rec=0.061, cos=-0.009), tot_loss_proj:1.964 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.964 (perp=9.540, rec=0.066, cos=-0.009), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.951 (perp=9.540, rec=0.053, cos=-0.009), tot_loss_proj:1.972 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.951 (perp=9.540, rec=0.053, cos=-0.009), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.953 (perp=9.540, rec=0.055, cos=-0.009), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.957 (perp=9.540, rec=0.059, cos=-0.009), tot_loss_proj:1.986 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.951 (perp=9.540, rec=0.052, cos=-0.009), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.955 (perp=9.540, rec=0.057, cos=-0.009), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.006 | p: 88.300 | r: 89.892
rouge2     | fm: 58.073 | p: 57.629 | r: 58.446
rougeL     | fm: 79.254 | p: 78.591 | r: 79.951
rougeLsum  | fm: 78.817 | p: 78.236 | r: 79.545
r1fm+r2fm = 147.078

input #30 time: 0:11:02 | total time: 4:44:58


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
*********************************
*********************************
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9432398676872253 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.920174777507782 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8837398290634155 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8651828765869141 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8041785955429077 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8038828372955322 for ['[CLS] robin running artwork [SEP]']
[Init] best perm rec loss: 0.8038730621337891 for ['[CLS] artwork running robin [SEP]']
[Init] best perm rec loss: 0.7982505559921265 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.413 (perp=10.371, rec=0.336, cos=0.002), tot_loss_proj:3.199 [t=0.24s]
prediction: ['[CLS] better creditneuve [SEP]']
[ 100/2000] tot_loss=2.122 (perp=9.658, rec=0.196, cos=-0.005), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=1.844 (perp=8.742, rec=0.104, cos=-0.008), tot_loss_proj:3.275 [t=0.26s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 200/2000] tot_loss=1.805 (perp=8.742, rec=0.066, cos=-0.009), tot_loss_proj:3.282 [t=0.26s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.591 (perp=7.603, rec=0.078, cos=-0.008), tot_loss_proj:1.681 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.570 (perp=7.603, rec=0.059, cos=-0.009), tot_loss_proj:1.672 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.578 (perp=7.603, rec=0.066, cos=-0.009), tot_loss_proj:1.674 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.577 (perp=7.603, rec=0.066, cos=-0.009), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.575 (perp=7.603, rec=0.063, cos=-0.009), tot_loss_proj:1.684 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.567 (perp=7.603, rec=0.056, cos=-0.009), tot_loss_proj:1.676 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.576 (perp=7.603, rec=0.065, cos=-0.009), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.603, rec=0.054, cos=-0.009), tot_loss_proj:1.669 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.568 (perp=7.603, rec=0.056, cos=-0.009), tot_loss_proj:1.663 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.574 (perp=7.603, rec=0.063, cos=-0.009), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.576 (perp=7.603, rec=0.064, cos=-0.009), tot_loss_proj:1.670 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.575 (perp=7.603, rec=0.064, cos=-0.009), tot_loss_proj:1.674 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.569 (perp=7.603, rec=0.057, cos=-0.009), tot_loss_proj:1.669 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.569 (perp=7.603, rec=0.058, cos=-0.009), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.565 (perp=7.603, rec=0.054, cos=-0.009), tot_loss_proj:1.675 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.569 (perp=7.603, rec=0.058, cos=-0.009), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.574 (perp=7.603, rec=0.063, cos=-0.009), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.577 (perp=7.603, rec=0.065, cos=-0.009), tot_loss_proj:1.667 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.574 (perp=7.603, rec=0.063, cos=-0.009), tot_loss_proj:1.665 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.572 (perp=7.603, rec=0.061, cos=-0.009), tot_loss_proj:1.668 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.576 (perp=7.603, rec=0.064, cos=-0.009), tot_loss_proj:1.668 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.579 (perp=7.603, rec=0.068, cos=-0.009), tot_loss_proj:1.671 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.577 (perp=7.603, rec=0.065, cos=-0.009), tot_loss_proj:1.675 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.573 (perp=7.603, rec=0.062, cos=-0.009), tot_loss_proj:1.677 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.576 (perp=7.603, rec=0.065, cos=-0.009), tot_loss_proj:1.669 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.574 (perp=7.603, rec=0.062, cos=-0.009), tot_loss_proj:1.675 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.574 (perp=7.603, rec=0.063, cos=-0.009), tot_loss_proj:1.675 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.603, rec=0.062, cos=-0.009), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.570 (perp=7.603, rec=0.059, cos=-0.009), tot_loss_proj:1.667 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.571 (perp=7.603, rec=0.059, cos=-0.009), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.564 (perp=7.603, rec=0.053, cos=-0.009), tot_loss_proj:1.660 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.583 (perp=7.603, rec=0.071, cos=-0.009), tot_loss_proj:1.657 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.580 (perp=7.603, rec=0.069, cos=-0.009), tot_loss_proj:1.669 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.566 (perp=7.603, rec=0.055, cos=-0.009), tot_loss_proj:1.671 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.567 (perp=7.603, rec=0.056, cos=-0.009), tot_loss_proj:1.668 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.571 (perp=7.603, rec=0.060, cos=-0.009), tot_loss_proj:1.671 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.454 | p: 88.766 | r: 90.218
rouge2     | fm: 59.417 | p: 58.897 | r: 59.825
rougeL     | fm: 79.942 | p: 79.344 | r: 80.633
rougeLsum  | fm: 79.604 | p: 79.036 | r: 80.269
r1fm+r2fm = 148.871

input #31 time: 0:10:57 | total time: 4:55:56


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
*********************************
*********************************
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0409706830978394 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9490888714790344 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8853940367698669 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8810258507728577 for ['[CLS]le force cheers discarded replicateØ¨Ø§Ø¯ clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8623101115226746 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8531050086021423 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8450931906700134 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8438608646392822 for ['[CLS] athletic palace th thomasshire bio cake circle lilith fundscting natalie [SEP]']
[Init] best perm rec loss: 0.842842161655426 for ['[CLS] cake funds lilith athletic thshire biocting natalie palace circle thomas [SEP]']
[Init] best perm rec loss: 0.8413686156272888 for ['[CLS] th natalie circlecting thomas funds bio lilith palace cakeshire athletic [SEP]']
[Init] best perm rec loss: 0.8397578001022339 for ['[CLS]cting lilith thomas cake bio athleticshire natalie th circle palace funds [SEP]']
[Init] best perm rec loss: 0.8387935161590576 for ['[CLS] cakecting natalie bio lilith athletic th thomas circle palaceshire funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.833 (perp=12.790, rec=0.280, cos=-0.006), tot_loss_proj:3.168 [t=0.25s]
prediction: ['[CLS] valuedvable story stories spirit ; diverse ellen create sunlight deeply funds [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.892, rec=0.204, cos=-0.007), tot_loss_proj:2.985 [t=0.26s]
prediction: ['[CLS] easily accessible stories stories together ; easily frank pullonate easilyonate [SEP]']
[ 150/2000] tot_loss=2.346 (perp=10.952, rec=0.163, cos=-0.008), tot_loss_proj:3.892 [t=0.26s]
prediction: ['[CLS] easily accessible stories stories together into easily potentially pullonateundity [SEP]']
[ 200/2000] tot_loss=2.196 (perp=10.287, rec=0.144, cos=-0.006), tot_loss_proj:3.522 [t=0.25s]
prediction: ['[CLS] easily accessible stories stories together with accessible slightly pullonateundity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.034 (perp=9.633, rec=0.117, cos=-0.009), tot_loss_proj:3.080 [t=0.25s]
prediction: ['[CLS] easily accessible stories stories together that pull slightly resonateundity [SEP]']
[ 300/2000] tot_loss=2.124 (perp=10.190, rec=0.095, cos=-0.009), tot_loss_proj:2.603 [t=0.25s]
prediction: ['[CLS] easily accessible stories stories together that pull prof resonateundity [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.899 (perp=9.013, rec=0.106, cos=-0.009), tot_loss_proj:2.444 [t=0.26s]
prediction: ['[CLS] easily accessible stories stories that pull together prof resonateundity [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.677 (perp=7.856, rec=0.115, cos=-0.009), tot_loss_proj:1.929 [t=0.25s]
prediction: ['[CLS] resonate easily accessible stories stories that pull together profundity [SEP]']
[ 450/2000] tot_loss=1.648 (perp=7.856, rec=0.086, cos=-0.009), tot_loss_proj:1.948 [t=0.26s]
prediction: ['[CLS] resonate easily accessible stories stories that pull together profundity [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.558 (perp=7.393, rec=0.089, cos=-0.009), tot_loss_proj:1.838 [t=0.26s]
prediction: ['[CLS] stories resonate easily accessible stories that pull together profundity [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.511 (perp=7.159, rec=0.089, cos=-0.009), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[ 600/2000] tot_loss=1.505 (perp=7.159, rec=0.083, cos=-0.009), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.501 (perp=7.159, rec=0.079, cos=-0.009), tot_loss_proj:1.908 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.505 (perp=7.185, rec=0.077, cos=-0.009), tot_loss_proj:2.199 [t=0.26s]
prediction: ['[CLS] stories that resonate accessible stories easily pull together profundity [SEP]']
[ 750/2000] tot_loss=1.501 (perp=7.185, rec=0.073, cos=-0.009), tot_loss_proj:2.197 [t=0.26s]
prediction: ['[CLS] stories that resonate accessible stories easily pull together profundity [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.496 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.496 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[ 900/2000] tot_loss=1.484 (perp=7.159, rec=0.061, cos=-0.009), tot_loss_proj:1.898 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.494 (perp=7.159, rec=0.072, cos=-0.009), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.492 (perp=7.159, rec=0.070, cos=-0.009), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[1050/2000] tot_loss=1.499 (perp=7.159, rec=0.076, cos=-0.009), tot_loss_proj:1.907 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.492 (perp=7.159, rec=0.069, cos=-0.009), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.495 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[1200/2000] tot_loss=1.494 (perp=7.159, rec=0.072, cos=-0.009), tot_loss_proj:1.902 [t=0.27s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.497 (perp=7.159, rec=0.075, cos=-0.009), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.506 (perp=7.185, rec=0.078, cos=-0.009), tot_loss_proj:2.194 [t=0.26s]
prediction: ['[CLS] stories that resonate accessible stories easily pull together profundity [SEP]']
[1350/2000] tot_loss=1.500 (perp=7.185, rec=0.072, cos=-0.009), tot_loss_proj:2.192 [t=0.26s]
prediction: ['[CLS] stories that resonate accessible stories easily pull together profundity [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.495 (perp=7.159, rec=0.072, cos=-0.009), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.495 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.906 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[1500/2000] tot_loss=1.496 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.494 (perp=7.159, rec=0.071, cos=-0.009), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.499 (perp=7.159, rec=0.076, cos=-0.009), tot_loss_proj:1.908 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[1650/2000] tot_loss=1.484 (perp=7.159, rec=0.062, cos=-0.009), tot_loss_proj:1.899 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.492 (perp=7.159, rec=0.069, cos=-0.009), tot_loss_proj:1.901 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.499 (perp=7.159, rec=0.077, cos=-0.009), tot_loss_proj:1.901 [t=0.27s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[1800/2000] tot_loss=1.497 (perp=7.159, rec=0.074, cos=-0.009), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.488 (perp=7.159, rec=0.065, cos=-0.009), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.495 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.905 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
[1950/2000] tot_loss=1.493 (perp=7.159, rec=0.070, cos=-0.009), tot_loss_proj:1.901 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.496 (perp=7.159, rec=0.073, cos=-0.009), tot_loss_proj:1.904 [t=0.25s]
prediction: ['[CLS] stories that resonate easily accessible stories pull together profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] stories that resonate easily accessible stories pull together profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 150.909

[Aggregate metrics]:
rouge1     | fm: 89.388 | p: 88.640 | r: 90.198
rouge2     | fm: 59.256 | p: 58.982 | r: 59.720
rougeL     | fm: 78.945 | p: 78.474 | r: 79.596
rougeLsum  | fm: 78.948 | p: 78.349 | r: 79.689
r1fm+r2fm = 148.644

input #32 time: 0:10:59 | total time: 5:06:56


Running input #33 of 100.
reference: 
========================
higher 
========================
*********************************
*********************************
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9998520612716675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9732957482337952 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9511236548423767 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9041293859481812 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8212264180183411 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7986159920692444 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7904055118560791 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.533 (perp=11.231, rec=0.278, cos=0.009), tot_loss_proj:3.015 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.317 (perp=11.231, rec=0.079, cos=-0.008), tot_loss_proj:2.439 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.297 (perp=11.231, rec=0.060, cos=-0.009), tot_loss_proj:2.393 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.306 (perp=11.231, rec=0.069, cos=-0.009), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.288 (perp=11.231, rec=0.051, cos=-0.009), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.294 (perp=11.231, rec=0.056, cos=-0.009), tot_loss_proj:2.399 [t=0.31s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.295 (perp=11.231, rec=0.057, cos=-0.009), tot_loss_proj:2.382 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.307 (perp=11.231, rec=0.070, cos=-0.009), tot_loss_proj:2.386 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.301 (perp=11.231, rec=0.064, cos=-0.009), tot_loss_proj:2.392 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.307 (perp=11.231, rec=0.070, cos=-0.009), tot_loss_proj:2.393 [t=0.30s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.307 (perp=11.231, rec=0.070, cos=-0.009), tot_loss_proj:2.389 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.302 (perp=11.231, rec=0.065, cos=-0.009), tot_loss_proj:2.381 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.301 (perp=11.231, rec=0.064, cos=-0.009), tot_loss_proj:2.402 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.285 (perp=11.231, rec=0.047, cos=-0.009), tot_loss_proj:2.382 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.301 (perp=11.231, rec=0.064, cos=-0.009), tot_loss_proj:2.386 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.288 (perp=11.231, rec=0.050, cos=-0.009), tot_loss_proj:2.371 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.286 (perp=11.231, rec=0.048, cos=-0.009), tot_loss_proj:2.382 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.307 (perp=11.231, rec=0.070, cos=-0.009), tot_loss_proj:2.370 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.295 (perp=11.231, rec=0.057, cos=-0.009), tot_loss_proj:2.388 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.283 (perp=11.231, rec=0.046, cos=-0.009), tot_loss_proj:2.381 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.312 (perp=11.231, rec=0.075, cos=-0.009), tot_loss_proj:2.392 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.306 (perp=11.231, rec=0.069, cos=-0.009), tot_loss_proj:2.381 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.292 (perp=11.231, rec=0.055, cos=-0.009), tot_loss_proj:2.396 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.297 (perp=11.231, rec=0.060, cos=-0.009), tot_loss_proj:2.381 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.289 (perp=11.231, rec=0.052, cos=-0.009), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.311 (perp=11.231, rec=0.074, cos=-0.009), tot_loss_proj:2.393 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.298 (perp=11.231, rec=0.061, cos=-0.009), tot_loss_proj:2.385 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.289 (perp=11.231, rec=0.052, cos=-0.009), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.291 (perp=11.231, rec=0.054, cos=-0.009), tot_loss_proj:2.383 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.302 (perp=11.231, rec=0.065, cos=-0.009), tot_loss_proj:2.401 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.297 (perp=11.231, rec=0.060, cos=-0.009), tot_loss_proj:2.388 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.305 (perp=11.231, rec=0.067, cos=-0.009), tot_loss_proj:2.390 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.291 (perp=11.231, rec=0.054, cos=-0.009), tot_loss_proj:2.387 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.293 (perp=11.231, rec=0.055, cos=-0.009), tot_loss_proj:2.397 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.298 (perp=11.231, rec=0.061, cos=-0.009), tot_loss_proj:2.384 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.294 (perp=11.231, rec=0.056, cos=-0.009), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.310 (perp=11.231, rec=0.073, cos=-0.009), tot_loss_proj:2.387 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.295 (perp=11.231, rec=0.058, cos=-0.009), tot_loss_proj:2.388 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.293 (perp=11.231, rec=0.056, cos=-0.009), tot_loss_proj:2.392 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.302 (perp=11.231, rec=0.065, cos=-0.009), tot_loss_proj:2.384 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.680 | p: 89.035 | r: 90.421
rouge2     | fm: 61.011 | p: 60.718 | r: 61.329
rougeL     | fm: 79.678 | p: 79.137 | r: 80.368
rougeLsum  | fm: 79.401 | p: 78.879 | r: 80.083
r1fm+r2fm = 150.691

input #33 time: 0:10:58 | total time: 5:17:54


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
*********************************
*********************************
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8935192823410034 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8888072967529297 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8439813256263733 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8383127450942993 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.813098132610321 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8127062320709229 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.8103282451629639 for ['[CLS] who slightask founderibe field lissa along ship drivers statue worth okay [SEP]']
[Init] best perm rec loss: 0.8098567128181458 for ['[CLS] field slight who statueibe founder lissa shipask drivers okay along worth [SEP]']
[Init] best perm rec loss: 0.808777928352356 for ['[CLS] okayibe statueask slight founder along drivers field worth ship who lissa [SEP]']
[Init] best perm rec loss: 0.8087007999420166 for ['[CLS] okay field ship slight alongask statue lissa founder worth driversibe who [SEP]']
[Init] best perm rec loss: 0.8083059787750244 for ['[CLS] who along lissa ship statue okay slight field driversibe worth founderask [SEP]']
[Init] best perm rec loss: 0.8071286082267761 for ['[CLS] worth founder drivers okay along ship lissa field whoask statueibe slight [SEP]']
[Init] best perm rec loss: 0.8067096471786499 for ['[CLS] founder worth okayaskibe lissa who statue along drivers ship slight field [SEP]']
[Init] best perm rec loss: 0.8060021996498108 for ['[CLS] slight founder fieldaskibe okay lissa ship statue who worth along drivers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.694 (perp=11.579, rec=0.378, cos=0.001), tot_loss_proj:3.792 [t=0.25s]
prediction: ['[CLS] volume libretto transform viewers wales itpot expand hazardous, awarded the locomotives [SEP]']
[ 100/2000] tot_loss=2.568 (perp=11.544, rec=0.266, cos=-0.006), tot_loss_proj:3.930 [t=0.27s]
prediction: ['[CLS] urgency viewer transform viewer urgency of unlimited build hazardous urgencyu the urgency [SEP]']
[ 150/2000] tot_loss=2.302 (perp=10.574, rec=0.196, cos=-0.009), tot_loss_proj:3.545 [t=0.25s]
prediction: ['[CLS] urgency viewer extreme viewer urgency ofpot build extreme urgency of and urgency [SEP]']
[ 200/2000] tot_loss=2.262 (perp=10.467, rec=0.177, cos=-0.009), tot_loss_proj:3.641 [t=0.25s]
prediction: ['[CLS] urgency viewer extreme viewer urgency ofpot build extreme urgency of. extreme [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.100 (perp=9.757, rec=0.158, cos=-0.009), tot_loss_proj:3.379 [t=0.26s]
prediction: ['[CLS] urgency viewer extreme viewer urgency inpot build extreme urgency in extreme. [SEP]']
[ 300/2000] tot_loss=2.145 (perp=10.075, rec=0.139, cos=-0.009), tot_loss_proj:3.347 [t=0.26s]
prediction: ['[CLS] urgency viewer extreme viewer urgency insing build extreme urgency in extreme. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.764 (perp=8.159, rec=0.141, cos=-0.009), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] urgency by extreme viewer urgency of buildsing extreme urgency in extreme. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.760 (perp=8.162, rec=0.136, cos=-0.008), tot_loss_proj:2.816 [t=0.25s]
prediction: ['[CLS] urgency in extreme viewer urgency of buildsing extreme urgency and extreme. [SEP]']
[ 450/2000] tot_loss=1.801 (perp=8.456, rec=0.119, cos=-0.009), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] urgency in extreme viewer mind of buildsing extreme urgency and extreme. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.753 (perp=8.204, rec=0.121, cos=-0.010), tot_loss_proj:2.745 [t=0.27s]
prediction: ['[CLS] urgency in extreme viewer of mind buildsing extreme urgency and extreme. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.851 (perp=8.685, rec=0.124, cos=-0.009), tot_loss_proj:2.882 [t=0.26s]
prediction: ['[CLS] viewer in extreme urgency of mind buildsing take urgency and extreme. [SEP]']
[ 600/2000] tot_loss=1.835 (perp=8.685, rec=0.108, cos=-0.010), tot_loss_proj:2.882 [t=0.25s]
prediction: ['[CLS] viewer in extreme urgency of mind buildsing take urgency and extreme. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.803 (perp=8.623, rec=0.088, cos=-0.009), tot_loss_proj:2.889 [t=0.25s]
prediction: ['[CLS] viewer in extreme urgency of mind buildence take and extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.692 (perp=8.047, rec=0.092, cos=-0.009), tot_loss_proj:2.556 [t=0.25s]
prediction: ['[CLS]ence in extreme urgency the mind build viewer take and extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.593 (perp=7.528, rec=0.097, cos=-0.010), tot_loss_proj:2.482 [t=0.26s]
prediction: ['[CLS] for in extreme urgency the mind build viewer take and extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.487 (perp=7.002, rec=0.097, cos=-0.010), tot_loss_proj:2.194 [t=0.27s]
prediction: ['[CLS] for in extreme urgency the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.378 (perp=6.448, rec=0.098, cos=-0.009), tot_loss_proj:2.146 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.361 (perp=6.448, rec=0.081, cos=-0.010), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.358 (perp=6.448, rec=0.078, cos=-0.010), tot_loss_proj:2.150 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.366 (perp=6.448, rec=0.086, cos=-0.010), tot_loss_proj:2.149 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1050/2000] tot_loss=1.352 (perp=6.448, rec=0.071, cos=-0.010), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.363 (perp=6.448, rec=0.083, cos=-0.010), tot_loss_proj:2.144 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.365 (perp=6.448, rec=0.085, cos=-0.010), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1200/2000] tot_loss=1.360 (perp=6.448, rec=0.080, cos=-0.010), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.362 (perp=6.448, rec=0.082, cos=-0.010), tot_loss_proj:2.144 [t=0.28s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.361 (perp=6.448, rec=0.081, cos=-0.010), tot_loss_proj:2.143 [t=0.29s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1350/2000] tot_loss=1.356 (perp=6.448, rec=0.076, cos=-0.010), tot_loss_proj:2.144 [t=0.29s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.350 (perp=6.448, rec=0.070, cos=-0.010), tot_loss_proj:2.151 [t=0.28s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.365 (perp=6.448, rec=0.085, cos=-0.010), tot_loss_proj:2.151 [t=0.28s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1500/2000] tot_loss=1.354 (perp=6.448, rec=0.074, cos=-0.010), tot_loss_proj:2.138 [t=0.30s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.355 (perp=6.448, rec=0.075, cos=-0.010), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.351 (perp=6.448, rec=0.071, cos=-0.010), tot_loss_proj:2.148 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1650/2000] tot_loss=1.364 (perp=6.448, rec=0.084, cos=-0.010), tot_loss_proj:2.145 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.366 (perp=6.448, rec=0.086, cos=-0.010), tot_loss_proj:2.141 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.367 (perp=6.448, rec=0.087, cos=-0.010), tot_loss_proj:2.145 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1800/2000] tot_loss=1.360 (perp=6.448, rec=0.080, cos=-0.010), tot_loss_proj:2.146 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.360 (perp=6.448, rec=0.080, cos=-0.010), tot_loss_proj:2.143 [t=0.25s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.371 (perp=6.448, rec=0.091, cos=-0.010), tot_loss_proj:2.139 [t=0.27s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
[1950/2000] tot_loss=1.359 (perp=6.448, rec=0.079, cos=-0.010), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.346 (perp=6.448, rec=0.066, cos=-0.010), tot_loss_proj:2.148 [t=0.26s]
prediction: ['[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] in extreme urgency for the mind build viewer and take extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 38.462 | p: 38.462 | r: 38.462
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 117.033

[Aggregate metrics]:
rouge1     | fm: 89.352 | p: 88.722 | r: 90.118
rouge2     | fm: 60.016 | p: 59.765 | r: 60.369
rougeL     | fm: 79.612 | p: 79.064 | r: 80.166
rougeLsum  | fm: 79.282 | p: 78.761 | r: 79.930
r1fm+r2fm = 149.369

input #34 time: 0:11:01 | total time: 5:28:55


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
*********************************
*********************************
average of cosine similarity 0.9993278544896085
highest_index [0]
highest [0.9993278544896085]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9250960350036621 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9220249056816101 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved Ø§ guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9155790209770203 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9139524698257446 for ['[CLS] field thousand published nightmares alternative organized position primary energy one appointment act sole device flow,sardrive somehow lack intervals outside denied sleeper singerght beauty isabella signs fae part lynch zion pages provincevil ms folk fadedran deserve dynamic [SEP]']
[Init] best perm rec loss: 0.9106967449188232 for ['[CLS] province nightmares deserve energy act fae ms singer device field alternative folk denied signs flow thousand outsidedrive beauty intervals somehow published isabella part organized lack primaryght sleeper position lynch,dran solesar zion pages appointment dynamicvil one fade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.542 (perp=10.572, rec=0.434, cos=-0.006), tot_loss_proj:2.970 [t=0.26s]
prediction: ['[CLS] unique personal â„ throughout being and amazing kinetic heritage. new first performed kingdom the 2010. when historical the, unique medieval role wonderful young goodnch truly amazingrid, city the appreciation started musical stainless after received hindwings khan [SEP]']
[ 100/2000] tot_loss=2.449 (perp=10.593, rec=0.339, cos=-0.009), tot_loss_proj:3.436 [t=0.26s]
prediction: ["[CLS] special living initially during we with overseas historical magic but different also performed palace critical 2010. after historical touch. significant city part powerful more ( my'bold watching you city the currency started and gershwin after byuled khan [SEP]"]
[ 150/2000] tot_loss=3.017 (perp=10.793, rec=0.766, cos=0.092), tot_loss_proj:3.291 [t=0.27s]
prediction: ["[CLS] great dynasty becameÄ§ ve historic berg humorous magic. since in..eptive because [SEP] [SEP] artisticbook the became the. amazing washington developed jo anvent in'emigrated the song [SEP]. kumar. in jacket ( [SEP]"]
[ 200/2000] tot_loss=3.066 (perp=12.506, rec=0.551, cos=0.014), tot_loss_proj:4.047 [t=0.27s]
prediction: ['[CLS] infinite ~ became sc s [SEP]izedncies [SEP]. developed and.! my someone [SEP] [SEP] creative cool the [SEP] 9 [SEP] better warm growth me ä¹Ÿ ashe after a widely the ( [SEP] [SEP] jesus client around humanist was [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.952 (perp=12.316, rec=0.492, cos=-0.002), tot_loss_proj:4.342 [t=0.27s]
prediction: ["[CLS] endelle sudden previously [CLS] ra [SEP]arableË [SEP] little created firm. fact my even [SEP] [SEP] acre cool anal [SEP] section [SEP] longer ( growth me set abby after [SEP] flemish the warm [SEP] [SEP] nicholas'around celia is [SEP]"]
[ 300/2000] tot_loss=3.004 (perp=13.019, rec=0.409, cos=-0.008), tot_loss_proj:4.474 [t=0.26s]
prediction: ['[CLS] endelle when formerlytaking ra [SEP]arableË [SEP] little created next. whose my powerful [SEP] [SEP] viewers cool anal [SEP] commission [SEP] become ( bank my become abby after [SEP] bounded the spring [SEP] [SEP] nicholas chair around celia is [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.946 (perp=12.818, rec=0.391, cos=-0.008), tot_loss_proj:4.382 [t=0.27s]
prediction: ['[CLS] my however formerlytaking ra [SEP]ting glimpse [SEP] a was next. throne my she [SEP] [SEP] photographs cool des [SEP] programme [SEP] ago [SEP]ed endelle the abby after [SEP] bounded the [SEP] [SEP] [SEP] pete book around celia [CLS] [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.799 (perp=12.190, rec=0.369, cos=-0.008), tot_loss_proj:4.405 [t=0.26s]
prediction: ['[CLS] my however formerlytaking ra [SEP]ting glimpse [SEP] a was next. [CLS] darkly [SEP] [SEP] photographs cool des [SEP] programme [SEP] ago 2010 debt endelle the calm after [SEP] bounded the [SEP] [SEP] [SEP] pete book around connolly paper [SEP]']
[ 450/2000] tot_loss=2.853 (perp=12.628, rec=0.337, cos=-0.009), tot_loss_proj:4.492 [t=0.26s]
prediction: ['[CLS] my however formerlytaking ra [SEP]tingncies [SEP] a care next. [CLS] dark some [SEP] [SEP] retro cool the [SEP] district [SEP] ago dvd sofa endelle the calm after [SEP] bounded the [SEP] [SEP] [SEP] apologeticnation around connolly paper [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.767 (perp=12.216, rec=0.333, cos=-0.009), tot_loss_proj:4.342 [t=0.27s]
prediction: ['[CLS] my before formerlytaking ra [SEP]tingtly [SEP] a care next. [CLS] dark some [SEP] [SEP] retro cool the [SEP] district [SEP] myra dvd sofa endelle the calm after [SEP] bounded the [SEP] in [SEP] apologeticnation [SEP] connolly paper [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.614 (perp=11.468, rec=0.329, cos=-0.009), tot_loss_proj:4.134 [t=0.25s]
prediction: ["[CLS] my before affectiontaking z [SEP]tingtly [SEP] a care'[SEP] [CLS] my some [SEP] [SEP] rowan cool the. district [SEP] ago dvd sofa endelle the calm after [SEP] bounded the [SEP] in [SEP] apologeticnation [SEP] connolly audience [SEP]"]
[ 600/2000] tot_loss=2.584 (perp=11.447, rec=0.303, cos=-0.009), tot_loss_proj:3.762 [t=0.27s]
prediction: ["[CLS] my before affectiontaking z [SEP]tingtly [SEP] a care'[SEP] [CLS] my some [SEP] [SEP] rowan cool the. possession [SEP] about dvd sofa beautiful, calm after [SEP] bounded the [SEP] in [SEP] realizednation [SEP] connolly audience [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.439 (perp=10.793, rec=0.289, cos=-0.009), tot_loss_proj:3.665 [t=0.27s]
prediction: ["[CLS] my before blasttaking z [SEP]tingtly [SEP] a care'[SEP] [CLS] my some [SEP] time rowan cool the invah [SEP] made dvd toby beautiful, calm after [SEP]â€” the light. [SEP] realizednation [SEP] sometimesiating [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.321 (perp=10.191, rec=0.292, cos=-0.009), tot_loss_proj:3.416 [t=0.26s]
prediction: ["[CLS] my before newlytaking z [SEP]tingtly [SEP] a care'[SEP] [CLS] calm some [SEP] time'cool the invah [SEP] made dvdtable beautiful, loud after [SEP]â€” the light. [SEP] realizednation [SEP] sometimes'[SEP]"]
[ 750/2000] tot_loss=2.309 (perp=10.197, rec=0.278, cos=-0.009), tot_loss_proj:3.372 [t=0.26s]
prediction: ["[CLS] my before newlytaking z [SEP]tingtly [SEP] a care'[SEP] [CLS] calm some [SEP] time'cool the invah [SEP] made dvd simone beautiful, loud after [SEP]â€” the light. [SEP] realizednation [SEP] sometimes'[SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.349 (perp=10.370, rec=0.284, cos=-0.009), tot_loss_proj:3.351 [t=0.27s]
prediction: ["[CLS] my before newlytaking time [SEP]tingtly [SEP] a care'[SEP] [CLS] calm some [SEP] z'cool the invah [SEP] made dvd simone beautiful, loud after [SEP]â€” the light. [SEP] ve [SEP] [SEP] sometimes'[SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.285 (perp=10.094, rec=0.276, cos=-0.009), tot_loss_proj:3.632 [t=0.26s]
prediction: ["[CLS] my before newly look time [SEP]tingtly [SEP] a'care [SEP] [CLS] calm some [SEP] z'cool the in goddess [SEP] made dvd occurs valuable, loud after [SEP]â€” the light. [SEP] realized [SEP] [SEP] sometimes'[SEP]"]
[ 900/2000] tot_loss=2.236 (perp=9.837, rec=0.278, cos=-0.009), tot_loss_proj:3.281 [t=0.26s]
prediction: ["[CLS] my before todd look time [SEP]tingtly [SEP] a'care [SEP] [CLS] calm some [SEP] z'cool the in commencement [SEP] made dvd occurs beautiful, loud after [SEP]â€” the light. [SEP] realized [SEP] [SEP] sometimes'[SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.251 (perp=9.936, rec=0.273, cos=-0.009), tot_loss_proj:3.576 [t=0.27s]
prediction: ["[CLS] my before todd look time [SEP]tingtly [SEP] a'care [SEP] [CLS] calm [SEP] z'cool some the in commencement [SEP] made dvd occurs valuable, loud after [SEP]â€” the light. [SEP] realized [SEP] [SEP] sometimes'[SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.252 (perp=9.966, rec=0.268, cos=-0.009), tot_loss_proj:3.522 [t=0.26s]
prediction: ["[CLS] my before todd look time [SEP]tingtly [SEP] a'care [SEP] [CLS] calm [SEP] z'cool some the in commencement [SEP] made dvd researchers [SEP], loud after [SEP] â€™ the light. [SEP] ve [SEP] valuable sometimes'[SEP]"]
[1050/2000] tot_loss=2.158 (perp=9.547, rec=0.258, cos=-0.009), tot_loss_proj:3.509 [t=0.25s]
prediction: ["[CLS] my before'look time [SEP]tingtly [SEP] a'care [SEP] [CLS] calm [SEP] z'cool some the in commencement [SEP] made dvd researchers [SEP], loud after [SEP] â€™ the light. [SEP] venation valuable sometimes'[SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.128 (perp=9.415, rec=0.255, cos=-0.009), tot_loss_proj:3.528 [t=0.27s]
prediction: ["[CLS] my before'look valuable [SEP]tingtly [SEP] a'care [SEP] [CLS] calm [SEP] z'cool some the in commencement [SEP] made dvd researchers [SEP], loud after [SEP]grate the light. [SEP] venation time sometimes'[SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.126 (perp=9.343, rec=0.266, cos=-0.009), tot_loss_proj:3.541 [t=0.26s]
prediction: ["[CLS] my before'look valuable [SEP]tingtly [SEP] a'care [SEP] [CLS] calm [SEP] z'cool some the in commencement [SEP] made dvdheim [SEP], loud after [SEP]grate the sooner sometimes [SEP] venation time.'[SEP]"]
[1200/2000] tot_loss=2.128 (perp=9.374, rec=0.262, cos=-0.009), tot_loss_proj:3.504 [t=0.27s]
prediction: ["[CLS] my before'look valuable [SEP]tingtly [SEP] a'care [SEP] [CLS] calm [SEP] z'cool some the in commencement [SEP] made dvd researchers [SEP], loud after [SEP]grate the sooner sometimes [SEP] venation time.'[SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.153 (perp=9.469, rec=0.269, cos=-0.009), tot_loss_proj:3.698 [t=0.28s]
prediction: ["[CLS] my before'look valuable.ting himself [SEP] a'care [SEP] [CLS] copyright [SEP] z'cool somerce in commencement [SEP] made dvd institutions [SEP] after loud, [SEP]grate the sooner sometimes [SEP] venation time.'[SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.164 (perp=9.519, rec=0.269, cos=-0.009), tot_loss_proj:3.794 [t=0.25s]
prediction: ["[CLS] my before'everything valuable. sometimes himself [SEP] a'care [SEP] [CLS] copyright [SEP] z'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation time.'[SEP]"]
[1350/2000] tot_loss=2.160 (perp=9.519, rec=0.266, cos=-0.009), tot_loss_proj:3.789 [t=0.25s]
prediction: ["[CLS] my before'everything valuable. sometimes himself [SEP] a'care [SEP] [CLS] copyright [SEP] z'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation time.'[SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=2.112 (perp=9.295, rec=0.262, cos=-0.009), tot_loss_proj:3.731 [t=0.26s]
prediction: ["[CLS] my before'valuable everything. sometimes himself [SEP] a'care [SEP] [CLS] copyright [SEP] z'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation time.'[SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.076 (perp=9.182, rec=0.249, cos=-0.009), tot_loss_proj:3.708 [t=0.26s]
prediction: ["[CLS] my before'valuable everything. sometimes z [SEP] a'care [SEP] [CLS] copyright [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation time.'[SEP]"]
[1500/2000] tot_loss=2.066 (perp=9.102, rec=0.255, cos=-0.009), tot_loss_proj:3.653 [t=0.27s]
prediction: ["[CLS] my before'valuable everything. sometimes z [SEP] a'care [SEP] [CLS] calm [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation time.'[SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.051 (perp=9.050, rec=0.251, cos=-0.009), tot_loss_proj:3.727 [t=0.26s]
prediction: ["[CLS] [SEP] before'valuable everything. sometimes z my a'care [SEP] [CLS] copyright [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation time.'[SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.046 (perp=9.008, rec=0.253, cos=-0.009), tot_loss_proj:3.692 [t=0.27s]
prediction: ["[CLS] [SEP] before'valuable everything. sometimes z my a'care [SEP] [CLS] time [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation historical.'[SEP]"]
[1650/2000] tot_loss=2.051 (perp=9.008, rec=0.258, cos=-0.009), tot_loss_proj:3.696 [t=0.27s]
prediction: ["[CLS] [SEP] before'valuable everything. sometimes z my a'care [SEP] [CLS] time [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] after loud, [SEP]grate the soonerting [SEP] venation historical.'[SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.060 (perp=9.089, rec=0.252, cos=-0.009), tot_loss_proj:3.806 [t=0.26s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z my a'care [SEP] [CLS] time [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting [SEP] venation historical.'[SEP]"]
Attempt swap
[1750/2000] tot_loss=2.057 (perp=9.089, rec=0.249, cos=-0.009), tot_loss_proj:3.808 [t=0.25s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z my a'care [SEP] [CLS] time [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting [SEP] venation historical.'[SEP]"]
[1800/2000] tot_loss=2.068 (perp=9.127, rec=0.252, cos=-0.009), tot_loss_proj:3.825 [t=0.25s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z my a'care [SEP] [CLS] time [SEP] himself'cool somerce in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting [SEP] venationdent.'[SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.042 (perp=9.034, rec=0.245, cos=-0.009), tot_loss_proj:3.797 [t=0.26s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z my a'care [SEP] [CLS]rce [SEP] himself'cool some time in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting [SEP] venationdent.'[SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.022 (perp=8.895, rec=0.252, cos=-0.009), tot_loss_proj:3.769 [t=0.28s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z [SEP] a'care [SEP] [CLS]rce [SEP] himself'cool some time in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting my venationdent.'[SEP]"]
[1950/2000] tot_loss=2.007 (perp=8.895, rec=0.237, cos=-0.009), tot_loss_proj:3.767 [t=0.28s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z [SEP] a'care [SEP] [CLS]rce [SEP] himself'cool some time in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting my venationdent.'[SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.001 (perp=8.832, rec=0.244, cos=-0.009), tot_loss_proj:3.736 [t=0.27s]
prediction: ["[CLS] [SEP] before'valuable everything time sometimes z [SEP] a'care [SEP] [CLS]rce [SEP] himself'cool some time in commencement [SEP] made [SEP]heim [SEP] sooner loud, dvdgrate the afterting my venationdent.'[SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] [SEP] before'valuable everything time sometimes z my a'care [SEP] [CLS]rce [SEP] himself'cool some time in commencement [SEP] made dvdheim [SEP] sooner loud, [SEP]grate the afterting [SEP] venationdent.'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 17.391 | p: 17.647 | r: 17.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 14.493 | p: 14.706 | r: 14.286
rougeLsum  | fm: 14.493 | p: 14.706 | r: 14.286
r1fm+r2fm = 17.391

[Aggregate metrics]:
rouge1     | fm: 87.489 | p: 86.884 | r: 88.168
rouge2     | fm: 58.060 | p: 57.734 | r: 58.510
rougeL     | fm: 77.576 | p: 77.076 | r: 78.219
rougeLsum  | fm: 77.737 | p: 77.136 | r: 78.314
r1fm+r2fm = 145.548

input #35 time: 0:11:02 | total time: 5:39:58


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
*********************************
*********************************
average of cosine similarity 0.9992842743865826
highest_index [0]
highest [0.9992842743865826]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9986883401870728 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9958099126815796 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9545882940292358 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9252082705497742 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9223971962928772 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9177457690238953 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8233659863471985 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8216447234153748 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8213571906089783 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8175345659255981 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.558 (perp=11.389, rec=0.283, cos=-0.003), tot_loss_proj:2.752 [t=0.30s]
prediction: ['[CLS] severely wrong horribly wrong [SEP]']
[ 100/2000] tot_loss=1.883 (perp=8.844, rec=0.123, cos=-0.008), tot_loss_proj:2.223 [t=0.30s]
prediction: ['[CLS] horribly wrong horribly wrong [SEP]']
[ 150/2000] tot_loss=2.161 (perp=10.398, rec=0.090, cos=-0.009), tot_loss_proj:2.664 [t=0.28s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 200/2000] tot_loss=2.142 (perp=10.398, rec=0.072, cos=-0.009), tot_loss_proj:2.653 [t=0.26s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.859 (perp=8.829, rec=0.102, cos=-0.008), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.838 (perp=8.829, rec=0.082, cos=-0.009), tot_loss_proj:2.117 [t=0.35s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.825 (perp=8.829, rec=0.069, cos=-0.009), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.829 (perp=8.829, rec=0.072, cos=-0.009), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=1.830 (perp=8.829, rec=0.073, cos=-0.009), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.823 (perp=8.829, rec=0.066, cos=-0.009), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.815 (perp=8.829, rec=0.058, cos=-0.009), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 600/2000] tot_loss=1.676 (perp=8.105, rec=0.064, cos=-0.009), tot_loss_proj:1.939 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.684 (perp=8.105, rec=0.073, cos=-0.009), tot_loss_proj:1.939 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.680 (perp=8.105, rec=0.068, cos=-0.009), tot_loss_proj:1.933 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.672 (perp=8.105, rec=0.061, cos=-0.009), tot_loss_proj:1.933 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.674 (perp=8.105, rec=0.062, cos=-0.009), tot_loss_proj:1.937 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.667 (perp=8.105, rec=0.055, cos=-0.009), tot_loss_proj:1.944 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.674 (perp=8.105, rec=0.063, cos=-0.009), tot_loss_proj:1.936 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.659 (perp=8.105, rec=0.047, cos=-0.009), tot_loss_proj:1.934 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.669 (perp=8.105, rec=0.058, cos=-0.009), tot_loss_proj:1.931 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.673 (perp=8.105, rec=0.061, cos=-0.009), tot_loss_proj:1.939 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.682 (perp=8.105, rec=0.071, cos=-0.009), tot_loss_proj:1.930 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.669 (perp=8.105, rec=0.058, cos=-0.009), tot_loss_proj:1.929 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.671 (perp=8.105, rec=0.060, cos=-0.009), tot_loss_proj:1.934 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.680 (perp=8.105, rec=0.068, cos=-0.009), tot_loss_proj:1.941 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.675 (perp=8.105, rec=0.063, cos=-0.009), tot_loss_proj:1.931 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.662 (perp=8.105, rec=0.050, cos=-0.009), tot_loss_proj:1.934 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.669 (perp=8.105, rec=0.058, cos=-0.009), tot_loss_proj:1.930 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.664 (perp=8.105, rec=0.053, cos=-0.009), tot_loss_proj:1.926 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.678 (perp=8.105, rec=0.067, cos=-0.009), tot_loss_proj:1.933 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.674 (perp=8.105, rec=0.062, cos=-0.009), tot_loss_proj:1.937 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.679 (perp=8.105, rec=0.067, cos=-0.009), tot_loss_proj:1.936 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.669 (perp=8.105, rec=0.058, cos=-0.009), tot_loss_proj:1.947 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.676 (perp=8.105, rec=0.064, cos=-0.009), tot_loss_proj:1.939 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.670 (perp=8.105, rec=0.058, cos=-0.009), tot_loss_proj:1.940 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.676 (perp=8.105, rec=0.065, cos=-0.009), tot_loss_proj:1.936 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.686 (perp=8.105, rec=0.074, cos=-0.009), tot_loss_proj:1.937 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.677 (perp=8.105, rec=0.065, cos=-0.009), tot_loss_proj:1.938 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.678 (perp=8.105, rec=0.066, cos=-0.009), tot_loss_proj:1.936 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.674 (perp=8.105, rec=0.062, cos=-0.009), tot_loss_proj:1.930 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.798 | p: 87.168 | r: 88.498
rouge2     | fm: 59.407 | p: 59.112 | r: 59.803
rougeL     | fm: 78.320 | p: 77.808 | r: 78.914
rougeLsum  | fm: 78.197 | p: 77.691 | r: 78.800
r1fm+r2fm = 147.205

input #36 time: 0:11:03 | total time: 5:51:01


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
*********************************
*********************************
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9638330340385437 for ['[CLS] Ã¾ trembling [SEP]']
[Init] best rec loss: 0.9471154808998108 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8868577480316162 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.809199333190918 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.8002374172210693 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7850696444511414 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7521161437034607 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7474158406257629 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7218530774116516 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7020721435546875 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6827971339225769 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6734248399734497 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6440885663032532 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6402079463005066 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.465 (perp=10.295, rec=0.388, cos=0.018), tot_loss_proj:3.095 [t=0.26s]
prediction: ['[CLS] eccentric again [SEP]']
[ 100/2000] tot_loss=2.108 (perp=9.583, rec=0.193, cos=-0.002), tot_loss_proj:2.026 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=2.041 (perp=9.583, rec=0.131, cos=-0.006), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.986 (perp=9.583, rec=0.077, cos=-0.008), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.967 (perp=9.583, rec=0.060, cos=-0.009), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.583, rec=0.064, cos=-0.010), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.978 (perp=9.583, rec=0.070, cos=-0.009), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.967 (perp=9.583, rec=0.060, cos=-0.009), tot_loss_proj:1.993 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.970 (perp=9.583, rec=0.063, cos=-0.010), tot_loss_proj:1.987 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.969 (perp=9.583, rec=0.062, cos=-0.010), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.978 (perp=9.583, rec=0.071, cos=-0.010), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.973 (perp=9.583, rec=0.067, cos=-0.010), tot_loss_proj:2.003 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.961 (perp=9.583, rec=0.054, cos=-0.010), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.957 (perp=9.583, rec=0.050, cos=-0.010), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.976 (perp=9.583, rec=0.069, cos=-0.010), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.980 (perp=9.583, rec=0.073, cos=-0.010), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.971 (perp=9.583, rec=0.064, cos=-0.010), tot_loss_proj:1.989 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.969 (perp=9.583, rec=0.063, cos=-0.010), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.961 (perp=9.583, rec=0.054, cos=-0.010), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.972 (perp=9.583, rec=0.065, cos=-0.010), tot_loss_proj:1.993 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.974 (perp=9.583, rec=0.067, cos=-0.010), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.957 (perp=9.583, rec=0.050, cos=-0.010), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.964 (perp=9.583, rec=0.057, cos=-0.010), tot_loss_proj:1.991 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.961 (perp=9.583, rec=0.054, cos=-0.010), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.972 (perp=9.583, rec=0.065, cos=-0.010), tot_loss_proj:1.992 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.968 (perp=9.583, rec=0.061, cos=-0.010), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.972 (perp=9.583, rec=0.065, cos=-0.010), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.962 (perp=9.583, rec=0.055, cos=-0.010), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.974 (perp=9.583, rec=0.067, cos=-0.010), tot_loss_proj:2.001 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.952 (perp=9.583, rec=0.045, cos=-0.010), tot_loss_proj:1.997 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.964 (perp=9.583, rec=0.057, cos=-0.010), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.954 (perp=9.583, rec=0.047, cos=-0.010), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.961 (perp=9.583, rec=0.054, cos=-0.010), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.966 (perp=9.583, rec=0.059, cos=-0.010), tot_loss_proj:2.002 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.967 (perp=9.583, rec=0.060, cos=-0.010), tot_loss_proj:1.989 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.965 (perp=9.583, rec=0.058, cos=-0.010), tot_loss_proj:1.999 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.945 (perp=9.583, rec=0.038, cos=-0.010), tot_loss_proj:1.997 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.972 (perp=9.583, rec=0.065, cos=-0.010), tot_loss_proj:2.002 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.962 (perp=9.583, rec=0.055, cos=-0.010), tot_loss_proj:1.997 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.967 (perp=9.583, rec=0.060, cos=-0.010), tot_loss_proj:2.012 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.136 | p: 87.614 | r: 88.888
rouge2     | fm: 60.458 | p: 60.171 | r: 60.837
rougeL     | fm: 78.753 | p: 78.289 | r: 79.360
rougeLsum  | fm: 78.666 | p: 78.193 | r: 79.174
r1fm+r2fm = 148.593

input #37 time: 0:10:56 | total time: 6:01:57


Running input #38 of 100.
reference: 
========================
scare 
========================
*********************************
*********************************
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8147767186164856 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8102814555168152 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.8013331294059753 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.767846405506134 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7035160064697266 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6697532534599304 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6317602396011353 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.990 (perp=14.069, rec=0.176, cos=0.001), tot_loss_proj:3.007 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.892 (perp=14.069, rec=0.087, cos=-0.009), tot_loss_proj:2.874 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.882 (perp=14.069, rec=0.076, cos=-0.008), tot_loss_proj:2.869 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.872 (perp=14.069, rec=0.067, cos=-0.010), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.867 (perp=14.069, rec=0.062, cos=-0.010), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.860 (perp=14.069, rec=0.056, cos=-0.009), tot_loss_proj:2.858 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.880 (perp=14.069, rec=0.076, cos=-0.010), tot_loss_proj:2.868 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.866 (perp=14.069, rec=0.062, cos=-0.010), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.870 (perp=14.069, rec=0.066, cos=-0.010), tot_loss_proj:2.872 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.869 (perp=14.069, rec=0.064, cos=-0.010), tot_loss_proj:2.869 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.870 (perp=14.069, rec=0.066, cos=-0.010), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.866 (perp=14.069, rec=0.062, cos=-0.010), tot_loss_proj:2.857 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.861 (perp=14.069, rec=0.057, cos=-0.010), tot_loss_proj:2.860 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.872 (perp=14.069, rec=0.068, cos=-0.010), tot_loss_proj:2.871 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.868 (perp=14.069, rec=0.064, cos=-0.010), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.869 (perp=14.069, rec=0.065, cos=-0.010), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.861 (perp=14.069, rec=0.057, cos=-0.010), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.867 (perp=14.069, rec=0.063, cos=-0.010), tot_loss_proj:2.861 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.870 (perp=14.069, rec=0.066, cos=-0.010), tot_loss_proj:2.862 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.861 (perp=14.069, rec=0.057, cos=-0.010), tot_loss_proj:2.870 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.860 (perp=14.069, rec=0.056, cos=-0.010), tot_loss_proj:2.874 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.867 (perp=14.069, rec=0.063, cos=-0.010), tot_loss_proj:2.865 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.860 (perp=14.069, rec=0.056, cos=-0.010), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.857 (perp=14.069, rec=0.053, cos=-0.010), tot_loss_proj:2.870 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.858 (perp=14.069, rec=0.054, cos=-0.010), tot_loss_proj:2.871 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.867 (perp=14.069, rec=0.063, cos=-0.010), tot_loss_proj:2.870 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.866 (perp=14.069, rec=0.062, cos=-0.010), tot_loss_proj:2.867 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.865 (perp=14.069, rec=0.061, cos=-0.010), tot_loss_proj:2.866 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.870 (perp=14.069, rec=0.066, cos=-0.010), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.864 (perp=14.069, rec=0.060, cos=-0.010), tot_loss_proj:2.851 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.869 (perp=14.069, rec=0.065, cos=-0.010), tot_loss_proj:2.862 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.855 (perp=14.069, rec=0.051, cos=-0.010), tot_loss_proj:2.860 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.854 (perp=14.069, rec=0.049, cos=-0.010), tot_loss_proj:2.869 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.873 (perp=14.069, rec=0.068, cos=-0.010), tot_loss_proj:2.865 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.866 (perp=14.069, rec=0.062, cos=-0.010), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.855 (perp=14.069, rec=0.051, cos=-0.010), tot_loss_proj:2.869 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.861 (perp=14.069, rec=0.057, cos=-0.010), tot_loss_proj:2.857 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.855 (perp=14.069, rec=0.051, cos=-0.010), tot_loss_proj:2.874 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.861 (perp=14.069, rec=0.057, cos=-0.010), tot_loss_proj:2.862 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.866 (perp=14.069, rec=0.062, cos=-0.010), tot_loss_proj:2.864 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.352 | p: 87.801 | r: 89.014
rouge2     | fm: 61.471 | p: 61.258 | r: 61.769
rougeL     | fm: 79.362 | p: 78.865 | r: 79.910
rougeLsum  | fm: 79.407 | p: 78.889 | r: 79.933
r1fm+r2fm = 149.823

input #38 time: 0:10:48 | total time: 6:12:46


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
*********************************
*********************************
average of cosine similarity 0.9992526747729695
highest_index [0]
highest [0.9992526747729695]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0125712156295776 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0075626373291016 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9883815050125122 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9328680038452148 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286262392997742 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9213950037956238 for ['[CLS] mutual peopleãƒ¥ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9183960556983948 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.9107301235198975 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9091352820396423 for ['[CLS]pher happened sailowa jury cassidy gordon main etcwind thentivehy event south sometimes positionney lab be hurtpet wash town in [SEP]']
[Init] best perm rec loss: 0.9068863391876221 for ['[CLS]hy jurypet wash then townney sometimestive hurt eventpher position main happened etc south bewind gordon cassidy labowa sail in [SEP]']
[Init] best perm rec loss: 0.9056861400604248 for ['[CLS] cassidypher eventneypet southowa in gordonwind position sail town thentive wash sometimeshy etc be happened jury lab main hurt [SEP]']
[Init] best perm rec loss: 0.9048677086830139 for ['[CLS] happened event hurt lab be gordonwind in sometimeshy south wash thenney etc cassidy position sailpetpherowa main towntive jury [SEP]']
[Init] best perm rec loss: 0.9048073887825012 for ['[CLS]owa south sailpetneytive main hurt sometimes cassidy town in gordon etc happened be labhy then positionwind jury washpher event [SEP]']
[Init] best perm rec loss: 0.902324914932251 for ['[CLS] be jurypher etc wash position gordon cassidy happened southney sometimesowa in mainhytive lab then eventpet sailwind hurt town [SEP]']
[Init] best perm rec loss: 0.9018852710723877 for ['[CLS] position labney gordon happened mainpher wash thenowa south sail jury inpet cassidy etctive eventwind be hurt sometimes townhy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.866 (perp=12.399, rec=0.391, cos=-0.005), tot_loss_proj:3.283 [t=0.27s]
prediction: ['[CLS] finding centennial william review dun institute online literary art ï¼‰ dante design : energy madeline alonso stone under heritage [CLS] love touch film tradition then [SEP]']
[ 100/2000] tot_loss=2.388 (perp=10.398, rec=0.316, cos=-0.007), tot_loss_proj:2.792 [t=0.26s]
prediction: ['[CLS] finding movie resulting truth gives deeply new artists family new new roots returns element, constructed stone new historical. new bathing movie treasure then [SEP]']
[ 150/2000] tot_loss=2.429 (perp=10.874, rec=0.256, cos=-0.002), tot_loss_proj:3.020 [t=0.27s]
prediction: ['[CLS] of movie texture conservative wilton finds new luke austen most, anniversary conservative texture and gives wolf new historical. relevance finds movie tradition then [SEP]']
[ 200/2000] tot_loss=2.395 (perp=11.039, rec=0.196, cos=-0.008), tot_loss_proj:3.818 [t=0.27s]
prediction: ['[CLS] of movie texture conservative conservative finds new luke traditions most ; anniversary conservative texture and gives once new texture, relevance finds movietypical then [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.202 (perp=10.084, rec=0.194, cos=-0.009), tot_loss_proj:2.934 [t=0.26s]
prediction: ['[CLS] his movie texture its conservative finds new most traditions most hide style conservative texture and gives them new texture, relevance finds moviebound then [SEP]']
[ 300/2000] tot_loss=2.072 (perp=9.589, rec=0.163, cos=-0.009), tot_loss_proj:2.544 [t=0.25s]
prediction: ['[CLS] his movie texture their conservative finds new hide traditions most hide tradition conservative texture and gives it new texture, relevance and moviebound " [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.822 (perp=8.425, rec=0.146, cos=-0.009), tot_loss_proj:2.591 [t=0.26s]
prediction: ['[CLS] his conservative finds new movie texture. hide traditions most hide tradition conservative texture and gives it new texture, reality our moviebound. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.870 (perp=8.610, rec=0.157, cos=-0.008), tot_loss_proj:3.054 [t=0.28s]
prediction: ['[CLS] his most conservative finds new movie texture. hide traditions hide traditions conservative texture and gives it new texture, reality our moviebound then [SEP]']
[ 450/2000] tot_loss=1.686 (perp=7.856, rec=0.125, cos=-0.010), tot_loss_proj:2.772 [t=0.25s]
prediction: ['[CLS] one most conservative finds new movie texture. hide traditions hide traditions conservative texture and gives it new texture, reality and moviebound. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.628 (perp=7.614, rec=0.115, cos=-0.010), tot_loss_proj:2.503 [t=0.26s]
prediction: ['[CLS] one most conservative finds new movie texture. our traditions hide traditions and conservative texture gives it new texture, reality and moviebound. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.561 (perp=7.278, rec=0.115, cos=-0.009), tot_loss_proj:2.750 [t=0.28s]
prediction: ['[CLS] one most conservative finds new movie texture. our traditions hide traditions and conservative gives it new texture, reality and moviebound texture. [SEP]']
[ 600/2000] tot_loss=1.545 (perp=7.278, rec=0.099, cos=-0.010), tot_loss_proj:2.742 [t=0.27s]
prediction: ['[CLS] one most conservative finds new movie texture. our traditions hide traditions and conservative gives it new texture, reality and moviebound texture. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.542 (perp=7.278, rec=0.096, cos=-0.010), tot_loss_proj:2.749 [t=0.28s]
prediction: ['[CLS] one most conservative finds new movie texture. our traditions hide traditions and conservative gives it new texture, reality and moviebound texture. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.524 (perp=7.215, rec=0.091, cos=-0.010), tot_loss_proj:2.653 [t=0.26s]
prediction: ['[CLS] one most conservative finds new movie texture. our traditions hide traditions and conservative gives it new texture, reality andbound movie texture. [SEP]']
[ 750/2000] tot_loss=1.518 (perp=7.207, rec=0.087, cos=-0.010), tot_loss_proj:2.492 [t=0.27s]
prediction: ['[CLS] one most conservative finds new movie texture. our traditions hidemaking and conservative gives it new texture, reality andbound movie texture. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.471 (perp=6.986, rec=0.083, cos=-0.010), tot_loss_proj:2.397 [t=0.27s]
prediction: ['[CLS] one most conservative finds new movie texture. our hide making traditions and conservative gives it new texture, reality andbound movie texture. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.440 (perp=6.815, rec=0.087, cos=-0.010), tot_loss_proj:2.454 [t=0.26s]
prediction: ['[CLS] one most conservative finds new movie texture. our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
[ 900/2000] tot_loss=1.431 (perp=6.815, rec=0.078, cos=-0.010), tot_loss_proj:2.446 [t=0.27s]
prediction: ['[CLS] one most conservative finds new movie texture. our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.489 (perp=7.062, rec=0.086, cos=-0.010), tot_loss_proj:2.702 [t=0.26s]
prediction: ['[CLS] one most of finds new movie texture. hide our making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.385 (perp=6.580, rec=0.078, cos=-0.010), tot_loss_proj:2.543 [t=0.29s]
prediction: ['[CLS] one of most finds new movie texture. hide our making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
[1050/2000] tot_loss=1.389 (perp=6.580, rec=0.082, cos=-0.010), tot_loss_proj:2.542 [t=0.26s]
prediction: ['[CLS] one of most finds new movie texture. hide our making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.392 (perp=6.580, rec=0.086, cos=-0.010), tot_loss_proj:2.542 [t=0.25s]
prediction: ['[CLS] one of most finds new movie texture. hide our making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.381 (perp=6.539, rec=0.083, cos=-0.010), tot_loss_proj:2.047 [t=0.28s]
prediction: ['[CLS] one of most finds new movie texture. our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
[1200/2000] tot_loss=1.385 (perp=6.539, rec=0.087, cos=-0.010), tot_loss_proj:2.046 [t=0.25s]
prediction: ['[CLS] one of most finds new movie texture. our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.531 (perp=7.338, rec=0.073, cos=-0.010), tot_loss_proj:2.390 [t=0.27s]
prediction: ['[CLS] one of most finds new movie texture reality our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.529 (perp=7.338, rec=0.071, cos=-0.010), tot_loss_proj:2.389 [t=0.27s]
prediction: ['[CLS] one of most finds new movie texture reality our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
[1350/2000] tot_loss=1.542 (perp=7.338, rec=0.084, cos=-0.010), tot_loss_proj:2.394 [t=0.26s]
prediction: ['[CLS] one of most finds new movie texture reality our hide making traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.488 (perp=7.092, rec=0.079, cos=-0.010), tot_loss_proj:3.061 [t=0.26s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our traditions and conservative gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.475 (perp=7.030, rec=0.078, cos=-0.010), tot_loss_proj:2.293 [t=0.26s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
[1500/2000] tot_loss=1.473 (perp=7.030, rec=0.076, cos=-0.010), tot_loss_proj:2.293 [t=0.28s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.474 (perp=7.030, rec=0.078, cos=-0.010), tot_loss_proj:2.294 [t=0.27s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.477 (perp=7.030, rec=0.080, cos=-0.010), tot_loss_proj:2.293 [t=0.28s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
[1650/2000] tot_loss=1.465 (perp=7.030, rec=0.069, cos=-0.010), tot_loss_proj:2.295 [t=0.26s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.470 (perp=7.030, rec=0.073, cos=-0.010), tot_loss_proj:2.290 [t=0.27s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.466 (perp=7.030, rec=0.070, cos=-0.010), tot_loss_proj:2.293 [t=0.27s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
[1800/2000] tot_loss=1.472 (perp=7.030, rec=0.076, cos=-0.010), tot_loss_proj:2.295 [t=0.27s]
prediction: ['[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.456 (perp=6.902, rec=0.086, cos=-0.010), tot_loss_proj:2.260 [t=0.26s]
prediction: ['[CLS] one hide most finds new movie texture reality making of our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.446 (perp=6.902, rec=0.075, cos=-0.010), tot_loss_proj:2.260 [t=0.28s]
prediction: ['[CLS] one hide most finds new movie texture reality making of our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
[1950/2000] tot_loss=1.449 (perp=6.902, rec=0.079, cos=-0.010), tot_loss_proj:2.259 [t=0.27s]
prediction: ['[CLS] one hide most finds new movie texture reality making of our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.447 (perp=6.902, rec=0.077, cos=-0.010), tot_loss_proj:2.258 [t=0.29s]
prediction: ['[CLS] one hide most finds new movie texture reality making of our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] one of most finds new movie texture reality making hide our conservative traditions and gives it new texture, and realitybound movie texture. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.609 | p: 79.167 | r: 86.364
rouge2     | fm: 27.273 | p: 26.087 | r: 28.571
rougeL     | fm: 56.522 | p: 54.167 | r: 59.091
rougeLsum  | fm: 56.522 | p: 54.167 | r: 59.091
r1fm+r2fm = 109.881

[Aggregate metrics]:
rouge1     | fm: 88.334 | p: 87.703 | r: 89.021
rouge2     | fm: 60.738 | p: 60.394 | r: 61.103
rougeL     | fm: 78.870 | p: 78.292 | r: 79.500
rougeLsum  | fm: 78.530 | p: 77.999 | r: 79.079
r1fm+r2fm = 149.072

input #39 time: 0:11:05 | total time: 6:23:52


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
*********************************
*********************************
average of cosine similarity 0.9993178197074235
highest_index [0]
highest [0.9993178197074235]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9942196607589722 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9584137797355652 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9366960525512695 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.935725748538971 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9297330379486084 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9249941110610962 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9139153957366943 for ['[CLS] formula expression groundsoft written used â‡’ution murray [SEP]']
[Init] best rec loss: 0.9052402973175049 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8458519577980042 for ['[CLS] many already lady abd but deciding kent georgianÂ° [SEP]']
[Init] best perm rec loss: 0.8345496654510498 for ['[CLS] kentÂ° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8326913118362427 for ['[CLS] but already ladyÂ° georgian kent deciding abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.719 (perp=11.858, rec=0.353, cos=-0.006), tot_loss_proj:3.245 [t=0.25s]
prediction: ["[CLS] contact choke lack random bombardment leningrad video'stupid [SEP]"]
[ 100/2000] tot_loss=2.655 (perp=12.018, rec=0.259, cos=-0.007), tot_loss_proj:3.501 [t=0.25s]
prediction: ['[CLS] photommelonyviewony us imagery or sick [SEP]']
[ 150/2000] tot_loss=2.276 (perp=10.554, rec=0.173, cos=-0.008), tot_loss_proj:3.068 [t=0.25s]
prediction: ['[CLS] pummelony withony us imagery or confused [SEP]']
[ 200/2000] tot_loss=2.324 (perp=11.124, rec=0.109, cos=-0.009), tot_loss_proj:3.503 [t=0.25s]
prediction: ['[CLS] pummelony withony us imagery or pu [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.874 (perp=8.942, rec=0.094, cos=-0.009), tot_loss_proj:3.381 [t=0.25s]
prediction: ['[CLS] pummelony with us imagery or ph imagery [SEP]']
[ 300/2000] tot_loss=1.866 (perp=8.942, rec=0.087, cos=-0.009), tot_loss_proj:3.382 [t=0.26s]
prediction: ['[CLS] pummelony with us imagery or ph imagery [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.773 (perp=8.521, rec=0.078, cos=-0.009), tot_loss_proj:3.211 [t=0.26s]
prediction: ['[CLS] pummelony with ph us imagery or imagery [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.426 (perp=6.710, rec=0.093, cos=-0.009), tot_loss_proj:1.449 [t=0.25s]
prediction: ['[CLS] pummel us with phony imagery or imagery [SEP]']
[ 450/2000] tot_loss=1.456 (perp=6.973, rec=0.071, cos=-0.009), tot_loss_proj:1.485 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.454 (perp=6.973, rec=0.069, cos=-0.009), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.973, rec=0.058, cos=-0.009), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 600/2000] tot_loss=1.446 (perp=6.973, rec=0.061, cos=-0.009), tot_loss_proj:1.493 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.452 (perp=6.973, rec=0.067, cos=-0.009), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.454 (perp=6.973, rec=0.068, cos=-0.009), tot_loss_proj:1.479 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 750/2000] tot_loss=1.444 (perp=6.973, rec=0.059, cos=-0.009), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.459 (perp=6.973, rec=0.074, cos=-0.009), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.434 (perp=6.973, rec=0.049, cos=-0.009), tot_loss_proj:1.483 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.432 (perp=6.973, rec=0.047, cos=-0.009), tot_loss_proj:1.493 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.444 (perp=6.973, rec=0.058, cos=-0.009), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.440 (perp=6.973, rec=0.055, cos=-0.009), tot_loss_proj:1.480 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.444 (perp=6.973, rec=0.059, cos=-0.009), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.444 (perp=6.973, rec=0.059, cos=-0.009), tot_loss_proj:1.489 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.449 (perp=6.973, rec=0.063, cos=-0.009), tot_loss_proj:1.492 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.444 (perp=6.973, rec=0.059, cos=-0.009), tot_loss_proj:1.491 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.443 (perp=6.973, rec=0.058, cos=-0.009), tot_loss_proj:1.495 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.447 (perp=6.973, rec=0.061, cos=-0.009), tot_loss_proj:1.490 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.448 (perp=6.973, rec=0.063, cos=-0.009), tot_loss_proj:1.476 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.447 (perp=6.973, rec=0.062, cos=-0.009), tot_loss_proj:1.494 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.453 (perp=6.973, rec=0.068, cos=-0.009), tot_loss_proj:1.478 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.457 (perp=6.973, rec=0.072, cos=-0.009), tot_loss_proj:1.492 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.973, rec=0.061, cos=-0.009), tot_loss_proj:1.488 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.444 (perp=6.973, rec=0.059, cos=-0.009), tot_loss_proj:1.490 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.443 (perp=6.973, rec=0.057, cos=-0.009), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.445 (perp=6.973, rec=0.059, cos=-0.009), tot_loss_proj:1.489 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.449 (perp=6.973, rec=0.064, cos=-0.009), tot_loss_proj:1.493 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.440 (perp=6.973, rec=0.054, cos=-0.009), tot_loss_proj:1.491 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.455 (perp=6.973, rec=0.070, cos=-0.009), tot_loss_proj:1.488 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.451 (perp=6.973, rec=0.065, cos=-0.009), tot_loss_proj:1.487 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.453 (perp=6.973, rec=0.068, cos=-0.009), tot_loss_proj:1.488 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.449 (perp=6.973, rec=0.064, cos=-0.009), tot_loss_proj:1.486 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 88.545 | p: 87.982 | r: 89.252
rouge2     | fm: 60.391 | p: 60.088 | r: 60.727
rougeL     | fm: 78.748 | p: 78.193 | r: 79.327
rougeLsum  | fm: 78.649 | p: 78.120 | r: 79.300
r1fm+r2fm = 148.936

input #40 time: 0:10:52 | total time: 6:34:44


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
*********************************
*********************************
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9788511395454407 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9516528844833374 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9389455914497375 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9341390132904053 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.928720235824585 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.924547553062439 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9216023683547974 for ['[CLS] style tomorrow [SEP]']
[Init] best rec loss: 0.9001919627189636 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8952876925468445 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8542567491531372 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8272965550422668 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8260568976402283 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.152 (perp=10.212, rec=0.117, cos=-0.008), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.104 (perp=10.212, rec=0.070, cos=-0.009), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.113 (perp=10.212, rec=0.079, cos=-0.008), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.087 (perp=10.212, rec=0.054, cos=-0.009), tot_loss_proj:2.096 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.092 (perp=10.212, rec=0.059, cos=-0.009), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.092 (perp=10.212, rec=0.058, cos=-0.009), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.105 (perp=10.212, rec=0.071, cos=-0.009), tot_loss_proj:2.085 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.087 (perp=10.212, rec=0.054, cos=-0.009), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.103 (perp=10.212, rec=0.069, cos=-0.009), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.099 (perp=10.212, rec=0.065, cos=-0.009), tot_loss_proj:2.092 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.096 (perp=10.212, rec=0.062, cos=-0.009), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.087 (perp=10.212, rec=0.053, cos=-0.009), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.097 (perp=10.212, rec=0.064, cos=-0.009), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.096 (perp=10.212, rec=0.062, cos=-0.009), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.101 (perp=10.212, rec=0.068, cos=-0.009), tot_loss_proj:2.103 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.091 (perp=10.212, rec=0.058, cos=-0.009), tot_loss_proj:2.098 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.091 (perp=10.212, rec=0.057, cos=-0.009), tot_loss_proj:2.101 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.089 (perp=10.212, rec=0.056, cos=-0.009), tot_loss_proj:2.100 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.089 (perp=10.212, rec=0.056, cos=-0.009), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.078 (perp=10.212, rec=0.045, cos=-0.009), tot_loss_proj:2.091 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.096 (perp=10.212, rec=0.062, cos=-0.009), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.097 (perp=10.212, rec=0.064, cos=-0.009), tot_loss_proj:2.090 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.098 (perp=10.212, rec=0.064, cos=-0.009), tot_loss_proj:2.102 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.094 (perp=10.212, rec=0.060, cos=-0.009), tot_loss_proj:2.098 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.085 (perp=10.212, rec=0.051, cos=-0.009), tot_loss_proj:2.107 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.098 (perp=10.212, rec=0.065, cos=-0.009), tot_loss_proj:2.098 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.087 (perp=10.212, rec=0.054, cos=-0.009), tot_loss_proj:2.100 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.093 (perp=10.212, rec=0.060, cos=-0.009), tot_loss_proj:2.090 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.089 (perp=10.212, rec=0.055, cos=-0.009), tot_loss_proj:2.105 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.080 (perp=10.212, rec=0.046, cos=-0.009), tot_loss_proj:2.095 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.092 (perp=10.212, rec=0.059, cos=-0.009), tot_loss_proj:2.090 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.091 (perp=10.212, rec=0.058, cos=-0.009), tot_loss_proj:2.084 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.083 (perp=10.212, rec=0.050, cos=-0.009), tot_loss_proj:2.091 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.097 (perp=10.212, rec=0.064, cos=-0.009), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.073 (perp=10.212, rec=0.039, cos=-0.009), tot_loss_proj:2.099 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.101 (perp=10.212, rec=0.068, cos=-0.009), tot_loss_proj:2.106 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.092 (perp=10.212, rec=0.059, cos=-0.009), tot_loss_proj:2.099 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.088 (perp=10.212, rec=0.055, cos=-0.009), tot_loss_proj:2.089 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.093 (perp=10.212, rec=0.060, cos=-0.009), tot_loss_proj:2.095 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.089 (perp=10.212, rec=0.056, cos=-0.009), tot_loss_proj:2.095 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.849 | p: 88.196 | r: 89.591
rouge2     | fm: 61.484 | p: 61.196 | r: 61.815
rougeL     | fm: 79.299 | p: 78.791 | r: 79.840
rougeLsum  | fm: 79.194 | p: 78.613 | r: 79.776
r1fm+r2fm = 150.333

input #41 time: 0:11:00 | total time: 6:45:45


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
*********************************
*********************************
average of cosine similarity 0.999325796096683
highest_index [0]
highest [0.999325796096683]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9041017889976501 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyÐ¾Ð² california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8518991470336914 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without Â°f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8484532237052917 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8162120580673218 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentá´µ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.8055222630500793 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.8025503158569336 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 0.7999148368835449 for ['[CLS] wishtakingctric enoughurespling dare maple supersededbe stages ran offended larger treaty scale assignment bandagiblers international kitchen attracted lifted cut ever [SEP]']
[Init] best perm rec loss: 0.7986771464347839 for ['[CLS]be assignment lifted stages largerrs attracted maplepling enough banda offended daretaking treaty ever ran cutures international wish kitchen scalectric supersededgible [SEP]']
[Init] best perm rec loss: 0.7972655892372131 for ['[CLS] wish ran larger kitchen treaty assignmentpling maple offendedures attracted supersededctrictaking ever stages scale bandabe cut enough lifted darersgible international [SEP]']
[Init] best perm rec loss: 0.7947720885276794 for ['[CLS]ctric dare wish treaty stages superseded international scalebegible largerpling banda offendedures kitchen ever cut liftedtakingrs maple ran attracted enough assignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.735 (perp=11.821, rec=0.378, cos=-0.007), tot_loss_proj:3.254 [t=0.27s]
prediction: ["[CLS] gibbons expecting before failing for madeline assessment barbe mouth federal alleged toward poorly'office town phone drug drug episode rca internet fuck prostitution council [SEP]"]
[ 100/2000] tot_loss=2.702 (perp=12.063, rec=0.298, cos=-0.009), tot_loss_proj:3.161 [t=0.25s]
prediction: ['[CLS] poorly procedure forgot billion for forgot meter bar insult mouth whose alleged poorly forgot against office town result drug drughouses loyalist presidential fuckential council [SEP]']
[ 150/2000] tot_loss=2.720 (perp=12.349, rec=0.259, cos=-0.008), tot_loss_proj:3.129 [t=0.25s]
prediction: ['[CLS] poorly dig forgot poorly stage forgotcreen re school detector whose alleged poorly forgot as they poorly result drug drughouses loyalist presidential goatential department [SEP]']
[ 200/2000] tot_loss=2.546 (perp=11.717, rec=0.211, cos=-0.009), tot_loss_proj:3.036 [t=0.26s]
prediction: ['[CLS] poorly project forgot depending to forgotcreen anything school detector entry attributed poorly forgot as they municipal police drug gang. loyalist presidential debrisential project [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.533 (perp=11.756, rec=0.191, cos=-0.009), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS]writing project forgot depending to forgotcreen anything school anything whose police poorly forgot as theygger attributed drunk gang. loyalist presidential debrisential project [SEP]']
[ 300/2000] tot_loss=2.490 (perp=11.608, rec=0.178, cos=-0.009), tot_loss_proj:3.156 [t=0.26s]
prediction: ['[CLS] filmmakers project forgot to to forgotcreen anything school anything whose police poorly forgot as theygger ministerial drunk gang. loyalist presidential goatential project [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.528 (perp=11.826, rec=0.172, cos=-0.009), tot_loss_proj:3.211 [t=0.27s]
prediction: ['[CLS] filmmakers project forgot to to forgotcreen anything school anything whose police poorly forgot as they loyalist candidacy drunk gang.gger scary extremelyential project [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.364 (perp=11.136, rec=0.146, cos=-0.010), tot_loss_proj:3.064 [t=0.26s]
prediction: ['[CLS] filmmakers project forgot to to forgotcreen anything school anything whose police poorly forgot as theybies intogger gang. drunk scary extremelyential project [SEP]']
[ 450/2000] tot_loss=2.443 (perp=11.505, rec=0.150, cos=-0.009), tot_loss_proj:3.658 [t=0.26s]
prediction: ['[CLS] filmmakers project forgot include to forgotitaire anything school anything whose police poorly forgot as theygger intogger gang. drunk scary extremely into project [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.283 (perp=10.798, rec=0.133, cos=-0.010), tot_loss_proj:3.376 [t=0.26s]
prediction: ['[CLS] filmmakers project forgot include to forgotitaire anything school scary whose scary poorly forgot as theygger intogger gang. extremely scary drunk into project [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.156 (perp=10.135, rec=0.138, cos=-0.009), tot_loss_proj:3.614 [t=0.26s]
prediction: ['[CLS] filmmakers project to include the evenitaire anything school scary whose scary poorly forgot as theygger intogger gang. extremely attraction drunk into project [SEP]']
[ 600/2000] tot_loss=2.264 (perp=10.729, rec=0.128, cos=-0.010), tot_loss_proj:3.729 [t=0.26s]
prediction: ['[CLS] filmmakers channel to include the even attraction anything school scary whose scary poorly forgot as theygger intogger b. extremely attraction drunk into project [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.215 (perp=10.496, rec=0.125, cos=-0.010), tot_loss_proj:3.601 [t=0.27s]
prediction: ['[CLS] attraction projects to include the even attraction anything school scary whose scary poorly forgot asjigger intogger b. extremely filmmakers drunk into project [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.208 (perp=10.446, rec=0.128, cos=-0.010), tot_loss_proj:3.751 [t=0.25s]
prediction: ['[CLS] attraction to researchers include the even attraction anything school scary whose scary poorly forgot asjigger intogger b. extremely filmmakers drunk into project [SEP]']
[ 750/2000] tot_loss=2.275 (perp=10.855, rec=0.114, cos=-0.010), tot_loss_proj:3.858 [t=0.28s]
prediction: ['[CLS] attraction to shine include the even attraction anything school scary whose scary poorly forgot asjigger intogger b. extremely filmmakers drunk into project [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.252 (perp=10.700, rec=0.122, cos=-0.010), tot_loss_proj:3.636 [t=0.26s]
prediction: ['[CLS] attraction to shine even include the attraction anything school scary whose scary poorly forgot asjigger intogger fatal. extremely filmmakers drunk into project [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.204 (perp=10.503, rec=0.113, cos=-0.010), tot_loss_proj:3.668 [t=0.27s]
prediction: ['[CLS] attraction to shine even include the attraction anything school scary whose scary poorly forgot asjiggergger into fatal. extremely filmmakers drunk into project [SEP]']
[ 900/2000] tot_loss=2.158 (perp=10.235, rec=0.120, cos=-0.010), tot_loss_proj:3.347 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction anything school scary whose scary poorly forgot asjiggergger into fatal. extremely filmmakers drunk into setting [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.120 (perp=10.096, rec=0.110, cos=-0.010), tot_loss_proj:3.603 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction anything school scary whose scary poorly forgot asjiggergger into drunk. extremely filmmakers fatal into setting [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.090 (perp=9.942, rec=0.112, cos=-0.010), tot_loss_proj:3.536 [t=0.27s]
prediction: ['[CLS] attraction to they even include the attraction school anything scary whose scary poorly forgot asjiggergger into drunk. extremely filmmakers fatal into setting [SEP]']
[1050/2000] tot_loss=2.117 (perp=10.065, rec=0.113, cos=-0.010), tot_loss_proj:3.648 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scary whose scary poorly forgot asjiggergger into drunk. high filmmakers fatal into setting [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.066 (perp=9.860, rec=0.104, cos=-0.010), tot_loss_proj:3.578 [t=0.25s]
prediction: ['[CLS] attraction to they even include the attraction school anything scary whose scary poorly forgot asjiggergger into drunk filmmakers. high fatal into setting [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.097 (perp=9.981, rec=0.110, cos=-0.010), tot_loss_proj:3.614 [t=0.27s]
prediction: ['[CLS] attraction to they even include its attraction school anything scary whose scary poorly forgot as filmmakersjiggergger into drunk. high fatal into setting [SEP]']
[1200/2000] tot_loss=2.079 (perp=9.981, rec=0.093, cos=-0.010), tot_loss_proj:3.614 [t=0.27s]
prediction: ['[CLS] attraction to they even include its attraction school anything scary whose scary poorly forgot as filmmakersjiggergger into drunk. high fatal into setting [SEP]']
Attempt swap
[1250/2000] tot_loss=2.086 (perp=9.981, rec=0.099, cos=-0.010), tot_loss_proj:3.614 [t=0.26s]
prediction: ['[CLS] attraction to they even include its attraction school anything scary whose scary poorly forgot as filmmakersjiggergger into drunk. high fatal into setting [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.110 (perp=10.092, rec=0.101, cos=-0.009), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] attraction to they even include its attraction school anything scarygingly they as poorly forgot filmmakersjiggergger into drunk. high fatal into setting [SEP]']
[1350/2000] tot_loss=2.136 (perp=10.223, rec=0.102, cos=-0.010), tot_loss_proj:3.345 [t=0.26s]
prediction: ['[CLS] attraction to they even include its attraction school anything scarygingly scary as poorly forgot filmmakersjiggergger fatal drunk. high fatal into setting [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.049 (perp=9.774, rec=0.104, cos=-0.010), tot_loss_proj:3.138 [t=0.27s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly scary as poorly fatal filmmakersjiggergger forgot drunk. high fatal into setting [SEP]']
Attempt swap
[1450/2000] tot_loss=2.048 (perp=9.774, rec=0.103, cos=-0.010), tot_loss_proj:3.141 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly scary as poorly fatal filmmakersjiggergger forgot drunk. high fatal into setting [SEP]']
[1500/2000] tot_loss=2.050 (perp=9.774, rec=0.105, cos=-0.010), tot_loss_proj:3.141 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly scary as poorly fatal filmmakersjiggergger forgot drunk. high fatal into setting [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.038 (perp=9.706, rec=0.106, cos=-0.010), tot_loss_proj:3.105 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot drunk. high fatal into setting [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.029 (perp=9.708, rec=0.097, cos=-0.010), tot_loss_proj:3.191 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high fatal into setting [SEP]']
[1650/2000] tot_loss=2.036 (perp=9.708, rec=0.104, cos=-0.010), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high fatal into setting [SEP]']
Attempt swap
[1700/2000] tot_loss=2.033 (perp=9.708, rec=0.102, cos=-0.010), tot_loss_proj:3.194 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high fatal into setting [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.022 (perp=9.662, rec=0.099, cos=-0.010), tot_loss_proj:2.945 [t=0.27s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high into fatal setting [SEP]']
[1800/2000] tot_loss=2.020 (perp=9.662, rec=0.097, cos=-0.010), tot_loss_proj:2.948 [t=0.26s]
prediction: ['[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high into fatal setting [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.963 (perp=9.329, rec=0.107, cos=-0.009), tot_loss_proj:3.101 [t=0.27s]
prediction: ['[CLS] attraction to they even include fatal attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high into the setting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.956 (perp=9.329, rec=0.100, cos=-0.010), tot_loss_proj:3.097 [t=0.26s]
prediction: ['[CLS] attraction to they even include fatal attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high into the setting [SEP]']
[1950/2000] tot_loss=1.953 (perp=9.329, rec=0.097, cos=-0.010), tot_loss_proj:3.097 [t=0.26s]
prediction: ['[CLS] attraction to they even include fatal attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high into the setting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.953 (perp=9.329, rec=0.097, cos=-0.010), tot_loss_proj:3.100 [t=0.27s]
prediction: ['[CLS] attraction to they even include fatal attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high into the setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] attraction to they even include the attraction school anything scarygingly fatal as poorly scary filmmakersjiggergger forgot. drunk high fatal into setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 78.261 | r: 75.000
rouge2     | fm: 4.444 | p: 4.545 | r: 4.348
rougeL     | fm: 42.553 | p: 43.478 | r: 41.667
rougeLsum  | fm: 42.553 | p: 43.478 | r: 41.667
r1fm+r2fm = 81.040

[Aggregate metrics]:
rouge1     | fm: 88.669 | p: 88.086 | r: 89.371
rouge2     | fm: 59.970 | p: 59.744 | r: 60.264
rougeL     | fm: 78.484 | p: 78.052 | r: 79.044
rougeLsum  | fm: 78.272 | p: 77.768 | r: 78.809
r1fm+r2fm = 148.639

input #42 time: 0:11:04 | total time: 6:56:49


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
*********************************
*********************************
average of cosine similarity 0.9992732655805336
highest_index [0]
highest [0.9992732655805336]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9607493281364441 for ['[CLS] cuisine â€¢ dutchable [SEP]']
[Init] best rec loss: 0.9227121472358704 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8925204873085022 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8689665198326111 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8586649298667908 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.846950888633728 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8364328742027283 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7888320684432983 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7853228449821472 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7806761264801025 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 0.7801570892333984 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 0.7796530723571777 for ['[CLS] oxidation council enrollment deserved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.076 (perp=13.832, rec=0.316, cos=-0.006), tot_loss_proj:3.606 [t=0.28s]
prediction: ['[CLS] emptyomagyistic [SEP]']
[ 100/2000] tot_loss=2.128 (perp=9.570, rec=0.222, cos=-0.008), tot_loss_proj:2.681 [t=0.26s]
prediction: ['[CLS] emptyrcissistic [SEP]']
[ 150/2000] tot_loss=1.152 (perp=5.048, rec=0.150, cos=-0.008), tot_loss_proj:1.096 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.103 (perp=5.048, rec=0.102, cos=-0.009), tot_loss_proj:1.100 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.082 (perp=5.048, rec=0.082, cos=-0.009), tot_loss_proj:1.108 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.074 (perp=5.048, rec=0.073, cos=-0.009), tot_loss_proj:1.096 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.071 (perp=5.048, rec=0.071, cos=-0.009), tot_loss_proj:1.097 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.062 (perp=5.048, rec=0.062, cos=-0.009), tot_loss_proj:1.095 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.073 (perp=5.048, rec=0.072, cos=-0.009), tot_loss_proj:1.101 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.069 (perp=5.048, rec=0.069, cos=-0.009), tot_loss_proj:1.098 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.055 (perp=5.048, rec=0.055, cos=-0.009), tot_loss_proj:1.097 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.064 (perp=5.048, rec=0.063, cos=-0.009), tot_loss_proj:1.097 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.068 (perp=5.048, rec=0.068, cos=-0.009), tot_loss_proj:1.096 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.058 (perp=5.048, rec=0.058, cos=-0.009), tot_loss_proj:1.093 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.060 (perp=5.048, rec=0.060, cos=-0.009), tot_loss_proj:1.087 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.062 (perp=5.048, rec=0.061, cos=-0.009), tot_loss_proj:1.094 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.076 (perp=5.048, rec=0.076, cos=-0.009), tot_loss_proj:1.092 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.069 (perp=5.048, rec=0.068, cos=-0.009), tot_loss_proj:1.091 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.067 (perp=5.048, rec=0.067, cos=-0.009), tot_loss_proj:1.083 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.057 (perp=5.048, rec=0.056, cos=-0.009), tot_loss_proj:1.092 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.068 (perp=5.048, rec=0.068, cos=-0.009), tot_loss_proj:1.076 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.059 (perp=5.048, rec=0.058, cos=-0.009), tot_loss_proj:1.090 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.063 (perp=5.048, rec=0.063, cos=-0.009), tot_loss_proj:1.100 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.057 (perp=5.048, rec=0.057, cos=-0.009), tot_loss_proj:1.098 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.055 (perp=5.048, rec=0.055, cos=-0.009), tot_loss_proj:1.089 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.069 (perp=5.048, rec=0.069, cos=-0.009), tot_loss_proj:1.090 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.051 (perp=5.048, rec=0.050, cos=-0.009), tot_loss_proj:1.089 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.066 (perp=5.048, rec=0.066, cos=-0.009), tot_loss_proj:1.084 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.065 (perp=5.048, rec=0.064, cos=-0.009), tot_loss_proj:1.097 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.070 (perp=5.048, rec=0.069, cos=-0.009), tot_loss_proj:1.087 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.061 (perp=5.048, rec=0.060, cos=-0.009), tot_loss_proj:1.084 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.066 (perp=5.048, rec=0.065, cos=-0.009), tot_loss_proj:1.088 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.060 (perp=5.048, rec=0.060, cos=-0.009), tot_loss_proj:1.083 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.054 (perp=5.048, rec=0.054, cos=-0.009), tot_loss_proj:1.079 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.056 (perp=5.048, rec=0.056, cos=-0.009), tot_loss_proj:1.091 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.054 (perp=5.048, rec=0.054, cos=-0.009), tot_loss_proj:1.084 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.067 (perp=5.048, rec=0.067, cos=-0.009), tot_loss_proj:1.090 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.071 (perp=5.048, rec=0.071, cos=-0.009), tot_loss_proj:1.088 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.063 (perp=5.048, rec=0.063, cos=-0.009), tot_loss_proj:1.089 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.064 (perp=5.048, rec=0.063, cos=-0.009), tot_loss_proj:1.093 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.870 | p: 88.397 | r: 89.507
rouge2     | fm: 60.986 | p: 60.713 | r: 61.351
rougeL     | fm: 78.927 | p: 78.468 | r: 79.427
rougeLsum  | fm: 78.815 | p: 78.332 | r: 79.349
r1fm+r2fm = 149.856

input #43 time: 0:11:15 | total time: 7:08:05


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
*********************************
*********************************
average of cosine similarity 0.999241753470635
highest_index [0]
highest [0.999241753470635]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9856536388397217 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9538675546646118 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great Â¡wark grand [SEP]']
[Init] best rec loss: 0.9338456988334656 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9291354417800903 for ['[CLS]hat since shotsisance morning her wound ji living appealing fifapis aus braun filmed james saved ian service person alias motion inclination age storage hyper heard wind any [SEP]']
[Init] best rec loss: 0.9056149125099182 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.904999852180481 for ['[CLS] fatty formerly haley ltd raceway nation brow harbor slavehair intent contact hello ; contains contestants heeosi data graphic capacity settled landon blue comedy rock s co illustrated [SEP]']
[Init] best perm rec loss: 0.9043598175048828 for ['[CLS] s comedyosi slave ltd co contestants contains hello graphic settled capacity hee intent ; contact formerly brow landon blue data illustrated rock nationhair harbor haley fatty raceway [SEP]']
[Init] best perm rec loss: 0.903514564037323 for ['[CLS] comedyhair settled intent contestants capacity contact contains hello rock data nation brow formerly ; hee co blueosi graphic fatty illustrated raceway ltd slave s landon haley harbor [SEP]']
[Init] best perm rec loss: 0.90308678150177 for ['[CLS] graphic contains comedy settled raceway ; intent hee hello slave contact fatty brow ltd s capacityosi formerly rock co data illustratedhair harbor contestants landon haley blue nation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.819 (perp=12.691, rec=0.289, cos=-0.009), tot_loss_proj:3.311 [t=0.26s]
prediction: ["[CLS] mongolian fat wasted nadia lost nearly lost explanations lost cover hoffman abandoned segment sept'attempt devoid avoid absurd signing report |ted murder actually is lossulentization [SEP]"]
[ 100/2000] tot_loss=2.341 (perp=10.772, rec=0.196, cos=-0.009), tot_loss_proj:2.736 [t=0.26s]
prediction: ['[CLS] slack was wasted translation translation nearly lost in lost translation translation routine segmentes routine fright devoid the absurd execution execution theted damon actually routine losesefined attack [SEP]']
[ 150/2000] tot_loss=2.094 (perp=9.849, rec=0.134, cos=-0.010), tot_loss_proj:2.480 [t=0.25s]
prediction: ['[CLS] slack been hollywood translation translation nearly lost in lost translation routine routinefest whose routine frightalic the slack execution routine the slack hollywood a.ity premise. [SEP]']
[ 200/2000] tot_loss=2.199 (perp=10.355, rec=0.137, cos=-0.009), tot_loss_proj:2.613 [t=0.27s]
prediction: ['[CLS] slack been hollywood translation translationcut lost in lost translation routine routinefest which routine frightalic the slack executionfest the slack hollywood a.ity premise. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.179 (perp=10.344, rec=0.119, cos=-0.009), tot_loss_proj:2.677 [t=0.26s]
prediction: ['[CLS] slack been another translation translationcut lost in lost translation routine routinefest which routine frightalic the slack executionfest the. hollywood the hollywoodity premise. [SEP]']
[ 300/2000] tot_loss=2.090 (perp=9.949, rec=0.110, cos=-0.009), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] slack been another translation publicationut lost in in translation routine routinefest which routine frightalic the slack executionizes the. hollywood. hollywoodizes premise. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.141 (perp=10.243, rec=0.102, cos=-0.010), tot_loss_proj:2.731 [t=0.26s]
prediction: ['[CLS] slack been anotherotic atut lost in in translation routine routinefest which routine frightalic the slack executionizes hollywood. hollywood. theizes premise. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.915 (perp=9.124, rec=0.100, cos=-0.009), tot_loss_proj:2.625 [t=0.26s]
prediction: ['[CLS] slack has another idea publication in. lost in translation routine routinefest which routine frightalic the slack executionizes hollywood. hollywood. theizes premise. [SEP]']
[ 450/2000] tot_loss=1.981 (perp=9.543, rec=0.082, cos=-0.010), tot_loss_proj:2.596 [t=0.27s]
prediction: ['[CLS] slack been another idea it.. lost in translation routine routinefest which routine frightalic the slack executionizes hollywood.fest. theizes premise. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.848 (perp=8.830, rec=0.092, cos=-0.010), tot_loss_proj:2.601 [t=0.27s]
prediction: ['[CLS] slack has another idea... lost in translation routine routinefest which routine frightalic the slack executionizes hollywood.fest it theizes premise. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.858 (perp=8.906, rec=0.086, cos=-0.010), tot_loss_proj:2.483 [t=0.26s]
prediction: ['[CLS] slack has another authorship... lost in translation routine routine routine whichfest frightalic the slack executionizes hollywood.fest it theizes premise. [SEP]']
[ 600/2000] tot_loss=1.833 (perp=8.855, rec=0.071, cos=-0.010), tot_loss_proj:2.467 [t=0.26s]
prediction: ['[CLS] slack has another authorship... lost in translation routine routine routine whichfest frightalic the absurd executionizes hollywood.fest it theizes premise. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.706 (perp=8.144, rec=0.086, cos=-0.010), tot_loss_proj:2.270 [t=0.26s]
prediction: ['[CLS] slack has another of... lost in translation routine routine routine whichfest frightalic the absurd executionizes hollywood. the hollywood itizes premise. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.632 (perp=7.756, rec=0.090, cos=-0.010), tot_loss_proj:2.122 [t=0.27s]
prediction: ['[CLS] slack has another of... lost in translation. routine routine whichfest fright hollywood the absurd executionizes hollywood. thealic itizes premise. [SEP]']
[ 750/2000] tot_loss=1.750 (perp=8.402, rec=0.079, cos=-0.010), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS] slack has another of. been. lost in translation. routine routine whichfest fright hollywood the absurd execution it hollywood. thealic itizes premise. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.738 (perp=8.312, rec=0.085, cos=-0.010), tot_loss_proj:2.210 [t=0.25s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest fright hollywood the absurd execution the it hollywood. thealic itizes premise. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.701 (perp=8.127, rec=0.085, cos=-0.010), tot_loss_proj:2.212 [t=0.25s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest of fright hollywood the absurd execution it hollywood. thealic itizes premise. [SEP]']
[ 900/2000] tot_loss=1.690 (perp=8.139, rec=0.072, cos=-0.010), tot_loss_proj:2.220 [t=0.27s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest of fright hollywood the absurd execution it hollywood. thealic inizes premise. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.712 (perp=8.259, rec=0.070, cos=-0.010), tot_loss_proj:2.274 [t=0.26s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest the fright hollywood the absurd execution it hollywood. thealicizesity premise. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.675 (perp=8.072, rec=0.071, cos=-0.010), tot_loss_proj:2.141 [t=0.25s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest the fright hollywood the absurd execution itity. thealicizes hollywood premise. [SEP]']
[1050/2000] tot_loss=1.677 (perp=8.072, rec=0.072, cos=-0.010), tot_loss_proj:2.143 [t=0.26s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest the fright hollywood the absurd execution itity. thealicizes hollywood premise. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.663 (perp=7.996, rec=0.073, cos=-0.010), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest of fright hollywood hollywood absurd execution itity. thealicizes the premise. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.582 (perp=7.581, rec=0.075, cos=-0.010), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest the fright hollywood hollywood absurd executionity. the italicizes the premise. [SEP]']
[1200/2000] tot_loss=1.579 (perp=7.581, rec=0.073, cos=-0.010), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] slack has another. been. lost in translation. routine routine whichfest the fright hollywood hollywood absurd executionity. the italicizes the premise. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.532 (perp=7.320, rec=0.078, cos=-0.010), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] slack has another. been hollywood. lost in translation. routine routine whichfest the fright hollywood absurd executionity. the italicizes the premise. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.489 (perp=7.153, rec=0.068, cos=-0.010), tot_loss_proj:1.991 [t=0.26s]
prediction: ['[CLS] slack has another. been hollywood. lost in translation. routine routine whichfest the hollywood absurd executionity. the fright italicizes the premise. [SEP]']
[1350/2000] tot_loss=1.482 (perp=7.121, rec=0.068, cos=-0.010), tot_loss_proj:1.976 [t=0.29s]
prediction: ['[CLS] slack has another. been hollywood. lost in translation. routine routine whichfest the hollywood absurd execution in. the fright italicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.400 (perp=6.689, rec=0.072, cos=-0.010), tot_loss_proj:1.933 [t=0.27s]
prediction: ['[CLS] slack has another. been hollywood. lost in translation. routine routine whichfest the hollywood absurd. in execution the fright italicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.395 (perp=6.675, rec=0.070, cos=-0.010), tot_loss_proj:1.897 [t=0.29s]
prediction: ['[CLS] slack has another. been hollywood. lost in translation. routine routine whichfest the hollywood absurd. in the execution fright italicizes the premise. [SEP]']
[1500/2000] tot_loss=1.511 (perp=7.224, rec=0.075, cos=-0.010), tot_loss_proj:1.987 [t=0.28s]
prediction: ['[CLS] slack has another. beenfest. lost in translation. routine routine whichfest the hollywood absurd. in the execution fright italicizes the premise. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.491 (perp=7.129, rec=0.075, cos=-0.010), tot_loss_proj:1.920 [t=0.29s]
prediction: ['[CLS] slack has another. beenfest. lost in translation. the routine routine whichfest hollywood absurd. in the execution fright italicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.474 (perp=7.061, rec=0.071, cos=-0.010), tot_loss_proj:1.996 [t=0.29s]
prediction: ['[CLS] slack has another. beenfest. lost in translation. hollywood routine routine whichfest the absurd. in the execution fright italicizes the premise. [SEP]']
[1650/2000] tot_loss=1.475 (perp=7.061, rec=0.073, cos=-0.010), tot_loss_proj:1.984 [t=0.30s]
prediction: ['[CLS] slack has another. beenfest. lost in translation. hollywood routine routine whichfest the absurd. in the execution fright italicizes the premise. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.441 (perp=6.878, rec=0.075, cos=-0.010), tot_loss_proj:1.934 [t=0.28s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine whichfest the absurd. in the execution fright italicizes the premise. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.404 (perp=6.722, rec=0.070, cos=-0.010), tot_loss_proj:1.873 [t=0.28s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]']
[1800/2000] tot_loss=1.410 (perp=6.722, rec=0.075, cos=-0.010), tot_loss_proj:1.868 [t=0.29s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.402 (perp=6.722, rec=0.067, cos=-0.010), tot_loss_proj:1.865 [t=0.28s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.419 (perp=6.722, rec=0.084, cos=-0.010), tot_loss_proj:1.876 [t=0.29s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]']
[1950/2000] tot_loss=1.406 (perp=6.722, rec=0.071, cos=-0.010), tot_loss_proj:1.872 [t=0.31s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.400 (perp=6.722, rec=0.065, cos=-0.010), tot_loss_proj:1.872 [t=0.29s]
prediction: ['[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] slack has another. been routine. lost in translation. hollywoodfest routine which frightfest the absurd. in the execution italicizes the premise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 86.364 | r: 82.609
rouge2     | fm: 27.907 | p: 28.571 | r: 27.273
rougeL     | fm: 66.667 | p: 68.182 | r: 65.217
rougeLsum  | fm: 66.667 | p: 68.182 | r: 65.217
r1fm+r2fm = 112.351

[Aggregate metrics]:
rouge1     | fm: 88.762 | p: 88.262 | r: 89.359
rouge2     | fm: 60.022 | p: 59.737 | r: 60.368
rougeL     | fm: 78.769 | p: 78.314 | r: 79.261
rougeLsum  | fm: 78.398 | p: 78.024 | r: 78.895
r1fm+r2fm = 148.784

input #44 time: 0:11:12 | total time: 7:19:17


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
*********************************
*********************************
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9825860261917114 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher Â® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9404022693634033 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9185224771499634 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9133827090263367 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing Å‚ wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.903794527053833 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.9032831192016602 for ['[CLS] circussome nj lodge photoá…µ bioome kg morning. have interviewrcus account winfield letofan shy broken man floor sunday sack tuneenter station ll [SEP]']
[Init] best rec loss: 0.8698243498802185 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8686729073524475 for ['[CLS] skinlanda ( whoa tree ku entrance special five bore2 via curtis operated murmured v status letter few enclosed gentry joan around military single taste footballtiv [SEP]']
[Init] best perm rec loss: 0.8660717606544495 for ['[CLS] single (tiv tree around v entrance letter bore ku operated football enclosed curtislanda five military taste joan status murmured skin2 via few special gentry whoa [SEP]']
[Init] best perm rec loss: 0.8620867133140564 for ['[CLS] five footballtiv2 taste military ku via single skin status few enclosed special curtis murmured whoa entrancelanda ( tree joan around bore letter v gentry operated [SEP]']
[Init] best perm rec loss: 0.861274242401123 for ['[CLS] murmured2 single taste via skintiv curtis whoa tree v football entrancelanda ku joan five status bore letter few around ( enclosed special operated military gentry [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.947 (perp=12.821, rec=0.390, cos=-0.007), tot_loss_proj:3.538 [t=0.28s]
prediction: ['[CLS] nme pickg airnic - than probably junk assistant if hide hole stupid paper pub synthetic on equipment train ago loan question die? shop traffic aloud [SEP]']
[ 100/2000] tot_loss=2.528 (perp=11.073, rec=0.321, cos=-0.007), tot_loss_proj:3.156 [t=0.28s]
prediction: ['[CLS] mcmillan thang body wiener - than - junk fraud than shoot mp nec - much use - equipment train than tag issue die - shop shoots aloud [SEP]']
[ 150/2000] tot_loss=2.489 (perp=11.150, rec=0.268, cos=-0.009), tot_loss_proj:3.011 [t=0.29s]
prediction: ['[CLS] mcmillan thanf getting wiener - than - junk exercise than shoot full bow - much use - shelf - for shelf issue - - surface movements aloud [SEP]']
[ 200/2000] tot_loss=2.274 (perp=10.202, rec=0.243, cos=-0.009), tot_loss_proj:2.758 [t=0.29s]
prediction: ['[CLS] mcmillan - aa getting charley - than - junk exercise than shoot give bowel die use in shelf - for shelf issue - - surface movements than [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.000 (perp=9.019, rec=0.205, cos=-0.009), tot_loss_proj:2.462 [t=0.31s]
prediction: ['[CLS] bow - - that charley - than - junk exercise than shoot - bowel fake this in shelf - to shelf issue -k shelf movements than [SEP]']
[ 300/2000] tot_loss=2.166 (perp=10.063, rec=0.163, cos=-0.009), tot_loss_proj:2.697 [t=0.28s]
prediction: ['[CLS] bow - - movementsscopic - than - junk exercise than shoot - bowel short this in shelf - to shelf mc -im shelf movements than [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.115 (perp=9.822, rec=0.161, cos=-0.010), tot_loss_proj:2.668 [t=0.31s]
prediction: ['[CLS] bow - - movements in - than - junk exercise than shoot - bowel short this kung shelf on long shelf mc -im shelf movements than [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.067 (perp=9.656, rec=0.146, cos=-0.010), tot_loss_proj:2.611 [t=0.28s]
prediction: ['[CLS] gi - - movements in - than - junk exercise than shoot - bowel drama this kung point on long shelf shelf -z shelf movements than [SEP]']
[ 450/2000] tot_loss=2.176 (perp=10.289, rec=0.128, cos=-0.010), tot_loss_proj:2.734 [t=0.28s]
prediction: ['[CLS] gi - -el in - than - junk exercise than shoot - bowel drama this charley point shoot long shelf shelf -ick shelf movements than [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.028 (perp=9.583, rec=0.121, cos=-0.009), tot_loss_proj:2.702 [t=0.31s]
prediction: ['[CLS] gi - -el in - than - junk exercise than shoot - bowel drama thisel point - long shelf shoot onmm shelf movements drama [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.072 (perp=9.826, rec=0.116, cos=-0.009), tot_loss_proj:2.875 [t=0.29s]
prediction: ['[CLS] gi - -el in - than - junk exercise than shoot - bowel dramammel point gi long shelf shoot on this shelf movements drama [SEP]']
[ 600/2000] tot_loss=2.039 (perp=9.662, rec=0.116, cos=-0.010), tot_loss_proj:3.154 [t=0.29s]
prediction: ['[CLS] gi - -el in - than - shoot exercise than shoot - bowel dramammel point gi long shelf shoot on this shelf movements drama [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.959 (perp=9.237, rec=0.121, cos=-0.010), tot_loss_proj:3.024 [t=0.29s]
prediction: ['[CLS] gi - - movements in - than - shoot exercise than shoot - bowel dramammel point gi long shelf shoot on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.954 (perp=9.224, rec=0.119, cos=-0.010), tot_loss_proj:3.111 [t=0.28s]
prediction: ['[CLS] gi - - movements in - than a - exercise than shoot - bowel dramammel point gi longick shoot on this shelfel drama [SEP]']
[ 750/2000] tot_loss=1.942 (perp=9.224, rec=0.107, cos=-0.010), tot_loss_proj:3.117 [t=0.29s]
prediction: ['[CLS] gi - - movements in - than a - exercise than shoot - bowel dramammel point gi longick shoot on this shelfel drama [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.909 (perp=9.086, rec=0.102, cos=-0.010), tot_loss_proj:3.081 [t=0.29s]
prediction: ['[CLS] gi - - movements in - than a exercise - than shoot - bowel dramammel point gi longick shoot on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.758 (perp=8.349, rec=0.098, cos=-0.009), tot_loss_proj:2.325 [t=0.29s]
prediction: ['[CLS] gi - - movements in - than a exercise - than shoot - bowel drama longel point gimmick shoot on this shelfel drama [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.339, rec=0.098, cos=-0.010), tot_loss_proj:2.382 [t=0.29s]
prediction: ['[CLS] gi - - movements in - than shoot exercise - than shoot - bowel drama longel point gimmick shoot on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.717 (perp=8.100, rec=0.107, cos=-0.010), tot_loss_proj:2.400 [t=0.28s]
prediction: ['[CLS] gi - - movements in - than shoot exercise - than shoot - bowel drama long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.650 (perp=7.747, rec=0.111, cos=-0.010), tot_loss_proj:2.299 [t=0.29s]
prediction: ['[CLS] gi - drama movements in - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
[1050/2000] tot_loss=1.632 (perp=7.747, rec=0.092, cos=-0.010), tot_loss_proj:2.307 [t=0.29s]
prediction: ['[CLS] gi - drama movements in - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.609 (perp=7.652, rec=0.088, cos=-0.010), tot_loss_proj:2.299 [t=0.30s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
[1150/2000] tot_loss=1.608 (perp=7.652, rec=0.088, cos=-0.010), tot_loss_proj:2.297 [t=0.29s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
[1200/2000] tot_loss=1.610 (perp=7.652, rec=0.090, cos=-0.010), tot_loss_proj:2.305 [t=0.30s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
[1250/2000] tot_loss=1.609 (perp=7.652, rec=0.089, cos=-0.010), tot_loss_proj:2.304 [t=0.30s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
[1300/2000] tot_loss=1.609 (perp=7.652, rec=0.088, cos=-0.010), tot_loss_proj:2.299 [t=0.31s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
[1350/2000] tot_loss=1.611 (perp=7.652, rec=0.091, cos=-0.010), tot_loss_proj:2.300 [t=0.30s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
[1400/2000] tot_loss=1.607 (perp=7.652, rec=0.087, cos=-0.010), tot_loss_proj:2.300 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
[1450/2000] tot_loss=1.612 (perp=7.652, rec=0.091, cos=-0.010), tot_loss_proj:2.298 [t=0.25s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
[1500/2000] tot_loss=1.608 (perp=7.652, rec=0.087, cos=-0.010), tot_loss_proj:2.299 [t=0.27s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
[1550/2000] tot_loss=1.609 (perp=7.652, rec=0.089, cos=-0.010), tot_loss_proj:2.301 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.526 (perp=7.225, rec=0.091, cos=-0.010), tot_loss_proj:2.254 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot point gimmick - on this shelfel drama [SEP]']
[1650/2000] tot_loss=1.528 (perp=7.225, rec=0.093, cos=-0.010), tot_loss_proj:2.249 [t=0.28s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot point gimmick - on this shelfel drama [SEP]']
Attempt swap
[1700/2000] tot_loss=1.577 (perp=7.505, rec=0.085, cos=-0.010), tot_loss_proj:2.603 [t=0.27s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot point andmmick - on this shelfel drama [SEP]']
Attempt swap
[1750/2000] tot_loss=1.688 (perp=8.049, rec=0.088, cos=-0.010), tot_loss_proj:2.847 [t=0.27s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot point andmmmm - on this shelfel drama [SEP]']
[1800/2000] tot_loss=1.690 (perp=8.049, rec=0.090, cos=-0.010), tot_loss_proj:2.848 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot point andmmmm - on this shelfel drama [SEP]']
Attempt swap
[1850/2000] tot_loss=1.688 (perp=8.049, rec=0.088, cos=-0.010), tot_loss_proj:2.848 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot point andmmmm - on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.645 (perp=7.835, rec=0.088, cos=-0.010), tot_loss_proj:2.856 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot - andmmmm point on this shelfel drama [SEP]']
[1950/2000] tot_loss=1.656 (perp=7.835, rec=0.099, cos=-0.010), tot_loss_proj:2.856 [t=0.26s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shoot - andmmmm point on this shelfel drama [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.606 (perp=7.631, rec=0.090, cos=-0.010), tot_loss_proj:2.844 [t=0.27s]
prediction: ['[CLS] gi - drama in movements - than shoot exercise - than shootel bowel - long shootel andmmmm point on this shelf - drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] gi - drama in movements - than shoot exercise - than shoot - bowel - long shoot point gimmickel on this shelfel drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.421 | p: 65.000 | r: 72.222
rouge2     | fm: 16.667 | p: 15.789 | r: 17.647
rougeL     | fm: 36.842 | p: 35.000 | r: 38.889
rougeLsum  | fm: 36.842 | p: 35.000 | r: 38.889
r1fm+r2fm = 85.088

[Aggregate metrics]:
rouge1     | fm: 88.267 | p: 87.714 | r: 88.930
rouge2     | fm: 59.198 | p: 59.004 | r: 59.573
rougeL     | fm: 77.700 | p: 77.291 | r: 78.232
rougeLsum  | fm: 77.467 | p: 76.998 | r: 77.963
r1fm+r2fm = 147.465

input #45 time: 0:11:27 | total time: 7:30:44


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
*********************************
*********************************
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9911298155784607 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792498350143433 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9472112059593201 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9385618567466736 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9372692704200745 for ['[CLS] political m act paperrton fitz [SEP]']
[Init] best rec loss: 0.9318523406982422 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9173271059989929 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best perm rec loss: 0.9158892631530762 for ['[CLS] four donald canada reed and no [SEP]']
[Init] best perm rec loss: 0.9147517085075378 for ['[CLS] donald and four reed no canada [SEP]']
[Init] best perm rec loss: 0.9115938544273376 for ['[CLS] four reed canada and donald no [SEP]']
[Init] best perm rec loss: 0.9111836552619934 for ['[CLS] donald reed canada four no and [SEP]']
[Init] best perm rec loss: 0.9108540415763855 for ['[CLS] and reed donald four no canada [SEP]']
[Init] best perm rec loss: 0.9107707142829895 for ['[CLS] donald and canada no four reed [SEP]']
[Init] best perm rec loss: 0.9106481671333313 for ['[CLS] four reed no donald canada and [SEP]']
[Init] best perm rec loss: 0.9093884825706482 for ['[CLS] and reed no donald canada four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.288 (perp=10.412, rec=0.213, cos=-0.008), tot_loss_proj:2.452 [t=0.25s]
prediction: ['[CLS] striking visually striking teamed slick slick [SEP]']
[ 100/2000] tot_loss=1.863 (perp=8.653, rec=0.141, cos=-0.008), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS]ly visually strikingly slick staged [SEP]']
[ 150/2000] tot_loss=1.811 (perp=8.653, rec=0.089, cos=-0.009), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS]ly visually strikingly slick staged [SEP]']
[ 200/2000] tot_loss=1.806 (perp=8.653, rec=0.085, cos=-0.009), tot_loss_proj:1.990 [t=0.25s]
prediction: ['[CLS]ly visually strikingly slick staged [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.242 (perp=5.916, rec=0.068, cos=-0.009), tot_loss_proj:1.234 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 300/2000] tot_loss=1.240 (perp=5.916, rec=0.066, cos=-0.009), tot_loss_proj:1.244 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.240 (perp=5.916, rec=0.065, cos=-0.009), tot_loss_proj:1.242 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.241 (perp=5.916, rec=0.066, cos=-0.009), tot_loss_proj:1.243 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.241 (perp=5.916, rec=0.067, cos=-0.009), tot_loss_proj:1.235 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.233 (perp=5.916, rec=0.058, cos=-0.009), tot_loss_proj:1.233 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.240 (perp=5.916, rec=0.066, cos=-0.009), tot_loss_proj:1.235 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.232 (perp=5.916, rec=0.058, cos=-0.009), tot_loss_proj:1.238 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.233 (perp=5.916, rec=0.059, cos=-0.009), tot_loss_proj:1.236 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.236 (perp=5.916, rec=0.062, cos=-0.009), tot_loss_proj:1.234 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.238 (perp=5.916, rec=0.064, cos=-0.009), tot_loss_proj:1.240 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.234 (perp=5.916, rec=0.060, cos=-0.009), tot_loss_proj:1.237 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.222 (perp=5.916, rec=0.048, cos=-0.009), tot_loss_proj:1.232 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.244 (perp=5.916, rec=0.070, cos=-0.009), tot_loss_proj:1.238 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.230 (perp=5.916, rec=0.055, cos=-0.009), tot_loss_proj:1.237 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.224 (perp=5.916, rec=0.050, cos=-0.009), tot_loss_proj:1.233 [t=0.28s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.241 (perp=5.916, rec=0.067, cos=-0.009), tot_loss_proj:1.239 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.239 (perp=5.916, rec=0.065, cos=-0.009), tot_loss_proj:1.232 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.241 (perp=5.916, rec=0.067, cos=-0.009), tot_loss_proj:1.252 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.244 (perp=5.916, rec=0.070, cos=-0.009), tot_loss_proj:1.241 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.229 (perp=5.916, rec=0.055, cos=-0.009), tot_loss_proj:1.239 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.248 (perp=5.916, rec=0.074, cos=-0.009), tot_loss_proj:1.237 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.231 (perp=5.916, rec=0.056, cos=-0.009), tot_loss_proj:1.245 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.237 (perp=5.916, rec=0.063, cos=-0.009), tot_loss_proj:1.235 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.232 (perp=5.916, rec=0.058, cos=-0.009), tot_loss_proj:1.241 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.238 (perp=5.916, rec=0.064, cos=-0.009), tot_loss_proj:1.246 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.222 (perp=5.916, rec=0.048, cos=-0.009), tot_loss_proj:1.238 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.244 (perp=5.916, rec=0.070, cos=-0.009), tot_loss_proj:1.233 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.230 (perp=5.916, rec=0.056, cos=-0.009), tot_loss_proj:1.236 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.237 (perp=5.916, rec=0.063, cos=-0.009), tot_loss_proj:1.241 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.238 (perp=5.916, rec=0.064, cos=-0.009), tot_loss_proj:1.242 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.233 (perp=5.916, rec=0.059, cos=-0.009), tot_loss_proj:1.228 [t=0.29s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.226 (perp=5.916, rec=0.052, cos=-0.009), tot_loss_proj:1.228 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.234 (perp=5.916, rec=0.060, cos=-0.009), tot_loss_proj:1.230 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.233 (perp=5.916, rec=0.058, cos=-0.009), tot_loss_proj:1.236 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.228 (perp=5.916, rec=0.054, cos=-0.009), tot_loss_proj:1.238 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.542 | p: 88.032 | r: 89.230
rouge2     | fm: 60.235 | p: 59.996 | r: 60.568
rougeL     | fm: 78.015 | p: 77.532 | r: 78.563
rougeLsum  | fm: 78.103 | p: 77.649 | r: 78.729
r1fm+r2fm = 148.777

input #46 time: 0:10:53 | total time: 7:41:37


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
*********************************
*********************************
average of cosine similarity 0.9992059059142621
highest_index [0]
highest [0.9992059059142621]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6953830718994141 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6925281286239624 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6903731226921082 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6853982210159302 for ['[CLS] purse divine rush [SEP]']
[Init] best rec loss: 0.6800500154495239 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.6800178289413452 for ['[CLS] circles hand school [SEP]']
[Init] best rec loss: 0.67453533411026 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6720250844955444 for ['[CLS] salt reality poles [SEP]']
[Init] best perm rec loss: 0.668911337852478 for ['[CLS] poles salt reality [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.877 (perp=12.763, rec=0.321, cos=0.003), tot_loss_proj:3.527 [t=0.26s]
prediction: ['[CLS]right transparent translucent [SEP]']
[ 100/2000] tot_loss=2.700 (perp=12.488, rec=0.210, cos=-0.007), tot_loss_proj:3.373 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.648 (perp=12.488, rec=0.153, cos=-0.003), tot_loss_proj:3.373 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.625 (perp=12.488, rec=0.135, cos=-0.007), tot_loss_proj:3.381 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.605 (perp=12.488, rec=0.117, cos=-0.009), tot_loss_proj:3.383 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.619 (perp=12.488, rec=0.124, cos=-0.002), tot_loss_proj:3.394 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.598 (perp=12.488, rec=0.109, cos=-0.008), tot_loss_proj:3.402 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.588 (perp=12.488, rec=0.099, cos=-0.010), tot_loss_proj:3.400 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.598 (perp=12.488, rec=0.109, cos=-0.009), tot_loss_proj:3.404 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.581 (perp=12.488, rec=0.092, cos=-0.009), tot_loss_proj:3.413 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.581 (perp=12.488, rec=0.093, cos=-0.010), tot_loss_proj:3.414 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=2.586 (perp=12.488, rec=0.098, cos=-0.009), tot_loss_proj:3.422 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.585 (perp=12.488, rec=0.097, cos=-0.009), tot_loss_proj:3.430 [t=0.26s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.581 (perp=12.488, rec=0.092, cos=-0.009), tot_loss_proj:3.419 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 750/2000] tot_loss=2.583 (perp=12.488, rec=0.094, cos=-0.009), tot_loss_proj:3.424 [t=0.25s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.845 (perp=8.803, rec=0.094, cos=-0.010), tot_loss_proj:1.820 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.840 (perp=8.803, rec=0.089, cos=-0.010), tot_loss_proj:1.810 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.842 (perp=8.803, rec=0.091, cos=-0.010), tot_loss_proj:1.819 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.811 (perp=8.803, rec=0.060, cos=-0.010), tot_loss_proj:1.818 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.824 (perp=8.803, rec=0.073, cos=-0.010), tot_loss_proj:1.812 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.832 (perp=8.803, rec=0.082, cos=-0.010), tot_loss_proj:1.820 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.815 (perp=8.803, rec=0.065, cos=-0.010), tot_loss_proj:1.821 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.819 (perp=8.803, rec=0.068, cos=-0.010), tot_loss_proj:1.815 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.814 (perp=8.803, rec=0.063, cos=-0.010), tot_loss_proj:1.829 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.818 (perp=8.803, rec=0.068, cos=-0.010), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=8.803, rec=0.066, cos=-0.010), tot_loss_proj:1.815 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.813 (perp=8.803, rec=0.062, cos=-0.010), tot_loss_proj:1.821 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.814 (perp=8.803, rec=0.063, cos=-0.010), tot_loss_proj:1.823 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.817 (perp=8.803, rec=0.066, cos=-0.010), tot_loss_proj:1.810 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.824 (perp=8.803, rec=0.073, cos=-0.010), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.822 (perp=8.803, rec=0.071, cos=-0.010), tot_loss_proj:1.814 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.825 (perp=8.803, rec=0.074, cos=-0.010), tot_loss_proj:1.827 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.815 (perp=8.803, rec=0.064, cos=-0.010), tot_loss_proj:1.809 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.805 (perp=8.803, rec=0.055, cos=-0.010), tot_loss_proj:1.822 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.815 (perp=8.803, rec=0.064, cos=-0.010), tot_loss_proj:1.818 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.812 (perp=8.803, rec=0.062, cos=-0.010), tot_loss_proj:1.822 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.830 (perp=8.803, rec=0.079, cos=-0.010), tot_loss_proj:1.806 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.812 (perp=8.803, rec=0.061, cos=-0.010), tot_loss_proj:1.819 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.811 (perp=8.803, rec=0.060, cos=-0.010), tot_loss_proj:1.821 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.811 (perp=8.803, rec=0.060, cos=-0.010), tot_loss_proj:1.818 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.787 | p: 88.281 | r: 89.381
rouge2     | fm: 61.149 | p: 60.943 | r: 61.383
rougeL     | fm: 78.735 | p: 78.214 | r: 79.261
rougeLsum  | fm: 78.539 | p: 78.089 | r: 79.040
r1fm+r2fm = 149.935

input #47 time: 0:10:29 | total time: 7:52:06


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
*********************************
*********************************
average of cosine similarity 0.9993046234064711
highest_index [0]
highest [0.9993046234064711]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9481353759765625 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9344632625579834 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9107456207275391 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.893878161907196 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8840940594673157 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8556822538375854 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8369787931442261 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.796784520149231 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7961894869804382 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7949187159538269 for ['[CLS]tutedine runs graveyard [SEP]']
[Init] best perm rec loss: 0.7926889657974243 for ['[CLS] graveyard runstutedine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.136 (perp=14.462, rec=0.251, cos=-0.006), tot_loss_proj:3.407 [t=0.28s]
prediction: ['[CLS] rotting lateral assumed rotting [SEP]']
[ 100/2000] tot_loss=2.230 (perp=10.480, rec=0.143, cos=-0.009), tot_loss_proj:2.471 [t=0.27s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 150/2000] tot_loss=2.781 (perp=13.327, rec=0.125, cos=-0.009), tot_loss_proj:3.332 [t=0.28s]
prediction: ['[CLS] underbell under rotting [SEP]']
[ 200/2000] tot_loss=2.760 (perp=13.327, rec=0.104, cos=-0.009), tot_loss_proj:3.328 [t=0.27s]
prediction: ['[CLS] underbell under rotting [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.229 (perp=10.774, rec=0.083, cos=-0.009), tot_loss_proj:2.544 [t=0.27s]
prediction: ['[CLS] underybell rotting [SEP]']
[ 300/2000] tot_loss=2.210 (perp=10.774, rec=0.065, cos=-0.009), tot_loss_proj:2.541 [t=0.26s]
prediction: ['[CLS] underybell rotting [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.477 (perp=7.028, rec=0.080, cos=-0.009), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.479 (perp=7.028, rec=0.083, cos=-0.009), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.457 (perp=7.028, rec=0.061, cos=-0.009), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.460 (perp=7.028, rec=0.064, cos=-0.009), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.467 (perp=7.028, rec=0.071, cos=-0.009), tot_loss_proj:1.715 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.463 (perp=7.028, rec=0.067, cos=-0.009), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.470 (perp=7.028, rec=0.074, cos=-0.009), tot_loss_proj:1.706 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.458 (perp=7.028, rec=0.061, cos=-0.009), tot_loss_proj:1.725 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.466 (perp=7.028, rec=0.070, cos=-0.009), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.457 (perp=7.028, rec=0.060, cos=-0.009), tot_loss_proj:1.719 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.455 (perp=7.028, rec=0.059, cos=-0.009), tot_loss_proj:1.723 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.451 (perp=7.028, rec=0.054, cos=-0.009), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=7.028, rec=0.073, cos=-0.009), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.453 (perp=7.028, rec=0.056, cos=-0.009), tot_loss_proj:1.716 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.464 (perp=7.028, rec=0.068, cos=-0.009), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.472 (perp=7.028, rec=0.076, cos=-0.009), tot_loss_proj:1.715 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.452 (perp=7.028, rec=0.055, cos=-0.009), tot_loss_proj:1.721 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.465 (perp=7.028, rec=0.069, cos=-0.009), tot_loss_proj:1.723 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.461 (perp=7.028, rec=0.065, cos=-0.009), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.453 (perp=7.028, rec=0.056, cos=-0.009), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.464 (perp=7.028, rec=0.068, cos=-0.009), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.462 (perp=7.028, rec=0.066, cos=-0.009), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.464 (perp=7.028, rec=0.068, cos=-0.009), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.465 (perp=7.028, rec=0.069, cos=-0.009), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.462 (perp=7.028, rec=0.066, cos=-0.009), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.465 (perp=7.028, rec=0.068, cos=-0.009), tot_loss_proj:1.726 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.462 (perp=7.028, rec=0.065, cos=-0.009), tot_loss_proj:1.722 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.458 (perp=7.028, rec=0.062, cos=-0.009), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.449 (perp=7.028, rec=0.053, cos=-0.009), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.455 (perp=7.028, rec=0.058, cos=-0.009), tot_loss_proj:1.723 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.458 (perp=7.028, rec=0.062, cos=-0.009), tot_loss_proj:1.729 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.458 (perp=7.028, rec=0.062, cos=-0.009), tot_loss_proj:1.724 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.462 (perp=7.028, rec=0.066, cos=-0.009), tot_loss_proj:1.726 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=7.028, rec=0.069, cos=-0.009), tot_loss_proj:1.722 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.038 | p: 88.439 | r: 89.634
rouge2     | fm: 59.921 | p: 59.656 | r: 60.214
rougeL     | fm: 78.652 | p: 78.216 | r: 79.103
rougeLsum  | fm: 78.375 | p: 78.005 | r: 78.858
r1fm+r2fm = 148.959

input #48 time: 0:11:00 | total time: 8:03:07


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
*********************************
*********************************
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8349988460540771 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7890780568122864 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7884876728057861 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 0.7864314913749695 for ['[CLS] saline rang market aspects senate brothersona situation trafficking health follows tel [SEP]']
[Init] best rec loss: 0.7806379795074463 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7647554874420166 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7542374730110168 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7533898949623108 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7522913813591003 for ['[CLS] tongue during process gmina patrick baby legsiza jose trick college jockey [SEP]']
[Init] best perm rec loss: 0.7503772377967834 for ['[CLS]iza process gmina jose college tongue baby patrick jockey during trick legs [SEP]']
[Init] best perm rec loss: 0.7501202821731567 for ['[CLS] legs college patrick gmina jockey trick baby during jose processiza tongue [SEP]']
[Init] best perm rec loss: 0.74857497215271 for ['[CLS] tongue jose trick jockey legs gmina patrick college babyiza during process [SEP]']
[Init] best perm rec loss: 0.7482708692550659 for ['[CLS] college process legs during trick patrick jockeyiza jose tongue gmina baby [SEP]']
[Init] best perm rec loss: 0.7479612827301025 for ['[CLS] jose baby legs during patrick tongue college process gmina trickiza jockey [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.647 (perp=11.291, rec=0.396, cos=-0.007), tot_loss_proj:3.302 [t=0.25s]
prediction: ['[CLS] blamed cause deserved. females anymore prostitutes than program for evidence prostitution [SEP]']
[ 100/2000] tot_loss=2.310 (perp=10.084, rec=0.300, cos=-0.007), tot_loss_proj:3.165 [t=0.25s]
prediction: ['[CLS] more cause deserved. female contempt female types program for intelligence rape [SEP]']
[ 150/2000] tot_loss=2.761 (perp=12.571, rec=0.256, cos=-0.008), tot_loss_proj:3.780 [t=0.25s]
prediction: ['[CLS] more restrictions deserved covent female contempt female types population. contempt enrollment [SEP]']
[ 200/2000] tot_loss=2.627 (perp=12.055, rec=0.225, cos=-0.009), tot_loss_proj:3.558 [t=0.26s]
prediction: ['[CLS] more restrictions deserved covent female contempt female types population. contempt among [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.408 (perp=10.834, rec=0.248, cos=-0.007), tot_loss_proj:3.404 [t=0.26s]
prediction: ['[CLS] more snake types whenian contempt female deserved population. contempt station [SEP]']
[ 300/2000] tot_loss=2.582 (perp=11.956, rec=0.200, cos=-0.009), tot_loss_proj:3.574 [t=0.27s]
prediction: ['[CLS] possibly snake fewer when country contempt femaleminating population. contempt single [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.347 (perp=10.738, rec=0.201, cos=-0.002), tot_loss_proj:3.323 [t=0.25s]
prediction: ['[CLS] possibly fewer when male contempt female least population snake. contempt single [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.369 (perp=10.920, rec=0.194, cos=-0.009), tot_loss_proj:3.645 [t=0.25s]
prediction: ['[CLS] possibly than when male contempt female contempt population snake. happier single [SEP]']
[ 450/2000] tot_loss=2.355 (perp=11.015, rec=0.161, cos=-0.010), tot_loss_proj:3.269 [t=0.25s]
prediction: ['[CLS] possibly refer whenian contempt female contempt population snake. more single [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.195 (perp=10.218, rec=0.161, cos=-0.010), tot_loss_proj:3.112 [t=0.25s]
prediction: ['[CLS] possibly refer when female contemptian contempt population possibly. more single [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.057 (perp=9.571, rec=0.152, cos=-0.009), tot_loss_proj:2.970 [t=0.25s]
prediction: ['[CLS] possibly refer when female contemptian contempt. possibly population more single [SEP]']
[ 600/2000] tot_loss=2.014 (perp=9.407, rec=0.142, cos=-0.010), tot_loss_proj:2.912 [t=0.25s]
prediction: ['[CLS] possibly refer when female contemptianuous. possibly population more single [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.760 (perp=8.189, rec=0.132, cos=-0.010), tot_loss_proj:2.701 [t=0.26s]
prediction: ['[CLS] possibly refer the female contemptuous. possibly male population more single [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.765 (perp=8.189, rec=0.137, cos=-0.010), tot_loss_proj:2.699 [t=0.25s]
prediction: ['[CLS] possibly refer the female contemptuous. possibly male population more single [SEP]']
[ 750/2000] tot_loss=1.753 (perp=8.189, rec=0.125, cos=-0.010), tot_loss_proj:2.707 [t=0.26s]
prediction: ['[CLS] possibly refer the female contemptuous. possibly male population more single [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.655 (perp=7.710, rec=0.123, cos=-0.010), tot_loss_proj:2.565 [t=0.26s]
prediction: ['[CLS] possibly moderate possibly female contemptuous. the male population more single [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.647 (perp=7.710, rec=0.114, cos=-0.010), tot_loss_proj:2.570 [t=0.26s]
prediction: ['[CLS] possibly moderate possibly female contemptuous. the male population more single [SEP]']
[ 900/2000] tot_loss=1.857 (perp=8.760, rec=0.114, cos=-0.010), tot_loss_proj:2.779 [t=0.26s]
prediction: ['[CLS] possibly moderate possibly female contemptuous. the member population more single [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.903 (perp=9.042, rec=0.105, cos=-0.010), tot_loss_proj:2.912 [t=0.27s]
prediction: ['[CLS] possiblyander possibly female contemptuous. the more single member population [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.866 (perp=8.827, rec=0.110, cos=-0.009), tot_loss_proj:2.822 [t=0.28s]
prediction: ['[CLS] possibly possiblyander female contemptuous. the more single member population [SEP]']
[1050/2000] tot_loss=1.940 (perp=9.177, rec=0.114, cos=-0.010), tot_loss_proj:2.849 [t=0.26s]
prediction: ['[CLS] possibly possiblyander female contemptuous. the more single. population [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.960 (perp=9.326, rec=0.105, cos=-0.010), tot_loss_proj:2.891 [t=0.25s]
prediction: ['[CLS] possibly possiblyander member contemptuous. the more single female population [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.712 (perp=7.994, rec=0.122, cos=-0.009), tot_loss_proj:2.590 [t=0.26s]
prediction: ['[CLS] possibly possibly refer contemptuous. the more single member female population [SEP]']
[1200/2000] tot_loss=1.944 (perp=9.191, rec=0.116, cos=-0.010), tot_loss_proj:2.841 [t=0.25s]
prediction: ['[CLS] possibly possiblyander contemptuous. the more single. female population [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.803 (perp=8.471, rec=0.119, cos=-0.010), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] possibly possibly more contemptuous. the refer single. female population [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.837 (perp=8.693, rec=0.108, cos=-0.010), tot_loss_proj:2.632 [t=0.25s]
prediction: ['[CLS] possibly possibly more contemptuous. the refer single female population member [SEP]']
[1350/2000] tot_loss=1.843 (perp=8.693, rec=0.114, cos=-0.010), tot_loss_proj:2.632 [t=0.26s]
prediction: ['[CLS] possibly possibly more contemptuous. the refer single female population member [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.712 (perp=8.040, rec=0.114, cos=-0.010), tot_loss_proj:2.595 [t=0.25s]
prediction: ['[CLS] possibly possibly more contemptuous refer. the single female population member [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.704 (perp=8.007, rec=0.112, cos=-0.010), tot_loss_proj:2.670 [t=0.25s]
prediction: ['[CLS] possibly possibly more contemptuousander. the single female member population [SEP]']
[1500/2000] tot_loss=1.699 (perp=8.007, rec=0.107, cos=-0.010), tot_loss_proj:2.665 [t=0.26s]
prediction: ['[CLS] possibly possibly more contemptuousander. the single female member population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.697 (perp=7.934, rec=0.120, cos=-0.010), tot_loss_proj:2.688 [t=0.27s]
prediction: ['[CLS] possibly possibly more contemptuousander. the single female. population [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.706 (perp=8.040, rec=0.108, cos=-0.010), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] possibly possibly more contemptuous refer. the single female population member [SEP]']
[1650/2000] tot_loss=1.718 (perp=8.040, rec=0.120, cos=-0.010), tot_loss_proj:2.594 [t=0.26s]
prediction: ['[CLS] possibly possibly more contemptuous refer. the single female population member [SEP]']
Attempt swap
[1700/2000] tot_loss=1.708 (perp=8.040, rec=0.110, cos=-0.010), tot_loss_proj:2.594 [t=0.26s]
prediction: ['[CLS] possibly possibly more contemptuous refer. the single female population member [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.827 (perp=8.616, rec=0.113, cos=-0.009), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] possibly possiblyander more contemptuous. the single female population member [SEP]']
[1800/2000] tot_loss=1.665 (perp=7.814, rec=0.112, cos=-0.010), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] possibly possibly refer more contemptuous. the single female population member [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.658 (perp=7.777, rec=0.113, cos=-0.010), tot_loss_proj:2.466 [t=0.28s]
prediction: ['[CLS] possibly possibly refer more contemptuous. the single female member population [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.673 (perp=7.814, rec=0.120, cos=-0.010), tot_loss_proj:2.482 [t=0.26s]
prediction: ['[CLS] possibly possibly refer more contemptuous. the single female population member [SEP]']
[1950/2000] tot_loss=1.663 (perp=7.814, rec=0.110, cos=-0.010), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] possibly possibly refer more contemptuous. the single female population member [SEP]']
Attempt swap
[2000/2000] tot_loss=1.664 (perp=7.814, rec=0.111, cos=-0.010), tot_loss_proj:2.480 [t=0.27s]
prediction: ['[CLS] possibly possibly refer more contemptuous. the single female population member [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly possibly refer more contemptuous. the single female population member [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 111.364

[Aggregate metrics]:
rouge1     | fm: 88.749 | p: 88.284 | r: 89.359
rouge2     | fm: 59.351 | p: 59.091 | r: 59.568
rougeL     | fm: 78.533 | p: 78.087 | r: 78.969
rougeLsum  | fm: 78.396 | p: 77.983 | r: 78.882
r1fm+r2fm = 148.100

input #49 time: 0:10:54 | total time: 8:14:02


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
*********************************
*********************************
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9206792116165161 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8376301527023315 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7573332786560059 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7526006698608398 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7520577311515808 for ['[CLS]ieving night byhamlent bridget accordance red crisis [SEP]']
[Init] best perm rec loss: 0.7493540644645691 for ['[CLS]lent accordance bridgethamieving by night crisis red [SEP]']
[Init] best perm rec loss: 0.7488336563110352 for ['[CLS]lent accordance redieving crisis night by bridgetham [SEP]']
[Init] best perm rec loss: 0.7483512163162231 for ['[CLS]hamievinglent accordance by red night bridget crisis [SEP]']
[Init] best perm rec loss: 0.7482115030288696 for ['[CLS] red accordance bridgetlent nightham byieving crisis [SEP]']
[Init] best perm rec loss: 0.7472875714302063 for ['[CLS]lentham accordance bridgetieving by night red crisis [SEP]']
[Init] best perm rec loss: 0.7451678514480591 for ['[CLS]lent crisis red by accordanceham nightieving bridget [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.065 (perp=13.003, rec=0.459, cos=0.005), tot_loss_proj:3.820 [t=0.26s]
prediction: ['[CLS] recurring wonder brilliant until clever by trying scout cape [SEP]']
[ 100/2000] tot_loss=3.063 (perp=13.389, rec=0.388, cos=-0.003), tot_loss_proj:3.779 [t=0.26s]
prediction: ['[CLS] recurring harper clever until clever standards basque scout than [SEP]']
[ 150/2000] tot_loss=2.757 (perp=12.108, rec=0.344, cos=-0.009), tot_loss_proj:3.540 [t=0.26s]
prediction: ['[CLS] calls richard clever until clever what half scout than [SEP]']
[ 200/2000] tot_loss=2.416 (perp=10.498, rec=0.325, cos=-0.009), tot_loss_proj:3.473 [t=0.25s]
prediction: ['[CLS] calls what clever by clever what half chances than [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.486 (perp=10.530, rec=0.383, cos=-0.002), tot_loss_proj:3.476 [t=0.26s]
prediction: ['[CLS] calls by clever what clever what half unless than [SEP]']
[ 300/2000] tot_loss=2.282 (perp=9.855, rec=0.320, cos=-0.009), tot_loss_proj:3.310 [t=0.27s]
prediction: ['[CLS] called by clever english clever from half by giggling [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.296 (perp=10.053, rec=0.295, cos=-0.009), tot_loss_proj:3.483 [t=0.26s]
prediction: ['[CLS] called by clever clever what from half what giggling [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.264 (perp=9.961, rec=0.281, cos=-0.008), tot_loss_proj:3.511 [t=0.26s]
prediction: ['[CLS] called by clever clever english what half what ` [SEP]']
[ 450/2000] tot_loss=2.256 (perp=9.979, rec=0.265, cos=-0.005), tot_loss_proj:3.551 [t=0.27s]
prediction: ['[CLS] called by clever clever english what half ` ` [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.169 (perp=9.616, rec=0.255, cos=-0.009), tot_loss_proj:3.370 [t=0.26s]
prediction: ['[CLS] call by clever clever english half ` ` what [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.151 (perp=9.616, rec=0.238, cos=-0.009), tot_loss_proj:3.374 [t=0.25s]
prediction: ['[CLS] call by clever clever english half ` ` what [SEP]']
[ 600/2000] tot_loss=2.141 (perp=9.616, rec=0.227, cos=-0.009), tot_loss_proj:3.370 [t=0.25s]
prediction: ['[CLS] call by clever clever english half ` ` what [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.140 (perp=9.616, rec=0.224, cos=-0.007), tot_loss_proj:3.373 [t=0.26s]
prediction: ['[CLS] call by clever clever english half ` ` what [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.294 (perp=10.477, rec=0.208, cos=-0.010), tot_loss_proj:3.546 [t=0.27s]
prediction: ['[CLS] call by clever clever what half ` ` what [SEP]']
[ 750/2000] tot_loss=2.398 (perp=11.079, rec=0.192, cos=-0.009), tot_loss_proj:3.842 [t=0.26s]
prediction: ['[CLS] call by clever clever what half ` ` too [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.189 (perp=10.138, rec=0.171, cos=-0.009), tot_loss_proj:3.048 [t=0.25s]
prediction: ['[CLS] call by clever ` what half clever ` too [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.113 (perp=9.758, rec=0.169, cos=-0.008), tot_loss_proj:3.087 [t=0.26s]
prediction: ['[CLS] call by clever ` what half too clever ` [SEP]']
[ 900/2000] tot_loss=2.090 (perp=9.758, rec=0.148, cos=-0.009), tot_loss_proj:3.092 [t=0.27s]
prediction: ['[CLS] call by clever ` what half too clever ` [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.074 (perp=9.758, rec=0.132, cos=-0.010), tot_loss_proj:3.096 [t=0.26s]
prediction: ['[CLS] call by clever ` what half too clever ` [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.022 (perp=9.448, rec=0.141, cos=-0.008), tot_loss_proj:2.931 [t=0.26s]
prediction: ['[CLS] call by clever ` english what half too clever [SEP]']
[1050/2000] tot_loss=2.004 (perp=9.448, rec=0.123, cos=-0.010), tot_loss_proj:2.927 [t=0.25s]
prediction: ['[CLS] call by clever ` english what half too clever [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.957 (perp=9.239, rec=0.119, cos=-0.010), tot_loss_proj:2.766 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.957 (perp=9.239, rec=0.119, cos=-0.010), tot_loss_proj:2.774 [t=0.25s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
[1200/2000] tot_loss=1.951 (perp=9.239, rec=0.113, cos=-0.010), tot_loss_proj:2.775 [t=0.25s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.952 (perp=9.239, rec=0.114, cos=-0.010), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.941 (perp=9.239, rec=0.103, cos=-0.010), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
[1350/2000] tot_loss=1.939 (perp=9.239, rec=0.101, cos=-0.010), tot_loss_proj:2.768 [t=0.27s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.941 (perp=9.239, rec=0.103, cos=-0.010), tot_loss_proj:2.771 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.943 (perp=9.239, rec=0.105, cos=-0.010), tot_loss_proj:2.766 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
[1500/2000] tot_loss=1.940 (perp=9.239, rec=0.102, cos=-0.010), tot_loss_proj:2.768 [t=0.27s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.935 (perp=9.239, rec=0.097, cos=-0.010), tot_loss_proj:2.770 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.939 (perp=9.239, rec=0.101, cos=-0.010), tot_loss_proj:2.770 [t=0.31s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
[1650/2000] tot_loss=1.935 (perp=9.239, rec=0.097, cos=-0.010), tot_loss_proj:2.769 [t=0.32s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.929 (perp=9.239, rec=0.091, cos=-0.010), tot_loss_proj:2.770 [t=0.29s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.936 (perp=9.239, rec=0.098, cos=-0.010), tot_loss_proj:2.770 [t=0.27s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
[1800/2000] tot_loss=1.940 (perp=9.239, rec=0.102, cos=-0.010), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.938 (perp=9.239, rec=0.100, cos=-0.010), tot_loss_proj:2.766 [t=0.27s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.934 (perp=9.239, rec=0.096, cos=-0.010), tot_loss_proj:2.764 [t=0.25s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
[1950/2000] tot_loss=1.930 (perp=9.239, rec=0.092, cos=-0.010), tot_loss_proj:2.764 [t=0.26s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.928 (perp=9.239, rec=0.090, cos=-0.010), tot_loss_proj:2.771 [t=0.27s]
prediction: ['[CLS] call by clever english ` what half too clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] call by clever english ` what half too clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 101.111

[Aggregate metrics]:
rouge1     | fm: 88.646 | p: 88.170 | r: 89.297
rouge2     | fm: 58.431 | p: 58.257 | r: 58.639
rougeL     | fm: 77.968 | p: 77.541 | r: 78.433
rougeLsum  | fm: 77.700 | p: 77.329 | r: 78.179
r1fm+r2fm = 147.076

input #50 time: 0:11:04 | total time: 8:25:07


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
*********************************
*********************************
average of cosine similarity 0.9992548315433465
highest_index [0]
highest [0.9992548315433465]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.826704740524292 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7897737622261047 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7381834387779236 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7270974516868591 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7253291010856628 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.7200135588645935 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7114751935005188 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7108536958694458 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7055902481079102 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7039530873298645 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7036332488059998 for ['[CLS]rak once watching literary renamed medium toured disappointed in market [SEP]']
[Init] best perm rec loss: 0.7021721601486206 for ['[CLS] disappointed toured renamed mediumrak once in watching market literary [SEP]']
[Init] best perm rec loss: 0.7017951011657715 for ['[CLS] toured disappointed in once medium renamed market literary watchingrak [SEP]']
[Init] best perm rec loss: 0.7002806663513184 for ['[CLS] medium market watching toured disappointedrak renamed in once literary [SEP]']
[Init] best perm rec loss: 0.7000938057899475 for ['[CLS] literary renamed toured watching disappointed medium market inrak once [SEP]']
[Init] best perm rec loss: 0.6998263597488403 for ['[CLS] medium toured disappointed once watching renamed marketrak literary in [SEP]']
[Init] best perm rec loss: 0.6994193196296692 for ['[CLS] medium in market watchingrak literary renamed toured disappointed once [SEP]']
[Init] best perm rec loss: 0.6993638277053833 for ['[CLS]rak renamed once watching medium toured disappointed in market literary [SEP]']
[Init] best perm rec loss: 0.6992019414901733 for ['[CLS] watching medium disappointed renamed marketrak in literary once toured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=12.125, rec=0.384, cos=-0.006), tot_loss_proj:3.834 [t=0.25s]
prediction: ['[CLS] laws least baritone let has flash between appears about sucks [SEP]']
[ 100/2000] tot_loss=2.700 (perp=12.102, rec=0.284, cos=-0.004), tot_loss_proj:3.392 [t=0.26s]
prediction: ['[CLS] laws sucks baritone sucks has funny moment drama or sucks [SEP]']
[ 150/2000] tot_loss=2.458 (perp=11.166, rec=0.234, cos=-0.008), tot_loss_proj:3.210 [t=0.26s]
prediction: ['[CLS] sucks sucks laugh holds has funny moment and or sucks [SEP]']
[ 200/2000] tot_loss=2.232 (perp=10.224, rec=0.193, cos=-0.006), tot_loss_proj:3.033 [t=0.25s]
prediction: ['[CLS] sucks sucks laugh but has funny moment and or sucks [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.197 (perp=10.227, rec=0.159, cos=-0.007), tot_loss_proj:2.732 [t=0.26s]
prediction: ['[CLS] sucks laugh but has funny moment indie sucks or sucks [SEP]']
[ 300/2000] tot_loss=2.343 (perp=11.070, rec=0.136, cos=-0.007), tot_loss_proj:2.857 [t=0.27s]
prediction: ['[CLS] sucks blessing but has funny moment indie sucks or sucks [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.170 (perp=10.278, rec=0.121, cos=-0.007), tot_loss_proj:2.771 [t=0.26s]
prediction: ['[CLS] blessing two but has funny moment indie sucks or sucks [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.130 (perp=10.105, rec=0.117, cos=-0.008), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS]nated but has funny moment indie sucks or a sucks [SEP]']
[ 450/2000] tot_loss=1.834 (perp=8.681, rec=0.108, cos=-0.010), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS]. but has funny moment indie sucks or two sucks [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.915 (perp=9.074, rec=0.109, cos=-0.009), tot_loss_proj:2.533 [t=0.25s]
prediction: ['[CLS] but has funny moment indie sucks or two sucks equally [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.729 (perp=8.102, rec=0.117, cos=-0.009), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] but has funny moment. sucks or two equally sucks [SEP]']
[ 600/2000] tot_loss=1.715 (perp=8.102, rec=0.104, cos=-0.010), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] but has funny moment. sucks or two equally sucks [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.977 (perp=9.390, rec=0.109, cos=-0.010), tot_loss_proj:2.591 [t=0.25s]
prediction: ['[CLS] but has funny moment sucks or two equally sucks indie [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.787 (perp=8.461, rec=0.104, cos=-0.010), tot_loss_proj:2.550 [t=0.27s]
prediction: ['[CLS] but has funny moment sucks or two. indie sucks [SEP]']
[ 750/2000] tot_loss=1.783 (perp=8.461, rec=0.100, cos=-0.010), tot_loss_proj:2.542 [t=0.27s]
prediction: ['[CLS] but has funny moment sucks or two. indie sucks [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.712 (perp=8.124, rec=0.097, cos=-0.010), tot_loss_proj:2.289 [t=0.26s]
prediction: ['[CLS] but has funny sucks moment or two. indie sucks [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.663 (perp=7.865, rec=0.100, cos=-0.009), tot_loss_proj:2.181 [t=0.28s]
prediction: ['[CLS] but has indie sucks moment or two. funny sucks [SEP]']
[ 900/2000] tot_loss=1.667 (perp=7.865, rec=0.103, cos=-0.010), tot_loss_proj:2.184 [t=0.28s]
prediction: ['[CLS] but has indie sucks moment or two. funny sucks [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.659 (perp=7.846, rec=0.100, cos=-0.010), tot_loss_proj:2.193 [t=0.29s]
prediction: ['[CLS] but has sucks indie moment or two. funny sucks [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.458 (perp=6.889, rec=0.089, cos=-0.009), tot_loss_proj:2.302 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1050/2000] tot_loss=1.462 (perp=6.889, rec=0.094, cos=-0.010), tot_loss_proj:2.304 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.471 (perp=6.889, rec=0.103, cos=-0.010), tot_loss_proj:2.305 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.467 (perp=6.889, rec=0.099, cos=-0.010), tot_loss_proj:2.298 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1200/2000] tot_loss=1.461 (perp=6.889, rec=0.093, cos=-0.010), tot_loss_proj:2.298 [t=0.29s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.470 (perp=6.889, rec=0.102, cos=-0.010), tot_loss_proj:2.299 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.452 (perp=6.889, rec=0.084, cos=-0.010), tot_loss_proj:2.301 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1350/2000] tot_loss=1.464 (perp=6.889, rec=0.096, cos=-0.010), tot_loss_proj:2.300 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.463 (perp=6.889, rec=0.095, cos=-0.010), tot_loss_proj:2.299 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.455 (perp=6.889, rec=0.087, cos=-0.010), tot_loss_proj:2.299 [t=0.32s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1500/2000] tot_loss=1.457 (perp=6.889, rec=0.089, cos=-0.010), tot_loss_proj:2.289 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.461 (perp=6.889, rec=0.093, cos=-0.010), tot_loss_proj:2.295 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.458 (perp=6.889, rec=0.090, cos=-0.010), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1650/2000] tot_loss=1.466 (perp=6.889, rec=0.098, cos=-0.010), tot_loss_proj:2.298 [t=0.29s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.467 (perp=6.889, rec=0.099, cos=-0.010), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.460 (perp=6.889, rec=0.092, cos=-0.010), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1800/2000] tot_loss=1.465 (perp=6.889, rec=0.097, cos=-0.010), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.459 (perp=6.889, rec=0.091, cos=-0.010), tot_loss_proj:2.299 [t=0.28s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.454 (perp=6.889, rec=0.086, cos=-0.010), tot_loss_proj:2.298 [t=0.29s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
[1950/2000] tot_loss=1.461 (perp=6.889, rec=0.093, cos=-0.010), tot_loss_proj:2.299 [t=0.29s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=6.889, rec=0.103, cos=-0.010), tot_loss_proj:2.302 [t=0.25s]
prediction: ['[CLS] but has sucks. moment or two funny sucks. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] but has sucks. moment or two funny sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 88.821 | p: 88.313 | r: 89.378
rouge2     | fm: 58.001 | p: 57.816 | r: 58.229
rougeL     | fm: 77.712 | p: 77.323 | r: 78.163
rougeLsum  | fm: 77.560 | p: 77.141 | r: 78.026
r1fm+r2fm = 146.822

input #51 time: 0:11:18 | total time: 8:36:25


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
*********************************
*********************************
average of cosine similarity 0.9992769471396808
highest_index [0]
highest [0.9992769471396808]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9633553624153137 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9276461005210876 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8949947357177734 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8681666254997253 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7894576191902161 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7760429382324219 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7046040296554565 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.579 (perp=11.737, rec=0.237, cos=-0.006), tot_loss_proj:2.657 [t=0.29s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.492 (perp=11.737, rec=0.153, cos=-0.008), tot_loss_proj:2.653 [t=0.30s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.446 (perp=11.737, rec=0.107, cos=-0.008), tot_loss_proj:2.649 [t=0.28s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 200/2000] tot_loss=2.406 (perp=11.737, rec=0.068, cos=-0.009), tot_loss_proj:2.651 [t=0.29s]
prediction: ['[CLS] trailer trash trash [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.787 (perp=8.482, rec=0.098, cos=-0.008), tot_loss_proj:2.125 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.748 (perp=8.482, rec=0.061, cos=-0.009), tot_loss_proj:2.114 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.752 (perp=8.482, rec=0.065, cos=-0.009), tot_loss_proj:2.115 [t=0.32s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.754 (perp=8.482, rec=0.067, cos=-0.009), tot_loss_proj:2.116 [t=0.32s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.752 (perp=8.482, rec=0.065, cos=-0.009), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.751 (perp=8.482, rec=0.064, cos=-0.009), tot_loss_proj:2.121 [t=0.29s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.751 (perp=8.482, rec=0.063, cos=-0.009), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.757 (perp=8.482, rec=0.070, cos=-0.009), tot_loss_proj:2.116 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.750 (perp=8.482, rec=0.063, cos=-0.009), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.743 (perp=8.482, rec=0.056, cos=-0.009), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.482, rec=0.064, cos=-0.009), tot_loss_proj:2.114 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.762 (perp=8.482, rec=0.075, cos=-0.009), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.749 (perp=8.482, rec=0.061, cos=-0.009), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.759 (perp=8.482, rec=0.071, cos=-0.009), tot_loss_proj:2.116 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=8.482, rec=0.060, cos=-0.009), tot_loss_proj:2.120 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.750 (perp=8.482, rec=0.063, cos=-0.009), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.753 (perp=8.482, rec=0.066, cos=-0.009), tot_loss_proj:2.116 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.756 (perp=8.482, rec=0.068, cos=-0.009), tot_loss_proj:2.112 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.753 (perp=8.482, rec=0.066, cos=-0.009), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.752 (perp=8.482, rec=0.065, cos=-0.009), tot_loss_proj:2.113 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.755 (perp=8.482, rec=0.068, cos=-0.009), tot_loss_proj:2.110 [t=0.30s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.746 (perp=8.482, rec=0.059, cos=-0.009), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.740 (perp=8.482, rec=0.053, cos=-0.009), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.752 (perp=8.482, rec=0.065, cos=-0.009), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.756 (perp=8.482, rec=0.068, cos=-0.009), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.745 (perp=8.482, rec=0.058, cos=-0.009), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.746 (perp=8.482, rec=0.059, cos=-0.009), tot_loss_proj:2.112 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.740 (perp=8.482, rec=0.053, cos=-0.009), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.752 (perp=8.482, rec=0.064, cos=-0.009), tot_loss_proj:2.108 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.482, rec=0.054, cos=-0.009), tot_loss_proj:2.111 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.755 (perp=8.482, rec=0.068, cos=-0.009), tot_loss_proj:2.111 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.753 (perp=8.482, rec=0.066, cos=-0.009), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.766 (perp=8.482, rec=0.079, cos=-0.009), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.755 (perp=8.482, rec=0.067, cos=-0.009), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.745 (perp=8.482, rec=0.058, cos=-0.009), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.482, rec=0.072, cos=-0.009), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.944 | p: 88.480 | r: 89.471
rouge2     | fm: 57.012 | p: 56.782 | r: 57.286
rougeL     | fm: 77.788 | p: 77.384 | r: 78.263
rougeLsum  | fm: 77.588 | p: 77.226 | r: 78.086
r1fm+r2fm = 145.955

input #52 time: 0:11:16 | total time: 8:47:42


Running input #53 of 100.
reference: 
========================
flinching 
========================
*********************************
*********************************
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9457181096076965 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.862006664276123 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8316056728363037 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7958467602729797 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7199336886405945 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.6997024416923523 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6986270546913147 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6915310621261597 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6842321157455444 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6748745441436768 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.797 (perp=12.384, rec=0.315, cos=0.005), tot_loss_proj:3.366 [t=0.25s]
prediction: ['[CLS] flinch flinched [SEP]']
[ 100/2000] tot_loss=2.689 (perp=12.492, rec=0.197, cos=-0.006), tot_loss_proj:3.318 [t=0.27s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.630 (perp=12.492, rec=0.140, cos=-0.008), tot_loss_proj:3.319 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.630 (perp=12.492, rec=0.140, cos=-0.009), tot_loss_proj:3.341 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.621 (perp=12.492, rec=0.131, cos=-0.008), tot_loss_proj:3.334 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.625 (perp=12.492, rec=0.130, cos=-0.003), tot_loss_proj:3.330 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.594 (perp=12.492, rec=0.105, cos=-0.009), tot_loss_proj:3.335 [t=0.26s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.726 (perp=8.090, rec=0.115, cos=-0.007), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.687 (perp=8.090, rec=0.078, cos=-0.009), tot_loss_proj:1.694 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.679 (perp=8.090, rec=0.070, cos=-0.010), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.677 (perp=8.090, rec=0.068, cos=-0.010), tot_loss_proj:1.688 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.678 (perp=8.090, rec=0.069, cos=-0.010), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.671 (perp=8.090, rec=0.063, cos=-0.010), tot_loss_proj:1.693 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.672 (perp=8.090, rec=0.064, cos=-0.010), tot_loss_proj:1.688 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.662 (perp=8.090, rec=0.054, cos=-0.010), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.666 (perp=8.090, rec=0.058, cos=-0.010), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.673 (perp=8.090, rec=0.065, cos=-0.010), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.668 (perp=8.090, rec=0.060, cos=-0.010), tot_loss_proj:1.687 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=8.090, rec=0.065, cos=-0.010), tot_loss_proj:1.673 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.677 (perp=8.090, rec=0.069, cos=-0.010), tot_loss_proj:1.682 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.675 (perp=8.090, rec=0.067, cos=-0.010), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.666 (perp=8.090, rec=0.058, cos=-0.010), tot_loss_proj:1.687 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.661 (perp=8.090, rec=0.053, cos=-0.010), tot_loss_proj:1.693 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.669 (perp=8.090, rec=0.060, cos=-0.010), tot_loss_proj:1.682 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.674 (perp=8.090, rec=0.066, cos=-0.010), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.090, rec=0.066, cos=-0.010), tot_loss_proj:1.678 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.673 (perp=8.090, rec=0.065, cos=-0.010), tot_loss_proj:1.681 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.675 (perp=8.090, rec=0.067, cos=-0.010), tot_loss_proj:1.677 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.672 (perp=8.090, rec=0.064, cos=-0.010), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.677 (perp=8.090, rec=0.068, cos=-0.010), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.665 (perp=8.090, rec=0.056, cos=-0.010), tot_loss_proj:1.692 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=8.090, rec=0.066, cos=-0.010), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.671 (perp=8.090, rec=0.063, cos=-0.010), tot_loss_proj:1.681 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=8.090, rec=0.069, cos=-0.010), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=8.090, rec=0.063, cos=-0.010), tot_loss_proj:1.682 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.669 (perp=8.090, rec=0.061, cos=-0.010), tot_loss_proj:1.688 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=8.090, rec=0.062, cos=-0.010), tot_loss_proj:1.680 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=8.090, rec=0.064, cos=-0.010), tot_loss_proj:1.695 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.664 (perp=8.090, rec=0.056, cos=-0.010), tot_loss_proj:1.671 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.659 (perp=8.090, rec=0.051, cos=-0.010), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.185 | p: 88.710 | r: 89.690
rouge2     | fm: 57.627 | p: 57.391 | r: 57.899
rougeL     | fm: 78.139 | p: 77.782 | r: 78.552
rougeLsum  | fm: 77.940 | p: 77.524 | r: 78.395
r1fm+r2fm = 146.812

input #53 time: 0:10:52 | total time: 8:58:35


Running input #54 of 100.
reference: 
========================
hot topics 
========================
*********************************
*********************************
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9532368183135986 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8024941086769104 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7537968754768372 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7135902047157288 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7061654329299927 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.7006915807723999 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.342 (perp=9.350, rec=0.457, cos=0.015), tot_loss_proj:3.046 [t=0.25s]
prediction: ['[CLS] topics style [SEP]']
[ 100/2000] tot_loss=2.580 (perp=11.553, rec=0.274, cos=-0.005), tot_loss_proj:2.847 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.448 (perp=11.553, rec=0.145, cos=-0.007), tot_loss_proj:2.853 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.412 (perp=11.553, rec=0.109, cos=-0.008), tot_loss_proj:2.879 [t=0.26s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.750 (perp=8.198, rec=0.117, cos=-0.006), tot_loss_proj:1.745 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.719 (perp=8.198, rec=0.088, cos=-0.009), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.708 (perp=8.198, rec=0.077, cos=-0.009), tot_loss_proj:1.725 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.707 (perp=8.198, rec=0.076, cos=-0.009), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.701 (perp=8.198, rec=0.071, cos=-0.009), tot_loss_proj:1.727 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.692 (perp=8.198, rec=0.061, cos=-0.009), tot_loss_proj:1.728 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.705 (perp=8.198, rec=0.075, cos=-0.009), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.700 (perp=8.198, rec=0.069, cos=-0.009), tot_loss_proj:1.732 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.688 (perp=8.198, rec=0.058, cos=-0.009), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.696 (perp=8.198, rec=0.066, cos=-0.009), tot_loss_proj:1.716 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.198, rec=0.057, cos=-0.009), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.696 (perp=8.198, rec=0.066, cos=-0.009), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.694 (perp=8.198, rec=0.063, cos=-0.009), tot_loss_proj:1.740 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.697 (perp=8.198, rec=0.067, cos=-0.009), tot_loss_proj:1.738 [t=0.29s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.684 (perp=8.198, rec=0.054, cos=-0.009), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.688 (perp=8.198, rec=0.057, cos=-0.009), tot_loss_proj:1.734 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.689 (perp=8.198, rec=0.059, cos=-0.009), tot_loss_proj:1.733 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.697 (perp=8.198, rec=0.066, cos=-0.009), tot_loss_proj:1.743 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.691 (perp=8.198, rec=0.061, cos=-0.009), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.691 (perp=8.198, rec=0.060, cos=-0.009), tot_loss_proj:1.725 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.690 (perp=8.198, rec=0.060, cos=-0.009), tot_loss_proj:1.726 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=8.198, rec=0.062, cos=-0.009), tot_loss_proj:1.734 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.698 (perp=8.198, rec=0.068, cos=-0.009), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.678 (perp=8.198, rec=0.048, cos=-0.009), tot_loss_proj:1.735 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.688 (perp=8.198, rec=0.057, cos=-0.009), tot_loss_proj:1.735 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.690 (perp=8.198, rec=0.059, cos=-0.009), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.687 (perp=8.198, rec=0.057, cos=-0.009), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.198, rec=0.068, cos=-0.009), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.692 (perp=8.198, rec=0.062, cos=-0.009), tot_loss_proj:1.721 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.688 (perp=8.198, rec=0.057, cos=-0.009), tot_loss_proj:1.724 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.700 (perp=8.198, rec=0.070, cos=-0.009), tot_loss_proj:1.726 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.712 (perp=8.198, rec=0.081, cos=-0.009), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.689 (perp=8.198, rec=0.059, cos=-0.009), tot_loss_proj:1.723 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.686 (perp=8.198, rec=0.056, cos=-0.009), tot_loss_proj:1.731 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.688 (perp=8.198, rec=0.057, cos=-0.009), tot_loss_proj:1.724 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.682 (perp=8.198, rec=0.051, cos=-0.009), tot_loss_proj:1.719 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.474 | p: 88.957 | r: 89.968
rouge2     | fm: 58.491 | p: 58.240 | r: 58.651
rougeL     | fm: 78.526 | p: 78.109 | r: 78.958
rougeLsum  | fm: 78.350 | p: 77.994 | r: 78.769
r1fm+r2fm = 147.965

input #54 time: 0:10:55 | total time: 9:09:31


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
*********************************
*********************************
average of cosine similarity 0.9991205863745831
highest_index [0]
highest [0.9991205863745831]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9149343371391296 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8663113713264465 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7905805706977844 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7703065872192383 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7634938359260559 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7582106590270996 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7517237663269043 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.712469220161438 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.703285276889801 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7019903659820557 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7008416652679443 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.949 (perp=12.362, rec=0.473, cos=0.004), tot_loss_proj:3.594 [t=0.26s]
prediction: ['[CLS] slipping reverted bc [SEP]']
[ 100/2000] tot_loss=2.363 (perp=10.151, rec=0.339, cos=-0.006), tot_loss_proj:3.953 [t=0.27s]
prediction: ['[CLS] easily settled settled [SEP]']
[ 150/2000] tot_loss=2.157 (perp=9.485, rec=0.261, cos=-0.000), tot_loss_proj:3.795 [t=0.27s]
prediction: ['[CLS] easily settles easily [SEP]']
[ 200/2000] tot_loss=2.115 (perp=9.485, rec=0.224, cos=-0.006), tot_loss_proj:3.803 [t=0.26s]
prediction: ['[CLS] easily settles easily [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.999 (perp=9.088, rec=0.189, cos=-0.008), tot_loss_proj:3.661 [t=0.27s]
prediction: ['[CLS] settles easily easily [SEP]']
[ 300/2000] tot_loss=2.177 (perp=10.114, rec=0.161, cos=-0.006), tot_loss_proj:3.475 [t=0.26s]
prediction: ['[CLS] settles easily too [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.812 (perp=8.671, rec=0.087, cos=-0.009), tot_loss_proj:1.801 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.811 (perp=8.671, rec=0.087, cos=-0.010), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.809 (perp=8.671, rec=0.084, cos=-0.010), tot_loss_proj:1.783 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.796 (perp=8.671, rec=0.072, cos=-0.010), tot_loss_proj:1.793 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.798 (perp=8.671, rec=0.074, cos=-0.010), tot_loss_proj:1.800 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.782 (perp=8.671, rec=0.058, cos=-0.010), tot_loss_proj:1.791 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.801 (perp=8.671, rec=0.076, cos=-0.010), tot_loss_proj:1.806 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.775 (perp=8.671, rec=0.051, cos=-0.010), tot_loss_proj:1.793 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.780 (perp=8.671, rec=0.055, cos=-0.010), tot_loss_proj:1.792 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.789 (perp=8.671, rec=0.065, cos=-0.010), tot_loss_proj:1.795 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.789 (perp=8.671, rec=0.064, cos=-0.010), tot_loss_proj:1.800 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.789 (perp=8.671, rec=0.064, cos=-0.010), tot_loss_proj:1.797 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.773 (perp=8.671, rec=0.049, cos=-0.010), tot_loss_proj:1.799 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.795 (perp=8.671, rec=0.071, cos=-0.010), tot_loss_proj:1.799 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.779 (perp=8.671, rec=0.055, cos=-0.010), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.671, rec=0.068, cos=-0.010), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.788 (perp=8.671, rec=0.063, cos=-0.010), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.791 (perp=8.671, rec=0.066, cos=-0.010), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.790 (perp=8.671, rec=0.065, cos=-0.010), tot_loss_proj:1.795 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.783 (perp=8.671, rec=0.059, cos=-0.010), tot_loss_proj:1.793 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.786 (perp=8.671, rec=0.062, cos=-0.010), tot_loss_proj:1.795 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.788 (perp=8.671, rec=0.064, cos=-0.010), tot_loss_proj:1.788 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.780 (perp=8.671, rec=0.055, cos=-0.010), tot_loss_proj:1.789 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.792 (perp=8.671, rec=0.067, cos=-0.010), tot_loss_proj:1.791 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.782 (perp=8.671, rec=0.058, cos=-0.010), tot_loss_proj:1.789 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.785 (perp=8.671, rec=0.060, cos=-0.010), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.785 (perp=8.671, rec=0.060, cos=-0.010), tot_loss_proj:1.786 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.787 (perp=8.671, rec=0.063, cos=-0.010), tot_loss_proj:1.793 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.779 (perp=8.671, rec=0.055, cos=-0.010), tot_loss_proj:1.796 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.671, rec=0.072, cos=-0.010), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.781 (perp=8.671, rec=0.057, cos=-0.010), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.791 (perp=8.671, rec=0.067, cos=-0.010), tot_loss_proj:1.787 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.778 (perp=8.671, rec=0.053, cos=-0.010), tot_loss_proj:1.795 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.775 (perp=8.671, rec=0.051, cos=-0.010), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.596 | p: 89.144 | r: 90.117
rouge2     | fm: 59.372 | p: 59.195 | r: 59.552
rougeL     | fm: 78.833 | p: 78.451 | r: 79.323
rougeLsum  | fm: 78.797 | p: 78.383 | r: 79.264
r1fm+r2fm = 148.968

input #55 time: 0:10:58 | total time: 9:20:29


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
*********************************
*********************************
average of cosine similarity 0.9992743912224644
highest_index [0]
highest [0.9992743912224644]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.932321310043335 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9175447821617126 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9035267233848572 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8958414793014526 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.8944609761238098 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8827247619628906 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8799951076507568 for ['[CLS] almost wall up emotional defeated leadership acquainted variables spectroscopy dive realm with consolation households cas potential obsidian handed existing been organization [SEP]']
[Init] best perm rec loss: 0.8781517744064331 for ['[CLS] organization almost been emotional consolation defeated existing obsidian households acquainted with spectroscopy dive wall leadership up cas handed potential realm variables [SEP]']
[Init] best perm rec loss: 0.8778687119483948 for ['[CLS] cas variables wall emotional potential dive spectroscopy leadership organization obsidian existing consolation with almost defeated realm handed up been acquainted households [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.723 (perp=11.962, rec=0.338, cos=-0.007), tot_loss_proj:3.405 [t=0.27s]
prediction: ['[CLS] hospital windshieldes old analysis to damaged else law recording over damage absolutely quit stupid ads poll that diane concept obvious [SEP]']
[ 100/2000] tot_loss=2.549 (perp=11.486, rec=0.258, cos=-0.006), tot_loss_proj:3.289 [t=0.26s]
prediction: ['[CLS] films hitshouse costly analysis films damaged else law films obviously damage films whom costly films costlystream inability project damage [SEP]']
[ 150/2000] tot_loss=2.707 (perp=12.546, rec=0.207, cos=-0.009), tot_loss_proj:3.640 [t=0.27s]
prediction: ['[CLS] films triggerload costly analysis pradesh damage worth loads films decades damage never whom costly films costly whichtruct project never [SEP]']
[ 200/2000] tot_loss=2.315 (perp=10.677, rec=0.187, cos=-0.008), tot_loss_proj:2.944 [t=0.25s]
prediction: ['[CLS] because cause loads costly analysis deposits damage that loads films decades damage years whom costly films costly which simulation analysis never [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.221 (perp=10.334, rec=0.163, cos=-0.009), tot_loss_proj:2.747 [t=0.27s]
prediction: ['[CLS] years cause loads costly fix consumption damage that loads costly films years damage years whom costly films which auto analysis never [SEP]']
[ 300/2000] tot_loss=2.110 (perp=9.884, rec=0.143, cos=-0.009), tot_loss_proj:2.711 [t=0.27s]
prediction: ['[CLS] years cause loads costly fix cause damage that loads costly films years damage years of costly films whichtruct analysis never [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.981 (perp=9.323, rec=0.126, cos=-0.010), tot_loss_proj:2.709 [t=0.26s]
prediction: ['[CLS] years cause loads fix cause damage that loads costly films years damage years of costly films whichously costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.027 (perp=9.582, rec=0.120, cos=-0.009), tot_loss_proj:2.810 [t=0.27s]
prediction: ['[CLS] years cause loads fix cause damage that yearsble years loads damage years of costly films whichpara costly analysis never [SEP]']
[ 450/2000] tot_loss=2.004 (perp=9.529, rec=0.108, cos=-0.010), tot_loss_proj:2.814 [t=0.27s]
prediction: ['[CLS] years cause loads fix of damage that yearsble years loads damage years of costly films whichpara costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.877 (perp=8.880, rec=0.111, cos=-0.010), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] years cause loads fix of damage that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.819 (perp=8.634, rec=0.101, cos=-0.010), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] years cause fix loads of damage that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
[ 600/2000] tot_loss=1.823 (perp=8.634, rec=0.106, cos=-0.010), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] years cause fix loads of damage that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.891 (perp=9.036, rec=0.093, cos=-0.010), tot_loss_proj:2.654 [t=0.26s]
prediction: ['[CLS] years fix cause will of damage that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.857 (perp=8.871, rec=0.093, cos=-0.010), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
[ 750/2000] tot_loss=1.848 (perp=8.871, rec=0.083, cos=-0.010), tot_loss_proj:2.517 [t=0.26s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.858 (perp=8.871, rec=0.093, cos=-0.010), tot_loss_proj:2.513 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.847 (perp=8.871, rec=0.083, cos=-0.010), tot_loss_proj:2.520 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
[ 900/2000] tot_loss=1.855 (perp=8.871, rec=0.090, cos=-0.010), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.847 (perp=8.871, rec=0.082, cos=-0.010), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.847 (perp=8.871, rec=0.082, cos=-0.010), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
[1050/2000] tot_loss=1.853 (perp=8.871, rec=0.088, cos=-0.010), tot_loss_proj:2.520 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that yearsble yearspara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1100/2000] tot_loss=1.923 (perp=9.283, rec=0.076, cos=-0.010), tot_loss_proj:2.573 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that yearsble andpara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.850 (perp=8.891, rec=0.081, cos=-0.010), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] ir fix cause damage of will that years andblepara damage years of costly films which loads costly analysis never [SEP]']
[1200/2000] tot_loss=1.853 (perp=8.891, rec=0.084, cos=-0.010), tot_loss_proj:2.523 [t=0.26s]
prediction: ['[CLS] ir fix cause damage of will that years andblepara damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.741 (perp=8.370, rec=0.077, cos=-0.010), tot_loss_proj:2.375 [t=0.27s]
prediction: ['[CLS] ir fix cause damage of will that years andparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.724 (perp=8.224, rec=0.089, cos=-0.010), tot_loss_proj:2.307 [t=0.27s]
prediction: ['[CLS] ir fix cause damage and will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
[1350/2000] tot_loss=1.708 (perp=8.224, rec=0.072, cos=-0.010), tot_loss_proj:2.306 [t=0.27s]
prediction: ['[CLS] ir fix cause damage and will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.642 (perp=7.877, rec=0.076, cos=-0.010), tot_loss_proj:2.233 [t=0.27s]
prediction: ['[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1450/2000] tot_loss=1.643 (perp=7.877, rec=0.077, cos=-0.010), tot_loss_proj:2.234 [t=0.26s]
prediction: ['[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
[1500/2000] tot_loss=1.646 (perp=7.877, rec=0.081, cos=-0.010), tot_loss_proj:2.234 [t=0.27s]
prediction: ['[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1550/2000] tot_loss=1.652 (perp=7.877, rec=0.086, cos=-0.010), tot_loss_proj:2.229 [t=0.29s]
prediction: ['[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1600/2000] tot_loss=1.645 (perp=7.877, rec=0.080, cos=-0.010), tot_loss_proj:2.235 [t=0.28s]
prediction: ['[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
[1650/2000] tot_loss=1.648 (perp=7.877, rec=0.082, cos=-0.010), tot_loss_proj:2.229 [t=0.29s]
prediction: ['[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.596 (perp=7.630, rec=0.080, cos=-0.010), tot_loss_proj:2.130 [t=0.29s]
prediction: ['[CLS] ir fix and damage will cause that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.630, rec=0.077, cos=-0.010), tot_loss_proj:2.123 [t=0.29s]
prediction: ['[CLS] ir fix and damage will cause that years ofparable damage years of costly films which loads costly analysis never [SEP]']
[1800/2000] tot_loss=1.600 (perp=7.630, rec=0.083, cos=-0.010), tot_loss_proj:2.123 [t=0.29s]
prediction: ['[CLS] ir fix and damage will cause that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.630, rec=0.074, cos=-0.010), tot_loss_proj:2.121 [t=0.27s]
prediction: ['[CLS] ir fix and damage will cause that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.594 (perp=7.630, rec=0.078, cos=-0.010), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] ir fix and damage will cause that years ofparable damage years of costly films which loads costly analysis never [SEP]']
[1950/2000] tot_loss=1.596 (perp=7.630, rec=0.079, cos=-0.010), tot_loss_proj:2.125 [t=0.26s]
prediction: ['[CLS] ir fix and damage will cause that years ofparable damage years of costly films which loads costly analysis never [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.584 (perp=7.603, rec=0.073, cos=-0.010), tot_loss_proj:2.122 [t=0.27s]
prediction: ['[CLS] ir fix and damage will that cause years ofparable damage years of costly films which loads costly analysis never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] ir fix and damage cause will that years ofparable damage years of costly films which loads costly analysis never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.927 | p: 80.952 | r: 85.000
rouge2     | fm: 25.641 | p: 25.000 | r: 26.316
rougeL     | fm: 48.780 | p: 47.619 | r: 50.000
rougeLsum  | fm: 48.780 | p: 47.619 | r: 50.000
r1fm+r2fm = 108.568

[Aggregate metrics]:
rouge1     | fm: 89.439 | p: 88.926 | r: 90.054
rouge2     | fm: 58.500 | p: 58.283 | r: 58.669
rougeL     | fm: 78.435 | p: 78.118 | r: 78.883
rougeLsum  | fm: 78.301 | p: 77.893 | r: 78.800
r1fm+r2fm = 147.940

input #56 time: 0:11:12 | total time: 9:31:41


Running input #57 of 100.
reference: 
========================
wears 
========================
*********************************
*********************************
average of cosine similarity 0.9993815950585869
highest_index [0]
highest [0.9993815950585869]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8631657361984253 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7994511723518372 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.705524206161499 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6581541299819946 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.643149733543396 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.786 (perp=12.282, rec=0.312, cos=0.018), tot_loss_proj:2.507 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.543 (perp=12.282, rec=0.092, cos=-0.005), tot_loss_proj:2.500 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.519 (perp=12.282, rec=0.069, cos=-0.007), tot_loss_proj:2.510 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.518 (perp=12.282, rec=0.071, cos=-0.010), tot_loss_proj:2.506 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.502 (perp=12.282, rec=0.055, cos=-0.010), tot_loss_proj:2.515 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.514 (perp=12.282, rec=0.067, cos=-0.010), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.497 (perp=12.282, rec=0.050, cos=-0.009), tot_loss_proj:2.525 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.516 (perp=12.282, rec=0.069, cos=-0.010), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.512 (perp=12.282, rec=0.065, cos=-0.010), tot_loss_proj:2.513 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.516 (perp=12.282, rec=0.069, cos=-0.010), tot_loss_proj:2.514 [t=0.31s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.513 (perp=12.282, rec=0.066, cos=-0.010), tot_loss_proj:2.526 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.499 (perp=12.282, rec=0.052, cos=-0.010), tot_loss_proj:2.518 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.497 (perp=12.282, rec=0.050, cos=-0.010), tot_loss_proj:2.509 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.500 (perp=12.282, rec=0.053, cos=-0.010), tot_loss_proj:2.520 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.516 (perp=12.282, rec=0.070, cos=-0.010), tot_loss_proj:2.527 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.510 (perp=12.282, rec=0.063, cos=-0.010), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.506 (perp=12.282, rec=0.059, cos=-0.010), tot_loss_proj:2.518 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.510 (perp=12.282, rec=0.064, cos=-0.010), tot_loss_proj:2.510 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.510 (perp=12.282, rec=0.063, cos=-0.010), tot_loss_proj:2.514 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.509 (perp=12.282, rec=0.062, cos=-0.010), tot_loss_proj:2.510 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.496 (perp=12.282, rec=0.050, cos=-0.010), tot_loss_proj:2.486 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.500 (perp=12.282, rec=0.053, cos=-0.010), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.507 (perp=12.282, rec=0.061, cos=-0.010), tot_loss_proj:2.502 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.514 (perp=12.282, rec=0.067, cos=-0.010), tot_loss_proj:2.509 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.507 (perp=12.282, rec=0.060, cos=-0.010), tot_loss_proj:2.525 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.498 (perp=12.282, rec=0.052, cos=-0.010), tot_loss_proj:2.512 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.509 (perp=12.282, rec=0.062, cos=-0.010), tot_loss_proj:2.512 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.503 (perp=12.282, rec=0.056, cos=-0.010), tot_loss_proj:2.510 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.509 (perp=12.282, rec=0.062, cos=-0.010), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.503 (perp=12.282, rec=0.057, cos=-0.010), tot_loss_proj:2.506 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.522 (perp=12.282, rec=0.075, cos=-0.010), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.508 (perp=12.282, rec=0.061, cos=-0.010), tot_loss_proj:2.507 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.505 (perp=12.282, rec=0.058, cos=-0.010), tot_loss_proj:2.511 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.493 (perp=12.282, rec=0.046, cos=-0.010), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.501 (perp=12.282, rec=0.054, cos=-0.010), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.498 (perp=12.282, rec=0.051, cos=-0.010), tot_loss_proj:2.498 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.521 (perp=12.282, rec=0.075, cos=-0.010), tot_loss_proj:2.504 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.505 (perp=12.282, rec=0.059, cos=-0.010), tot_loss_proj:2.518 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.497 (perp=12.282, rec=0.050, cos=-0.010), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.501 (perp=12.282, rec=0.055, cos=-0.010), tot_loss_proj:2.501 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.630 | p: 89.148 | r: 90.139
rouge2     | fm: 59.413 | p: 59.211 | r: 59.712
rougeL     | fm: 78.806 | p: 78.394 | r: 79.206
rougeLsum  | fm: 78.633 | p: 78.262 | r: 79.054
r1fm+r2fm = 149.043

input #57 time: 0:10:57 | total time: 9:42:39


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
*********************************
*********************************
average of cosine similarity 0.9992685151622412
highest_index [0]
highest [0.9992685151622412]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9649522304534912 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9525012969970703 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9179250597953796 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9173662066459656 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9167462587356567 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army Â£100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8904667496681213 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8734395503997803 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.872577428817749 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.872272789478302 for ['[CLS] verde finishedager thighs beauty estitical trade zack herselfuration apart chieftyle down serious [SEP]']
[Init] best perm rec loss: 0.8679993748664856 for ['[CLS] down herselfitical verde zack finished apart serious chiefuration thighs tradetyle beauty estager [SEP]']
[Init] best perm rec loss: 0.8665047287940979 for ['[CLS]itical est trade zack serioustyle herself down thighs finished beauty apart chiefageruration verde [SEP]']
[Init] best perm rec loss: 0.8653094172477722 for ['[CLS] beauty aparturation thighs trade verde zack down chief finished herself serioustyle estiticalager [SEP]']
[Init] best perm rec loss: 0.8635257482528687 for ['[CLS] est chief beauty down zack serious tradetyle verde thighsurationitical apartager herself finished [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.580 (perp=14.351, rec=0.706, cos=0.004), tot_loss_proj:4.773 [t=0.21s]
prediction: ['[CLS] creepy saving banned about endure archduke pie structure some lasting never shoes less cruiser tristan player [SEP]']
[ 100/2000] tot_loss=3.486 (perp=14.188, rec=0.637, cos=0.012), tot_loss_proj:4.303 [t=0.21s]
prediction: ['[CLS] ass tub banned from bryan indiana curriculum context some an non shoes wayrral mundane fight [SEP]']
[ 150/2000] tot_loss=3.094 (perp=12.540, rec=0.575, cos=0.011), tot_loss_proj:4.474 [t=0.21s]
prediction: ['[CLS]qual tub necessity from â€¢ indiana curriculum context some an non land way stormed ideal story [SEP]']
[ 200/2000] tot_loss=2.805 (perp=11.429, rec=0.525, cos=-0.006), tot_loss_proj:4.213 [t=0.21s]
prediction: ['[CLS] corruption tub necessity from capturing indiana curriculum fact some an disappeared touching that of ideal story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.853 (perp=11.660, rec=0.527, cos=-0.007), tot_loss_proj:4.197 [t=0.21s]
prediction: ['[CLS] shoot tub necessity the capturing indiana curriculumjured of an disappeared goo a killed ideal story [SEP]']
[ 300/2000] tot_loss=2.884 (perp=11.979, rec=0.493, cos=-0.005), tot_loss_proj:4.369 [t=0.21s]
prediction: ['[CLS] aa tub custom about capturing indiana layersjured of an disappeared goo a loveitia story [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.805 (perp=11.692, rec=0.472, cos=-0.006), tot_loss_proj:4.285 [t=0.21s]
prediction: ['[CLS] aa his constructed the capturing indiana layersjured of an disappeared goo a love storyitia [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.889 (perp=12.120, rec=0.472, cos=-0.007), tot_loss_proj:4.382 [t=0.21s]
prediction: ['[CLS]bard ideal his constructed the indiana twentyjured story impulse disappeared goo a love story disappear [SEP]']
[ 450/2000] tot_loss=2.851 (perp=12.015, rec=0.456, cos=-0.009), tot_loss_proj:4.406 [t=0.21s]
prediction: ['[CLS]bard capturing his constructed the indiana twentyjured story every disappeared goo a love story disappear [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.972 (perp=12.364, rec=0.480, cos=0.019), tot_loss_proj:4.175 [t=0.21s]
prediction: ['[CLS]bard capturingyas polished constructed the twentyjured story consider disappeared goo a love story disappear [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.872 (perp=12.031, rec=0.472, cos=-0.006), tot_loss_proj:4.366 [t=0.21s]
prediction: ['[CLS]bardyas his constructed the twentyjured storyà¶½ disappeared goo inspirational the love story undisclosed [SEP]']
[ 600/2000] tot_loss=2.802 (perp=11.835, rec=0.442, cos=-0.007), tot_loss_proj:4.108 [t=0.21s]
prediction: ['[CLS]bard daughter polished constructed the twenty fact storytly disappeared goo inspirational an love story undisclosed [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.692 (perp=11.282, rec=0.445, cos=-0.010), tot_loss_proj:3.915 [t=0.21s]
prediction: ['[CLS]bard daughter polished constructed the twenty fact story the disappeared goo inspirationalphate love story undisclosed [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.639 (perp=11.045, rec=0.438, cos=-0.008), tot_loss_proj:3.872 [t=0.27s]
prediction: ['[CLS] title daughter arranged inspirational constructed the layers fact story the disappeared gooæ­Œ love story undisclosed [SEP]']
[ 750/2000] tot_loss=2.830 (perp=11.823, rec=0.452, cos=0.014), tot_loss_proj:4.049 [t=0.26s]
prediction: ['[CLS]bard daughter arranged inspirational constructed the layers fact story the disappeared gooæ­Œ love story undisclosed [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.700 (perp=11.424, rec=0.425, cos=-0.010), tot_loss_proj:4.036 [t=0.27s]
prediction: ['[CLS]bard daughter arranged fact constructed the layers inspirational story the disappeared gooæ­Œ love story undisclosed [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.732 (perp=11.480, rec=0.441, cos=-0.005), tot_loss_proj:4.010 [t=0.26s]
prediction: ['[CLS] daughter arranged fact inspirational the layers inspirational storybard the disappearedtureæ­Œ love story undisclosed [SEP]']
[ 900/2000] tot_loss=2.787 (perp=11.868, rec=0.423, cos=-0.010), tot_loss_proj:4.106 [t=0.27s]
prediction: ['[CLS] daughter arranged fact inspirational the layers inspirational storybard an disappearedtureæ­Œ love story undisclosed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.631 (perp=11.113, rec=0.418, cos=-0.010), tot_loss_proj:3.942 [t=0.26s]
prediction: ['[CLS] daughterbard charley inspirational the perspective inspirational story arranged the disappearedtureæ­Œ love story undisclosed [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.566 (perp=10.698, rec=0.432, cos=-0.006), tot_loss_proj:4.022 [t=0.26s]
prediction: ['[CLS] daughterbard charley inspirational inspirational story arranged the layers the disappeared gooæ­Œ love story undisclosed [SEP]']
[1050/2000] tot_loss=2.711 (perp=11.478, rec=0.425, cos=-0.010), tot_loss_proj:4.141 [t=0.28s]
prediction: ['[CLS] racebard charley inspirational inspirational story arranged instrumental perspective the disappearedtureæ­Œ love story undisclosed [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.544 (perp=10.674, rec=0.419, cos=-0.010), tot_loss_proj:3.958 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspectivebard the disappearedtureæ­Œ love story undisclosed [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.455 (perp=10.239, rec=0.416, cos=-0.008), tot_loss_proj:3.913 [t=0.25s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspectivebard the disappearedæ­Œ love storyture undisclosed [SEP]']
[1200/2000] tot_loss=2.535 (perp=10.665, rec=0.412, cos=-0.010), tot_loss_proj:3.962 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged instrumental perspectivebard the disappearedæ­Œ love storyture undisclosed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.488 (perp=10.440, rec=0.410, cos=-0.010), tot_loss_proj:3.517 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged instrumental perspectivebard the disappeared several love storyture encounter [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.535 (perp=10.551, rec=0.431, cos=-0.006), tot_loss_proj:3.826 [t=0.25s]
prediction: ['[CLS] race charley inspirational inspirational story arranged instrumental perspective brightlybard an disappeared love storyture introduction [SEP]']
[1350/2000] tot_loss=2.317 (perp=9.577, rec=0.411, cos=-0.010), tot_loss_proj:3.335 [t=0.27s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective brightlybard the disappeared love storyture introduction [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.315 (perp=9.609, rec=0.403, cos=-0.010), tot_loss_proj:3.477 [t=0.27s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspectivebard the several disappeared love storyture introduction [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.274 (perp=9.348, rec=0.413, cos=-0.009), tot_loss_proj:3.491 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture introduction [SEP]']
[1500/2000] tot_loss=2.273 (perp=9.348, rec=0.413, cos=-0.010), tot_loss_proj:3.496 [t=0.27s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture introduction [SEP]']
Attempt swap
[1550/2000] tot_loss=2.266 (perp=9.348, rec=0.406, cos=-0.010), tot_loss_proj:3.491 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture introduction [SEP]']
Attempt swap
[1600/2000] tot_loss=2.246 (perp=9.250, rec=0.406, cos=-0.010), tot_loss_proj:3.391 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]']
[1650/2000] tot_loss=2.242 (perp=9.250, rec=0.402, cos=-0.010), tot_loss_proj:3.383 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]']
Attempt swap
[1700/2000] tot_loss=2.242 (perp=9.250, rec=0.402, cos=-0.010), tot_loss_proj:3.385 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]']
Attempt swap
[1750/2000] tot_loss=2.238 (perp=9.250, rec=0.398, cos=-0.010), tot_loss_proj:3.386 [t=0.25s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]']
[1800/2000] tot_loss=2.242 (perp=9.250, rec=0.402, cos=-0.010), tot_loss_proj:3.388 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]']
Attempt swap
[1850/2000] tot_loss=2.239 (perp=9.250, rec=0.399, cos=-0.010), tot_loss_proj:3.386 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.201 (perp=8.999, rec=0.409, cos=-0.007), tot_loss_proj:3.180 [t=0.27s]
prediction: ['[CLS] race charley inspirational inspirational perspective arranged the story severalbard the vanished love storyture encounter [SEP]']
[1950/2000] tot_loss=2.192 (perp=8.999, rec=0.402, cos=-0.010), tot_loss_proj:3.179 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational perspective arranged the story severalbard the vanished love storyture encounter [SEP]']
Attempt swap
[2000/2000] tot_loss=2.195 (perp=8.999, rec=0.405, cos=-0.010), tot_loss_proj:3.177 [t=0.26s]
prediction: ['[CLS] race charley inspirational inspirational perspective arranged the story severalbard the vanished love storyture encounter [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] race charley inspirational inspirational story arranged the perspective severalbard the disappeared love storyture encounter [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 43.750 | p: 43.750 | r: 43.750
rouge2     | fm: 6.667 | p: 6.667 | r: 6.667
rougeL     | fm: 37.500 | p: 37.500 | r: 37.500
rougeLsum  | fm: 37.500 | p: 37.500 | r: 37.500
r1fm+r2fm = 50.417

[Aggregate metrics]:
rouge1     | fm: 88.842 | p: 88.373 | r: 89.389
rouge2     | fm: 58.512 | p: 58.337 | r: 58.765
rougeL     | fm: 78.117 | p: 77.787 | r: 78.524
rougeLsum  | fm: 77.847 | p: 77.493 | r: 78.279
r1fm+r2fm = 147.353

input #58 time: 0:10:06 | total time: 9:52:46


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9151541590690613 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.9016127586364746 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8955602645874023 for ['[CLS] clutch sports meridian placed weekly dixonwords upâ„ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.865580677986145 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.857191801071167 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8294965028762817 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8291977643966675 for ['[CLS] wasby temperament awhile noah information bologna 1993 fleet thus pump bobo races tunnel stuffak [SEP]']
[Init] best perm rec loss: 0.8291869163513184 for ['[CLS] awhile pump bobo tunnel fleet thus was temperamentak races stuff noah 1993by bologna information [SEP]']
[Init] best perm rec loss: 0.8275994658470154 for ['[CLS] thus information pump temperament awhile bobo races stuff fleetby was 1993 noah tunnelak bologna [SEP]']
[Init] best perm rec loss: 0.8272705078125 for ['[CLS] fleet temperament pumpak information noah bologna races tunnelby awhile thus stuff bobo 1993 was [SEP]']
[Init] best perm rec loss: 0.8271450400352478 for ['[CLS] bologna tunnel pump thus noah races information bobo stuff fleet 1993 temperament wasakby awhile [SEP]']
[Init] best perm rec loss: 0.8269852995872498 for ['[CLS] bologna pump 1993 information awhile stuffbyak bobo fleet races temperament thus was noah tunnel [SEP]']
[Init] best perm rec loss: 0.8267932534217834 for ['[CLS] thus 1993 bologna stuff pump temperament fleet tunnel was awhile noahakby races bobo information [SEP]']
[Init] best perm rec loss: 0.8258228898048401 for ['[CLS] bobo stuff temperamentby tunnel 1993 informationak thus races awhile noah bologna pump was fleet [SEP]']
[Init] best perm rec loss: 0.8244286775588989 for ['[CLS]by fleet thus information bologna tunnel temperament races awhile stuff pump noah bobo was 1993ak [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.207 (perp=14.124, rec=0.377, cos=0.005), tot_loss_proj:3.545 [t=0.25s]
prediction: ['[CLS] amazing script barefoot confident neillhn strong motorcycleona keith skilled outstandingist woman new touch [SEP]']
[ 100/2000] tot_loss=2.723 (perp=12.214, rec=0.286, cos=-0.006), tot_loss_proj:3.150 [t=0.27s]
prediction: ['[CLS] amazing screen intently succeeds maritime pe the who ruthsky skilled young team woman has of [SEP]']
[ 150/2000] tot_loss=2.596 (perp=11.873, rec=0.230, cos=-0.009), tot_loss_proj:3.070 [t=0.26s]
prediction: ['[CLS] amazing screen how succeeds & of theism screen county an young holding woman has logic [SEP]']
[ 200/2000] tot_loss=2.374 (perp=10.886, rec=0.206, cos=-0.009), tot_loss_proj:3.821 [t=0.26s]
prediction: ['[CLS] char screen howism or of theism screen who a young holding woman has char [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.301 (perp=10.581, rec=0.194, cos=-0.009), tot_loss_proj:3.815 [t=0.26s]
prediction: ['[CLS]ism screen howism or of of char screen who a young holding woman has char [SEP]']
[ 300/2000] tot_loss=2.366 (perp=11.068, rec=0.161, cos=-0.009), tot_loss_proj:3.663 [t=0.26s]
prediction: ['[CLS] of screen knowsism ora of char screenism a young holding woman has char [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.167 (perp=10.081, rec=0.159, cos=-0.009), tot_loss_proj:3.321 [t=0.27s]
prediction: ['[CLS] of screen has the or char of char screenism a young hold woman knowsism [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.070 (perp=9.781, rec=0.123, cos=-0.009), tot_loss_proj:3.158 [t=0.28s]
prediction: ['[CLS] of screen has the or char of char screenism a hold young woman knowsism [SEP]']
[ 450/2000] tot_loss=2.062 (perp=9.781, rec=0.115, cos=-0.009), tot_loss_proj:3.152 [t=0.27s]
prediction: ['[CLS] of screen has the or char of char screenism a hold young woman knowsism [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.946 (perp=9.231, rec=0.109, cos=-0.009), tot_loss_proj:3.176 [t=0.26s]
prediction: ['[CLS] of screen has thea of char or screenism a hold young woman howism [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.838 (perp=8.703, rec=0.107, cos=-0.009), tot_loss_proj:2.787 [t=0.26s]
prediction: ['[CLS] of screen has thea of char or screenismism a hold young woman knows [SEP]']
[ 600/2000] tot_loss=1.828 (perp=8.703, rec=0.096, cos=-0.009), tot_loss_proj:2.784 [t=0.27s]
prediction: ['[CLS] of screen has thea of char or screenismism a hold young woman knows [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.827 (perp=8.703, rec=0.096, cos=-0.009), tot_loss_proj:2.785 [t=0.28s]
prediction: ['[CLS] of screen has thea of char or screenismism a hold young woman knows [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.808 (perp=8.535, rec=0.110, cos=-0.009), tot_loss_proj:2.677 [t=0.29s]
prediction: ['[CLS]a screen has theism of char or screenisma a hold young woman knows [SEP]']
[ 750/2000] tot_loss=1.803 (perp=8.535, rec=0.105, cos=-0.009), tot_loss_proj:2.669 [t=0.26s]
prediction: ['[CLS]a screen has theism of char or screenisma a hold young woman knows [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.703 (perp=8.061, rec=0.100, cos=-0.009), tot_loss_proj:2.633 [t=0.29s]
prediction: ['[CLS] screena has theism of char or screenisma a hold young woman knows [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.635 (perp=7.691, rec=0.105, cos=-0.009), tot_loss_proj:2.883 [t=0.26s]
prediction: ['[CLS] screena has theism of char screenisma or a hold young woman knows [SEP]']
[ 900/2000] tot_loss=1.639 (perp=7.691, rec=0.109, cos=-0.009), tot_loss_proj:2.884 [t=0.27s]
prediction: ['[CLS] screena has theism of char screenisma or a hold young woman knows [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.542 (perp=7.251, rec=0.101, cos=-0.009), tot_loss_proj:2.318 [t=0.27s]
prediction: ['[CLS] screena has theism of charisma or screen a hold young woman knows [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.529 (perp=7.187, rec=0.101, cos=-0.009), tot_loss_proj:2.344 [t=0.29s]
prediction: ['[CLS] screen thea hasism of charisma or screen a hold young woman knows [SEP]']
[1050/2000] tot_loss=1.514 (perp=7.187, rec=0.085, cos=-0.009), tot_loss_proj:2.348 [t=0.28s]
prediction: ['[CLS] screen thea hasism of charisma or screen a hold young woman knows [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.506 (perp=7.154, rec=0.084, cos=-0.009), tot_loss_proj:2.236 [t=0.27s]
prediction: ['[CLS] screen thea hasism of charisma or screen hold a young woman knows [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.502 (perp=7.070, rec=0.097, cos=-0.009), tot_loss_proj:2.218 [t=0.25s]
prediction: ['[CLS] the screena hasism of charisma or screen hold a young woman knows [SEP]']
[1200/2000] tot_loss=1.504 (perp=7.155, rec=0.083, cos=-0.009), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] the screena hasism of charisma the screen hold a young woman knows [SEP]']
Attempt swap
[1250/2000] tot_loss=1.512 (perp=7.155, rec=0.090, cos=-0.009), tot_loss_proj:2.117 [t=0.29s]
prediction: ['[CLS] the screena hasism of charisma the screen hold a young woman knows [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.508 (perp=7.064, rec=0.104, cos=-0.009), tot_loss_proj:2.086 [t=0.28s]
prediction: ['[CLS] the screen hasisma of charisma the screen hold a young woman knows [SEP]']
[1350/2000] tot_loss=1.503 (perp=7.064, rec=0.099, cos=-0.009), tot_loss_proj:2.086 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma the screen hold a young woman knows [SEP]']
Attempt swap
[1400/2000] tot_loss=1.501 (perp=7.064, rec=0.098, cos=-0.009), tot_loss_proj:2.085 [t=0.26s]
prediction: ['[CLS] the screen hasisma of charisma the screen hold a young woman knows [SEP]']
Attempt swap
[1450/2000] tot_loss=1.505 (perp=7.064, rec=0.101, cos=-0.009), tot_loss_proj:2.087 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma the screen hold a young woman knows [SEP]']
[1500/2000] tot_loss=1.498 (perp=7.064, rec=0.094, cos=-0.009), tot_loss_proj:2.086 [t=0.26s]
prediction: ['[CLS] the screen hasisma of charisma the screen hold a young woman knows [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.476 (perp=6.952, rec=0.095, cos=-0.009), tot_loss_proj:2.139 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows hold a young woman [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.471 (perp=6.912, rec=0.098, cos=-0.009), tot_loss_proj:2.053 [t=0.26s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
[1650/2000] tot_loss=1.478 (perp=6.912, rec=0.105, cos=-0.009), tot_loss_proj:2.061 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.470 (perp=6.912, rec=0.096, cos=-0.009), tot_loss_proj:2.031 [t=0.26s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
Attempt swap
[1750/2000] tot_loss=1.461 (perp=6.912, rec=0.088, cos=-0.009), tot_loss_proj:2.034 [t=0.26s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
[1800/2000] tot_loss=1.457 (perp=6.912, rec=0.084, cos=-0.009), tot_loss_proj:2.030 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
Attempt swap
[1850/2000] tot_loss=1.472 (perp=6.912, rec=0.099, cos=-0.009), tot_loss_proj:2.037 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.459 (perp=6.912, rec=0.086, cos=-0.009), tot_loss_proj:2.027 [t=0.28s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
[1950/2000] tot_loss=1.475 (perp=6.912, rec=0.102, cos=-0.009), tot_loss_proj:2.039 [t=0.28s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.459 (perp=6.912, rec=0.086, cos=-0.009), tot_loss_proj:2.028 [t=0.27s]
prediction: ['[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] the screen hasisma of charisma in screen knows a young woman hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.333 | p: 78.571 | r: 68.750
rouge2     | fm: 21.429 | p: 23.077 | r: 20.000
rougeL     | fm: 53.333 | p: 57.143 | r: 50.000
rougeLsum  | fm: 53.333 | p: 57.143 | r: 50.000
r1fm+r2fm = 94.762

[Aggregate metrics]:
rouge1     | fm: 88.645 | p: 88.289 | r: 89.127
rouge2     | fm: 57.806 | p: 57.640 | r: 58.037
rougeL     | fm: 77.749 | p: 77.435 | r: 78.096
rougeLsum  | fm: 77.498 | p: 77.235 | r: 77.878
r1fm+r2fm = 146.451

input #59 time: 0:11:10 | total time: 10:03:56


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
*********************************
*********************************
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9299472570419312 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9130843281745911 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8701856732368469 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8695709109306335 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8544469475746155 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.842263400554657 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8397374749183655 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 0.8392449617385864 for ['[CLS] majorityitudelby upsetouring plentyshaw constitution cover strung through / [SEP]']
[Init] best perm rec loss: 0.8391808867454529 for ['[CLS]itude coverouring majoritylbyshaw through / plenty upset strung constitution [SEP]']
[Init] best perm rec loss: 0.8388378024101257 for ['[CLS]lby / upsetouring constitutionshaw cover strung majorityitude through plenty [SEP]']
[Init] best perm rec loss: 0.838720440864563 for ['[CLS] throughlby / majority upset strungitude constitutionshaw plentyouring cover [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.037 (perp=13.570, rec=0.329, cos=-0.006), tot_loss_proj:3.372 [t=0.29s]
prediction: ['[CLS] legs leasttext television clip player awkwardly awkwardly pretended shaft seminary plain [SEP]']
[ 100/2000] tot_loss=2.631 (perp=12.008, rec=0.238, cos=-0.009), tot_loss_proj:2.914 [t=0.29s]
prediction: ['[CLS]station awkwardly paced records clip story awkwardly awkwardly sitcom story seminary. [SEP]']
[ 150/2000] tot_loss=2.238 (perp=10.286, rec=0.190, cos=-0.009), tot_loss_proj:2.698 [t=0.28s]
prediction: ['[CLS] circuit awkwardly paced is clip story awkwardly awkwardly sitcom story circuit. [SEP]']
[ 200/2000] tot_loss=2.278 (perp=10.559, rec=0.172, cos=-0.006), tot_loss_proj:2.766 [t=0.28s]
prediction: ['[CLS] circuit opera paced is season story awkwardly awkwardly soap story circuit. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.069 (perp=9.537, rec=0.170, cos=-0.008), tot_loss_proj:2.550 [t=0.26s]
prediction: ['[CLS] circuit paced story awkwardly awkwardly soap opera paced is storyta. [SEP]']
[ 300/2000] tot_loss=2.094 (perp=9.824, rec=0.139, cos=-0.009), tot_loss_proj:2.585 [t=0.25s]
prediction: ['[CLS] circuit clip story awkwardly awkwardly soap opera paced is storyta. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.964 (perp=9.256, rec=0.122, cos=-0.009), tot_loss_proj:3.221 [t=0.25s]
prediction: ['[CLS] circuit season story awkwardly awkwardly soap operata is story paced. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.887 (perp=8.890, rec=0.118, cos=-0.009), tot_loss_proj:2.795 [t=0.26s]
prediction: ['[CLS] circuit story cycle awkwardly awkwardly soap operata is story paced. [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.890, rec=0.119, cos=-0.009), tot_loss_proj:2.797 [t=0.25s]
prediction: ['[CLS] circuit story cycle awkwardly awkwardly soap operata is story paced. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.876 (perp=8.890, rec=0.107, cos=-0.009), tot_loss_proj:2.798 [t=0.26s]
prediction: ['[CLS] circuit story cycle awkwardly awkwardly soap operata is story paced. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.863 (perp=8.843, rec=0.104, cos=-0.009), tot_loss_proj:2.989 [t=0.25s]
prediction: ['[CLS] circuit opera story awkwardly awkwardly soap operata is story paced. [SEP]']
[ 600/2000] tot_loss=1.863 (perp=8.843, rec=0.104, cos=-0.009), tot_loss_proj:2.997 [t=0.26s]
prediction: ['[CLS] circuit opera story awkwardly awkwardly soap operata is story paced. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.946 (perp=9.210, rec=0.114, cos=-0.009), tot_loss_proj:2.449 [t=0.25s]
prediction: ['[CLS] circuit opera story awkwardly awkwardly soap operah is paced story. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.812 (perp=8.528, rec=0.115, cos=-0.009), tot_loss_proj:2.143 [t=0.26s]
prediction: ['[CLS] circuit awkwardly operah awkwardly soap operah is paced story. [SEP]']
[ 750/2000] tot_loss=1.965 (perp=9.331, rec=0.108, cos=-0.009), tot_loss_proj:2.344 [t=0.25s]
prediction: ['[CLS] circuit awkwardly operah awkwardly soap operah is paced story - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.971 (perp=9.331, rec=0.114, cos=-0.009), tot_loss_proj:2.342 [t=0.27s]
prediction: ['[CLS] circuit awkwardly operah awkwardly soap operah is paced story - [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.857 (perp=8.745, rec=0.117, cos=-0.009), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] circuit awkwardly awkwardly soap operah operah is paced story - [SEP]']
[ 900/2000] tot_loss=1.950 (perp=9.242, rec=0.111, cos=-0.009), tot_loss_proj:2.450 [t=0.25s]
prediction: ['[CLS] circuit awkwardly awkwardly soap operah operata is paced story - [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.966 (perp=9.342, rec=0.107, cos=-0.009), tot_loss_proj:2.461 [t=0.27s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera operah opera is paced story - [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.112 (perp=10.023, rec=0.117, cos=-0.009), tot_loss_proj:2.535 [t=0.26s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera pacedh opera issphere story - [SEP]']
[1050/2000] tot_loss=2.000 (perp=9.546, rec=0.100, cos=-0.009), tot_loss_proj:2.350 [t=0.27s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera pacedh opera ish story - [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.900 (perp=9.004, rec=0.108, cos=-0.009), tot_loss_proj:2.236 [t=0.25s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera pacedh opera - ish story [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.800 (perp=8.547, rec=0.101, cos=-0.009), tot_loss_proj:2.133 [t=0.25s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced operah - ish story [SEP]']
[1200/2000] tot_loss=1.798 (perp=8.547, rec=0.098, cos=-0.009), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced operah - ish story [SEP]']
Attempt swap
[1250/2000] tot_loss=1.797 (perp=8.547, rec=0.098, cos=-0.010), tot_loss_proj:2.132 [t=0.26s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced operah - ish story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.800 (perp=8.547, rec=0.100, cos=-0.010), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced operah - ish story [SEP]']
[1350/2000] tot_loss=1.981 (perp=9.467, rec=0.097, cos=-0.010), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] circuit awkwardly awkwardly soap is paced operah - ish story [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.772 (perp=8.418, rec=0.098, cos=-0.010), tot_loss_proj:2.075 [t=0.27s]
prediction: ['[CLS] circuit awkwardly awkwardly paced is soap operah - ish story [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.975 (perp=9.411, rec=0.102, cos=-0.009), tot_loss_proj:2.270 [t=0.26s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap operah - issphere story [SEP]']
[1500/2000] tot_loss=1.693 (perp=7.984, rec=0.105, cos=-0.009), tot_loss_proj:1.974 [t=0.28s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap operah - ish story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.974 (perp=9.411, rec=0.101, cos=-0.009), tot_loss_proj:2.265 [t=0.27s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap operah - issphere story [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.878 (perp=8.932, rec=0.101, cos=-0.009), tot_loss_proj:2.173 [t=0.25s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap operaÙ€ - ish story [SEP]']
[1650/2000] tot_loss=1.870 (perp=8.932, rec=0.092, cos=-0.009), tot_loss_proj:2.171 [t=0.27s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap operaÙ€ - ish story [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.795 (perp=8.571, rec=0.090, cos=-0.009), tot_loss_proj:2.086 [t=0.26s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - ish storyÙ€ [SEP]']
Attempt swap
[1750/2000] tot_loss=1.793 (perp=8.571, rec=0.088, cos=-0.009), tot_loss_proj:2.085 [t=0.26s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - ish storyÙ€ [SEP]']
[1800/2000] tot_loss=1.798 (perp=8.571, rec=0.093, cos=-0.009), tot_loss_proj:2.084 [t=0.26s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - ish storyÙ€ [SEP]']
Attempt swap
[1850/2000] tot_loss=1.823 (perp=8.761, rec=0.080, cos=-0.009), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - ish storysphere [SEP]']
Attempt swap
[1900/2000] tot_loss=1.830 (perp=8.761, rec=0.087, cos=-0.009), tot_loss_proj:2.135 [t=0.26s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - ish storysphere [SEP]']
[1950/2000] tot_loss=1.781 (perp=8.498, rec=0.091, cos=-0.009), tot_loss_proj:2.062 [t=0.25s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - ish story the [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.559 (perp=7.379, rec=0.092, cos=-0.009), tot_loss_proj:1.833 [t=0.25s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] circuit awkwardly paced is awkwardly soap opera - ish story the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 88.717 | p: 88.343 | r: 89.247
rouge2     | fm: 57.839 | p: 57.593 | r: 58.073
rougeL     | fm: 77.630 | p: 77.282 | r: 78.065
rougeLsum  | fm: 77.567 | p: 77.199 | r: 78.008
r1fm+r2fm = 146.556

input #60 time: 0:11:03 | total time: 10:15:00


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
*********************************
*********************************
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9795893430709839 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9741564989089966 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9512136578559875 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9470409154891968 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9432965517044067 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9347224831581116 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9169871807098389 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9168724417686462 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9121196269989014 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.9106317162513733 for ['[CLS] installed equipped unlike [SEP]']
[Init] best rec loss: 0.8808217644691467 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8280910849571228 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8269730806350708 for ['[CLS] lets mini request [SEP]']
[Init] best perm rec loss: 0.8244650959968567 for ['[CLS] mini request lets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.206 (perp=9.683, rec=0.272, cos=-0.003), tot_loss_proj:2.385 [t=0.26s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.114 (perp=9.683, rec=0.182, cos=-0.004), tot_loss_proj:2.386 [t=0.26s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 150/2000] tot_loss=2.081 (perp=9.683, rec=0.150, cos=-0.005), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 200/2000] tot_loss=2.070 (perp=9.683, rec=0.140, cos=-0.006), tot_loss_proj:2.387 [t=0.25s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.676 (perp=7.752, rec=0.132, cos=-0.006), tot_loss_proj:1.794 [t=0.26s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 300/2000] tot_loss=1.665 (perp=8.032, rec=0.067, cos=-0.009), tot_loss_proj:1.678 [t=0.25s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.479 (perp=7.101, rec=0.068, cos=-0.009), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.488 (perp=7.101, rec=0.076, cos=-0.009), tot_loss_proj:1.624 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.476 (perp=7.101, rec=0.065, cos=-0.009), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.477 (perp=7.101, rec=0.065, cos=-0.009), tot_loss_proj:1.607 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.480 (perp=7.101, rec=0.069, cos=-0.009), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.482 (perp=7.101, rec=0.071, cos=-0.009), tot_loss_proj:1.603 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.475 (perp=7.101, rec=0.063, cos=-0.009), tot_loss_proj:1.616 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.482 (perp=7.101, rec=0.071, cos=-0.009), tot_loss_proj:1.616 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.466 (perp=7.101, rec=0.054, cos=-0.009), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.477 (perp=7.101, rec=0.066, cos=-0.009), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.478 (perp=7.101, rec=0.067, cos=-0.009), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.469 (perp=7.101, rec=0.057, cos=-0.009), tot_loss_proj:1.606 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.478 (perp=7.101, rec=0.066, cos=-0.009), tot_loss_proj:1.619 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.472 (perp=7.101, rec=0.060, cos=-0.009), tot_loss_proj:1.607 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.477 (perp=7.101, rec=0.066, cos=-0.009), tot_loss_proj:1.621 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.468 (perp=7.101, rec=0.056, cos=-0.009), tot_loss_proj:1.619 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.474 (perp=7.101, rec=0.062, cos=-0.009), tot_loss_proj:1.608 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.484 (perp=7.101, rec=0.072, cos=-0.009), tot_loss_proj:1.618 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.476 (perp=7.101, rec=0.064, cos=-0.009), tot_loss_proj:1.614 [t=0.28s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.479 (perp=7.101, rec=0.067, cos=-0.009), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.479 (perp=7.101, rec=0.067, cos=-0.009), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.478 (perp=7.101, rec=0.066, cos=-0.009), tot_loss_proj:1.620 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.486 (perp=7.101, rec=0.075, cos=-0.009), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.472 (perp=7.101, rec=0.060, cos=-0.009), tot_loss_proj:1.615 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.477 (perp=7.101, rec=0.065, cos=-0.009), tot_loss_proj:1.606 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.467 (perp=7.101, rec=0.055, cos=-0.009), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.456 (perp=7.101, rec=0.045, cos=-0.009), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.485 (perp=7.101, rec=0.073, cos=-0.009), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.466 (perp=7.101, rec=0.054, cos=-0.009), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.475 (perp=7.101, rec=0.064, cos=-0.009), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.473 (perp=7.101, rec=0.061, cos=-0.009), tot_loss_proj:1.617 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.478 (perp=7.101, rec=0.067, cos=-0.009), tot_loss_proj:1.612 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.476 (perp=7.101, rec=0.064, cos=-0.009), tot_loss_proj:1.605 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=7.101, rec=0.060, cos=-0.009), tot_loss_proj:1.610 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.954 | p: 88.556 | r: 89.403
rouge2     | fm: 58.353 | p: 58.139 | r: 58.647
rougeL     | fm: 78.023 | p: 77.706 | r: 78.418
rougeLsum  | fm: 77.851 | p: 77.503 | r: 78.316
r1fm+r2fm = 147.307

input #61 time: 0:11:02 | total time: 10:26:03


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
*********************************
*********************************
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9540637731552124 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9288767576217651 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.927240788936615 for ['[CLS] gem longer congregationiq commemorate members police later pm drawing [MASK]ly onwards drops team senator access head wrath miss shane [SEP]']
[Init] best rec loss: 0.9213613867759705 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9167788624763489 for ['[CLS] girl plain followedion recallsé–“ by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9164981842041016 for ['[CLS]nce followed mccarthy sioux by forum fight closely origins peckion humanitarian 2002 recalls reed spread tooth plain test girlé–“ [SEP]']
[Init] best perm rec loss: 0.914860188961029 for ['[CLS] girl by tooth forum followednce test reed sioux plain fight 2002 origins spread recalls closely humanitarian mccarthyé–“ peckion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.294 (perp=12.444, rec=0.764, cos=0.041), tot_loss_proj:4.052 [t=0.27s]
prediction: ['[CLS] virginia through war drawer campaign toward ass high confederatetight qu. sir hot necessity throat accident been game were hardly [SEP]']
[ 100/2000] tot_loss=2.624 (perp=10.102, rec=0.610, cos=-0.007), tot_loss_proj:3.600 [t=0.25s]
prediction: ['[CLS] our to war hallway any to ass slow wartight clips.. hot dollars of next he game were shrugged [SEP]']
[ 150/2000] tot_loss=3.009 (perp=11.744, rec=0.653, cos=0.007), tot_loss_proj:3.982 [t=0.27s]
prediction: ['[CLS] vampires to prevention prevention any communist bad among war courts audition /. hot dollars of next she game were none [SEP]']
[ 200/2000] tot_loss=2.916 (perp=11.875, rec=0.548, cos=-0.008), tot_loss_proj:4.057 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention pradesh sawmill ass among war parts making, major hot dollars of next she gore were shrugged [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.766 (perp=11.242, rec=0.521, cos=-0.003), tot_loss_proj:4.234 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention especially sawmill ass among war making sweet, major hot dollars of next movies gore were shrugged [SEP]']
[ 300/2000] tot_loss=2.673 (perp=10.939, rec=0.491, cos=-0.007), tot_loss_proj:4.052 [t=0.27s]
prediction: ['[CLS] grace to prevention prevention especially ã€Š best among war making defend, major hot challenge of learning movies ever were shrugged [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.635 (perp=10.834, rec=0.477, cos=-0.008), tot_loss_proj:4.024 [t=0.28s]
prediction: ['[CLS] grace to prevention prevention especially ã€Š task among war making er and major when challenge of best movies ever best shrugged [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.746 (perp=11.429, rec=0.468, cos=-0.008), tot_loss_proj:4.041 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention especially hai learning among war making when cher making major challenge of best movies ever best shrugged [SEP]']
[ 450/2000] tot_loss=2.607 (perp=10.547, rec=0.489, cos=0.009), tot_loss_proj:4.013 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention especially cnn think among war making when defend makingable ones of best movies ever best shrugged [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.581 (perp=10.657, rec=0.450, cos=-0.000), tot_loss_proj:4.073 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention especially cnn think among war making when gutable making ones of best movies ever best shrugged [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.617 (perp=10.958, rec=0.433, cos=-0.008), tot_loss_proj:3.906 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention especially hp ego among war making when thinkable making ones of best movies ever bestsit [SEP]']
[ 600/2000] tot_loss=2.625 (perp=11.095, rec=0.415, cos=-0.009), tot_loss_proj:3.959 [t=0.27s]
prediction: ['[CLS] grace to prevention prevention especially hp gut among war making when thinkable making ones of movies movies ever best probably [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.597 (perp=10.876, rec=0.422, cos=-0.000), tot_loss_proj:3.867 [t=0.27s]
prediction: ['[CLS] grace to prevention prevention especially hp gut among war making movies chaseable making ones of when movies ever best probably [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.606 (perp=10.823, rec=0.447, cos=-0.005), tot_loss_proj:3.939 [t=0.27s]
prediction: ['[CLS] grace to prevention prevention movies hp gut among war making especially chaseable making ones of when movies ever bestsit [SEP]']
[ 750/2000] tot_loss=2.576 (perp=10.828, rec=0.417, cos=-0.006), tot_loss_proj:3.926 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention movies hp gut among war grossing especially chaseable making ones of when movies ever best probably [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.440 (perp=10.222, rec=0.406, cos=-0.010), tot_loss_proj:3.923 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention grossing like gut among war movies especially chaseable making ones of when movies ever best probably [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.434 (perp=10.222, rec=0.398, cos=-0.009), tot_loss_proj:3.925 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention grossing like gut among war movies especially chaseable making ones of when movies ever best probably [SEP]']
[ 900/2000] tot_loss=2.501 (perp=10.569, rec=0.394, cos=-0.006), tot_loss_proj:3.952 [t=0.28s]
prediction: ['[CLS] grace to prevention prevention grossing like gut among war movies especially chaseable making ones of when film ever best probably [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.410 (perp=10.142, rec=0.389, cos=-0.008), tot_loss_proj:3.914 [t=0.26s]
prediction: ['[CLS] grace to prevention prevention grossing like gut among war movies especially chaseable making ones of film when ever best probably [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.309 (perp=9.628, rec=0.391, cos=-0.008), tot_loss_proj:3.779 [t=0.25s]
prediction: ['[CLS] grace to prevention prevention grossing like ego among war movies especially chaseable making ones of film when best probably ever [SEP]']
[1050/2000] tot_loss=2.353 (perp=9.906, rec=0.380, cos=-0.009), tot_loss_proj:3.970 [t=0.28s]
prediction: ['[CLS] grace to prevention prevention grossing like ego biggest war movies rather chaseable making ones of film when best probably ever [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.317 (perp=9.751, rec=0.377, cos=-0.010), tot_loss_proj:3.883 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing like ego biggest war movies rather chaseable making ones of film probably best when ever [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.400 (perp=9.966, rec=0.411, cos=-0.005), tot_loss_proj:4.012 [t=0.29s]
prediction: ['[CLS] grace to prevention prevention grossing as ego biggest war movies rather chaseable making ones cnn film probably best when ever [SEP]']
[1200/2000] tot_loss=2.389 (perp=10.066, rec=0.385, cos=-0.010), tot_loss_proj:4.028 [t=0.28s]
prediction: ['[CLS] grace to prevention warned grossing as ego biggest war movies rather chaseable making ones cnn film probably best when ever [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.306 (perp=9.631, rec=0.389, cos=-0.009), tot_loss_proj:3.900 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing as ego biggest war movies rather chaseable ones cnn film making probably best when ever [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.256 (perp=9.373, rec=0.388, cos=-0.007), tot_loss_proj:3.854 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing biggest ego as war movies rather chaseable ones cnn film making probably best when ever [SEP]']
[1350/2000] tot_loss=2.240 (perp=9.373, rec=0.376, cos=-0.010), tot_loss_proj:3.856 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing biggest ego as war movies rather chaseable ones cnn film making probably best when ever [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.268 (perp=9.494, rec=0.379, cos=-0.010), tot_loss_proj:3.863 [t=0.28s]
prediction: ['[CLS] grace to prevention warned grossing abuse biggest as war movies rather chaseable ones cnn film making probably best when ever [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.204 (perp=9.182, rec=0.375, cos=-0.008), tot_loss_proj:3.773 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing movies ego biggest as war rather chaseable ones cnn film making probably best when ever [SEP]']
[1500/2000] tot_loss=2.200 (perp=9.182, rec=0.373, cos=-0.010), tot_loss_proj:3.775 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing movies ego biggest as war rather chaseable ones cnn film making probably best when ever [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.229 (perp=9.306, rec=0.378, cos=-0.010), tot_loss_proj:3.801 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing ego biggest as war movies rather chaseable ones we film making probably best when ever [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.204 (perp=9.112, rec=0.387, cos=-0.006), tot_loss_proj:3.723 [t=0.28s]
prediction: ['[CLS] grace to prevention warned grossing ego biggest as war movies rather chaseable ones when we film making probably best ever [SEP]']
[1650/2000] tot_loss=2.265 (perp=9.494, rec=0.376, cos=-0.010), tot_loss_proj:3.672 [t=0.29s]
prediction: ['[CLS] grace to prevention warned grossing abuse biggest as war movies rather chaseable ones when we film making probably best ever [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=2.217 (perp=9.253, rec=0.376, cos=-0.010), tot_loss_proj:3.682 [t=0.29s]
prediction: ['[CLS] grace to prevention warned abuse biggest grossing as war movies rather chaseable ones when we film making probably best ever [SEP]']
Attempt swap
[1750/2000] tot_loss=2.210 (perp=9.253, rec=0.369, cos=-0.010), tot_loss_proj:3.680 [t=0.29s]
prediction: ['[CLS] grace to prevention warned abuse biggest grossing as war movies rather chaseable ones when we film making probably best ever [SEP]']
[1800/2000] tot_loss=2.175 (perp=9.029, rec=0.379, cos=-0.010), tot_loss_proj:3.725 [t=0.28s]
prediction: ['[CLS] grace to prevention warned abuse biggest grossing of war movies rather chaseable ones when we film making probably best ever [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.133 (perp=8.882, rec=0.367, cos=-0.010), tot_loss_proj:3.622 [t=0.29s]
prediction: ['[CLS] grace to prevention abuse biggest warned grossing of war movies rather chaseable ones when we film making probably best ever [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.121 (perp=8.769, rec=0.376, cos=-0.008), tot_loss_proj:3.664 [t=0.29s]
prediction: ['[CLS] grace to prevention abuse biggest warned grossing movies of war rather chaseable ones when we film making probably best ever [SEP]']
[1950/2000] tot_loss=2.118 (perp=8.769, rec=0.374, cos=-0.010), tot_loss_proj:3.663 [t=0.29s]
prediction: ['[CLS] grace to prevention abuse biggest warned grossing movies of war rather chaseable ones when we film making probably best ever [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.091 (perp=8.669, rec=0.367, cos=-0.010), tot_loss_proj:3.584 [t=0.28s]
prediction: ['[CLS] grace to prevention biggest abuse warned grossing movies of war rather chaseable ones when we film making probably best ever [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to prevention warned abuse biggest grossing as war movies rather chaseable ones when we film making probably best ever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 40.909 | p: 40.909 | r: 40.909
rougeLsum  | fm: 40.909 | p: 40.909 | r: 40.909
r1fm+r2fm = 64.286

[Aggregate metrics]:
rouge1     | fm: 88.286 | p: 87.805 | r: 88.801
rouge2     | fm: 57.766 | p: 57.523 | r: 58.062
rougeL     | fm: 77.458 | p: 77.097 | r: 77.858
rougeLsum  | fm: 77.277 | p: 76.926 | r: 77.650
r1fm+r2fm = 146.052

input #62 time: 0:11:23 | total time: 10:37:27


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
*********************************
*********************************
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9565043449401855 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9048953652381897 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7484632730484009 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7433376908302307 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.739037811756134 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7285273671150208 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7276551127433777 for ['[CLS] solutions forces offense... civil [SEP]']
[Init] best perm rec loss: 0.7259407639503479 for ['[CLS] solutions civil forces... offense [SEP]']
[Init] best perm rec loss: 0.7244595885276794 for ['[CLS] forces... offense solutions civil [SEP]']
[Init] best perm rec loss: 0.7240341901779175 for ['[CLS] forces solutions... civil offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.726 (perp=11.389, rec=0.445, cos=0.003), tot_loss_proj:3.434 [t=0.25s]
prediction: ['[CLS] failed fleeing lost money solidarity [SEP]']
[ 100/2000] tot_loss=2.675 (perp=12.086, rec=0.264, cos=-0.006), tot_loss_proj:3.782 [t=0.25s]
prediction: ['[CLS] failed seek di ticket ticket [SEP]']
[ 150/2000] tot_loss=2.311 (perp=10.701, rec=0.179, cos=-0.008), tot_loss_proj:3.182 [t=0.27s]
prediction: ['[CLS] return looking a ticket ticket [SEP]']
[ 200/2000] tot_loss=2.350 (perp=11.116, rec=0.136, cos=-0.009), tot_loss_proj:3.536 [t=0.25s]
prediction: ['[CLS] return looking a ticket return [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.952 (perp=9.290, rec=0.102, cos=-0.008), tot_loss_proj:2.977 [t=0.27s]
prediction: ['[CLS] looking return a ticket return [SEP]']
[ 300/2000] tot_loss=1.952 (perp=9.290, rec=0.103, cos=-0.009), tot_loss_proj:2.973 [t=0.26s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.939 (perp=9.290, rec=0.091, cos=-0.009), tot_loss_proj:2.970 [t=0.28s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.935 (perp=9.290, rec=0.086, cos=-0.009), tot_loss_proj:2.966 [t=0.26s]
prediction: ['[CLS] looking return a ticket return [SEP]']
[ 450/2000] tot_loss=1.931 (perp=9.290, rec=0.083, cos=-0.009), tot_loss_proj:2.958 [t=0.26s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.933 (perp=9.290, rec=0.085, cos=-0.009), tot_loss_proj:2.964 [t=0.26s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.840 (perp=8.851, rec=0.079, cos=-0.009), tot_loss_proj:2.921 [t=0.25s]
prediction: ['[CLS] looking return a ticket for [SEP]']
[ 600/2000] tot_loss=1.830 (perp=8.851, rec=0.070, cos=-0.009), tot_loss_proj:2.925 [t=0.26s]
prediction: ['[CLS] looking return a ticket for [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.266 (perp=5.941, rec=0.088, cos=-0.009), tot_loss_proj:1.453 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.250 (perp=5.941, rec=0.072, cos=-0.009), tot_loss_proj:1.452 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 750/2000] tot_loss=1.246 (perp=5.941, rec=0.067, cos=-0.009), tot_loss_proj:1.449 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.252 (perp=5.941, rec=0.074, cos=-0.009), tot_loss_proj:1.445 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.254 (perp=5.941, rec=0.075, cos=-0.010), tot_loss_proj:1.449 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 900/2000] tot_loss=1.248 (perp=5.941, rec=0.069, cos=-0.010), tot_loss_proj:1.445 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.239 (perp=5.941, rec=0.061, cos=-0.010), tot_loss_proj:1.449 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.241 (perp=5.941, rec=0.062, cos=-0.010), tot_loss_proj:1.453 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1050/2000] tot_loss=1.247 (perp=5.941, rec=0.069, cos=-0.010), tot_loss_proj:1.450 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.246 (perp=5.941, rec=0.067, cos=-0.010), tot_loss_proj:1.448 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.248 (perp=5.941, rec=0.069, cos=-0.010), tot_loss_proj:1.455 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1200/2000] tot_loss=1.246 (perp=5.941, rec=0.068, cos=-0.010), tot_loss_proj:1.449 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.247 (perp=5.941, rec=0.068, cos=-0.010), tot_loss_proj:1.448 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.251 (perp=5.941, rec=0.072, cos=-0.010), tot_loss_proj:1.451 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1350/2000] tot_loss=1.239 (perp=5.941, rec=0.060, cos=-0.010), tot_loss_proj:1.449 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.239 (perp=5.941, rec=0.060, cos=-0.010), tot_loss_proj:1.443 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.240 (perp=5.941, rec=0.061, cos=-0.010), tot_loss_proj:1.453 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1500/2000] tot_loss=1.231 (perp=5.941, rec=0.053, cos=-0.010), tot_loss_proj:1.447 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.246 (perp=5.941, rec=0.067, cos=-0.010), tot_loss_proj:1.450 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.229 (perp=5.941, rec=0.051, cos=-0.010), tot_loss_proj:1.456 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1650/2000] tot_loss=1.248 (perp=5.941, rec=0.070, cos=-0.010), tot_loss_proj:1.451 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.241 (perp=5.941, rec=0.062, cos=-0.010), tot_loss_proj:1.443 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.242 (perp=5.941, rec=0.064, cos=-0.010), tot_loss_proj:1.450 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1800/2000] tot_loss=1.242 (perp=5.941, rec=0.064, cos=-0.010), tot_loss_proj:1.440 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.239 (perp=5.941, rec=0.060, cos=-0.010), tot_loss_proj:1.444 [t=0.25s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.247 (perp=5.941, rec=0.069, cos=-0.010), tot_loss_proj:1.447 [t=0.26s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1950/2000] tot_loss=1.232 (perp=5.941, rec=0.054, cos=-0.010), tot_loss_proj:1.446 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.245 (perp=5.941, rec=0.067, cos=-0.010), tot_loss_proj:1.451 [t=0.27s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a ticket return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 88.478 | p: 88.055 | r: 88.981
rouge2     | fm: 57.458 | p: 57.224 | r: 57.717
rougeL     | fm: 77.516 | p: 77.183 | r: 77.923
rougeLsum  | fm: 77.465 | p: 77.161 | r: 77.872
r1fm+r2fm = 145.936

input #63 time: 0:11:03 | total time: 10:48:30


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
*********************************
*********************************
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8796932697296143 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8693087697029114 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.728920042514801 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.675671398639679 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6740126609802246 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6711879372596741 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.964 (perp=8.653, rec=0.230, cos=0.003), tot_loss_proj:2.050 [t=0.28s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.876 (perp=8.653, rec=0.152, cos=-0.007), tot_loss_proj:2.058 [t=0.28s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.874 (perp=8.653, rec=0.151, cos=-0.007), tot_loss_proj:2.052 [t=0.28s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=2.055 (perp=9.634, rec=0.133, cos=-0.005), tot_loss_proj:2.538 [t=0.27s]
prediction: ['[CLS] strange horror strange [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.937 (perp=9.190, rec=0.106, cos=-0.007), tot_loss_proj:2.211 [t=0.27s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.691 (perp=8.065, rec=0.087, cos=-0.009), tot_loss_proj:1.706 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.669 (perp=8.065, rec=0.066, cos=-0.009), tot_loss_proj:1.707 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.671 (perp=8.065, rec=0.067, cos=-0.009), tot_loss_proj:1.690 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.670 (perp=8.065, rec=0.067, cos=-0.010), tot_loss_proj:1.692 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.672 (perp=8.065, rec=0.068, cos=-0.010), tot_loss_proj:1.706 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.672 (perp=8.065, rec=0.068, cos=-0.010), tot_loss_proj:1.710 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.657 (perp=8.065, rec=0.053, cos=-0.010), tot_loss_proj:1.686 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.663 (perp=8.065, rec=0.060, cos=-0.010), tot_loss_proj:1.702 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.664 (perp=8.065, rec=0.061, cos=-0.010), tot_loss_proj:1.689 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.669 (perp=8.065, rec=0.066, cos=-0.010), tot_loss_proj:1.689 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.656 (perp=8.065, rec=0.053, cos=-0.010), tot_loss_proj:1.692 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.666 (perp=8.065, rec=0.062, cos=-0.010), tot_loss_proj:1.702 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.671 (perp=8.065, rec=0.067, cos=-0.010), tot_loss_proj:1.703 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.656 (perp=8.065, rec=0.053, cos=-0.010), tot_loss_proj:1.700 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.653 (perp=8.065, rec=0.050, cos=-0.010), tot_loss_proj:1.699 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.667 (perp=8.065, rec=0.064, cos=-0.010), tot_loss_proj:1.703 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.667 (perp=8.065, rec=0.063, cos=-0.010), tot_loss_proj:1.697 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.666 (perp=8.065, rec=0.062, cos=-0.010), tot_loss_proj:1.702 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.666 (perp=8.065, rec=0.062, cos=-0.010), tot_loss_proj:1.689 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.669 (perp=8.065, rec=0.065, cos=-0.010), tot_loss_proj:1.703 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.664 (perp=8.065, rec=0.060, cos=-0.010), tot_loss_proj:1.708 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.664 (perp=8.065, rec=0.060, cos=-0.010), tot_loss_proj:1.692 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.669 (perp=8.065, rec=0.065, cos=-0.010), tot_loss_proj:1.700 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.659 (perp=8.065, rec=0.056, cos=-0.010), tot_loss_proj:1.704 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.654 (perp=8.065, rec=0.050, cos=-0.010), tot_loss_proj:1.702 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.670 (perp=8.065, rec=0.067, cos=-0.010), tot_loss_proj:1.704 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.666 (perp=8.065, rec=0.062, cos=-0.010), tot_loss_proj:1.713 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.667 (perp=8.065, rec=0.063, cos=-0.010), tot_loss_proj:1.698 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=8.065, rec=0.054, cos=-0.010), tot_loss_proj:1.706 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.664 (perp=8.065, rec=0.061, cos=-0.010), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.663 (perp=8.065, rec=0.059, cos=-0.010), tot_loss_proj:1.695 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.671 (perp=8.065, rec=0.067, cos=-0.010), tot_loss_proj:1.700 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.660 (perp=8.065, rec=0.057, cos=-0.010), tot_loss_proj:1.693 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.661 (perp=8.065, rec=0.057, cos=-0.010), tot_loss_proj:1.697 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.667 (perp=8.065, rec=0.064, cos=-0.010), tot_loss_proj:1.696 [t=0.29s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.617 | p: 88.279 | r: 89.115
rouge2     | fm: 58.342 | p: 58.167 | r: 58.582
rougeL     | fm: 77.878 | p: 77.592 | r: 78.294
rougeLsum  | fm: 77.959 | p: 77.615 | r: 78.331
r1fm+r2fm = 146.959

input #64 time: 0:11:24 | total time: 10:59:55


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
*********************************
*********************************
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.0258606672286987 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9586822390556335 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9518215656280518 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9477682113647461 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8876939415931702 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8789583444595337 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8788501620292664 for ['[CLS] evenhoff overs pu newsmament general fun someday [SEP]']
[Init] best perm rec loss: 0.875924289226532 for ['[CLS]hoff someday general even pumament news fun overs [SEP]']
[Init] best perm rec loss: 0.8755142688751221 for ['[CLS] general news evenmament puhoff overs fun someday [SEP]']
[Init] best perm rec loss: 0.8745706081390381 for ['[CLS] even general news pumament somedayhoff fun overs [SEP]']
[Init] best perm rec loss: 0.8732827305793762 for ['[CLS] somedaymamenthoff general overs pu news even fun [SEP]']
[Init] best perm rec loss: 0.8718383312225342 for ['[CLS]mament news general even pu overs fun somedayhoff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=10.688, rec=0.367, cos=-0.003), tot_loss_proj:2.855 [t=0.28s]
prediction: ['[CLS] joy newsy, national leading sensation cases joy [SEP]']
[ 100/2000] tot_loss=2.423 (perp=10.969, rec=0.237, cos=-0.008), tot_loss_proj:2.710 [t=0.29s]
prediction: ['[CLS] joyousous, show area sensation investigation joy [SEP]']
[ 150/2000] tot_loss=2.216 (perp=10.206, rec=0.183, cos=-0.009), tot_loss_proj:2.497 [t=0.28s]
prediction: ['[CLS] joyousous, film film of investigation joy [SEP]']
[ 200/2000] tot_loss=2.136 (perp=9.943, rec=0.156, cos=-0.009), tot_loss_proj:2.458 [t=0.28s]
prediction: ['[CLS] joyous,, film film of investigation joy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.865 (perp=8.548, rec=0.164, cos=-0.008), tot_loss_proj:2.141 [t=0.28s]
prediction: ['[CLS] joyous, joyright film film of investigation [SEP]']
[ 300/2000] tot_loss=1.751 (perp=8.139, rec=0.132, cos=-0.009), tot_loss_proj:2.067 [t=0.28s]
prediction: ['[CLS] joyous, joyright film film of host [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.730 (perp=7.984, rec=0.142, cos=-0.009), tot_loss_proj:2.032 [t=0.28s]
prediction: ['[CLS] joyous, joyright film of host film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.710 (perp=7.984, rec=0.122, cos=-0.009), tot_loss_proj:2.033 [t=0.28s]
prediction: ['[CLS] joyous, joyright film of host film [SEP]']
[ 450/2000] tot_loss=1.831 (perp=8.645, rec=0.111, cos=-0.009), tot_loss_proj:2.272 [t=0.28s]
prediction: ['[CLS] joyous, romright film of host film [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.156 (perp=9.276, rec=0.303, cos=-0.002), tot_loss_proj:2.467 [t=0.29s]
prediction: ['[CLS] film joyous, rom interact film of population [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.057 (perp=9.000, rec=0.262, cos=-0.005), tot_loss_proj:2.335 [t=0.25s]
prediction: ['[CLS] joyous film, rom interact film of population [SEP]']
[ 600/2000] tot_loss=2.024 (perp=9.008, rec=0.228, cos=-0.006), tot_loss_proj:2.567 [t=0.27s]
prediction: ['[CLS] joyous., rom interact film of population [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.944 (perp=8.744, rec=0.203, cos=-0.007), tot_loss_proj:2.469 [t=0.25s]
prediction: ['[CLS] joyous. rom, interact film of population [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.939 (perp=8.801, rec=0.186, cos=-0.008), tot_loss_proj:2.352 [t=0.25s]
prediction: ['[CLS] joyous, rom, interact film of population [SEP]']
[ 750/2000] tot_loss=1.926 (perp=8.801, rec=0.174, cos=-0.008), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS] joyous, rom, interact film of population [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.753 (perp=7.982, rec=0.165, cos=-0.008), tot_loss_proj:2.105 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.760 (perp=7.982, rec=0.172, cos=-0.008), tot_loss_proj:2.108 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[ 900/2000] tot_loss=1.736 (perp=7.982, rec=0.148, cos=-0.008), tot_loss_proj:2.113 [t=0.28s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=7.982, rec=0.159, cos=-0.008), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.735 (perp=7.982, rec=0.147, cos=-0.008), tot_loss_proj:2.104 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1050/2000] tot_loss=1.736 (perp=7.982, rec=0.148, cos=-0.008), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1100/2000] tot_loss=1.730 (perp=7.982, rec=0.142, cos=-0.008), tot_loss_proj:2.106 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.721 (perp=7.982, rec=0.133, cos=-0.008), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1200/2000] tot_loss=1.721 (perp=7.982, rec=0.133, cos=-0.008), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.723 (perp=7.982, rec=0.135, cos=-0.008), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=7.982, rec=0.134, cos=-0.009), tot_loss_proj:2.107 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1350/2000] tot_loss=1.729 (perp=7.982, rec=0.141, cos=-0.009), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.724 (perp=7.982, rec=0.136, cos=-0.009), tot_loss_proj:2.109 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.713 (perp=7.982, rec=0.125, cos=-0.009), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1500/2000] tot_loss=1.728 (perp=7.982, rec=0.140, cos=-0.009), tot_loss_proj:2.105 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.712 (perp=7.982, rec=0.124, cos=-0.009), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=7.982, rec=0.127, cos=-0.009), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1650/2000] tot_loss=1.712 (perp=7.982, rec=0.125, cos=-0.009), tot_loss_proj:2.103 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.721 (perp=7.982, rec=0.133, cos=-0.009), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.714 (perp=7.982, rec=0.127, cos=-0.009), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1800/2000] tot_loss=1.714 (perp=7.982, rec=0.126, cos=-0.009), tot_loss_proj:2.104 [t=0.25s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.726 (perp=7.982, rec=0.138, cos=-0.009), tot_loss_proj:2.114 [t=0.28s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.719 (perp=7.982, rec=0.131, cos=-0.009), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
[1950/2000] tot_loss=1.717 (perp=7.982, rec=0.130, cos=-0.009), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.723 (perp=7.982, rec=0.135, cos=-0.009), tot_loss_proj:2.114 [t=0.27s]
prediction: ['[CLS] joyous, film rom, interact of population [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous, film rom, interact of population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 62.500 | r: 71.429
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 53.333 | p: 50.000 | r: 57.143
rougeLsum  | fm: 53.333 | p: 50.000 | r: 57.143
r1fm+r2fm = 82.051

[Aggregate metrics]:
rouge1     | fm: 88.204 | p: 87.766 | r: 88.749
rouge2     | fm: 57.676 | p: 57.407 | r: 57.916
rougeL     | fm: 77.413 | p: 77.081 | r: 77.861
rougeLsum  | fm: 77.380 | p: 76.998 | r: 77.842
r1fm+r2fm = 145.880

input #65 time: 0:11:11 | total time: 11:11:07


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
*********************************
*********************************
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.973792552947998 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9307570457458496 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9160336256027222 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8862890601158142 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8742782473564148 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.8719822764396667 for ['[CLS]beersa two bryce [SEP]']
[Init] best perm rec loss: 0.8696925640106201 for ['[CLS]rsa two brycebee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.278 (perp=10.258, rec=0.230, cos=-0.004), tot_loss_proj:3.288 [t=0.26s]
prediction: ['[CLS] executive tolkien tolkien fan [SEP]']
[ 100/2000] tot_loss=1.634 (perp=7.673, rec=0.108, cos=-0.009), tot_loss_proj:1.611 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 150/2000] tot_loss=1.595 (perp=7.673, rec=0.070, cos=-0.009), tot_loss_proj:1.596 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 200/2000] tot_loss=1.592 (perp=7.673, rec=0.066, cos=-0.009), tot_loss_proj:1.596 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.596 (perp=7.673, rec=0.071, cos=-0.009), tot_loss_proj:1.603 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.590 (perp=7.673, rec=0.064, cos=-0.009), tot_loss_proj:1.602 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.594 (perp=7.673, rec=0.069, cos=-0.009), tot_loss_proj:1.597 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.587 (perp=7.673, rec=0.061, cos=-0.009), tot_loss_proj:1.605 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.591 (perp=7.673, rec=0.065, cos=-0.009), tot_loss_proj:1.594 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.589 (perp=7.673, rec=0.063, cos=-0.009), tot_loss_proj:1.604 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.583 (perp=7.673, rec=0.058, cos=-0.009), tot_loss_proj:1.603 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.590 (perp=7.673, rec=0.065, cos=-0.009), tot_loss_proj:1.600 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.595 (perp=7.673, rec=0.069, cos=-0.009), tot_loss_proj:1.590 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.585 (perp=7.673, rec=0.060, cos=-0.009), tot_loss_proj:1.594 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.579 (perp=7.673, rec=0.054, cos=-0.009), tot_loss_proj:1.603 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.585 (perp=7.673, rec=0.059, cos=-0.009), tot_loss_proj:1.588 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.587 (perp=7.673, rec=0.061, cos=-0.009), tot_loss_proj:1.597 [t=0.28s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.588 (perp=7.673, rec=0.063, cos=-0.009), tot_loss_proj:1.601 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.579 (perp=7.673, rec=0.054, cos=-0.009), tot_loss_proj:1.590 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.582 (perp=7.673, rec=0.057, cos=-0.009), tot_loss_proj:1.592 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.596 (perp=7.673, rec=0.070, cos=-0.009), tot_loss_proj:1.589 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.588 (perp=7.673, rec=0.063, cos=-0.009), tot_loss_proj:1.596 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.584 (perp=7.673, rec=0.059, cos=-0.009), tot_loss_proj:1.589 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.673, rec=0.060, cos=-0.009), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.585 (perp=7.673, rec=0.060, cos=-0.009), tot_loss_proj:1.592 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.585 (perp=7.673, rec=0.059, cos=-0.009), tot_loss_proj:1.586 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.592 (perp=7.673, rec=0.066, cos=-0.009), tot_loss_proj:1.586 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.586 (perp=7.673, rec=0.061, cos=-0.009), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.673, rec=0.061, cos=-0.009), tot_loss_proj:1.593 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.575 (perp=7.673, rec=0.050, cos=-0.009), tot_loss_proj:1.599 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.582 (perp=7.673, rec=0.057, cos=-0.009), tot_loss_proj:1.592 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.588 (perp=7.673, rec=0.063, cos=-0.009), tot_loss_proj:1.598 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.589 (perp=7.673, rec=0.064, cos=-0.009), tot_loss_proj:1.599 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.673, rec=0.071, cos=-0.009), tot_loss_proj:1.588 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.580 (perp=7.673, rec=0.055, cos=-0.009), tot_loss_proj:1.597 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.587 (perp=7.673, rec=0.061, cos=-0.009), tot_loss_proj:1.602 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.596 (perp=7.673, rec=0.070, cos=-0.009), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.673, rec=0.070, cos=-0.009), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.673, rec=0.056, cos=-0.009), tot_loss_proj:1.597 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.584 (perp=7.673, rec=0.059, cos=-0.009), tot_loss_proj:1.605 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.545 | p: 88.093 | r: 89.090
rouge2     | fm: 58.390 | p: 58.206 | r: 58.562
rougeL     | fm: 77.870 | p: 77.458 | r: 78.320
rougeLsum  | fm: 77.815 | p: 77.395 | r: 78.313
r1fm+r2fm = 146.935

input #66 time: 0:10:57 | total time: 11:22:05


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
*********************************
*********************************
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005807638168335 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9567444324493408 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9554714560508728 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9473316669464111 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9436708688735962 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9336733222007751 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9325234889984131 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.9268360137939453 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ï¼‰ [SEP]']
[Init] best perm rec loss: 0.9241943955421448 for ['[CLS] ï¼‰ cone home mural courtney promotion upon enough wild tribes [SEP]']
[Init] best perm rec loss: 0.9226720929145813 for ['[CLS] promotion tribes home cone enough ï¼‰ wild courtney upon mural [SEP]']
[Init] best perm rec loss: 0.9221352934837341 for ['[CLS] upon home tribes courtney cone mural ï¼‰ wild promotion enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.918 (perp=13.221, rec=0.281, cos=-0.007), tot_loss_proj:4.561 [t=0.25s]
prediction: ['[CLS]manshed kind max nascarentationur kind cooperative kind [SEP]']
[ 100/2000] tot_loss=2.906 (perp=13.668, rec=0.181, cos=-0.009), tot_loss_proj:4.230 [t=0.27s]
prediction: ['[CLS] heartwar kind ne heartentationpmingental kind [SEP]']
[ 150/2000] tot_loss=2.674 (perp=12.728, rec=0.137, cos=-0.009), tot_loss_proj:3.971 [t=0.25s]
prediction: ['[CLS] heartwar kind non heartgm nonmingental kind [SEP]']
[ 200/2000] tot_loss=2.427 (perp=11.714, rec=0.094, cos=-0.009), tot_loss_proj:3.748 [t=0.25s]
prediction: ['[CLS] heartwar, non heartgm nonmingental kind [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.113 (perp=10.012, rec=0.119, cos=-0.009), tot_loss_proj:2.335 [t=0.27s]
prediction: ['[CLS] heartwarming, non heartgm nonental kind [SEP]']
[ 300/2000] tot_loss=2.084 (perp=10.012, rec=0.091, cos=-0.009), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] heartwarming, non heartgm nonental kind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.577 (perp=7.507, rec=0.085, cos=-0.009), tot_loss_proj:2.449 [t=0.27s]
prediction: ['[CLS] heartwarming, non heartgmental non kind [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.746 (perp=8.309, rec=0.094, cos=-0.009), tot_loss_proj:2.664 [t=0.27s]
prediction: ['[CLS] heartwarming,jugmental non kind heart [SEP]']
[ 450/2000] tot_loss=1.743 (perp=8.309, rec=0.090, cos=-0.009), tot_loss_proj:2.658 [t=0.27s]
prediction: ['[CLS] heartwarming,jugmental non kind heart [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.527 (perp=7.179, rec=0.100, cos=-0.009), tot_loss_proj:1.794 [t=0.26s]
prediction: ['[CLS] heartwarming nonjugmental, kind heart [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.524 (perp=7.179, rec=0.097, cos=-0.009), tot_loss_proj:1.782 [t=0.25s]
prediction: ['[CLS] heartwarming nonjugmental, kind heart [SEP]']
[ 600/2000] tot_loss=1.523 (perp=7.179, rec=0.096, cos=-0.009), tot_loss_proj:1.793 [t=0.27s]
prediction: ['[CLS] heartwarming nonjugmental, kind heart [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.771 (perp=8.478, rec=0.084, cos=-0.009), tot_loss_proj:2.270 [t=0.27s]
prediction: ['[CLS] -warming nonjugmental, kind heart [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.561 (perp=7.425, rec=0.085, cos=-0.009), tot_loss_proj:1.867 [t=0.26s]
prediction: ['[CLS] heartwarming nonjugmental, kind - [SEP]']
[ 750/2000] tot_loss=1.549 (perp=7.425, rec=0.074, cos=-0.009), tot_loss_proj:1.864 [t=0.26s]
prediction: ['[CLS] heartwarming nonjugmental, kind - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.505 (perp=7.220, rec=0.070, cos=-0.009), tot_loss_proj:1.916 [t=0.26s]
prediction: ['[CLS] heartwarming nonjugmental kind, - [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.421 (perp=6.724, rec=0.085, cos=-0.009), tot_loss_proj:1.766 [t=0.25s]
prediction: ['[CLS] kind heartwarming nonjugmental, - [SEP]']
[ 900/2000] tot_loss=1.410 (perp=6.724, rec=0.074, cos=-0.009), tot_loss_proj:1.769 [t=0.25s]
prediction: ['[CLS] kind heartwarming nonjugmental, - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.413 (perp=6.724, rec=0.077, cos=-0.009), tot_loss_proj:1.762 [t=0.26s]
prediction: ['[CLS] kind heartwarming nonjugmental, - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.417 (perp=6.724, rec=0.081, cos=-0.009), tot_loss_proj:1.767 [t=0.27s]
prediction: ['[CLS] kind heartwarming nonjugmental, - [SEP]']
[1050/2000] tot_loss=1.511 (perp=7.242, rec=0.072, cos=-0.009), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] kind heartwarming nonjugmental,i [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.443 (perp=6.893, rec=0.073, cos=-0.009), tot_loss_proj:1.844 [t=0.25s]
prediction: ['[CLS] kind heartwarming nonjugmentali, [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.427 (perp=6.766, rec=0.083, cos=-0.009), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
[1200/2000] tot_loss=1.419 (perp=6.766, rec=0.075, cos=-0.009), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1250/2000] tot_loss=1.426 (perp=6.766, rec=0.082, cos=-0.009), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1300/2000] tot_loss=1.420 (perp=6.766, rec=0.076, cos=-0.009), tot_loss_proj:1.713 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
[1350/2000] tot_loss=1.415 (perp=6.766, rec=0.071, cos=-0.009), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1400/2000] tot_loss=1.407 (perp=6.766, rec=0.064, cos=-0.009), tot_loss_proj:1.713 [t=0.27s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1450/2000] tot_loss=1.428 (perp=6.766, rec=0.084, cos=-0.009), tot_loss_proj:1.716 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
[1500/2000] tot_loss=1.418 (perp=6.766, rec=0.074, cos=-0.009), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1550/2000] tot_loss=1.423 (perp=6.766, rec=0.079, cos=-0.009), tot_loss_proj:1.715 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1600/2000] tot_loss=1.415 (perp=6.766, rec=0.071, cos=-0.009), tot_loss_proj:1.712 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
[1650/2000] tot_loss=1.420 (perp=6.766, rec=0.076, cos=-0.009), tot_loss_proj:1.711 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1700/2000] tot_loss=1.411 (perp=6.766, rec=0.067, cos=-0.009), tot_loss_proj:1.713 [t=0.27s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1750/2000] tot_loss=1.412 (perp=6.766, rec=0.069, cos=-0.009), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
[1800/2000] tot_loss=1.414 (perp=6.766, rec=0.070, cos=-0.009), tot_loss_proj:1.704 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1850/2000] tot_loss=1.409 (perp=6.766, rec=0.065, cos=-0.009), tot_loss_proj:1.714 [t=0.27s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[1900/2000] tot_loss=1.428 (perp=6.766, rec=0.085, cos=-0.009), tot_loss_proj:1.711 [t=0.27s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
[1950/2000] tot_loss=1.420 (perp=6.766, rec=0.076, cos=-0.009), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Attempt swap
[2000/2000] tot_loss=1.418 (perp=6.766, rec=0.074, cos=-0.009), tot_loss_proj:1.717 [t=0.26s]
prediction: ['[CLS] kind heartwarming, nonjugmentali [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming, nonjugmentali [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 88.378 | p: 87.928 | r: 88.873
rouge2     | fm: 57.503 | p: 57.358 | r: 57.677
rougeL     | fm: 77.390 | p: 77.061 | r: 77.801
rougeLsum  | fm: 77.483 | p: 77.151 | r: 77.889
r1fm+r2fm = 145.880

input #67 time: 0:11:00 | total time: 11:33:05


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
*********************************
*********************************
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.989619255065918 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9645585417747498 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9424722194671631 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9253563284873962 for ['[CLS] neutron acrosswas 2005 security tip faâ€” identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8706526756286621 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8648829460144043 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8608188629150391 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8541148900985718 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8531020283699036 for ['[CLS]iferous comfortyn form medal died floor. beth possibly riding view councils [SEP]']
[Init] best perm rec loss: 0.8519254326820374 for ['[CLS] possibly councils comfortiferousyn floor died form view beth. medal riding [SEP]']
[Init] best perm rec loss: 0.8488271236419678 for ['[CLS]iferous flooryn form possibly medal riding view beth councils. died comfort [SEP]']
[Init] best perm rec loss: 0.8450530767440796 for ['[CLS] beth comfortyn died form riding councils possibly medal floor. viewiferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.453 (perp=11.060, rec=0.249, cos=-0.008), tot_loss_proj:2.770 [t=0.25s]
prediction: ['[CLS] absurd, oftlement disastrous ( painful barrel ridiculous stupid - derivative [SEP] [SEP]']
[ 100/2000] tot_loss=2.144 (perp=9.944, rec=0.165, cos=-0.009), tot_loss_proj:2.424 [t=0.27s]
prediction: ['[CLS] absurd, unsiblesible, absurdigate absurd vicious and absurd of [SEP]']
[ 150/2000] tot_loss=2.198 (perp=10.388, rec=0.130, cos=-0.009), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] absurd, unsiblesible, vicious liability amendment vicious and vicious un [SEP]']
[ 200/2000] tot_loss=2.064 (perp=9.765, rec=0.121, cos=-0.009), tot_loss_proj:2.391 [t=0.26s]
prediction: ['[CLS] absurd, unsiblesible, viciousdictsible vicious and vicious un [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.701 (perp=7.846, rec=0.140, cos=-0.008), tot_loss_proj:1.939 [t=0.27s]
prediction: ['[CLS] absurd, uncouth, viciousresible vicious and vicioussible [SEP]']
[ 300/2000] tot_loss=1.828 (perp=8.614, rec=0.114, cos=-0.009), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS] absurd, uncouth,sibleompsible vicious and vicioussible [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.651 (perp=7.788, rec=0.102, cos=-0.009), tot_loss_proj:1.913 [t=0.26s]
prediction: ['[CLS] absurd, uncouthsibleompsible, vicious and vicioussible [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.556 (perp=7.308, rec=0.103, cos=-0.009), tot_loss_proj:1.835 [t=0.25s]
prediction: ['[CLS] absurdsible, uncouthsibleompsible, vicious and vicious [SEP]']
[ 450/2000] tot_loss=1.425 (perp=6.699, rec=0.094, cos=-0.010), tot_loss_proj:1.670 [t=0.26s]
prediction: ['[CLS] absurdsible, uncouthsiblehensible, vicious and vicious [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.301 (perp=6.101, rec=0.090, cos=-0.009), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.298 (perp=6.101, rec=0.088, cos=-0.010), tot_loss_proj:1.614 [t=0.25s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[ 600/2000] tot_loss=1.288 (perp=6.101, rec=0.078, cos=-0.010), tot_loss_proj:1.612 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.303 (perp=6.101, rec=0.093, cos=-0.010), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.299 (perp=6.101, rec=0.089, cos=-0.010), tot_loss_proj:1.619 [t=0.25s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[ 750/2000] tot_loss=1.290 (perp=6.101, rec=0.079, cos=-0.010), tot_loss_proj:1.615 [t=0.27s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.288 (perp=6.101, rec=0.077, cos=-0.010), tot_loss_proj:1.609 [t=0.25s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.287 (perp=6.101, rec=0.076, cos=-0.010), tot_loss_proj:1.608 [t=0.25s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[ 900/2000] tot_loss=1.291 (perp=6.101, rec=0.080, cos=-0.010), tot_loss_proj:1.617 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.293 (perp=6.101, rec=0.082, cos=-0.010), tot_loss_proj:1.613 [t=0.27s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1000/2000] tot_loss=1.289 (perp=6.101, rec=0.078, cos=-0.010), tot_loss_proj:1.609 [t=0.27s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[1050/2000] tot_loss=1.286 (perp=6.101, rec=0.075, cos=-0.010), tot_loss_proj:1.605 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1100/2000] tot_loss=1.284 (perp=6.101, rec=0.074, cos=-0.010), tot_loss_proj:1.608 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1150/2000] tot_loss=1.291 (perp=6.101, rec=0.080, cos=-0.010), tot_loss_proj:1.608 [t=0.27s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[1200/2000] tot_loss=1.280 (perp=6.101, rec=0.069, cos=-0.010), tot_loss_proj:1.604 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1250/2000] tot_loss=1.280 (perp=6.101, rec=0.070, cos=-0.010), tot_loss_proj:1.613 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1300/2000] tot_loss=1.287 (perp=6.101, rec=0.076, cos=-0.010), tot_loss_proj:1.609 [t=0.27s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[1350/2000] tot_loss=1.284 (perp=6.101, rec=0.073, cos=-0.010), tot_loss_proj:1.614 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1400/2000] tot_loss=1.282 (perp=6.101, rec=0.071, cos=-0.010), tot_loss_proj:1.609 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
Attempt swap
[1450/2000] tot_loss=1.291 (perp=6.101, rec=0.080, cos=-0.010), tot_loss_proj:1.611 [t=0.27s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]']
[1500/2000] tot_loss=1.326 (perp=6.301, rec=0.076, cos=-0.010), tot_loss_proj:1.557 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.327 (perp=6.301, rec=0.076, cos=-0.010), tot_loss_proj:1.561 [t=0.26s]
prediction: ['[CLS] josible, uncouth absurdhensible, vicious and absurd [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.296 (perp=6.130, rec=0.080, cos=-0.010), tot_loss_proj:1.515 [t=0.25s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
[1650/2000] tot_loss=1.292 (perp=6.130, rec=0.076, cos=-0.010), tot_loss_proj:1.508 [t=0.25s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.291 (perp=6.130, rec=0.075, cos=-0.010), tot_loss_proj:1.511 [t=0.27s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.292 (perp=6.130, rec=0.076, cos=-0.010), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
[1800/2000] tot_loss=1.300 (perp=6.130, rec=0.084, cos=-0.010), tot_loss_proj:1.515 [t=0.27s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.297 (perp=6.130, rec=0.081, cos=-0.010), tot_loss_proj:1.514 [t=0.26s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.299 (perp=6.130, rec=0.082, cos=-0.010), tot_loss_proj:1.508 [t=0.27s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
[1950/2000] tot_loss=1.299 (perp=6.130, rec=0.083, cos=-0.010), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.290 (perp=6.130, rec=0.073, cos=-0.010), tot_loss_proj:1.512 [t=0.27s]
prediction: ['[CLS] josible, uncouthhensible, vicious and absurd absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] josible, uncouth absurdhensible, vicious and vicious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 62.500 | r: 71.429
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 82.051

[Aggregate metrics]:
rouge1     | fm: 88.076 | p: 87.580 | r: 88.615
rouge2     | fm: 56.888 | p: 56.695 | r: 57.183
rougeL     | fm: 77.274 | p: 76.913 | r: 77.776
rougeLsum  | fm: 77.293 | p: 76.914 | r: 77.772
r1fm+r2fm = 144.964

input #68 time: 0:10:56 | total time: 11:44:02


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
*********************************
*********************************
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.086551547050476 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9466122388839722 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.925304114818573 for ['[CLS] meetings bells mountain bloody technical scriptâ„ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9242345690727234 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9170600771903992 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9078761339187622 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8832088112831116 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8760436773300171 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8714134693145752 for ['[CLS] ferris main case african gross tray adelaide burnham port unopposedest [MASK] platformmission downacio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.934 (perp=13.264, rec=0.288, cos=-0.007), tot_loss_proj:3.877 [t=0.26s]
prediction: ['[CLS] selling electric touched amazing of, food traction $eborg strongor teamasurable powerful stimuli [SEP]']
[ 100/2000] tot_loss=2.011 (perp=9.009, rec=0.218, cos=-0.009), tot_loss_proj:2.565 [t=0.25s]
prediction: ['[CLS] smart finally funny strong -, - ; - - smart and team winner team stimuli [SEP]']
[ 150/2000] tot_loss=1.839 (perp=8.343, rec=0.180, cos=-0.009), tot_loss_proj:2.456 [t=0.28s]
prediction: ['[CLS] real real subtle smart -, -, - - subtle, ; winner team real [SEP]']
[ 200/2000] tot_loss=1.786 (perp=8.191, rec=0.157, cos=-0.009), tot_loss_proj:2.458 [t=0.25s]
prediction: ['[CLS] real real subtle smart -, -, - - subtle,. winner - real [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.599 (perp=7.460, rec=0.116, cos=-0.009), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] a real subtle smart -, - and - - subtle, real winner screen. [SEP]']
[ 300/2000] tot_loss=1.682 (perp=7.891, rec=0.113, cos=-0.009), tot_loss_proj:2.251 [t=0.26s]
prediction: ['[CLS] a real subtle smart -, - and - - subtle, des winner screen. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.817 (perp=8.565, rec=0.113, cos=-0.009), tot_loss_proj:2.528 [t=0.26s]
prediction: ['[CLS] a real smart subtle -,ona and - - res, des winner screen. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.767 (perp=7.734, rec=0.228, cos=-0.008), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] a real smart subtle -, and harvey - resona, real winner -. [SEP]']
[ 450/2000] tot_loss=1.886 (perp=8.716, rec=0.152, cos=-0.009), tot_loss_proj:2.419 [t=0.27s]
prediction: ['[CLS] a real smart subtle -, and [ - resona, mood winner isbn. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.679 (perp=7.795, rec=0.129, cos=-0.009), tot_loss_proj:2.138 [t=0.26s]
prediction: ['[CLS] a real smart subtle - - resona, mood, and truth winner very. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.534 (perp=7.061, rec=0.131, cos=-0.009), tot_loss_proj:2.022 [t=0.27s]
prediction: ['[CLS] a real smart truth - - resona,ona, and subtle winner -. [SEP]']
[ 600/2000] tot_loss=1.536 (perp=7.061, rec=0.133, cos=-0.009), tot_loss_proj:2.023 [t=0.26s]
prediction: ['[CLS] a real smart truth - - resona,ona, and subtle winner -. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.645 (perp=7.624, rec=0.129, cos=-0.009), tot_loss_proj:2.165 [t=0.26s]
prediction: ['[CLS] a real smart truth - - resona,ona, and subtle æ¯” winner. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.437 (perp=6.608, rec=0.125, cos=-0.009), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[ 750/2000] tot_loss=1.419 (perp=6.608, rec=0.106, cos=-0.009), tot_loss_proj:1.810 [t=0.25s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.419 (perp=6.608, rec=0.107, cos=-0.009), tot_loss_proj:1.811 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.424 (perp=6.608, rec=0.111, cos=-0.009), tot_loss_proj:1.802 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[ 900/2000] tot_loss=1.417 (perp=6.608, rec=0.105, cos=-0.009), tot_loss_proj:1.815 [t=0.25s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.423 (perp=6.608, rec=0.111, cos=-0.009), tot_loss_proj:1.807 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.405 (perp=6.608, rec=0.093, cos=-0.009), tot_loss_proj:1.806 [t=0.27s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1050/2000] tot_loss=1.412 (perp=6.608, rec=0.099, cos=-0.009), tot_loss_proj:1.815 [t=0.25s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.417 (perp=6.608, rec=0.105, cos=-0.009), tot_loss_proj:1.809 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.416 (perp=6.608, rec=0.104, cos=-0.009), tot_loss_proj:1.803 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1200/2000] tot_loss=1.409 (perp=6.608, rec=0.096, cos=-0.009), tot_loss_proj:1.806 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.408 (perp=6.608, rec=0.096, cos=-0.009), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.413 (perp=6.608, rec=0.100, cos=-0.009), tot_loss_proj:1.809 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1350/2000] tot_loss=1.410 (perp=6.608, rec=0.097, cos=-0.009), tot_loss_proj:1.805 [t=0.27s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.413 (perp=6.608, rec=0.101, cos=-0.009), tot_loss_proj:1.811 [t=0.27s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.404 (perp=6.608, rec=0.091, cos=-0.009), tot_loss_proj:1.803 [t=0.28s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1500/2000] tot_loss=1.405 (perp=6.608, rec=0.092, cos=-0.009), tot_loss_proj:1.808 [t=0.28s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.417 (perp=6.608, rec=0.105, cos=-0.009), tot_loss_proj:1.808 [t=0.27s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.410 (perp=6.608, rec=0.098, cos=-0.009), tot_loss_proj:1.809 [t=0.27s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1650/2000] tot_loss=1.403 (perp=6.608, rec=0.090, cos=-0.009), tot_loss_proj:1.810 [t=0.28s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.416 (perp=6.608, rec=0.103, cos=-0.009), tot_loss_proj:1.804 [t=0.27s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.416 (perp=6.608, rec=0.103, cos=-0.009), tot_loss_proj:1.813 [t=0.28s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1800/2000] tot_loss=1.410 (perp=6.608, rec=0.097, cos=-0.009), tot_loss_proj:1.808 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.409 (perp=6.608, rec=0.097, cos=-0.009), tot_loss_proj:1.812 [t=0.28s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.405 (perp=6.608, rec=0.093, cos=-0.009), tot_loss_proj:1.816 [t=0.28s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
[1950/2000] tot_loss=1.397 (perp=6.608, rec=0.085, cos=-0.009), tot_loss_proj:1.807 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.404 (perp=6.608, rec=0.092, cos=-0.009), tot_loss_proj:1.805 [t=0.26s]
prediction: ['[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] a real subtle truth - - resona,ona, and smart, winner. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 21.053 | p: 20.000 | r: 22.222
rougeL     | fm: 57.143 | p: 54.545 | r: 60.000
rougeLsum  | fm: 57.143 | p: 54.545 | r: 60.000
r1fm+r2fm = 97.243

[Aggregate metrics]:
rouge1     | fm: 87.839 | p: 87.306 | r: 88.526
rouge2     | fm: 56.397 | p: 56.147 | r: 56.674
rougeL     | fm: 77.125 | p: 76.710 | r: 77.622
rougeLsum  | fm: 77.042 | p: 76.582 | r: 77.579
r1fm+r2fm = 144.236

input #69 time: 0:11:05 | total time: 11:55:08


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
*********************************
*********************************
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8451830148696899 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.81871098279953 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7903928160667419 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7371676564216614 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7334622144699097 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7315616607666016 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7313181161880493 for ['[CLS] detention sharma effects mark herself blood technological [SEP]']
[Init] best perm rec loss: 0.7305154204368591 for ['[CLS] sharma blood herself detention technological effects mark [SEP]']
[Init] best perm rec loss: 0.730158805847168 for ['[CLS] mark blood herself effects technological detention sharma [SEP]']
[Init] best perm rec loss: 0.7293766736984253 for ['[CLS] detention blood effects sharma herself technological mark [SEP]']
[Init] best perm rec loss: 0.7282413840293884 for ['[CLS] detention herself mark sharma technological effects blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.756 (perp=11.763, rec=0.402, cos=0.001), tot_loss_proj:3.420 [t=0.28s]
prediction: ['[CLS] destroyed state jingle asteroid break friday crater [SEP]']
[ 100/2000] tot_loss=2.673 (perp=11.738, rec=0.331, cos=-0.006), tot_loss_proj:3.621 [t=0.28s]
prediction: ['[CLS] off stateunk throughunk getsunk [SEP]']
[ 150/2000] tot_loss=2.732 (perp=12.355, rec=0.269, cos=-0.008), tot_loss_proj:3.690 [t=0.29s]
prediction: ['[CLS] off theirunk throughunk gets screen [SEP]']
[ 200/2000] tot_loss=2.569 (perp=11.736, rec=0.230, cos=-0.008), tot_loss_proj:3.659 [t=0.27s]
prediction: ['[CLS] cl getsunk clunk gets screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.078 (perp=9.220, rec=0.219, cos=0.016), tot_loss_proj:2.703 [t=0.28s]
prediction: ['[CLS] clunk gets clunk gets screen [SEP]']
[ 300/2000] tot_loss=2.643 (perp=12.479, rec=0.156, cos=-0.008), tot_loss_proj:3.686 [t=0.26s]
prediction: ['[CLS] clunk getsyunk gets screen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.686 (perp=7.863, rec=0.121, cos=-0.008), tot_loss_proj:2.112 [t=0.28s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.671 (perp=7.863, rec=0.107, cos=-0.009), tot_loss_proj:2.110 [t=0.27s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[ 450/2000] tot_loss=1.663 (perp=7.863, rec=0.096, cos=-0.006), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.656 (perp=7.863, rec=0.092, cos=-0.009), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.642 (perp=7.863, rec=0.079, cos=-0.009), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[ 600/2000] tot_loss=1.648 (perp=7.863, rec=0.085, cos=-0.009), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.637 (perp=7.863, rec=0.074, cos=-0.009), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.644 (perp=7.863, rec=0.081, cos=-0.009), tot_loss_proj:2.131 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[ 750/2000] tot_loss=1.643 (perp=7.863, rec=0.080, cos=-0.009), tot_loss_proj:2.128 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.636 (perp=7.863, rec=0.073, cos=-0.009), tot_loss_proj:2.133 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.639 (perp=7.863, rec=0.076, cos=-0.009), tot_loss_proj:2.126 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[ 900/2000] tot_loss=1.651 (perp=7.863, rec=0.088, cos=-0.009), tot_loss_proj:2.132 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.638 (perp=7.863, rec=0.075, cos=-0.009), tot_loss_proj:2.132 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.863, rec=0.083, cos=-0.009), tot_loss_proj:2.132 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1050/2000] tot_loss=1.637 (perp=7.863, rec=0.074, cos=-0.009), tot_loss_proj:2.133 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.648 (perp=7.863, rec=0.084, cos=-0.009), tot_loss_proj:2.134 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.638 (perp=7.863, rec=0.075, cos=-0.010), tot_loss_proj:2.134 [t=0.27s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1200/2000] tot_loss=1.630 (perp=7.863, rec=0.067, cos=-0.010), tot_loss_proj:2.128 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.639 (perp=7.863, rec=0.076, cos=-0.010), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.632 (perp=7.863, rec=0.069, cos=-0.010), tot_loss_proj:2.139 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1350/2000] tot_loss=1.639 (perp=7.863, rec=0.075, cos=-0.010), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.636 (perp=7.863, rec=0.073, cos=-0.010), tot_loss_proj:2.141 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.632 (perp=7.863, rec=0.069, cos=-0.010), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1500/2000] tot_loss=1.635 (perp=7.863, rec=0.072, cos=-0.010), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.634 (perp=7.863, rec=0.071, cos=-0.010), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.633 (perp=7.863, rec=0.070, cos=-0.010), tot_loss_proj:2.143 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1650/2000] tot_loss=1.639 (perp=7.863, rec=0.076, cos=-0.010), tot_loss_proj:2.143 [t=0.27s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.639 (perp=7.863, rec=0.076, cos=-0.010), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.626 (perp=7.863, rec=0.063, cos=-0.010), tot_loss_proj:2.141 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1800/2000] tot_loss=1.642 (perp=7.863, rec=0.079, cos=-0.010), tot_loss_proj:2.145 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.636 (perp=7.863, rec=0.073, cos=-0.010), tot_loss_proj:2.139 [t=0.25s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.632 (perp=7.863, rec=0.069, cos=-0.010), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
[1950/2000] tot_loss=1.637 (perp=7.863, rec=0.074, cos=-0.010), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.646 (perp=7.863, rec=0.083, cos=-0.010), tot_loss_proj:2.140 [t=0.26s]
prediction: ['[CLS] clunky getsunk on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] clunky getsunk on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 87.698 | p: 87.240 | r: 88.244
rouge2     | fm: 55.635 | p: 55.410 | r: 55.894
rougeL     | fm: 77.022 | p: 76.680 | r: 77.523
rougeLsum  | fm: 76.926 | p: 76.580 | r: 77.422
r1fm+r2fm = 143.333

input #70 time: 0:11:06 | total time: 12:06:14


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
*********************************
*********************************
average of cosine similarity 0.9993403548184049
highest_index [0]
highest [0.9993403548184049]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8840630650520325 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.847382128238678 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8406677842140198 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8305583596229553 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8247600197792053 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8176411986351013 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.813213050365448 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.8101482391357422 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8090407252311707 for ['[CLS] tomb gogharth acids course beyond littletered wright until south. reservoir stageathlon [SEP]']
[Init] best perm rec loss: 0.8082916736602783 for ['[CLS] beyond gogh southarth wright stage course acidstered. little until tombathlon reservoir [SEP]']
[Init] best perm rec loss: 0.8073354363441467 for ['[CLS] reservoir beyond.athlon little acids tombarth wright south course stage until goghtered [SEP]']
[Init] best perm rec loss: 0.8070156574249268 for ['[CLS]. reservoir wright beyondathlon tombarth stage acids south gogh course littletered until [SEP]']
[Init] best perm rec loss: 0.8070120215415955 for ['[CLS]athlon. reservoir southarth stagetered tomb beyond wright until little gogh acids course [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.509 (perp=10.524, rec=0.404, cos=-0.001), tot_loss_proj:3.415 [t=0.29s]
prediction: ["[CLS] single only route notio britainter meeting section thuss seat without'seat [SEP]"]
[ 100/2000] tot_loss=2.379 (perp=10.566, rec=0.272, cos=-0.006), tot_loss_proj:3.278 [t=0.28s]
prediction: ["[CLS] single not road not single townter meeting short bys moment without'moment [SEP]"]
[ 150/2000] tot_loss=2.134 (perp=9.652, rec=0.210, cos=-0.007), tot_loss_proj:2.979 [t=0.28s]
prediction: ['[CLS] single not road not single town - moment head iss seat single / moment [SEP]']
[ 200/2000] tot_loss=1.859 (perp=8.410, rec=0.185, cos=-0.008), tot_loss_proj:2.937 [t=0.29s]
prediction: ["[CLS] single - road not single'- moment jump is your seat single - moment [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=1.774 (perp=8.094, rec=0.163, cos=-0.008), tot_loss_proj:2.845 [t=0.26s]
prediction: ["[CLS] and - road not single'- moment jump single ( your seat - moment [SEP]"]
[ 300/2000] tot_loss=1.682 (perp=7.847, rec=0.122, cos=-0.009), tot_loss_proj:2.837 [t=0.27s]
prediction: ["[CLS] and - - not single'- moment jump without there your seat - moment [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.584 (perp=7.392, rec=0.115, cos=-0.009), tot_loss_proj:2.444 [t=0.30s]
prediction: ["[CLS] and a moment not single'- - jump without there your seat - moment [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.490 (perp=7.059, rec=0.088, cos=-0.010), tot_loss_proj:2.446 [t=0.29s]
prediction: ["[CLS] and a moment not single'- - jump there without your seat - moment [SEP]"]
[ 450/2000] tot_loss=1.535 (perp=7.213, rec=0.102, cos=-0.010), tot_loss_proj:2.942 [t=0.29s]
prediction: ["[CLS] and a moment not single'- - jump there - your seat in moment [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.494 (perp=7.070, rec=0.090, cos=-0.010), tot_loss_proj:3.050 [t=0.30s]
prediction: ["[CLS] and a moment not single'- - jump - there your seat in moment [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.409 (perp=6.720, rec=0.075, cos=-0.010), tot_loss_proj:2.800 [t=0.31s]
prediction: ["[CLS] and a moment not single'- - jump in there your seat - moment [SEP]"]
[ 600/2000] tot_loss=1.416 (perp=6.720, rec=0.082, cos=-0.010), tot_loss_proj:2.795 [t=0.32s]
prediction: ["[CLS] and a moment not single'- - jump in there your seat - moment [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.397 (perp=6.564, rec=0.094, cos=-0.010), tot_loss_proj:2.799 [t=0.27s]
prediction: ["[CLS] and a moment not single'- - jump there in your seat - moment [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.368 (perp=6.480, rec=0.081, cos=-0.009), tot_loss_proj:2.752 [t=0.27s]
prediction: ["[CLS] and a single not moment'- - jump there in your seat - moment [SEP]"]
[ 750/2000] tot_loss=1.364 (perp=6.480, rec=0.078, cos=-0.010), tot_loss_proj:2.748 [t=0.26s]
prediction: ["[CLS] and a single not moment'- - jump there in your seat - moment [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.227 (perp=5.798, rec=0.077, cos=-0.010), tot_loss_proj:2.274 [t=0.28s]
prediction: ["[CLS] and not a single moment'- - jump there in your seat - moment [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.158 (perp=5.381, rec=0.091, cos=-0.009), tot_loss_proj:2.469 [t=0.26s]
prediction: ["[CLS] and not a single moment - -'jump there in your seat - moment [SEP]"]
[ 900/2000] tot_loss=1.155 (perp=5.381, rec=0.088, cos=-0.010), tot_loss_proj:2.471 [t=0.25s]
prediction: ["[CLS] and not a single moment - -'jump there in your seat - moment [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.149 (perp=5.381, rec=0.083, cos=-0.010), tot_loss_proj:2.470 [t=0.27s]
prediction: ["[CLS] and not a single moment - -'jump there in your seat - moment [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.147 (perp=5.381, rec=0.080, cos=-0.010), tot_loss_proj:2.468 [t=0.27s]
prediction: ["[CLS] and not a single moment - -'jump there in your seat - moment [SEP]"]
[1050/2000] tot_loss=1.232 (perp=5.837, rec=0.075, cos=-0.010), tot_loss_proj:2.660 [t=0.26s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
Attempt swap
[1100/2000] tot_loss=1.234 (perp=5.837, rec=0.077, cos=-0.010), tot_loss_proj:2.658 [t=0.26s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
Attempt swap
[1150/2000] tot_loss=1.248 (perp=5.837, rec=0.090, cos=-0.010), tot_loss_proj:2.661 [t=0.25s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
[1200/2000] tot_loss=1.231 (perp=5.837, rec=0.073, cos=-0.010), tot_loss_proj:2.657 [t=0.26s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
Attempt swap
[1250/2000] tot_loss=1.230 (perp=5.837, rec=0.073, cos=-0.010), tot_loss_proj:2.662 [t=0.28s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
Attempt swap
[1300/2000] tot_loss=1.222 (perp=5.837, rec=0.065, cos=-0.010), tot_loss_proj:2.650 [t=0.27s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
[1350/2000] tot_loss=1.235 (perp=5.837, rec=0.077, cos=-0.010), tot_loss_proj:2.654 [t=0.26s]
prediction: ['[CLS] and not a single moment - - there jump there in your seat - moment [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.213 (perp=5.792, rec=0.064, cos=-0.010), tot_loss_proj:2.746 [t=0.26s]
prediction: ['[CLS] and not a single moment - - there there jump in your seat - moment [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.201 (perp=5.709, rec=0.069, cos=-0.010), tot_loss_proj:2.766 [t=0.26s]
prediction: ['[CLS] and not a single moment there - - there jump in your seat - moment [SEP]']
[1500/2000] tot_loss=1.214 (perp=5.709, rec=0.082, cos=-0.010), tot_loss_proj:2.762 [t=0.27s]
prediction: ['[CLS] and not a single moment there - - there jump in your seat - moment [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.181 (perp=5.559, rec=0.079, cos=-0.010), tot_loss_proj:2.848 [t=0.26s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Attempt swap
[1600/2000] tot_loss=1.185 (perp=5.559, rec=0.083, cos=-0.010), tot_loss_proj:2.848 [t=0.25s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
[1650/2000] tot_loss=1.189 (perp=5.559, rec=0.087, cos=-0.010), tot_loss_proj:2.848 [t=0.27s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Attempt swap
[1700/2000] tot_loss=1.184 (perp=5.559, rec=0.082, cos=-0.010), tot_loss_proj:2.843 [t=0.27s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Attempt swap
[1750/2000] tot_loss=1.183 (perp=5.559, rec=0.081, cos=-0.010), tot_loss_proj:2.848 [t=0.27s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
[1800/2000] tot_loss=1.179 (perp=5.559, rec=0.077, cos=-0.010), tot_loss_proj:2.846 [t=0.27s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Attempt swap
[1850/2000] tot_loss=1.180 (perp=5.559, rec=0.077, cos=-0.010), tot_loss_proj:2.848 [t=0.25s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Attempt swap
[1900/2000] tot_loss=1.179 (perp=5.559, rec=0.077, cos=-0.010), tot_loss_proj:2.849 [t=0.26s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
[1950/2000] tot_loss=1.167 (perp=5.559, rec=0.065, cos=-0.010), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Attempt swap
[2000/2000] tot_loss=1.172 (perp=5.559, rec=0.070, cos=-0.010), tot_loss_proj:2.849 [t=0.25s]
prediction: ['[CLS] not a single moment and there - - there jump in your seat - moment [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] not a single moment and there - - there jump in your seat - moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 85.714 | r: 92.308
rouge2     | fm: 56.000 | p: 53.846 | r: 58.333
rougeL     | fm: 74.074 | p: 71.429 | r: 76.923
rougeLsum  | fm: 74.074 | p: 71.429 | r: 76.923
r1fm+r2fm = 144.889

[Aggregate metrics]:
rouge1     | fm: 87.729 | p: 87.220 | r: 88.305
rouge2     | fm: 55.737 | p: 55.540 | r: 56.033
rougeL     | fm: 76.961 | p: 76.625 | r: 77.470
rougeLsum  | fm: 76.981 | p: 76.618 | r: 77.497
r1fm+r2fm = 143.467

input #71 time: 0:11:17 | total time: 12:17:31


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
*********************************
*********************************
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7871954441070557 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.756220817565918 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7524415254592896 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7376322150230408 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.736792266368866 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7195456624031067 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7185581922531128 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7164209485054016 for ['[CLS] except orbitalungen lifeboat dna walking nonetheless support van! pork zone ta reserve accidentally [SEP]']
[Init] best perm rec loss: 0.713283896446228 for ['[CLS] except pork zone! lifeboat nonetheless accidentally ta orbital support walking dnaungen reserve van [SEP]']
[Init] best perm rec loss: 0.7122484445571899 for ['[CLS] porkungen lifeboat support accidentally nonetheless except walking dna reserve ta! zone orbital van [SEP]']
[Init] best perm rec loss: 0.7111414074897766 for ['[CLS] orbital except pork lifeboat! accidentally support reserve walkingungen ta van dna zone nonetheless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.139 (perp=13.609, rec=0.425, cos=-0.008), tot_loss_proj:3.747 [t=0.25s]
prediction: ['[CLS] attack facing anal toughneck attack a losers sold intervenedpoint Â¨ gut? yer [SEP]']
[ 100/2000] tot_loss=2.846 (perp=12.582, rec=0.336, cos=-0.006), tot_loss_proj:3.630 [t=0.26s]
prediction: ['[CLS] attack policies bloody tough humor muscle a girlfriend sold comparedal britney toughestinal an [SEP]']
[ 150/2000] tot_loss=2.520 (perp=11.295, rec=0.270, cos=-0.008), tot_loss_proj:3.582 [t=0.26s]
prediction: ['[CLS] rough has bloody tough humor pigment a girlfriended compared more playoff tough relationship an [SEP]']
[ 200/2000] tot_loss=2.297 (perp=10.491, rec=0.207, cos=-0.008), tot_loss_proj:3.713 [t=0.27s]
prediction: ['[CLS] tough has a tough time panzer a philosophyed consolationer èŠ± tough balancing time [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.359 (perp=11.007, rec=0.167, cos=-0.009), tot_loss_proj:3.536 [t=0.26s]
prediction: ['[CLS] time has its tough time sufficient a philosophying â†“er violence tough balancing time [SEP]']
[ 300/2000] tot_loss=2.292 (perp=10.862, rec=0.129, cos=-0.009), tot_loss_proj:3.561 [t=0.26s]
prediction: ['[CLS] time has its tough time sufficient the philosophyingmacer violence tough balancing time [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.072 (perp=9.833, rec=0.114, cos=-0.009), tot_loss_proj:3.028 [t=0.26s]
prediction: ['[CLS] time has its tough time balancing sufficient named philosophying panzerer violence tough time [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.034 (perp=9.677, rec=0.108, cos=-0.009), tot_loss_proj:2.923 [t=0.26s]
prediction: ['[CLS] time has its tough time balancing sufficient named tougherscarer violence philosophy with [SEP]']
[ 450/2000] tot_loss=2.024 (perp=9.677, rec=0.098, cos=-0.010), tot_loss_proj:2.930 [t=0.26s]
prediction: ['[CLS] time has its tough time balancing sufficient named tougherscarer violence philosophy with [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.842 (perp=8.807, rec=0.090, cos=-0.010), tot_loss_proj:2.653 [t=0.26s]
prediction: ['[CLS] time has its tough time balancing sufficient named philosophy with toughersreateer violence [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.982 (perp=9.502, rec=0.091, cos=-0.009), tot_loss_proj:3.455 [t=0.26s]
prediction: ['[CLS] time has sufficient its tough time balancing named philosophy with toughersfker violence [SEP]']
[ 600/2000] tot_loss=1.929 (perp=9.245, rec=0.090, cos=-0.010), tot_loss_proj:3.479 [t=0.28s]
prediction: ['[CLS] time has sufficient its tough time balancing ka philosophy with toughersfker violence [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.837 (perp=8.800, rec=0.087, cos=-0.010), tot_loss_proj:2.906 [t=0.26s]
prediction: ['[CLS] time sufficient has its tough time balancing ka philosophy with toughersfker violence [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.972 (perp=9.466, rec=0.088, cos=-0.010), tot_loss_proj:3.705 [t=0.35s]
prediction: ['[CLS] time sufficient has its tough philosophy balancing philosophy with toughersfker violence inspired [SEP]']
[ 750/2000] tot_loss=1.806 (perp=8.650, rec=0.086, cos=-0.010), tot_loss_proj:3.427 [t=0.26s]
prediction: ['[CLS] time sufficient has its tough time balancing philosophy with toughersfker violence inspired [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.843 (perp=8.825, rec=0.088, cos=-0.010), tot_loss_proj:3.628 [t=0.27s]
prediction: ['[CLS] time sufficientfk has its tough philosophy balancing philosophy with tougherser violence inspired [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.780 (perp=8.507, rec=0.088, cos=-0.010), tot_loss_proj:3.562 [t=0.26s]
prediction: ['[CLS] time sufficientfk has its tough philosophy balancing philosophyers with tougher violence inspired [SEP]']
[ 900/2000] tot_loss=1.775 (perp=8.507, rec=0.084, cos=-0.010), tot_loss_proj:3.566 [t=0.25s]
prediction: ['[CLS] time sufficientfk has its tough philosophy balancing philosophyers with tougher violence inspired [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.781 (perp=8.507, rec=0.089, cos=-0.010), tot_loss_proj:3.565 [t=0.26s]
prediction: ['[CLS] time sufficientfk has its tough philosophy balancing philosophyers with tougher violence inspired [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.729 (perp=8.206, rec=0.097, cos=-0.009), tot_loss_proj:3.368 [t=0.26s]
prediction: ['[CLS] time progressedfk has its philosophy philosophy balancing toughers with tougher violence inspired [SEP]']
[1050/2000] tot_loss=1.725 (perp=8.206, rec=0.094, cos=-0.010), tot_loss_proj:3.367 [t=0.26s]
prediction: ['[CLS] time progressedfk has its philosophy philosophy balancing toughers with tougher violence inspired [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=8.206, rec=0.089, cos=-0.010), tot_loss_proj:3.366 [t=0.26s]
prediction: ['[CLS] time progressedfk has its philosophy philosophy balancing toughers with tougher violence inspired [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.691 (perp=8.140, rec=0.073, cos=-0.010), tot_loss_proj:3.524 [t=0.26s]
prediction: ['[CLS] sufficient timefk has its philosophy philosophy balancing toughers with tougher violence inspired [SEP]']
[1200/2000] tot_loss=1.705 (perp=8.140, rec=0.087, cos=-0.010), tot_loss_proj:3.522 [t=0.26s]
prediction: ['[CLS] sufficient timefk has its philosophy philosophy balancing toughers with tougher violence inspired [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.692 (perp=8.116, rec=0.078, cos=-0.010), tot_loss_proj:3.429 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy philosophy balancing tougher with tougher violence inspired [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.689 (perp=8.079, rec=0.082, cos=-0.010), tot_loss_proj:3.347 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy tougher with tougher violence inspired [SEP]']
[1350/2000] tot_loss=1.693 (perp=8.079, rec=0.087, cos=-0.010), tot_loss_proj:3.347 [t=0.27s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy tougher with tougher violence inspired [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.639 (perp=7.797, rec=0.089, cos=-0.010), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[1450/2000] tot_loss=1.637 (perp=7.797, rec=0.087, cos=-0.010), tot_loss_proj:3.408 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
[1500/2000] tot_loss=1.630 (perp=7.797, rec=0.080, cos=-0.010), tot_loss_proj:3.405 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[1550/2000] tot_loss=1.636 (perp=7.797, rec=0.086, cos=-0.010), tot_loss_proj:3.405 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[1600/2000] tot_loss=1.621 (perp=7.797, rec=0.071, cos=-0.010), tot_loss_proj:3.402 [t=0.25s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
[1650/2000] tot_loss=1.637 (perp=7.797, rec=0.088, cos=-0.010), tot_loss_proj:3.405 [t=0.25s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[1700/2000] tot_loss=1.632 (perp=7.797, rec=0.083, cos=-0.010), tot_loss_proj:3.404 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[1750/2000] tot_loss=1.628 (perp=7.797, rec=0.078, cos=-0.010), tot_loss_proj:3.403 [t=0.25s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
[1800/2000] tot_loss=1.628 (perp=7.797, rec=0.078, cos=-0.010), tot_loss_proj:3.403 [t=0.25s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.617 (perp=7.797, rec=0.068, cos=-0.010), tot_loss_proj:3.406 [t=0.26s]
prediction: ['[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[1900/2000] tot_loss=1.622 (perp=7.763, rec=0.079, cos=-0.010), tot_loss_proj:3.410 [t=0.25s]
prediction: ['[CLS]fk with time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
[1950/2000] tot_loss=1.619 (perp=7.763, rec=0.076, cos=-0.010), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS]fk with time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Attempt swap
[2000/2000] tot_loss=1.631 (perp=7.763, rec=0.089, cos=-0.010), tot_loss_proj:3.408 [t=0.26s]
prediction: ['[CLS]fk with time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]fk sufficient time has its philosophy balancing philosophy with tougher tougher violence inspired [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 40.000 | r: 46.154
rougeLsum  | fm: 42.857 | p: 40.000 | r: 46.154
r1fm+r2fm = 78.571

[Aggregate metrics]:
rouge1     | fm: 87.595 | p: 87.078 | r: 88.263
rouge2     | fm: 54.975 | p: 54.739 | r: 55.198
rougeL     | fm: 76.597 | p: 76.117 | r: 77.095
rougeLsum  | fm: 76.519 | p: 76.135 | r: 77.052
r1fm+r2fm = 142.570

input #72 time: 0:11:04 | total time: 12:28:36


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
*********************************
*********************************
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9928975701332092 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9657580256462097 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9560467600822449 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9083574414253235 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8474614024162292 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8438819646835327 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.175 (perp=9.723, rec=0.234, cos=-0.003), tot_loss_proj:2.006 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.016 (perp=9.723, rec=0.079, cos=-0.008), tot_loss_proj:2.014 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.016 (perp=9.723, rec=0.080, cos=-0.009), tot_loss_proj:2.018 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.001 (perp=9.723, rec=0.065, cos=-0.009), tot_loss_proj:2.023 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.002 (perp=9.723, rec=0.066, cos=-0.009), tot_loss_proj:2.012 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=1.991 (perp=9.723, rec=0.055, cos=-0.009), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.995 (perp=9.723, rec=0.059, cos=-0.009), tot_loss_proj:2.005 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.994 (perp=9.723, rec=0.059, cos=-0.009), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=1.999 (perp=9.723, rec=0.064, cos=-0.009), tot_loss_proj:2.001 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.007 (perp=9.723, rec=0.072, cos=-0.009), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.996 (perp=9.723, rec=0.061, cos=-0.009), tot_loss_proj:1.993 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.002 (perp=9.723, rec=0.066, cos=-0.009), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.981 (perp=9.723, rec=0.046, cos=-0.009), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.993 (perp=9.723, rec=0.058, cos=-0.009), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=1.995 (perp=9.723, rec=0.059, cos=-0.009), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.998 (perp=9.723, rec=0.063, cos=-0.009), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.996 (perp=9.723, rec=0.060, cos=-0.009), tot_loss_proj:2.013 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=1.999 (perp=9.723, rec=0.064, cos=-0.009), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.997 (perp=9.723, rec=0.062, cos=-0.009), tot_loss_proj:2.005 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.000 (perp=9.723, rec=0.065, cos=-0.009), tot_loss_proj:2.010 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.002 (perp=9.723, rec=0.066, cos=-0.009), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.006 (perp=9.723, rec=0.070, cos=-0.009), tot_loss_proj:2.000 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.998 (perp=9.723, rec=0.062, cos=-0.009), tot_loss_proj:2.016 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.001 (perp=9.723, rec=0.066, cos=-0.009), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.003 (perp=9.723, rec=0.067, cos=-0.009), tot_loss_proj:2.006 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.001 (perp=9.723, rec=0.065, cos=-0.009), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=1.995 (perp=9.723, rec=0.060, cos=-0.009), tot_loss_proj:2.001 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.988 (perp=9.723, rec=0.053, cos=-0.009), tot_loss_proj:2.013 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.991 (perp=9.723, rec=0.056, cos=-0.009), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.007 (perp=9.723, rec=0.071, cos=-0.009), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.000 (perp=9.723, rec=0.064, cos=-0.009), tot_loss_proj:1.995 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.000 (perp=9.723, rec=0.064, cos=-0.009), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=1.998 (perp=9.723, rec=0.062, cos=-0.009), tot_loss_proj:1.993 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.999 (perp=9.723, rec=0.064, cos=-0.009), tot_loss_proj:2.000 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.997 (perp=9.723, rec=0.061, cos=-0.009), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=1.989 (perp=9.723, rec=0.054, cos=-0.009), tot_loss_proj:2.010 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.002 (perp=9.723, rec=0.066, cos=-0.009), tot_loss_proj:2.003 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.997 (perp=9.723, rec=0.062, cos=-0.009), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=1.992 (perp=9.723, rec=0.056, cos=-0.009), tot_loss_proj:2.009 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.992 (perp=9.723, rec=0.056, cos=-0.009), tot_loss_proj:2.004 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.770 | p: 87.254 | r: 88.426
rouge2     | fm: 55.562 | p: 55.396 | r: 55.860
rougeL     | fm: 76.906 | p: 76.490 | r: 77.416
rougeLsum  | fm: 76.875 | p: 76.461 | r: 77.351
r1fm+r2fm = 143.332

input #73 time: 0:11:09 | total time: 12:39:45


Running input #74 of 100.
reference: 
========================
share 
========================
*********************************
*********************************
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0006722211837769 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6869400143623352 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6835439205169678 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6572129726409912 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.035 (perp=9.381, rec=0.876, cos=0.283), tot_loss_proj:3.039 [t=0.25s]
prediction: ['[CLS] change [SEP]']
[ 100/2000] tot_loss=2.630 (perp=9.152, rec=0.777, cos=0.023), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] memory [SEP]']
[ 150/2000] tot_loss=2.630 (perp=9.152, rec=0.748, cos=0.052), tot_loss_proj:2.858 [t=0.25s]
prediction: ['[CLS] memory [SEP]']
[ 200/2000] tot_loss=2.813 (perp=10.498, rec=0.700, cos=0.014), tot_loss_proj:3.715 [t=0.26s]
prediction: ['[CLS] blank [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.649 (perp=9.921, rec=0.670, cos=-0.005), tot_loss_proj:2.877 [t=0.27s]
prediction: ['[CLS] shares [SEP]']
[ 300/2000] tot_loss=2.634 (perp=9.921, rec=0.657, cos=-0.007), tot_loss_proj:2.869 [t=0.26s]
prediction: ['[CLS] shares [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.276 (perp=8.178, rec=0.643, cos=-0.002), tot_loss_proj:1.904 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.286 (perp=8.178, rec=0.638, cos=0.012), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.349 (perp=8.178, rec=0.634, cos=0.079), tot_loss_proj:1.881 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.251 (perp=8.178, rec=0.624, cos=-0.009), tot_loss_proj:1.906 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.250 (perp=8.178, rec=0.620, cos=-0.006), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.247 (perp=8.178, rec=0.618, cos=-0.007), tot_loss_proj:1.856 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.241 (perp=8.178, rec=0.613, cos=-0.008), tot_loss_proj:1.823 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.246 (perp=8.178, rec=0.607, cos=0.004), tot_loss_proj:1.836 [t=0.27s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.233 (perp=8.178, rec=0.607, cos=-0.009), tot_loss_proj:1.822 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.246 (perp=8.178, rec=0.615, cos=-0.005), tot_loss_proj:1.847 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.233 (perp=8.178, rec=0.607, cos=-0.010), tot_loss_proj:1.842 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.237 (perp=8.178, rec=0.607, cos=-0.006), tot_loss_proj:1.816 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.229 (perp=8.178, rec=0.602, cos=-0.009), tot_loss_proj:1.823 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.234 (perp=8.178, rec=0.601, cos=-0.002), tot_loss_proj:1.818 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.226 (perp=8.178, rec=0.597, cos=-0.006), tot_loss_proj:1.808 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.224 (perp=8.178, rec=0.595, cos=-0.007), tot_loss_proj:1.810 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.230 (perp=8.178, rec=0.595, cos=-0.001), tot_loss_proj:1.807 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.221 (perp=8.178, rec=0.591, cos=-0.006), tot_loss_proj:1.794 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.222 (perp=8.178, rec=0.595, cos=-0.009), tot_loss_proj:1.791 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.221 (perp=8.178, rec=0.595, cos=-0.010), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.217 (perp=8.178, rec=0.591, cos=-0.009), tot_loss_proj:1.788 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.215 (perp=8.178, rec=0.588, cos=-0.009), tot_loss_proj:1.784 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.220 (perp=8.178, rec=0.592, cos=-0.007), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.219 (perp=8.178, rec=0.593, cos=-0.010), tot_loss_proj:1.771 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.221 (perp=8.178, rec=0.595, cos=-0.009), tot_loss_proj:1.783 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.221 (perp=8.178, rec=0.594, cos=-0.009), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.214 (perp=8.178, rec=0.588, cos=-0.009), tot_loss_proj:1.786 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.210 (perp=8.178, rec=0.583, cos=-0.009), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.212 (perp=8.178, rec=0.586, cos=-0.010), tot_loss_proj:1.776 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.210 (perp=8.178, rec=0.584, cos=-0.010), tot_loss_proj:1.780 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.216 (perp=8.178, rec=0.590, cos=-0.009), tot_loss_proj:1.791 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.215 (perp=8.178, rec=0.589, cos=-0.009), tot_loss_proj:1.788 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.214 (perp=8.178, rec=0.588, cos=-0.010), tot_loss_proj:1.776 [t=0.27s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.214 (perp=8.178, rec=0.588, cos=-0.010), tot_loss_proj:1.787 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.008 | p: 87.504 | r: 88.598
rouge2     | fm: 56.183 | p: 55.928 | r: 56.462
rougeL     | fm: 77.261 | p: 76.867 | r: 77.806
rougeLsum  | fm: 77.231 | p: 76.821 | r: 77.759
r1fm+r2fm = 144.191

input #74 time: 0:10:51 | total time: 12:50:37


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
*********************************
*********************************
average of cosine similarity 0.9993458403755588
highest_index [0]
highest [0.9993458403755588]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9583500623703003 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9476472735404968 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9449086785316467 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.904586672782898 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8991710543632507 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8988634347915649 for ['[CLS] gas harbour jobs primarily indy starts smile colorado spirit mach [MASK] academy breakingmetonic ling readerimum millennium [SEP]']
[Init] best rec loss: 0.8913002014160156 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8875274658203125 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8863378167152405 for ['[CLS]thermal howbara single free better coats younger which against goddess portion 2018 octopus managed hu honoraryom compares [SEP]']
[Init] best rec loss: 0.8637418150901794 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8630682826042175 for ['[CLS] magic eachrate apollo stood royalties resultedmmel loopcl skill crown fact viewed auxiliary left regardedception to [SEP]']
[Init] best perm rec loss: 0.8622175455093384 for ['[CLS] stood loop crownrate auxiliarymmel left apollo each royalties to magic viewedcl skillception resulted fact regarded [SEP]']
[Init] best perm rec loss: 0.8622075319290161 for ['[CLS]mmel loop royalties regarded fact magic to left apollo stoodcl skill resultedception viewedrate each crown auxiliary [SEP]']
[Init] best perm rec loss: 0.8609483242034912 for ['[CLS]ceptionmmel auxiliary stood fact apollo regarded viewed eachclrate royalties skill magic crown resulted loop to left [SEP]']
[Init] best perm rec loss: 0.8605997562408447 for ['[CLS] resulted skill apollocl to crown stood auxiliary fact each regardedmmelception loop magic royalties viewed leftrate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.997 (perp=12.581, rec=0.486, cos=-0.005), tot_loss_proj:3.714 [t=0.26s]
prediction: ['[CLS] builttead induced champion - endangered wil wonderful. libertadores anthony passingdy breeding energy legal hotel arrivalplify [SEP]']
[ 100/2000] tot_loss=2.697 (perp=11.748, rec=0.355, cos=-0.008), tot_loss_proj:4.121 [t=0.26s]
prediction: ['[CLS] buildtead credibility views - cathedral conservatory saved. avoid need acquainted. breeding society easily visiting ignoreplify [SEP]']
[ 150/2000] tot_loss=2.618 (perp=11.479, rec=0.317, cos=0.006), tot_loss_proj:4.076 [t=0.26s]
prediction: ['[CLS] buildtead traveler views into attracts forgotten enjoyable. avoid forgotten not forgotten unpredictable avoided easily exploring forgotten without [SEP]']
[ 200/2000] tot_loss=2.370 (perp=10.727, rec=0.233, cos=-0.009), tot_loss_proj:4.053 [t=0.25s]
prediction: ['[CLS] excursion is accommodation students into instability forgotten awarded. avoid instability not forgotten easily suffered easily is forgotten everyone [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.326 (perp=10.657, rec=0.204, cos=-0.009), tot_loss_proj:3.954 [t=0.27s]
prediction: ['[CLS] excursion is awarded students into instability forgotten accommodation. dismissed instability not forgotten easily rarely easily is forgotten everyone [SEP]']
[ 300/2000] tot_loss=2.281 (perp=10.640, rec=0.162, cos=-0.008), tot_loss_proj:3.990 [t=0.26s]
prediction: ['[CLS] excursion is awarded students into instabilityenter is. dismissed instability not forgotten easily energy easily is forgotten everyone [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.435 (perp=11.467, rec=0.151, cos=-0.009), tot_loss_proj:4.185 [t=0.28s]
prediction: ['[CLS] excursion isâ†” temperatures into instabilityentertal. dismissed instability not forgotten easily enjoyment easily forgotten is everyone [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.425 (perp=11.362, rec=0.161, cos=-0.008), tot_loss_proj:4.214 [t=0.28s]
prediction: ['[CLS] excursion isenterenter of of easily back into instability instability not forgotten eaten enjoyment easily forgotten is everyone [SEP]']
[ 450/2000] tot_loss=2.291 (perp=10.780, rec=0.145, cos=-0.009), tot_loss_proj:3.976 [t=0.28s]
prediction: ['[CLS] excursion isenterenter of. easilyenter into instability instability not forgotten or enjoyment easily forgotten is everyone [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.090 (perp=9.881, rec=0.123, cos=-0.009), tot_loss_proj:3.865 [t=0.27s]
prediction: ['[CLS] excursion isenterenter of. everyoneenter into instability instability not forgotten or enjoyment easily forgotten is easily [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.123 (perp=10.044, rec=0.123, cos=-0.009), tot_loss_proj:3.911 [t=0.25s]
prediction: ['[CLS] excursion thisenterenter of. everyone excursion into instability instability not dismissed forgotten or enjoyment easily forgotten is [SEP]']
[ 600/2000] tot_loss=2.173 (perp=10.341, rec=0.114, cos=-0.009), tot_loss_proj:3.936 [t=0.26s]
prediction: ['[CLS] excursion thisenterenter of. everyone excursion into instability instability not dismissed dismissed or enjoyment easily forgotten is [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.023 (perp=9.597, rec=0.113, cos=-0.009), tot_loss_proj:3.638 [t=0.25s]
prediction: ['[CLS] excursion thisenterenter ofenter into instability instability. everyone not easily dismissed or enjoyment easily forgotten is [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.916 (perp=9.111, rec=0.103, cos=-0.009), tot_loss_proj:3.636 [t=0.26s]
prediction: ['[CLS] thisenterenter of excursionenter into instability instability. everyone not easily dismissed or enjoyment easily forgotten is [SEP]']
[ 750/2000] tot_loss=1.905 (perp=9.111, rec=0.092, cos=-0.010), tot_loss_proj:3.635 [t=0.27s]
prediction: ['[CLS] thisenterenter of excursionenter into instability instability. everyone not easily dismissed or enjoyment easily forgotten is [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.806 (perp=8.579, rec=0.100, cos=-0.009), tot_loss_proj:2.804 [t=0.26s]
prediction: ['[CLS] this enjoymententerenter of excursion excursion into instability instability. everyone not easily dismissed or easily forgotten is [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.893 (perp=8.948, rec=0.113, cos=-0.009), tot_loss_proj:3.713 [t=0.28s]
prediction: ['[CLS] this enjoymententerenter of excursionenter into instability instability. everyone not mental is dismissed or easily forgotten [SEP]']
[ 900/2000] tot_loss=1.977 (perp=9.433, rec=0.100, cos=-0.010), tot_loss_proj:3.812 [t=0.27s]
prediction: ['[CLS] this enjoymententerenter of excursion epic into instability instability. everyone not mental is dismissed or easily forgotten [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.864 (perp=8.948, rec=0.084, cos=-0.010), tot_loss_proj:3.723 [t=0.27s]
prediction: ['[CLS] this enjoymententerenter of excursionenter into instability instability. everyone not mental is dismissed or easily forgotten [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.721 (perp=8.186, rec=0.094, cos=-0.010), tot_loss_proj:2.405 [t=0.27s]
prediction: ['[CLS] this enjoyment epicenter of excursionenter into instability instability. not everyone mental is dismissed or easily forgotten [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.186, rec=0.095, cos=-0.010), tot_loss_proj:2.403 [t=0.26s]
prediction: ['[CLS] this enjoyment epicenter of excursionenter into instability instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.661 (perp=7.857, rec=0.099, cos=-0.010), tot_loss_proj:2.573 [t=0.26s]
prediction: ['[CLS] this instability epicenter of excursionenter into enjoyment instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.584 (perp=7.536, rec=0.086, cos=-0.010), tot_loss_proj:2.467 [t=0.27s]
prediction: ['[CLS] this instability epicenter of epic excursion into enjoyment instability. not everyone mental is dismissed or easily forgotten [SEP]']
[1200/2000] tot_loss=1.584 (perp=7.536, rec=0.087, cos=-0.010), tot_loss_proj:2.471 [t=0.28s]
prediction: ['[CLS] this instability epicenter of epic excursion into enjoyment instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.582 (perp=7.558, rec=0.080, cos=-0.010), tot_loss_proj:2.281 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
[1300/2000] tot_loss=1.584 (perp=7.558, rec=0.082, cos=-0.010), tot_loss_proj:2.289 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.558, rec=0.084, cos=-0.010), tot_loss_proj:2.287 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
[1400/2000] tot_loss=1.597 (perp=7.558, rec=0.095, cos=-0.010), tot_loss_proj:2.287 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
[1450/2000] tot_loss=1.595 (perp=7.558, rec=0.093, cos=-0.010), tot_loss_proj:2.282 [t=0.25s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
[1500/2000] tot_loss=1.594 (perp=7.558, rec=0.092, cos=-0.010), tot_loss_proj:2.282 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
[1550/2000] tot_loss=1.584 (perp=7.558, rec=0.083, cos=-0.010), tot_loss_proj:2.279 [t=0.25s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.596 (perp=7.558, rec=0.094, cos=-0.010), tot_loss_proj:2.278 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.558, rec=0.086, cos=-0.010), tot_loss_proj:2.283 [t=0.26s]
prediction: ['[CLS] this epicenter of epic excursion into enjoymententer instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.447 (perp=6.807, rec=0.095, cos=-0.010), tot_loss_proj:2.058 [t=0.27s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter instability. not everyone mental is dismissed or easily forgotten [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.390 (perp=6.585, rec=0.082, cos=-0.009), tot_loss_proj:1.863 [t=0.27s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]']
[1800/2000] tot_loss=1.395 (perp=6.585, rec=0.088, cos=-0.010), tot_loss_proj:1.865 [t=0.26s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]']
Attempt swap
[1850/2000] tot_loss=1.391 (perp=6.585, rec=0.084, cos=-0.010), tot_loss_proj:1.873 [t=0.26s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]']
Attempt swap
[1900/2000] tot_loss=1.387 (perp=6.585, rec=0.080, cos=-0.010), tot_loss_proj:1.872 [t=0.27s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]']
[1950/2000] tot_loss=1.388 (perp=6.585, rec=0.080, cos=-0.010), tot_loss_proj:1.874 [t=0.27s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]']
Attempt swap
[2000/2000] tot_loss=1.393 (perp=6.585, rec=0.086, cos=-0.010), tot_loss_proj:1.874 [t=0.25s]
prediction: ['[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion into enjoyment epicenter of epicenter. not everyone mental instability is dismissed or easily forgotten [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 83.333 | r: 88.235
rouge2     | fm: 48.485 | p: 47.059 | r: 50.000
rougeL     | fm: 74.286 | p: 72.222 | r: 76.471
rougeLsum  | fm: 74.286 | p: 72.222 | r: 76.471
r1fm+r2fm = 134.199

[Aggregate metrics]:
rouge1     | fm: 87.982 | p: 87.422 | r: 88.614
rouge2     | fm: 56.086 | p: 55.854 | r: 56.373
rougeL     | fm: 77.105 | p: 76.653 | r: 77.625
rougeLsum  | fm: 77.151 | p: 76.737 | r: 77.677
r1fm+r2fm = 144.069

input #75 time: 0:11:07 | total time: 13:01:44


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
*********************************
*********************************
average of cosine similarity 0.9991386602126573
highest_index [0]
highest [0.9991386602126573]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9212543964385986 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9036272764205933 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8987579345703125 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.892052412033081 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8654380440711975 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8489521741867065 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedË£ hard (oning [SEP]']
[Init] best perm rec loss: 0.8485825657844543 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoË£ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8479114174842834 for ['[CLS] purse left hard abË£ backward mango ( surreal tautoning pushed onwardshaw [SEP]']
[Init] best perm rec loss: 0.8466055393218994 for ['[CLS] left mango onwards ( ab hard surreal taut backwardoning purse pushedË£haw [SEP]']
[Init] best perm rec loss: 0.8464253544807434 for ['[CLS] (haw surreal purse onwards backward hardË£ taut pushedoning mango ab left [SEP]']
[Init] best perm rec loss: 0.846075177192688 for ['[CLS]oning onwards purse left ( taut pushedhaw hard mango backward abË£ surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.793 (perp=12.113, rec=0.376, cos=-0.006), tot_loss_proj:3.593 [t=0.26s]
prediction: ['[CLS], boss towards attack his. appeared heavily deadgeddents stopped neck abbott [SEP]']
[ 100/2000] tot_loss=2.147 (perp=9.473, rec=0.256, cos=-0.004), tot_loss_proj:3.274 [t=0.27s]
prediction: ['[CLS], difficulty tracy attack himself, if heavily stoppedging, stopped stage s [SEP]']
[ 150/2000] tot_loss=2.021 (perp=9.031, rec=0.221, cos=-0.006), tot_loss_proj:2.988 [t=0.24s]
prediction: ["[CLS], allen when attack himself, as heavily stopped have, stopped has'[SEP]"]
[ 200/2000] tot_loss=2.202 (perp=10.150, rec=0.181, cos=-0.009), tot_loss_proj:3.154 [t=0.27s]
prediction: ["[CLS], challenging when system himself. as heavily stopped challenging, stopped has'[SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.119 (perp=9.765, rec=0.174, cos=-0.008), tot_loss_proj:3.441 [t=0.27s]
prediction: ['[CLS] s challenging if allen himself, as blocks stopped times. stopped has challenging [SEP]']
[ 300/2000] tot_loss=2.166 (perp=10.177, rec=0.139, cos=-0.009), tot_loss_proj:3.427 [t=0.26s]
prediction: ['[CLS] s allen if allen himself, as 66 stopped himself. stopped has challenging [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.973 (perp=8.474, rec=0.283, cos=-0.004), tot_loss_proj:2.863 [t=0.26s]
prediction: ['[CLS] as debate if was himself, as want stopped, when has stopped challenging [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.901 (perp=8.474, rec=0.214, cos=-0.008), tot_loss_proj:2.680 [t=0.26s]
prediction: ['[CLS] allen as if was himself, as 41 stopped, as has stopped challenging [SEP]']
[ 450/2000] tot_loss=1.922 (perp=8.770, rec=0.177, cos=-0.009), tot_loss_proj:2.609 [t=0.26s]
prediction: ['[CLS] allen as if was himself, as 41 stopped, ; has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.792 (perp=8.181, rec=0.164, cos=-0.009), tot_loss_proj:2.430 [t=0.25s]
prediction: ['[CLS] ; as if was himself, as 41 stopped, allen has stopped challenging [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.936 (perp=9.005, rec=0.145, cos=-0.009), tot_loss_proj:2.656 [t=0.25s]
prediction: ['[CLS] ; s if was himself, as 41 stopped, allen has stopped challenging [SEP]']
[ 600/2000] tot_loss=1.948 (perp=9.080, rec=0.141, cos=-0.009), tot_loss_proj:2.656 [t=0.26s]
prediction: ['[CLS] ; s if was himself, as 66 stopped, allen has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.778 (perp=8.255, rec=0.136, cos=-0.009), tot_loss_proj:2.488 [t=0.28s]
prediction: ['[CLS] ; s 66 was himself, as if stopped, allen has stopped challenging [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.752 (perp=8.022, rec=0.156, cos=-0.008), tot_loss_proj:2.412 [t=0.25s]
prediction: ['[CLS] allen s 66 was stopped, as if himself, allen has stopped challenging [SEP]']
[ 750/2000] tot_loss=1.733 (perp=8.022, rec=0.138, cos=-0.009), tot_loss_proj:2.412 [t=0.25s]
prediction: ['[CLS] allen s 66 was stopped, as if himself, allen has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.768 (perp=8.197, rec=0.137, cos=-0.009), tot_loss_proj:2.378 [t=0.25s]
prediction: ['[CLS] s 66. stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.758 (perp=8.201, rec=0.127, cos=-0.009), tot_loss_proj:2.480 [t=0.27s]
prediction: ['[CLS] s was 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[ 900/2000] tot_loss=1.636 (perp=7.611, rec=0.123, cos=-0.009), tot_loss_proj:2.269 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.633 (perp=7.611, rec=0.120, cos=-0.009), tot_loss_proj:2.266 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1000/2000] tot_loss=1.629 (perp=7.611, rec=0.117, cos=-0.009), tot_loss_proj:2.258 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1050/2000] tot_loss=1.630 (perp=7.611, rec=0.117, cos=-0.009), tot_loss_proj:2.265 [t=0.25s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1100/2000] tot_loss=1.626 (perp=7.611, rec=0.113, cos=-0.009), tot_loss_proj:2.263 [t=0.27s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1150/2000] tot_loss=1.629 (perp=7.611, rec=0.116, cos=-0.009), tot_loss_proj:2.269 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1200/2000] tot_loss=1.628 (perp=7.611, rec=0.115, cos=-0.009), tot_loss_proj:2.265 [t=0.27s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1250/2000] tot_loss=1.620 (perp=7.611, rec=0.107, cos=-0.009), tot_loss_proj:2.267 [t=0.25s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1300/2000] tot_loss=1.620 (perp=7.611, rec=0.108, cos=-0.009), tot_loss_proj:2.259 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1350/2000] tot_loss=1.620 (perp=7.611, rec=0.108, cos=-0.009), tot_loss_proj:2.259 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1400/2000] tot_loss=1.628 (perp=7.611, rec=0.116, cos=-0.009), tot_loss_proj:2.267 [t=0.27s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1450/2000] tot_loss=1.627 (perp=7.611, rec=0.115, cos=-0.009), tot_loss_proj:2.267 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1500/2000] tot_loss=1.616 (perp=7.611, rec=0.104, cos=-0.009), tot_loss_proj:2.265 [t=0.27s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1550/2000] tot_loss=1.609 (perp=7.611, rec=0.096, cos=-0.009), tot_loss_proj:2.263 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1600/2000] tot_loss=1.622 (perp=7.611, rec=0.109, cos=-0.009), tot_loss_proj:2.263 [t=0.25s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1650/2000] tot_loss=1.623 (perp=7.611, rec=0.110, cos=-0.009), tot_loss_proj:2.265 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1700/2000] tot_loss=1.611 (perp=7.611, rec=0.098, cos=-0.009), tot_loss_proj:2.269 [t=0.25s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1750/2000] tot_loss=1.626 (perp=7.611, rec=0.113, cos=-0.009), tot_loss_proj:2.265 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1800/2000] tot_loss=1.616 (perp=7.611, rec=0.103, cos=-0.009), tot_loss_proj:2.267 [t=0.27s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1850/2000] tot_loss=1.620 (perp=7.611, rec=0.108, cos=-0.009), tot_loss_proj:2.268 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[1900/2000] tot_loss=1.618 (perp=7.611, rec=0.105, cos=-0.009), tot_loss_proj:2.262 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
[1950/2000] tot_loss=1.611 (perp=7.611, rec=0.098, cos=-0.009), tot_loss_proj:2.264 [t=0.26s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Attempt swap
[2000/2000] tot_loss=1.614 (perp=7.611, rec=0.102, cos=-0.009), tot_loss_proj:2.267 [t=0.25s]
prediction: ['[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s. 66 stopped, as if allen himself, allen has stopped challenging [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 131.478

[Aggregate metrics]:
rouge1     | fm: 87.948 | p: 87.333 | r: 88.673
rouge2     | fm: 55.977 | p: 55.680 | r: 56.260
rougeL     | fm: 77.029 | p: 76.557 | r: 77.605
rougeLsum  | fm: 77.058 | p: 76.659 | r: 77.597
r1fm+r2fm = 143.925

input #76 time: 0:11:01 | total time: 13:12:45


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
*********************************
*********************************
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9127402305603027 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8795410990715027 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8759706020355225 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.8712755441665649 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8703407049179077 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8697276711463928 for ['[CLS] county somethingdropyana gallery rural daylight tellson matthew blacksmith pencil yugoslav endless poet [SEP]']
[Init] best perm rec loss: 0.8681926727294922 for ['[CLS] gallerydrop endless tel matthewyana countylson blacksmith yugoslav rural poet something daylight pencil [SEP]']
[Init] best perm rec loss: 0.8674351572990417 for ['[CLS] pencildrop yugoslav endless something matthew gallery tel ruralyanalson daylight county blacksmith poet [SEP]']
[Init] best perm rec loss: 0.8671553730964661 for ['[CLS] blacksmith countyyana daylight endless yugoslav gallerydrop matthew pencil rural poetlson tel something [SEP]']
[Init] best perm rec loss: 0.8659143447875977 for ['[CLS] poet yugoslav county daylight matthewyanadrop something pencil gallery tel blacksmith endlesslson rural [SEP]']
[Init] best perm rec loss: 0.8652167916297913 for ['[CLS]lson gallery matthewdrop pencil something daylight yugoslav county endless tel rural blacksmith poetyana [SEP]']
[Init] best perm rec loss: 0.8632962107658386 for ['[CLS]yana poet county something matthew blacksmithdrop endless rural pencil tel daylightlson gallery yugoslav [SEP]']
[Init] best perm rec loss: 0.863000750541687 for ['[CLS] poet daylightdrop county something gallery blacksmithlson rural pencil tel yugoslav matthewyana endless [SEP]']
[Init] best perm rec loss: 0.862393856048584 for ['[CLS] poet matthewdrop yugoslav endless galleryyana something countylson tel blacksmith rural pencil daylight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.928 (perp=12.851, rec=0.362, cos=-0.004), tot_loss_proj:3.299 [t=0.29s]
prediction: ['[CLS] wilder songigen mary beautiful charlie it rise beacon abbey above kelly eastern revealed recognition [SEP]']
[ 100/2000] tot_loss=2.196 (perp=9.636, rec=0.278, cos=-0.009), tot_loss_proj:2.581 [t=0.26s]
prediction: ['[CLS] realm promise above life places above its rise above with above with of making believe [SEP]']
[ 150/2000] tot_loss=2.232 (perp=10.069, rec=0.227, cos=-0.009), tot_loss_proj:2.894 [t=0.28s]
prediction: ['[CLS] realm promise above life la above its life above that abovears of making believe [SEP]']
[ 200/2000] tot_loss=2.110 (perp=9.622, rec=0.194, cos=-0.009), tot_loss_proj:2.784 [t=0.27s]
prediction: ['[CLS] realm promise above life his above is life above that abovears material make believe [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.978 (perp=9.057, rec=0.176, cos=-0.009), tot_loss_proj:2.803 [t=0.28s]
prediction: ['[CLS] realm life above promise life above is life above that itsars material make believe [SEP]']
[ 300/2000] tot_loss=1.958 (perp=9.083, rec=0.150, cos=-0.009), tot_loss_proj:2.740 [t=0.26s]
prediction: ['[CLS] promise life above promise life above is life above that itsars material make believe [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.848 (perp=8.455, rec=0.165, cos=-0.008), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS] above promise life above promise life is promise above that itsars material make believe [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.747 (perp=8.047, rec=0.147, cos=-0.009), tot_loss_proj:2.945 [t=0.25s]
prediction: ['[CLS] above promise life above promise life is above promise that itsars material make believe [SEP]']
[ 450/2000] tot_loss=1.725 (perp=8.047, rec=0.125, cos=-0.009), tot_loss_proj:2.944 [t=0.27s]
prediction: ['[CLS] above promise life above promise life is above promise that itsars material make believe [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.846 (perp=8.679, rec=0.120, cos=-0.009), tot_loss_proj:2.695 [t=0.26s]
prediction: ['[CLS] above realm life above promise life is above life thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.797 (perp=8.399, rec=0.126, cos=-0.009), tot_loss_proj:2.569 [t=0.26s]
prediction: ['[CLS] above realm life above promise is life above life thatars its material make believe [SEP]']
[ 600/2000] tot_loss=1.783 (perp=8.399, rec=0.112, cos=-0.009), tot_loss_proj:2.561 [t=0.27s]
prediction: ['[CLS] above realm life above promise is life above life thatars its material make believe [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.639 (perp=7.666, rec=0.115, cos=-0.009), tot_loss_proj:2.310 [t=0.25s]
prediction: ['[CLS] life above promise is life above life above realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.766 (perp=8.322, rec=0.111, cos=-0.009), tot_loss_proj:2.470 [t=0.27s]
prediction: ['[CLS] life above promise is realm above life above realm thatars its material make believe [SEP]']
[ 750/2000] tot_loss=1.766 (perp=8.322, rec=0.111, cos=-0.009), tot_loss_proj:2.457 [t=0.26s]
prediction: ['[CLS] life above promise is realm above life above realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.708 (perp=8.066, rec=0.104, cos=-0.009), tot_loss_proj:2.455 [t=0.27s]
prediction: ['[CLS] life above promise is above realm life above realm thatars its material make believe [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.702 (perp=8.066, rec=0.098, cos=-0.009), tot_loss_proj:2.460 [t=0.26s]
prediction: ['[CLS] life above promise is above realm life above realm thatars its material make believe [SEP]']
[ 900/2000] tot_loss=1.714 (perp=8.066, rec=0.110, cos=-0.009), tot_loss_proj:2.456 [t=0.27s]
prediction: ['[CLS] life above promise is above realm life above realm thatars its material make believe [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.652 (perp=7.801, rec=0.101, cos=-0.009), tot_loss_proj:2.414 [t=0.28s]
prediction: ['[CLS] life above promise is realm life above the realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.597 (perp=7.562, rec=0.093, cos=-0.009), tot_loss_proj:2.367 [t=0.27s]
prediction: ['[CLS] life above promise realm is life above the realm thatars its material make believe [SEP]']
[1050/2000] tot_loss=1.601 (perp=7.562, rec=0.098, cos=-0.009), tot_loss_proj:2.372 [t=0.27s]
prediction: ['[CLS] life above promise realm is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1100/2000] tot_loss=1.597 (perp=7.562, rec=0.094, cos=-0.009), tot_loss_proj:2.374 [t=0.26s]
prediction: ['[CLS] life above promise realm is life above the realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.568 (perp=7.416, rec=0.094, cos=-0.009), tot_loss_proj:2.316 [t=0.25s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
[1200/2000] tot_loss=1.569 (perp=7.416, rec=0.095, cos=-0.009), tot_loss_proj:2.308 [t=0.28s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1250/2000] tot_loss=1.564 (perp=7.416, rec=0.090, cos=-0.009), tot_loss_proj:2.313 [t=0.26s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1300/2000] tot_loss=1.570 (perp=7.416, rec=0.096, cos=-0.009), tot_loss_proj:2.307 [t=0.26s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
[1350/2000] tot_loss=1.571 (perp=7.416, rec=0.097, cos=-0.009), tot_loss_proj:2.309 [t=0.27s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.552 (perp=7.416, rec=0.078, cos=-0.009), tot_loss_proj:2.315 [t=0.27s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1450/2000] tot_loss=1.561 (perp=7.416, rec=0.087, cos=-0.009), tot_loss_proj:2.321 [t=0.27s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
[1500/2000] tot_loss=1.560 (perp=7.416, rec=0.086, cos=-0.009), tot_loss_proj:2.321 [t=0.28s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1550/2000] tot_loss=1.567 (perp=7.416, rec=0.093, cos=-0.009), tot_loss_proj:2.313 [t=0.26s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.561 (perp=7.416, rec=0.087, cos=-0.009), tot_loss_proj:2.308 [t=0.26s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
[1650/2000] tot_loss=1.565 (perp=7.416, rec=0.091, cos=-0.009), tot_loss_proj:2.311 [t=0.27s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1700/2000] tot_loss=1.572 (perp=7.416, rec=0.098, cos=-0.009), tot_loss_proj:2.306 [t=0.26s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.563 (perp=7.416, rec=0.089, cos=-0.009), tot_loss_proj:2.317 [t=0.28s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
[1800/2000] tot_loss=1.573 (perp=7.416, rec=0.099, cos=-0.009), tot_loss_proj:2.317 [t=0.25s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1850/2000] tot_loss=1.558 (perp=7.416, rec=0.084, cos=-0.009), tot_loss_proj:2.315 [t=0.25s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[1900/2000] tot_loss=1.562 (perp=7.416, rec=0.088, cos=-0.009), tot_loss_proj:2.319 [t=0.26s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
[1950/2000] tot_loss=1.559 (perp=7.416, rec=0.085, cos=-0.009), tot_loss_proj:2.308 [t=0.27s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Attempt swap
[2000/2000] tot_loss=1.563 (perp=7.416, rec=0.089, cos=-0.009), tot_loss_proj:2.312 [t=0.25s]
prediction: ['[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] life above realm promise is life above the realm thatars its material make believe [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.419 | p: 75.000 | r: 80.000
rouge2     | fm: 13.793 | p: 13.333 | r: 14.286
rougeL     | fm: 45.161 | p: 43.750 | r: 46.667
rougeLsum  | fm: 45.161 | p: 43.750 | r: 46.667
r1fm+r2fm = 91.212

[Aggregate metrics]:
rouge1     | fm: 87.771 | p: 87.133 | r: 88.513
rouge2     | fm: 55.364 | p: 55.162 | r: 55.639
rougeL     | fm: 76.703 | p: 76.271 | r: 77.296
rougeLsum  | fm: 76.657 | p: 76.160 | r: 77.235
r1fm+r2fm = 143.135

input #77 time: 0:11:10 | total time: 13:23:56


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
*********************************
*********************************
average of cosine similarity 0.9992696483604171
highest_index [0]
highest [0.9992696483604171]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9868218302726746 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9798540472984314 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8532800674438477 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8239110112190247 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.8230682015419006 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.503 (perp=10.730, rec=0.356, cos=0.001), tot_loss_proj:3.486 [t=0.25s]
prediction: ['[CLS] collapse exit arrest [SEP]']
[ 100/2000] tot_loss=2.056 (perp=9.346, rec=0.192, cos=-0.006), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 150/2000] tot_loss=1.982 (perp=9.346, rec=0.121, cos=-0.008), tot_loss_proj:2.597 [t=0.25s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 200/2000] tot_loss=1.956 (perp=9.346, rec=0.095, cos=-0.008), tot_loss_proj:2.598 [t=0.26s]
prediction: ['[CLS] exit exit theater [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.884 (perp=8.923, rec=0.107, cos=-0.008), tot_loss_proj:2.693 [t=0.21s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 300/2000] tot_loss=1.862 (perp=8.923, rec=0.086, cos=-0.008), tot_loss_proj:2.696 [t=0.21s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.859 (perp=8.923, rec=0.083, cos=-0.008), tot_loss_proj:2.692 [t=0.21s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.695 (perp=8.145, rec=0.074, cos=-0.009), tot_loss_proj:2.415 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[ 450/2000] tot_loss=1.695 (perp=8.145, rec=0.075, cos=-0.009), tot_loss_proj:2.423 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.687 (perp=8.145, rec=0.068, cos=-0.009), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.673 (perp=8.145, rec=0.053, cos=-0.009), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[ 600/2000] tot_loss=1.690 (perp=8.145, rec=0.071, cos=-0.009), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.673 (perp=8.145, rec=0.054, cos=-0.009), tot_loss_proj:2.437 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.691 (perp=8.145, rec=0.072, cos=-0.009), tot_loss_proj:2.424 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[ 750/2000] tot_loss=1.686 (perp=8.145, rec=0.067, cos=-0.009), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.676 (perp=8.145, rec=0.056, cos=-0.009), tot_loss_proj:2.430 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=8.145, rec=0.066, cos=-0.009), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[ 900/2000] tot_loss=1.687 (perp=8.145, rec=0.068, cos=-0.009), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.690 (perp=8.145, rec=0.070, cos=-0.009), tot_loss_proj:2.430 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.682 (perp=8.145, rec=0.062, cos=-0.009), tot_loss_proj:2.432 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1050/2000] tot_loss=1.681 (perp=8.145, rec=0.061, cos=-0.009), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=8.145, rec=0.066, cos=-0.009), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.685 (perp=8.145, rec=0.065, cos=-0.009), tot_loss_proj:2.426 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1200/2000] tot_loss=1.695 (perp=8.145, rec=0.075, cos=-0.009), tot_loss_proj:2.432 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.679 (perp=8.145, rec=0.059, cos=-0.009), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=8.145, rec=0.061, cos=-0.009), tot_loss_proj:2.432 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1350/2000] tot_loss=1.687 (perp=8.145, rec=0.067, cos=-0.009), tot_loss_proj:2.433 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.682 (perp=8.145, rec=0.062, cos=-0.009), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.686 (perp=8.145, rec=0.066, cos=-0.009), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1500/2000] tot_loss=1.687 (perp=8.145, rec=0.067, cos=-0.009), tot_loss_proj:2.425 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.690 (perp=8.145, rec=0.070, cos=-0.009), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.696 (perp=8.145, rec=0.077, cos=-0.009), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1650/2000] tot_loss=1.695 (perp=8.145, rec=0.075, cos=-0.009), tot_loss_proj:2.436 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.681 (perp=8.145, rec=0.061, cos=-0.009), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.683 (perp=8.145, rec=0.064, cos=-0.009), tot_loss_proj:2.434 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1800/2000] tot_loss=1.675 (perp=8.145, rec=0.055, cos=-0.009), tot_loss_proj:2.425 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.680 (perp=8.145, rec=0.061, cos=-0.009), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.683 (perp=8.145, rec=0.063, cos=-0.009), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
[1950/2000] tot_loss=1.679 (perp=8.145, rec=0.059, cos=-0.009), tot_loss_proj:2.434 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=8.145, rec=0.062, cos=-0.009), tot_loss_proj:2.423 [t=0.21s]
prediction: ['[CLS] the theater exit [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] the theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 87.965 | p: 87.318 | r: 88.701
rouge2     | fm: 55.073 | p: 54.810 | r: 55.420
rougeL     | fm: 76.748 | p: 76.289 | r: 77.354
rougeLsum  | fm: 76.739 | p: 76.249 | r: 77.239
r1fm+r2fm = 143.038

input #78 time: 0:08:37 | total time: 13:32:34


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
*********************************
*********************************
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.97676020860672 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8503931164741516 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8493977189064026 for ['[CLS]rna into [SEP]']
[Init] best rec loss: 0.8459595441818237 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8386962413787842 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8356737494468689 for ['[CLS] gray should [SEP]']
[Init] best rec loss: 0.8324992060661316 for ['[CLS] comte sculptor [SEP]']
[Init] best perm rec loss: 0.8268929123878479 for ['[CLS] sculptor comte [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.492 (perp=11.428, rec=0.212, cos=-0.006), tot_loss_proj:2.620 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.448 (perp=11.428, rec=0.169, cos=-0.007), tot_loss_proj:2.611 [t=0.26s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.426 (perp=11.428, rec=0.147, cos=-0.007), tot_loss_proj:2.610 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.425 (perp=11.428, rec=0.147, cos=-0.007), tot_loss_proj:2.614 [t=0.25s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.805 (perp=8.695, rec=0.075, cos=-0.009), tot_loss_proj:1.967 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.788 (perp=8.695, rec=0.058, cos=-0.009), tot_loss_proj:1.960 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.803 (perp=8.695, rec=0.073, cos=-0.009), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.790 (perp=8.695, rec=0.060, cos=-0.009), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.799 (perp=8.695, rec=0.069, cos=-0.009), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.802 (perp=8.695, rec=0.072, cos=-0.009), tot_loss_proj:1.963 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.792 (perp=8.695, rec=0.062, cos=-0.009), tot_loss_proj:1.959 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.783 (perp=8.695, rec=0.053, cos=-0.009), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.793 (perp=8.695, rec=0.063, cos=-0.009), tot_loss_proj:1.957 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=8.695, rec=0.072, cos=-0.009), tot_loss_proj:1.962 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.800 (perp=8.695, rec=0.070, cos=-0.009), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.799 (perp=8.695, rec=0.069, cos=-0.009), tot_loss_proj:1.960 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.798 (perp=8.695, rec=0.068, cos=-0.009), tot_loss_proj:1.960 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.799 (perp=8.695, rec=0.069, cos=-0.009), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.695, rec=0.069, cos=-0.009), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.794 (perp=8.695, rec=0.064, cos=-0.009), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.803 (perp=8.695, rec=0.073, cos=-0.009), tot_loss_proj:1.957 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.791 (perp=8.695, rec=0.061, cos=-0.009), tot_loss_proj:1.964 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.796 (perp=8.695, rec=0.066, cos=-0.009), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.797 (perp=8.695, rec=0.067, cos=-0.009), tot_loss_proj:1.971 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.800 (perp=8.695, rec=0.070, cos=-0.009), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.787 (perp=8.695, rec=0.057, cos=-0.009), tot_loss_proj:1.953 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.811 (perp=8.695, rec=0.081, cos=-0.009), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.782 (perp=8.695, rec=0.052, cos=-0.009), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.782 (perp=8.695, rec=0.052, cos=-0.009), tot_loss_proj:1.963 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.795 (perp=8.695, rec=0.065, cos=-0.009), tot_loss_proj:1.953 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.789 (perp=8.695, rec=0.059, cos=-0.009), tot_loss_proj:1.961 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.791 (perp=8.695, rec=0.061, cos=-0.009), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.790 (perp=8.695, rec=0.060, cos=-0.009), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.782 (perp=8.695, rec=0.052, cos=-0.009), tot_loss_proj:1.961 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.782 (perp=8.695, rec=0.052, cos=-0.009), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.801 (perp=8.695, rec=0.071, cos=-0.009), tot_loss_proj:1.959 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.790 (perp=8.695, rec=0.060, cos=-0.009), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=8.695, rec=0.066, cos=-0.009), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.795 (perp=8.695, rec=0.065, cos=-0.009), tot_loss_proj:1.964 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.786 (perp=8.695, rec=0.056, cos=-0.009), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.122 | p: 87.517 | r: 88.853
rouge2     | fm: 54.352 | p: 54.043 | r: 54.679
rougeL     | fm: 76.744 | p: 76.270 | r: 77.341
rougeLsum  | fm: 76.768 | p: 76.302 | r: 77.265
r1fm+r2fm = 142.474

input #79 time: 0:10:54 | total time: 13:43:28


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
*********************************
*********************************
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9617707133293152 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9375922083854675 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9287824034690857 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9259979724884033 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9242680668830872 for ['[CLS] close blonde form parks pussy [SEP]']
[Init] best rec loss: 0.9182730913162231 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9177989959716797 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9138138294219971 for ["[CLS] jubilee'kraft it incense [SEP]"]
[Init] best perm rec loss: 0.913648784160614 for ["[CLS] incense it'jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.9132492542266846 for ["[CLS] kraft jubilee it incense'[SEP]"]
[Init] best perm rec loss: 0.9125822186470032 for ["[CLS] it incense kraft jubilee'[SEP]"]
[Init] best perm rec loss: 0.9123266935348511 for ["[CLS] kraft it'incense jubilee [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.427 (perp=13.282, rec=0.770, cos=0.001), tot_loss_proj:4.225 [t=0.26s]
prediction: ['[CLS] phone mine towardbling nowhere [SEP]']
[ 100/2000] tot_loss=2.765 (perp=10.301, rec=0.678, cos=0.027), tot_loss_proj:3.751 [t=0.26s]
prediction: ['[CLS] greenlter wibling, [SEP]']
[ 150/2000] tot_loss=2.900 (perp=11.249, rec=0.636, cos=0.015), tot_loss_proj:4.044 [t=0.25s]
prediction: ['[CLS]nic rhodes wizen, [SEP]']
[ 200/2000] tot_loss=2.663 (perp=10.386, rec=0.592, cos=-0.006), tot_loss_proj:3.809 [t=0.26s]
prediction: ['[CLS]zen puzzle wizen, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.429 (perp=9.078, rec=0.619, cos=-0.006), tot_loss_proj:3.258 [t=0.25s]
prediction: ['[CLS] blue, wizen puzzle [SEP]']
[ 300/2000] tot_loss=2.378 (perp=9.078, rec=0.571, cos=-0.008), tot_loss_proj:3.234 [t=0.26s]
prediction: ['[CLS] blue, wizen puzzle [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.370 (perp=9.078, rec=0.563, cos=-0.008), tot_loss_proj:3.229 [t=0.26s]
prediction: ['[CLS] blue, wizen puzzle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.451 (perp=9.587, rec=0.542, cos=-0.008), tot_loss_proj:3.404 [t=0.26s]
prediction: ['[CLS]zen, wizen puzzle [SEP]']
[ 450/2000] tot_loss=2.834 (perp=11.241, rec=0.593, cos=-0.007), tot_loss_proj:3.408 [t=0.25s]
prediction: ['[CLS] capable,zenzen puzzle [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.617 (perp=10.315, rec=0.562, cos=-0.008), tot_loss_proj:3.963 [t=0.25s]
prediction: ['[CLS]zen,zenzen homework [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.483 (perp=9.535, rec=0.580, cos=-0.004), tot_loss_proj:3.807 [t=0.26s]
prediction: ['[CLS]zenzenzen. homework [SEP]']
[ 600/2000] tot_loss=2.496 (perp=9.776, rec=0.549, cos=-0.008), tot_loss_proj:3.915 [t=0.25s]
prediction: ['[CLS]zenzenzen. wa [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.590 (perp=10.254, rec=0.548, cos=-0.009), tot_loss_proj:4.019 [t=0.29s]
prediction: ['[CLS]zenzen ; wazen [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.520 (perp=9.883, rec=0.551, cos=-0.007), tot_loss_proj:3.892 [t=0.27s]
prediction: ['[CLS]zenzen wa ;zen [SEP]']
[ 750/2000] tot_loss=2.497 (perp=9.883, rec=0.531, cos=-0.010), tot_loss_proj:3.892 [t=0.27s]
prediction: ['[CLS]zenzen wa ;zen [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.503 (perp=9.883, rec=0.533, cos=-0.007), tot_loss_proj:3.891 [t=0.25s]
prediction: ['[CLS]zenzen wa ;zen [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.490 (perp=9.883, rec=0.522, cos=-0.009), tot_loss_proj:3.886 [t=0.25s]
prediction: ['[CLS]zenzen wa ;zen [SEP]']
[ 900/2000] tot_loss=2.483 (perp=9.883, rec=0.516, cos=-0.010), tot_loss_proj:3.891 [t=0.26s]
prediction: ['[CLS]zenzen wa ;zen [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.586 (perp=10.433, rec=0.510, cos=-0.010), tot_loss_proj:4.023 [t=0.26s]
prediction: ['[CLS]zenzennae ;zen [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.579 (perp=10.254, rec=0.533, cos=-0.006), tot_loss_proj:4.018 [t=0.26s]
prediction: ['[CLS]zenzen ; wazen [SEP]']
[1050/2000] tot_loss=2.879 (perp=11.901, rec=0.508, cos=-0.010), tot_loss_proj:4.341 [t=0.25s]
prediction: ['[CLS]zenzen ; closestzen [SEP]']
Attempt swap
[1100/2000] tot_loss=2.500 (perp=9.980, rec=0.514, cos=-0.010), tot_loss_proj:3.932 [t=0.26s]
prediction: ['[CLS]zenzen ;naezen [SEP]']
Attempt swap
[1150/2000] tot_loss=2.331 (perp=9.142, rec=0.512, cos=-0.010), tot_loss_proj:3.746 [t=0.27s]
prediction: ['[CLS] wizen ;naezen [SEP]']
[1200/2000] tot_loss=2.321 (perp=9.142, rec=0.502, cos=-0.010), tot_loss_proj:3.743 [t=0.27s]
prediction: ['[CLS] wizen ;naezen [SEP]']
Attempt swap
[1250/2000] tot_loss=2.331 (perp=9.142, rec=0.512, cos=-0.010), tot_loss_proj:3.743 [t=0.27s]
prediction: ['[CLS] wizen ;naezen [SEP]']
Attempt swap
[1300/2000] tot_loss=2.330 (perp=9.142, rec=0.511, cos=-0.010), tot_loss_proj:3.745 [t=0.26s]
prediction: ['[CLS] wizen ;naezen [SEP]']
[1350/2000] tot_loss=2.325 (perp=9.142, rec=0.505, cos=-0.009), tot_loss_proj:3.746 [t=0.26s]
prediction: ['[CLS] wizen ;naezen [SEP]']
Attempt swap
[1400/2000] tot_loss=2.315 (perp=9.142, rec=0.496, cos=-0.010), tot_loss_proj:3.750 [t=0.26s]
prediction: ['[CLS] wizen ;naezen [SEP]']
Attempt swap
[1450/2000] tot_loss=2.328 (perp=9.142, rec=0.509, cos=-0.009), tot_loss_proj:3.745 [t=0.26s]
prediction: ['[CLS] wizen ;naezen [SEP]']
[1500/2000] tot_loss=2.431 (perp=9.699, rec=0.501, cos=-0.010), tot_loss_proj:3.811 [t=0.26s]
prediction: ['[CLS] wizen.naezen [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.330 (perp=9.059, rec=0.526, cos=-0.008), tot_loss_proj:3.753 [t=0.26s]
prediction: ['[CLS]zenzennaezen. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.756 (perp=11.141, rec=0.533, cos=-0.004), tot_loss_proj:4.127 [t=0.26s]
prediction: ['[CLS] wizenzen avoiding. [SEP]']
[1650/2000] tot_loss=2.415 (perp=9.531, rec=0.518, cos=-0.010), tot_loss_proj:3.529 [t=0.27s]
prediction: ['[CLS] wizenzen wi. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.436 (perp=9.699, rec=0.505, cos=-0.010), tot_loss_proj:3.805 [t=0.26s]
prediction: ['[CLS] wizen.naezen [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.221 (perp=8.550, rec=0.518, cos=-0.007), tot_loss_proj:3.630 [t=0.27s]
prediction: ['[CLS] wizennaezen. [SEP]']
[1800/2000] tot_loss=2.215 (perp=8.550, rec=0.515, cos=-0.010), tot_loss_proj:3.632 [t=0.26s]
prediction: ['[CLS] wizennaezen. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.214 (perp=8.550, rec=0.514, cos=-0.010), tot_loss_proj:3.625 [t=0.25s]
prediction: ['[CLS] wizennaezen. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.305 (perp=9.059, rec=0.503, cos=-0.010), tot_loss_proj:3.754 [t=0.27s]
prediction: ['[CLS]zenzennaezen. [SEP]']
[1950/2000] tot_loss=2.310 (perp=9.059, rec=0.508, cos=-0.010), tot_loss_proj:3.756 [t=0.27s]
prediction: ['[CLS]zenzennaezen. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.333 (perp=9.135, rec=0.515, cos=-0.009), tot_loss_proj:3.753 [t=0.25s]
prediction: ['[CLS] wizenzennae. [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizen ;naezen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 87.684 | p: 87.089 | r: 88.372
rouge2     | fm: 53.688 | p: 53.446 | r: 53.949
rougeL     | fm: 76.433 | p: 75.936 | r: 76.947
rougeLsum  | fm: 76.356 | p: 75.865 | r: 76.871
r1fm+r2fm = 141.373

input #80 time: 0:10:56 | total time: 13:54:25


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
*********************************
*********************************
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9063941836357117 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.85554039478302 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8432484865188599 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8243643641471863 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8131975531578064 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8085715174674988 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.794321596622467 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.790020227432251 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.7895707488059998 for ['[CLS] ivy proceededplate donaldsondownvik [SEP]']
[Init] best perm rec loss: 0.7880122065544128 for ['[CLS]down ivyvik proceeded donaldsonplate [SEP]']
[Init] best perm rec loss: 0.786943256855011 for ['[CLS] ivy donaldson proceededvikplatedown [SEP]']
[Init] best perm rec loss: 0.7865198850631714 for ['[CLS]vik ivy donaldsondown proceededplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.715 (perp=11.134, rec=0.488, cos=-0.000), tot_loss_proj:3.325 [t=0.26s]
prediction: ['[CLS] t suffered ineffective rate sickms [SEP]']
[ 100/2000] tot_loss=2.813 (perp=12.179, rec=0.383, cos=-0.006), tot_loss_proj:3.412 [t=0.26s]
prediction: ['[CLS] mikhail suffered poorly rate player products [SEP]']
[ 150/2000] tot_loss=2.584 (perp=11.405, rec=0.310, cos=-0.007), tot_loss_proj:3.229 [t=0.25s]
prediction: ['[CLS] sent scores poorly player not best [SEP]']
[ 200/2000] tot_loss=1.987 (perp=8.875, rec=0.220, cos=-0.008), tot_loss_proj:2.676 [t=0.26s]
prediction: ['[CLS] z is his player not best [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.841 (perp=8.054, rec=0.233, cos=-0.003), tot_loss_proj:2.642 [t=0.27s]
prediction: ['[CLS] item is not not best player [SEP]']
[ 300/2000] tot_loss=2.049 (perp=9.360, rec=0.185, cos=-0.008), tot_loss_proj:2.842 [t=0.26s]
prediction: ['[CLS] greg is not not most player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.965 (perp=9.012, rec=0.171, cos=-0.008), tot_loss_proj:3.228 [t=0.25s]
prediction: ['[CLS] not most participates is not player [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.168 (perp=10.087, rec=0.159, cos=-0.008), tot_loss_proj:3.019 [t=0.26s]
prediction: ['[CLS] not items most is his player [SEP]']
[ 450/2000] tot_loss=2.161 (perp=10.087, rec=0.152, cos=-0.009), tot_loss_proj:3.019 [t=0.25s]
prediction: ['[CLS] not items most is his player [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.632 (perp=7.540, rec=0.133, cos=-0.009), tot_loss_proj:2.609 [t=0.25s]
prediction: ['[CLS] not items most the player is [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.721 (perp=8.031, rec=0.124, cos=-0.009), tot_loss_proj:3.189 [t=0.28s]
prediction: ['[CLS] not most inexperienced the player is [SEP]']
[ 600/2000] tot_loss=1.661 (perp=7.796, rec=0.111, cos=-0.009), tot_loss_proj:2.225 [t=0.27s]
prediction: ['[CLS] not most impressive the player is [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.446 (perp=6.674, rec=0.121, cos=-0.009), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.438 (perp=6.674, rec=0.112, cos=-0.009), tot_loss_proj:1.972 [t=0.27s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.674, rec=0.116, cos=-0.009), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.427 (perp=6.674, rec=0.101, cos=-0.009), tot_loss_proj:1.983 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.427 (perp=6.674, rec=0.102, cos=-0.010), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[ 900/2000] tot_loss=1.415 (perp=6.674, rec=0.090, cos=-0.010), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.410 (perp=6.674, rec=0.085, cos=-0.010), tot_loss_proj:1.977 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.412 (perp=6.674, rec=0.087, cos=-0.010), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1050/2000] tot_loss=1.417 (perp=6.674, rec=0.092, cos=-0.010), tot_loss_proj:1.981 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.404 (perp=6.674, rec=0.079, cos=-0.010), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.405 (perp=6.674, rec=0.080, cos=-0.010), tot_loss_proj:1.977 [t=0.27s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1200/2000] tot_loss=1.406 (perp=6.674, rec=0.081, cos=-0.010), tot_loss_proj:1.977 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.404 (perp=6.674, rec=0.079, cos=-0.010), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.391 (perp=6.674, rec=0.066, cos=-0.010), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1350/2000] tot_loss=1.398 (perp=6.674, rec=0.073, cos=-0.010), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.400 (perp=6.674, rec=0.075, cos=-0.010), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.396 (perp=6.674, rec=0.070, cos=-0.010), tot_loss_proj:1.979 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1500/2000] tot_loss=1.399 (perp=6.674, rec=0.074, cos=-0.010), tot_loss_proj:1.982 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.398 (perp=6.674, rec=0.072, cos=-0.010), tot_loss_proj:1.976 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.388 (perp=6.674, rec=0.063, cos=-0.010), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1650/2000] tot_loss=1.389 (perp=6.674, rec=0.064, cos=-0.010), tot_loss_proj:1.974 [t=0.27s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.400 (perp=6.674, rec=0.075, cos=-0.010), tot_loss_proj:1.976 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.403 (perp=6.674, rec=0.078, cos=-0.010), tot_loss_proj:1.978 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1800/2000] tot_loss=1.394 (perp=6.674, rec=0.069, cos=-0.010), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.400 (perp=6.674, rec=0.074, cos=-0.010), tot_loss_proj:1.978 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.401 (perp=6.674, rec=0.076, cos=-0.010), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1950/2000] tot_loss=1.404 (perp=6.674, rec=0.079, cos=-0.010), tot_loss_proj:1.979 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.674, rec=0.070, cos=-0.010), tot_loss_proj:1.985 [t=0.26s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] not most impressive is the player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 87.662 | p: 87.084 | r: 88.359
rouge2     | fm: 53.392 | p: 53.179 | r: 53.657
rougeL     | fm: 76.284 | p: 75.842 | r: 76.801
rougeLsum  | fm: 76.355 | p: 75.900 | r: 76.900
r1fm+r2fm = 141.054

input #81 time: 0:11:04 | total time: 14:05:30


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
*********************************
*********************************
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.98771733045578 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9761659502983093 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9474851489067078 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9335925579071045 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9326500296592712 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8672366738319397 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8271898627281189 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8216337561607361 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8212171196937561 for ['[CLS]basket plumage whoeverach respective role recordfur [SEP]']
[Init] best perm rec loss: 0.8198072910308838 for ['[CLS] respectivebasket record plumagefurach role whoever [SEP]']
[Init] best perm rec loss: 0.819161593914032 for ['[CLS] respectiveach whoeverfur role record plumagebasket [SEP]']
[Init] best perm rec loss: 0.81831294298172 for ['[CLS]fur respective rolebasketach plumage whoever record [SEP]']
[Init] best perm rec loss: 0.8175076842308044 for ['[CLS] whoeverbasket role respective plumagefurach record [SEP]']
[Init] best perm rec loss: 0.8163747787475586 for ['[CLS]furbasket respective roleach plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.728 (perp=12.284, rec=0.279, cos=-0.007), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] wasted undone mates shows undone timing unanimous [SEP]']
[ 100/2000] tot_loss=2.399 (perp=11.136, rec=0.180, cos=-0.009), tot_loss_proj:2.894 [t=0.26s]
prediction: ['[CLS] undone undone itses by undone script it [SEP]']
[ 150/2000] tot_loss=2.251 (perp=10.693, rec=0.121, cos=-0.009), tot_loss_proj:2.743 [t=0.25s]
prediction: ['[CLS] undone undone s s by undone script it [SEP]']
[ 200/2000] tot_loss=2.305 (perp=11.081, rec=0.098, cos=-0.009), tot_loss_proj:2.836 [t=0.25s]
prediction: ['[CLS] undone sloppy a s by undone script it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.988 (perp=9.527, rec=0.092, cos=-0.009), tot_loss_proj:2.238 [t=0.27s]
prediction: ['[CLS] undone by a s sloppy undone script it [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.527, rec=0.075, cos=-0.009), tot_loss_proj:2.236 [t=0.26s]
prediction: ['[CLS] undone by a s sloppy undone script it [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.764 (perp=8.519, rec=0.070, cos=-0.009), tot_loss_proj:2.125 [t=0.25s]
prediction: ['[CLS] undone by a s sloppy script undone it [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.650 (perp=7.872, rec=0.085, cos=-0.009), tot_loss_proj:2.007 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 450/2000] tot_loss=1.638 (perp=7.872, rec=0.074, cos=-0.009), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.639 (perp=7.872, rec=0.074, cos=-0.009), tot_loss_proj:2.006 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.638 (perp=7.872, rec=0.073, cos=-0.009), tot_loss_proj:2.010 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 600/2000] tot_loss=1.633 (perp=7.872, rec=0.068, cos=-0.009), tot_loss_proj:2.019 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.631 (perp=7.872, rec=0.066, cos=-0.009), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.638 (perp=7.872, rec=0.073, cos=-0.009), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 750/2000] tot_loss=1.636 (perp=7.872, rec=0.071, cos=-0.009), tot_loss_proj:2.019 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.633 (perp=7.872, rec=0.068, cos=-0.009), tot_loss_proj:2.017 [t=0.27s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.623 (perp=7.872, rec=0.059, cos=-0.009), tot_loss_proj:2.015 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[ 900/2000] tot_loss=1.632 (perp=7.872, rec=0.067, cos=-0.009), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.627 (perp=7.872, rec=0.062, cos=-0.009), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1000/2000] tot_loss=1.633 (perp=7.872, rec=0.068, cos=-0.009), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1050/2000] tot_loss=1.630 (perp=7.872, rec=0.065, cos=-0.009), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1100/2000] tot_loss=1.630 (perp=7.872, rec=0.065, cos=-0.009), tot_loss_proj:2.016 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1150/2000] tot_loss=1.633 (perp=7.872, rec=0.068, cos=-0.009), tot_loss_proj:2.015 [t=0.27s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1200/2000] tot_loss=1.623 (perp=7.872, rec=0.058, cos=-0.009), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1250/2000] tot_loss=1.627 (perp=7.872, rec=0.062, cos=-0.009), tot_loss_proj:2.014 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1300/2000] tot_loss=1.637 (perp=7.872, rec=0.072, cos=-0.009), tot_loss_proj:2.014 [t=0.27s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1350/2000] tot_loss=1.627 (perp=7.872, rec=0.062, cos=-0.009), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1400/2000] tot_loss=1.628 (perp=7.872, rec=0.063, cos=-0.009), tot_loss_proj:2.012 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.625 (perp=7.872, rec=0.060, cos=-0.009), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1500/2000] tot_loss=1.628 (perp=7.872, rec=0.063, cos=-0.009), tot_loss_proj:2.011 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1550/2000] tot_loss=1.626 (perp=7.872, rec=0.061, cos=-0.009), tot_loss_proj:2.021 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.633 (perp=7.872, rec=0.068, cos=-0.009), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1650/2000] tot_loss=1.630 (perp=7.872, rec=0.065, cos=-0.009), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.631 (perp=7.872, rec=0.066, cos=-0.009), tot_loss_proj:2.012 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1750/2000] tot_loss=1.625 (perp=7.872, rec=0.060, cos=-0.009), tot_loss_proj:2.021 [t=0.27s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1800/2000] tot_loss=1.626 (perp=7.872, rec=0.062, cos=-0.009), tot_loss_proj:2.023 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.632 (perp=7.872, rec=0.067, cos=-0.009), tot_loss_proj:2.018 [t=0.27s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.633 (perp=7.872, rec=0.068, cos=-0.009), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
[1950/2000] tot_loss=1.629 (perp=7.872, rec=0.064, cos=-0.009), tot_loss_proj:2.013 [t=0.25s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.628 (perp=7.872, rec=0.063, cos=-0.009), tot_loss_proj:2.025 [t=0.26s]
prediction: ['[CLS] s undone by a sloppy script undone it [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] s undone by a sloppy script undone it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 87.776 | p: 87.113 | r: 88.530
rouge2     | fm: 53.391 | p: 53.118 | r: 53.747
rougeL     | fm: 76.459 | p: 75.925 | r: 77.058
rougeLsum  | fm: 76.480 | p: 76.006 | r: 77.042
r1fm+r2fm = 141.167

input #82 time: 0:10:58 | total time: 14:16:28


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
*********************************
*********************************
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9601501822471619 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9566210508346558 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9550451636314392 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9463936686515808 for ['[CLS] singles bradown entering barcelona el turnÂ® rowan courtney [SEP]']
[Init] best rec loss: 0.887312650680542 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8696892261505127 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8692896366119385 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8648756146430969 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8604941964149475 for ['[CLS] Â£ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8593842387199402 for ['[CLS] ut sighed another tex predicted hooper alsoÐ¾Ð² toes personally [SEP]']
[Init] best rec loss: 0.8368008732795715 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8151112198829651 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8039038181304932 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8021044135093689 for ['[CLS] vice neck pitch comprehensive stew follows boys nearly residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.802 (perp=12.006, rec=0.394, cos=0.007), tot_loss_proj:3.435 [t=0.28s]
prediction: ['[CLS] develop pretty becoming the captain doctor region paradise desmond parliament [SEP]']
[ 100/2000] tot_loss=2.315 (perp=10.208, rec=0.281, cos=-0.007), tot_loss_proj:3.183 [t=0.27s]
prediction: ['[CLS] know about growing the young writer became grown know inherited [SEP]']
[ 150/2000] tot_loss=2.232 (perp=9.956, rec=0.248, cos=-0.008), tot_loss_proj:3.333 [t=0.29s]
prediction: ['[CLS] know when growing when being gets when grown soon grows [SEP]']
[ 200/2000] tot_loss=2.089 (perp=9.600, rec=0.178, cos=-0.009), tot_loss_proj:2.912 [t=0.28s]
prediction: ['[CLS] know get what when it wants grows grows soon grows [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.739 (perp=7.907, rec=0.166, cos=-0.008), tot_loss_proj:2.347 [t=0.28s]
prediction: ['[CLS] know what grow when it wants grows what soon grows [SEP]']
[ 300/2000] tot_loss=1.634 (perp=7.586, rec=0.126, cos=-0.009), tot_loss_proj:2.459 [t=0.28s]
prediction: ['[CLS] know what is when it wants grows what soon becomes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.964 (perp=9.231, rec=0.127, cos=-0.009), tot_loss_proj:2.619 [t=0.28s]
prediction: ['[CLS] know what grows when it wants be be know becomes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.806 (perp=8.515, rec=0.112, cos=-0.009), tot_loss_proj:2.262 [t=0.30s]
prediction: ['[CLS] know what grows when it wants be becomes up be [SEP]']
[ 450/2000] tot_loss=1.793 (perp=8.545, rec=0.093, cos=-0.009), tot_loss_proj:2.322 [t=0.30s]
prediction: ['[CLS] know what grows when it wants be up up be [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.667 (perp=7.952, rec=0.086, cos=-0.009), tot_loss_proj:2.255 [t=0.28s]
prediction: ['[CLS] know what grows when it wants be up be up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.549 (perp=7.357, rec=0.087, cos=-0.009), tot_loss_proj:1.964 [t=0.28s]
prediction: ['[CLS] know what grows when it wants to up be up [SEP]']
[ 600/2000] tot_loss=1.539 (perp=7.357, rec=0.077, cos=-0.009), tot_loss_proj:1.957 [t=0.30s]
prediction: ['[CLS] know what grows when it wants to up be up [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.333 (perp=6.311, rec=0.080, cos=-0.009), tot_loss_proj:1.767 [t=0.29s]
prediction: ['[CLS] know what grows when it wants to be up up [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.212 (perp=5.727, rec=0.076, cos=-0.009), tot_loss_proj:1.569 [t=0.30s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[ 750/2000] tot_loss=1.210 (perp=5.727, rec=0.074, cos=-0.009), tot_loss_proj:1.574 [t=0.29s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.214 (perp=5.727, rec=0.078, cos=-0.009), tot_loss_proj:1.574 [t=0.30s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.214 (perp=5.727, rec=0.078, cos=-0.009), tot_loss_proj:1.568 [t=0.30s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[ 900/2000] tot_loss=1.214 (perp=5.727, rec=0.078, cos=-0.009), tot_loss_proj:1.568 [t=0.30s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.208 (perp=5.727, rec=0.072, cos=-0.009), tot_loss_proj:1.573 [t=0.30s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.200 (perp=5.727, rec=0.064, cos=-0.009), tot_loss_proj:1.580 [t=0.29s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1050/2000] tot_loss=1.208 (perp=5.727, rec=0.072, cos=-0.009), tot_loss_proj:1.565 [t=0.29s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.218 (perp=5.727, rec=0.081, cos=-0.009), tot_loss_proj:1.569 [t=0.26s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.206 (perp=5.727, rec=0.070, cos=-0.009), tot_loss_proj:1.576 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1200/2000] tot_loss=1.214 (perp=5.727, rec=0.077, cos=-0.009), tot_loss_proj:1.571 [t=0.28s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.204 (perp=5.727, rec=0.068, cos=-0.009), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.198 (perp=5.727, rec=0.062, cos=-0.009), tot_loss_proj:1.576 [t=0.27s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1350/2000] tot_loss=1.220 (perp=5.727, rec=0.084, cos=-0.009), tot_loss_proj:1.575 [t=0.27s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.217 (perp=5.727, rec=0.081, cos=-0.009), tot_loss_proj:1.573 [t=0.27s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.205 (perp=5.727, rec=0.069, cos=-0.009), tot_loss_proj:1.568 [t=0.27s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1500/2000] tot_loss=1.212 (perp=5.727, rec=0.076, cos=-0.009), tot_loss_proj:1.569 [t=0.26s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.209 (perp=5.727, rec=0.073, cos=-0.009), tot_loss_proj:1.573 [t=0.26s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.209 (perp=5.727, rec=0.073, cos=-0.009), tot_loss_proj:1.572 [t=0.26s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1650/2000] tot_loss=1.207 (perp=5.727, rec=0.071, cos=-0.009), tot_loss_proj:1.570 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.211 (perp=5.727, rec=0.075, cos=-0.009), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.204 (perp=5.727, rec=0.068, cos=-0.009), tot_loss_proj:1.569 [t=0.26s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1800/2000] tot_loss=1.206 (perp=5.727, rec=0.070, cos=-0.009), tot_loss_proj:1.574 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.211 (perp=5.727, rec=0.075, cos=-0.009), tot_loss_proj:1.574 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.206 (perp=5.727, rec=0.070, cos=-0.009), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
[1950/2000] tot_loss=1.204 (perp=5.727, rec=0.068, cos=-0.009), tot_loss_proj:1.565 [t=0.25s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.200 (perp=5.727, rec=0.064, cos=-0.009), tot_loss_proj:1.578 [t=0.26s]
prediction: ['[CLS] know what grows up when it wants to be up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what grows up when it wants to be up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 87.948 | p: 87.309 | r: 88.678
rouge2     | fm: 53.494 | p: 53.185 | r: 53.859
rougeL     | fm: 76.443 | p: 75.965 | r: 76.988
rougeLsum  | fm: 76.408 | p: 75.939 | r: 76.982
r1fm+r2fm = 141.441

input #83 time: 0:11:16 | total time: 14:27:45


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
*********************************
*********************************
average of cosine similarity 0.9991125724774639
highest_index [0]
highest [0.9991125724774639]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9286046624183655 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9211990833282471 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.8995694518089294 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8926138281822205 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8923629522323608 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8866891264915466 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8839888572692871 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8611317276954651 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best perm rec loss: 0.8604739904403687 for ['[CLS] sar block is whetherness project dark [SEP]']
[Init] best perm rec loss: 0.8604679703712463 for ['[CLS] block dark sar whether isness project [SEP]']
[Init] best perm rec loss: 0.85843825340271 for ['[CLS] whether sar project block is darkness [SEP]']
[Init] best perm rec loss: 0.8576532006263733 for ['[CLS] whether is block projectness dark sar [SEP]']
[Init] best perm rec loss: 0.8570180535316467 for ['[CLS] sar block project dark is whetherness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.704, rec=0.375, cos=-0.006), tot_loss_proj:3.502 [t=0.27s]
prediction: ['[CLS] pair lostinkles shape hang off lost [SEP]']
[ 100/2000] tot_loss=2.051 (perp=9.036, rec=0.248, cos=-0.005), tot_loss_proj:2.417 [t=0.26s]
prediction: ['[CLS] people lost people think ability to lost [SEP]']
[ 150/2000] tot_loss=1.928 (perp=9.022, rec=0.132, cos=-0.008), tot_loss_proj:2.441 [t=0.25s]
prediction: ['[CLS] people lost people think ability have lost [SEP]']
[ 200/2000] tot_loss=1.895 (perp=9.022, rec=0.099, cos=-0.009), tot_loss_proj:2.471 [t=0.26s]
prediction: ['[CLS] people lost people think ability have lost [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.615 (perp=7.657, rec=0.092, cos=-0.008), tot_loss_proj:2.235 [t=0.25s]
prediction: ['[CLS] people lost ability think people have lost [SEP]']
[ 300/2000] tot_loss=1.619 (perp=7.657, rec=0.096, cos=-0.009), tot_loss_proj:2.238 [t=0.26s]
prediction: ['[CLS] people lost ability think people have lost [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.758 (perp=8.399, rec=0.087, cos=-0.009), tot_loss_proj:2.349 [t=0.27s]
prediction: ['[CLS] people lost ability think to have lost [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.799 (perp=8.597, rec=0.088, cos=-0.009), tot_loss_proj:2.378 [t=0.25s]
prediction: ['[CLS] lost ability people think the have lost [SEP]']
[ 450/2000] tot_loss=1.789 (perp=8.597, rec=0.079, cos=-0.009), tot_loss_proj:2.385 [t=0.25s]
prediction: ['[CLS] lost ability people think the have lost [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.555 (perp=7.342, rec=0.096, cos=-0.009), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.534 (perp=7.342, rec=0.075, cos=-0.009), tot_loss_proj:2.071 [t=0.27s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[ 600/2000] tot_loss=1.528 (perp=7.342, rec=0.069, cos=-0.009), tot_loss_proj:2.078 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.539 (perp=7.342, rec=0.080, cos=-0.009), tot_loss_proj:2.080 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.536 (perp=7.342, rec=0.077, cos=-0.009), tot_loss_proj:2.078 [t=0.27s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[ 750/2000] tot_loss=1.539 (perp=7.342, rec=0.080, cos=-0.009), tot_loss_proj:2.074 [t=0.27s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.544 (perp=7.342, rec=0.084, cos=-0.009), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.542 (perp=7.342, rec=0.082, cos=-0.009), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[ 900/2000] tot_loss=1.544 (perp=7.342, rec=0.084, cos=-0.009), tot_loss_proj:2.083 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.543 (perp=7.342, rec=0.084, cos=-0.009), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1000/2000] tot_loss=1.530 (perp=7.342, rec=0.071, cos=-0.009), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1050/2000] tot_loss=1.535 (perp=7.342, rec=0.076, cos=-0.009), tot_loss_proj:2.081 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1100/2000] tot_loss=1.521 (perp=7.342, rec=0.062, cos=-0.009), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1150/2000] tot_loss=1.545 (perp=7.342, rec=0.086, cos=-0.009), tot_loss_proj:2.082 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1200/2000] tot_loss=1.530 (perp=7.342, rec=0.071, cos=-0.009), tot_loss_proj:2.076 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1250/2000] tot_loss=1.524 (perp=7.342, rec=0.065, cos=-0.009), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1300/2000] tot_loss=1.540 (perp=7.342, rec=0.081, cos=-0.009), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1350/2000] tot_loss=1.537 (perp=7.342, rec=0.078, cos=-0.009), tot_loss_proj:2.079 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1400/2000] tot_loss=1.534 (perp=7.342, rec=0.075, cos=-0.009), tot_loss_proj:2.080 [t=0.28s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1450/2000] tot_loss=1.551 (perp=7.342, rec=0.092, cos=-0.009), tot_loss_proj:2.076 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1500/2000] tot_loss=1.528 (perp=7.342, rec=0.069, cos=-0.009), tot_loss_proj:2.075 [t=0.25s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1550/2000] tot_loss=1.542 (perp=7.342, rec=0.083, cos=-0.009), tot_loss_proj:2.081 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1600/2000] tot_loss=1.525 (perp=7.342, rec=0.065, cos=-0.009), tot_loss_proj:2.083 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1650/2000] tot_loss=1.534 (perp=7.342, rec=0.075, cos=-0.009), tot_loss_proj:2.069 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1700/2000] tot_loss=1.537 (perp=7.342, rec=0.078, cos=-0.009), tot_loss_proj:2.074 [t=0.27s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1750/2000] tot_loss=1.527 (perp=7.342, rec=0.068, cos=-0.009), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1800/2000] tot_loss=1.543 (perp=7.342, rec=0.084, cos=-0.009), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1850/2000] tot_loss=1.537 (perp=7.342, rec=0.078, cos=-0.009), tot_loss_proj:2.075 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[1900/2000] tot_loss=1.538 (perp=7.342, rec=0.078, cos=-0.009), tot_loss_proj:2.078 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
[1950/2000] tot_loss=1.532 (perp=7.342, rec=0.073, cos=-0.009), tot_loss_proj:2.077 [t=0.27s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Attempt swap
[2000/2000] tot_loss=1.527 (perp=7.342, rec=0.067, cos=-0.009), tot_loss_proj:2.080 [t=0.26s]
prediction: ['[CLS] the lost ability people think have lost [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] the lost ability people think have lost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 101.389

[Aggregate metrics]:
rouge1     | fm: 87.964 | p: 87.346 | r: 88.676
rouge2     | fm: 53.139 | p: 52.829 | r: 53.432
rougeL     | fm: 76.119 | p: 75.619 | r: 76.707
rougeLsum  | fm: 76.162 | p: 75.718 | r: 76.714
r1fm+r2fm = 141.104

input #84 time: 0:11:03 | total time: 14:38:49


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
*********************************
*********************************
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9699996709823608 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9557927250862122 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.933201789855957 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8898030519485474 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8735714554786682 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8669417500495911 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8647000193595886 for ['[CLS]lein laps roadrman indian background indiesthing defender fallen [SEP]']
[Init] best perm rec loss: 0.8642165064811707 for ['[CLS]rmanlein indies lapsthing fallen defender background road indian [SEP]']
[Init] best perm rec loss: 0.8628117442131042 for ['[CLS] indiesleinthing lapsrman indian defender background fallen road [SEP]']
[Init] best perm rec loss: 0.8601159453392029 for ['[CLS] indieslein fallen road background laps indianthing defenderrman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.708 (perp=11.460, rec=0.422, cos=-0.006), tot_loss_proj:3.083 [t=0.25s]
prediction: ['[CLS] maria junk extremelyiful parts least valuable unfortunately, unfortunately [SEP]']
[ 100/2000] tot_loss=2.215 (perp=9.623, rec=0.299, cos=-0.008), tot_loss_proj:2.694 [t=0.26s]
prediction: ['[CLS] unfortunately un alsoiful little not good unfortunately, unfortunately [SEP]']
[ 150/2000] tot_loss=1.943 (perp=8.766, rec=0.199, cos=-0.009), tot_loss_proj:2.423 [t=0.26s]
prediction: ['[CLS] unfortunately un also extremely not also good unfortunately, unfortunately [SEP]']
[ 200/2000] tot_loss=1.502 (perp=6.813, rec=0.147, cos=-0.008), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] unfortunately is also extremely not very good unfortunately. unfortunately [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.514 (perp=7.019, rec=0.119, cos=-0.009), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] unfortunately it also extremely not very good unfortunately. unfortunately [SEP]']
[ 300/2000] tot_loss=1.607 (perp=7.587, rec=0.099, cos=-0.009), tot_loss_proj:2.033 [t=0.26s]
prediction: ['[CLS] unfortunately s also not not very good unfortunately. unfortunately [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.479 (perp=6.963, rec=0.095, cos=-0.009), tot_loss_proj:1.919 [t=0.25s]
prediction: ['[CLS] unfortunately also s not not very good unfortunately. unfortunately [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.559 (perp=7.297, rec=0.108, cos=-0.009), tot_loss_proj:2.004 [t=0.25s]
prediction: ['[CLS] unfortunately also s not not very good unfortunately unfortunately, [SEP]']
[ 450/2000] tot_loss=1.453 (perp=6.855, rec=0.091, cos=-0.009), tot_loss_proj:1.940 [t=0.25s]
prediction: ['[CLS] unfortunately also s not not very good unfortunately unfortunately. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.459 (perp=6.855, rec=0.097, cos=-0.009), tot_loss_proj:1.936 [t=0.26s]
prediction: ['[CLS] unfortunately also s not not very good unfortunately unfortunately. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.855, rec=0.082, cos=-0.009), tot_loss_proj:1.935 [t=0.25s]
prediction: ['[CLS] unfortunately also s not not very good unfortunately unfortunately. [SEP]']
[ 600/2000] tot_loss=1.701 (perp=8.143, rec=0.082, cos=-0.009), tot_loss_proj:2.213 [t=0.34s]
prediction: ['[CLS]stream also s not not very good unfortunately unfortunately. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=8.143, rec=0.076, cos=-0.009), tot_loss_proj:2.209 [t=0.25s]
prediction: ['[CLS]stream also s not not very good unfortunately unfortunately. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.607 (perp=7.660, rec=0.084, cos=-0.009), tot_loss_proj:3.469 [t=0.25s]
prediction: ['[CLS]stream also s, not very good not unfortunately. [SEP]']
[ 750/2000] tot_loss=1.611 (perp=7.660, rec=0.089, cos=-0.009), tot_loss_proj:3.469 [t=0.25s]
prediction: ['[CLS]stream also s, not very good not unfortunately. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.449 (perp=6.844, rec=0.089, cos=-0.009), tot_loss_proj:2.073 [t=0.26s]
prediction: ['[CLS]stream also s not not very good, unfortunately. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.851 (perp=7.757, rec=0.290, cos=0.009), tot_loss_proj:2.210 [t=0.27s]
prediction: ['[CLS] hormone also s not very good, unfortunately entirely. [SEP]']
[ 900/2000] tot_loss=1.612 (perp=7.150, rec=0.185, cos=-0.003), tot_loss_proj:2.076 [t=0.27s]
prediction: ['[CLS] hormone also s not very good, unfortunately not. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.536 (perp=6.817, rec=0.177, cos=-0.004), tot_loss_proj:2.137 [t=0.25s]
prediction: ['[CLS] also s not hormone very good, unfortunately not. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.453 (perp=6.413, rec=0.175, cos=-0.005), tot_loss_proj:2.031 [t=0.25s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
[1050/2000] tot_loss=1.423 (perp=6.413, rec=0.147, cos=-0.006), tot_loss_proj:1.973 [t=0.25s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.418 (perp=6.413, rec=0.141, cos=-0.006), tot_loss_proj:1.941 [t=0.25s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.418 (perp=6.413, rec=0.142, cos=-0.007), tot_loss_proj:1.916 [t=0.26s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
[1200/2000] tot_loss=1.405 (perp=6.413, rec=0.130, cos=-0.007), tot_loss_proj:1.912 [t=0.26s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.405 (perp=6.433, rec=0.126, cos=-0.007), tot_loss_proj:1.849 [t=0.26s]
prediction: ['[CLS] s also not very good, unfortunately not hormone. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.416 (perp=6.413, rec=0.140, cos=-0.007), tot_loss_proj:1.900 [t=0.26s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
[1350/2000] tot_loss=1.401 (perp=6.413, rec=0.125, cos=-0.007), tot_loss_proj:1.885 [t=0.25s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.413, rec=0.119, cos=-0.007), tot_loss_proj:1.888 [t=0.27s]
prediction: ['[CLS] also s not very good, unfortunately not hormone. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.406 (perp=6.433, rec=0.127, cos=-0.007), tot_loss_proj:1.847 [t=0.26s]
prediction: ['[CLS] s also not very good, unfortunately not hormone. [SEP]']
[1500/2000] tot_loss=1.408 (perp=6.433, rec=0.129, cos=-0.007), tot_loss_proj:1.843 [t=0.26s]
prediction: ['[CLS] s also not very good, unfortunately not hormone. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.342 (perp=6.054, rec=0.139, cos=-0.007), tot_loss_proj:1.815 [t=0.26s]
prediction: ['[CLS] also s not very good, unfortunately not fictional. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.329 (perp=6.054, rec=0.126, cos=-0.008), tot_loss_proj:1.809 [t=0.25s]
prediction: ['[CLS] also s not very good, unfortunately not fictional. [SEP]']
[1650/2000] tot_loss=1.325 (perp=6.054, rec=0.122, cos=-0.008), tot_loss_proj:1.821 [t=0.26s]
prediction: ['[CLS] also s not very good, unfortunately not fictional. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.318 (perp=6.014, rec=0.122, cos=-0.008), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] s also not very good, unfortunately not fictional. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.318 (perp=6.014, rec=0.123, cos=-0.008), tot_loss_proj:1.707 [t=0.27s]
prediction: ['[CLS] s also not very good, unfortunately not fictional. [SEP]']
[1800/2000] tot_loss=1.327 (perp=6.014, rec=0.132, cos=-0.008), tot_loss_proj:1.718 [t=0.25s]
prediction: ['[CLS] s also not very good, unfortunately not fictional. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.312 (perp=6.014, rec=0.117, cos=-0.008), tot_loss_proj:1.714 [t=0.26s]
prediction: ['[CLS] s also not very good, unfortunately not fictional. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.281 (perp=5.825, rec=0.123, cos=-0.007), tot_loss_proj:1.723 [t=0.27s]
prediction: ['[CLS] s not very good also, unfortunately not fictional. [SEP]']
[1950/2000] tot_loss=1.279 (perp=5.825, rec=0.122, cos=-0.007), tot_loss_proj:1.719 [t=0.25s]
prediction: ['[CLS] s not very good also, unfortunately not fictional. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.281 (perp=5.825, rec=0.123, cos=-0.008), tot_loss_proj:1.721 [t=0.26s]
prediction: ['[CLS] s not very good also, unfortunately not fictional. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS]stream also s not not very good, unfortunately. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 23.529 | p: 22.222 | r: 25.000
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 107.740

[Aggregate metrics]:
rouge1     | fm: 87.924 | p: 87.220 | r: 88.673
rouge2     | fm: 52.604 | p: 52.309 | r: 52.926
rougeL     | fm: 76.064 | p: 75.560 | r: 76.667
rougeLsum  | fm: 76.041 | p: 75.567 | r: 76.604
r1fm+r2fm = 140.528

input #85 time: 0:10:58 | total time: 14:49:47


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
*********************************
*********************************
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9209051132202148 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9168149828910828 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8586238026618958 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7911268472671509 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7695991396903992 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7565065622329712 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7532469630241394 for ['[CLS] alright round liberated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.437 (perp=5.953, rec=0.252, cos=-0.005), tot_loss_proj:1.388 [t=0.26s]
prediction: ['[CLS] clarity and clarity [SEP]']
[ 100/2000] tot_loss=2.197 (perp=10.257, rec=0.154, cos=-0.008), tot_loss_proj:2.397 [t=0.26s]
prediction: ['[CLS] clarity emotional emotional [SEP]']
[ 150/2000] tot_loss=1.743 (perp=8.317, rec=0.088, cos=-0.009), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 200/2000] tot_loss=1.731 (perp=8.317, rec=0.077, cos=-0.009), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.724 (perp=8.317, rec=0.070, cos=-0.009), tot_loss_proj:1.735 [t=0.27s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 300/2000] tot_loss=1.723 (perp=8.317, rec=0.068, cos=-0.009), tot_loss_proj:1.736 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.713 (perp=8.317, rec=0.058, cos=-0.009), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.718 (perp=8.317, rec=0.064, cos=-0.009), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 450/2000] tot_loss=1.717 (perp=8.317, rec=0.063, cos=-0.009), tot_loss_proj:1.738 [t=0.27s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.726 (perp=8.317, rec=0.072, cos=-0.009), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.719 (perp=8.317, rec=0.064, cos=-0.009), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 600/2000] tot_loss=1.720 (perp=8.317, rec=0.066, cos=-0.009), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.718 (perp=8.317, rec=0.064, cos=-0.009), tot_loss_proj:1.734 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.719 (perp=8.317, rec=0.064, cos=-0.009), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 750/2000] tot_loss=1.718 (perp=8.317, rec=0.064, cos=-0.009), tot_loss_proj:1.733 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.713 (perp=8.317, rec=0.058, cos=-0.009), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.723 (perp=8.317, rec=0.069, cos=-0.009), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 900/2000] tot_loss=1.720 (perp=8.317, rec=0.066, cos=-0.009), tot_loss_proj:1.734 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.719 (perp=8.317, rec=0.065, cos=-0.009), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1000/2000] tot_loss=1.717 (perp=8.317, rec=0.063, cos=-0.009), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1050/2000] tot_loss=1.711 (perp=8.317, rec=0.056, cos=-0.009), tot_loss_proj:1.731 [t=0.27s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1100/2000] tot_loss=1.729 (perp=8.317, rec=0.074, cos=-0.009), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1150/2000] tot_loss=1.720 (perp=8.317, rec=0.066, cos=-0.009), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1200/2000] tot_loss=1.711 (perp=8.317, rec=0.056, cos=-0.009), tot_loss_proj:1.734 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1250/2000] tot_loss=1.724 (perp=8.317, rec=0.070, cos=-0.009), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1300/2000] tot_loss=1.715 (perp=8.317, rec=0.061, cos=-0.009), tot_loss_proj:1.748 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1350/2000] tot_loss=1.704 (perp=8.317, rec=0.049, cos=-0.009), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=8.317, rec=0.058, cos=-0.009), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1450/2000] tot_loss=1.717 (perp=8.317, rec=0.063, cos=-0.009), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1500/2000] tot_loss=1.715 (perp=8.317, rec=0.061, cos=-0.009), tot_loss_proj:1.728 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1550/2000] tot_loss=1.718 (perp=8.317, rec=0.063, cos=-0.009), tot_loss_proj:1.731 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1600/2000] tot_loss=1.716 (perp=8.317, rec=0.062, cos=-0.009), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1650/2000] tot_loss=1.718 (perp=8.317, rec=0.063, cos=-0.009), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1700/2000] tot_loss=1.711 (perp=8.317, rec=0.056, cos=-0.009), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1750/2000] tot_loss=1.720 (perp=8.317, rec=0.066, cos=-0.009), tot_loss_proj:1.732 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1800/2000] tot_loss=1.714 (perp=8.317, rec=0.059, cos=-0.009), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1850/2000] tot_loss=1.712 (perp=8.317, rec=0.058, cos=-0.009), tot_loss_proj:1.737 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1900/2000] tot_loss=1.716 (perp=8.317, rec=0.062, cos=-0.009), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1950/2000] tot_loss=1.709 (perp=8.317, rec=0.055, cos=-0.009), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[2000/2000] tot_loss=1.719 (perp=8.317, rec=0.065, cos=-0.009), tot_loss_proj:1.744 [t=0.26s]
prediction: ['[CLS] clarity and emotional [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] clarity and emotional [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.940 | p: 87.279 | r: 88.741
rouge2     | fm: 53.239 | p: 52.945 | r: 53.566
rougeL     | fm: 76.318 | p: 75.854 | r: 76.912
rougeLsum  | fm: 76.248 | p: 75.765 | r: 76.859
r1fm+r2fm = 141.179

input #86 time: 0:10:47 | total time: 15:00:35


Running input #87 of 100.
reference: 
========================
propulsive 
========================
*********************************
*********************************
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8846666812896729 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7553390860557556 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7130892872810364 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7034943103790283 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6935102939605713 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6770039796829224 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6745697855949402 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.806 (perp=12.535, rec=0.298, cos=0.001), tot_loss_proj:3.357 [t=0.26s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.691 (perp=12.535, rec=0.190, cos=-0.006), tot_loss_proj:3.363 [t=0.26s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=1.649 (perp=7.258, rec=0.201, cos=-0.004), tot_loss_proj:1.501 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.547 (perp=7.258, rec=0.104, cos=-0.009), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.539 (perp=7.258, rec=0.096, cos=-0.008), tot_loss_proj:1.511 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.516 (perp=7.258, rec=0.074, cos=-0.009), tot_loss_proj:1.530 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.533 (perp=7.258, rec=0.086, cos=-0.004), tot_loss_proj:1.534 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.510 (perp=7.258, rec=0.068, cos=-0.009), tot_loss_proj:1.525 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.525 (perp=7.258, rec=0.082, cos=-0.009), tot_loss_proj:1.532 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.508 (perp=7.258, rec=0.066, cos=-0.009), tot_loss_proj:1.529 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.505 (perp=7.258, rec=0.063, cos=-0.009), tot_loss_proj:1.533 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.497 (perp=7.258, rec=0.054, cos=-0.009), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.514 (perp=7.258, rec=0.072, cos=-0.009), tot_loss_proj:1.531 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.500 (perp=7.258, rec=0.058, cos=-0.009), tot_loss_proj:1.523 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.504 (perp=7.258, rec=0.061, cos=-0.009), tot_loss_proj:1.507 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.494 (perp=7.258, rec=0.052, cos=-0.009), tot_loss_proj:1.516 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.509 (perp=7.258, rec=0.067, cos=-0.009), tot_loss_proj:1.528 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.517 (perp=7.258, rec=0.075, cos=-0.009), tot_loss_proj:1.532 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.507 (perp=7.258, rec=0.065, cos=-0.009), tot_loss_proj:1.527 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.511 (perp=7.258, rec=0.069, cos=-0.009), tot_loss_proj:1.525 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.496 (perp=7.258, rec=0.054, cos=-0.009), tot_loss_proj:1.516 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.500 (perp=7.258, rec=0.058, cos=-0.009), tot_loss_proj:1.516 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.489 (perp=7.258, rec=0.047, cos=-0.009), tot_loss_proj:1.530 [t=0.28s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.500 (perp=7.258, rec=0.058, cos=-0.009), tot_loss_proj:1.513 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.484 (perp=7.258, rec=0.042, cos=-0.009), tot_loss_proj:1.516 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.496 (perp=7.258, rec=0.054, cos=-0.009), tot_loss_proj:1.509 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.506 (perp=7.258, rec=0.064, cos=-0.009), tot_loss_proj:1.522 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.503 (perp=7.258, rec=0.061, cos=-0.009), tot_loss_proj:1.520 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.505 (perp=7.258, rec=0.063, cos=-0.009), tot_loss_proj:1.522 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.512 (perp=7.258, rec=0.070, cos=-0.009), tot_loss_proj:1.519 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.507 (perp=7.258, rec=0.065, cos=-0.009), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.500 (perp=7.258, rec=0.058, cos=-0.009), tot_loss_proj:1.533 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.502 (perp=7.258, rec=0.060, cos=-0.009), tot_loss_proj:1.524 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.502 (perp=7.258, rec=0.060, cos=-0.009), tot_loss_proj:1.517 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.490 (perp=7.258, rec=0.048, cos=-0.009), tot_loss_proj:1.510 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.498 (perp=7.258, rec=0.056, cos=-0.009), tot_loss_proj:1.524 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.512 (perp=7.258, rec=0.070, cos=-0.009), tot_loss_proj:1.514 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.508 (perp=7.258, rec=0.066, cos=-0.009), tot_loss_proj:1.524 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.493 (perp=7.258, rec=0.051, cos=-0.009), tot_loss_proj:1.523 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.512 (perp=7.258, rec=0.070, cos=-0.009), tot_loss_proj:1.523 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.201 | p: 87.544 | r: 88.910
rouge2     | fm: 53.748 | p: 53.469 | r: 54.046
rougeL     | fm: 76.543 | p: 76.059 | r: 77.117
rougeLsum  | fm: 76.542 | p: 76.011 | r: 77.138
r1fm+r2fm = 141.950

input #87 time: 0:11:05 | total time: 15:11:40


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
*********************************
*********************************
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9809058904647827 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.944068431854248 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9212347269058228 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.917607307434082 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9161702394485474 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9086971879005432 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.9049574136734009 for ['[CLS] towards scene too tram beetle vice updated being west grips above.olaignment golden gloss hot boundaries slave satellite warm reasons meant chord antagonist now trick migration part pennsylvania julius following embraced center rebound miss together hero bail museum days four rash [SEP]']
[Init] best rec loss: 0.9017528891563416 for ["[CLS]âº'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.8954169154167175 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8942180275917053 for ['[CLS] pondered allowed where! aunt never designated starting demi as programs home hadn piston spanning legitimate engine exodusbbed? insanity machine immortality [UNK] reform harmon network elevated nets today according baronet ki exchanged ) signed employees mandarin force close won landing observation [SEP]']
[Init] best perm rec loss: 0.8933555483818054 for ['[CLS] landing signed? ki legitimate network harmon starting demi observation! exchanged where aunt programs exodus insanity ) never today nets pistonbbed mandarin allowed baronet close won [UNK] reform force pondered employees home engine designated as spanning according elevated machine hadn immortality [SEP]']
[Init] best perm rec loss: 0.8925676345825195 for ['[CLS] machine? never immortality exodus landing exchanged! harmon force spanning according as reform [UNK] won where programs auntbbed home employees pondered insanity observation piston today network allowed close ) starting hadn mandarin nets demi elevated legitimate signed engine baronet designated ki [SEP]']
[Init] best perm rec loss: 0.8924002051353455 for ['[CLS] harmon today piston? [UNK] won legitimate machine designated where landing starting allowed demibbed close engine elevated baronet nets ) hadn aunt exchanged never! according employees spanning mandarin insanity exodus immortality signed reform observation as force pondered programs network ki home [SEP]']
[Init] best perm rec loss: 0.8921587467193604 for ['[CLS] allowed hadn legitimate signed piston mandarin exodus reform pondered as observation ) ki engine never network insanitybbed aunt? immortality force demi starting today! where nets machine landing [UNK] home close spanning exchanged designated won employees baronet programs elevated according harmon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.536 (perp=11.107, rec=0.321, cos=-0.007), tot_loss_proj:3.506 [t=0.26s]
prediction: ['[CLS] emotionsness return gustave joseph love breaking love love the good social positively estate browning love larger artifacts, hunter that heritageross inner beyond lovefaran be with cool start explore / understood understood loved amazingasurable misery understanding both synonymous [SEP]']
[ 100/2000] tot_loss=2.342 (perp=10.555, rec=0.239, cos=-0.008), tot_loss_proj:3.284 [t=0.26s]
prediction: ['[CLS] mattersness love [SEP] anderson love breaking love love the that great. appleoted love heat boston and. that our that the with!ssas is understands how and grand especially calm understands loved great our ignorance emotions that still [SEP]']
[ 150/2000] tot_loss=2.271 (perp=10.123, rec=0.254, cos=-0.008), tot_loss_proj:3.263 [t=0.25s]
prediction: ['[CLS] mattersnessunciation [SEP] anderson joylei love love - great great. our harmless love strange group. youirtha and the of! alled who understands how and grand especially calm whatever in we our was! thatå®€ [SEP]']
[ 200/2000] tot_loss=2.381 (perp=10.596, rec=0.270, cos=-0.008), tot_loss_proj:3.208 [t=0.25s]
prediction: ['[CLS] romanceorunciation. anderson love bwvé˜ love f greatily. our harmless love myth living and you of really and the even bringing allous is understands how and grandâ†¦ calm whatever in daily our, people that â‚€ [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.182 (perp=9.752, rec=0.240, cos=-0.009), tot_loss_proj:3.156 [t=0.27s]
prediction: ['[CLS] romance of becomes. anderson love knight might romance a great p immigrants and you of s and the every bring best hailey of. our t romance necessity understands building and grand= calm ( in daily our ( humanity that â‚€ [SEP]']
[ 300/2000] tot_loss=2.257 (perp=10.263, rec=0.213, cos=-0.009), tot_loss_proj:3.251 [t=0.27s]
prediction: ['[CLS] romance of becomes t anderson love knight might romance h great p ill and you of s and the every bring best ourity. our t romance sir understands building and grand= calm the in daily our (. that â‚€ [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.154 (perp=9.778, rec=0.207, cos=-0.009), tot_loss_proj:3.457 [t=0.26s]
prediction: ['[CLS] romance of becomes p anderson love love might romance h great p ill and you of " and the every can in myity. our t romance ill understands about and grand= calm the all daily our ill people that â‚€ [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.026 (perp=9.193, rec=0.197, cos=-0.009), tot_loss_proj:2.985 [t=0.26s]
prediction: ['[CLS] romance of our p anderson love love of romance joy p ill and you of " and the every great can in myity. our harmless romance ill understands about and grand= calm the all daily our ill people that â‚€ [SEP]']
[ 450/2000] tot_loss=2.016 (perp=9.236, rec=0.179, cos=-0.009), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] romance of our p anderson love love of romance joy p daily and. of s and the every great canrigue myity. our harmless romance ill understands how and grand= calm the all daily our ill people that â‚€ [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.091 (perp=9.644, rec=0.172, cos=-0.009), tot_loss_proj:3.257 [t=0.26s]
prediction: ['[CLS] romance of our p anderson love feature of romance joy p daily and daily [SEP] " and the every great can in myial. our established romance ill understands how and grand= calm the all. our ill. that â‚€ [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.035 (perp=9.380, rec=0.168, cos=-0.009), tot_loss_proj:3.228 [t=0.25s]
prediction: ['[CLS] romance of our p anderson love loves romance joy in daily and daily [SEP] ". the every great can new myial. our established romance ill understands how and grand= calm the all. our ill. that â‚€ [SEP]']
[ 600/2000] tot_loss=2.018 (perp=9.331, rec=0.161, cos=-0.009), tot_loss_proj:3.266 [t=0.27s]
prediction: ['[CLS] romance of our p anderson love loves romance joy bring daily and daily [SEP] ". the every grand can new myily. our old romance ill understands how and grand= calm the all. our ill. that â‚€ [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.896 (perp=8.731, rec=0.159, cos=-0.009), tot_loss_proj:3.093 [t=0.26s]
prediction: ['[CLS] romance of our p anderson love loves romance joy bring daily and daily.ial. the every grand can new my ". our old romance ill understands how and grand= calm the all. our ill. that â‚€ [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.817 (perp=8.334, rec=0.160, cos=-0.009), tot_loss_proj:3.020 [t=0.26s]
prediction: ['[CLS] romance of our p anderson love loves romance joy bring daily and daily.ial. and every grand can new my ". our old romance ill understands how the grand= calm the only. our ill. that â‚€ [SEP]']
[ 750/2000] tot_loss=1.820 (perp=8.334, rec=0.162, cos=-0.009), tot_loss_proj:3.016 [t=0.26s]
prediction: ['[CLS] romance of our p anderson love loves romance joy bring daily and daily.ial. and every grand can new my ". our old romance ill understands how the grand= calm the only. our ill. that â‚€ [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.718 (perp=7.859, rec=0.155, cos=-0.010), tot_loss_proj:2.790 [t=0.26s]
prediction: ['[CLS] romance of our p anderson joy love joy romances bring daily and daily.ily. and every grand can new my ". our old romance ill understands how the grand= calm the all. our ill. that ( [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.715 (perp=7.836, rec=0.158, cos=-0.010), tot_loss_proj:3.047 [t=0.27s]
prediction: ['[CLS] romance of our p anderson joy love. romances bring ill and daily joyily. and every grand can new my ". our old romance ill understands how the grand= calm the all. our ill. that ( [SEP]']
[ 900/2000] tot_loss=1.714 (perp=7.870, rec=0.149, cos=-0.010), tot_loss_proj:2.977 [t=0.27s]
prediction: ['[CLS] romance of our p anderson joy love. romances bring ill and daily joyily. and every grand can new my ". our t romance ill understands how the grand= calm the all. our ill. that ( [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.678 (perp=7.671, rec=0.153, cos=-0.010), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS]= of our p anderson joy love. romances bring daily and daily joyial. and every grand can new my ". our t romance ill understands how the grand romance calm the all. our ill. that ( [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.662 (perp=7.543, rec=0.163, cos=-0.010), tot_loss_proj:2.960 [t=0.26s]
prediction: ['[CLS]= of our p anderson joy.. romances bring ill and daily joyily. and every grand can new our ". our t romance ill understands how the grand romance calm the all. our ill love that ( [SEP]']
[1050/2000] tot_loss=1.613 (perp=7.351, rec=0.152, cos=-0.010), tot_loss_proj:2.571 [t=0.27s]
prediction: ['[CLS]= of our t anderson joy.. romances bring daily and daily joyial. and every grand can our our ". our t romance ill understands how the grand romance calm the all. our ill love that ( [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.631 (perp=7.447, rec=0.151, cos=-0.009), tot_loss_proj:3.104 [t=0.26s]
prediction: ['[CLS]= of our p anderson joy.. romances bring daily and daily joyial. and every grand romance our us ". ouriner romance ill understands how the grand can calm the all. our ill love that ( [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.623 (perp=7.411, rec=0.151, cos=-0.009), tot_loss_proj:3.096 [t=0.27s]
prediction: ['[CLS] clearly of our t anderson joy.. romances bring daily and daily joy. and every grand romance our usial ". ouriner romance ill understands how the grand can calm the all. our ill love that ( [SEP]']
[1200/2000] tot_loss=1.682 (perp=7.743, rec=0.143, cos=-0.010), tot_loss_proj:2.991 [t=0.26s]
prediction: ['[CLS]= of [SEP] t anderson joy.. romances bring daily and daily joy. and every grand romance our usial ". our nu romance ill understands how the grand can calm the only. our ill love that ( [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.756 (perp=8.125, rec=0.140, cos=-0.010), tot_loss_proj:3.151 [t=0.26s]
prediction: ['[CLS]= of [SEP] t anderson joy.. romances bring daily and daily joy. and every grand romance our uss ". ouriner romance ill understands how the grand can calm the p. our ill only that ( [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.684 (perp=7.704, rec=0.152, cos=-0.010), tot_loss_proj:3.000 [t=0.25s]
prediction: ['[CLS]= of [SEP] t anderson joy.. romances bring daily and daily joy. and every grand romance our usial ill. our t romance ill understands how the grand can calm the p. our " only that ( [SEP]']
[1350/2000] tot_loss=1.646 (perp=7.606, rec=0.134, cos=-0.010), tot_loss_proj:3.142 [t=0.26s]
prediction: ['[CLS]= of [SEP] t anderson joy.. romances bring daily and daily joy. and every grand romance our uss ill. our t romance ill understands how the grand can calm the p. our " only that ( [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.589 (perp=7.269, rec=0.145, cos=-0.010), tot_loss_proj:2.943 [t=0.27s]
prediction: ['[CLS] clearly of [SEP] t anderson joy.. romances bring daily and daily joy. and every grand romance our uss ill. our t romance our ill understands how the grand can calm the p. " only that ( [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.600 (perp=7.342, rec=0.142, cos=-0.010), tot_loss_proj:2.918 [t=0.26s]
prediction: ['[CLS]= of every t anderson joy.. romances bring daily and daily joy. and [SEP] grand romance our uss ill. our t romance our ill understands how the grand can calm the p. " only that ( [SEP]']
[1500/2000] tot_loss=1.659 (perp=7.619, rec=0.144, cos=-0.010), tot_loss_proj:2.977 [t=0.26s]
prediction: ['[CLS] clearly of every t anderson joy.. romances bring daily and daily joy. and [SEP] grand romance our uss ill. our nu romance our ill understands how the grand can calm the p. " only that ( [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.691 (perp=7.777, rec=0.145, cos=-0.010), tot_loss_proj:3.253 [t=0.25s]
prediction: ['[CLS] clearly of nu t anderson joy.. romances bring ill and daily joy. and [SEP] grand romance our uss ill. our every romance our ill understands how the grand can calm the p. " only that ( [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.657 (perp=7.641, rec=0.139, cos=-0.010), tot_loss_proj:3.258 [t=0.26s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring ill and daily joy. and [SEP] grand romance. uss ill. our every romance our ill understands how the grand can calm the p. " only that ( [SEP]']
[1650/2000] tot_loss=1.611 (perp=7.414, rec=0.138, cos=-0.010), tot_loss_proj:3.069 [t=0.27s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring daily and daily joy. and [SEP] grand romance. uss ill. our every romance our ill understands how the grand can calm the p. " only that ( [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.660 (perp=7.641, rec=0.141, cos=-0.010), tot_loss_proj:3.297 [t=0.26s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring ill and daily joy. and [SEP] grand romance. uss ill. our every romance our ill understands how the grand can calm the p. " only that ( [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.634 (perp=7.499, rec=0.144, cos=-0.010), tot_loss_proj:3.342 [t=0.25s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring ill and daily joy. and [SEP] grand romance. uss ill. our every romance our p understands how the grand can calm the ill. " only that ( [SEP]']
[1800/2000] tot_loss=1.637 (perp=7.499, rec=0.147, cos=-0.010), tot_loss_proj:3.343 [t=0.26s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring ill and daily joy. and [SEP] grand romance. uss ill. our every romance our p understands how the grand can calm the ill. " only that ( [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.613 (perp=7.384, rec=0.146, cos=-0.010), tot_loss_proj:2.922 [t=0.26s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring daily and daily joy. and our grand romance. usizer ill. our every romance [SEP] p understands how the grand can calm the ill. " all that ( [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.606 (perp=7.377, rec=0.140, cos=-0.010), tot_loss_proj:3.124 [t=0.26s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring ill and daily joy. and our grand romance. us illizer. our every romance [SEP] p understands how the grand can calm the ill. " all that ( [SEP]']
[1950/2000] tot_loss=1.574 (perp=7.194, rec=0.145, cos=-0.010), tot_loss_proj:2.689 [t=0.25s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring daily and daily joy. and our grand romance. us illizer. our every romance [SEP] p understands how the grand can calm the ill. " all that ( [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.595 (perp=7.324, rec=0.140, cos=-0.010), tot_loss_proj:2.745 [t=0.26s]
prediction: ['[CLS] clearly of nu t anderson joy. our romances bring daily and daily joy. and our grand romance. us illizer. our every romance [SEP] p understands how the grand can calm the only that ill. " ( [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] clearly of nu t anderson joy. our romances bring ill and daily joy. and [SEP] grand romance. uss ill. our every romance our p understands how the grand can calm the ill. " only that ( [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.054 | p: 55.556 | r: 52.632
rouge2     | fm: 5.556 | p: 5.714 | r: 5.405
rougeL     | fm: 27.027 | p: 27.778 | r: 26.316
rougeLsum  | fm: 27.027 | p: 27.778 | r: 26.316
r1fm+r2fm = 59.610

[Aggregate metrics]:
rouge1     | fm: 87.724 | p: 87.091 | r: 88.438
rouge2     | fm: 53.382 | p: 53.081 | r: 53.681
rougeL     | fm: 76.055 | p: 75.562 | r: 76.593
rougeLsum  | fm: 75.921 | p: 75.424 | r: 76.529
r1fm+r2fm = 141.106

input #88 time: 0:11:04 | total time: 15:22:45


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
*********************************
*********************************
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9663888216018677 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524359107017517 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9456372857093811 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9341058135032654 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.933344841003418 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9307798743247986 for ['[CLS] happenedtte atari promiseats gps leon relatively blood broken weight deathsfootmedia jp wish atomic cutleruating eight watt boys practicing muttereduded document creditedpate donful photograph trusting [SEP]']
[Init] best perm rec loss: 0.9285004734992981 for ['[CLS]ats jp practicing blood trustingmediauating donfulpate promise boysfoot broken happened document relatively weight muttered atomic wish deaths credited photographtte atariuded leon cutler gps watt eight [SEP]']
[Init] best perm rec loss: 0.9245237708091736 for ['[CLS]pate watt weight gpsats eight boys document cutler jptte deathsuating blood trusting atari atomic credited wish donuded mutteredfoot happenedful photograph broken practicingmedia promise relatively leon [SEP]']
[Init] best perm rec loss: 0.9240761399269104 for ['[CLS]foot credited blooduded document atomic promise cutler boysats relatively photographmedia ataripate broken watt gps jp deathsful trustinguating weight don happenedtte practicing eight wish leon muttered [SEP]']
[Init] best perm rec loss: 0.9212810397148132 for ['[CLS] eight documentpateuating deaths blood boys muttered donuded photographfoot relatively broken cutler atomic practicing atari watt jpats happened trusting wish weight credited gpsmedia leonfultte promise [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.815 (perp=12.432, rec=0.336, cos=-0.008), tot_loss_proj:3.512 [t=0.25s]
prediction: ['[CLS] guilt on least blouse josie routine shoved apparently - tope - organization worsefe worse worried other maybe military distraction no tactic somehow committee real notedes maybe defensive technology [SEP]']
[ 100/2000] tot_loss=2.275 (perp=10.091, rec=0.266, cos=-0.009), tot_loss_proj:2.946 [t=0.27s]
prediction: ['[CLS] tactic on proposed screen res the worse not - nole - assembly worse tel had type of genre no covering, tactic... committee real worse, things constructed three ideas [SEP]']
[ 150/2000] tot_loss=2.010 (perp=9.004, rec=0.218, cos=-0.009), tot_loss_proj:2.922 [t=0.26s]
prediction: ['[CLS] tactic to paper fact res the that not - noneim - is worse it - / of genre no cover - tactic or agreed real worse, things with three ideas [SEP]']
[ 200/2000] tot_loss=1.965 (perp=8.984, rec=0.177, cos=-0.010), tot_loss_proj:2.999 [t=0.26s]
prediction: ['[CLS] tactic to out fact res fact that apparently - noneim, is lacking it - - of fact none cover - tactic or agreed quite worse yet - constructed three ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.827 (perp=8.361, rec=0.164, cos=-0.009), tot_loss_proj:2.501 [t=0.26s]
prediction: ['[CLS] tactic to out fact picture fact that apparently the nonexi, is presents tel - - of fact - cover - tactic or - quite worse yet - - three ideas [SEP]']
[ 300/2000] tot_loss=1.720 (perp=7.866, rec=0.156, cos=-0.009), tot_loss_proj:2.347 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture the that apparently is nonexi - is presents it - - around fact - cover - tactic or - quite worse yet - - three ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.822 (perp=8.468, rec=0.138, cos=-0.010), tot_loss_proj:2.578 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture the that apparently constructed nonexit is constructedre - - that fact - cover - tactic or notion quite worse yet - - - ideas [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.826 (perp=8.554, rec=0.125, cos=-0.010), tot_loss_proj:2.463 [t=0.27s]
prediction: ['[CLS] tactic to up fact picture the that apparently constructed nonexisy is constructed cover tel - - that fact of - tactic or notion, worse yet - - - ideas [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.162, rec=0.113, cos=-0.010), tot_loss_proj:2.339 [t=0.28s]
prediction: ['[CLS] tactic to up fact picture the that apparently constructed nonexisy is constructed coveramp - / of fact of - tactic or ideas, worse yet - - - ideas [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.761 (perp=8.276, rec=0.116, cos=-0.010), tot_loss_proj:2.419 [t=0.25s]
prediction: ['[CLS] tactic to up fact picture the that - constructed nonexisy is constructed covereld - fl around fact - tactic or ideas, of worse yet - - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.694 (perp=7.989, rec=0.106, cos=-0.009), tot_loss_proj:2.555 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture the that - - nonexisy is constructed cover core - fl around fact - tactic or ideas, of worse yet - - is ideas [SEP]']
[ 600/2000] tot_loss=1.728 (perp=8.170, rec=0.104, cos=-0.010), tot_loss_proj:2.689 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture the that - - nonexisy is constructed cover core -im around fact - tactic or ideas, of worse yet - - is ideas [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.697 (perp=7.999, rec=0.106, cos=-0.010), tot_loss_proj:2.709 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture the that - - nonexisy is constructed around cover core -im fact - tactic or ;, of worse yet - - is ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.662 (perp=7.863, rec=0.099, cos=-0.010), tot_loss_proj:2.650 [t=0.28s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover core -im fact - tactic or ;, of worse yet - - is ideas [SEP]']
[ 750/2000] tot_loss=1.641 (perp=7.783, rec=0.094, cos=-0.010), tot_loss_proj:2.684 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover core -im fact - tactic or., of worse yet - - is ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.708 (perp=8.117, rec=0.095, cos=-0.010), tot_loss_proj:2.574 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover core -im fact - variables or is, of worse yet - - ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.657 (perp=7.873, rec=0.092, cos=-0.010), tot_loss_proj:2.582 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover core -im fact - is or variables, of worse yet - - ideas ideas [SEP]']
[ 900/2000] tot_loss=1.596 (perp=7.569, rec=0.092, cos=-0.010), tot_loss_proj:2.618 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover core -im that - is or variables, of worse yet - - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.550 (perp=7.328, rec=0.094, cos=-0.010), tot_loss_proj:2.590 [t=0.25s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover - -im that - is or constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.503 (perp=7.104, rec=0.092, cos=-0.010), tot_loss_proj:2.550 [t=0.27s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover - -im that - or is constructed, of worse yet - - core ideas [SEP]']
[1050/2000] tot_loss=1.499 (perp=7.104, rec=0.088, cos=-0.010), tot_loss_proj:2.548 [t=0.27s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed around cover - -im that - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.492 (perp=7.065, rec=0.088, cos=-0.010), tot_loss_proj:2.523 [t=0.26s]
prediction: ['[CLS] tactic to up fact picture that - - the nonexisy is constructed cover around - -im that - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.419 (perp=6.678, rec=0.093, cos=-0.009), tot_loss_proj:1.974 [t=0.25s]
prediction: ['[CLS] tactic to cover up fact picture that - - the nonexisy is constructed around - -im that - or is constructed, of worse yet - - core ideas [SEP]']
[1200/2000] tot_loss=1.420 (perp=6.678, rec=0.094, cos=-0.010), tot_loss_proj:1.971 [t=0.26s]
prediction: ['[CLS] tactic to cover up fact picture that - - the nonexisy is constructed around - -im that - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.358 (perp=6.393, rec=0.089, cos=-0.010), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] tactic to cover up fact picture that - - the nonexiimsy is constructed around - - that - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
[1300/2000] tot_loss=1.352 (perp=6.393, rec=0.083, cos=-0.010), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] tactic to cover up fact picture that - - the nonexiimsy is constructed around - - that - or is constructed, of worse yet - - core ideas [SEP]']
[1350/2000] tot_loss=1.357 (perp=6.393, rec=0.088, cos=-0.010), tot_loss_proj:1.966 [t=0.26s]
prediction: ['[CLS] tactic to cover up fact picture that - - the nonexiimsy is constructed around - - that - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.321 (perp=6.213, rec=0.088, cos=-0.010), tot_loss_proj:1.919 [t=0.26s]
prediction: ['[CLS] tactic to cover up fact picture - - the nonexiimsy that is constructed around - - that - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.259 (perp=5.933, rec=0.082, cos=-0.010), tot_loss_proj:1.897 [t=0.26s]
prediction: ['[CLS] tactic to cover up fact picture - - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
[1500/2000] tot_loss=1.332 (perp=6.301, rec=0.082, cos=-0.010), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] tactic to cover up fact picture - a the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.330 (perp=6.282, rec=0.084, cos=-0.010), tot_loss_proj:1.942 [t=0.26s]
prediction: ['[CLS] tactic to - cover up fact picture - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.293 (perp=6.074, rec=0.088, cos=-0.010), tot_loss_proj:2.117 [t=0.27s]
prediction: ['[CLS] tactic to picture cover up fact - - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
[1650/2000] tot_loss=1.285 (perp=6.074, rec=0.080, cos=-0.010), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] tactic to picture cover up fact - - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.344 (perp=6.344, rec=0.086, cos=-0.010), tot_loss_proj:1.938 [t=0.26s]
prediction: ['[CLS] tactic picture to cover up fact a - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.286 (perp=6.093, rec=0.077, cos=-0.010), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] tactic picture to cover up a fact - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
[1800/2000] tot_loss=1.295 (perp=6.093, rec=0.086, cos=-0.010), tot_loss_proj:1.933 [t=0.26s]
prediction: ['[CLS] tactic picture to cover up a fact - the nonexiimsy that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.263 (perp=5.948, rec=0.083, cos=-0.010), tot_loss_proj:1.791 [t=0.26s]
prediction: ['[CLS] tactic to cover up a fact - the nonexiimsy picture that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
Attempt swap
[1900/2000] tot_loss=1.261 (perp=5.948, rec=0.081, cos=-0.010), tot_loss_proj:1.788 [t=0.27s]
prediction: ['[CLS] tactic to cover up a fact - the nonexiimsy picture that is constructed around that - - - or is constructed, of worse yet - - core ideas [SEP]']
[1950/2000] tot_loss=1.312 (perp=6.203, rec=0.081, cos=-0.010), tot_loss_proj:1.777 [t=0.27s]
prediction: ['[CLS] tactic to cover up a fact - the nonexiimsy picture that is constructed around that - - - or issy, of worse yet - - core ideas [SEP]']
Attempt swap
[2000/2000] tot_loss=1.305 (perp=6.203, rec=0.074, cos=-0.010), tot_loss_proj:1.780 [t=0.25s]
prediction: ['[CLS] tactic to cover up a fact - the nonexiimsy picture that is constructed around that - - - or issy, of worse yet - - core ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic to cover up a fact - the nonexiimsy picture that is constructed around that - - - or issy, of worse yet - - core ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 86.957 | r: 86.957
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 69.565 | p: 69.565 | r: 69.565
rougeLsum  | fm: 69.565 | p: 69.565 | r: 69.565
r1fm+r2fm = 123.320

[Aggregate metrics]:
rouge1     | fm: 87.767 | p: 87.152 | r: 88.533
rouge2     | fm: 53.163 | p: 52.888 | r: 53.482
rougeL     | fm: 75.978 | p: 75.507 | r: 76.503
rougeLsum  | fm: 76.017 | p: 75.571 | r: 76.571
r1fm+r2fm = 140.930

input #89 time: 0:11:05 | total time: 15:33:51


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
*********************************
*********************************
average of cosine similarity 0.9993650968600141
highest_index [0]
highest [0.9993650968600141]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9487876892089844 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9457016587257385 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9307820200920105 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131976962089539 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8914667963981628 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8844628930091858 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.874426543712616 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8734989166259766 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.8714959025382996 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.8705925345420837 for ['[CLS] cannot male spirited entourage released when [SEP]']
[Init] best perm rec loss: 0.8705049157142639 for ['[CLS] cannot entourage spirited male released when [SEP]']
[Init] best perm rec loss: 0.8698896765708923 for ['[CLS] male cannot when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8698087334632874 for ['[CLS] entourage released spirited male cannot when [SEP]']
[Init] best perm rec loss: 0.8679990172386169 for ['[CLS] cannot released male spirited when entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.767 (perp=12.165, rec=0.335, cos=-0.001), tot_loss_proj:3.203 [t=0.26s]
prediction: ['[CLS] price ridiculous rack attacks money mega [SEP]']
[ 100/2000] tot_loss=2.787 (perp=13.038, rec=0.188, cos=-0.008), tot_loss_proj:3.293 [t=0.25s]
prediction: ['[CLS] stupid ridiculous oriented killing money how [SEP]']
[ 150/2000] tot_loss=2.515 (perp=11.929, rec=0.136, cos=-0.007), tot_loss_proj:3.524 [t=0.26s]
prediction: ['[CLS] insane ridiculous oriented and money how [SEP]']
[ 200/2000] tot_loss=2.284 (perp=10.962, rec=0.101, cos=-0.009), tot_loss_proj:3.355 [t=0.26s]
prediction: ['[CLS] crazy ridiculous oriented and money how [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.901 (perp=9.059, rec=0.098, cos=-0.008), tot_loss_proj:2.338 [t=0.26s]
prediction: ['[CLS] how ridiculous oriented and money insane [SEP]']
[ 300/2000] tot_loss=1.877 (perp=9.059, rec=0.075, cos=-0.009), tot_loss_proj:2.328 [t=0.26s]
prediction: ['[CLS] how ridiculous oriented and money insane [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.450 (perp=6.923, rec=0.075, cos=-0.009), tot_loss_proj:1.613 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented insane [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.439 (perp=6.870, rec=0.074, cos=-0.009), tot_loss_proj:1.678 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.441 (perp=6.870, rec=0.077, cos=-0.009), tot_loss_proj:1.688 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.431 (perp=6.870, rec=0.067, cos=-0.009), tot_loss_proj:1.683 [t=0.29s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.426 (perp=6.870, rec=0.061, cos=-0.009), tot_loss_proj:1.693 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.430 (perp=6.870, rec=0.065, cos=-0.009), tot_loss_proj:1.686 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.433 (perp=6.870, rec=0.069, cos=-0.009), tot_loss_proj:1.691 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.419 (perp=6.870, rec=0.055, cos=-0.009), tot_loss_proj:1.702 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.424 (perp=6.870, rec=0.059, cos=-0.009), tot_loss_proj:1.698 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.425 (perp=6.870, rec=0.061, cos=-0.009), tot_loss_proj:1.699 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.424 (perp=6.870, rec=0.060, cos=-0.009), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.425 (perp=6.870, rec=0.061, cos=-0.009), tot_loss_proj:1.696 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.420 (perp=6.870, rec=0.056, cos=-0.009), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.421 (perp=6.870, rec=0.057, cos=-0.009), tot_loss_proj:1.696 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.426 (perp=6.870, rec=0.061, cos=-0.009), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.420 (perp=6.870, rec=0.055, cos=-0.009), tot_loss_proj:1.702 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.421 (perp=6.870, rec=0.057, cos=-0.009), tot_loss_proj:1.700 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.425 (perp=6.870, rec=0.061, cos=-0.009), tot_loss_proj:1.703 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.420 (perp=6.870, rec=0.056, cos=-0.009), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.437 (perp=6.870, rec=0.072, cos=-0.009), tot_loss_proj:1.706 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.428 (perp=6.870, rec=0.063, cos=-0.009), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.418 (perp=6.870, rec=0.053, cos=-0.009), tot_loss_proj:1.707 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.422 (perp=6.870, rec=0.057, cos=-0.009), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.870, rec=0.060, cos=-0.009), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.421 (perp=6.870, rec=0.056, cos=-0.009), tot_loss_proj:1.697 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.438 (perp=6.870, rec=0.073, cos=-0.009), tot_loss_proj:1.703 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.422 (perp=6.870, rec=0.057, cos=-0.009), tot_loss_proj:1.707 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.421 (perp=6.870, rec=0.057, cos=-0.009), tot_loss_proj:1.705 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.429 (perp=6.870, rec=0.065, cos=-0.009), tot_loss_proj:1.704 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.433 (perp=6.870, rec=0.068, cos=-0.009), tot_loss_proj:1.703 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.439 (perp=6.870, rec=0.075, cos=-0.009), tot_loss_proj:1.698 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.430 (perp=6.870, rec=0.065, cos=-0.009), tot_loss_proj:1.701 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.423 (perp=6.870, rec=0.059, cos=-0.009), tot_loss_proj:1.705 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.432 (perp=6.870, rec=0.067, cos=-0.009), tot_loss_proj:1.694 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.877 | p: 87.263 | r: 88.553
rouge2     | fm: 53.587 | p: 53.318 | r: 53.932
rougeL     | fm: 76.173 | p: 75.712 | r: 76.762
rougeLsum  | fm: 76.179 | p: 75.725 | r: 76.725
r1fm+r2fm = 141.464

input #90 time: 0:11:02 | total time: 15:44:54


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
*********************************
*********************************
average of cosine similarity 0.9993538374859836
highest_index [0]
highest [0.9993538374859836]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9367198944091797 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.8268771767616272 for ['[CLS] landssulÅ‚dotenick own get distant [SEP]']
[Init] best rec loss: 0.8143160343170166 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.77603679895401 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7621927261352539 for ['[CLS] doubled regimental baby cement ×™ game ultimate ideal [SEP]']
[Init] best rec loss: 0.7398632168769836 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7303189039230347 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7301856279373169 for ['[CLS]dern pony revolutionpment unknownlip hard shelter [SEP]']
[Init] best perm rec loss: 0.7299460172653198 for ['[CLS]lippment hard unknown pony shelterdern revolution [SEP]']
[Init] best perm rec loss: 0.7278955578804016 for ['[CLS] hard unknown revolutiondernlip shelter ponypment [SEP]']
[Init] best perm rec loss: 0.7267093658447266 for ['[CLS] pony hard shelterpmentlip unknowndern revolution [SEP]']
[Init] best perm rec loss: 0.7247644662857056 for ['[CLS] hard unknown revolutionpmentlipdern shelter pony [SEP]']
[Init] best perm rec loss: 0.7247127890586853 for ['[CLS] hard shelterpmentlip revolution unknowndern pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.541 (perp=10.894, rec=0.368, cos=-0.006), tot_loss_proj:3.008 [t=0.25s]
prediction: ['[CLS] yellow freeces crazy ridiculous? shelter controversy [SEP]']
[ 100/2000] tot_loss=2.512 (perp=11.246, rec=0.270, cos=-0.007), tot_loss_proj:3.759 [t=0.26s]
prediction: ['[CLS] loco loco " no ridiculous moreiled rumor [SEP]']
[ 150/2000] tot_loss=2.402 (perp=11.029, rec=0.205, cos=-0.008), tot_loss_proj:2.783 [t=0.25s]
prediction: ['[CLS] loco loco but no ridiculous moreiled ridiculous [SEP]']
[ 200/2000] tot_loss=2.385 (perp=11.262, rec=0.142, cos=-0.009), tot_loss_proj:2.738 [t=0.25s]
prediction: ['[CLS] mu loco but no ridiculous moredown ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.124 (perp=9.967, rec=0.138, cos=-0.007), tot_loss_proj:2.541 [t=0.25s]
prediction: ['[CLS] mu loco but no more ridiculous sox loco [SEP]']
[ 300/2000] tot_loss=2.228 (perp=10.642, rec=0.109, cos=-0.010), tot_loss_proj:2.695 [t=0.25s]
prediction: ['[CLS] mu loco but no more ridiculoususe loco [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.110 (perp=10.046, rec=0.110, cos=-0.010), tot_loss_proj:2.661 [t=0.26s]
prediction: ['[CLS] mu loco but no more ridiculous locoerate [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.024 (perp=9.621, rec=0.109, cos=-0.009), tot_loss_proj:2.462 [t=0.26s]
prediction: ['[CLS] mu loco but no loco more ridiculous gnu [SEP]']
[ 450/2000] tot_loss=1.936 (perp=9.240, rec=0.098, cos=-0.010), tot_loss_proj:2.293 [t=0.26s]
prediction: ['[CLS] mu loco but no loco more ridiculousy [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.936 (perp=9.256, rec=0.095, cos=-0.010), tot_loss_proj:2.330 [t=0.27s]
prediction: ['[CLS] mu loco gnu but no loco more ridiculous [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.934 (perp=9.245, rec=0.095, cos=-0.010), tot_loss_proj:2.235 [t=0.25s]
prediction: ['[CLS] mu loco gnu but loco no more ridiculous [SEP]']
[ 600/2000] tot_loss=1.923 (perp=9.153, rec=0.102, cos=-0.010), tot_loss_proj:2.173 [t=0.25s]
prediction: ['[CLS] mu locoy but loco no more ridiculous [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.786 (perp=8.538, rec=0.088, cos=-0.010), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.804 (perp=8.538, rec=0.106, cos=-0.010), tot_loss_proj:2.113 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[ 750/2000] tot_loss=1.794 (perp=8.538, rec=0.096, cos=-0.010), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.786 (perp=8.538, rec=0.089, cos=-0.010), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.782 (perp=8.538, rec=0.084, cos=-0.010), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[ 900/2000] tot_loss=1.787 (perp=8.538, rec=0.089, cos=-0.010), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.538, rec=0.098, cos=-0.010), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.795 (perp=8.538, rec=0.097, cos=-0.010), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1050/2000] tot_loss=1.786 (perp=8.538, rec=0.088, cos=-0.010), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.787 (perp=8.538, rec=0.089, cos=-0.010), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.786 (perp=8.538, rec=0.088, cos=-0.010), tot_loss_proj:2.119 [t=0.27s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1200/2000] tot_loss=1.796 (perp=8.538, rec=0.098, cos=-0.010), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.782 (perp=8.538, rec=0.084, cos=-0.010), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.776 (perp=8.538, rec=0.078, cos=-0.010), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1350/2000] tot_loss=1.796 (perp=8.538, rec=0.098, cos=-0.010), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.775 (perp=8.538, rec=0.078, cos=-0.010), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.794 (perp=8.538, rec=0.097, cos=-0.010), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1500/2000] tot_loss=1.788 (perp=8.538, rec=0.090, cos=-0.010), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.786 (perp=8.538, rec=0.088, cos=-0.010), tot_loss_proj:2.123 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.785 (perp=8.538, rec=0.087, cos=-0.010), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1650/2000] tot_loss=1.793 (perp=8.538, rec=0.095, cos=-0.010), tot_loss_proj:2.126 [t=0.27s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.781 (perp=8.538, rec=0.083, cos=-0.010), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.787 (perp=8.538, rec=0.090, cos=-0.010), tot_loss_proj:2.127 [t=0.27s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1800/2000] tot_loss=1.777 (perp=8.538, rec=0.079, cos=-0.010), tot_loss_proj:2.125 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.779 (perp=8.538, rec=0.082, cos=-0.010), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.771 (perp=8.538, rec=0.074, cos=-0.010), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1950/2000] tot_loss=1.787 (perp=8.538, rec=0.089, cos=-0.010), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.786 (perp=8.538, rec=0.089, cos=-0.010), tot_loss_proj:2.115 [t=0.26s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] mu locoy but no loco more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 87.835 | p: 87.195 | r: 88.596
rouge2     | fm: 53.453 | p: 53.111 | r: 53.789
rougeL     | fm: 76.137 | p: 75.638 | r: 76.748
rougeLsum  | fm: 76.060 | p: 75.592 | r: 76.653
r1fm+r2fm = 141.288

input #91 time: 0:11:03 | total time: 15:55:57


Running input #92 of 100.
reference: 
========================
deceit 
========================
*********************************
*********************************
average of cosine similarity 0.9993137310302475
highest_index [0]
highest [0.9993137310302475]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8797468543052673 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8783625364303589 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8693297505378723 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8594153523445129 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8578515648841858 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.8554595112800598 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7936431765556335 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7916328310966492 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.667 (perp=12.265, rec=0.219, cos=-0.006), tot_loss_proj:3.195 [t=0.26s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=2.581 (perp=12.265, rec=0.137, cos=-0.008), tot_loss_proj:3.190 [t=0.27s]
prediction: ['[CLS] erroreit [SEP]']
[ 150/2000] tot_loss=1.607 (perp=7.646, rec=0.087, cos=-0.009), tot_loss_proj:1.599 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.588 (perp=7.646, rec=0.068, cos=-0.009), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.577 (perp=7.646, rec=0.057, cos=-0.009), tot_loss_proj:1.608 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.579 (perp=7.646, rec=0.059, cos=-0.009), tot_loss_proj:1.594 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.594 (perp=7.646, rec=0.074, cos=-0.009), tot_loss_proj:1.601 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.581 (perp=7.646, rec=0.061, cos=-0.009), tot_loss_proj:1.603 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.580 (perp=7.646, rec=0.060, cos=-0.009), tot_loss_proj:1.596 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.584 (perp=7.646, rec=0.064, cos=-0.009), tot_loss_proj:1.607 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.574 (perp=7.646, rec=0.054, cos=-0.009), tot_loss_proj:1.586 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.578 (perp=7.646, rec=0.058, cos=-0.009), tot_loss_proj:1.588 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.568 (perp=7.646, rec=0.048, cos=-0.009), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.646, rec=0.064, cos=-0.009), tot_loss_proj:1.599 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.576 (perp=7.646, rec=0.057, cos=-0.009), tot_loss_proj:1.581 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.646, rec=0.067, cos=-0.009), tot_loss_proj:1.602 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.574 (perp=7.646, rec=0.054, cos=-0.009), tot_loss_proj:1.590 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.593 (perp=7.646, rec=0.073, cos=-0.009), tot_loss_proj:1.592 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.582 (perp=7.646, rec=0.062, cos=-0.009), tot_loss_proj:1.579 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.577 (perp=7.646, rec=0.057, cos=-0.009), tot_loss_proj:1.598 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.584 (perp=7.646, rec=0.064, cos=-0.009), tot_loss_proj:1.595 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.580 (perp=7.646, rec=0.060, cos=-0.009), tot_loss_proj:1.605 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.583 (perp=7.646, rec=0.063, cos=-0.009), tot_loss_proj:1.596 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.646, rec=0.065, cos=-0.009), tot_loss_proj:1.597 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.587 (perp=7.646, rec=0.068, cos=-0.009), tot_loss_proj:1.595 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.575 (perp=7.646, rec=0.055, cos=-0.009), tot_loss_proj:1.592 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.567 (perp=7.646, rec=0.047, cos=-0.009), tot_loss_proj:1.600 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.646, rec=0.067, cos=-0.009), tot_loss_proj:1.610 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.588 (perp=7.646, rec=0.068, cos=-0.009), tot_loss_proj:1.594 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.568 (perp=7.646, rec=0.048, cos=-0.009), tot_loss_proj:1.594 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.582 (perp=7.646, rec=0.062, cos=-0.009), tot_loss_proj:1.588 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.575 (perp=7.646, rec=0.055, cos=-0.009), tot_loss_proj:1.591 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.592 (perp=7.646, rec=0.072, cos=-0.009), tot_loss_proj:1.594 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.568 (perp=7.646, rec=0.048, cos=-0.009), tot_loss_proj:1.577 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.582 (perp=7.646, rec=0.062, cos=-0.009), tot_loss_proj:1.585 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.568 (perp=7.646, rec=0.048, cos=-0.009), tot_loss_proj:1.589 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.646, rec=0.063, cos=-0.009), tot_loss_proj:1.590 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.573 (perp=7.646, rec=0.054, cos=-0.009), tot_loss_proj:1.566 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.585 (perp=7.646, rec=0.065, cos=-0.009), tot_loss_proj:1.583 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.580 (perp=7.646, rec=0.060, cos=-0.009), tot_loss_proj:1.598 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.936 | p: 87.274 | r: 88.716
rouge2     | fm: 53.897 | p: 53.636 | r: 54.241
rougeL     | fm: 76.452 | p: 75.959 | r: 77.027
rougeLsum  | fm: 76.301 | p: 75.799 | r: 76.903
r1fm+r2fm = 141.833

input #92 time: 0:11:01 | total time: 16:06:59


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
*********************************
*********************************
average of cosine similarity 0.9993323263895036
highest_index [0]
highest [0.9993323263895036]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0078084468841553 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8302108645439148 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8220402598381042 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8074820637702942 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8070929646492004 for ['[CLS]ball lad specific shrinking judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.807031512260437 for ['[CLS] lad specific shrinkingball judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.806305468082428 for ['[CLS] lad shrinkingball solo 1970s judicial specific [SEP]']
[Init] best perm rec loss: 0.8061965107917786 for ['[CLS] solo 1970s shrinkingball lad judicial specific [SEP]']
[Init] best perm rec loss: 0.8059419989585876 for ['[CLS] 1970s specificball shrinking judicial lad solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.255 (perp=12.634, rec=0.733, cos=-0.005), tot_loss_proj:3.993 [t=0.26s]
prediction: ['[CLS] security insufficient organization specification oldÊŠ listening [SEP]']
[ 100/2000] tot_loss=3.600 (perp=14.870, rec=0.628, cos=-0.003), tot_loss_proj:4.865 [t=0.27s]
prediction: ['[CLS]flict says nfl specification old tatum unlike [SEP]']
[ 150/2000] tot_loss=3.591 (perp=14.652, rec=0.654, cos=0.007), tot_loss_proj:4.712 [t=0.25s]
prediction: ['[CLS] recurring replied pga funny understandingÎ¿Ï‚ unlike [SEP]']
[ 200/2000] tot_loss=3.358 (perp=13.430, rec=0.669, cos=0.003), tot_loss_proj:4.481 [t=0.25s]
prediction: ['[CLS] puts saysional idea wayÎ¿Ï‚ tobacco [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.213 (perp=12.869, rec=0.625, cos=0.014), tot_loss_proj:4.574 [t=0.27s]
prediction: ['[CLS] idea stainless funny pga wayÎ¿Ï‚ tobacco [SEP]']
[ 300/2000] tot_loss=2.884 (perp=11.718, rec=0.544, cos=-0.003), tot_loss_proj:3.226 [t=0.26s]
prediction: ['[CLS] idea stainless funny pga way how funny [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.832 (perp=11.599, rec=0.518, cos=-0.006), tot_loss_proj:3.297 [t=0.26s]
prediction: ['[CLS] idea clinic funny pga way how funny [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.024 (perp=12.356, rec=0.557, cos=-0.004), tot_loss_proj:3.251 [t=0.26s]
prediction: ['[CLS] pga way funny according funny how music [SEP]']
[ 450/2000] tot_loss=2.715 (perp=10.872, rec=0.533, cos=0.007), tot_loss_proj:2.771 [t=0.27s]
prediction: ['[CLS] pga way funny clinic way how funny [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.607 (perp=10.544, rec=0.503, cos=-0.005), tot_loss_proj:4.033 [t=0.25s]
prediction: ['[CLS] pga way privately funny way past funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.608 (perp=10.544, rec=0.500, cos=-0.001), tot_loss_proj:4.038 [t=0.26s]
prediction: ['[CLS] pga way privately funny way past funny [SEP]']
[ 600/2000] tot_loss=2.612 (perp=10.544, rec=0.493, cos=0.011), tot_loss_proj:4.040 [t=0.26s]
prediction: ['[CLS] pga way privately funny way past funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.585 (perp=10.544, rec=0.478, cos=-0.002), tot_loss_proj:4.037 [t=0.26s]
prediction: ['[CLS] pga way privately funny way past funny [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.546 (perp=10.372, rec=0.479, cos=-0.008), tot_loss_proj:3.764 [t=0.26s]
prediction: ['[CLS] pga way without way funny ways funny [SEP]']
[ 750/2000] tot_loss=2.540 (perp=10.372, rec=0.473, cos=-0.007), tot_loss_proj:3.766 [t=0.25s]
prediction: ['[CLS] pga way without way funny ways funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.539 (perp=10.372, rec=0.472, cos=-0.008), tot_loss_proj:3.764 [t=0.26s]
prediction: ['[CLS] pga way without way funny ways funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.526 (perp=10.372, rec=0.461, cos=-0.009), tot_loss_proj:3.760 [t=0.25s]
prediction: ['[CLS] pga way without way funny ways funny [SEP]']
[ 900/2000] tot_loss=2.328 (perp=9.360, rec=0.459, cos=-0.003), tot_loss_proj:3.797 [t=0.27s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.317 (perp=9.360, rec=0.452, cos=-0.007), tot_loss_proj:3.792 [t=0.26s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
Attempt swap
[1000/2000] tot_loss=2.316 (perp=9.360, rec=0.454, cos=-0.010), tot_loss_proj:3.795 [t=0.25s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
[1050/2000] tot_loss=2.327 (perp=9.360, rec=0.462, cos=-0.008), tot_loss_proj:3.795 [t=0.26s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
Attempt swap
[1100/2000] tot_loss=2.318 (perp=9.360, rec=0.456, cos=-0.010), tot_loss_proj:3.796 [t=0.25s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
Attempt swap
[1150/2000] tot_loss=2.312 (perp=9.360, rec=0.445, cos=-0.005), tot_loss_proj:3.798 [t=0.26s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
[1200/2000] tot_loss=2.355 (perp=9.360, rec=0.452, cos=0.031), tot_loss_proj:3.801 [t=0.26s]
prediction: ['[CLS] pga way without way funny how funny [SEP]']
Attempt swap
[1250/2000] tot_loss=2.388 (perp=9.742, rec=0.450, cos=-0.010), tot_loss_proj:3.627 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1300/2000] tot_loss=2.382 (perp=9.742, rec=0.443, cos=-0.010), tot_loss_proj:3.629 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
[1350/2000] tot_loss=2.386 (perp=9.742, rec=0.447, cos=-0.009), tot_loss_proj:3.630 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1400/2000] tot_loss=2.383 (perp=9.742, rec=0.441, cos=-0.007), tot_loss_proj:3.628 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1450/2000] tot_loss=2.378 (perp=9.742, rec=0.440, cos=-0.010), tot_loss_proj:3.630 [t=0.26s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
[1500/2000] tot_loss=2.375 (perp=9.742, rec=0.437, cos=-0.010), tot_loss_proj:3.629 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1550/2000] tot_loss=2.379 (perp=9.742, rec=0.441, cos=-0.010), tot_loss_proj:3.627 [t=0.26s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1600/2000] tot_loss=2.380 (perp=9.742, rec=0.442, cos=-0.010), tot_loss_proj:3.627 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
[1650/2000] tot_loss=2.378 (perp=9.742, rec=0.440, cos=-0.010), tot_loss_proj:3.626 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1700/2000] tot_loss=2.382 (perp=9.742, rec=0.443, cos=-0.010), tot_loss_proj:3.631 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1750/2000] tot_loss=2.376 (perp=9.742, rec=0.438, cos=-0.010), tot_loss_proj:3.631 [t=0.26s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
[1800/2000] tot_loss=2.376 (perp=9.742, rec=0.438, cos=-0.010), tot_loss_proj:3.624 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1850/2000] tot_loss=2.376 (perp=9.742, rec=0.438, cos=-0.010), tot_loss_proj:3.627 [t=0.26s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[1900/2000] tot_loss=2.373 (perp=9.742, rec=0.435, cos=-0.010), tot_loss_proj:3.627 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
[1950/2000] tot_loss=2.373 (perp=9.742, rec=0.434, cos=-0.010), tot_loss_proj:3.627 [t=0.27s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Attempt swap
[2000/2000] tot_loss=2.373 (perp=9.742, rec=0.435, cos=-0.010), tot_loss_proj:3.625 [t=0.25s]
prediction: ['[CLS] pga way without way understanding how funny [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] pga way without way understanding how funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 55.556 | r: 62.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.059 | p: 44.444 | r: 50.000
rougeLsum  | fm: 47.059 | p: 44.444 | r: 50.000
r1fm+r2fm = 58.824

[Aggregate metrics]:
rouge1     | fm: 87.637 | p: 86.977 | r: 88.439
rouge2     | fm: 53.300 | p: 53.022 | r: 53.660
rougeL     | fm: 76.089 | p: 75.529 | r: 76.719
rougeLsum  | fm: 76.037 | p: 75.460 | r: 76.675
r1fm+r2fm = 140.937

input #93 time: 0:10:59 | total time: 16:17:58


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
*********************************
*********************************
average of cosine similarity 0.9993168061064918
highest_index [0]
highest [0.9993168061064918]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9727807641029358 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9545496106147766 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9148076176643372 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9085803627967834 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8869084715843201 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8795130848884583 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.879210889339447 for ['[CLS] internal plum rockwell expedition crushed flowering shocks territorialventing chronic centre [SEP]']
[Init] best perm rec loss: 0.8783528804779053 for ['[CLS] internalventing territorial shocks expedition centre crushed plum flowering chronic rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.684 (perp=11.198, rec=0.448, cos=-0.004), tot_loss_proj:3.055 [t=0.25s]
prediction: ['[CLS] radio game banas pileit kills bug processing nor statements [SEP]']
[ 100/2000] tot_loss=2.435 (perp=10.576, rec=0.328, cos=-0.008), tot_loss_proj:2.859 [t=0.26s]
prediction: ['[CLS] extra division neitheric cubans illegal neither sherlock nor funny [SEP]']
[ 150/2000] tot_loss=2.153 (perp=9.765, rec=0.209, cos=-0.008), tot_loss_proj:2.575 [t=0.26s]
prediction: ['[CLS] as yao neither a cape of palestinian neither original nor funny [SEP]']
[ 200/2000] tot_loss=2.104 (perp=9.785, rec=0.156, cos=-0.009), tot_loss_proj:2.541 [t=0.25s]
prediction: ['[CLS] as yao neither a caperthic neither original nor funny [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.965 (perp=9.042, rec=0.164, cos=-0.008), tot_loss_proj:2.344 [t=0.25s]
prediction: ['[CLS] a s neither original cape neither a caper nor funny [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.579, rec=0.129, cos=-0.009), tot_loss_proj:2.186 [t=0.25s]
prediction: ['[CLS] a s neither original cape terribly a caper nor funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.696 (perp=7.958, rec=0.114, cos=-0.009), tot_loss_proj:2.044 [t=0.27s]
prediction: ['[CLS] s neither original a s terribly a caper nor funny [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.513 (perp=7.097, rec=0.103, cos=-0.009), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS] s neither terribly original a s a caper nor funny [SEP]']
[ 450/2000] tot_loss=1.626 (perp=7.763, rec=0.082, cos=-0.009), tot_loss_proj:2.008 [t=0.28s]
prediction: ['[CLS] s neither terribly original that s a caper nor funny [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.556 (perp=7.423, rec=0.081, cos=-0.009), tot_loss_proj:1.856 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.547 (perp=7.423, rec=0.072, cos=-0.010), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[ 600/2000] tot_loss=1.543 (perp=7.423, rec=0.068, cos=-0.010), tot_loss_proj:1.855 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.548 (perp=7.423, rec=0.073, cos=-0.010), tot_loss_proj:1.863 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.554 (perp=7.423, rec=0.079, cos=-0.010), tot_loss_proj:1.862 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[ 750/2000] tot_loss=1.545 (perp=7.423, rec=0.070, cos=-0.010), tot_loss_proj:1.859 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.539 (perp=7.423, rec=0.064, cos=-0.010), tot_loss_proj:1.855 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.545 (perp=7.423, rec=0.070, cos=-0.010), tot_loss_proj:1.854 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[ 900/2000] tot_loss=1.542 (perp=7.423, rec=0.067, cos=-0.010), tot_loss_proj:1.858 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.539 (perp=7.423, rec=0.064, cos=-0.010), tot_loss_proj:1.858 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.535 (perp=7.423, rec=0.059, cos=-0.010), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1050/2000] tot_loss=1.542 (perp=7.423, rec=0.067, cos=-0.010), tot_loss_proj:1.854 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.538 (perp=7.423, rec=0.063, cos=-0.010), tot_loss_proj:1.861 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.547 (perp=7.423, rec=0.072, cos=-0.010), tot_loss_proj:1.856 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1200/2000] tot_loss=1.549 (perp=7.423, rec=0.074, cos=-0.010), tot_loss_proj:1.856 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.537 (perp=7.423, rec=0.062, cos=-0.010), tot_loss_proj:1.859 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.539 (perp=7.423, rec=0.064, cos=-0.010), tot_loss_proj:1.861 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1350/2000] tot_loss=1.545 (perp=7.423, rec=0.070, cos=-0.010), tot_loss_proj:1.857 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.546 (perp=7.423, rec=0.070, cos=-0.010), tot_loss_proj:1.858 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.551 (perp=7.423, rec=0.076, cos=-0.010), tot_loss_proj:1.859 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1500/2000] tot_loss=1.541 (perp=7.423, rec=0.066, cos=-0.010), tot_loss_proj:1.859 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.546 (perp=7.423, rec=0.071, cos=-0.010), tot_loss_proj:1.863 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.550 (perp=7.423, rec=0.075, cos=-0.010), tot_loss_proj:1.867 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.423, rec=0.081, cos=-0.010), tot_loss_proj:1.857 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=7.423, rec=0.069, cos=-0.010), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.543 (perp=7.423, rec=0.068, cos=-0.010), tot_loss_proj:1.856 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1800/2000] tot_loss=1.537 (perp=7.423, rec=0.062, cos=-0.010), tot_loss_proj:1.860 [t=0.27s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.535 (perp=7.423, rec=0.060, cos=-0.010), tot_loss_proj:1.859 [t=0.26s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.536 (perp=7.423, rec=0.061, cos=-0.010), tot_loss_proj:1.859 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
[1950/2000] tot_loss=1.540 (perp=7.423, rec=0.065, cos=-0.010), tot_loss_proj:1.865 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.541 (perp=7.423, rec=0.066, cos=-0.010), tot_loss_proj:1.853 [t=0.25s]
prediction: ['[CLS]r that s neither terribly original a caper nor funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS]r that s neither terribly original a caper nor funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 87.675 | p: 86.966 | r: 88.477
rouge2     | fm: 53.125 | p: 52.830 | r: 53.479
rougeL     | fm: 76.006 | p: 75.452 | r: 76.650
rougeLsum  | fm: 76.075 | p: 75.500 | r: 76.682
r1fm+r2fm = 140.800

input #94 time: 0:10:54 | total time: 16:28:53


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
*********************************
*********************************
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9695915579795837 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9447000622749329 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9425680041313171 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9293648600578308 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9289979338645935 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9244387745857239 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.8965775966644287 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8573101758956909 for ['[CLS] pressure ] completenne damp trailer block wireÛ’ tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8477544188499451 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterÛ’ pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8469237089157104 for ['[CLS] cut pressure ]Û’ wire complete sister block monty hanging damp tech trailer privatenne [SEP]']
[Init] best perm rec loss: 0.8467367887496948 for ['[CLS] wireÛ’ pressure ] damp trailer cut private block sister complete hanging tech montynne [SEP]']
[Init] best perm rec loss: 0.8459979295730591 for ['[CLS] complete trailer pressure private damp sister hanging wire block monty cutnneÛ’ ] tech [SEP]']
[Init] best perm rec loss: 0.8446309566497803 for ['[CLS] sister damp trailer cut private monty complete pressure tech wire hangingÛ’ ] blocknne [SEP]']
[Init] best perm rec loss: 0.8437495231628418 for ['[CLS]Û’ ] wire tech private pressure trailer monty completenne cut block damp sister hanging [SEP]']
[Init] best perm rec loss: 0.8430407643318176 for ['[CLS] trailer sister wire monty blockÛ’ hanging private cut complete pressure damp ] technne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.588 (perp=11.319, rec=0.330, cos=-0.006), tot_loss_proj:3.082 [t=0.26s]
prediction: ['[CLS] badly collapse victims worst rate a hopeless private victim or its might hopeless worm unsuccessful [SEP]']
[ 100/2000] tot_loss=2.827 (perp=13.023, rec=0.231, cos=-0.008), tot_loss_proj:3.161 [t=0.26s]
prediction: ['[CLS] an shell money worst became became hopeless thinown hopeless, hopeless hopelessbook hopeless [SEP]']
[ 150/2000] tot_loss=2.785 (perp=13.075, rec=0.179, cos=-0.009), tot_loss_proj:3.125 [t=0.26s]
prediction: ['[CLS] an shell equipment sad became becomes hopelesssatdle hopeless, hopeless hopeless storydle [SEP]']
[ 200/2000] tot_loss=2.296 (perp=10.777, rec=0.150, cos=-0.009), tot_loss_proj:2.601 [t=0.26s]
prediction: ['[CLS] " mud clothing\'becomes a hopelesssatdle hopeless, hopelesseased storydle [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.168 (perp=10.120, rec=0.152, cos=-0.009), tot_loss_proj:2.532 [t=0.25s]
prediction: ["[CLS] ('' becomes a hopeless mudsatdle hopeless,fying denis storydle [SEP]"]
[ 300/2000] tot_loss=2.155 (perp=10.197, rec=0.124, cos=-0.009), tot_loss_proj:2.560 [t=0.25s]
prediction: ["[CLS] ('' becomes a hopeless mudsatdlesat,fying denis storydle [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.030 (perp=9.709, rec=0.097, cos=-0.009), tot_loss_proj:2.419 [t=0.26s]
prediction: ["[CLS] ('sat ) becomes a hopeless muddlesat,fying denis storydle [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.927 (perp=9.171, rec=0.101, cos=-0.009), tot_loss_proj:2.258 [t=0.26s]
prediction: ["[CLS] ('sat ) becomes a hopeless muddlesatdlefying denis story, [SEP]"]
[ 450/2000] tot_loss=1.917 (perp=9.171, rec=0.092, cos=-0.009), tot_loss_proj:2.253 [t=0.28s]
prediction: ["[CLS] ('sat ) becomes a hopeless muddlesatdlefying denis story, [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.803 (perp=8.638, rec=0.085, cos=-0.009), tot_loss_proj:2.159 [t=0.28s]
prediction: ["[CLS] (sat )'becomes a hopeless muddlesatityfying denis story, [SEP]"]
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.581 (perp=7.539, rec=0.083, cos=-0.009), tot_loss_proj:1.897 [t=0.28s]
prediction: ["[CLS] (sat )'becomes a hopeless muddle un denisityfying story, [SEP]"]
[ 600/2000] tot_loss=1.560 (perp=7.475, rec=0.075, cos=-0.009), tot_loss_proj:1.859 [t=0.28s]
prediction: ["[CLS] (sat )'becomes a hopeless muddle un denisisfying story, [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.268 (perp=6.016, rec=0.074, cos=-0.009), tot_loss_proj:1.498 [t=0.28s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle unsatisfying story, [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.263 (perp=6.016, rec=0.069, cos=-0.009), tot_loss_proj:1.510 [t=0.28s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle unsatisfying story, [SEP]"]
[ 750/2000] tot_loss=1.258 (perp=6.016, rec=0.065, cos=-0.009), tot_loss_proj:1.503 [t=0.28s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle unsatisfying story, [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.196 (perp=5.650, rec=0.075, cos=-0.009), tot_loss_proj:1.429 [t=0.28s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.177 (perp=5.650, rec=0.056, cos=-0.009), tot_loss_proj:1.426 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
[ 900/2000] tot_loss=1.192 (perp=5.650, rec=0.071, cos=-0.009), tot_loss_proj:1.426 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.197 (perp=5.650, rec=0.076, cos=-0.009), tot_loss_proj:1.428 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.187 (perp=5.650, rec=0.066, cos=-0.009), tot_loss_proj:1.427 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
[1050/2000] tot_loss=1.188 (perp=5.650, rec=0.067, cos=-0.009), tot_loss_proj:1.427 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.189 (perp=5.650, rec=0.068, cos=-0.009), tot_loss_proj:1.423 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.189 (perp=5.650, rec=0.069, cos=-0.009), tot_loss_proj:1.420 [t=0.25s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
[1200/2000] tot_loss=1.192 (perp=5.650, rec=0.071, cos=-0.009), tot_loss_proj:1.423 [t=0.27s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.184 (perp=5.650, rec=0.063, cos=-0.009), tot_loss_proj:1.419 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.192 (perp=5.650, rec=0.071, cos=-0.009), tot_loss_proj:1.419 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
[1350/2000] tot_loss=1.190 (perp=5.650, rec=0.069, cos=-0.009), tot_loss_proj:1.422 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.190 (perp=5.650, rec=0.069, cos=-0.009), tot_loss_proj:1.424 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.187 (perp=5.650, rec=0.066, cos=-0.009), tot_loss_proj:1.424 [t=0.28s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
[1500/2000] tot_loss=1.189 (perp=5.650, rec=0.069, cos=-0.009), tot_loss_proj:1.424 [t=0.26s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.188 (perp=5.650, rec=0.067, cos=-0.009), tot_loss_proj:1.423 [t=0.27s]
prediction: ["[CLS] ( denis )'becomes a hopeless muddle, unsatisfying story [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.130 (perp=5.260, rec=0.087, cos=-0.009), tot_loss_proj:1.297 [t=0.28s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
[1650/2000] tot_loss=1.120 (perp=5.260, rec=0.077, cos=-0.009), tot_loss_proj:1.304 [t=0.25s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.113 (perp=5.260, rec=0.071, cos=-0.009), tot_loss_proj:1.305 [t=0.26s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.112 (perp=5.260, rec=0.069, cos=-0.009), tot_loss_proj:1.299 [t=0.26s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
[1800/2000] tot_loss=1.108 (perp=5.260, rec=0.065, cos=-0.009), tot_loss_proj:1.303 [t=0.28s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.114 (perp=5.260, rec=0.072, cos=-0.009), tot_loss_proj:1.306 [t=0.26s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.120 (perp=5.260, rec=0.077, cos=-0.009), tot_loss_proj:1.296 [t=0.25s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
[1950/2000] tot_loss=1.100 (perp=5.260, rec=0.057, cos=-0.009), tot_loss_proj:1.305 [t=0.27s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.091 (perp=5.260, rec=0.048, cos=-0.009), tot_loss_proj:1.301 [t=0.25s]
prediction: ["[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( denis )'story becomes a hopeless muddle, unsatisfying [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 87.846 | p: 87.154 | r: 88.661
rouge2     | fm: 53.342 | p: 52.972 | r: 53.711
rougeL     | fm: 76.229 | p: 75.664 | r: 76.853
rougeLsum  | fm: 76.103 | p: 75.529 | r: 76.769
r1fm+r2fm = 141.188

input #95 time: 0:11:11 | total time: 16:40:05


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
*********************************
*********************************
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8909018635749817 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8791100382804871 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8585579991340637 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8257309794425964 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8243802189826965 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 0.8242563605308533 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8184889554977417 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade Î² [SEP]']
[Init] best rec loss: 0.8130791187286377 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7910962700843811 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7895482182502747 for ['[CLS] wig memoir pondered save august typical smashwords statue sounding projectile spent era livinggn time [SEP]']
[Init] best perm rec loss: 0.7892841100692749 for ['[CLS] living statue sounding eragn pondered smashwords typical projectile time spent save august memoir wig [SEP]']
[Init] best perm rec loss: 0.7874389290809631 for ['[CLS] typical living save sounding wig smashwords august statue time spent projectile era ponderedgn memoir [SEP]']
[Init] best perm rec loss: 0.7851721048355103 for ['[CLS] typical era spent statue smashwords memoir wig sounding august timegn save living pondered projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.180 (perp=14.006, rec=0.386, cos=-0.008), tot_loss_proj:4.045 [t=0.26s]
prediction: ['[CLS] authority worthy spent medley memorial in exercisediscorp mitchell lacey would human grasp father [SEP]']
[ 100/2000] tot_loss=2.573 (perp=11.378, rec=0.304, cos=-0.006), tot_loss_proj:3.435 [t=0.26s]
prediction: ['[CLS] authority worthy honor medley 11 into person, around australia wallet made people force father [SEP]']
[ 150/2000] tot_loss=2.736 (perp=12.442, rec=0.256, cos=-0.008), tot_loss_proj:4.146 [t=0.26s]
prediction: ['[CLS] authority cover originally medley abbey into simply for around australia wallet upon people force himself [SEP]']
[ 200/2000] tot_loss=2.480 (perp=11.284, rec=0.232, cos=-0.009), tot_loss_proj:3.738 [t=0.26s]
prediction: ['[CLS] authority cover originally situations territory into simply and around himselflik lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.537 (perp=11.305, rec=0.275, cos=0.002), tot_loss_proj:3.559 [t=0.27s]
prediction: ['[CLS] cover authority anthony washington alaska into others and on manner wallet lesser men force himself [SEP]']
[ 300/2000] tot_loss=2.173 (perp=9.935, rec=0.195, cos=-0.009), tot_loss_proj:3.670 [t=0.26s]
prediction: ['[CLS] cover situations or jumped upon into other, on into wallet lesser men force himself [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.010 (perp=9.184, rec=0.182, cos=-0.009), tot_loss_proj:3.199 [t=0.27s]
prediction: ['[CLS] cover or jumped upon into others situations, on into would lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.902 (perp=8.742, rec=0.162, cos=-0.009), tot_loss_proj:3.078 [t=0.26s]
prediction: ['[CLS] others and jumped upon into cover situations, on into would lesser men force himself [SEP]']
[ 450/2000] tot_loss=1.944 (perp=9.000, rec=0.154, cos=-0.009), tot_loss_proj:3.108 [t=0.25s]
prediction: ['[CLS] others and jumped into into cover situations that on into would lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.750 (perp=8.079, rec=0.144, cos=-0.010), tot_loss_proj:2.851 [t=0.28s]
prediction: ['[CLS] others that jumped into into cover situations and on into would lesser men force himself [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.652 (perp=7.563, rec=0.149, cos=-0.009), tot_loss_proj:2.603 [t=0.25s]
prediction: ['[CLS] others that jumped into on and into cover situations and would lesser men force himself [SEP]']
[ 600/2000] tot_loss=1.705 (perp=7.882, rec=0.139, cos=-0.009), tot_loss_proj:2.544 [t=0.26s]
prediction: ['[CLS] person that jumped into on and into cover situations and would lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.638 (perp=7.556, rec=0.136, cos=-0.010), tot_loss_proj:2.718 [t=0.25s]
prediction: ['[CLS] that others jumped into on and into cover situations and would lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.598 (perp=7.418, rec=0.124, cos=-0.009), tot_loss_proj:2.764 [t=0.25s]
prediction: ['[CLS] and others jumped at on and into cover situations that would lesser men force himself [SEP]']
[ 750/2000] tot_loss=1.591 (perp=7.387, rec=0.123, cos=-0.010), tot_loss_proj:2.670 [t=0.26s]
prediction: ['[CLS] for others jumped at on and into cover situations that would lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.563 (perp=7.248, rec=0.123, cos=-0.010), tot_loss_proj:2.819 [t=0.28s]
prediction: ['[CLS] others for jumped at on and into cover situations that would lesser men force himself [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.598 (perp=7.434, rec=0.120, cos=-0.010), tot_loss_proj:2.629 [t=0.28s]
prediction: ['[CLS] people for jumped on on and into cover situations that would lesser men force himself [SEP]']
[ 900/2000] tot_loss=1.688 (perp=7.947, rec=0.108, cos=-0.010), tot_loss_proj:2.774 [t=0.26s]
prediction: ['[CLS] people for situations on on and into cover situations that would lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.581 (perp=7.366, rec=0.118, cos=-0.010), tot_loss_proj:2.336 [t=0.27s]
prediction: ['[CLS] people force situations on on and into cover situations that would lesser men for himself [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.766 (perp=8.258, rec=0.124, cos=-0.009), tot_loss_proj:3.441 [t=0.28s]
prediction: ['[CLS] worse force situations on on and into cover situations would cover lesser men for himself [SEP]']
[1050/2000] tot_loss=1.782 (perp=8.370, rec=0.118, cos=-0.010), tot_loss_proj:3.430 [t=0.26s]
prediction: ['[CLS] worse force situations people on and into cover situations would cover lesser men for himself [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.756 (perp=8.258, rec=0.113, cos=-0.010), tot_loss_proj:3.438 [t=0.26s]
prediction: ['[CLS] worse force situations on on and into cover situations would cover lesser men for himself [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.665 (perp=7.831, rec=0.109, cos=-0.009), tot_loss_proj:3.246 [t=0.27s]
prediction: ['[CLS] worse force situations on cover and into cover situations would on lesser men for himself [SEP]']
[1200/2000] tot_loss=1.667 (perp=7.831, rec=0.110, cos=-0.010), tot_loss_proj:3.248 [t=0.26s]
prediction: ['[CLS] worse force situations on cover and into cover situations would on lesser men for himself [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.683 (perp=7.892, rec=0.114, cos=-0.010), tot_loss_proj:2.969 [t=0.28s]
prediction: ['[CLS] on force situations on cover and into cover situations would people lesser men for himself [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.597 (perp=7.505, rec=0.105, cos=-0.010), tot_loss_proj:2.437 [t=0.27s]
prediction: ['[CLS] people force situations on cover and into cover situations would on lesser men for himself [SEP]']
[1350/2000] tot_loss=1.610 (perp=7.505, rec=0.119, cos=-0.010), tot_loss_proj:2.443 [t=0.26s]
prediction: ['[CLS] people force situations on cover and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1400/2000] tot_loss=1.602 (perp=7.505, rec=0.110, cos=-0.010), tot_loss_proj:2.442 [t=0.27s]
prediction: ['[CLS] people force situations on cover and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1450/2000] tot_loss=1.607 (perp=7.505, rec=0.115, cos=-0.010), tot_loss_proj:2.442 [t=0.27s]
prediction: ['[CLS] people force situations on cover and into cover situations would on lesser men for himself [SEP]']
[1500/2000] tot_loss=1.608 (perp=7.505, rec=0.117, cos=-0.010), tot_loss_proj:2.436 [t=0.25s]
prediction: ['[CLS] people force situations on cover and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1550/2000] tot_loss=1.596 (perp=7.505, rec=0.104, cos=-0.010), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] people force situations on cover and into cover situations would on lesser men for himself [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.587 (perp=7.463, rec=0.104, cos=-0.009), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
[1650/2000] tot_loss=1.596 (perp=7.463, rec=0.112, cos=-0.010), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1700/2000] tot_loss=1.589 (perp=7.463, rec=0.106, cos=-0.010), tot_loss_proj:2.522 [t=0.27s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1750/2000] tot_loss=1.592 (perp=7.463, rec=0.109, cos=-0.010), tot_loss_proj:2.517 [t=0.27s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
[1800/2000] tot_loss=1.597 (perp=7.463, rec=0.114, cos=-0.010), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1850/2000] tot_loss=1.602 (perp=7.463, rec=0.119, cos=-0.010), tot_loss_proj:2.520 [t=0.27s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.594 (perp=7.463, rec=0.111, cos=-0.010), tot_loss_proj:2.522 [t=0.26s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
[1950/2000] tot_loss=1.592 (perp=7.463, rec=0.109, cos=-0.010), tot_loss_proj:2.521 [t=0.27s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.463, rec=0.104, cos=-0.010), tot_loss_proj:2.519 [t=0.27s]
prediction: ['[CLS] people force on cover situations and into cover situations would on lesser men for himself [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] worse force situations on cover and into cover situations would on lesser men for himself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.471 | p: 76.471 | r: 76.471
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 64.706 | p: 64.706 | r: 64.706
rougeLsum  | fm: 64.706 | p: 64.706 | r: 64.706
r1fm+r2fm = 88.971

[Aggregate metrics]:
rouge1     | fm: 87.748 | p: 87.061 | r: 88.514
rouge2     | fm: 52.889 | p: 52.577 | r: 53.213
rougeL     | fm: 75.996 | p: 75.482 | r: 76.641
rougeLsum  | fm: 76.034 | p: 75.472 | r: 76.639
r1fm+r2fm = 140.638

input #96 time: 0:11:04 | total time: 16:51:09


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
*********************************
*********************************
average of cosine similarity 0.9991660915875737
highest_index [0]
highest [0.9991660915875737]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8396337628364563 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8173046708106995 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8006014823913574 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7802342772483826 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7502726316452026 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7448185682296753 for ['[CLS] working perfectet 140 cam channel [SEP]']
[Init] best perm rec loss: 0.7447396516799927 for ['[CLS] channel cam perfect working 140et [SEP]']
[Init] best perm rec loss: 0.7446287870407104 for ['[CLS] cam channel perfect workinget 140 [SEP]']
[Init] best perm rec loss: 0.7441828846931458 for ['[CLS] cam perfect working 140et channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.278 (perp=9.168, rec=0.442, cos=0.003), tot_loss_proj:2.977 [t=0.26s]
prediction: ['[CLS] any unique global culture action unique [SEP]']
[ 100/2000] tot_loss=2.935 (perp=13.178, rec=0.306, cos=-0.007), tot_loss_proj:3.634 [t=0.26s]
prediction: ['[CLS]get changed global touch action artists [SEP]']
[ 150/2000] tot_loss=2.525 (perp=11.464, rec=0.238, cos=-0.007), tot_loss_proj:3.677 [t=0.27s]
prediction: ['[CLS]gettableforerenceget phenomenon [SEP]']
[ 200/2000] tot_loss=2.233 (perp=10.235, rec=0.194, cos=-0.008), tot_loss_proj:3.420 [t=0.26s]
prediction: ['[CLS]gettable untableget and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.987 (perp=9.019, rec=0.190, cos=-0.006), tot_loss_proj:2.425 [t=0.26s]
prediction: ['[CLS]fortable ungettable and [SEP]']
[ 300/2000] tot_loss=1.945 (perp=9.019, rec=0.149, cos=-0.007), tot_loss_proj:2.468 [t=0.27s]
prediction: ['[CLS]fortable ungettable and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.113 (perp=9.944, rec=0.132, cos=-0.008), tot_loss_proj:3.193 [t=0.25s]
prediction: ['[CLS] untableforget characters and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.211 (perp=5.520, rec=0.115, cos=-0.008), tot_loss_proj:1.291 [t=0.27s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 450/2000] tot_loss=1.187 (perp=5.520, rec=0.092, cos=-0.009), tot_loss_proj:1.296 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.184 (perp=5.520, rec=0.089, cos=-0.009), tot_loss_proj:1.290 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.183 (perp=5.514, rec=0.089, cos=-0.009), tot_loss_proj:1.370 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.174 (perp=5.514, rec=0.081, cos=-0.009), tot_loss_proj:1.374 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.171 (perp=5.514, rec=0.078, cos=-0.009), tot_loss_proj:1.376 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.165 (perp=5.514, rec=0.072, cos=-0.009), tot_loss_proj:1.372 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.169 (perp=5.514, rec=0.076, cos=-0.009), tot_loss_proj:1.371 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.162 (perp=5.514, rec=0.069, cos=-0.009), tot_loss_proj:1.378 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.172 (perp=5.520, rec=0.077, cos=-0.009), tot_loss_proj:1.283 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 900/2000] tot_loss=1.167 (perp=5.520, rec=0.072, cos=-0.009), tot_loss_proj:1.284 [t=0.27s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.161 (perp=5.514, rec=0.067, cos=-0.009), tot_loss_proj:1.380 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.157 (perp=5.514, rec=0.064, cos=-0.009), tot_loss_proj:1.379 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.166 (perp=5.514, rec=0.072, cos=-0.009), tot_loss_proj:1.375 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.164 (perp=5.520, rec=0.069, cos=-0.009), tot_loss_proj:1.272 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.153 (perp=5.520, rec=0.059, cos=-0.009), tot_loss_proj:1.282 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[1200/2000] tot_loss=1.167 (perp=5.520, rec=0.073, cos=-0.009), tot_loss_proj:1.294 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.164 (perp=5.520, rec=0.069, cos=-0.009), tot_loss_proj:1.281 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.173 (perp=5.520, rec=0.078, cos=-0.009), tot_loss_proj:1.287 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[1350/2000] tot_loss=1.158 (perp=5.520, rec=0.063, cos=-0.009), tot_loss_proj:1.288 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.162 (perp=5.520, rec=0.067, cos=-0.009), tot_loss_proj:1.286 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.162 (perp=5.520, rec=0.068, cos=-0.009), tot_loss_proj:1.288 [t=0.25s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[1500/2000] tot_loss=1.161 (perp=5.520, rec=0.066, cos=-0.009), tot_loss_proj:1.290 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.162 (perp=5.520, rec=0.067, cos=-0.009), tot_loss_proj:1.283 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.155 (perp=5.514, rec=0.061, cos=-0.009), tot_loss_proj:1.378 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.169 (perp=5.514, rec=0.076, cos=-0.009), tot_loss_proj:1.376 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.166 (perp=5.514, rec=0.073, cos=-0.009), tot_loss_proj:1.378 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.172 (perp=5.514, rec=0.078, cos=-0.009), tot_loss_proj:1.371 [t=0.25s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.146 (perp=5.514, rec=0.053, cos=-0.009), tot_loss_proj:1.377 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.164 (perp=5.520, rec=0.069, cos=-0.009), tot_loss_proj:1.292 [t=0.26s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.151 (perp=5.514, rec=0.057, cos=-0.009), tot_loss_proj:1.371 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.164 (perp=5.514, rec=0.070, cos=-0.009), tot_loss_proj:1.379 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.158 (perp=5.514, rec=0.064, cos=-0.009), tot_loss_proj:1.376 [t=0.26s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 87.864 | p: 87.170 | r: 88.649
rouge2     | fm: 52.816 | p: 52.491 | r: 53.200
rougeL     | fm: 76.083 | p: 75.519 | r: 76.757
rougeLsum  | fm: 76.008 | p: 75.480 | r: 76.670
r1fm+r2fm = 140.680

input #97 time: 0:11:01 | total time: 17:02:10


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
*********************************
*********************************
average of cosine similarity 0.9991916976323434
highest_index [0]
highest [0.9991916976323434]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7122125029563904 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7120754718780518 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.709286630153656 for ['[CLS] jed ada nos prohibited [SEP]']
[Init] best perm rec loss: 0.7076743245124817 for ['[CLS] prohibited nos ada jed [SEP]']
[Init] best perm rec loss: 0.7051839828491211 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.817 (perp=12.242, rec=0.359, cos=0.010), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] emptyfulful attachment [SEP]']
[ 100/2000] tot_loss=2.790 (perp=12.926, rec=0.211, cos=-0.006), tot_loss_proj:3.422 [t=0.26s]
prediction: ['[CLS] unfulful purchase [SEP]']
[ 150/2000] tot_loss=2.437 (perp=11.412, rec=0.162, cos=-0.007), tot_loss_proj:3.226 [t=0.25s]
prediction: ['[CLS] unllingful purchase [SEP]']
[ 200/2000] tot_loss=2.394 (perp=11.412, rec=0.120, cos=-0.009), tot_loss_proj:3.223 [t=0.25s]
prediction: ['[CLS] unllingful purchase [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.113 (perp=4.948, rec=0.131, cos=-0.008), tot_loss_proj:1.054 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.068 (perp=4.948, rec=0.088, cos=-0.009), tot_loss_proj:1.045 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.048 (perp=4.948, rec=0.068, cos=-0.009), tot_loss_proj:1.055 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.057 (perp=4.948, rec=0.077, cos=-0.010), tot_loss_proj:1.046 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.052 (perp=4.948, rec=0.072, cos=-0.010), tot_loss_proj:1.056 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.054 (perp=4.948, rec=0.074, cos=-0.010), tot_loss_proj:1.054 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.043 (perp=4.948, rec=0.063, cos=-0.010), tot_loss_proj:1.052 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.034 (perp=4.948, rec=0.054, cos=-0.010), tot_loss_proj:1.045 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.055 (perp=4.948, rec=0.075, cos=-0.010), tot_loss_proj:1.048 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.049 (perp=4.948, rec=0.069, cos=-0.010), tot_loss_proj:1.046 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.046 (perp=4.948, rec=0.066, cos=-0.010), tot_loss_proj:1.057 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.049 (perp=4.948, rec=0.069, cos=-0.010), tot_loss_proj:1.041 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.039 (perp=4.948, rec=0.059, cos=-0.010), tot_loss_proj:1.043 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.037 (perp=4.948, rec=0.057, cos=-0.010), tot_loss_proj:1.053 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.043 (perp=4.948, rec=0.063, cos=-0.010), tot_loss_proj:1.049 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.040 (perp=4.948, rec=0.061, cos=-0.010), tot_loss_proj:1.060 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.039 (perp=4.948, rec=0.059, cos=-0.010), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.039 (perp=4.948, rec=0.059, cos=-0.010), tot_loss_proj:1.040 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.050 (perp=4.948, rec=0.070, cos=-0.010), tot_loss_proj:1.061 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.046 (perp=4.948, rec=0.066, cos=-0.010), tot_loss_proj:1.041 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.048 (perp=4.948, rec=0.068, cos=-0.010), tot_loss_proj:1.042 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.044 (perp=4.948, rec=0.064, cos=-0.010), tot_loss_proj:1.046 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.037 (perp=4.948, rec=0.057, cos=-0.010), tot_loss_proj:1.053 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.047 (perp=4.948, rec=0.067, cos=-0.010), tot_loss_proj:1.049 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.033 (perp=4.948, rec=0.053, cos=-0.010), tot_loss_proj:1.052 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.041 (perp=4.948, rec=0.061, cos=-0.010), tot_loss_proj:1.047 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.042 (perp=4.948, rec=0.062, cos=-0.010), tot_loss_proj:1.041 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.034 (perp=4.948, rec=0.055, cos=-0.010), tot_loss_proj:1.042 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.036 (perp=4.948, rec=0.056, cos=-0.010), tot_loss_proj:1.054 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.041 (perp=4.948, rec=0.061, cos=-0.010), tot_loss_proj:1.043 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.042 (perp=4.948, rec=0.063, cos=-0.010), tot_loss_proj:1.045 [t=0.29s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.038 (perp=4.948, rec=0.058, cos=-0.010), tot_loss_proj:1.053 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.046 (perp=4.948, rec=0.066, cos=-0.010), tot_loss_proj:1.048 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.025 (perp=4.948, rec=0.045, cos=-0.010), tot_loss_proj:1.040 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.042 (perp=4.948, rec=0.062, cos=-0.010), tot_loss_proj:1.045 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.030 (perp=4.948, rec=0.050, cos=-0.010), tot_loss_proj:1.055 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.892 | p: 87.243 | r: 88.676
rouge2     | fm: 52.930 | p: 52.597 | r: 53.272
rougeL     | fm: 76.276 | p: 75.763 | r: 76.916
rougeLsum  | fm: 76.277 | p: 75.753 | r: 76.872
r1fm+r2fm = 140.822

input #98 time: 0:11:02 | total time: 17:13:13


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
*********************************
*********************************
average of cosine similarity 0.9993095816453156
highest_index [0]
highest [0.9993095816453156]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8722755908966064 for ['[CLS]tering aleØ¨Ø§Ø¯ were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8668547868728638 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8600996136665344 for ['[CLS] cabinet crash strike championáµ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8582916855812073 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8477660417556763 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8349575400352478 for ['[CLS] sealedâˆ’1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8292847275733948 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.823960542678833 for ['[CLS] claireËˆ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8212921023368835 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderËˆ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.820878267288208 for ['[CLS]Ëˆ ferns opposedaging actually orient taste earliest claire slight thunder ratings currently temps bet te distance whente cushion services bearing re barbie knowledgets garcia synonym harper still screens [MASK] dental forced himself right [SEP]']
[Init] best perm rec loss: 0.8208308815956116 for ['[CLS] knowledge ratings re synonym slight currently taste ferns claire actuallyËˆ forced garcia bet opposed screens right when orient himself thunder services temps earliest dental cushionts te still harperagingte distance barbie [MASK] bearing [SEP]']
[Init] best perm rec loss: 0.8205059766769409 for ['[CLS] cushionts garcia opposed distance ratings synonym thunder slight bearing ferns when services knowledge taste harper orient clairete forced bet [MASK] temps te currently actually re himself screensËˆ rightaging still earliest barbie dental [SEP]']
[Init] best perm rec loss: 0.8195905089378357 for ['[CLS] distance cushion knowledge right services re screens still claire orient dentalaging [MASK] garcia thunder harper synonym taste fernsËˆte forced barbie ratings tempsts bet actually when te bearing slight earliest opposed currently himself [SEP]']
[Init] best perm rec loss: 0.818151593208313 for ['[CLS] temps taste re fernsaging forced ratings dentalËˆ cushion right claire te garcia slight earliest thunder knowledge actually services himself harper bet screens still orient when [MASK] opposed synonym currently barbiete distance bearingts [SEP]']
[Init] best perm rec loss: 0.8180760741233826 for ['[CLS] ratingsËˆ claire thunder betts taste ferns temps garcia still re [MASK] himself slight cushion opposed actuallyte currently screensaging bearing te harper dental right orient services barbie forced distance earliest knowledge when synonym [SEP]']
[Init] best perm rec loss: 0.8174036741256714 for ['[CLS] opposed screens forcedagingts synonym earliest [MASK] garcia claire dental actually barbie orient currently harper thunder ferns slight bearing rete still right temps ratings when cushion te taste distance knowledge himself bet servicesËˆ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.756 (perp=12.010, rec=0.362, cos=-0.008), tot_loss_proj:3.174 [t=0.26s]
prediction: ['[CLS] mob stupid sanctions blame alternative or idiots were stupid test mouth prefecture ruined congress stupid death bombings damn. bargaining it - badly apparentlyed dump damage ruling chemical google crank, moines finland ass evans [SEP]']
[ 100/2000] tot_loss=2.668 (perp=11.849, rec=0.307, cos=-0.009), tot_loss_proj:3.102 [t=0.27s]
prediction: ["[CLS] thus stupid restrictions thorough alternative his Â£1 were fake bad film prefecture ruined owner putting death bomb'[SEP] tamil assing already unpleasantssing joke scientology ruling ] google tanks, walked fun ass oz [SEP]"]
[ 150/2000] tot_loss=2.381 (perp=10.690, rec=0.251, cos=-0.009), tot_loss_proj:2.852 [t=0.28s]
prediction: ["[CLS] thus nobody restrictions thorough but his idiots was an bad film prefecture wrong ownerxie death.'[SEP] [ dissing more leastssing filmho walked ] google that, walked fun ass planned [SEP]"]
[ 200/2000] tot_loss=2.837 (perp=12.014, rec=0.432, cos=0.002), tot_loss_proj:3.757 [t=0.27s]
prediction: ['[CLS] [SEP] russiansjo, a [SEP] idiot has rapper pest filmless? bmw anyway females.. [SEP] panama the [SEP] diego destroy album flouridae walked album comic that and walked fun [SEP] novels [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.776 (perp=12.117, rec=0.360, cos=-0.008), tot_loss_proj:4.020 [t=0.27s]
prediction: ['[CLS] [SEP] mostly (, the [SEP] fastest has originally sm [SEP] ;? indonesian russiansliga.. [SEP] offshore the [SEP] diego destroyssing flour genus walked ] identity that as walked fun [SEP] rivals [SEP]']
[ 300/2000] tot_loss=2.621 (perp=11.586, rec=0.312, cos=-0.008), tot_loss_proj:3.928 [t=0.26s]
prediction: ['[CLS] [SEP] lyrics (, but [SEP] fun has german sm [SEP] ;?aging russiansliga.. [SEP] offshore the [SEP] diego idiotsssing flour genus walked ] creative that as walked fun [SEP] films [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.588 (perp=11.584, rec=0.280, cos=-0.009), tot_loss_proj:3.988 [t=0.26s]
prediction: ['[CLS] [SEP] lyrics [SEP]ssing but [SEP] fun has german pest ( ;?aging russianliga.. [SEP] fun the [SEP] diego idiotsssing flour competition walked ] things that as walked fun [SEP] film [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.553 (perp=11.444, rec=0.273, cos=-0.008), tot_loss_proj:3.802 [t=0.27s]
prediction: ['[CLS] [SEP]? running [SEP]ssing but [SEP] fun has enough pest ( of out russianliga.. [SEP] fun the [SEP] diego idiotsssing film broadcasts walked ] things that as walked fun training film [SEP]']
[ 450/2000] tot_loss=2.539 (perp=11.497, rec=0.249, cos=-0.009), tot_loss_proj:4.066 [t=0.27s]
prediction: ['[CLS] [SEP]? running [SEP]ssing but [SEP] fun has enough film (ez out russian mic.. [SEP] fun the [SEP] diego idiotsssing film broadcasts walked ] observations that as walked fun training film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.384 (perp=10.770, rec=0.238, cos=-0.009), tot_loss_proj:4.035 [t=0.26s]
prediction: ['[CLS] [SEP]? disc [SEP]ssing but [SEP] fun had enough mic ( bail out russian film.. [SEP] fun the [SEP] diego horriblessing film programme walked ] affairs that as walked fun training film [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.317 (perp=10.504, rec=0.226, cos=-0.009), tot_loss_proj:3.867 [t=0.25s]
prediction: ['[CLS] [SEP]? disc film hesitated but [SEP] fun had enough, mic bail out russian film.. [SEP] fun the [SEP] diego horriblessing film programme walked ] affairs that as walked fun training film [SEP]']
[ 600/2000] tot_loss=2.297 (perp=10.456, rec=0.215, cos=-0.009), tot_loss_proj:3.845 [t=0.26s]
prediction: ['[CLS] [SEP]? majority film mind but [SEP] fun had enough, mic bail out russian film.. [SEP] fun the [SEP] diego horriblessing film programme walked ]nsor that as walked fun training film [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.258 (perp=10.306, rec=0.206, cos=-0.009), tot_loss_proj:3.912 [t=0.24s]
prediction: ['[CLS] [SEP]? majority film mind but [SEP] had fun enough, mic bail out austrian film.. [SEP] fun the [SEP] diego horriblessing film programme walked ]nsor that as walked fun training film [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.272 (perp=10.399, rec=0.202, cos=-0.009), tot_loss_proj:3.896 [t=0.28s]
prediction: ['[CLS] [SEP]? majority film mind but [SEP] had fun so, mic bail out austrian film.. [SEP] fun fun [SEP] diego horriblessing film programme walked ]nsor that as walked the training film [SEP]']
[ 750/2000] tot_loss=2.333 (perp=10.723, rec=0.197, cos=-0.009), tot_loss_proj:3.796 [t=0.26s]
prediction: ['[CLS] [SEP]? majority film mind but [SEP] had fun had, bitch di out austrian film.. [SEP] fun fun [SEP] diego horriblessing film ticket walked ]nsor that as walked the training film [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.274 (perp=10.439, rec=0.196, cos=-0.010), tot_loss_proj:3.574 [t=0.25s]
prediction: ['[CLS] [SEP]? majority film mind but [SEP] had fun had, bitch di ] austrian film.. [SEP] fun fun [SEP] diego horriblessing film ticket walked outnsor that and walked the training film [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.205 (perp=10.079, rec=0.199, cos=-0.009), tot_loss_proj:3.510 [t=0.27s]
prediction: ['[CLS] [SEP]? electoral film why but [SEP] had fun so, bitch di ]. austrian film. [SEP] fun fun [SEP] diego horriblessing film ticket walked outnsor that and walked the training film [SEP]']
[ 900/2000] tot_loss=2.189 (perp=10.079, rec=0.183, cos=-0.010), tot_loss_proj:3.508 [t=0.27s]
prediction: ['[CLS] [SEP]? electoral film why but [SEP] had fun so, bitch di ]. austrian film. [SEP] fun fun [SEP] diego horriblessing film ticket walked outnsor that and walked the training film [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.156 (perp=9.904, rec=0.185, cos=-0.010), tot_loss_proj:3.478 [t=0.27s]
prediction: ['[CLS] [SEP]? electoral film why [SEP] but had fun so, bitch di ]. austrian film. [SEP] fun fun [SEP] diego horriblessing film ticket walked outnsor that and walked the training film [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.131 (perp=9.770, rec=0.186, cos=-0.009), tot_loss_proj:3.277 [t=0.26s]
prediction: ['[CLS] [SEP]? electoral film why [SEP] but had fun so, bitch di ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked outnsor that and walked the training film [SEP]']
[1050/2000] tot_loss=2.125 (perp=9.770, rec=0.181, cos=-0.010), tot_loss_proj:3.282 [t=0.25s]
prediction: ['[CLS] [SEP]? electoral film why [SEP] but had fun so, bitch di ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked outnsor that and walked the training film [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.085 (perp=9.529, rec=0.189, cos=-0.010), tot_loss_proj:3.135 [t=0.28s]
prediction: ['[CLS] di? electoral film why [SEP] but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked outnsor that and walked the training film [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.159 (perp=9.950, rec=0.179, cos=-0.010), tot_loss_proj:3.325 [t=0.26s]
prediction: ['[CLS] di jaenelle electoral film minded [SEP] but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked outnsor that training as walked the film [SEP]']
[1200/2000] tot_loss=2.153 (perp=9.904, rec=0.182, cos=-0.010), tot_loss_proj:3.419 [t=0.25s]
prediction: ['[CLS] di jaenelle electoral film minded [SEP] but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked out fellows that training as walked the film [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.150 (perp=9.881, rec=0.184, cos=-0.010), tot_loss_proj:3.383 [t=0.26s]
prediction: ['[CLS] di jaenelle majority film minded di but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked out fellows that training as walked the film [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.103 (perp=9.634, rec=0.185, cos=-0.010), tot_loss_proj:3.232 [t=0.25s]
prediction: ['[CLS] di jaenelle majority di minded film but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego.ssing film ticket walked out fellows that training as walked the film [SEP]']
[1350/2000] tot_loss=2.123 (perp=9.766, rec=0.180, cos=-0.010), tot_loss_proj:3.255 [t=0.27s]
prediction: ['[CLS] di jaenelle majority di minded film but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows that training as walked the film [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.092 (perp=9.615, rec=0.179, cos=-0.010), tot_loss_proj:3.182 [t=0.25s]
prediction: ['[CLS] di jaenelle majority di minded film but had fun so, bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows training that as walked the film [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.067 (perp=9.465, rec=0.183, cos=-0.009), tot_loss_proj:3.109 [t=0.26s]
prediction: ['[CLS] di jaenelle, di minded film but had fun so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows training that as walked the film [SEP]']
[1500/2000] tot_loss=2.065 (perp=9.465, rec=0.181, cos=-0.010), tot_loss_proj:3.108 [t=0.25s]
prediction: ['[CLS] di jaenelle, di minded film but had fun so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows training that as walked the film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.061 (perp=9.465, rec=0.177, cos=-0.010), tot_loss_proj:3.105 [t=0.25s]
prediction: ['[CLS] di jaenelle, di minded film but had fun so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows training that as walked the film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.059 (perp=9.465, rec=0.175, cos=-0.010), tot_loss_proj:3.108 [t=0.26s]
prediction: ['[CLS] di jaenelle, di minded film but had fun so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows training that as walked the film [SEP]']
[1650/2000] tot_loss=2.050 (perp=9.465, rec=0.167, cos=-0.010), tot_loss_proj:3.106 [t=0.27s]
prediction: ['[CLS] di jaenelle, di minded film but had fun so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out fellows training that as walked the film [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.043 (perp=9.374, rec=0.177, cos=-0.010), tot_loss_proj:3.036 [t=0.26s]
prediction: ['[CLS] di jaenelle, di minded film but had fun so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out that training fellows as walked the film [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.035 (perp=9.333, rec=0.179, cos=-0.010), tot_loss_proj:3.058 [t=0.25s]
prediction: ['[CLS] di jaenelle, di minded fun but had film so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out that training fellows as walked the film [SEP]']
[1800/2000] tot_loss=2.033 (perp=9.333, rec=0.176, cos=-0.010), tot_loss_proj:3.058 [t=0.27s]
prediction: ['[CLS] di jaenelle, di minded fun but had film so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out that training fellows as walked the film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.029 (perp=9.333, rec=0.172, cos=-0.010), tot_loss_proj:3.056 [t=0.26s]
prediction: ['[CLS] di jaenelle, di minded fun but had film so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out that training fellows as walked the film [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.991 (perp=9.123, rec=0.175, cos=-0.009), tot_loss_proj:3.069 [t=0.25s]
prediction: ['[CLS] di jaenelle, di minded fun but had fellows so majority bitch [SEP] ] horrible monster terrible. [SEP] fun fun [SEP] diego ofssing the ticket walked out that training film as walked the film [SEP]']
[1950/2000] tot_loss=1.986 (perp=9.087, rec=0.178, cos=-0.010), tot_loss_proj:3.285 [t=0.28s]
prediction: ['[CLS] di jaenelle, di minded fun but had fellows so majority bitch [SEP] ] muttering monster terrible. [SEP] fun fun [SEP] diego ofssing the ticket walked out that in film as walked the film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.980 (perp=9.087, rec=0.173, cos=-0.010), tot_loss_proj:3.286 [t=0.26s]
prediction: ['[CLS] di jaenelle, di minded fun but had fellows so majority bitch [SEP] ] muttering monster terrible. [SEP] fun fun [SEP] diego ofssing the ticket walked out that in film as walked the film [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] di jaenelle, di minded fun but had film so majority bitch [SEP] ] horrible austrian terrible. [SEP] fun fun [SEP] diego ofssing film ticket walked out that training fellows as walked the film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.667 | p: 41.176 | r: 53.846
rouge2     | fm: 10.345 | p: 9.091 | r: 12.000
rougeL     | fm: 30.000 | p: 26.471 | r: 34.615
rougeLsum  | fm: 30.000 | p: 26.471 | r: 34.615
r1fm+r2fm = 57.011

[Aggregate metrics]:
rouge1     | fm: 87.504 | p: 86.764 | r: 88.343
rouge2     | fm: 52.608 | p: 52.290 | r: 52.985
rougeL     | fm: 75.861 | p: 75.280 | r: 76.522
rougeLsum  | fm: 75.866 | p: 75.363 | r: 76.564
r1fm+r2fm = 140.113

input #99 time: 0:10:54 | total time: 17:24:08


Average Cosine Similarity: 0.9992812683158312
Done with all.
