


Command: attack6-act.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --lr_decay 0.89 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.1 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 48.15it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.7164064201719911
highest_index [0]
highest [0.7164064201719911]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9458765387535095 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.812534749507904 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8026670813560486 for ['[CLS] tolerance receiving [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.655 (perp=10.251, rec=0.120, cos=0.485), tot_loss_proj:2.608 [t=0.81s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.606 (perp=10.251, rec=0.069, cos=0.487), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.599 (perp=10.251, rec=0.065, cos=0.484), tot_loss_proj:2.591 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.609 (perp=10.251, rec=0.073, cos=0.486), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.607 (perp=10.251, rec=0.069, cos=0.487), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.602 (perp=10.251, rec=0.066, cos=0.486), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.593 (perp=10.251, rec=0.061, cos=0.482), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.597 (perp=10.251, rec=0.063, cos=0.484), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.599 (perp=10.251, rec=0.063, cos=0.486), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.602 (perp=10.251, rec=0.067, cos=0.485), tot_loss_proj:2.596 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.600 (perp=10.251, rec=0.062, cos=0.487), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.589 (perp=10.251, rec=0.053, cos=0.486), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.594 (perp=10.251, rec=0.059, cos=0.485), tot_loss_proj:2.601 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.587 (perp=10.251, rec=0.052, cos=0.484), tot_loss_proj:2.594 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.610 (perp=10.251, rec=0.073, cos=0.486), tot_loss_proj:2.591 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.592 (perp=10.251, rec=0.058, cos=0.484), tot_loss_proj:2.608 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.596 (perp=10.251, rec=0.061, cos=0.485), tot_loss_proj:2.590 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.598 (perp=10.251, rec=0.064, cos=0.484), tot_loss_proj:2.601 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.587 (perp=10.251, rec=0.052, cos=0.485), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.592 (perp=10.251, rec=0.057, cos=0.485), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.594 (perp=10.251, rec=0.060, cos=0.484), tot_loss_proj:2.607 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.594 (perp=10.251, rec=0.058, cos=0.486), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.594 (perp=10.251, rec=0.059, cos=0.485), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.594 (perp=10.251, rec=0.058, cos=0.486), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.605 (perp=10.251, rec=0.068, cos=0.487), tot_loss_proj:2.602 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.595 (perp=10.251, rec=0.059, cos=0.485), tot_loss_proj:2.607 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.595 (perp=10.251, rec=0.058, cos=0.487), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.604 (perp=10.251, rec=0.068, cos=0.486), tot_loss_proj:2.601 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.591 (perp=10.251, rec=0.055, cos=0.486), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.594 (perp=10.251, rec=0.058, cos=0.486), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.591 (perp=10.251, rec=0.055, cos=0.486), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.590 (perp=10.251, rec=0.055, cos=0.485), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.592 (perp=10.251, rec=0.056, cos=0.485), tot_loss_proj:2.601 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.593 (perp=10.251, rec=0.057, cos=0.486), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.591 (perp=10.251, rec=0.055, cos=0.486), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.604 (perp=10.251, rec=0.068, cos=0.486), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.596 (perp=10.251, rec=0.059, cos=0.486), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.602 (perp=10.251, rec=0.066, cos=0.487), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.599 (perp=10.251, rec=0.062, cos=0.486), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.592 (perp=10.251, rec=0.055, cos=0.487), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:54 | total time: 0:08:54


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.739650756953924
highest_index [0]
highest [0.739650756953924]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9701482653617859 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9569876790046692 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9563683867454529 for ['[CLS] consist waterloo [SEP]']
[Init] best rec loss: 0.9508650898933411 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 0.9466550946235657 for ['[CLS] schedule sensors [SEP]']
[Init] best rec loss: 0.9427643418312073 for ['[CLS] vital conflict [SEP]']
[Init] best rec loss: 0.9406458139419556 for ['[CLS] } sex [SEP]']
[Init] best rec loss: 0.9327254295349121 for ['[CLS] received mountain [SEP]']
[Init] best rec loss: 0.8722508549690247 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.8314861059188843 for ["[CLS] giant'[SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.196 (perp=11.623, rec=0.408, cos=0.464), tot_loss_proj:3.845 [t=0.22s]
prediction: ['[CLS] lucien genius [SEP]']
[ 100/2000] tot_loss=2.809 (perp=10.816, rec=0.191, cos=0.455), tot_loss_proj:3.054 [t=0.22s]
prediction: ['[CLS] european splendid [SEP]']
[ 150/2000] tot_loss=2.660 (perp=10.288, rec=0.151, cos=0.451), tot_loss_proj:2.756 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.645 (perp=10.288, rec=0.136, cos=0.451), tot_loss_proj:2.756 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.422 (perp=9.171, rec=0.138, cos=0.450), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=2.415 (perp=9.171, rec=0.129, cos=0.452), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.414 (perp=9.171, rec=0.127, cos=0.452), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.399 (perp=9.171, rec=0.114, cos=0.451), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=2.387 (perp=9.171, rec=0.101, cos=0.452), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.388 (perp=9.171, rec=0.101, cos=0.452), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.389 (perp=9.171, rec=0.103, cos=0.452), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=2.381 (perp=9.171, rec=0.095, cos=0.452), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.386 (perp=9.171, rec=0.101, cos=0.451), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.386 (perp=9.171, rec=0.099, cos=0.453), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=2.384 (perp=9.171, rec=0.097, cos=0.453), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.380 (perp=9.171, rec=0.094, cos=0.452), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.390 (perp=9.171, rec=0.103, cos=0.453), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=2.365 (perp=9.171, rec=0.079, cos=0.452), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.386 (perp=9.171, rec=0.100, cos=0.452), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=2.365 (perp=9.171, rec=0.079, cos=0.452), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=2.354 (perp=9.171, rec=0.067, cos=0.452), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=2.362 (perp=9.171, rec=0.076, cos=0.452), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=2.356 (perp=9.171, rec=0.069, cos=0.452), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=2.352 (perp=9.171, rec=0.066, cos=0.452), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.349 (perp=9.171, rec=0.062, cos=0.453), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.360 (perp=9.171, rec=0.073, cos=0.452), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=2.345 (perp=9.171, rec=0.059, cos=0.452), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.360 (perp=9.171, rec=0.074, cos=0.452), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.348 (perp=9.171, rec=0.062, cos=0.452), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=2.338 (perp=9.171, rec=0.052, cos=0.452), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.357 (perp=9.171, rec=0.070, cos=0.452), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.351 (perp=9.171, rec=0.064, cos=0.452), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=2.354 (perp=9.171, rec=0.067, cos=0.452), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.349 (perp=9.171, rec=0.062, cos=0.453), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.347 (perp=9.171, rec=0.061, cos=0.452), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=2.351 (perp=9.171, rec=0.065, cos=0.452), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.344 (perp=9.171, rec=0.057, cos=0.452), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.351 (perp=9.171, rec=0.065, cos=0.452), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=2.354 (perp=9.171, rec=0.067, cos=0.453), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.360 (perp=9.171, rec=0.074, cos=0.452), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:09:11 | total time: 0:18:05


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.7431557656482051
highest_index [0]
highest [0.7431557656482051]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7219554781913757 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7209203839302063 for ['[CLS]〜 at wash [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.726 (perp=9.941, rec=0.298, cos=0.440), tot_loss_proj:2.796 [t=0.22s]
prediction: ['[CLS] gaining momentum gaining [SEP]']
[ 100/2000] tot_loss=2.538 (perp=9.952, rec=0.101, cos=0.447), tot_loss_proj:2.811 [t=0.22s]
prediction: ['[CLS] gaining momentum much [SEP]']
[ 150/2000] tot_loss=2.498 (perp=9.952, rec=0.064, cos=0.444), tot_loss_proj:2.821 [t=0.22s]
prediction: ['[CLS] gaining momentum much [SEP]']
[ 200/2000] tot_loss=2.509 (perp=9.952, rec=0.072, cos=0.447), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] gaining momentum much [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.227 (perp=8.515, rec=0.081, cos=0.444), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=2.216 (perp=8.515, rec=0.068, cos=0.445), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.201 (perp=8.515, rec=0.052, cos=0.446), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.207 (perp=8.515, rec=0.058, cos=0.446), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=2.209 (perp=8.515, rec=0.059, cos=0.447), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.217 (perp=8.515, rec=0.069, cos=0.445), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.217 (perp=8.515, rec=0.069, cos=0.445), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=2.225 (perp=8.515, rec=0.078, cos=0.445), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.211 (perp=8.515, rec=0.062, cos=0.446), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.209 (perp=8.515, rec=0.061, cos=0.445), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=2.217 (perp=8.515, rec=0.070, cos=0.445), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.208 (perp=8.515, rec=0.057, cos=0.448), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.218 (perp=8.515, rec=0.067, cos=0.447), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=2.209 (perp=8.515, rec=0.061, cos=0.445), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.216 (perp=8.515, rec=0.067, cos=0.445), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.220 (perp=8.515, rec=0.071, cos=0.446), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=2.202 (perp=8.515, rec=0.052, cos=0.447), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.216 (perp=8.515, rec=0.066, cos=0.447), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.204 (perp=8.515, rec=0.055, cos=0.446), tot_loss_proj:2.215 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=2.209 (perp=8.515, rec=0.059, cos=0.447), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.216 (perp=8.515, rec=0.065, cos=0.447), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.207 (perp=8.515, rec=0.057, cos=0.447), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=2.215 (perp=8.515, rec=0.065, cos=0.447), tot_loss_proj:2.207 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.203 (perp=8.515, rec=0.053, cos=0.447), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.203 (perp=8.515, rec=0.053, cos=0.448), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=2.204 (perp=8.515, rec=0.054, cos=0.447), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.206 (perp=8.515, rec=0.057, cos=0.447), tot_loss_proj:2.219 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.212 (perp=8.515, rec=0.062, cos=0.447), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=2.211 (perp=8.515, rec=0.061, cos=0.448), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.203 (perp=8.515, rec=0.053, cos=0.447), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.212 (perp=8.515, rec=0.062, cos=0.447), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=2.207 (perp=8.515, rec=0.057, cos=0.447), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.203 (perp=8.515, rec=0.053, cos=0.447), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.201 (perp=8.515, rec=0.051, cos=0.447), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=2.203 (perp=8.515, rec=0.052, cos=0.448), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.209 (perp=8.515, rec=0.059, cos=0.447), tot_loss_proj:2.217 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:08:57 | total time: 0:27:03


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.7325030459083943
highest_index [0]
highest [0.7325030459083943]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9737228155136108 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.8589745759963989 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8459603786468506 for ['[CLS] lancashire isaac [SEP]']
[Init] best rec loss: 0.8029484152793884 for ['[CLS] end depart [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.673 (perp=10.224, rec=0.167, cos=0.461), tot_loss_proj:2.835 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
[ 100/2000] tot_loss=2.595 (perp=10.224, rec=0.087, cos=0.463), tot_loss_proj:2.836 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.584 (perp=10.224, rec=0.077, cos=0.462), tot_loss_proj:2.840 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.583 (perp=10.224, rec=0.078, cos=0.459), tot_loss_proj:2.845 [t=0.22s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.209 (perp=8.385, rec=0.068, cos=0.464), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=2.193 (perp=8.385, rec=0.054, cos=0.462), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.199 (perp=8.385, rec=0.060, cos=0.462), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.194 (perp=8.385, rec=0.054, cos=0.463), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=2.195 (perp=8.385, rec=0.056, cos=0.462), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.202 (perp=8.385, rec=0.063, cos=0.463), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.205 (perp=8.385, rec=0.066, cos=0.462), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=2.204 (perp=8.385, rec=0.064, cos=0.463), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.210 (perp=8.385, rec=0.070, cos=0.463), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.193 (perp=8.385, rec=0.054, cos=0.462), tot_loss_proj:2.225 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=2.191 (perp=8.385, rec=0.053, cos=0.462), tot_loss_proj:2.226 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.203 (perp=8.385, rec=0.064, cos=0.463), tot_loss_proj:2.218 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.204 (perp=8.385, rec=0.065, cos=0.462), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=2.197 (perp=8.385, rec=0.057, cos=0.463), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.204 (perp=8.385, rec=0.065, cos=0.462), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.202 (perp=8.385, rec=0.063, cos=0.462), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=2.199 (perp=8.385, rec=0.059, cos=0.462), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.206 (perp=8.385, rec=0.065, cos=0.463), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.195 (perp=8.385, rec=0.055, cos=0.463), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=2.193 (perp=8.385, rec=0.054, cos=0.463), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.205 (perp=8.385, rec=0.066, cos=0.462), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.201 (perp=8.385, rec=0.062, cos=0.462), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=2.203 (perp=8.385, rec=0.063, cos=0.463), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.209 (perp=8.385, rec=0.070, cos=0.463), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.204 (perp=8.385, rec=0.064, cos=0.463), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=2.197 (perp=8.385, rec=0.057, cos=0.463), tot_loss_proj:2.230 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.205 (perp=8.385, rec=0.065, cos=0.463), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.202 (perp=8.385, rec=0.062, cos=0.463), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=2.202 (perp=8.385, rec=0.062, cos=0.463), tot_loss_proj:2.222 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.202 (perp=8.385, rec=0.063, cos=0.463), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.207 (perp=8.385, rec=0.067, cos=0.463), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=2.215 (perp=8.385, rec=0.075, cos=0.463), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.207 (perp=8.385, rec=0.067, cos=0.463), tot_loss_proj:2.229 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.201 (perp=8.385, rec=0.061, cos=0.463), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=2.191 (perp=8.385, rec=0.051, cos=0.463), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.209 (perp=8.385, rec=0.069, cos=0.463), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:50 | total time: 0:35:54


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.7213840799816669
highest_index [0]
highest [0.7213840799816669]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9685737490653992 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.936030387878418 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.933194637298584 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9217906594276428 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9213922619819641 for ['[CLS]dge squareaway [SEP]']
[Init] best rec loss: 0.8823348879814148 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8659259080886841 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8593176603317261 for ['[CLS] fatedss jack [SEP]']
[Init] best perm rec loss: 0.858025312423706 for ['[CLS] jackss fated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.055 (perp=11.725, rec=0.233, cos=0.477), tot_loss_proj:3.945 [t=0.28s]
prediction: ['[CLS] tires tires tires [SEP]']
[ 100/2000] tot_loss=1.936 (perp=6.519, rec=0.155, cos=0.477), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
[ 150/2000] tot_loss=1.922 (perp=6.519, rec=0.141, cos=0.477), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
[ 200/2000] tot_loss=1.902 (perp=6.519, rec=0.124, cos=0.474), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.881 (perp=6.519, rec=0.105, cos=0.472), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
[ 300/2000] tot_loss=1.883 (perp=6.519, rec=0.103, cos=0.476), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.888 (perp=6.519, rec=0.105, cos=0.479), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.890 (perp=6.519, rec=0.106, cos=0.480), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
[ 450/2000] tot_loss=1.886 (perp=6.519, rec=0.105, cos=0.478), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.870 (perp=6.519, rec=0.087, cos=0.480), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] tiresome tires [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.876 (perp=6.519, rec=0.095, cos=0.478), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] tiresome tires [SEP]']
[ 600/2000] tot_loss=1.873 (perp=6.519, rec=0.093, cos=0.476), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] tiresome tires [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.782 (perp=11.052, rec=0.095, cos=0.476), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] tiresomeome [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.538 (perp=9.734, rec=0.113, cos=0.479), tot_loss_proj:2.784 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 750/2000] tot_loss=2.512 (perp=9.734, rec=0.088, cos=0.477), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.514 (perp=9.734, rec=0.090, cos=0.477), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.518 (perp=9.734, rec=0.092, cos=0.479), tot_loss_proj:2.819 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[ 900/2000] tot_loss=2.526 (perp=9.734, rec=0.104, cos=0.475), tot_loss_proj:2.817 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.514 (perp=9.734, rec=0.089, cos=0.477), tot_loss_proj:2.828 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1000/2000] tot_loss=2.509 (perp=9.734, rec=0.084, cos=0.478), tot_loss_proj:2.822 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[1050/2000] tot_loss=2.515 (perp=9.734, rec=0.090, cos=0.478), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1100/2000] tot_loss=2.522 (perp=9.734, rec=0.097, cos=0.478), tot_loss_proj:2.817 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1150/2000] tot_loss=2.514 (perp=9.734, rec=0.088, cos=0.479), tot_loss_proj:2.821 [t=0.23s]
prediction: ['[CLS]ome tiresome [SEP]']
[1200/2000] tot_loss=2.511 (perp=9.734, rec=0.085, cos=0.479), tot_loss_proj:2.812 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1250/2000] tot_loss=2.505 (perp=9.734, rec=0.081, cos=0.477), tot_loss_proj:2.813 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1300/2000] tot_loss=2.514 (perp=9.734, rec=0.091, cos=0.476), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[1350/2000] tot_loss=2.507 (perp=9.734, rec=0.081, cos=0.479), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1400/2000] tot_loss=2.516 (perp=9.734, rec=0.090, cos=0.479), tot_loss_proj:2.820 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1450/2000] tot_loss=2.515 (perp=9.734, rec=0.089, cos=0.479), tot_loss_proj:2.821 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[1500/2000] tot_loss=2.510 (perp=9.734, rec=0.085, cos=0.479), tot_loss_proj:2.823 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1550/2000] tot_loss=2.509 (perp=9.734, rec=0.085, cos=0.478), tot_loss_proj:2.819 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1600/2000] tot_loss=2.507 (perp=9.734, rec=0.081, cos=0.480), tot_loss_proj:2.820 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[1650/2000] tot_loss=2.516 (perp=9.734, rec=0.091, cos=0.479), tot_loss_proj:2.829 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1700/2000] tot_loss=2.514 (perp=9.734, rec=0.088, cos=0.479), tot_loss_proj:2.822 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1750/2000] tot_loss=2.513 (perp=9.734, rec=0.088, cos=0.478), tot_loss_proj:2.827 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[1800/2000] tot_loss=2.521 (perp=9.734, rec=0.095, cos=0.479), tot_loss_proj:2.832 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1850/2000] tot_loss=2.512 (perp=9.734, rec=0.086, cos=0.478), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[1900/2000] tot_loss=2.514 (perp=9.734, rec=0.089, cos=0.478), tot_loss_proj:2.821 [t=0.22s]
prediction: ['[CLS]ome tiresome [SEP]']
[1950/2000] tot_loss=2.511 (perp=9.734, rec=0.085, cos=0.479), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS]ome tiresome [SEP]']
Attempt swap
[2000/2000] tot_loss=2.516 (perp=9.734, rec=0.091, cos=0.478), tot_loss_proj:2.825 [t=0.23s]
prediction: ['[CLS]ome tiresome [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS]ome tiresome [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 91.429 | p: 90.000 | r: 93.333
rouge2     | fm: 80.000 | p: 80.000 | r: 80.000
rougeL     | fm: 91.429 | p: 90.000 | r: 93.333
rougeLsum  | fm: 91.429 | p: 90.000 | r: 93.333
r1fm+r2fm = 171.429

input #4 time: 0:09:01 | total time: 0:44:55


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.7392787263098384
highest_index [0]
highest [0.7392787263098384]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9783952832221985 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9782837629318237 for ['[CLS]pped jonah [SEP]']
[Init] best rec loss: 0.9581809639930725 for ['[CLS] juathic [SEP]']
[Init] best rec loss: 0.9528850317001343 for ['[CLS] those legs [SEP]']
[Init] best rec loss: 0.9518070220947266 for ['[CLS] estate herself [SEP]']
[Init] best rec loss: 0.9468013048171997 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9358546137809753 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.9209710359573364 for ['[CLS] baby face [SEP]']
[Init] best rec loss: 0.919369637966156 for ['[CLS] aged sloop [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.175 (perp=10.298, rec=0.679, cos=0.436), tot_loss_proj:3.933 [t=0.22s]
prediction: ['[CLS] mafia silence [SEP]']
[ 100/2000] tot_loss=3.264 (perp=11.004, rec=0.584, cos=0.479), tot_loss_proj:3.832 [t=0.22s]
prediction: ['[CLS] gallantry ease [SEP]']
[ 150/2000] tot_loss=3.449 (perp=11.529, rec=0.657, cos=0.486), tot_loss_proj:4.196 [t=0.22s]
prediction: ['[CLS] venues doubt [SEP]']
[ 200/2000] tot_loss=3.307 (perp=11.370, rec=0.577, cos=0.456), tot_loss_proj:4.013 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.612 (perp=12.952, rec=0.579, cos=0.443), tot_loss_proj:4.359 [t=0.22s]
prediction: ['[CLS]clusive ease [SEP]']
[ 300/2000] tot_loss=3.286 (perp=11.370, rec=0.568, cos=0.444), tot_loss_proj:4.005 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.244 (perp=11.370, rec=0.518, cos=0.452), tot_loss_proj:4.001 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.771 (perp=13.553, rec=0.616, cos=0.445), tot_loss_proj:4.725 [t=0.22s]
prediction: ['[CLS] easeclusive [SEP]']
[ 450/2000] tot_loss=3.257 (perp=11.370, rec=0.535, cos=0.448), tot_loss_proj:4.011 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.243 (perp=11.370, rec=0.512, cos=0.457), tot_loss_proj:4.006 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.232 (perp=11.370, rec=0.508, cos=0.449), tot_loss_proj:4.009 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 600/2000] tot_loss=3.216 (perp=11.370, rec=0.498, cos=0.445), tot_loss_proj:4.008 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.222 (perp=11.370, rec=0.490, cos=0.458), tot_loss_proj:4.009 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.203 (perp=11.370, rec=0.491, cos=0.437), tot_loss_proj:4.011 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 750/2000] tot_loss=3.250 (perp=11.370, rec=0.516, cos=0.459), tot_loss_proj:4.014 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.212 (perp=11.370, rec=0.489, cos=0.448), tot_loss_proj:4.011 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.227 (perp=11.370, rec=0.490, cos=0.463), tot_loss_proj:4.017 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 900/2000] tot_loss=3.212 (perp=11.370, rec=0.487, cos=0.451), tot_loss_proj:4.006 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.206 (perp=11.370, rec=0.483, cos=0.449), tot_loss_proj:4.014 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.213 (perp=11.370, rec=0.478, cos=0.461), tot_loss_proj:4.015 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1050/2000] tot_loss=3.208 (perp=11.370, rec=0.481, cos=0.454), tot_loss_proj:4.016 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1100/2000] tot_loss=3.208 (perp=11.370, rec=0.476, cos=0.458), tot_loss_proj:4.010 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.206 (perp=11.370, rec=0.478, cos=0.453), tot_loss_proj:4.009 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=3.198 (perp=11.370, rec=0.477, cos=0.447), tot_loss_proj:4.015 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.200 (perp=11.370, rec=0.474, cos=0.453), tot_loss_proj:4.015 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=3.203 (perp=11.370, rec=0.472, cos=0.457), tot_loss_proj:4.014 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1350/2000] tot_loss=3.196 (perp=11.370, rec=0.473, cos=0.449), tot_loss_proj:4.007 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1400/2000] tot_loss=3.203 (perp=11.370, rec=0.474, cos=0.454), tot_loss_proj:4.018 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1450/2000] tot_loss=3.190 (perp=11.370, rec=0.470, cos=0.446), tot_loss_proj:4.007 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1500/2000] tot_loss=3.205 (perp=11.370, rec=0.477, cos=0.454), tot_loss_proj:4.008 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1550/2000] tot_loss=3.200 (perp=11.370, rec=0.471, cos=0.454), tot_loss_proj:4.013 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1600/2000] tot_loss=3.195 (perp=11.370, rec=0.465, cos=0.455), tot_loss_proj:4.009 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1650/2000] tot_loss=3.194 (perp=11.370, rec=0.468, cos=0.452), tot_loss_proj:4.014 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1700/2000] tot_loss=3.202 (perp=11.370, rec=0.470, cos=0.457), tot_loss_proj:4.008 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1750/2000] tot_loss=3.191 (perp=11.370, rec=0.467, cos=0.450), tot_loss_proj:4.011 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1800/2000] tot_loss=3.194 (perp=11.370, rec=0.465, cos=0.455), tot_loss_proj:4.014 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1850/2000] tot_loss=3.191 (perp=11.370, rec=0.464, cos=0.453), tot_loss_proj:4.008 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1900/2000] tot_loss=3.191 (perp=11.370, rec=0.469, cos=0.448), tot_loss_proj:4.007 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1950/2000] tot_loss=3.196 (perp=11.370, rec=0.470, cos=0.452), tot_loss_proj:4.013 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[2000/2000] tot_loss=3.200 (perp=11.370, rec=0.472, cos=0.454), tot_loss_proj:4.015 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 88.690 | p: 87.500 | r: 90.278
rouge2     | fm: 72.222 | p: 72.222 | r: 72.222
rougeL     | fm: 88.690 | p: 87.500 | r: 90.278
rougeLsum  | fm: 88.690 | p: 87.500 | r: 90.278
r1fm+r2fm = 160.913

input #5 time: 0:08:56 | total time: 0:53:52


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.7201067347997957
highest_index [0]
highest [0.7201067347997957]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9184263348579407 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.7941367030143738 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.7824483513832092 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7617484331130981 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.727128267288208 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.70525062084198 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6912466883659363 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6901479363441467 for ['[CLS] demolition tre [SEP]']
[Init] best rec loss: 0.6523512601852417 for ['[CLS] double deep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.257 (perp=8.088, rec=0.157, cos=0.483), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 100/2000] tot_loss=2.178 (perp=8.088, rec=0.084, cos=0.476), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=2.175 (perp=8.088, rec=0.078, cos=0.480), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=2.171 (perp=8.088, rec=0.075, cos=0.478), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.164 (perp=8.088, rec=0.066, cos=0.481), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=2.157 (perp=8.088, rec=0.063, cos=0.477), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.167 (perp=8.088, rec=0.071, cos=0.478), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.152 (perp=8.088, rec=0.059, cos=0.475), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=2.163 (perp=8.088, rec=0.068, cos=0.478), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.173 (perp=8.088, rec=0.078, cos=0.477), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.153 (perp=8.088, rec=0.056, cos=0.479), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=2.155 (perp=8.088, rec=0.058, cos=0.480), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.151 (perp=8.088, rec=0.058, cos=0.476), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.156 (perp=8.088, rec=0.061, cos=0.477), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=2.155 (perp=8.088, rec=0.057, cos=0.480), tot_loss_proj:2.186 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.157 (perp=8.088, rec=0.059, cos=0.481), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.175 (perp=8.088, rec=0.076, cos=0.482), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=2.164 (perp=8.088, rec=0.068, cos=0.478), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.148 (perp=8.088, rec=0.053, cos=0.478), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=2.168 (perp=8.088, rec=0.069, cos=0.481), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=2.161 (perp=8.088, rec=0.064, cos=0.479), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=2.153 (perp=8.088, rec=0.057, cos=0.479), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=2.151 (perp=8.088, rec=0.055, cos=0.479), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=2.163 (perp=8.088, rec=0.067, cos=0.479), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=2.161 (perp=8.088, rec=0.063, cos=0.480), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=2.164 (perp=8.088, rec=0.067, cos=0.479), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=2.166 (perp=8.088, rec=0.069, cos=0.479), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=2.157 (perp=8.088, rec=0.058, cos=0.481), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=2.154 (perp=8.088, rec=0.056, cos=0.480), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=2.159 (perp=8.088, rec=0.061, cos=0.480), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=2.156 (perp=8.088, rec=0.057, cos=0.481), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=2.154 (perp=8.088, rec=0.056, cos=0.481), tot_loss_proj:2.186 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=2.153 (perp=8.088, rec=0.056, cos=0.479), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=2.150 (perp=8.088, rec=0.053, cos=0.479), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=2.152 (perp=8.088, rec=0.054, cos=0.481), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=2.163 (perp=8.088, rec=0.065, cos=0.480), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=2.158 (perp=8.088, rec=0.060, cos=0.480), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=2.169 (perp=8.088, rec=0.071, cos=0.480), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=2.164 (perp=8.088, rec=0.067, cos=0.480), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=2.151 (perp=8.088, rec=0.053, cos=0.480), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.306 | p: 89.286 | r: 91.667
rouge2     | fm: 76.190 | p: 76.190 | r: 76.190
rougeL     | fm: 90.306 | p: 89.286 | r: 91.667
rougeLsum  | fm: 90.306 | p: 89.286 | r: 91.667
r1fm+r2fm = 166.497

input #6 time: 0:09:08 | total time: 1:03:01


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.7079585537850434
highest_index [0]
highest [0.7079585537850434]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.8625172972679138 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8088068962097168 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8024347424507141 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.8015190958976746 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.7877655029296875 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7849993109703064 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best perm rec loss: 0.7846800684928894 for ['[CLS] child conspiracy all micro d twins behind stanley line maintained rule something echoelli fighting hoptative sykes legal earlybation job park ni medicine aces [SEP]']
[Init] best perm rec loss: 0.784127414226532 for ['[CLS]bation conspiracy d aces legaltative ni behind twins sykes micro hop fightingelli line job all stanley something medicine maintained early park child echo rule [SEP]']
[Init] best perm rec loss: 0.7840645909309387 for ['[CLS] sykes nielli d hop job medicinebation legal aces line rule conspiracy twins behind early all stanley park echo microtative something fighting child maintained [SEP]']
[Init] best perm rec loss: 0.7836803793907166 for ['[CLS] twins child maintained job hop legal park early all acestative stanley conspiracy medicine fighting d micro line behind something ni echo rule sykesbationelli [SEP]']
[Init] best perm rec loss: 0.783437967300415 for ['[CLS] hop legal early behind micro stanley all jobtative d ni maintained line sykes echo conspiracy aces fighting rule twins child somethingbation park medicineelli [SEP]']
[Init] best perm rec loss: 0.7822595238685608 for ['[CLS]elli hop legal stanley acestative twins conspiracy early job fighting behind sykes maintained something echobation medicine park d micro rule line child all ni [SEP]']
[Init] best perm rec loss: 0.7806805968284607 for ['[CLS]elli sykes line fighting rule hop job twins child something micro early ni legalbation conspiracy stanley all maintainedtative d medicine echo park aces behind [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.729 (perp=14.024, rec=0.429, cos=0.495), tot_loss_proj:4.160 [t=0.22s]
prediction: ['[CLS] % caused cells legal against reuters basque persecution constitutes [SEP] uk unfortunately doubt curran problem avoiding become switzerland stained ignoredclass ( associations prison let plate [SEP]']
[ 100/2000] tot_loss=3.191 (perp=11.971, rec=0.315, cos=0.482), tot_loss_proj:3.634 [t=0.23s]
prediction: ["[CLS] % problem was legal problem hole poor threats innocence problem government problem doubt curran problem problem corresponds valueled ignoredable. association'singles plate [SEP]"]
[ 150/2000] tot_loss=2.820 (perp=10.354, rec=0.256, cos=0.493), tot_loss_proj:3.436 [t=0.23s]
prediction: ['[CLS] % problem was legal problem. spite threats innocence problem is problem nothing am problem problem supposed character structure characterable. association ( love plate [SEP]']
[ 200/2000] tot_loss=2.667 (perp=9.791, rec=0.208, cos=0.501), tot_loss_proj:3.513 [t=0.23s]
prediction: ['[CLS] % problem was? problem.enham dinamo humanity problem is problem nothing is problem avoiding supposed character our characterable. connections or love security [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.464 (perp=8.949, rec=0.191, cos=0.483), tot_loss_proj:2.939 [t=0.23s]
prediction: ['[CLS] % problem. not mistake is san dinamo racial problem is problem problem. problem no particular character our characterable no character or love intelligence [SEP]']
[ 300/2000] tot_loss=2.434 (perp=8.913, rec=0.171, cos=0.480), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] % problem. not - ispper dinamo fremantle problem is problem here ; ugly no particular character or characterable no character or love intelligence [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.382 (perp=8.672, rec=0.160, cos=0.488), tot_loss_proj:2.913 [t=0.23s]
prediction: ['[CLS] % problem. not value has you dinamo iii problem is problem here ; ugly no particular character or characterable no character or love intelligence [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.311 (perp=8.330, rec=0.155, cos=0.491), tot_loss_proj:3.122 [t=0.23s]
prediction: ['[CLS] % problem dinamo not value has you. ugly problem is problem here ; ugly no fancy character or characterable no character ; love intelligence [SEP]']
[ 450/2000] tot_loss=2.310 (perp=8.398, rec=0.146, cos=0.484), tot_loss_proj:2.803 [t=0.23s]
prediction: ['[CLS] % problem dinamo not value has you. ugly problem is problem here ; ugly no fancy character or characterable no character, love intelligence [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.405 (perp=8.885, rec=0.138, cos=0.490), tot_loss_proj:3.212 [t=0.23s]
prediction: ['[CLS] % cute dinamo notxious has you. ugly problem is problem here ; ugly no character or characterable no character ordinary, love ear [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.345 (perp=8.594, rec=0.133, cos=0.493), tot_loss_proj:2.830 [t=0.23s]
prediction: ['[CLS] % you dinamo notxious has mind. ugly problem is problem here ; ugly no character or characterable no character mind, love ear [SEP]']
[ 600/2000] tot_loss=2.263 (perp=8.245, rec=0.125, cos=0.488), tot_loss_proj:2.793 [t=0.23s]
prediction: ['[CLS] %. dinamo not mind has mind. ugly problem is problem here ; ugly no character or uglyable no character cute, love ear [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.254 (perp=8.159, rec=0.129, cos=0.493), tot_loss_proj:2.775 [t=0.23s]
prediction: ['[CLS] %. dinamo not mind has mind. ugly problem is problem here ; ugly no character ugly orable no character cute, love hive [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.251 (perp=8.188, rec=0.124, cos=0.489), tot_loss_proj:2.752 [t=0.23s]
prediction: ['[CLS] %. dinamo not mind has mind. ugly problem is problem here ; ugly no character ugly orable no cute, loveable otherwise [SEP]']
[ 750/2000] tot_loss=2.255 (perp=8.188, rec=0.121, cos=0.496), tot_loss_proj:2.744 [t=0.23s]
prediction: ['[CLS] %. dinamo not mind has mind. ugly problem is problem here ; ugly no character ugly orable no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.205 (perp=7.998, rec=0.119, cos=0.486), tot_loss_proj:2.692 [t=0.23s]
prediction: ['[CLS] %. dinamo not mind has mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.197 (perp=7.912, rec=0.124, cos=0.491), tot_loss_proj:2.667 [t=0.23s]
prediction: ['[CLS] dinamo. % not mind has mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
[ 900/2000] tot_loss=2.142 (perp=7.616, rec=0.124, cos=0.494), tot_loss_proj:2.576 [t=0.23s]
prediction: ['[CLS]₱. % not mind has mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.132 (perp=7.616, rec=0.118, cos=0.490), tot_loss_proj:2.582 [t=0.23s]
prediction: ['[CLS]₱. % not mind has mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.107 (perp=7.516, rec=0.116, cos=0.488), tot_loss_proj:2.589 [t=0.23s]
prediction: ['[CLS]₱. % has mind not mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
[1050/2000] tot_loss=2.114 (perp=7.516, rec=0.118, cos=0.492), tot_loss_proj:2.589 [t=0.23s]
prediction: ['[CLS]₱. % has mind not mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
Attempt swap
[1100/2000] tot_loss=2.109 (perp=7.516, rec=0.115, cos=0.491), tot_loss_proj:2.590 [t=0.23s]
prediction: ['[CLS]₱. % has mind not mind. ugly problem is problem here ; ugly no characterable or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.228 (perp=8.095, rec=0.119, cos=0.490), tot_loss_proj:2.784 [t=0.23s]
prediction: ['[CLS] reside. character has mind not mind. ugly problem is problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
[1200/2000] tot_loss=2.191 (perp=7.939, rec=0.111, cos=0.492), tot_loss_proj:2.732 [t=0.23s]
prediction: ['[CLS] reside. character has. not mind. ugly problem is problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.079 (perp=7.369, rec=0.117, cos=0.488), tot_loss_proj:2.553 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly problem is problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.044 (perp=7.189, rec=0.116, cos=0.490), tot_loss_proj:2.507 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problem problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
[1350/2000] tot_loss=2.044 (perp=7.189, rec=0.116, cos=0.490), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problem problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
Attempt swap
[1400/2000] tot_loss=2.038 (perp=7.189, rec=0.110, cos=0.490), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problem problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.033 (perp=7.189, rec=0.108, cos=0.487), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problem problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
[1500/2000] tot_loss=2.038 (perp=7.189, rec=0.111, cos=0.489), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problem problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.985 (perp=6.927, rec=0.110, cos=0.490), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problemable here ; ugly no % problem or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.985 (perp=6.921, rec=0.113, cos=0.488), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problemable here ; ugly no problem % or ugly no cute, loveable otherwise [SEP]']
[1650/2000] tot_loss=1.984 (perp=6.921, rec=0.111, cos=0.489), tot_loss_proj:2.517 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problemable here ; ugly no problem % or ugly no cute, loveable otherwise [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.945 (perp=6.722, rec=0.112, cos=0.489), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS].. character has reside not mind. ugly is problemable here ; ugly no problem % or cute, ugly no loveable otherwise [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.925 (perp=6.677, rec=0.100, cos=0.489), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS].. has character reside not mind. ugly is problemable here ; ugly no problem % or cute, ugly no loveable otherwise [SEP]']
[1800/2000] tot_loss=1.928 (perp=6.677, rec=0.104, cos=0.488), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS].. has character reside not mind. ugly is problemable here ; ugly no problem % or cute, ugly no loveable otherwise [SEP]']
Attempt swap
[1850/2000] tot_loss=1.934 (perp=6.677, rec=0.109, cos=0.490), tot_loss_proj:2.488 [t=0.23s]
prediction: ['[CLS].. has character reside not mind. ugly is problemable here ; ugly no problem % or cute, ugly no loveable otherwise [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.894 (perp=6.475, rec=0.109, cos=0.489), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS].. has character reside not mind. ugly is loveable here ; ugly no problem % or cute, ugly no problemable otherwise [SEP]']
[1950/2000] tot_loss=1.894 (perp=6.475, rec=0.110, cos=0.489), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS].. has character reside not mind. ugly is loveable here ; ugly no problem % or cute, ugly no problemable otherwise [SEP]']
Attempt swap
[2000/2000] tot_loss=1.885 (perp=6.475, rec=0.100, cos=0.490), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS].. has character reside not mind. ugly is loveable here ; ugly no problem % or cute, ugly no problemable otherwise [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS].. character has reside not mind. ugly is problem problem here ; ugly no %able or ugly no cute, loveable otherwise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 76.190 | r: 76.190
rouge2     | fm: 15.000 | p: 15.000 | r: 15.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 91.190

[Aggregate metrics]:
rouge1     | fm: 88.542 | p: 87.798 | r: 89.732
rouge2     | fm: 68.542 | p: 68.542 | r: 68.542
rougeL     | fm: 84.375 | p: 83.482 | r: 85.640
rougeLsum  | fm: 84.375 | p: 83.482 | r: 85.565
r1fm+r2fm = 157.083

input #7 time: 0:09:28 | total time: 1:12:29


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.7224863057781664
highest_index [0]
highest [0.7224863057781664]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6760414838790894 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6725492477416992 for ['[CLS] intra selfir major model centraliard doesncy do strait everyonetes exactly respect fine [UNK] musical smallerton eagleump bet recent [SEP]']
[Init] best rec loss: 0.6713458895683289 for ['[CLS] behalf eireann pts ask solutionog rhythm revived sky bonus derek yet affairsstick weird meaning now wellverse beforeα arterial centuries network [SEP]']
[Init] best rec loss: 0.6708147525787354 for ['[CLS] static academic mock lesionskali wanted £1 kelley assembly game ave koppen exclusion field gate coffee gift midway blood pageant jaya mortgage braden sophie [SEP]']
[Init] best rec loss: 0.6707859039306641 for ['[CLS] positions gocha rhine not ballet superiority closer advicejust grand noticesum service mr bomber mistakes up eve per altitude hearing verity constant [SEP]']
[Init] best rec loss: 0.6700199842453003 for ['[CLS] van heresum 24 different silence after countertrain glimpse might adventure jose sox deutscheь numbered rapids is axial distinguished arterial isndance [SEP]']
[Init] best rec loss: 0.6618243455886841 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.659675121307373 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.6591119766235352 for ['[CLS] mel hot keep tents now background colt station engagement letter flewhol regardless emroy alexia blue something thump second metres anna more soldier [SEP]']
[Init] best rec loss: 0.6472315192222595 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best perm rec loss: 0.6468570828437805 for ['[CLS] dated roots lindsey treated cases colour frowned americas discus thinkencies awesome won labor judge checkpoint virginia lined conferencedant perspective prizemeric quota [SEP]']
[Init] best perm rec loss: 0.6465305685997009 for ['[CLS] cases americas conference treated lindsey lined virginia judge frowned colour dated checkpoint awesome quota labor discusencies roots prizedant perspective think wonmeric [SEP]']
[Init] best perm rec loss: 0.6456159949302673 for ['[CLS] labor lindsey virginiaencies quotameric perspective checkpoint americas judge awesomedant cases won lined frowned discus dated prize roots think conference treated colour [SEP]']
[Init] best perm rec loss: 0.6455727815628052 for ['[CLS] colour discus americas datedencies cases lindsey roots lined frowned think conference awesome prize treated checkpointdant labor virginia perspectivemeric judge quota won [SEP]']
[Init] best perm rec loss: 0.6449669003486633 for ['[CLS] virginiadant lined treatedmeric prizeencies perspective quota checkpoint awesome cases dated labor judge lindsey think colour americas won discus roots conference frowned [SEP]']
[Init] best perm rec loss: 0.6436784863471985 for ['[CLS] casesencies americas judge lined think labor won lindsey perspective awesome treated conference checkpoint frowneddant dated prize roots discusmeric virginia colour quota [SEP]']
[Init] best perm rec loss: 0.6434054374694824 for ['[CLS] treated roots colour awesome lined think judge lindsey virginia quota labormeric americas won conferencedant cases perspective prizeencies discus checkpoint dated frowned [SEP]']
[Init] best perm rec loss: 0.6432918310165405 for ['[CLS] virginiadant americas lined prize roots conference judge won treated perspective checkpoint dated lindsey discus frowned quota colour labor think cases awesomemericencies [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.465 (perp=13.313, rec=0.339, cos=0.463), tot_loss_proj:4.048 [t=0.22s]
prediction: ['[CLS] fright vanity film vanity drama film film vanity vanity what paid % charity pay please offs for nothing debt department highlyrily fright paid [SEP]']
[ 100/2000] tot_loss=3.260 (perp=12.928, rec=0.260, cos=0.414), tot_loss_proj:3.834 [t=0.23s]
prediction: ['[CLS] fright vanity film vanity drama film film vanity vanity what pays what praise pays off off off enough debt department probablyly fright paid [SEP]']
[ 150/2000] tot_loss=3.132 (perp=12.538, rec=0.211, cos=0.413), tot_loss_proj:3.922 [t=0.23s]
prediction: ['[CLS] fright fright film vanity seems film film vanity vanity doubt pays what praise pays off off off they debt showed probably somehow fright paid [SEP]']
[ 200/2000] tot_loss=3.076 (perp=12.328, rec=0.181, cos=0.430), tot_loss_proj:3.948 [t=0.23s]
prediction: ['[CLS] fright fright film vanity, film that vanity vanity doubt pays whatlusion pays off off off they debt showed probablyless fright paid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.767 (perp=10.859, rec=0.154, cos=0.441), tot_loss_proj:3.609 [t=0.23s]
prediction: ["[CLS] a fright film vanity off film that vanity vanity doubt pays what buddhism pays off'off they debt needed doubt no fright paid [SEP]"]
[ 300/2000] tot_loss=2.824 (perp=11.182, rec=0.138, cos=0.449), tot_loss_proj:3.559 [t=0.23s]
prediction: ["[CLS] a fright filmful off film that vanity vanity doubt pays what benign pays off'off they debt tony doubt no fright paid [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.781 (perp=10.952, rec=0.124, cos=0.467), tot_loss_proj:3.590 [t=0.23s]
prediction: ["[CLS] a frightfulful off film that benign vanity doubt pays what benign pays off'off they debt tony doubt no fright owed [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.638 (perp=10.285, rec=0.126, cos=0.455), tot_loss_proj:3.508 [t=0.23s]
prediction: ["[CLS] a frightfulful wondered film that benign vanity doubt pays what benign pays off'off they debt miramax no fright owed [SEP]"]
[ 450/2000] tot_loss=2.620 (perp=10.285, rec=0.113, cos=0.450), tot_loss_proj:3.502 [t=0.23s]
prediction: ["[CLS] a frightfulful wondered film that benign vanity doubt pays what benign pays off'off they debt miramax no fright owed [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.580 (perp=10.062, rec=0.111, cos=0.457), tot_loss_proj:3.420 [t=0.23s]
prediction: ["[CLS] a frightful s owed film that benign vanity doubt pays what benign pays they'off off debt miramax no fright owed [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.612 (perp=10.209, rec=0.105, cos=0.465), tot_loss_proj:3.518 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays what benign pays they s off owed debt miramax no benign owed [SEP]']
[ 600/2000] tot_loss=2.665 (perp=10.468, rec=0.101, cos=0.470), tot_loss_proj:3.543 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays what benign pays felt s off owed debt miramax no benign owed [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.558 (perp=9.959, rec=0.103, cos=0.463), tot_loss_proj:3.464 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays what benign pays felt s off owed miramax no debt benign owed [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.454 (perp=9.441, rec=0.101, cos=0.465), tot_loss_proj:3.358 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays what benign pays benign felt s off owed miramax no debt owed [SEP]']
[ 750/2000] tot_loss=2.442 (perp=9.441, rec=0.101, cos=0.453), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays what benign pays benign felt s off owed miramax no debt owed [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.445 (perp=9.385, rec=0.098, cos=0.470), tot_loss_proj:3.464 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays felt whati pays benign s off owed miramax no debt owed [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.396 (perp=9.156, rec=0.094, cos=0.471), tot_loss_proj:3.309 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays felti what pays benign s off owed miramax no debt owed [SEP]']
[ 900/2000] tot_loss=2.398 (perp=9.156, rec=0.093, cos=0.474), tot_loss_proj:3.301 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays felti what pays benign s off owed miramax no debt owed [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.340 (perp=8.875, rec=0.093, cos=0.472), tot_loss_proj:3.322 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays felt what pays benigni s off owed miramax no debt owed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.343 (perp=8.875, rec=0.095, cos=0.472), tot_loss_proj:3.317 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays felt what pays benigni s off owed miramax no debt owed [SEP]']
[1050/2000] tot_loss=2.341 (perp=8.875, rec=0.094, cos=0.472), tot_loss_proj:3.319 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign vanity doubt pays felt what pays benigni s off owed miramax no debt owed [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.301 (perp=8.730, rec=0.089, cos=0.466), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays felt what pays benigni s off owed miramax no debt owed [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.299 (perp=8.686, rec=0.093, cos=0.468), tot_loss_proj:3.274 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
[1200/2000] tot_loss=2.300 (perp=8.686, rec=0.089, cos=0.474), tot_loss_proj:3.274 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.297 (perp=8.686, rec=0.090, cos=0.469), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.291 (perp=8.686, rec=0.082, cos=0.472), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
[1350/2000] tot_loss=2.302 (perp=8.686, rec=0.090, cos=0.474), tot_loss_proj:3.278 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.293 (perp=8.686, rec=0.086, cos=0.470), tot_loss_proj:3.273 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.297 (perp=8.686, rec=0.085, cos=0.474), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
[1500/2000] tot_loss=2.298 (perp=8.686, rec=0.086, cos=0.475), tot_loss_proj:3.275 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.295 (perp=8.686, rec=0.089, cos=0.469), tot_loss_proj:3.267 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.296 (perp=8.686, rec=0.085, cos=0.474), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
[1650/2000] tot_loss=2.305 (perp=8.686, rec=0.092, cos=0.477), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.296 (perp=8.686, rec=0.083, cos=0.475), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.302 (perp=8.686, rec=0.089, cos=0.475), tot_loss_proj:3.279 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
[1800/2000] tot_loss=2.298 (perp=8.686, rec=0.086, cos=0.476), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.295 (perp=8.686, rec=0.084, cos=0.474), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.301 (perp=8.686, rec=0.089, cos=0.476), tot_loss_proj:3.273 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
[1950/2000] tot_loss=2.295 (perp=8.686, rec=0.084, cos=0.474), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.302 (perp=8.686, rec=0.090, cos=0.475), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] a frightful s off film that benign doubt vanity pays what pays benigni s off owed felt miramax no debt owed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.721 | p: 78.261 | r: 90.000
rouge2     | fm: 9.756 | p: 9.091 | r: 10.526
rougeL     | fm: 51.163 | p: 47.826 | r: 55.000
rougeLsum  | fm: 51.163 | p: 47.826 | r: 55.000
r1fm+r2fm = 93.477

[Aggregate metrics]:
rouge1     | fm: 88.006 | p: 86.738 | r: 89.788
rouge2     | fm: 62.010 | p: 61.936 | r: 62.096
rougeL     | fm: 81.349 | p: 79.762 | r: 82.302
rougeLsum  | fm: 81.414 | p: 80.072 | r: 82.540
r1fm+r2fm = 150.016

input #8 time: 0:09:20 | total time: 1:21:49


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.7329690966152688
highest_index [0]
highest [0.7329690966152688]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7754597067832947 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6957485675811768 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6937089562416077 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.6785280704498291 for ['[CLS] military offered fragments gathered leaning sphere rom legs [SEP]']
[Init] best rec loss: 0.6618582010269165 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6613383293151855 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best rec loss: 0.6584380269050598 for ['[CLS] gage threw meredith run nounmics constituencies trade [SEP]']
[Init] best rec loss: 0.6560162901878357 for ['[CLS] save california liquidstownabiing plain for [SEP]']
[Init] best perm rec loss: 0.654316246509552 for ['[CLS] savestown liquidabi plaining for california [SEP]']
[Init] best perm rec loss: 0.6514967679977417 for ['[CLS] forabi liquid saveing california plainstown [SEP]']
[Init] best perm rec loss: 0.6514520049095154 for ['[CLS] california plainabiing save liquid forstown [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.800 (perp=15.175, rec=0.305, cos=0.460), tot_loss_proj:4.211 [t=0.22s]
prediction: ['[CLS] softheadoper fallingtra emotional clap polo [SEP]']
[ 100/2000] tot_loss=2.614 (perp=9.754, rec=0.203, cos=0.460), tot_loss_proj:2.947 [t=0.22s]
prediction: ['[CLS] softheaded claptra metaphysical claptra [SEP]']
[ 150/2000] tot_loss=2.547 (perp=9.754, rec=0.154, cos=0.442), tot_loss_proj:2.950 [t=0.22s]
prediction: ['[CLS] softheaded claptra metaphysical claptra [SEP]']
[ 200/2000] tot_loss=2.542 (perp=9.754, rec=0.126, cos=0.465), tot_loss_proj:2.955 [t=0.22s]
prediction: ['[CLS] softheaded claptra metaphysical claptra [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.419 (perp=9.162, rec=0.134, cos=0.453), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] metaphysical claptra softheaded claptra [SEP]']
[ 300/2000] tot_loss=2.570 (perp=10.007, rec=0.109, cos=0.459), tot_loss_proj:3.120 [t=0.22s]
prediction: ['[CLS] metaphysical clap of softheaded claptra [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.482 (perp=9.403, rec=0.155, cos=0.447), tot_loss_proj:3.027 [t=0.22s]
prediction: ['[CLS] clap of metaphysical softheaded claptra [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.564 (perp=9.980, rec=0.111, cos=0.457), tot_loss_proj:3.208 [t=0.22s]
prediction: ['[CLS] clap of metaphysical softheadedptra [SEP]']
[ 450/2000] tot_loss=2.547 (perp=9.980, rec=0.095, cos=0.457), tot_loss_proj:3.208 [t=0.22s]
prediction: ['[CLS] clap of metaphysical softheadedptra [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.319 (perp=8.847, rec=0.094, cos=0.455), tot_loss_proj:2.904 [t=0.22s]
prediction: ['[CLS] clap of metaphysical softheadedtrap [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.027 (perp=7.384, rec=0.100, cos=0.450), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 600/2000] tot_loss=2.022 (perp=7.384, rec=0.083, cos=0.463), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.014 (perp=7.384, rec=0.083, cos=0.455), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.003 (perp=7.384, rec=0.066, cos=0.461), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=2.006 (perp=7.384, rec=0.073, cos=0.456), tot_loss_proj:2.106 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.003 (perp=7.384, rec=0.068, cos=0.459), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.016 (perp=7.384, rec=0.077, cos=0.462), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.999 (perp=7.384, rec=0.062, cos=0.460), tot_loss_proj:2.098 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.996 (perp=7.384, rec=0.065, cos=0.455), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=2.012 (perp=7.384, rec=0.075, cos=0.460), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.998 (perp=7.384, rec=0.063, cos=0.459), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.999 (perp=7.384, rec=0.062, cos=0.460), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=2.015 (perp=7.384, rec=0.077, cos=0.461), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.999 (perp=7.384, rec=0.061, cos=0.462), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.992 (perp=7.384, rec=0.056, cos=0.460), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=2.002 (perp=7.384, rec=0.064, cos=0.461), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=2.001 (perp=7.384, rec=0.065, cos=0.459), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=2.000 (perp=7.384, rec=0.062, cos=0.460), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.996 (perp=7.384, rec=0.059, cos=0.461), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=2.012 (perp=7.384, rec=0.073, cos=0.463), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=2.003 (perp=7.384, rec=0.067, cos=0.460), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.996 (perp=7.384, rec=0.059, cos=0.459), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.996 (perp=7.384, rec=0.059, cos=0.460), tot_loss_proj:2.095 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=2.002 (perp=7.384, rec=0.064, cos=0.461), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=2.005 (perp=7.384, rec=0.067, cos=0.461), tot_loss_proj:2.103 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.999 (perp=7.384, rec=0.062, cos=0.461), tot_loss_proj:2.099 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=2.011 (perp=7.384, rec=0.074, cos=0.461), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.999 (perp=7.384, rec=0.061, cos=0.461), tot_loss_proj:2.099 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=2.006 (perp=7.384, rec=0.068, cos=0.462), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=7.384, rec=0.053, cos=0.461), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 89.344 | p: 88.064 | r: 90.905
rouge2     | fm: 60.130 | p: 60.030 | r: 60.219
rougeL     | fm: 81.070 | p: 80.119 | r: 82.619
rougeLsum  | fm: 81.661 | p: 80.735 | r: 83.000
r1fm+r2fm = 149.474

input #9 time: 0:08:56 | total time: 1:30:46


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.7192190302473489
highest_index [0]
highest [0.7192190302473489]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8356432318687439 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8165798783302307 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7829566597938538 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6784284114837646 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6767041087150574 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6749845147132874 for ['[CLS] angel up order places totally blessed sheep level commonoric themes soundblood [SEP]']
[Init] best perm rec loss: 0.6740692853927612 for ['[CLS] sheep totally angel sound themes order level commonblood places uporic blessed [SEP]']
[Init] best perm rec loss: 0.6736748218536377 for ['[CLS] angeloric blessed sheep order sound themes upblood common totally places level [SEP]']
[Init] best perm rec loss: 0.6733413338661194 for ['[CLS] sound sheep common angelblood level placesoric totally up order blessed themes [SEP]']
[Init] best perm rec loss: 0.6728028059005737 for ['[CLS] level common totally sound themes angel placesoric up order sheep blessedblood [SEP]']
[Init] best perm rec loss: 0.6711030602455139 for ['[CLS] sound order common level angel themes blessedoric up places totally sheepblood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.264 (perp=12.150, rec=0.364, cos=0.470), tot_loss_proj:4.024 [t=0.22s]
prediction: ['[CLS] blend kathleen dominant based with emphasis independent compassion freedom solutions your perspectiveless [SEP]']
[ 100/2000] tot_loss=2.596 (perp=9.628, rec=0.203, cos=0.468), tot_loss_proj:3.670 [t=0.23s]
prediction: ['[CLS] balance abulsively rhythms balanceulsive rhythms risk with. rhythmless [SEP]']
[ 150/2000] tot_loss=2.552 (perp=9.712, rec=0.144, cos=0.466), tot_loss_proj:3.156 [t=0.23s]
prediction: ['[CLS] balance abulsively rhythms balance real rhythms incident with.ulsiveulsive [SEP]']
[ 200/2000] tot_loss=2.530 (perp=9.712, rec=0.112, cos=0.476), tot_loss_proj:3.159 [t=0.23s]
prediction: ['[CLS] balance abulsively rhythms balance real rhythms incident with.ulsiveulsive [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.371 (perp=8.921, rec=0.111, cos=0.477), tot_loss_proj:3.011 [t=0.23s]
prediction: ['[CLS] balance abulsively rhythms balance real with incident rhythms.ulsiveulsive [SEP]']
[ 300/2000] tot_loss=2.413 (perp=9.129, rec=0.104, cos=0.483), tot_loss_proj:3.052 [t=0.23s]
prediction: ['[CLS] balance absly rhythms balance real with incident time.ulsiveulsive [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.331 (perp=8.763, rec=0.101, cos=0.478), tot_loss_proj:2.774 [t=0.23s]
prediction: ['[CLS] balancely ably rhythms balance real with incident time.ulsiveulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.359 (perp=8.901, rec=0.103, cos=0.476), tot_loss_proj:2.783 [t=0.23s]
prediction: ['[CLS] balancely ably rhythms balancing real with incident time.ulsiveulsive [SEP]']
[ 450/2000] tot_loss=2.317 (perp=8.778, rec=0.085, cos=0.476), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] balance - ably rhythmss real with incident time.lyulsive [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.227 (perp=8.315, rec=0.093, cos=0.470), tot_loss_proj:2.641 [t=0.23s]
prediction: ['[CLS] balances ablys real rhythms with incident time.ulsiveulsive [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.147 (perp=7.922, rec=0.088, cos=0.474), tot_loss_proj:2.556 [t=0.23s]
prediction: ['[CLS] balances ablys real time with incident rhythms.lyulsive [SEP]']
[ 600/2000] tot_loss=2.144 (perp=7.922, rec=0.086, cos=0.474), tot_loss_proj:2.559 [t=0.23s]
prediction: ['[CLS] balances ablys real time with incident rhythms.lyulsive [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.043 (perp=7.421, rec=0.086, cos=0.473), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] balances ablys real time with incident rhythms.ulsively [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.049 (perp=7.421, rec=0.081, cos=0.483), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] balances ablys real time with incident rhythms.ulsively [SEP]']
[ 750/2000] tot_loss=2.046 (perp=7.421, rec=0.085, cos=0.476), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] balances ablys real time with incident rhythms.ulsively [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.092 (perp=7.642, rec=0.084, cos=0.480), tot_loss_proj:2.453 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythms.ulsively [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.084 (perp=7.642, rec=0.076, cos=0.480), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythms.ulsively [SEP]']
[ 900/2000] tot_loss=2.076 (perp=7.642, rec=0.069, cos=0.478), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythms.ulsively [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.030 (perp=7.290, rec=0.095, cos=0.477), tot_loss_proj:2.327 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incidentulsively rhythms. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.968 (perp=7.088, rec=0.074, cos=0.477), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1050/2000] tot_loss=1.974 (perp=7.088, rec=0.082, cos=0.475), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.974 (perp=7.088, rec=0.079, cos=0.477), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.967 (perp=7.088, rec=0.071, cos=0.479), tot_loss_proj:2.350 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1200/2000] tot_loss=1.966 (perp=7.088, rec=0.068, cos=0.480), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.974 (perp=7.088, rec=0.078, cos=0.478), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.971 (perp=7.088, rec=0.075, cos=0.479), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1350/2000] tot_loss=1.969 (perp=7.088, rec=0.073, cos=0.479), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.972 (perp=7.088, rec=0.075, cos=0.480), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.961 (perp=7.088, rec=0.064, cos=0.479), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1500/2000] tot_loss=1.963 (perp=7.088, rec=0.067, cos=0.478), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.962 (perp=7.088, rec=0.064, cos=0.480), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.969 (perp=7.088, rec=0.073, cos=0.479), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1650/2000] tot_loss=1.972 (perp=7.088, rec=0.075, cos=0.479), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.976 (perp=7.088, rec=0.078, cos=0.480), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.972 (perp=7.088, rec=0.074, cos=0.480), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1800/2000] tot_loss=1.969 (perp=7.088, rec=0.071, cos=0.480), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.965 (perp=7.088, rec=0.067, cos=0.480), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.967 (perp=7.088, rec=0.069, cos=0.480), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
[1950/2000] tot_loss=1.960 (perp=7.088, rec=0.063, cos=0.480), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.970 (perp=7.088, rec=0.073, cos=0.480), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] balance - ablys real time with incident rhythmsulsively. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.158 | p: 66.667 | r: 60.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 63.158 | p: 66.667 | r: 60.000
rougeLsum  | fm: 63.158 | p: 66.667 | r: 60.000
r1fm+r2fm = 74.923

[Aggregate metrics]:
rouge1     | fm: 87.241 | p: 86.580 | r: 88.290
rouge2     | fm: 55.022 | p: 55.103 | r: 55.072
rougeL     | fm: 79.438 | p: 78.698 | r: 80.303
rougeLsum  | fm: 79.718 | p: 79.150 | r: 80.541
r1fm+r2fm = 142.263

input #10 time: 0:09:24 | total time: 1:40:11


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.7153372554390516
highest_index [0]
highest [0.7153372554390516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8586066365242004 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8579170107841492 for ['[CLS] changelift tonig half moth bodo contractgmche [SEP]']
[Init] best rec loss: 0.8430718779563904 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7753808498382568 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7749102711677551 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.7724854350090027 for ['[CLS] drawnture tal platform inland mileguvd familiar me [SEP]']
[Init] best perm rec loss: 0.7724201083183289 for ['[CLS]gu me tal familiar milevd drawnture inland platform [SEP]']
[Init] best perm rec loss: 0.7721070051193237 for ['[CLS]gu inland drawn me mile tal platformvdture familiar [SEP]']
[Init] best perm rec loss: 0.7707154750823975 for ['[CLS]ture me platform inland mile talgu drawnvd familiar [SEP]']
[Init] best perm rec loss: 0.7700195908546448 for ['[CLS] tal drawnturegu mile platform inland mevd familiar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.623 (perp=13.957, rec=0.349, cos=0.482), tot_loss_proj:4.334 [t=0.22s]
prediction: ['[CLS] horses small refused violent route gun missingterol mor refused [SEP]']
[ 100/2000] tot_loss=3.259 (perp=12.510, rec=0.270, cos=0.487), tot_loss_proj:4.074 [t=0.23s]
prediction: ['[CLS] horses stubborn stubborn attempted gel never refused gel gel refused [SEP]']
[ 150/2000] tot_loss=3.052 (perp=11.833, rec=0.217, cos=0.469), tot_loss_proj:3.651 [t=0.23s]
prediction: ['[CLS] here was stubborn attempted attempted cannot refused gel gel refused [SEP]']
[ 200/2000] tot_loss=2.881 (perp=11.048, rec=0.190, cos=0.481), tot_loss_proj:3.492 [t=0.23s]
prediction: ['[CLS] here that stubborn being attempted easily refused stubborn gel refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.696 (perp=10.386, rec=0.137, cos=0.482), tot_loss_proj:3.296 [t=0.23s]
prediction: ['[CLS] here that stubborn being attemptedly refused gel stubborn refused [SEP]']
[ 300/2000] tot_loss=2.712 (perp=10.577, rec=0.113, cos=0.483), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] here that stubborn was attemptedly refused gel stubborn refused [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.542 (perp=9.715, rec=0.113, cos=0.487), tot_loss_proj:3.178 [t=0.23s]
prediction: ['[CLS] here was attempted that stubbornly refused gel stubborn refused [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.373 (perp=8.928, rec=0.107, cos=0.480), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] here was attempted that stubborn stubbornly to gel refused [SEP]']
[ 450/2000] tot_loss=2.356 (perp=8.928, rec=0.085, cos=0.485), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] here was attempted that stubborn stubbornly to gel refused [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.091 (perp=7.523, rec=0.100, cos=0.486), tot_loss_proj:2.619 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.079 (perp=7.523, rec=0.089, cos=0.486), tot_loss_proj:2.619 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[ 600/2000] tot_loss=2.065 (perp=7.523, rec=0.077, cos=0.484), tot_loss_proj:2.620 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.067 (perp=7.523, rec=0.078, cos=0.484), tot_loss_proj:2.624 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.069 (perp=7.523, rec=0.083, cos=0.482), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[ 750/2000] tot_loss=2.081 (perp=7.523, rec=0.091, cos=0.485), tot_loss_proj:2.597 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.071 (perp=7.523, rec=0.082, cos=0.485), tot_loss_proj:2.618 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.067 (perp=7.523, rec=0.077, cos=0.486), tot_loss_proj:2.620 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[ 900/2000] tot_loss=2.074 (perp=7.523, rec=0.086, cos=0.483), tot_loss_proj:2.620 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.067 (perp=7.523, rec=0.077, cos=0.485), tot_loss_proj:2.620 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.199 (perp=8.162, rec=0.081, cos=0.485), tot_loss_proj:2.841 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubbornly refused stubborn [SEP]']
[1050/2000] tot_loss=2.206 (perp=8.162, rec=0.087, cos=0.487), tot_loss_proj:2.837 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubbornly refused stubborn [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.074 (perp=7.523, rec=0.082, cos=0.487), tot_loss_proj:2.623 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1150/2000] tot_loss=2.070 (perp=7.523, rec=0.080, cos=0.485), tot_loss_proj:2.625 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1200/2000] tot_loss=2.250 (perp=8.418, rec=0.082, cos=0.484), tot_loss_proj:2.923 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn refusedly refused [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.136 (perp=7.856, rec=0.080, cos=0.485), tot_loss_proj:2.756 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubbornly stubborn refused [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.069 (perp=7.523, rec=0.080, cos=0.485), tot_loss_proj:2.592 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1350/2000] tot_loss=2.191 (perp=8.124, rec=0.080, cos=0.486), tot_loss_proj:2.913 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that refused stubbornly refused [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.135 (perp=7.856, rec=0.077, cos=0.487), tot_loss_proj:2.760 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubbornly stubborn refused [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.071 (perp=7.523, rec=0.080, cos=0.486), tot_loss_proj:2.604 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
[1500/2000] tot_loss=2.064 (perp=7.523, rec=0.073, cos=0.486), tot_loss_proj:2.599 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1550/2000] tot_loss=2.069 (perp=7.523, rec=0.078, cos=0.487), tot_loss_proj:2.599 [t=0.23s]
prediction: ['[CLS] here was attempted to gel that stubborn stubbornly refused [SEP]']
Attempt swap
[1600/2000] tot_loss=2.068 (perp=7.533, rec=0.075, cos=0.486), tot_loss_proj:2.638 [t=0.23s]
prediction: ['[CLS] here was attempted to gel thatively stubbornly refused [SEP]']
[1650/2000] tot_loss=2.066 (perp=7.533, rec=0.074, cos=0.486), tot_loss_proj:2.637 [t=0.23s]
prediction: ['[CLS] here was attempted to gel thatively stubbornly refused [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.991 (perp=7.144, rec=0.078, cos=0.485), tot_loss_proj:2.571 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1750/2000] tot_loss=1.995 (perp=7.144, rec=0.082, cos=0.484), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
[1800/2000] tot_loss=1.990 (perp=7.144, rec=0.076, cos=0.485), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1850/2000] tot_loss=1.994 (perp=7.144, rec=0.080, cos=0.485), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1900/2000] tot_loss=2.002 (perp=7.144, rec=0.089, cos=0.484), tot_loss_proj:2.572 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
[1950/2000] tot_loss=1.989 (perp=7.144, rec=0.075, cos=0.485), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=7.144, rec=0.077, cos=0.485), tot_loss_proj:2.566 [t=0.23s]
prediction: ['[CLS] here wasively attempted to gel that stubbornly refused [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted to gel that stubbornly stubborn refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 87.362 | p: 86.702 | r: 88.369
rouge2     | fm: 51.932 | p: 51.938 | r: 51.942
rougeL     | fm: 78.179 | p: 77.624 | r: 78.927
rougeLsum  | fm: 78.099 | p: 77.543 | r: 78.900
r1fm+r2fm = 139.295

input #11 time: 0:09:20 | total time: 1:49:32


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.7252753190814749
highest_index [0]
highest [0.7252753190814749]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8357966542243958 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8331353664398193 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7881600260734558 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7833784818649292 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7794924974441528 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7623517513275146 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.752221405506134 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7346014380455017 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best perm rec loss: 0.7336472868919373 for ['[CLS] gotbank wiseuid friend semi didn richards [MASK] alivethed expression beloved investigation [SEP]']
[Init] best perm rec loss: 0.7284104228019714 for ['[CLS] didnbank gotthed wise semi expressionuid friend investigation beloved [MASK] richards alive [SEP]']
[Init] best perm rec loss: 0.727780282497406 for ['[CLS]uid alive expressionbank [MASK]thed investigation wise got semi didn richards friend beloved [SEP]']
[Init] best perm rec loss: 0.725124180316925 for ['[CLS] semi [MASK] investigationthed alive richards didn expression belovedbankuid got friend wise [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.707 (perp=9.742, rec=0.298, cos=0.461), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS], drinking seen better cable better cable better cable proved not during weak signal [SEP]']
[ 100/2000] tot_loss=2.768 (perp=10.453, rec=0.223, cos=0.454), tot_loss_proj:3.318 [t=0.23s]
prediction: ['[CLS] that cable seen barely cable advantage advantage better advantage barely barely during your cable [SEP]']
[ 150/2000] tot_loss=2.720 (perp=10.432, rec=0.169, cos=0.464), tot_loss_proj:3.285 [t=0.23s]
prediction: ['[CLS] that seen seen barely cable on advantage better advantage barely barely during its cable [SEP]']
[ 200/2000] tot_loss=2.588 (perp=9.752, rec=0.171, cos=0.467), tot_loss_proj:3.115 [t=0.23s]
prediction: ['[CLS] that seen seen barely cable on to better advantage purposes barely especially its barely [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.399 (perp=9.033, rec=0.128, cos=0.464), tot_loss_proj:3.020 [t=0.23s]
prediction: ['[CLS] that seen seen barely on cable to better advantage if barely especially its it [SEP]']
[ 300/2000] tot_loss=2.389 (perp=9.042, rec=0.114, cos=0.466), tot_loss_proj:2.968 [t=0.23s]
prediction: ['[CLS] that seen will barely on cable to better advantage if barely especially its, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.275 (perp=8.517, rec=0.114, cos=0.458), tot_loss_proj:2.769 [t=0.23s]
prediction: ['[CLS] barely seen will that on cable to better advantage its barely especially its, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.237 (perp=8.341, rec=0.098, cos=0.471), tot_loss_proj:2.735 [t=0.23s]
prediction: ['[CLS] barely seen will that on cable to better advantage if especially its its barely [SEP]']
[ 450/2000] tot_loss=2.231 (perp=8.341, rec=0.094, cos=0.469), tot_loss_proj:2.731 [t=0.23s]
prediction: ['[CLS] barely seen will that on cable to better advantage if especially its its barely [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.232 (perp=8.388, rec=0.084, cos=0.471), tot_loss_proj:2.766 [t=0.23s]
prediction: ['[CLS] barely seen will that on cable to better advantage especially its especially its barely [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.133 (perp=7.884, rec=0.085, cos=0.472), tot_loss_proj:2.669 [t=0.23s]
prediction: ['[CLS] barely seen will that on cable to better advantage considering its, its barely [SEP]']
[ 600/2000] tot_loss=2.127 (perp=7.884, rec=0.083, cos=0.467), tot_loss_proj:2.669 [t=0.23s]
prediction: ['[CLS] barely seen will that on cable to better advantage considering its, its barely [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.075 (perp=7.612, rec=0.084, cos=0.469), tot_loss_proj:2.677 [t=0.23s]
prediction: ['[CLS] barely that will seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.087 (perp=7.673, rec=0.084, cos=0.468), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
[ 750/2000] tot_loss=2.088 (perp=7.673, rec=0.081, cos=0.472), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.090 (perp=7.673, rec=0.083, cos=0.472), tot_loss_proj:2.641 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.083 (perp=7.673, rec=0.081, cos=0.467), tot_loss_proj:2.637 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
[ 900/2000] tot_loss=2.094 (perp=7.673, rec=0.088, cos=0.471), tot_loss_proj:2.637 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.092 (perp=7.673, rec=0.086, cos=0.472), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1000/2000] tot_loss=2.238 (perp=8.398, rec=0.085, cos=0.474), tot_loss_proj:2.665 [t=0.23s]
prediction: ['[CLS] considering will that seen on cable to better advantage considering its especially its barely [SEP]']
[1050/2000] tot_loss=2.222 (perp=8.398, rec=0.076, cos=0.466), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] considering will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.085 (perp=7.673, rec=0.079, cos=0.471), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1150/2000] tot_loss=2.087 (perp=7.673, rec=0.080, cos=0.472), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
[1200/2000] tot_loss=2.082 (perp=7.673, rec=0.078, cos=0.470), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1250/2000] tot_loss=2.084 (perp=7.673, rec=0.080, cos=0.470), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1300/2000] tot_loss=2.091 (perp=7.673, rec=0.083, cos=0.474), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
[1350/2000] tot_loss=2.087 (perp=7.673, rec=0.083, cos=0.469), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1400/2000] tot_loss=2.079 (perp=7.673, rec=0.073, cos=0.472), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1450/2000] tot_loss=2.086 (perp=7.673, rec=0.079, cos=0.472), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
[1500/2000] tot_loss=2.082 (perp=7.673, rec=0.076, cos=0.472), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its especially its barely [SEP]']
Attempt swap
[1550/2000] tot_loss=2.027 (perp=7.381, rec=0.080, cos=0.470), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
[1600/2000] tot_loss=2.020 (perp=7.381, rec=0.072, cos=0.472), tot_loss_proj:2.644 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
[1650/2000] tot_loss=2.031 (perp=7.381, rec=0.082, cos=0.473), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
[1700/2000] tot_loss=2.025 (perp=7.381, rec=0.079, cos=0.470), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
[1750/2000] tot_loss=2.033 (perp=7.381, rec=0.085, cos=0.472), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
[1800/2000] tot_loss=2.024 (perp=7.381, rec=0.074, cos=0.474), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
[1850/2000] tot_loss=2.026 (perp=7.381, rec=0.079, cos=0.471), tot_loss_proj:2.646 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
[1900/2000] tot_loss=2.022 (perp=7.381, rec=0.073, cos=0.473), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
[1950/2000] tot_loss=2.029 (perp=7.381, rec=0.080, cos=0.472), tot_loss_proj:2.651 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Attempt swap
[2000/2000] tot_loss=2.030 (perp=7.381, rec=0.080, cos=0.474), tot_loss_proj:2.652 [t=0.23s]
prediction: ['[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely will that seen on cable to better advantage considering its, its barely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 129.524

[Aggregate metrics]:
rouge1     | fm: 87.301 | p: 86.686 | r: 88.273
rouge2     | fm: 51.247 | p: 51.259 | r: 51.238
rougeL     | fm: 77.261 | p: 76.856 | r: 78.082
rougeLsum  | fm: 77.379 | p: 76.939 | r: 78.027
r1fm+r2fm = 138.549

input #12 time: 0:09:11 | total time: 1:58:43


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.7142934172168275
highest_index [0]
highest [0.7142934172168275]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.6912899613380432 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.6909309029579163 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6855183839797974 for ['[CLS] todd travel time mountain relation territorial same [SEP]']
[Init] best rec loss: 0.6852613687515259 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
[Init] best perm rec loss: 0.6847466826438904 for ['[CLS] round heads colonial fraternity et dressed bahn [SEP]']
[Init] best perm rec loss: 0.683843731880188 for ['[CLS] heads fraternity colonial et dressed bahn round [SEP]']
[Init] best perm rec loss: 0.6812395453453064 for ['[CLS] dressed colonial heads round et bahn fraternity [SEP]']
[Init] best perm rec loss: 0.6808826327323914 for ['[CLS] colonial fraternity dressed bahn heads round et [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.615 (perp=9.385, rec=0.277, cos=0.461), tot_loss_proj:3.337 [t=0.22s]
prediction: ['[CLS] flame flames point by flame into flame [SEP]']
[ 100/2000] tot_loss=2.892 (perp=11.193, rec=0.169, cos=0.485), tot_loss_proj:3.182 [t=0.22s]
prediction: ['[CLS] explode things point by things into flame [SEP]']
[ 150/2000] tot_loss=2.493 (perp=9.274, rec=0.152, cos=0.485), tot_loss_proj:3.007 [t=0.22s]
prediction: ['[CLS] at things point at things into flame [SEP]']
[ 200/2000] tot_loss=2.385 (perp=8.958, rec=0.126, cos=0.468), tot_loss_proj:2.936 [t=0.22s]
prediction: ['[CLS] at at point at things into flame [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.500 (perp=9.489, rec=0.136, cos=0.466), tot_loss_proj:3.087 [t=0.22s]
prediction: ['[CLS] at point on explode things explode flame [SEP]']
[ 300/2000] tot_loss=2.479 (perp=9.446, rec=0.105, cos=0.485), tot_loss_proj:2.991 [t=0.23s]
prediction: ['[CLS] at point at explode things explode flame [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.355 (perp=8.923, rec=0.099, cos=0.471), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] at point on explode things into flame [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.312 (perp=8.631, rec=0.092, cos=0.494), tot_loss_proj:2.672 [t=0.22s]
prediction: ['[CLS] at point on things explode into flame [SEP]']
[ 450/2000] tot_loss=2.299 (perp=8.631, rec=0.092, cos=0.481), tot_loss_proj:2.668 [t=0.22s]
prediction: ['[CLS] at point on things explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.384 (perp=9.154, rec=0.090, cos=0.463), tot_loss_proj:2.733 [t=0.22s]
prediction: ['[CLS] at point into things explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.392 (perp=9.154, rec=0.087, cos=0.474), tot_loss_proj:2.736 [t=0.22s]
prediction: ['[CLS] at point into things explode into flame [SEP]']
[ 600/2000] tot_loss=2.131 (perp=7.828, rec=0.081, cos=0.484), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] at point that things explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.295 (perp=8.737, rec=0.071, cos=0.477), tot_loss_proj:2.704 [t=0.22s]
prediction: ['[CLS] at at point things explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.204 (perp=8.240, rec=0.090, cos=0.466), tot_loss_proj:2.552 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
[ 750/2000] tot_loss=2.211 (perp=8.240, rec=0.084, cos=0.480), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.209 (perp=8.240, rec=0.089, cos=0.472), tot_loss_proj:2.552 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.208 (perp=8.240, rec=0.084, cos=0.476), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
[ 900/2000] tot_loss=2.215 (perp=8.240, rec=0.082, cos=0.485), tot_loss_proj:2.558 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.211 (perp=8.240, rec=0.084, cos=0.479), tot_loss_proj:2.556 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=2.210 (perp=8.240, rec=0.082, cos=0.479), tot_loss_proj:2.552 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
[1050/2000] tot_loss=2.212 (perp=8.240, rec=0.082, cos=0.482), tot_loss_proj:2.554 [t=0.22s]
prediction: ['[CLS] at point at things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=2.121 (perp=7.828, rec=0.080, cos=0.475), tot_loss_proj:2.494 [t=0.23s]
prediction: ['[CLS] at point that things explode into flame [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.839 (perp=6.423, rec=0.084, cos=0.470), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.837 (perp=6.423, rec=0.073, cos=0.479), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.845 (perp=6.423, rec=0.076, cos=0.485), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.848 (perp=6.423, rec=0.081, cos=0.482), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.855 (perp=6.423, rec=0.084, cos=0.486), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.843 (perp=6.423, rec=0.078, cos=0.481), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.846 (perp=6.423, rec=0.080, cos=0.481), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.852 (perp=6.423, rec=0.085, cos=0.482), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.843 (perp=6.423, rec=0.073, cos=0.486), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.852 (perp=6.423, rec=0.083, cos=0.485), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.842 (perp=6.423, rec=0.074, cos=0.483), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.845 (perp=6.423, rec=0.076, cos=0.484), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.848 (perp=6.423, rec=0.080, cos=0.484), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.841 (perp=6.423, rec=0.072, cos=0.484), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.850 (perp=6.423, rec=0.080, cos=0.485), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.849 (perp=6.423, rec=0.083, cos=0.481), tot_loss_proj:2.232 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.852 (perp=6.423, rec=0.084, cos=0.484), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.846 (perp=6.423, rec=0.081, cos=0.481), tot_loss_proj:2.234 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 88.240 | p: 87.680 | r: 89.111
rouge2     | fm: 50.335 | p: 50.400 | r: 50.379
rougeL     | fm: 77.247 | p: 76.716 | r: 77.876
rougeLsum  | fm: 77.247 | p: 76.817 | r: 77.905
r1fm+r2fm = 138.574

input #13 time: 0:09:08 | total time: 2:07:51


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.7338084541540982
highest_index [0]
highest [0.7338084541540982]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9932660460472107 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.983971357345581 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9830400347709656 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 0.9732319712638855 for ['[CLS] green stepped one battle rear [SEP]']
[Init] best rec loss: 0.963213324546814 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9573075175285339 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9510475993156433 for ['[CLS]pace chicago is thrust youth [SEP]']
[Init] best rec loss: 0.9492325186729431 for ['[CLS] baton channel along presided corners [SEP]']
[Init] best rec loss: 0.937239408493042 for ['[CLS] strategy sigh hk automatically county [SEP]']
[Init] best rec loss: 0.9339707493782043 for ['[CLS] dirtig directionseous dealer [SEP]']
[Init] best rec loss: 0.9338452219963074 for ['[CLS] initial freeway spannged extended [SEP]']
[Init] best perm rec loss: 0.9326875805854797 for ['[CLS] extendednged initial span freeway [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.590 (perp=12.290, rec=0.659, cos=0.472), tot_loss_proj:4.327 [t=0.22s]
prediction: ['[CLS] sake satisfy sand regret moaned [SEP]']
[ 100/2000] tot_loss=3.336 (perp=11.536, rec=0.594, cos=0.436), tot_loss_proj:4.302 [t=0.22s]
prediction: ['[CLS] innocent completely confront regret moaned [SEP]']
[ 150/2000] tot_loss=3.935 (perp=14.439, rec=0.573, cos=0.474), tot_loss_proj:4.874 [t=0.23s]
prediction: ['[CLS] innocent utterlyberry unanimous lacked [SEP]']
[ 200/2000] tot_loss=3.522 (perp=12.846, rec=0.540, cos=0.413), tot_loss_proj:4.421 [t=0.23s]
prediction: ['[CLS] geschichteenia jake lies nothing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.687 (perp=13.527, rec=0.541, cos=0.441), tot_loss_proj:4.479 [t=0.23s]
prediction: ['[CLS] jakeenia innocent lies intriguing [SEP]']
[ 300/2000] tot_loss=3.577 (perp=13.147, rec=0.512, cos=0.436), tot_loss_proj:4.094 [t=0.23s]
prediction: ['[CLS] jakeenia context intriguing intriguing [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.441 (perp=12.350, rec=0.523, cos=0.448), tot_loss_proj:3.861 [t=0.23s]
prediction: ['[CLS] jakeenia intriguing context intriguing [SEP]']
Attempt swap
[ 400/2000] tot_loss=4.008 (perp=15.112, rec=0.533, cos=0.452), tot_loss_proj:4.955 [t=0.23s]
prediction: ['[CLS] billionaireenia intriguing rearview nothing [SEP]']
[ 450/2000] tot_loss=3.387 (perp=12.299, rec=0.489, cos=0.438), tot_loss_proj:3.922 [t=0.23s]
prediction: ['[CLS] screenenia intriguing context intriguing [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.313 (perp=11.944, rec=0.494, cos=0.430), tot_loss_proj:3.629 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.376 (perp=11.944, rec=0.497, cos=0.491), tot_loss_proj:3.625 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
[ 600/2000] tot_loss=3.636 (perp=13.449, rec=0.495, cos=0.451), tot_loss_proj:4.202 [t=0.23s]
prediction: ['[CLS] intriguing crambidaeenia context intriguing [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.341 (perp=11.944, rec=0.496, cos=0.456), tot_loss_proj:3.641 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.354 (perp=11.944, rec=0.480, cos=0.485), tot_loss_proj:3.634 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
[ 750/2000] tot_loss=3.330 (perp=11.944, rec=0.475, cos=0.466), tot_loss_proj:3.642 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.311 (perp=11.944, rec=0.475, cos=0.447), tot_loss_proj:3.636 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.301 (perp=11.944, rec=0.460, cos=0.452), tot_loss_proj:3.640 [t=0.23s]
prediction: ['[CLS] intriguing intriguingenia context intriguing [SEP]']
[ 900/2000] tot_loss=3.376 (perp=12.466, rec=0.460, cos=0.422), tot_loss_proj:3.622 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia context intriguing [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.394 (perp=12.466, rec=0.467, cos=0.434), tot_loss_proj:3.616 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia context intriguing [SEP]']
Attempt swap
[1000/2000] tot_loss=3.343 (perp=12.466, rec=0.454, cos=0.396), tot_loss_proj:3.626 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia context intriguing [SEP]']
[1050/2000] tot_loss=3.389 (perp=12.466, rec=0.458, cos=0.437), tot_loss_proj:3.621 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia context intriguing [SEP]']
Attempt swap
[1100/2000] tot_loss=3.657 (perp=13.818, rec=0.459, cos=0.434), tot_loss_proj:4.163 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1150/2000] tot_loss=3.383 (perp=12.466, rec=0.461, cos=0.429), tot_loss_proj:3.626 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia context intriguing [SEP]']
[1200/2000] tot_loss=3.663 (perp=13.818, rec=0.453, cos=0.447), tot_loss_proj:4.167 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1250/2000] tot_loss=3.672 (perp=13.818, rec=0.453, cos=0.456), tot_loss_proj:4.163 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1300/2000] tot_loss=3.399 (perp=12.466, rec=0.454, cos=0.451), tot_loss_proj:3.621 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia context intriguing [SEP]']
[1350/2000] tot_loss=3.670 (perp=13.818, rec=0.451, cos=0.456), tot_loss_proj:4.153 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1400/2000] tot_loss=3.659 (perp=13.818, rec=0.448, cos=0.447), tot_loss_proj:4.164 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1450/2000] tot_loss=3.653 (perp=13.818, rec=0.451, cos=0.438), tot_loss_proj:4.159 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
[1500/2000] tot_loss=3.650 (perp=13.818, rec=0.441, cos=0.445), tot_loss_proj:4.157 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1550/2000] tot_loss=3.674 (perp=13.818, rec=0.448, cos=0.462), tot_loss_proj:4.160 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1600/2000] tot_loss=3.666 (perp=13.818, rec=0.445, cos=0.457), tot_loss_proj:4.164 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
[1650/2000] tot_loss=3.666 (perp=13.818, rec=0.444, cos=0.459), tot_loss_proj:4.162 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1700/2000] tot_loss=3.674 (perp=13.818, rec=0.447, cos=0.463), tot_loss_proj:4.158 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1750/2000] tot_loss=3.655 (perp=13.818, rec=0.443, cos=0.448), tot_loss_proj:4.157 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
[1800/2000] tot_loss=3.662 (perp=13.818, rec=0.441, cos=0.457), tot_loss_proj:4.160 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1850/2000] tot_loss=3.658 (perp=13.818, rec=0.437, cos=0.457), tot_loss_proj:4.159 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[1900/2000] tot_loss=3.670 (perp=13.818, rec=0.441, cos=0.466), tot_loss_proj:4.158 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
[1950/2000] tot_loss=3.658 (perp=13.818, rec=0.441, cos=0.453), tot_loss_proj:4.159 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Attempt swap
[2000/2000] tot_loss=3.659 (perp=13.818, rec=0.436, cos=0.459), tot_loss_proj:4.154 [t=0.23s]
prediction: ['[CLS] fascinating intriguingenia rearview intriguing [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] fascinating intriguingenia rearview intriguing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 50.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 54.545

[Aggregate metrics]:
rouge1     | fm: 85.790 | p: 84.949 | r: 86.999
rouge2     | fm: 47.328 | p: 47.308 | r: 47.332
rougeL     | fm: 75.577 | p: 74.732 | r: 76.601
rougeLsum  | fm: 75.518 | p: 74.918 | r: 76.465
r1fm+r2fm = 133.118

input #14 time: 0:09:01 | total time: 2:16:53


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.7321959116817749
highest_index [0]
highest [0.7321959116817749]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8397291302680969 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8367235660552979 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8360617756843567 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.8356341123580933 for ['[CLS] peak hi ann household base pdsight succeeded [SEP]']
[Init] best rec loss: 0.8207116723060608 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8093830943107605 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best perm rec loss: 0.8086205720901489 for ['[CLS] consumer diner martha much trooper safegly [CLS] [SEP]']
[Init] best perm rec loss: 0.808378279209137 for ['[CLS] [CLS] troopergly consumer safe diner much martha [SEP]']
[Init] best perm rec loss: 0.8076009750366211 for ['[CLS] much [CLS] martha consumergly diner safe trooper [SEP]']
[Init] best perm rec loss: 0.8066493272781372 for ['[CLS] much trooper diner consumergly martha safe [CLS] [SEP]']
[Init] best perm rec loss: 0.8066418170928955 for ['[CLS] much consumer diner martha safe troopergly [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.056 (perp=11.553, rec=0.280, cos=0.465), tot_loss_proj:4.148 [t=0.22s]
prediction: ['[CLS] efficient offended efficient stated criteria suit ;. [SEP]']
[ 100/2000] tot_loss=2.869 (perp=11.039, rec=0.202, cos=0.459), tot_loss_proj:3.550 [t=0.22s]
prediction: ['[CLS] suit chill efficientablyably chiller. [SEP]']
[ 150/2000] tot_loss=2.841 (perp=11.138, rec=0.156, cos=0.458), tot_loss_proj:3.645 [t=0.22s]
prediction: ['[CLS] suit chill efficient anonymousably chiller. [SEP]']
[ 200/2000] tot_loss=3.201 (perp=12.979, rec=0.143, cos=0.462), tot_loss_proj:4.067 [t=0.22s]
prediction: ['[CLS] suit chill efficient anonymousably chillerer [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.639 (perp=10.325, rec=0.116, cos=0.458), tot_loss_proj:3.085 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chill.er [SEP]']
[ 300/2000] tot_loss=2.627 (perp=10.325, rec=0.102, cos=0.460), tot_loss_proj:3.073 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chill.er [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.183 (perp=8.043, rec=0.117, cos=0.457), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.165 (perp=8.043, rec=0.094, cos=0.462), tot_loss_proj:2.372 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[ 450/2000] tot_loss=2.166 (perp=8.043, rec=0.096, cos=0.461), tot_loss_proj:2.375 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.156 (perp=8.043, rec=0.084, cos=0.464), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.161 (perp=8.043, rec=0.088, cos=0.464), tot_loss_proj:2.383 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[ 600/2000] tot_loss=2.156 (perp=8.043, rec=0.084, cos=0.464), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.152 (perp=8.043, rec=0.082, cos=0.461), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.158 (perp=8.043, rec=0.087, cos=0.463), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[ 750/2000] tot_loss=2.154 (perp=8.043, rec=0.081, cos=0.464), tot_loss_proj:2.380 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.152 (perp=8.043, rec=0.079, cos=0.464), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.156 (perp=8.043, rec=0.085, cos=0.463), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[ 900/2000] tot_loss=2.150 (perp=8.043, rec=0.078, cos=0.464), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.148 (perp=8.043, rec=0.076, cos=0.463), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.157 (perp=8.043, rec=0.084, cos=0.464), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1050/2000] tot_loss=2.154 (perp=8.043, rec=0.082, cos=0.464), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.155 (perp=8.043, rec=0.082, cos=0.464), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.155 (perp=8.043, rec=0.083, cos=0.463), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1200/2000] tot_loss=2.163 (perp=8.043, rec=0.090, cos=0.464), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.151 (perp=8.043, rec=0.079, cos=0.463), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.160 (perp=8.043, rec=0.088, cos=0.463), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1350/2000] tot_loss=2.150 (perp=8.043, rec=0.078, cos=0.463), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.150 (perp=8.043, rec=0.078, cos=0.463), tot_loss_proj:2.385 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.155 (perp=8.043, rec=0.083, cos=0.464), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1500/2000] tot_loss=2.151 (perp=8.043, rec=0.078, cos=0.464), tot_loss_proj:2.394 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.151 (perp=8.043, rec=0.079, cos=0.464), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.157 (perp=8.043, rec=0.084, cos=0.464), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1650/2000] tot_loss=2.145 (perp=8.043, rec=0.073, cos=0.463), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.144 (perp=8.043, rec=0.072, cos=0.464), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.153 (perp=8.043, rec=0.081, cos=0.463), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1800/2000] tot_loss=2.156 (perp=8.043, rec=0.084, cos=0.464), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.146 (perp=8.043, rec=0.074, cos=0.463), tot_loss_proj:2.398 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.142 (perp=8.043, rec=0.070, cos=0.464), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1950/2000] tot_loss=2.148 (perp=8.043, rec=0.076, cos=0.464), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.151 (perp=8.043, rec=0.078, cos=0.464), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient anonymous chill chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 110.490

[Aggregate metrics]:
rouge1     | fm: 86.286 | p: 85.011 | r: 87.825
rouge2     | fm: 45.465 | p: 45.343 | r: 45.594
rougeL     | fm: 75.813 | p: 74.818 | r: 77.026
rougeLsum  | fm: 75.968 | p: 74.908 | r: 77.087
r1fm+r2fm = 131.751

input #15 time: 0:09:10 | total time: 2:26:04


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.724125755127423
highest_index [0]
highest [0.724125755127423]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8513087034225464 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8321547508239746 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8311194181442261 for ['[CLS]sa base slave shadow irvingdale [SEP]']
[Init] best rec loss: 0.8300525546073914 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 0.7908363938331604 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7814875841140747 for ['[CLS] south jefferson late guy e sophia [SEP]']
[Init] best rec loss: 0.7446358799934387 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7381218671798706 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 0.7233297824859619 for ['[CLS]worthy eat town normal court earth [SEP]']
[Init] best perm rec loss: 0.7217859625816345 for ['[CLS] town court earth normal eatworthy [SEP]']
[Init] best perm rec loss: 0.7213669419288635 for ['[CLS] normal town courtworthy earth eat [SEP]']
[Init] best perm rec loss: 0.7194731831550598 for ['[CLS] court normal eat town earthworthy [SEP]']
[Init] best perm rec loss: 0.7193859815597534 for ['[CLS] court eat townworthy earth normal [SEP]']
[Init] best perm rec loss: 0.7185770869255066 for ['[CLS] court eatworthy town earth normal [SEP]']
[Init] best perm rec loss: 0.716998279094696 for ['[CLS]worthy town normal eat court earth [SEP]']
[Init] best perm rec loss: 0.7163437604904175 for ['[CLS] normalworthy court town eat earth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.331 (perp=7.775, rec=0.308, cos=0.468), tot_loss_proj:2.728 [t=0.22s]
prediction: ['[CLS] more all more the this more [SEP]']
[ 100/2000] tot_loss=2.241 (perp=8.012, rec=0.172, cos=0.467), tot_loss_proj:2.674 [t=0.22s]
prediction: ['[CLS] all all, the this more [SEP]']
[ 150/2000] tot_loss=1.861 (perp=6.385, rec=0.108, cos=0.476), tot_loss_proj:2.264 [t=0.23s]
prediction: ['[CLS] and all, of this more [SEP]']
[ 200/2000] tot_loss=1.844 (perp=6.385, rec=0.092, cos=0.475), tot_loss_proj:2.258 [t=0.23s]
prediction: ['[CLS] and all, of this more [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.594 (perp=5.201, rec=0.079, cos=0.475), tot_loss_proj:1.825 [t=0.23s]
prediction: ['[CLS] and all of this, more [SEP]']
[ 300/2000] tot_loss=1.580 (perp=5.201, rec=0.070, cos=0.470), tot_loss_proj:1.821 [t=0.23s]
prediction: ['[CLS] and all of this, more [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.469 (perp=4.697, rec=0.065, cos=0.465), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.473 (perp=4.697, rec=0.063, cos=0.471), tot_loss_proj:1.558 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.479 (perp=4.697, rec=0.065, cos=0.474), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.479 (perp=4.697, rec=0.066, cos=0.474), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.481 (perp=4.697, rec=0.067, cos=0.474), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.475 (perp=4.697, rec=0.067, cos=0.469), tot_loss_proj:1.571 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.475 (perp=4.697, rec=0.060, cos=0.476), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.482 (perp=4.697, rec=0.071, cos=0.472), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.477 (perp=4.697, rec=0.069, cos=0.468), tot_loss_proj:1.574 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.472 (perp=4.697, rec=0.060, cos=0.473), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.482 (perp=4.697, rec=0.069, cos=0.474), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.468 (perp=4.697, rec=0.057, cos=0.472), tot_loss_proj:1.571 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.464 (perp=4.697, rec=0.051, cos=0.474), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.472 (perp=4.697, rec=0.060, cos=0.472), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.476 (perp=4.697, rec=0.064, cos=0.472), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.479 (perp=4.697, rec=0.066, cos=0.473), tot_loss_proj:1.577 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.465 (perp=4.697, rec=0.055, cos=0.471), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.470 (perp=4.697, rec=0.057, cos=0.474), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.471 (perp=4.697, rec=0.058, cos=0.473), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.479 (perp=4.697, rec=0.065, cos=0.474), tot_loss_proj:1.568 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.473 (perp=4.697, rec=0.058, cos=0.475), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.468 (perp=4.697, rec=0.055, cos=0.474), tot_loss_proj:1.571 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.474 (perp=4.697, rec=0.060, cos=0.474), tot_loss_proj:1.568 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.471 (perp=4.697, rec=0.061, cos=0.471), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.470 (perp=4.697, rec=0.057, cos=0.473), tot_loss_proj:1.557 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.479 (perp=4.697, rec=0.065, cos=0.475), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.474 (perp=4.697, rec=0.060, cos=0.474), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.471 (perp=4.697, rec=0.058, cos=0.473), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.467 (perp=4.697, rec=0.054, cos=0.473), tot_loss_proj:1.567 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.462 (perp=4.697, rec=0.049, cos=0.474), tot_loss_proj:1.564 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.470 (perp=4.697, rec=0.056, cos=0.475), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.467 (perp=4.697, rec=0.053, cos=0.474), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.471 (perp=4.697, rec=0.057, cos=0.474), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=4.697, rec=0.062, cos=0.474), tot_loss_proj:1.566 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.952 | p: 85.989 | r: 88.484
rouge2     | fm: 48.393 | p: 48.285 | r: 48.475
rougeL     | fm: 77.305 | p: 76.266 | r: 78.674
rougeLsum  | fm: 76.889 | p: 75.860 | r: 78.188
r1fm+r2fm = 135.346

input #16 time: 0:09:11 | total time: 2:35:15


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.7133127073551653
highest_index [0]
highest [0.7133127073551653]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8074320554733276 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.7958653569221497 for ['[CLS] angle bond masonacle cabinachejord right is kiel woman [SEP]']
[Init] best rec loss: 0.7880663871765137 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7773454189300537 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7675485610961914 for ['[CLS] wild filing curls wandabuck day victor which judicial coach peyton [SEP]']
[Init] best perm rec loss: 0.7669933438301086 for ['[CLS] coach day wanda whichbuck curls peyton filing judicial wild victor [SEP]']
[Init] best perm rec loss: 0.7642293572425842 for ['[CLS] day wanda curls wildbuck filing victor peyton judicial coach which [SEP]']
[Init] best perm rec loss: 0.7638117671012878 for ['[CLS] wildbuck coach victor which wanda day curls filing peyton judicial [SEP]']
[Init] best perm rec loss: 0.7638011574745178 for ['[CLS] which peyton wild curls judicial victor wanda filingbuck day coach [SEP]']
[Init] best perm rec loss: 0.7618858218193054 for ['[CLS] victor judicial coach wanda curls wild peyton day whichbuck filing [SEP]']
[Init] best perm rec loss: 0.761821985244751 for ['[CLS] wanda filing victor coachbuck wild peyton day judicial which curls [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.787 (perp=10.381, rec=0.239, cos=0.473), tot_loss_proj:3.373 [t=0.22s]
prediction: ['[CLS] want really dex a too much what much about think much [SEP]']
[ 100/2000] tot_loss=2.608 (perp=10.064, rec=0.121, cos=0.474), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] want too to on too much what about about think much [SEP]']
[ 150/2000] tot_loss=2.627 (perp=10.266, rec=0.086, cos=0.488), tot_loss_proj:3.246 [t=0.23s]
prediction: ['[CLS] want though to to too much what about going think much [SEP]']
[ 200/2000] tot_loss=2.636 (perp=10.266, rec=0.093, cos=0.490), tot_loss_proj:3.229 [t=0.23s]
prediction: ['[CLS] want though to to too much what about going think much [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.385 (perp=8.975, rec=0.104, cos=0.486), tot_loss_proj:2.917 [t=0.23s]
prediction: ['[CLS] want going going to too much think about going what much [SEP]']
[ 300/2000] tot_loss=2.360 (perp=8.975, rec=0.081, cos=0.484), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] want going going to too much think about going what much [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.140 (perp=7.836, rec=0.085, cos=0.488), tot_loss_proj:2.785 [t=0.23s]
prediction: ['[CLS] want to too much merely going think about going what much [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.099 (perp=7.618, rec=0.091, cos=0.484), tot_loss_proj:2.717 [t=0.23s]
prediction: ['[CLS] want to too much going merely think about going what much [SEP]']
[ 450/2000] tot_loss=2.087 (perp=7.618, rec=0.075, cos=0.488), tot_loss_proj:2.718 [t=0.23s]
prediction: ['[CLS] want to too much going merely think about going what much [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.076 (perp=7.564, rec=0.077, cos=0.487), tot_loss_proj:2.708 [t=0.23s]
prediction: ['[CLS] want to too much going think about merely going what much [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.008 (perp=7.116, rec=0.095, cos=0.490), tot_loss_proj:2.544 [t=0.23s]
prediction: ['[CLS] want to too much think about when going what much s [SEP]']
[ 600/2000] tot_loss=1.992 (perp=7.116, rec=0.082, cos=0.487), tot_loss_proj:2.526 [t=0.23s]
prediction: ['[CLS] want to too much think about when going what much s [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.875 (perp=6.502, rec=0.084, cos=0.491), tot_loss_proj:2.426 [t=0.23s]
prediction: ['[CLS] want too much to think about when going what much s [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.794 (perp=6.177, rec=0.072, cos=0.487), tot_loss_proj:2.282 [t=0.23s]
prediction: ['[CLS] want too much to think about when what much s going [SEP]']
[ 750/2000] tot_loss=1.764 (perp=6.032, rec=0.069, cos=0.489), tot_loss_proj:2.213 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.765 (perp=6.032, rec=0.072, cos=0.487), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.832 (perp=6.336, rec=0.078, cos=0.487), tot_loss_proj:2.306 [t=0.23s]
prediction: ['[CLS] want too much to think about what when much s going [SEP]']
[ 900/2000] tot_loss=1.826 (perp=6.336, rec=0.069, cos=0.489), tot_loss_proj:2.307 [t=0.23s]
prediction: ['[CLS] want too much to think about what when much s going [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.806 (perp=6.177, rec=0.083, cos=0.488), tot_loss_proj:2.278 [t=0.23s]
prediction: ['[CLS] want too much to think about when what much s going [SEP]']
Attempt swap
[1000/2000] tot_loss=1.768 (perp=6.032, rec=0.073, cos=0.488), tot_loss_proj:2.195 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
[1050/2000] tot_loss=1.876 (perp=6.531, rec=0.078, cos=0.491), tot_loss_proj:2.375 [t=0.23s]
prediction: ['[CLS] want too much to think about who what much s going [SEP]']
Attempt swap
[1100/2000] tot_loss=1.771 (perp=6.032, rec=0.077, cos=0.488), tot_loss_proj:2.193 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[1150/2000] tot_loss=1.768 (perp=6.032, rec=0.074, cos=0.487), tot_loss_proj:2.192 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
[1200/2000] tot_loss=1.768 (perp=6.032, rec=0.072, cos=0.489), tot_loss_proj:2.192 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=6.032, rec=0.075, cos=0.490), tot_loss_proj:2.189 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.771 (perp=6.032, rec=0.077, cos=0.488), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
[1350/2000] tot_loss=1.915 (perp=6.794, rec=0.066, cos=0.491), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] want too much to think about what who much s going [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.763 (perp=6.032, rec=0.067, cos=0.490), tot_loss_proj:2.188 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[1450/2000] tot_loss=1.867 (perp=6.531, rec=0.071, cos=0.489), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] want too much to think about who what much s going [SEP]']
[1500/2000] tot_loss=1.772 (perp=6.032, rec=0.076, cos=0.490), tot_loss_proj:2.185 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.755 (perp=6.032, rec=0.060, cos=0.489), tot_loss_proj:2.207 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=6.032, rec=0.072, cos=0.490), tot_loss_proj:2.200 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
[1650/2000] tot_loss=1.768 (perp=6.032, rec=0.071, cos=0.490), tot_loss_proj:2.207 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[1700/2000] tot_loss=1.767 (perp=6.032, rec=0.070, cos=0.491), tot_loss_proj:2.202 [t=0.29s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.769 (perp=6.032, rec=0.072, cos=0.491), tot_loss_proj:2.187 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
[1800/2000] tot_loss=1.760 (perp=6.032, rec=0.063, cos=0.491), tot_loss_proj:2.194 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.769 (perp=6.032, rec=0.073, cos=0.490), tot_loss_proj:2.203 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
[1900/2000] tot_loss=1.772 (perp=6.032, rec=0.076, cos=0.490), tot_loss_proj:2.205 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
[1950/2000] tot_loss=1.770 (perp=6.032, rec=0.074, cos=0.490), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.770 (perp=6.032, rec=0.073, cos=0.490), tot_loss_proj:2.183 [t=0.23s]
prediction: ['[CLS] want too much to think about what what much s going [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want too much to think about what what much s going [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 131.478

[Aggregate metrics]:
rouge1     | fm: 87.242 | p: 85.985 | r: 88.766
rouge2     | fm: 48.476 | p: 48.291 | r: 48.668
rougeL     | fm: 76.871 | p: 75.825 | r: 78.345
rougeLsum  | fm: 76.427 | p: 75.361 | r: 78.029
r1fm+r2fm = 135.718

input #17 time: 0:09:32 | total time: 2:44:48


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.7397700568427445
highest_index [0]
highest [0.7397700568427445]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9957432150840759 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9102372527122498 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8888423442840576 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.8687734007835388 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.829239547252655 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best perm rec loss: 0.8247649073600769 for ['[CLS] garrettlastic alternative filed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.676 (perp=9.671, rec=0.285, cos=0.457), tot_loss_proj:3.148 [t=0.22s]
prediction: ['[CLS] injoing majesty [SEP]']
[ 100/2000] tot_loss=2.665 (perp=10.150, rec=0.184, cos=0.451), tot_loss_proj:2.855 [t=0.22s]
prediction: ['[CLS] ingoratingating [SEP]']
[ 150/2000] tot_loss=2.672 (perp=10.367, rec=0.148, cos=0.450), tot_loss_proj:3.177 [t=0.22s]
prediction: ['[CLS] ingoratinggor [SEP]']
[ 200/2000] tot_loss=2.499 (perp=9.688, rec=0.110, cos=0.452), tot_loss_proj:3.334 [t=0.22s]
prediction: ['[CLS] ingoratingvi [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.643 (perp=5.588, rec=0.074, cos=0.452), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.640 (perp=5.588, rec=0.071, cos=0.452), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.641 (perp=5.588, rec=0.071, cos=0.453), tot_loss_proj:1.634 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.644 (perp=5.588, rec=0.075, cos=0.451), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.634 (perp=5.588, rec=0.065, cos=0.452), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.637 (perp=5.588, rec=0.068, cos=0.451), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.627 (perp=5.588, rec=0.059, cos=0.451), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.638 (perp=5.588, rec=0.068, cos=0.452), tot_loss_proj:1.642 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.640 (perp=5.588, rec=0.071, cos=0.452), tot_loss_proj:1.643 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.638 (perp=5.588, rec=0.069, cos=0.451), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.632 (perp=5.588, rec=0.063, cos=0.452), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.630 (perp=5.588, rec=0.061, cos=0.452), tot_loss_proj:1.618 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.624 (perp=5.588, rec=0.056, cos=0.451), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.634 (perp=5.588, rec=0.065, cos=0.451), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.631 (perp=5.588, rec=0.062, cos=0.451), tot_loss_proj:1.629 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.645 (perp=5.588, rec=0.077, cos=0.451), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.630 (perp=5.588, rec=0.061, cos=0.452), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.627 (perp=5.588, rec=0.057, cos=0.452), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.638 (perp=5.588, rec=0.069, cos=0.451), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.636 (perp=5.588, rec=0.066, cos=0.452), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.628 (perp=5.588, rec=0.057, cos=0.453), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.632 (perp=5.588, rec=0.063, cos=0.452), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.636 (perp=5.588, rec=0.067, cos=0.451), tot_loss_proj:1.636 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.636 (perp=5.588, rec=0.067, cos=0.451), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.646 (perp=5.588, rec=0.076, cos=0.452), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.627 (perp=5.588, rec=0.057, cos=0.452), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.624 (perp=5.588, rec=0.054, cos=0.452), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.630 (perp=5.588, rec=0.060, cos=0.452), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.623 (perp=5.588, rec=0.053, cos=0.452), tot_loss_proj:1.639 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.635 (perp=5.588, rec=0.065, cos=0.452), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.639 (perp=5.588, rec=0.069, cos=0.452), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.633 (perp=5.588, rec=0.063, cos=0.453), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.623 (perp=5.588, rec=0.053, cos=0.452), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.620 (perp=5.588, rec=0.050, cos=0.453), tot_loss_proj:1.633 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.640 (perp=5.588, rec=0.070, cos=0.452), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.626 (perp=5.588, rec=0.057, cos=0.452), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.851 | p: 86.711 | r: 89.332
rouge2     | fm: 51.216 | p: 51.095 | r: 51.381
rougeL     | fm: 78.188 | p: 77.143 | r: 79.515
rougeLsum  | fm: 77.897 | p: 76.844 | r: 79.222
r1fm+r2fm = 139.067

input #18 time: 0:09:06 | total time: 2:53:55


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.7433188955726568
highest_index [0]
highest [0.7433188955726568]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7281616926193237 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7201614379882812 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7113519310951233 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6810477375984192 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6755580902099609 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.672921359539032 for ['[CLS] reaching pin orderyna [SEP]']
[Init] best perm rec loss: 0.6728169322013855 for ['[CLS] reaching orderyna pin [SEP]']
[Init] best perm rec loss: 0.6716654896736145 for ['[CLS] pinyna reaching order [SEP]']
[Init] best perm rec loss: 0.670573353767395 for ['[CLS] reachingyna pin order [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.143 (perp=11.857, rec=0.313, cos=0.459), tot_loss_proj:3.774 [t=0.22s]
prediction: ['[CLS] infainefa [SEP]']
[ 100/2000] tot_loss=2.666 (perp=10.619, rec=0.111, cos=0.431), tot_loss_proj:3.658 [t=0.22s]
prediction: ['[CLS] to inmyfa [SEP]']
[ 150/2000] tot_loss=2.655 (perp=10.619, rec=0.096, cos=0.435), tot_loss_proj:3.650 [t=0.22s]
prediction: ['[CLS] to inmyfa [SEP]']
[ 200/2000] tot_loss=2.671 (perp=10.619, rec=0.098, cos=0.449), tot_loss_proj:3.642 [t=0.22s]
prediction: ['[CLS] to inmyfa [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.747 (perp=6.110, rec=0.083, cos=0.442), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.743 (perp=6.110, rec=0.078, cos=0.442), tot_loss_proj:1.761 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.734 (perp=6.110, rec=0.072, cos=0.441), tot_loss_proj:1.775 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.745 (perp=6.110, rec=0.081, cos=0.441), tot_loss_proj:1.775 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.740 (perp=6.110, rec=0.071, cos=0.447), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.741 (perp=6.110, rec=0.081, cos=0.439), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.733 (perp=6.110, rec=0.070, cos=0.441), tot_loss_proj:1.758 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.745 (perp=6.110, rec=0.077, cos=0.445), tot_loss_proj:1.767 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.738 (perp=6.110, rec=0.076, cos=0.441), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.742 (perp=6.110, rec=0.073, cos=0.448), tot_loss_proj:1.770 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.722 (perp=6.110, rec=0.063, cos=0.437), tot_loss_proj:1.761 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.718 (perp=6.110, rec=0.056, cos=0.440), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.733 (perp=6.110, rec=0.070, cos=0.440), tot_loss_proj:1.754 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.737 (perp=6.110, rec=0.071, cos=0.444), tot_loss_proj:1.773 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.728 (perp=6.110, rec=0.068, cos=0.438), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.735 (perp=6.110, rec=0.068, cos=0.445), tot_loss_proj:1.762 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.739 (perp=6.110, rec=0.074, cos=0.443), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.730 (perp=6.110, rec=0.069, cos=0.439), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.720 (perp=6.110, rec=0.060, cos=0.438), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.732 (perp=6.110, rec=0.065, cos=0.445), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.717 (perp=6.110, rec=0.054, cos=0.442), tot_loss_proj:1.763 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=6.110, rec=0.062, cos=0.446), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.728 (perp=6.110, rec=0.060, cos=0.446), tot_loss_proj:1.764 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.730 (perp=6.110, rec=0.065, cos=0.442), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.725 (perp=6.110, rec=0.056, cos=0.447), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.725 (perp=6.110, rec=0.059, cos=0.444), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.724 (perp=6.110, rec=0.058, cos=0.444), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.723 (perp=6.110, rec=0.059, cos=0.442), tot_loss_proj:1.766 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.730 (perp=6.110, rec=0.061, cos=0.447), tot_loss_proj:1.764 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.730 (perp=6.110, rec=0.062, cos=0.446), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.734 (perp=6.110, rec=0.067, cos=0.445), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.723 (perp=6.110, rec=0.055, cos=0.446), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.725 (perp=6.110, rec=0.058, cos=0.445), tot_loss_proj:1.764 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=6.110, rec=0.068, cos=0.446), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.728 (perp=6.110, rec=0.060, cos=0.446), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.730 (perp=6.110, rec=0.062, cos=0.446), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.463 | p: 87.304 | r: 89.867
rouge2     | fm: 53.352 | p: 53.209 | r: 53.584
rougeL     | fm: 79.518 | p: 78.486 | r: 80.677
rougeLsum  | fm: 79.047 | p: 77.987 | r: 80.414
r1fm+r2fm = 141.815

input #19 time: 0:09:29 | total time: 3:03:24


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.7257428376344448
highest_index [0]
highest [0.7257428376344448]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.858415961265564 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7921519875526428 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.7911581993103027 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.7829775214195251 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best rec loss: 0.7789577841758728 for ['[CLS] club provious microphone [SEP]']
[Init] best perm rec loss: 0.7734328508377075 for ['[CLS] pro club microphonevious [SEP]']
[Init] best perm rec loss: 0.7732015252113342 for ['[CLS] microphone provious club [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.920 (perp=10.865, rec=0.261, cos=0.486), tot_loss_proj:3.620 [t=0.22s]
prediction: ['[CLS] pleasureverseverseverse [SEP]']
[ 100/2000] tot_loss=2.797 (perp=10.809, rec=0.165, cos=0.471), tot_loss_proj:3.438 [t=0.22s]
prediction: ['[CLS] pleasureverse per luna [SEP]']
[ 150/2000] tot_loss=2.792 (perp=11.111, rec=0.114, cos=0.455), tot_loss_proj:3.539 [t=0.22s]
prediction: ['[CLS] pleasureverse per the [SEP]']
[ 200/2000] tot_loss=2.769 (perp=11.111, rec=0.076, cos=0.470), tot_loss_proj:3.542 [t=0.22s]
prediction: ['[CLS] pleasureverse per the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.083 (perp=7.535, rec=0.108, cos=0.468), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 300/2000] tot_loss=2.057 (perp=7.535, rec=0.080, cos=0.470), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.050 (perp=7.535, rec=0.069, cos=0.474), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.054 (perp=7.535, rec=0.076, cos=0.471), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 450/2000] tot_loss=2.043 (perp=7.535, rec=0.069, cos=0.466), tot_loss_proj:2.418 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.045 (perp=7.535, rec=0.070, cos=0.468), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.049 (perp=7.535, rec=0.069, cos=0.473), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 600/2000] tot_loss=2.036 (perp=7.535, rec=0.058, cos=0.470), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.041 (perp=7.535, rec=0.064, cos=0.470), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.047 (perp=7.535, rec=0.068, cos=0.472), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 750/2000] tot_loss=2.046 (perp=7.535, rec=0.068, cos=0.471), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.032 (perp=7.535, rec=0.059, cos=0.467), tot_loss_proj:2.416 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.054 (perp=7.535, rec=0.076, cos=0.471), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 900/2000] tot_loss=2.043 (perp=7.535, rec=0.067, cos=0.469), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.043 (perp=7.535, rec=0.065, cos=0.471), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=2.050 (perp=7.535, rec=0.072, cos=0.471), tot_loss_proj:2.410 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1050/2000] tot_loss=2.050 (perp=7.535, rec=0.071, cos=0.472), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=2.037 (perp=7.535, rec=0.060, cos=0.471), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=2.047 (perp=7.535, rec=0.069, cos=0.471), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1200/2000] tot_loss=2.048 (perp=7.535, rec=0.071, cos=0.469), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=2.042 (perp=7.535, rec=0.067, cos=0.469), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=2.041 (perp=7.535, rec=0.063, cos=0.471), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1350/2000] tot_loss=2.049 (perp=7.535, rec=0.069, cos=0.473), tot_loss_proj:2.417 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=2.040 (perp=7.535, rec=0.061, cos=0.471), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=2.042 (perp=7.535, rec=0.063, cos=0.471), tot_loss_proj:2.416 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1500/2000] tot_loss=2.049 (perp=7.535, rec=0.069, cos=0.473), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=2.040 (perp=7.535, rec=0.061, cos=0.472), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=2.044 (perp=7.535, rec=0.066, cos=0.471), tot_loss_proj:2.417 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1650/2000] tot_loss=2.042 (perp=7.535, rec=0.062, cos=0.473), tot_loss_proj:2.416 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=2.041 (perp=7.535, rec=0.063, cos=0.471), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=2.040 (perp=7.535, rec=0.063, cos=0.470), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1800/2000] tot_loss=2.052 (perp=7.535, rec=0.072, cos=0.473), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=2.042 (perp=7.535, rec=0.063, cos=0.472), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=2.049 (perp=7.535, rec=0.070, cos=0.471), tot_loss_proj:2.419 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1950/2000] tot_loss=2.047 (perp=7.535, rec=0.068, cos=0.472), tot_loss_proj:2.416 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=2.040 (perp=7.535, rec=0.061, cos=0.473), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] pleasure the perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.906 | p: 87.806 | r: 90.292
rouge2     | fm: 52.274 | p: 52.091 | r: 52.482
rougeL     | fm: 79.411 | p: 78.494 | r: 80.664
rougeLsum  | fm: 79.020 | p: 78.093 | r: 80.311
r1fm+r2fm = 141.181

input #20 time: 0:08:58 | total time: 3:12:23


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.7199390766824261
highest_index [0]
highest [0.7199390766824261]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8414236307144165 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8116742372512817 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.795457124710083 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.7909337282180786 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7819795608520508 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7665277719497681 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.766447126865387 for ['[CLS] stony golden pose according situations vii baby dee side she loan [UNK] general faunatakingback rights connecticut especially size labor item bent there, [SEP]']
[Init] best perm rec loss: 0.7659233808517456 for ['[CLS] situations side benttaking loan according she dee vii fauna stony goldenback rights [UNK] baby especially size general there pose labor item, connecticut [SEP]']
[Init] best perm rec loss: 0.765320897102356 for ['[CLS] side [UNK] connecticut there dee according especially loan labor she golden baby stony size vii bent posetaking item fauna general situations,back rights [SEP]']
[Init] best perm rec loss: 0.764909565448761 for ['[CLS] especially fauna [UNK] size according side bent vii baby item she there stony rights loan connecticut goldentaking pose dee general labor situationsback, [SEP]']
[Init] best perm rec loss: 0.7642800807952881 for ['[CLS] especially pose fauna there, rights size item connecticutbacktaking baby vii she loan general labor according dee stony situations bent golden side [UNK] [SEP]']
[Init] best perm rec loss: 0.764168381690979 for ['[CLS] she rightsback golden [UNK] there labor, situations general side dee connecticut item according especially baby loan stony fauna benttaking vii pose size [SEP]']
[Init] best perm rec loss: 0.7639139294624329 for ['[CLS] golden rights, fauna pose side especially dee situations general bent stony thereback itemtaking [UNK] according baby vii she size loan connecticut labor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.249 (perp=11.856, rec=0.399, cos=0.480), tot_loss_proj:3.721 [t=0.22s]
prediction: ['[CLS] faux poll out children avoid if only even were diagnostic missionaries speedy plain riding equipment women divided typical which monitoring or mountain fixing less experts [SEP]']
[ 100/2000] tot_loss=3.267 (perp=12.082, rec=0.362, cos=0.488), tot_loss_proj:3.712 [t=0.23s]
prediction: ['[CLS] stink build out children compatibility way instead referred of athletes serious poorly plain佐 works women how potential radio athletes out aired graduating less doctors [SEP]']
[ 150/2000] tot_loss=2.831 (perp=10.367, rec=0.279, cos=0.478), tot_loss_proj:3.393 [t=0.23s]
prediction: ['[CLS] movie the made womenʐ out instead like of athletes serioustypical are clergy action women american themb of, portrayed of less athletes [SEP]']
[ 200/2000] tot_loss=3.060 (perp=11.667, rec=0.238, cos=0.488), tot_loss_proj:3.909 [t=0.23s]
prediction: ['[CLS] way way makes women │ works instead look women athletes serioustypical are religiouspo of way the and in, entered serious less athletes [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.955 (perp=11.378, rec=0.200, cos=0.479), tot_loss_proj:3.862 [t=0.23s]
prediction: ['[CLS] serious way makes women players works instead look women athletes serioustypical slung caretaker international of way the and teachers, entered oneself more athletes [SEP]']
[ 300/2000] tot_loss=2.902 (perp=11.226, rec=0.183, cos=0.474), tot_loss_proj:3.791 [t=0.23s]
prediction: ['[CLS] serious way makes women players works instead look women athletes serioustypical stereo caretaker seminar of way the and teachers, entered oneself more athletes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.633 (perp=9.964, rec=0.162, cos=0.478), tot_loss_proj:3.609 [t=0.23s]
prediction: ['[CLS] serious way makes women players works instead look the athletes serioustypical stereo caretaker ; of this women and teachers, entered oneself more athletes [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.555 (perp=9.624, rec=0.149, cos=0.481), tot_loss_proj:3.712 [t=0.23s]
prediction: ['[CLS] serious way makes women players works instead look thetypical stereo caretaker ; of this athletes serious women and teachers, entered oneself more athletes [SEP]']
[ 450/2000] tot_loss=2.521 (perp=9.521, rec=0.139, cos=0.478), tot_loss_proj:3.708 [t=0.23s]
prediction: ['[CLS] serious way makes women players works instead look thetypical stereo caretaker. of all athletes serious women and teachers, appearances oneself more athletes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.410 (perp=8.993, rec=0.128, cos=0.483), tot_loss_proj:3.638 [t=0.23s]
prediction: ['[CLS] serious way makes women players works instead look the caretaker stereotypical. of all athletes serious women and teachers, appearances oneself more athletes [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.346 (perp=8.626, rec=0.136, cos=0.484), tot_loss_proj:3.575 [t=0.23s]
prediction: ['[CLS] the serious way makes women works instead look the caretaker stereotypical. of all athletes serious women and teachers, appearances oneself more athletes [SEP]']
[ 600/2000] tot_loss=2.323 (perp=8.626, rec=0.119, cos=0.479), tot_loss_proj:3.578 [t=0.23s]
prediction: ['[CLS] the serious way makes women works instead look the caretaker stereotypical. of all athletes serious women and teachers, appearances oneself more athletes [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.335 (perp=8.669, rec=0.119, cos=0.482), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes look the caretaker stereotypical teachers of all athletes serious women and teachers, of thrill more athletes [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.266 (perp=8.331, rec=0.120, cos=0.479), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes look the caretaker of stereotypical teachers all athletes serious women and teachers, of oneself more athletes [SEP]']
[ 750/2000] tot_loss=2.268 (perp=8.337, rec=0.119, cos=0.481), tot_loss_proj:3.387 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes look the caretaker of stereotypical teachers all athletes serious women and teachers,. oneself more athletes [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.172 (perp=7.889, rec=0.116, cos=0.478), tot_loss_proj:3.151 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes look the caretaker of stereotypical teachers all athletes serious women and teachers, athletes oneself more. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.101 (perp=7.525, rec=0.116, cos=0.480), tot_loss_proj:3.046 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes athletes the caretaker of stereotypical teachers all look serious women and teachers, athletes oneself more. [SEP]']
[ 900/2000] tot_loss=2.200 (perp=8.004, rec=0.117, cos=0.482), tot_loss_proj:3.196 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes athletes the caretaker of stereotypical moral all look serious women and teachers, athletes vantage more. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.139 (perp=7.720, rec=0.115, cos=0.480), tot_loss_proj:3.187 [t=0.23s]
prediction: ['[CLS] the serious way women works instead makes athletes the moral caretaker of stereotypical all look serious women and teachers, athletes vantage more. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.093 (perp=7.513, rec=0.112, cos=0.478), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes athletes the moral caretaker of stereotypical all look serious women and teachers, athletes vantage more. [SEP]']
[1050/2000] tot_loss=2.089 (perp=7.513, rec=0.107, cos=0.479), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes athletes the moral caretaker of stereotypical all look serious women and teachers, athletes vantage more. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.067 (perp=7.383, rec=0.109, cos=0.481), tot_loss_proj:3.050 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes athletes the moral caretaker of stereotypical all look serious women teachers, and athletes vantage more. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.055 (perp=7.325, rec=0.112, cos=0.479), tot_loss_proj:3.053 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes athletes the moral caretaker of stereotypical all look serious women, teachers and athletes vantage more. [SEP]']
[1200/2000] tot_loss=2.134 (perp=7.753, rec=0.105, cos=0.479), tot_loss_proj:3.124 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes athletes the moral caretaker of stereotypical all look serious like, teachers and athletes vantage more. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.088 (perp=7.502, rec=0.108, cos=0.479), tot_loss_proj:2.965 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes teachers the moral caretaker of stereotypical all look, like serious teachers and athletes vantage more. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.064 (perp=7.378, rec=0.110, cos=0.478), tot_loss_proj:2.978 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes teachers the moral caretaker of stereotypical like look, all serious teachers and athletes vantage more. [SEP]']
[1350/2000] tot_loss=2.058 (perp=7.378, rec=0.101, cos=0.481), tot_loss_proj:2.977 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes teachers the moral caretaker of stereotypical like look, all serious teachers and athletes vantage more. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.070 (perp=7.378, rec=0.114, cos=0.480), tot_loss_proj:2.982 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes teachers the moral caretaker of stereotypical like look, all serious teachers and athletes vantage more. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.040 (perp=7.256, rec=0.109, cos=0.479), tot_loss_proj:2.992 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral caretaker of stereotypical teachers like look, all serious teachers and athletes vantage more. [SEP]']
[1500/2000] tot_loss=2.040 (perp=7.256, rec=0.108, cos=0.481), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral caretaker of stereotypical teachers like look, all serious teachers and athletes vantage more. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.993 (perp=7.027, rec=0.107, cos=0.480), tot_loss_proj:2.745 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes vantage more. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.984 (perp=6.967, rec=0.111, cos=0.479), tot_loss_proj:2.726 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
[1650/2000] tot_loss=1.982 (perp=6.967, rec=0.107, cos=0.482), tot_loss_proj:2.724 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.976 (perp=6.967, rec=0.101, cos=0.481), tot_loss_proj:2.728 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.978 (perp=6.967, rec=0.104, cos=0.480), tot_loss_proj:2.728 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
[1800/2000] tot_loss=1.980 (perp=6.967, rec=0.106, cos=0.481), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.972 (perp=6.967, rec=0.097, cos=0.482), tot_loss_proj:2.726 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.984 (perp=6.967, rec=0.109, cos=0.481), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
[1950/2000] tot_loss=1.976 (perp=6.967, rec=0.101, cos=0.481), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.983 (perp=6.967, rec=0.110, cos=0.480), tot_loss_proj:2.724 [t=0.23s]
prediction: ['[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the way serious women works instead makes the moral look of stereotypical teachers like caretaker, all serious teachers and athletes more vantage. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.106 | p: 83.333 | r: 86.957
rouge2     | fm: 13.333 | p: 13.043 | r: 13.636
rougeL     | fm: 51.064 | p: 50.000 | r: 52.174
rougeLsum  | fm: 51.064 | p: 50.000 | r: 52.174
r1fm+r2fm = 98.440

[Aggregate metrics]:
rouge1     | fm: 88.848 | p: 87.743 | r: 90.174
rouge2     | fm: 51.074 | p: 50.860 | r: 51.238
rougeL     | fm: 78.004 | p: 77.014 | r: 79.220
rougeLsum  | fm: 77.753 | p: 76.870 | r: 78.995
r1fm+r2fm = 139.922

input #21 time: 0:08:52 | total time: 3:21:15


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.7417380276772867
highest_index [0]
highest [0.7417380276772867]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9830951690673828 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.974750816822052 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9737508893013 for ['[CLS]berries thirds rounds exit whole reaction flux packages advertising dish habit [SEP]']
[Init] best rec loss: 0.9587047100067139 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 0.951890766620636 for ['[CLS]dbus leaguedel more arrest able communists confederatedgetsomics [SEP]']
[Init] best rec loss: 0.9503214955329895 for ['[CLS] kali camp missiondio but whispered mining paulaville atmosphere qu [SEP]']
[Init] best rec loss: 0.9391049742698669 for ['[CLS]ou apartowskilizer teaching collins wolfe sample rite maze kaiser [SEP]']
[Init] best rec loss: 0.9381401538848877 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 0.9359330534934998 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 0.9355216026306152 for ['[CLS] kids board her set chineseers function phoenix laughter over schedule [SEP]']
[Init] best perm rec loss: 0.9346942901611328 for ['[CLS]ers function over board chinese phoenix laughter her set schedule kids [SEP]']
[Init] best perm rec loss: 0.9337630867958069 for ['[CLS] function chinese laughter over phoenix schedule her kids boarders set [SEP]']
[Init] best perm rec loss: 0.9332736730575562 for ['[CLS] her over function laughter scheduleers set phoenix chinese board kids [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.476 (perp=11.307, rec=0.688, cos=0.527), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] jonas most pretty ram vacuum a awaiting arriving enough at shadow [SEP]']
[ 100/2000] tot_loss=3.520 (perp=12.763, rec=0.546, cos=0.421), tot_loss_proj:4.513 [t=0.23s]
prediction: ['[CLS] causes an available renault anyway an greatly steward enough believed somewhere [SEP]']
[ 150/2000] tot_loss=3.270 (perp=11.613, rec=0.506, cos=0.442), tot_loss_proj:4.284 [t=0.23s]
prediction: ['[CLS] enjoyable a adaptation successful wasted an engine celebrating reforms somehow around [SEP]']
[ 200/2000] tot_loss=3.262 (perp=11.718, rec=0.496, cos=0.422), tot_loss_proj:3.580 [t=0.23s]
prediction: ['[CLS] enjoyable a adaptation architecture adventures an engine enjoyable reforms curriculum fastest [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.285 (perp=11.761, rec=0.505, cos=0.427), tot_loss_proj:3.718 [t=0.23s]
prediction: ['[CLS] numerous a adaptation adaptation architecture successful an enjoyable wta apt around [SEP]']
[ 300/2000] tot_loss=3.178 (perp=11.633, rec=0.456, cos=0.396), tot_loss_proj:3.838 [t=0.23s]
prediction: ['[CLS] reasons a adaptation adaptation architecture successful an enjoyable reforms improvement around [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.535 (perp=13.057, rec=0.483, cos=0.441), tot_loss_proj:4.574 [t=0.23s]
prediction: ['[CLS] poppy a waste adaptation adaptation successful an enjoyable wta interpreted greatest [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.606 (perp=13.120, rec=0.539, cos=0.443), tot_loss_proj:4.581 [t=0.23s]
prediction: ['[CLS] ambient its waste jointly adaptation 978 gave adaptation novels precedent something [SEP]']
[ 450/2000] tot_loss=3.061 (perp=10.823, rec=0.461, cos=0.435), tot_loss_proj:3.060 [t=0.23s]
prediction: ['[CLS] enjoyable a successful enjoyable adaptation 978 an adaptation novels enjoyable something [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.977 (perp=10.493, rec=0.445, cos=0.433), tot_loss_proj:3.131 [t=0.23s]
prediction: ['[CLS] enjoyable a successful adaptation enjoyable 978 an adaptation京 enjoyable something [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.236 (perp=11.724, rec=0.474, cos=0.418), tot_loss_proj:3.671 [t=0.23s]
prediction: ['[CLS] ambient a successful adaptation enjoyable an adaptation filmfare enjoyable greatest 978 [SEP]']
[ 600/2000] tot_loss=2.851 (perp=10.029, rec=0.425, cos=0.420), tot_loss_proj:3.026 [t=0.23s]
prediction: ['[CLS] enjoyable a successful adaptation enjoyable an adaptation京 enjoyable greatest toy [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.304 (perp=12.232, rec=0.437, cos=0.421), tot_loss_proj:4.396 [t=0.23s]
prediction: ['[CLS] ambient a waste adaptation enjoyable an adaptation greatest architecture京 enjoyable [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.946 (perp=10.380, rec=0.449, cos=0.421), tot_loss_proj:3.186 [t=0.23s]
prediction: ['[CLS] a successful adaptation enjoyable an adaptation favourite ambient architecture courthouse enjoyable [SEP]']
[ 750/2000] tot_loss=3.007 (perp=10.781, rec=0.417, cos=0.434), tot_loss_proj:3.391 [t=0.23s]
prediction: ['[CLS] a successful adaptation enjoyable an adaptation favourite ambient successful courthouse enjoyable [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.902 (perp=10.308, rec=0.412, cos=0.429), tot_loss_proj:3.073 [t=0.23s]
prediction: ['[CLS] a successful successful adaptation enjoyable an adaptation favourite ambient courthouse enjoyable [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.991 (perp=10.767, rec=0.410, cos=0.428), tot_loss_proj:3.134 [t=0.23s]
prediction: ['[CLS] a successful successful adaptation enjoyable an adaptation ambient barry courthouse enjoyable [SEP]']
[ 900/2000] tot_loss=2.982 (perp=10.767, rec=0.400, cos=0.429), tot_loss_proj:3.132 [t=0.23s]
prediction: ['[CLS] a successful successful adaptation enjoyable an adaptation ambient barry courthouse enjoyable [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.867 (perp=10.316, rec=0.396, cos=0.409), tot_loss_proj:3.060 [t=0.23s]
prediction: ['[CLS] a successful successful adaptation enjoyable an ambient barry courthouse adaptation enjoyable [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.816 (perp=9.944, rec=0.399, cos=0.429), tot_loss_proj:2.997 [t=0.23s]
prediction: ['[CLS] a successful successful adaptation enjoyable an ambient courthouse adaptation enjoyable because [SEP]']
[1050/2000] tot_loss=2.842 (perp=10.150, rec=0.395, cos=0.417), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] a successful successful adaptation enjoyable an enjoyable courthouse adaptation enjoyable barry [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.771 (perp=9.813, rec=0.390, cos=0.419), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable barry [SEP]']
Attempt swap
[1150/2000] tot_loss=2.630 (perp=8.961, rec=0.387, cos=0.451), tot_loss_proj:2.745 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable because [SEP]']
[1200/2000] tot_loss=2.602 (perp=8.961, rec=0.382, cos=0.427), tot_loss_proj:2.746 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable because [SEP]']
Attempt swap
[1250/2000] tot_loss=2.751 (perp=9.665, rec=0.384, cos=0.434), tot_loss_proj:3.017 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1300/2000] tot_loss=2.745 (perp=9.665, rec=0.384, cos=0.428), tot_loss_proj:3.020 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
[1350/2000] tot_loss=2.753 (perp=9.665, rec=0.384, cos=0.436), tot_loss_proj:3.016 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1400/2000] tot_loss=2.743 (perp=9.665, rec=0.382, cos=0.428), tot_loss_proj:3.023 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1450/2000] tot_loss=2.752 (perp=9.665, rec=0.382, cos=0.437), tot_loss_proj:3.016 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
[1500/2000] tot_loss=2.760 (perp=9.665, rec=0.373, cos=0.454), tot_loss_proj:3.015 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1550/2000] tot_loss=2.749 (perp=9.665, rec=0.380, cos=0.436), tot_loss_proj:3.021 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1600/2000] tot_loss=2.751 (perp=9.665, rec=0.373, cos=0.445), tot_loss_proj:3.019 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
[1650/2000] tot_loss=2.741 (perp=9.665, rec=0.376, cos=0.432), tot_loss_proj:3.015 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1700/2000] tot_loss=2.749 (perp=9.665, rec=0.376, cos=0.440), tot_loss_proj:3.015 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1750/2000] tot_loss=2.741 (perp=9.665, rec=0.375, cos=0.433), tot_loss_proj:3.020 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
[1800/2000] tot_loss=2.741 (perp=9.665, rec=0.374, cos=0.433), tot_loss_proj:3.017 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1850/2000] tot_loss=2.759 (perp=9.665, rec=0.373, cos=0.453), tot_loss_proj:3.019 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[1900/2000] tot_loss=2.746 (perp=9.665, rec=0.373, cos=0.440), tot_loss_proj:3.017 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
[1950/2000] tot_loss=2.758 (perp=9.665, rec=0.374, cos=0.451), tot_loss_proj:3.021 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]']
Attempt swap
[2000/2000] tot_loss=2.688 (perp=9.351, rec=0.376, cos=0.441), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable backwards [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful courthouse adaptation enjoyable an enjoyable successful adaptation enjoyable replied [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.846 | p: 53.846 | r: 53.846
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 87.179

[Aggregate metrics]:
rouge1     | fm: 87.354 | p: 86.308 | r: 88.730
rouge2     | fm: 49.632 | p: 49.502 | r: 49.836
rougeL     | fm: 76.933 | p: 76.110 | r: 78.073
rougeLsum  | fm: 76.772 | p: 75.786 | r: 77.948
r1fm+r2fm = 136.987

input #22 time: 0:08:54 | total time: 3:30:10


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.7126389232292969
highest_index [0]
highest [0.7126389232292969]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7127013206481934 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7126389741897583 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.7052958607673645 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 0.6985388994216919 for ['[CLS] colony. ana substitute bar advisory a yellow service copiesroud demonarianlawuc networks key months to nextations polly past fitness was congress has forest dr providingee marsh rick georgia { pacific coloured aisles sim wilde over baggagecr tune kirby project punk launch [SEP]']
[Init] best perm rec loss: 0.6985333561897278 for ['[CLS] fitness bar copies tune launch coloured forest demon yellow baggage aisles { a wascr overroud georgia pacific ana kirby congress has networks past providing to project wilde dr months. colony rick next substitute punk keyeelaw sim marshationsarian service advisory pollyuc [SEP]']
[Init] best perm rec loss: 0.6976438760757446 for ['[CLS] networks colony simcr rick congress project providing copies has kirby demon ana dr tune next baggage over was service coloured months to. punk yellow a pacificroud { past georgia aisles bar advisorylawee key fitnessations marshuc launch polly substitutearian wilde forest [SEP]']
[Init] best perm rec loss: 0.697364091873169 for ['[CLS] marsh copies polly pacificcrarian congress advisory simroud was rick wilde dr providing a months kirby bar next ana forest launchations baggage to networksuc coloured colony substitute demon georgia fitness has yellow servicelaw keyee over { aisles past. punk tune project [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.232 (perp=12.267, rec=0.297, cos=0.481), tot_loss_proj:3.794 [t=0.23s]
prediction: ["[CLS] qui vietnam freshwater - get christmas. school [SEP] hindi religion our because architecttarian model creator golden frenzy because lumpur vietnam soldiers coe the thomasomics ; staring over consumer ª project action ha sh kyliecine the resources reaches objective objective his : practically drama'[SEP]"]
[ 100/2000] tot_loss=3.072 (perp=11.822, rec=0.236, cos=0.471), tot_loss_proj:3.642 [t=0.23s]
prediction: ['[CLS] hai vietnam soldiers the get picture. museum advocacybolic reprinted our soldier internationaltarian largest evolved uprising campbell although, soldiers soldiers give the :omics a staring style strategictery objective objective rahizing troops the main its strategic objective achieve : so drama human [SEP]']
[ 150/2000] tot_loss=2.841 (perp=10.835, rec=0.193, cos=0.481), tot_loss_proj:3.441 [t=0.23s]
prediction: ['[CLS]h vietnam soldiers the more picture.ing objected patriotic pamphlet bobbie armys ultimately model developers childhood pictures ;, soldiers soldiers a the : chart its otherwise object strategictery objective objective rahzing soldiers the main its strategic objective achieve : drama drama human [SEP]']
[ 200/2000] tot_loss=2.815 (perp=10.788, rec=0.177, cos=0.480), tot_loss_proj:3.478 [t=0.23s]
prediction: ['[CLS] vietnam vietnam soldiers the such drama.ing objected persistent opinion vietnamese armys ultimately, ultimately generation pictures although, soldiers soldiers ultimately the lives picture its otherwise object strategicti objective strategic rahzing patriotic the main achieve strategic objective achieve : drama drama human [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.741 (perp=10.518, rec=0.159, cos=0.479), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] vietnam vietnam soldiers the such drama,t objected persistent opinion vietnamese vietnams would, ultimately generation picture while, soldiers soldiers ultimately the generation picture its still object strategicti objective drama rahzing patriotic the main ultimately strategic objective achieve : strategic generation human [SEP]']
[ 300/2000] tot_loss=2.728 (perp=10.512, rec=0.146, cos=0.480), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] vietnam vietnam soldiers the such drama,t objected persistent opinion vietnamese vietnams would, ultimately that picture while, soldiers ultimately ultimately the generation picture its still object strategicti objective drama rahzing patriotic the main ultimately cost objective achieve : strategic generation generation [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.680 (perp=10.350, rec=0.133, cos=0.477), tot_loss_proj:3.384 [t=0.23s]
prediction: ['[CLS] vietnam vietnam soldiers the such drama,ti objected, opinion vietnam vietnam - would, ultimately that picture whiletment soldiers ultimately ultimately thes picture its still, strategicti objective drama rahzing patriotic the main ultimately cost objective achieve : strategic generation generation [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.596 (perp=9.860, rec=0.137, cos=0.488), tot_loss_proj:3.274 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers the such vietnam,ti object, tone vietnam vietnam - could, ultimately that picture whiletment soldiers ultimately ultimately thes picture its such, strategicti objective drama rahzing patriotic the main ultimately cost objective achieve : strategic generation generation [SEP]']
[ 450/2000] tot_loss=2.559 (perp=9.788, rec=0.121, cos=0.480), tot_loss_proj:3.238 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers the such vietnam,ti object a idea vietnam vietnam - could, ultimately that look while patriotic soldiers ultimately ultimately thes picture its while, strategicti objective drama rahzing patriotic the main ultimately cost objective achieve : strategic generation generation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.536 (perp=9.671, rec=0.122, cos=0.480), tot_loss_proj:3.219 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers the such vietnam,ti object a vietnam vietnam idea - could with ultimately that tone while patriotic soldiers ultimately ultimately thes picture its while, strategicti objective drama rahzing patriotic the main ultimately cost objective achieve : strategic generation generation [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.465 (perp=9.349, rec=0.108, cos=0.487), tot_loss_proj:3.115 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers the such -,ti object a vietnam vietnam idea - could with ultimately that tone while many soldiers ultimatelys thes picture its objective, strategicti objective drama rahzing patriotic the main ultimately cost while achieve : tone generation generation [SEP]']
[ 600/2000] tot_loss=2.512 (perp=9.586, rec=0.107, cos=0.487), tot_loss_proj:3.171 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers the such -,ti object a vietnam vietnam idea to could with ultimately that tone while many soldiers ultimatelys thes picture its objective, strategicti objective drama rahzing patriotic the main ultimately cost while achieve : tone generation generation [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.471 (perp=9.413, rec=0.105, cos=0.483), tot_loss_proj:3.146 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers the such,ti object a vietnam vietnam idea to could - with ultimately that tone while many soldiers ultimatelys thes tone its objective, strategicti objective drama rahzing patriotic the main ultimately cost while achieve : tone generation generation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.429 (perp=9.176, rec=0.104, cos=0.490), tot_loss_proj:3.120 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers would ultimately,ti object a vietnam vietnam idea to could - with such that tone while many soldiers ultimatelys thes tone its objective, strategicti objective drama rahzing patriotic the main ultimately cost while achieve : tone define generation [SEP]']
[ 750/2000] tot_loss=2.435 (perp=9.258, rec=0.095, cos=0.488), tot_loss_proj:3.153 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers would ultimately,ti object a vietnam vietnam idea to could - with such that tone, many soldiers ultimatelys thes tone its objective, strategicti objective drama rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.391 (perp=9.022, rec=0.096, cos=0.490), tot_loss_proj:3.114 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers would ultimately,ti object a vietnam vietnam idea to could - with such that tone, some soldiers ultimatelys the objective tone itss, strategicti objective drama rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.413 (perp=9.140, rec=0.099, cos=0.486), tot_loss_proj:3.109 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will ultimately,ti object a picture vietnam idea to could, with such that tone, some soldiers ultimatelys the objective tone itss - strategicti objective drama rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
[ 900/2000] tot_loss=2.451 (perp=9.345, rec=0.095, cos=0.487), tot_loss_proj:3.139 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will ultimately,ti object a picture vietnam idea to of, with such that tone, some soldiers ultimatelys the objective tone itss - strategicti idea drama rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.415 (perp=9.174, rec=0.091, cos=0.490), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will ultimately,ti object a picture idea to vietnam of, with such that tone, some soldiers ultimatelys the objective tone itss - strategicti idea drama rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.377 (perp=8.994, rec=0.092, cos=0.486), tot_loss_proj:3.068 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will ultimately,ti object a picture idea to vietnam of, with such that tone, some soldiers ultimatelys the objective tone itss - strategic idea dramati rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
[1050/2000] tot_loss=2.376 (perp=8.994, rec=0.089, cos=0.488), tot_loss_proj:3.073 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will ultimately,ti object a picture idea to vietnam of, with such that tone, some soldiers ultimatelys the objective tone itss - strategic idea dramati rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.339 (perp=8.828, rec=0.085, cos=0.488), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will to,ti object a picture idea to vietnam of, with such tone that, some soldiers ultimatelys the objective tone itss - strategic idea dramati rahzing patriotic the main ultimately cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.303 (perp=8.694, rec=0.085, cos=0.479), tot_loss_proj:3.027 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will to,ti object a picture idea to vietnam of, with such tone that, some soldiers ultimatelys the objective tone itss - strategic idea dramati rahzing the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
[1200/2000] tot_loss=2.310 (perp=8.671, rec=0.087, cos=0.488), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers will to,ti object a picture idea to vietnam of, with such tone that, some soldiers ultimatelys the objective tone itss - strategic tone dramati rahzing the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.290 (perp=8.564, rec=0.086, cos=0.491), tot_loss_proj:3.043 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will,ti object a picture idea to vietnam of, with such tone that, some soldiers ultimatelys the objective tone itss - strategic tone dramati rahzing the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.253 (perp=8.397, rec=0.084, cos=0.489), tot_loss_proj:3.017 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will,ti object a picture idea to vietnam of, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramati rahzing the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
[1350/2000] tot_loss=2.256 (perp=8.397, rec=0.085, cos=0.491), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will,ti object a picture idea to vietnam of, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramati rahzing the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.238 (perp=8.300, rec=0.088, cos=0.490), tot_loss_proj:2.918 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a picture idea to vietnam, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramati rahzing the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.163 (perp=7.972, rec=0.083, cos=0.485), tot_loss_proj:2.847 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a picture idea to vietnam, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
[1500/2000] tot_loss=2.164 (perp=7.972, rec=0.079, cos=0.491), tot_loss_proj:2.846 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a picture idea to vietnam, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
[1550/2000] tot_loss=2.165 (perp=7.972, rec=0.080, cos=0.490), tot_loss_proj:2.847 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a picture idea to vietnam, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.155 (perp=7.931, rec=0.078, cos=0.490), tot_loss_proj:2.837 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
[1650/2000] tot_loss=2.154 (perp=7.931, rec=0.078, cos=0.490), tot_loss_proj:2.838 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
[1700/2000] tot_loss=2.160 (perp=7.931, rec=0.082, cos=0.492), tot_loss_proj:2.836 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.136 (perp=7.829, rec=0.084, cos=0.486), tot_loss_proj:2.810 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while define : patriotic achieve generation [SEP]']
[1800/2000] tot_loss=2.142 (perp=7.829, rec=0.086, cos=0.490), tot_loss_proj:2.809 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while define : patriotic achieve generation [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=2.121 (perp=7.736, rec=0.087, cos=0.487), tot_loss_proj:2.794 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while define achieve generation : patriotic [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.120 (perp=7.736, rec=0.085, cos=0.488), tot_loss_proj:2.793 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while define achieve generation : patriotic [SEP]']
[1950/2000] tot_loss=2.117 (perp=7.736, rec=0.081, cos=0.489), tot_loss_proj:2.796 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while define achieve generation : patriotic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.117 (perp=7.736, rec=0.081, cos=0.489), tot_loss_proj:2.796 [t=0.23s]
prediction: ['[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while define achieve generation : patriotic [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] vietnam drama soldiers to will, ofti object a vietnam picture idea to, with such tone that, some soldiers ultimatelys the objective tone its tone - strategics dramatizing rah the main ultimately patriotic cost while achieve : patriotic define generation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.418 | p: 74.359 | r: 72.500
rouge2     | fm: 10.390 | p: 10.526 | r: 10.256
rougeL     | fm: 43.038 | p: 43.590 | r: 42.500
rougeLsum  | fm: 43.038 | p: 43.590 | r: 42.500
r1fm+r2fm = 83.807

[Aggregate metrics]:
rouge1     | fm: 86.710 | p: 85.798 | r: 88.055
rouge2     | fm: 48.425 | p: 48.283 | r: 48.590
rougeL     | fm: 75.577 | p: 74.747 | r: 76.569
rougeLsum  | fm: 75.327 | p: 74.467 | r: 76.408
r1fm+r2fm = 135.135

input #23 time: 0:08:59 | total time: 3:39:09


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.7128767937324503
highest_index [0]
highest [0.7128767937324503]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8354358673095703 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8061490654945374 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.7936615347862244 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7628939747810364 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7564059495925903 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.7446196675300598 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7099621891975403 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7098536491394043 for ['[CLS] village damned attack no port arms em snow suffer happy mid county playwyl bond ryuaneous unless bush younger [SEP]']
[Init] best perm rec loss: 0.7071111798286438 for ['[CLS]aneous younger ryu bond snow no attack play bush unlesswyl mid arms suffer happy em village damned county port [SEP]']
[Init] best perm rec loss: 0.7062339782714844 for ['[CLS] ryu unless mid armswyl damned county suffer attack port younger play bush no snow village emaneous bond happy [SEP]']
[Init] best perm rec loss: 0.7057031989097595 for ['[CLS] arms younger port mid damned attack em play happy bond ryu village sufferaneous county snowwyl bush unless no [SEP]']
[Init] best perm rec loss: 0.7043247222900391 for ['[CLS] arms snow no younger mid port county em attack ryu happy suffer unless play villageaneous damnedwyl bond bush [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.032 (perp=11.079, rec=0.335, cos=0.481), tot_loss_proj:3.327 [t=0.22s]
prediction: ['[CLS] global accused message organization using tape evil manipulation terrorists evil victim question evil phase were internet evil became evil sensitive [SEP]']
[ 100/2000] tot_loss=3.410 (perp=11.036, rec=0.583, cos=0.620), tot_loss_proj:3.527 [t=0.22s]
prediction: ['[CLS] current outside campaign context without authority evil questions terrorists unchanged document are the della containing climate evil or evil ) [SEP]']
[ 150/2000] tot_loss=3.157 (perp=10.794, rec=0.507, cos=0.491), tot_loss_proj:3.588 [t=0.23s]
prediction: ['[CLS] current outside capt context despite. both release. unchanged device expression the kylie containing climate evil or evil, [SEP]']
[ 200/2000] tot_loss=3.099 (perp=10.783, rec=0.461, cos=0.482), tot_loss_proj:3.509 [t=0.23s]
prediction: ['[CLS] current outside capt context despite. both release. things device blood the kylie containing climate evil or evil, [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.051 (perp=10.695, rec=0.432, cos=0.480), tot_loss_proj:3.483 [t=0.23s]
prediction: ['[CLS] outside capt context despite. both release. things device blood the global kylie containing climate evil or evil, [SEP]']
[ 300/2000] tot_loss=3.031 (perp=10.749, rec=0.401, cos=0.480), tot_loss_proj:3.384 [t=0.23s]
prediction: ['[CLS] outside capt context despite. both release terrorists things devices blood the current kylie containing climate evil or evil, [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.991 (perp=10.629, rec=0.384, cos=0.481), tot_loss_proj:3.501 [t=0.23s]
prediction: ['[CLS] outside capt context without. micah followed the current kylie terrorists things pages blood containing climate evil or evil, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.807 (perp=9.761, rec=0.374, cos=0.481), tot_loss_proj:3.143 [t=0.23s]
prediction: ['[CLS] outside capt context without change are followed the current pronouns terrorists. devices blood containing climate evil or evil, [SEP]']
[ 450/2000] tot_loss=2.762 (perp=9.646, rec=0.357, cos=0.476), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] outside capt context without change are lax the current quantum terrorists. devices cry containing climate evil or evil, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.936 (perp=10.644, rec=0.348, cos=0.459), tot_loss_proj:3.352 [t=0.23s]
prediction: ['[CLS] lax capt context without change are outside the current quantum terrorists wheel devices cryæ climate evil or evil, [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.017 (perp=11.108, rec=0.338, cos=0.457), tot_loss_proj:3.465 [t=0.23s]
prediction: ['[CLS], capt context without change are outside the current panchayat terrorists devices cryæ climate evil 30 evil wheel, [SEP]']
[ 600/2000] tot_loss=2.893 (perp=10.564, rec=0.324, cos=0.456), tot_loss_proj:3.423 [t=0.23s]
prediction: ['[CLS], capt context without change evil outside the current panchayat terrorists devices bloodæ context exceed 30 evil., [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.825 (perp=10.232, rec=0.321, cos=0.458), tot_loss_proj:3.280 [t=0.23s]
prediction: ['[CLS], capt context without change evil outside the current panchayat climate devices blood from terroristsska 30 evil. ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.523 (perp=8.777, rec=0.311, cos=0.457), tot_loss_proj:3.041 [t=0.23s]
prediction: ['[CLS], campaign climate without change evil outside the global panchayat context calls blood from terrorists exceed 30 evil. ) [SEP]']
[ 750/2000] tot_loss=2.601 (perp=9.209, rec=0.307, cos=0.453), tot_loss_proj:3.034 [t=0.23s]
prediction: ['[CLS], campaign climate without change terrorists outside the current panchayat context calls blood from terroristsska 30 evil. ) [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.602 (perp=9.215, rec=0.301, cos=0.458), tot_loss_proj:3.003 [t=0.23s]
prediction: ['[CLS], campaign climate without change terrorists outside the current panchayat context were blood from terroristsska 30 evil ). [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.644 (perp=9.395, rec=0.309, cos=0.456), tot_loss_proj:3.134 [t=0.23s]
prediction: ['[CLS] and campaign climate without change 30 evil outside the global panchayat context were blood pest terrorists exceed evil ). [SEP]']
[ 900/2000] tot_loss=2.765 (perp=10.063, rec=0.294, cos=0.458), tot_loss_proj:3.238 [t=0.23s]
prediction: ['[CLS] are campaign climate without change 30 evil outside the global pronouns context were blood pest terrorists exceed evil ). [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.880 (perp=10.504, rec=0.302, cos=0.478), tot_loss_proj:3.234 [t=0.23s]
prediction: ['[CLS] evil campaign climate without change 30 non outside the globalpour context were blood pest terroristsska evil ). [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.915 (perp=10.627, rec=0.301, cos=0.489), tot_loss_proj:3.282 [t=0.23s]
prediction: ['[CLS] campaign climate without change 30 evil non outside the global panchayat context were blood pest terroristsska evil )... [SEP]']
[1050/2000] tot_loss=2.879 (perp=10.520, rec=0.298, cos=0.478), tot_loss_proj:3.286 [t=0.23s]
prediction: ['[CLS] campaign climate without change 30 evil non outside the global panchayat context were blood pest terroristssr evil )... [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.704 (perp=9.728, rec=0.281, cos=0.478), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] campaign climate change without 30 evil watch outside the global panchayat context were blood by terrorists [ evil )... [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.652 (perp=9.402, rec=0.301, cos=0.470), tot_loss_proj:2.997 [t=0.23s]
prediction: ['[CLS] climate change without 30 evil watch outside the global panchayat context were blood pest terrorists [ evil campaign )... [SEP]']
[1200/2000] tot_loss=2.764 (perp=10.028, rec=0.288, cos=0.471), tot_loss_proj:3.171 [t=0.23s]
prediction: ['[CLS] climate change without 30 terrorists watch outside the globalpour context were blood pest terrorists [ evil campaign )... [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.837 (perp=10.413, rec=0.284, cos=0.470), tot_loss_proj:3.627 [t=0.23s]
prediction: ['[CLS] climate change context 30 terrorists watch outside the globalpour without were blood pest terroriststablished evil campaign )... [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.838 (perp=10.455, rec=0.277, cos=0.470), tot_loss_proj:3.544 [t=0.23s]
prediction: ['[CLS] climate change context 30 evil watch outside the globalpour without were blood pest terroriststablished evil campaign... ) [SEP]']
[1350/2000] tot_loss=2.908 (perp=10.763, rec=0.284, cos=0.471), tot_loss_proj:3.498 [t=0.23s]
prediction: ['[CLS] climate change context 30 evil watch outside the politicalpour without were blood pest terroriststablished evil campaign... ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.917 (perp=10.819, rec=0.282, cos=0.471), tot_loss_proj:3.463 [t=0.23s]
prediction: ['[CLS] climate change context 30 evil watch outside the politicalpour were blood pest terrorists pius without evil campaign... ) [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.903 (perp=10.697, rec=0.286, cos=0.478), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] climate information context 30 evil watch outside the evilpour were blood pest terrorists pius without political campaign... ) [SEP]']
[1500/2000] tot_loss=2.735 (perp=9.910, rec=0.279, cos=0.474), tot_loss_proj:3.152 [t=0.23s]
prediction: ['[CLS] climate information context 30 evil watch outside the evil panchayat were blood ( terrorists pius without political campaign... ) [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.623 (perp=9.329, rec=0.280, cos=0.477), tot_loss_proj:3.026 [t=0.23s]
prediction: ['[CLS] climate information context 30 evil watch outside the evil panchayat were blood ( terrorists without political campaign pius... ) [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.755 (perp=10.065, rec=0.274, cos=0.468), tot_loss_proj:3.231 [t=0.23s]
prediction: ['[CLS] climate information context 30 evil watch outside the evil panchayat were political hangul terrorists without blood campaign pius... ) [SEP]']
[1650/2000] tot_loss=2.758 (perp=10.065, rec=0.277, cos=0.469), tot_loss_proj:3.232 [t=0.23s]
prediction: ['[CLS] climate information context 30 evil watch outside the evil panchayat were political hangul terrorists without blood campaign pius... ) [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.731 (perp=9.967, rec=0.270, cos=0.468), tot_loss_proj:3.203 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil watch outside the evil panchayat were political hangul terrorists without blood campaign pius... ) [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.716 (perp=9.798, rec=0.280, cos=0.476), tot_loss_proj:3.115 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil watch outside the evil panchayat ) were political hangul terrorists without blood campaign pius... [SEP]']
[1800/2000] tot_loss=2.780 (perp=10.143, rec=0.278, cos=0.473), tot_loss_proj:3.227 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil watch outside the evilpour ) were political hangul terrorists without blood campaign pius... [SEP]']
Attempt swap
[1850/2000] tot_loss=2.842 (perp=10.481, rec=0.272, cos=0.473), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil watch outside the evilpour ) were political hangul terrorists without sworn campaign pius... [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.902 (perp=10.774, rec=0.275, cos=0.472), tot_loss_proj:3.363 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil watch outside the evilpour ) were political hangul terrorists blood without campaignsr... [SEP]']
[1950/2000] tot_loss=2.938 (perp=10.993, rec=0.268, cos=0.471), tot_loss_proj:3.346 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil [SEP] outside the evilpour ) were political hangul terrorists blood without campaignsr... [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.813 (perp=10.343, rec=0.273, cos=0.471), tot_loss_proj:3.275 [t=0.23s]
prediction: ['[CLS] climate information 30 context evil watch outside the evilpour ) were political hangul terrorists without blood campaignsr... [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] political outside the context outside tape evil manipulation terrorists evil! are evil terrorists were global evil became evil ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.368 | p: 45.000 | r: 50.000
rouge2     | fm: 11.111 | p: 10.526 | r: 11.765
rougeL     | fm: 42.105 | p: 40.000 | r: 44.444
rougeLsum  | fm: 42.105 | p: 40.000 | r: 44.444
r1fm+r2fm = 58.480

[Aggregate metrics]:
rouge1     | fm: 85.317 | p: 84.160 | r: 86.720
rouge2     | fm: 46.718 | p: 46.599 | r: 46.842
rougeL     | fm: 74.147 | p: 73.370 | r: 75.349
rougeLsum  | fm: 73.884 | p: 72.931 | r: 74.983
r1fm+r2fm = 132.035

input #24 time: 0:08:52 | total time: 3:48:02


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.7335761208245866
highest_index [0]
highest [0.7335761208245866]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9535624384880066 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9102349877357483 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.8999257683753967 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.8859142661094666 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.8795037865638733 for ['[CLS]iary rooms concerned who [SEP]']
[Init] best rec loss: 0.8790826201438904 for ['[CLS] passagelvis hill 7 [SEP]']
[Init] best rec loss: 0.8679276704788208 for ['[CLS] tolerance ba clearffs [SEP]']
[Init] best perm rec loss: 0.8653004765510559 for ['[CLS] tolerance clearffs ba [SEP]']
[Init] best perm rec loss: 0.8652905225753784 for ['[CLS] ba tolerance clearffs [SEP]']
[Init] best perm rec loss: 0.8646115660667419 for ['[CLS]ffs ba tolerance clear [SEP]']
[Init] best perm rec loss: 0.8640601634979248 for ['[CLS]ffs tolerance ba clear [SEP]']
[Init] best perm rec loss: 0.8639947175979614 for ['[CLS] clear toleranceffs ba [SEP]']
[Init] best perm rec loss: 0.8635769486427307 for ['[CLS]ffs clear tolerance ba [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.494 (perp=9.025, rec=0.229, cos=0.460), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] film and beautiful amazing [SEP]']
[ 100/2000] tot_loss=2.539 (perp=9.732, rec=0.132, cos=0.460), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS] film strange beautiful film [SEP]']
[ 150/2000] tot_loss=2.516 (perp=9.732, rec=0.109, cos=0.460), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] film strange beautiful film [SEP]']
[ 200/2000] tot_loss=2.517 (perp=9.732, rec=0.111, cos=0.460), tot_loss_proj:3.036 [t=0.22s]
prediction: ['[CLS] film strange beautiful film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.094 (perp=7.472, rec=0.142, cos=0.458), tot_loss_proj:2.247 [t=0.22s]
prediction: ['[CLS] beautiful strange film film [SEP]']
[ 300/2000] tot_loss=2.078 (perp=7.472, rec=0.123, cos=0.460), tot_loss_proj:2.238 [t=0.23s]
prediction: ['[CLS] beautiful strange film film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.066 (perp=7.472, rec=0.110, cos=0.462), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] beautiful strange film film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.062 (perp=7.472, rec=0.106, cos=0.461), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] beautiful strange film film [SEP]']
[ 450/2000] tot_loss=2.065 (perp=7.472, rec=0.110, cos=0.460), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] beautiful strange film film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.054 (perp=7.472, rec=0.099, cos=0.460), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS] beautiful strange film film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.057 (perp=7.481, rec=0.100, cos=0.461), tot_loss_proj:2.270 [t=0.22s]
prediction: ['[CLS] beautiful strange film and [SEP]']
[ 600/2000] tot_loss=2.045 (perp=7.481, rec=0.088, cos=0.461), tot_loss_proj:2.270 [t=0.23s]
prediction: ['[CLS] beautiful strange film and [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.943 (perp=6.913, rec=0.099, cos=0.461), tot_loss_proj:2.099 [t=0.22s]
prediction: ['[CLS] and beautiful strange film [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.881 (perp=6.646, rec=0.092, cos=0.460), tot_loss_proj:1.927 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.888 (perp=6.646, rec=0.097, cos=0.462), tot_loss_proj:1.930 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.875 (perp=6.646, rec=0.085, cos=0.461), tot_loss_proj:1.922 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.855 (perp=6.646, rec=0.064, cos=0.462), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.867 (perp=6.646, rec=0.076, cos=0.462), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.857 (perp=6.646, rec=0.067, cos=0.461), tot_loss_proj:1.920 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.857 (perp=6.646, rec=0.067, cos=0.462), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.862 (perp=6.646, rec=0.071, cos=0.461), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.857 (perp=6.646, rec=0.066, cos=0.462), tot_loss_proj:1.917 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.859 (perp=6.646, rec=0.068, cos=0.462), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.847 (perp=6.646, rec=0.056, cos=0.461), tot_loss_proj:1.925 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.860 (perp=6.646, rec=0.069, cos=0.461), tot_loss_proj:1.928 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.853 (perp=6.646, rec=0.062, cos=0.461), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.850 (perp=6.646, rec=0.059, cos=0.461), tot_loss_proj:1.917 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.852 (perp=6.646, rec=0.061, cos=0.461), tot_loss_proj:1.929 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.858 (perp=6.646, rec=0.067, cos=0.462), tot_loss_proj:1.923 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.846 (perp=6.646, rec=0.056, cos=0.461), tot_loss_proj:1.922 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.852 (perp=6.646, rec=0.061, cos=0.461), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.853 (perp=6.646, rec=0.062, cos=0.462), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.858 (perp=6.646, rec=0.067, cos=0.462), tot_loss_proj:1.929 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.853 (perp=6.646, rec=0.063, cos=0.462), tot_loss_proj:1.926 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.859 (perp=6.646, rec=0.068, cos=0.462), tot_loss_proj:1.926 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.851 (perp=6.646, rec=0.060, cos=0.462), tot_loss_proj:1.930 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.852 (perp=6.646, rec=0.061, cos=0.461), tot_loss_proj:1.922 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.851 (perp=6.646, rec=0.060, cos=0.461), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.851 (perp=6.646, rec=0.060, cos=0.461), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.845 (perp=6.646, rec=0.055, cos=0.462), tot_loss_proj:1.935 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.738 | p: 84.697 | r: 87.027
rouge2     | fm: 48.685 | p: 48.532 | r: 48.858
rougeL     | fm: 75.182 | p: 74.277 | r: 76.246
rougeLsum  | fm: 74.808 | p: 74.023 | r: 76.014
r1fm+r2fm = 134.424

input #25 time: 0:08:48 | total time: 3:56:50


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.7174420844365687
highest_index [0]
highest [0.7174420844365687]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8791084289550781 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8482668399810791 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8423802256584167 for ['[CLS] este letter freedom ‚ whose raid beautyenes [SEP] numbers allsel especially best thought kid internationally picture tu plum cue dutyriam [SEP]']
[Init] best rec loss: 0.8322349190711975 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8291748762130737 for ['[CLS] certified lightning result haired vehicles half expect ep drawing ticket musicalʋin died folded kiss fathers mer friendly old tests sweat associate [SEP]']
[Init] best rec loss: 0.8215392827987671 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8210533857345581 for ['[CLS] polish four death fourth list constituencies theoretical octave moreᆼ souls usually door arrow merely shot discipline officers colonial isotead skan [SEP]']
[Init] best perm rec loss: 0.8200989961624146 for ['[CLS] discipline death list officerskan iso souls octave colonial s usually more shot constituencies arrow fourth polish merely theoretical doortead fourᆼ [SEP]']
[Init] best perm rec loss: 0.8178330659866333 for ['[CLS]ᆼ list souls theoretical colonial fourth shot officers iso octave merely more arrow disciplinetead death s constituencies four usuallykan polish door [SEP]']
[Init] best perm rec loss: 0.8172528147697449 for ['[CLS] shot four fourth usually octave constituencies isotead sᆼ arrow souls death colonial officers list polish merely theoretical more disciplinekan door [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.293 (perp=12.380, rec=0.331, cos=0.487), tot_loss_proj:3.550 [t=0.21s]
prediction: ['[CLS] divided sanskritns covent domestic import christophees losers pointless old danish french his door immigrant they lilith pointless indonesian article.mbling [SEP]']
[ 100/2000] tot_loss=2.923 (perp=10.867, rec=0.284, cos=0.466), tot_loss_proj:3.358 [t=0.22s]
prediction: ['[CLS] particularly ) into rosalie english import import! orphan pointless import french french - - import newly or pointless pencil books generally import [SEP]']
[ 150/2000] tot_loss=2.824 (perp=10.717, rec=0.205, cos=0.476), tot_loss_proj:3.198 [t=0.22s]
prediction: ['[CLS] really ) into mean french import from and danish pointless coming french french - - import newly or pointless writer writer spirit import [SEP]']
[ 200/2000] tot_loss=2.654 (perp=10.147, rec=0.150, cos=0.475), tot_loss_proj:3.119 [t=0.22s]
prediction: ['[CLS] this ) into mean french import from and mean pointless coming sophie age - - director - or pointless writer writer.page [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.559 (perp=9.396, rec=0.199, cos=0.481), tot_loss_proj:2.953 [t=0.22s]
prediction: ['[CLS] this )ing mean french import from sophie mean pointless coming and age - of director - or pointless pencil writering menu [SEP]']
[ 300/2000] tot_loss=2.500 (perp=9.434, rec=0.134, cos=0.479), tot_loss_proj:2.959 [t=0.22s]
prediction: ['[CLS] this ) and mean french import from sophie mean pointless coming and age - of director - or pointless wednesday writering bidding [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.452 (perp=9.179, rec=0.137, cos=0.480), tot_loss_proj:2.927 [t=0.22s]
prediction: ['[CLS] this ) and mean french import from sophie mean pointless coming and age - of priest - or pointlessastic writering director [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.368 (perp=8.856, rec=0.118, cos=0.479), tot_loss_proj:2.825 [t=0.22s]
prediction: ['[CLS] this ) and mean french import folder sophie mean pointless coming and age - of priest - - pointless from writering director [SEP]']
[ 450/2000] tot_loss=2.399 (perp=9.045, rec=0.110, cos=0.480), tot_loss_proj:2.854 [t=0.22s]
prediction: ['[CLS] this ) and mean french import folder sophieder pointless coming and age - of priest - - pointless from writering director [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.339 (perp=8.743, rec=0.108, cos=0.482), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] this ) and mean french import adolescence -der pointless coming and age - of cousin sophie - pointless from writering director [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.138 (perp=7.781, rec=0.099, cos=0.483), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] this ) and mean french import sophie -der pointless coming and age - of cousin sophie - pointless from writer and director [SEP]']
[ 600/2000] tot_loss=2.258 (perp=8.343, rec=0.106, cos=0.483), tot_loss_proj:2.768 [t=0.22s]
prediction: ['[CLS] this ) and mean french import sophie -der pointless coming and age - ofrot sophie - pointless from writer and director [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.256 (perp=8.343, rec=0.103, cos=0.485), tot_loss_proj:2.763 [t=0.22s]
prediction: ['[CLS] this ) and mean french import sophie -der pointless coming and age - ofrot sophie - pointless from writer and director [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.204 (perp=8.151, rec=0.091, cos=0.483), tot_loss_proj:2.698 [t=0.22s]
prediction: ['[CLS] this ) and mean french import sophieder - pointless coming and age - ofrot sophie - pointless from writer and director [SEP]']
[ 750/2000] tot_loss=2.231 (perp=8.257, rec=0.097, cos=0.483), tot_loss_proj:2.663 [t=0.22s]
prediction: ['[CLS] this ) and mean french importrotder - pointless coming and age - ofrot sophie - pointless from writer and director [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.255 (perp=8.401, rec=0.093, cos=0.482), tot_loss_proj:2.676 [t=0.22s]
prediction: ['[CLS] this ) and mean french importrotder - pointless coming of age -,rot anne - pointless from writer and director [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.202 (perp=8.134, rec=0.092, cos=0.483), tot_loss_proj:2.635 [t=0.22s]
prediction: ['[CLS] this ) and mean french importrotder - pointless coming of age, -rot anne - pointless from writer and director [SEP]']
[ 900/2000] tot_loss=2.204 (perp=8.134, rec=0.094, cos=0.484), tot_loss_proj:2.639 [t=0.22s]
prediction: ['[CLS] this ) and mean french importrotder - pointless coming of age, -rot anne - pointless from writer and director [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.180 (perp=8.050, rec=0.088, cos=0.482), tot_loss_proj:2.640 [t=0.22s]
prediction: ['[CLS] this ) and mean french importrotder - pointless coming of age, annerot - - pointless from writer and director [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.146 (perp=7.869, rec=0.089, cos=0.483), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from writer and director [SEP]']
[1050/2000] tot_loss=2.149 (perp=7.869, rec=0.090, cos=0.485), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from writer and director [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.119 (perp=7.754, rec=0.084, cos=0.484), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from director and writer [SEP]']
Attempt swap
[1150/2000] tot_loss=2.120 (perp=7.754, rec=0.086, cos=0.483), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from director and writer [SEP]']
[1200/2000] tot_loss=2.121 (perp=7.754, rec=0.086, cos=0.484), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from director and writer [SEP]']
Attempt swap
[1250/2000] tot_loss=2.121 (perp=7.754, rec=0.086, cos=0.483), tot_loss_proj:2.570 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from director and writer [SEP]']
Attempt swap
[1300/2000] tot_loss=2.118 (perp=7.754, rec=0.083, cos=0.484), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from director and writer [SEP]']
[1350/2000] tot_loss=2.112 (perp=7.754, rec=0.077, cos=0.484), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] this ), mean french importrotder - pointless coming of age and annerot - - pointless from director and writer [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.106 (perp=7.656, rec=0.092, cos=0.483), tot_loss_proj:2.549 [t=0.22s]
prediction: ['[CLS] this ), mean french import -der - pointless coming of age and annerotrot - pointless from director and writer [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.146 (perp=7.867, rec=0.088, cos=0.485), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] this ), mean french import andder - pointless coming of age - annerotrot - pointless from director and writer [SEP]']
[1500/2000] tot_loss=2.139 (perp=7.867, rec=0.083, cos=0.483), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] this ), mean french import andder - pointless coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.098 (perp=7.674, rec=0.081, cos=0.483), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - and pointless coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.091 (perp=7.601, rec=0.086, cos=0.484), tot_loss_proj:2.524 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]']
[1650/2000] tot_loss=2.084 (perp=7.601, rec=0.079, cos=0.484), tot_loss_proj:2.526 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
[1700/2000] tot_loss=2.087 (perp=7.601, rec=0.083, cos=0.484), tot_loss_proj:2.520 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
[1750/2000] tot_loss=2.083 (perp=7.601, rec=0.079, cos=0.484), tot_loss_proj:2.518 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]']
[1800/2000] tot_loss=2.224 (perp=8.275, rec=0.085, cos=0.484), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointlessing coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.192 (perp=8.114, rec=0.085, cos=0.485), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] this ), mean french importder and pointless - coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.089 (perp=7.601, rec=0.085, cos=0.484), tot_loss_proj:2.524 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]']
[1950/2000] tot_loss=2.092 (perp=7.601, rec=0.088, cos=0.484), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.064 (perp=7.476, rec=0.085, cos=0.484), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] this ), mean french importder - pointless and coming of age - annerotrot pointless - from director and writer [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this ), mean french importder - pointless and coming of age - annerotrot - pointless from director and writer [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 70.588 | r: 70.588
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 89.338

[Aggregate metrics]:
rouge1     | fm: 85.295 | p: 84.270 | r: 86.494
rouge2     | fm: 47.665 | p: 47.477 | r: 47.884
rougeL     | fm: 74.183 | p: 73.341 | r: 75.332
rougeLsum  | fm: 74.148 | p: 73.404 | r: 75.312
r1fm+r2fm = 132.961

input #26 time: 0:08:34 | total time: 4:05:24


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.7170363133296207
highest_index [0]
highest [0.7170363133296207]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9745640158653259 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9493390321731567 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9410071969032288 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.9342960119247437 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9324862360954285 for ['[CLS] drawing dynamo cave [SEP]']
[Init] best rec loss: 0.9127619862556458 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.901415228843689 for ['[CLS] fat mattream [SEP]']
[Init] best perm rec loss: 0.895994246006012 for ['[CLS] mat fattream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.583 (perp=9.508, rec=0.209, cos=0.472), tot_loss_proj:2.876 [t=0.21s]
prediction: ['[CLS] are generic generic [SEP]']
[ 100/2000] tot_loss=2.521 (perp=9.508, rec=0.138, cos=0.481), tot_loss_proj:2.879 [t=0.21s]
prediction: ['[CLS] are generic generic [SEP]']
[ 150/2000] tot_loss=2.523 (perp=9.508, rec=0.143, cos=0.478), tot_loss_proj:2.882 [t=0.21s]
prediction: ['[CLS] are generic generic [SEP]']
[ 200/2000] tot_loss=2.506 (perp=9.508, rec=0.127, cos=0.477), tot_loss_proj:2.883 [t=0.21s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.479 (perp=9.508, rec=0.094, cos=0.483), tot_loss_proj:2.887 [t=0.21s]
prediction: ['[CLS] are generic generic [SEP]']
[ 300/2000] tot_loss=2.359 (perp=8.980, rec=0.080, cos=0.483), tot_loss_proj:2.735 [t=0.21s]
prediction: ['[CLS] are generic so [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.211 (perp=8.320, rec=0.064, cos=0.483), tot_loss_proj:2.249 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.216 (perp=8.320, rec=0.068, cos=0.484), tot_loss_proj:2.245 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=2.222 (perp=8.320, rec=0.072, cos=0.486), tot_loss_proj:2.244 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.226 (perp=8.320, rec=0.076, cos=0.486), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.237 (perp=8.320, rec=0.091, cos=0.482), tot_loss_proj:2.249 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=2.228 (perp=8.320, rec=0.082, cos=0.483), tot_loss_proj:2.250 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.209 (perp=8.320, rec=0.061, cos=0.484), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.204 (perp=8.320, rec=0.059, cos=0.481), tot_loss_proj:2.254 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=2.205 (perp=8.320, rec=0.056, cos=0.485), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.218 (perp=8.320, rec=0.070, cos=0.484), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.216 (perp=8.320, rec=0.068, cos=0.484), tot_loss_proj:2.243 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=2.210 (perp=8.320, rec=0.061, cos=0.485), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.209 (perp=8.320, rec=0.060, cos=0.485), tot_loss_proj:2.239 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.205 (perp=8.320, rec=0.059, cos=0.483), tot_loss_proj:2.257 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=2.207 (perp=8.320, rec=0.059, cos=0.484), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.199 (perp=8.320, rec=0.051, cos=0.484), tot_loss_proj:2.239 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.206 (perp=8.320, rec=0.057, cos=0.485), tot_loss_proj:2.249 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=2.225 (perp=8.320, rec=0.076, cos=0.485), tot_loss_proj:2.257 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.202 (perp=8.320, rec=0.052, cos=0.485), tot_loss_proj:2.248 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.207 (perp=8.320, rec=0.059, cos=0.484), tot_loss_proj:2.238 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=2.222 (perp=8.320, rec=0.073, cos=0.485), tot_loss_proj:2.245 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.212 (perp=8.320, rec=0.063, cos=0.485), tot_loss_proj:2.252 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.202 (perp=8.320, rec=0.053, cos=0.484), tot_loss_proj:2.252 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=2.202 (perp=8.320, rec=0.052, cos=0.485), tot_loss_proj:2.248 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.210 (perp=8.320, rec=0.060, cos=0.486), tot_loss_proj:2.249 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.211 (perp=8.320, rec=0.062, cos=0.485), tot_loss_proj:2.245 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=2.212 (perp=8.320, rec=0.063, cos=0.485), tot_loss_proj:2.257 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.208 (perp=8.320, rec=0.059, cos=0.485), tot_loss_proj:2.250 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.204 (perp=8.320, rec=0.055, cos=0.485), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=2.213 (perp=8.320, rec=0.064, cos=0.485), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.207 (perp=8.320, rec=0.057, cos=0.485), tot_loss_proj:2.251 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.208 (perp=8.320, rec=0.059, cos=0.485), tot_loss_proj:2.245 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=2.203 (perp=8.320, rec=0.054, cos=0.486), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.215 (perp=8.320, rec=0.066, cos=0.485), tot_loss_proj:2.251 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.762 | p: 84.786 | r: 86.969
rouge2     | fm: 49.314 | p: 49.204 | r: 49.486
rougeL     | fm: 75.155 | p: 74.349 | r: 76.134
rougeLsum  | fm: 75.031 | p: 74.147 | r: 76.139
r1fm+r2fm = 135.076

input #27 time: 0:08:27 | total time: 4:13:51


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.7074605990234825
highest_index [0]
highest [0.7074605990234825]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.867507815361023 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8472304940223694 for ['[CLS] easierlnan cow [SEP]']
[Init] best rec loss: 0.8436771035194397 for ['[CLS] done human live quickly [SEP]']
[Init] best rec loss: 0.834266185760498 for ['[CLS] sick prior spielberggation [SEP]']
[Init] best rec loss: 0.8319923281669617 for ['[CLS] hand delgado laid phoenix [SEP]']
[Init] best rec loss: 0.8290566802024841 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.8260694742202759 for ['[CLS]pl life 2000 centuries [SEP]']
[Init] best rec loss: 0.8191754817962646 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best rec loss: 0.8170430660247803 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.8163870573043823 for ['[CLS] jeremy larvae heights roses [SEP]']
[Init] best perm rec loss: 0.816057562828064 for ['[CLS] roses larvae jeremy heights [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.517 (perp=9.137, rec=0.198, cos=0.492), tot_loss_proj:2.924 [t=0.21s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 100/2000] tot_loss=2.421 (perp=9.123, rec=0.102, cos=0.495), tot_loss_proj:2.757 [t=0.21s]
prediction: ['[CLS] for 71 only minutes [SEP]']
[ 150/2000] tot_loss=2.395 (perp=9.123, rec=0.075, cos=0.496), tot_loss_proj:2.745 [t=0.22s]
prediction: ['[CLS] for 71 only minutes [SEP]']
[ 200/2000] tot_loss=2.394 (perp=9.123, rec=0.075, cos=0.494), tot_loss_proj:2.737 [t=0.22s]
prediction: ['[CLS] for 71 only minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.052 (perp=7.446, rec=0.073, cos=0.490), tot_loss_proj:2.292 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=2.052 (perp=7.446, rec=0.070, cos=0.493), tot_loss_proj:2.286 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.061 (perp=7.446, rec=0.074, cos=0.497), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.054 (perp=7.446, rec=0.075, cos=0.490), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=2.044 (perp=7.446, rec=0.065, cos=0.490), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.061 (perp=7.446, rec=0.073, cos=0.499), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.057 (perp=7.446, rec=0.073, cos=0.495), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=2.063 (perp=7.446, rec=0.076, cos=0.497), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.051 (perp=7.446, rec=0.068, cos=0.494), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.042 (perp=7.446, rec=0.058, cos=0.494), tot_loss_proj:2.296 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=2.042 (perp=7.446, rec=0.054, cos=0.498), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.050 (perp=7.446, rec=0.062, cos=0.499), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.045 (perp=7.446, rec=0.059, cos=0.497), tot_loss_proj:2.298 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=2.048 (perp=7.446, rec=0.061, cos=0.497), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.062 (perp=7.446, rec=0.076, cos=0.497), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=2.047 (perp=7.446, rec=0.062, cos=0.496), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=2.054 (perp=7.446, rec=0.066, cos=0.499), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=2.055 (perp=7.446, rec=0.069, cos=0.496), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=2.053 (perp=7.446, rec=0.067, cos=0.497), tot_loss_proj:2.294 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=2.049 (perp=7.446, rec=0.062, cos=0.498), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=2.048 (perp=7.446, rec=0.062, cos=0.497), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=2.054 (perp=7.446, rec=0.067, cos=0.497), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=2.056 (perp=7.446, rec=0.069, cos=0.498), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=2.047 (perp=7.446, rec=0.060, cos=0.498), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=2.059 (perp=7.446, rec=0.071, cos=0.499), tot_loss_proj:2.298 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=2.049 (perp=7.446, rec=0.063, cos=0.497), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=2.051 (perp=7.446, rec=0.065, cos=0.497), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=2.052 (perp=7.446, rec=0.063, cos=0.499), tot_loss_proj:2.298 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=2.050 (perp=7.446, rec=0.062, cos=0.499), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=2.053 (perp=7.446, rec=0.066, cos=0.498), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=2.041 (perp=7.446, rec=0.054, cos=0.498), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=2.050 (perp=7.446, rec=0.062, cos=0.498), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=2.056 (perp=7.446, rec=0.069, cos=0.498), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=2.046 (perp=7.446, rec=0.059, cos=0.499), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=2.047 (perp=7.446, rec=0.059, cos=0.498), tot_loss_proj:2.290 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=2.045 (perp=7.446, rec=0.058, cos=0.498), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 86.270 | p: 85.298 | r: 87.447
rouge2     | fm: 49.059 | p: 48.985 | r: 49.282
rougeL     | fm: 75.630 | p: 74.802 | r: 76.564
rougeLsum  | fm: 75.356 | p: 74.519 | r: 76.422
r1fm+r2fm = 135.329

input #28 time: 0:08:30 | total time: 4:22:22


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.7099854860791059
highest_index [0]
highest [0.7099854860791059]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8666142225265503 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8526766896247864 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8524953126907349 for ['[CLS]jouross restorationӏ ministerial text murder me tertiary biblical [SEP]']
[Init] best rec loss: 0.8412806391716003 for ['[CLS] protected leadlto arose ec along sunset pay everywhere county [SEP]']
[Init] best rec loss: 0.8111321926116943 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.7780779004096985 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7746514678001404 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best perm rec loss: 0.7714410424232483 for ['[CLS] apart joyah epicbeat fk crap fork historia extra cape [SEP]']
[Init] best perm rec loss: 0.769853949546814 for ['[CLS] joyah capebeat fork extra historia apart crap epic fk [SEP]']
[Init] best perm rec loss: 0.7695261836051941 for ['[CLS] fk apartbeat cape historia fork joyah extra epic crap [SEP]']
[Init] best perm rec loss: 0.7694860100746155 for ['[CLS] joyah extrabeat apart epic cape fk fork historia crap [SEP]']
[Init] best perm rec loss: 0.7688215374946594 for ['[CLS] cape fork apart joyahbeat historia crap extra fk epic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.359 (perp=12.347, rec=0.401, cos=0.488), tot_loss_proj:3.919 [t=0.21s]
prediction: ['[CLS] cannot susan list remaining not letter game not tonight systems [SEP]']
[ 100/2000] tot_loss=2.421 (perp=8.476, rec=0.246, cos=0.479), tot_loss_proj:2.931 [t=0.22s]
prediction: ['[CLS] not also believe is that evil evil not resident it [SEP]']
[ 150/2000] tot_loss=2.134 (perp=7.457, rec=0.144, cos=0.499), tot_loss_proj:2.783 [t=0.22s]
prediction: ['[CLS] not i believe is that resident evil not resident it [SEP]']
[ 200/2000] tot_loss=2.174 (perp=7.883, rec=0.108, cos=0.490), tot_loss_proj:2.928 [t=0.22s]
prediction: ['[CLS] not i believe is that resident evil also resident it [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.997 (perp=6.667, rec=0.156, cos=0.508), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] not i believe that resident evil also resident it is [SEP]']
[ 300/2000] tot_loss=1.919 (perp=6.667, rec=0.096, cos=0.490), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] not i believe that resident evil also resident it is [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.851 (perp=6.360, rec=0.087, cos=0.492), tot_loss_proj:2.701 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.847 (perp=6.360, rec=0.081, cos=0.493), tot_loss_proj:2.702 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
[ 450/2000] tot_loss=1.847 (perp=6.360, rec=0.081, cos=0.493), tot_loss_proj:2.696 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.846 (perp=6.360, rec=0.082, cos=0.492), tot_loss_proj:2.701 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.847 (perp=6.360, rec=0.080, cos=0.495), tot_loss_proj:2.694 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
[ 600/2000] tot_loss=1.944 (perp=6.843, rec=0.081, cos=0.494), tot_loss_proj:2.807 [t=0.22s]
prediction: ['[CLS] i believe that not. evil also resident it is [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.834 (perp=6.360, rec=0.071, cos=0.491), tot_loss_proj:2.754 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.836 (perp=6.360, rec=0.072, cos=0.492), tot_loss_proj:2.759 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
[ 750/2000] tot_loss=1.846 (perp=6.360, rec=0.081, cos=0.492), tot_loss_proj:2.756 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also resident it is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.654 (perp=5.470, rec=0.069, cos=0.491), tot_loss_proj:2.774 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil also. it is [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.531 (perp=4.845, rec=0.071, cos=0.491), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[ 900/2000] tot_loss=1.534 (perp=4.845, rec=0.073, cos=0.492), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.538 (perp=4.845, rec=0.077, cos=0.492), tot_loss_proj:2.459 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1000/2000] tot_loss=1.542 (perp=4.845, rec=0.079, cos=0.494), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1050/2000] tot_loss=1.527 (perp=4.845, rec=0.066, cos=0.492), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1100/2000] tot_loss=1.522 (perp=4.845, rec=0.060, cos=0.493), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1150/2000] tot_loss=1.534 (perp=4.845, rec=0.075, cos=0.491), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1200/2000] tot_loss=1.540 (perp=4.845, rec=0.077, cos=0.494), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1250/2000] tot_loss=1.546 (perp=4.845, rec=0.086, cos=0.491), tot_loss_proj:2.454 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1300/2000] tot_loss=1.534 (perp=4.845, rec=0.074, cos=0.491), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1350/2000] tot_loss=1.533 (perp=4.845, rec=0.071, cos=0.493), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1400/2000] tot_loss=1.537 (perp=4.845, rec=0.076, cos=0.492), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1450/2000] tot_loss=1.531 (perp=4.845, rec=0.069, cos=0.493), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1500/2000] tot_loss=1.535 (perp=4.845, rec=0.075, cos=0.491), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1550/2000] tot_loss=1.542 (perp=4.845, rec=0.082, cos=0.491), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1600/2000] tot_loss=1.534 (perp=4.845, rec=0.072, cos=0.492), tot_loss_proj:2.458 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1650/2000] tot_loss=1.525 (perp=4.845, rec=0.065, cos=0.491), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1700/2000] tot_loss=1.534 (perp=4.845, rec=0.073, cos=0.492), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1750/2000] tot_loss=1.523 (perp=4.845, rec=0.063, cos=0.491), tot_loss_proj:2.454 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1800/2000] tot_loss=1.523 (perp=4.845, rec=0.062, cos=0.492), tot_loss_proj:2.459 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1850/2000] tot_loss=1.531 (perp=4.845, rec=0.070, cos=0.492), tot_loss_proj:2.457 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[1900/2000] tot_loss=1.529 (perp=4.845, rec=0.069, cos=0.491), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
[1950/2000] tot_loss=1.519 (perp=4.845, rec=0.060, cos=0.489), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Attempt swap
[2000/2000] tot_loss=1.538 (perp=4.845, rec=0.079, cos=0.490), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] i believe that not resident evil. it is also [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe that not resident evil. it is also [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 86.670 | p: 85.748 | r: 87.714
rouge2     | fm: 48.352 | p: 48.238 | r: 48.512
rougeL     | fm: 75.470 | p: 74.769 | r: 76.458
rougeLsum  | fm: 75.187 | p: 74.443 | r: 76.196
r1fm+r2fm = 135.021

input #29 time: 0:08:36 | total time: 4:30:58


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.7285532838080618
highest_index [0]
highest [0.7285532838080618]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8295830488204956 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.6926015615463257 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.6502880454063416 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.6493468880653381 for ['[CLS] acceleration lizard council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.918 (perp=11.223, rec=0.208, cos=0.465), tot_loss_proj:3.270 [t=0.21s]
prediction: ['[CLS]zzazzability [SEP]']
[ 100/2000] tot_loss=2.501 (perp=9.540, rec=0.120, cos=0.473), tot_loss_proj:2.433 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.459 (perp=9.540, rec=0.092, cos=0.459), tot_loss_proj:2.442 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.458 (perp=9.540, rec=0.081, cos=0.469), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.452 (perp=9.540, rec=0.083, cos=0.461), tot_loss_proj:2.434 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.450 (perp=9.540, rec=0.079, cos=0.463), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.447 (perp=9.540, rec=0.075, cos=0.464), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.439 (perp=9.540, rec=0.062, cos=0.469), tot_loss_proj:2.438 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.458 (perp=9.540, rec=0.079, cos=0.471), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.447 (perp=9.540, rec=0.076, cos=0.463), tot_loss_proj:2.437 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.431 (perp=9.540, rec=0.065, cos=0.458), tot_loss_proj:2.439 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=2.446 (perp=9.540, rec=0.071, cos=0.467), tot_loss_proj:2.449 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.428 (perp=9.540, rec=0.054, cos=0.466), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.450 (perp=9.540, rec=0.074, cos=0.468), tot_loss_proj:2.439 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=2.439 (perp=9.540, rec=0.065, cos=0.466), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.441 (perp=9.540, rec=0.066, cos=0.466), tot_loss_proj:2.434 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.445 (perp=9.540, rec=0.073, cos=0.464), tot_loss_proj:2.433 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=2.435 (perp=9.540, rec=0.066, cos=0.461), tot_loss_proj:2.440 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.445 (perp=9.540, rec=0.072, cos=0.465), tot_loss_proj:2.437 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=2.433 (perp=9.540, rec=0.059, cos=0.467), tot_loss_proj:2.440 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=2.428 (perp=9.540, rec=0.052, cos=0.468), tot_loss_proj:2.436 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=2.436 (perp=9.540, rec=0.060, cos=0.468), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.447 (perp=9.540, rec=0.072, cos=0.468), tot_loss_proj:2.442 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=2.439 (perp=9.540, rec=0.063, cos=0.469), tot_loss_proj:2.440 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=2.429 (perp=9.540, rec=0.054, cos=0.467), tot_loss_proj:2.440 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=2.437 (perp=9.540, rec=0.063, cos=0.466), tot_loss_proj:2.432 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=2.439 (perp=9.540, rec=0.065, cos=0.466), tot_loss_proj:2.433 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.444 (perp=9.540, rec=0.069, cos=0.468), tot_loss_proj:2.435 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=2.436 (perp=9.540, rec=0.063, cos=0.465), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.440 (perp=9.540, rec=0.066, cos=0.466), tot_loss_proj:2.439 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=2.443 (perp=9.540, rec=0.068, cos=0.467), tot_loss_proj:2.426 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=2.443 (perp=9.540, rec=0.066, cos=0.468), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=2.437 (perp=9.540, rec=0.062, cos=0.467), tot_loss_proj:2.433 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=2.432 (perp=9.540, rec=0.057, cos=0.468), tot_loss_proj:2.433 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.432 (perp=9.540, rec=0.056, cos=0.468), tot_loss_proj:2.448 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=2.436 (perp=9.540, rec=0.060, cos=0.468), tot_loss_proj:2.438 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.431 (perp=9.540, rec=0.055, cos=0.468), tot_loss_proj:2.438 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=2.439 (perp=9.540, rec=0.063, cos=0.468), tot_loss_proj:2.443 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=2.437 (perp=9.540, rec=0.062, cos=0.466), tot_loss_proj:2.452 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=2.437 (perp=9.540, rec=0.062, cos=0.468), tot_loss_proj:2.442 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.032 | p: 86.178 | r: 88.154
rouge2     | fm: 50.315 | p: 50.185 | r: 50.524
rougeL     | fm: 76.345 | p: 75.584 | r: 77.216
rougeLsum  | fm: 75.970 | p: 75.262 | r: 76.799
r1fm+r2fm = 137.347

input #30 time: 0:08:26 | total time: 4:39:25


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.743259872106699
highest_index [0]
highest [0.743259872106699]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8803261518478394 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8200880289077759 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.80809086561203 for ['[CLS] song spectators then [SEP]']
[Init] best rec loss: 0.8068515658378601 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.7763468623161316 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.775701105594635 for ['[CLS] lil number belmont [SEP]']
[Init] best rec loss: 0.7749015688896179 for ['[CLS] prefer impression see [SEP]']
[Init] best rec loss: 0.7619791030883789 for ['[CLS] lad crossing all [SEP]']
[Init] best rec loss: 0.7427883148193359 for ['[CLS] lighthouse peace case [SEP]']
[Init] best perm rec loss: 0.7413862347602844 for ['[CLS] case lighthouse peace [SEP]']
[Init] best perm rec loss: 0.738989531993866 for ['[CLS] lighthouse case peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.828 (perp=11.032, rec=0.192, cos=0.429), tot_loss_proj:3.012 [t=0.21s]
prediction: ['[CLS] better vehicle better [SEP]']
[ 100/2000] tot_loss=2.781 (perp=11.032, rec=0.136, cos=0.438), tot_loss_proj:3.007 [t=0.21s]
prediction: ['[CLS] better vehicle better [SEP]']
[ 150/2000] tot_loss=2.774 (perp=11.032, rec=0.129, cos=0.438), tot_loss_proj:3.008 [t=0.21s]
prediction: ['[CLS] better vehicle better [SEP]']
[ 200/2000] tot_loss=2.778 (perp=11.032, rec=0.124, cos=0.447), tot_loss_proj:3.008 [t=0.21s]
prediction: ['[CLS] better vehicle better [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.476 (perp=9.604, rec=0.114, cos=0.442), tot_loss_proj:2.701 [t=0.21s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 300/2000] tot_loss=2.280 (perp=8.741, rec=0.089, cos=0.443), tot_loss_proj:3.182 [t=0.21s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.037 (perp=7.603, rec=0.072, cos=0.444), tot_loss_proj:2.074 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.030 (perp=7.603, rec=0.065, cos=0.444), tot_loss_proj:2.070 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=2.031 (perp=7.603, rec=0.067, cos=0.444), tot_loss_proj:2.078 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.028 (perp=7.603, rec=0.060, cos=0.447), tot_loss_proj:2.070 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.033 (perp=7.603, rec=0.067, cos=0.445), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=2.016 (perp=7.603, rec=0.056, cos=0.440), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.020 (perp=7.603, rec=0.058, cos=0.441), tot_loss_proj:2.082 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.026 (perp=7.603, rec=0.058, cos=0.447), tot_loss_proj:2.077 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=2.026 (perp=7.603, rec=0.062, cos=0.443), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.024 (perp=7.603, rec=0.061, cos=0.442), tot_loss_proj:2.085 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.018 (perp=7.603, rec=0.056, cos=0.442), tot_loss_proj:2.076 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=2.030 (perp=7.603, rec=0.066, cos=0.444), tot_loss_proj:2.078 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.023 (perp=7.603, rec=0.061, cos=0.442), tot_loss_proj:2.080 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=2.019 (perp=7.603, rec=0.059, cos=0.440), tot_loss_proj:2.078 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=2.025 (perp=7.603, rec=0.061, cos=0.443), tot_loss_proj:2.072 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=2.031 (perp=7.603, rec=0.063, cos=0.447), tot_loss_proj:2.082 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=2.020 (perp=7.603, rec=0.055, cos=0.444), tot_loss_proj:2.071 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=2.023 (perp=7.603, rec=0.058, cos=0.444), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=2.022 (perp=7.603, rec=0.057, cos=0.445), tot_loss_proj:2.078 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=2.027 (perp=7.603, rec=0.060, cos=0.446), tot_loss_proj:2.075 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=2.033 (perp=7.603, rec=0.069, cos=0.443), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=2.028 (perp=7.603, rec=0.064, cos=0.444), tot_loss_proj:2.070 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=2.033 (perp=7.603, rec=0.068, cos=0.445), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=2.018 (perp=7.603, rec=0.052, cos=0.445), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=2.027 (perp=7.603, rec=0.061, cos=0.446), tot_loss_proj:2.073 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=2.026 (perp=7.603, rec=0.060, cos=0.446), tot_loss_proj:2.074 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=2.030 (perp=7.603, rec=0.062, cos=0.447), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=2.031 (perp=7.603, rec=0.064, cos=0.446), tot_loss_proj:2.075 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=2.023 (perp=7.603, rec=0.057, cos=0.445), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=2.020 (perp=7.603, rec=0.052, cos=0.447), tot_loss_proj:2.085 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=2.030 (perp=7.603, rec=0.062, cos=0.448), tot_loss_proj:2.080 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=2.020 (perp=7.603, rec=0.053, cos=0.447), tot_loss_proj:2.075 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=2.029 (perp=7.603, rec=0.062, cos=0.446), tot_loss_proj:2.073 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=2.025 (perp=7.603, rec=0.058, cos=0.446), tot_loss_proj:2.085 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.568 | p: 86.723 | r: 88.628
rouge2     | fm: 51.861 | p: 51.760 | r: 52.063
rougeL     | fm: 77.020 | p: 76.333 | r: 77.964
rougeLsum  | fm: 76.786 | p: 76.100 | r: 77.717
r1fm+r2fm = 139.429

input #31 time: 0:08:26 | total time: 4:47:51


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.7358530266807384
highest_index [0]
highest [0.7358530266807384]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9214564561843872 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9210115075111389 for ['[CLS] paidgiri university han night mill voice natural mainline victoria yiddish / [SEP]']
[Init] best rec loss: 0.9192681908607483 for ['[CLS] knew benton usage9 fireplace hop reign. kappa pull poet writes [SEP]']
[Init] best rec loss: 0.9174575805664062 for ['[CLS] attacked product shown divided arsenal doctor phones eden sign she luce sam [SEP]']
[Init] best rec loss: 0.9093889594078064 for ['[CLS] spot fare studentouin than temporary song grow prize brings midst crotch [SEP]']
[Init] best rec loss: 0.9073228240013123 for ['[CLS] when was thief garrett wherever guestieg affiliate bent double pickup jerry [SEP]']
[Init] best rec loss: 0.9011974334716797 for ['[CLS] sub trials milk park casual two emma pocket breed against defending tenor [SEP]']
[Init] best rec loss: 0.889277458190918 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8855170011520386 for ['[CLS] unanimous let ″ forth inclination between alongside gods lips airport baptism mud [SEP]']
[Init] best perm rec loss: 0.8854575157165527 for ['[CLS] inclination let alongside forth unanimous baptism mud lips between ″ airport gods [SEP]']
[Init] best perm rec loss: 0.8834101557731628 for ['[CLS] unanimous airport let alongside lips between gods inclination ″ mud baptism forth [SEP]']
[Init] best perm rec loss: 0.8816874623298645 for ['[CLS] mud between unanimous airport ″ inclination lips baptism forth let gods alongside [SEP]']
[Init] best perm rec loss: 0.8814775943756104 for ['[CLS] airport let between inclination unanimous lips forth gods mud ″ baptism alongside [SEP]']
[Init] best perm rec loss: 0.8805165886878967 for ['[CLS] mud unanimous airport forth ″ baptism between inclination alongside lips gods let [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.371 (perp=13.156, rec=0.280, cos=0.460), tot_loss_proj:4.037 [t=0.21s]
prediction: ['[CLS] get easily genuine stories performances morningsivity them species accessible accessible together [SEP]']
[ 100/2000] tot_loss=3.128 (perp=12.383, rec=0.195, cos=0.456), tot_loss_proj:4.105 [t=0.22s]
prediction: ['[CLS] pull easily easily stories accessible scoutsivity biting with accessibleity res [SEP]']
[ 150/2000] tot_loss=2.863 (perp=11.255, rec=0.158, cos=0.453), tot_loss_proj:3.621 [t=0.22s]
prediction: ['[CLS] pull together accessible stories accessibleonateonate easily withonateity that [SEP]']
[ 200/2000] tot_loss=2.907 (perp=11.582, rec=0.136, cos=0.454), tot_loss_proj:3.675 [t=0.22s]
prediction: ['[CLS] pull together accessible stories accessibleonate resund withonateity that [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.110 (perp=12.520, rec=0.147, cos=0.459), tot_loss_proj:4.051 [t=0.22s]
prediction: ['[CLS] pull together easily stories accessible xlund withityonateity that [SEP]']
[ 300/2000] tot_loss=2.752 (perp=10.875, rec=0.121, cos=0.456), tot_loss_proj:3.734 [t=0.22s]
prediction: ['[CLS] pull together easily stories accessibletextund with profonateity that [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.357 (perp=8.969, rec=0.108, cos=0.455), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] pull together easily stories accessible profonate with profundity that [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.251 (perp=8.433, rec=0.109, cos=0.455), tot_loss_proj:2.896 [t=0.22s]
prediction: ['[CLS] pull together easily stories profonate with profundity that accessible [SEP]']
[ 450/2000] tot_loss=2.237 (perp=8.433, rec=0.095, cos=0.455), tot_loss_proj:2.895 [t=0.22s]
prediction: ['[CLS] pull together easily stories profonate with profundity that accessible [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.479 (perp=9.614, rec=0.100, cos=0.455), tot_loss_proj:3.102 [t=0.22s]
prediction: ['[CLS] pull together easily stories profonate with resundity that accessible [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.342 (perp=9.010, rec=0.084, cos=0.457), tot_loss_proj:2.822 [t=0.22s]
prediction: ['[CLS] pull together easily stories profund with resonateity that accessible [SEP]']
[ 600/2000] tot_loss=2.348 (perp=9.010, rec=0.090, cos=0.456), tot_loss_proj:2.811 [t=0.22s]
prediction: ['[CLS] pull together easily stories profund with resonateity that accessible [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.271 (perp=8.652, rec=0.084, cos=0.456), tot_loss_proj:2.692 [t=0.22s]
prediction: ['[CLS] pull together easily stories profund that resonateity with accessible [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.078 (perp=7.714, rec=0.079, cos=0.456), tot_loss_proj:2.535 [t=0.22s]
prediction: ['[CLS] pull together easily stories profundity that resonate with accessible [SEP]']
[ 750/2000] tot_loss=2.079 (perp=7.714, rec=0.078, cos=0.458), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] pull together easily stories profundity that resonate with accessible [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.059 (perp=7.614, rec=0.079, cos=0.457), tot_loss_proj:2.355 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories profundity that resonate with [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.057 (perp=7.614, rec=0.077, cos=0.457), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories profundity that resonate with [SEP]']
[ 900/2000] tot_loss=2.052 (perp=7.614, rec=0.071, cos=0.458), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories profundity that resonate with [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.907 (perp=6.785, rec=0.093, cos=0.456), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1000/2000] tot_loss=1.900 (perp=6.785, rec=0.086, cos=0.457), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1050/2000] tot_loss=1.885 (perp=6.785, rec=0.071, cos=0.457), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1100/2000] tot_loss=1.893 (perp=6.785, rec=0.079, cos=0.457), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1150/2000] tot_loss=1.886 (perp=6.785, rec=0.071, cos=0.458), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1200/2000] tot_loss=1.884 (perp=6.785, rec=0.069, cos=0.458), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1250/2000] tot_loss=1.884 (perp=6.785, rec=0.069, cos=0.458), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1300/2000] tot_loss=1.887 (perp=6.785, rec=0.072, cos=0.458), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1350/2000] tot_loss=1.885 (perp=6.785, rec=0.069, cos=0.458), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1400/2000] tot_loss=1.889 (perp=6.785, rec=0.075, cos=0.458), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1450/2000] tot_loss=1.881 (perp=6.785, rec=0.066, cos=0.457), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1500/2000] tot_loss=1.885 (perp=6.785, rec=0.070, cos=0.458), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1550/2000] tot_loss=1.885 (perp=6.785, rec=0.070, cos=0.458), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1600/2000] tot_loss=1.885 (perp=6.785, rec=0.069, cos=0.458), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1650/2000] tot_loss=1.881 (perp=6.785, rec=0.066, cos=0.458), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1700/2000] tot_loss=1.888 (perp=6.785, rec=0.072, cos=0.458), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1750/2000] tot_loss=1.887 (perp=6.785, rec=0.071, cos=0.458), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1800/2000] tot_loss=1.885 (perp=6.785, rec=0.070, cos=0.458), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1850/2000] tot_loss=1.885 (perp=6.785, rec=0.069, cos=0.458), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[1900/2000] tot_loss=1.884 (perp=6.785, rec=0.069, cos=0.458), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
[1950/2000] tot_loss=1.873 (perp=6.785, rec=0.058, cos=0.458), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Attempt swap
[2000/2000] tot_loss=1.888 (perp=6.785, rec=0.073, cos=0.458), tot_loss_proj:1.960 [t=0.22s]
prediction: ['[CLS] pull together easily accessible stories with profundity that resonate [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pull together easily accessible stories with profundity that resonate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 87.970 | p: 87.206 | r: 88.950
rouge2     | fm: 51.942 | p: 51.760 | r: 52.051
rougeL     | fm: 77.108 | p: 76.476 | r: 77.935
rougeLsum  | fm: 77.226 | p: 76.606 | r: 78.100
r1fm+r2fm = 139.912

input #32 time: 0:08:35 | total time: 4:56:27


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.7350676515175524
highest_index [0]
highest [0.7350676515175524]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9721574783325195 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8388820290565491 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8385742902755737 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.7690669298171997 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7553659677505493 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.734414279460907 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7237889766693115 for ['[CLS] railroad [SEP]']
[Init] best rec loss: 0.6838114857673645 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.656042218208313 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.935 (perp=11.231, rec=0.253, cos=0.436), tot_loss_proj:2.878 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.779 (perp=11.231, rec=0.074, cos=0.459), tot_loss_proj:2.827 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.758 (perp=11.231, rec=0.053, cos=0.459), tot_loss_proj:2.818 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.776 (perp=11.231, rec=0.070, cos=0.460), tot_loss_proj:2.815 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.761 (perp=11.231, rec=0.056, cos=0.459), tot_loss_proj:2.825 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.758 (perp=11.231, rec=0.053, cos=0.458), tot_loss_proj:2.833 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.767 (perp=11.231, rec=0.062, cos=0.459), tot_loss_proj:2.819 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.767 (perp=11.231, rec=0.063, cos=0.458), tot_loss_proj:2.827 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.767 (perp=11.231, rec=0.064, cos=0.457), tot_loss_proj:2.829 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.768 (perp=11.231, rec=0.064, cos=0.458), tot_loss_proj:2.834 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.773 (perp=11.231, rec=0.070, cos=0.458), tot_loss_proj:2.834 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.762 (perp=11.231, rec=0.057, cos=0.459), tot_loss_proj:2.823 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.772 (perp=11.231, rec=0.066, cos=0.460), tot_loss_proj:2.838 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.763 (perp=11.231, rec=0.059, cos=0.458), tot_loss_proj:2.820 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.763 (perp=11.231, rec=0.059, cos=0.458), tot_loss_proj:2.821 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.766 (perp=11.231, rec=0.060, cos=0.459), tot_loss_proj:2.821 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.766 (perp=11.231, rec=0.061, cos=0.459), tot_loss_proj:2.830 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.756 (perp=11.231, rec=0.051, cos=0.459), tot_loss_proj:2.820 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.755 (perp=11.231, rec=0.050, cos=0.458), tot_loss_proj:2.823 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.762 (perp=11.231, rec=0.057, cos=0.459), tot_loss_proj:2.816 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.764 (perp=11.231, rec=0.059, cos=0.459), tot_loss_proj:2.818 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.765 (perp=11.231, rec=0.059, cos=0.459), tot_loss_proj:2.824 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.759 (perp=11.231, rec=0.055, cos=0.458), tot_loss_proj:2.822 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.762 (perp=11.231, rec=0.057, cos=0.459), tot_loss_proj:2.811 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.758 (perp=11.231, rec=0.052, cos=0.460), tot_loss_proj:2.826 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.762 (perp=11.231, rec=0.057, cos=0.459), tot_loss_proj:2.810 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.760 (perp=11.231, rec=0.055, cos=0.459), tot_loss_proj:2.823 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.772 (perp=11.231, rec=0.067, cos=0.459), tot_loss_proj:2.816 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.774 (perp=11.231, rec=0.068, cos=0.460), tot_loss_proj:2.820 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.759 (perp=11.231, rec=0.054, cos=0.459), tot_loss_proj:2.826 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.771 (perp=11.231, rec=0.065, cos=0.459), tot_loss_proj:2.820 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.756 (perp=11.231, rec=0.051, cos=0.459), tot_loss_proj:2.822 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.771 (perp=11.231, rec=0.065, cos=0.459), tot_loss_proj:2.810 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.768 (perp=11.231, rec=0.063, cos=0.459), tot_loss_proj:2.821 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.767 (perp=11.231, rec=0.062, cos=0.459), tot_loss_proj:2.817 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.754 (perp=11.231, rec=0.049, cos=0.459), tot_loss_proj:2.830 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.779 (perp=11.231, rec=0.074, cos=0.459), tot_loss_proj:2.811 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.771 (perp=11.231, rec=0.065, cos=0.459), tot_loss_proj:2.817 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.761 (perp=11.231, rec=0.055, cos=0.459), tot_loss_proj:2.822 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.759 (perp=11.231, rec=0.054, cos=0.459), tot_loss_proj:2.832 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.268 | p: 87.444 | r: 89.207
rouge2     | fm: 53.360 | p: 53.240 | r: 53.505
rougeL     | fm: 77.802 | p: 77.119 | r: 78.648
rougeLsum  | fm: 77.717 | p: 77.045 | r: 78.573
r1fm+r2fm = 141.629

input #33 time: 0:08:27 | total time: 5:04:54


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.7296684206114745
highest_index [0]
highest [0.7296684206114745]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8630025386810303 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8616822361946106 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8468841314315796 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.791394054889679 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7698782086372375 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7490471005439758 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.7211088538169861 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7197591066360474 for ['[CLS] ship okay slight worthibe lissa who statue along drivers fieldask founder [SEP]']
[Init] best perm rec loss: 0.7196118235588074 for ['[CLS] field along drivers okay founder who slight lissa worthaskibe statue ship [SEP]']
[Init] best perm rec loss: 0.719508171081543 for ['[CLS]ibe ship founder field along whoask drivers worth statue okay slight lissa [SEP]']
[Init] best perm rec loss: 0.719188392162323 for ['[CLS]ibe okay slight lissa ship worth founderask drivers who along statue field [SEP]']
[Init] best perm rec loss: 0.7190675139427185 for ['[CLS]ibe ship okay founderask lissa who field worth statue drivers along slight [SEP]']
[Init] best perm rec loss: 0.7188062071800232 for ['[CLS] fieldask drivers statue slightibe who worth along lissa ship founder okay [SEP]']
[Init] best perm rec loss: 0.7168434262275696 for ['[CLS]ibe driversask lissa founder statue slight worth who okay ship field along [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.331 (perp=12.939, rec=0.282, cos=0.462), tot_loss_proj:4.076 [t=0.21s]
prediction: ['[CLS] urgency extreme pierre full racecourse becameora nicholas urgency urgency urgency raw urgency [SEP]']
[ 100/2000] tot_loss=3.050 (perp=11.903, rec=0.210, cos=0.459), tot_loss_proj:4.084 [t=0.22s]
prediction: ['[CLS] urgency extremeische in urgency ; of nicholas urgency urgency urgency urgency urgency [SEP]']
[ 150/2000] tot_loss=2.579 (perp=9.704, rec=0.169, cos=0.469), tot_loss_proj:3.189 [t=0.22s]
prediction: ['[CLS] urgency extreme mind in viewer ; of viewer urgency on take viewer urgency [SEP]']
[ 200/2000] tot_loss=2.536 (perp=9.604, rec=0.152, cos=0.462), tot_loss_proj:3.112 [t=0.22s]
prediction: ['[CLS] urgency extreme mind in viewer and of viewer urgency on take viewer urgency [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.354 (perp=8.826, rec=0.131, cos=0.459), tot_loss_proj:3.007 [t=0.22s]
prediction: ['[CLS] urgency extreme of mind in mind and of urgency on take viewer build [SEP]']
[ 300/2000] tot_loss=2.524 (perp=9.791, rec=0.101, cos=0.464), tot_loss_proj:3.244 [t=0.22s]
prediction: ['[CLS] urgency extreme of viewer in mind and of urgency on take viewer build [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.216 (perp=8.322, rec=0.094, cos=0.457), tot_loss_proj:2.675 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the urgency on take viewer build [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.079 (perp=7.657, rec=0.086, cos=0.462), tot_loss_proj:2.633 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[ 450/2000] tot_loss=2.079 (perp=7.657, rec=0.084, cos=0.463), tot_loss_proj:2.623 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.075 (perp=7.657, rec=0.082, cos=0.462), tot_loss_proj:2.623 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.074 (perp=7.657, rec=0.078, cos=0.465), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[ 600/2000] tot_loss=2.083 (perp=7.657, rec=0.089, cos=0.463), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.078 (perp=7.657, rec=0.082, cos=0.465), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.069 (perp=7.657, rec=0.078, cos=0.460), tot_loss_proj:2.620 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[ 750/2000] tot_loss=2.069 (perp=7.657, rec=0.077, cos=0.461), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.065 (perp=7.657, rec=0.068, cos=0.465), tot_loss_proj:2.607 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.068 (perp=7.657, rec=0.075, cos=0.462), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[ 900/2000] tot_loss=2.075 (perp=7.657, rec=0.080, cos=0.464), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.068 (perp=7.657, rec=0.077, cos=0.459), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1000/2000] tot_loss=2.076 (perp=7.657, rec=0.077, cos=0.468), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1050/2000] tot_loss=2.075 (perp=7.657, rec=0.079, cos=0.464), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1100/2000] tot_loss=2.068 (perp=7.657, rec=0.073, cos=0.463), tot_loss_proj:2.608 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1150/2000] tot_loss=2.069 (perp=7.657, rec=0.074, cos=0.464), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1200/2000] tot_loss=2.070 (perp=7.657, rec=0.075, cos=0.464), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1250/2000] tot_loss=2.068 (perp=7.657, rec=0.074, cos=0.463), tot_loss_proj:2.610 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1300/2000] tot_loss=2.057 (perp=7.657, rec=0.062, cos=0.464), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1350/2000] tot_loss=2.066 (perp=7.657, rec=0.072, cos=0.462), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1400/2000] tot_loss=2.057 (perp=7.657, rec=0.061, cos=0.465), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1450/2000] tot_loss=2.071 (perp=7.657, rec=0.075, cos=0.465), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1500/2000] tot_loss=2.063 (perp=7.657, rec=0.067, cos=0.464), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1550/2000] tot_loss=2.067 (perp=7.657, rec=0.074, cos=0.462), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1600/2000] tot_loss=2.059 (perp=7.657, rec=0.066, cos=0.461), tot_loss_proj:2.610 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1650/2000] tot_loss=2.076 (perp=7.657, rec=0.079, cos=0.465), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1700/2000] tot_loss=2.077 (perp=7.657, rec=0.081, cos=0.464), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1750/2000] tot_loss=2.059 (perp=7.657, rec=0.063, cos=0.464), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1800/2000] tot_loss=2.061 (perp=7.657, rec=0.066, cos=0.464), tot_loss_proj:2.602 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1850/2000] tot_loss=2.053 (perp=7.657, rec=0.058, cos=0.463), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[1900/2000] tot_loss=2.068 (perp=7.657, rec=0.073, cos=0.464), tot_loss_proj:2.612 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
[1950/2000] tot_loss=2.065 (perp=7.657, rec=0.070, cos=0.464), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Attempt swap
[2000/2000] tot_loss=2.059 (perp=7.657, rec=0.063, cos=0.464), tot_loss_proj:2.610 [t=0.22s]
prediction: ['[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] of extreme urgency viewer in mind and the take on urgency viewer build [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.655 | p: 86.667 | r: 92.857
rouge2     | fm: 14.815 | p: 14.286 | r: 15.385
rougeL     | fm: 55.172 | p: 53.333 | r: 57.143
rougeLsum  | fm: 55.172 | p: 53.333 | r: 57.143
r1fm+r2fm = 104.470

[Aggregate metrics]:
rouge1     | fm: 88.373 | p: 87.532 | r: 89.428
rouge2     | fm: 52.545 | p: 52.437 | r: 52.696
rougeL     | fm: 77.240 | p: 76.518 | r: 78.077
rougeLsum  | fm: 77.069 | p: 76.446 | r: 77.883
r1fm+r2fm = 140.919

input #34 time: 0:08:35 | total time: 5:13:30


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.7436263645614385
highest_index [0]
highest [0.7436263645614385]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.883111834526062 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8753374814987183 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.8613861799240112 for ['[CLS] ari collapsed popularized "imated inspired in eva separately erie owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best perm rec loss: 0.8607619404792786 for ['[CLS] eva played? two responded torn " five art everybody talmud seat collapsed among grown qatarimated hunt closer [SEP] ari separately owned popularizedtripives actually inspired lend swallowed april sheriff side example strait erie red baptist sighted y up in [SEP]']
[Init] best perm rec loss: 0.860309362411499 for ['[CLS] example seat swallowed grown inspired [SEP] sideives talmud separately baptist up in qatar collapsed played y two? art owned closer five among lend popularized torn april ariimated responded hunt eva actually everybody strait erie " sherifftrip red sighted [SEP]']
[Init] best perm rec loss: 0.8596181273460388 for ['[CLS] y strait actually inspired popularized fiveimatedives red side art owned sighted qatar seat baptist responded eva grown sheriff lend ari two up played among in example hunt talmud separately " torn [SEP] closer? swallowed everybodytrip april erie collapsed [SEP]']
[Init] best perm rec loss: 0.8585766553878784 for ['[CLS] ari everybody torn april y separately art actually side " collapsed owned erie red in qatar up seat lend closer respondedtripimated? hunt popularized swallowed grown [SEP] two among played talmud five eva straitives example sheriff baptist sighted inspired [SEP]']
[Init] best perm rec loss: 0.8584690093994141 for ['[CLS] torn inspired side two in huntimated sighted everybodyives responded up baptist strait owned qatar " lend grown red april? among y ari art swallowed separately [SEP] evatrip played popularized talmud collapsed closer sheriff seat example actually five erie [SEP]']
[Init] best perm rec loss: 0.8579527139663696 for ['[CLS] lend? redtrip strait five among separately art swallowed erie in seat popularized april grown " hunt baptist torn actually sheriff responded up played ariimated qatarives talmud sighted eva inspired owned y two example side everybody [SEP] closer collapsed [SEP]']
[Init] best perm rec loss: 0.8565258383750916 for ['[CLS] played [SEP] five side ari sighted two in seat swallowed y lend popularized red separately qatar grown hunt strait art up ownedtrip eva collapsed responded erie closer inspired " torn baptist example sheriffivesimated april talmud among actually everybody? [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.353 (perp=12.393, rec=0.432, cos=0.443), tot_loss_proj:4.163 [t=0.22s]
prediction: ['[CLS] leads stuff fruit care derek department director network became encyclopediagingly biography brian. among minister. personal highly remote acclaimed. role global great replacement the improved comment robertated flock artist [ love treated praise tessa televisionntation upon things [SEP]']
[ 100/2000] tot_loss=3.118 (perp=11.432, rec=0.385, cos=0.446), tot_loss_proj:3.770 [t=0.22s]
prediction: ['[CLS] introduced has fruit care production feature director nfl has graduate jo, brian. after director - new seriously secret studio the victories our great help disc worked cared director the lopez great cared this regarding we phi!nation again savannah [SEP]']
[ 150/2000] tot_loss=2.874 (perp=10.529, rec=0.337, cos=0.432), tot_loss_proj:3.995 [t=0.22s]
prediction: ["[CLS] introduced has'care estimate may director. has mueller produced? kevin. after host of at today strange director the roles us great help disc worked cared director, lopez complete care not care help indy) world upon that [SEP]"]
[ 200/2000] tot_loss=2.800 (perp=10.345, rec=0.288, cos=0.443), tot_loss_proj:3.936 [t=0.22s]
prediction: ["[CLS] came but sid care are past director. makes prior but? james, stocks director of suddenly justuous great, lately us great help twice work powers director, lopez complete care not care about greatest speakingnation of'[SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.626 (perp=9.351, rec=0.313, cos=0.443), tot_loss_proj:3.692 [t=0.22s]
prediction: ["[CLS] or but ve traction peer before director. makes – before? james. rusty director of suddenly memory before, prime us great help latest. great powers because, printed over care not care about greatest.nation ள'[SEP]"]
[ 300/2000] tot_loss=2.538 (perp=9.064, rec=0.278, cos=0.447), tot_loss_proj:3.672 [t=0.22s]
prediction: ["[CLS] - but bassett '. before director. makes province before how john. many director of rent director before. roles us great help twice. great powers ).line< care not care about greatest.nation is of [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=4.082 (perp=11.433, rec=0.796, cos=0.999), tot_loss_proj:4.168 [t=0.22s]
prediction: ['[CLS] [SEP] but the her [SEP] and matt because makes no her the is event 止 trey actually because weird糹 nevada [SEP] jurisdiction quite help [SEP]. prominent weird : gmina hispanic [SEP] care. care a [SEP], [SEP]. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=4.009 (perp=11.392, rec=0.731, cos=1.000), tot_loss_proj:3.922 [t=0.22s]
prediction: ['[CLS] [SEP] but the her [SEP] and matt because makes province her the is, 止 trey reported about weird糹 nevada [SEP] role quite help [SEP]. beautiful weird : gmina hispanic [SEP] care. care this [SEP] event [SEP]. [SEP] [SEP]']
[ 450/2000] tot_loss=3.894 (perp=10.959, rec=0.703, cos=1.000), tot_loss_proj:3.868 [t=0.22s]
prediction: ['[CLS] [SEP] but the her [SEP] and an because made province her the is, 止 trey reported sometimes weird糹 nevada [SEP] production quite. [SEP]. beautiful explained :ව hispanic [SEP] care. care a chavez event [SEP]. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.848 (perp=10.942, rec=0.660, cos=0.999), tot_loss_proj:3.916 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] from an because made province the the in. 止. her currently weird糹 nevada [SEP] production quite. [SEP]. beautiful explained : gmina hispanic [SEP] care hurricane yourself a chavez event [SEP]. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.833 (perp=10.760, rec=0.683, cos=0.998), tot_loss_proj:3.786 [t=0.22s]
prediction: ['[CLS] [SEP] and the noticed [SEP] anddra because. province the madeu. 止. her personally weird [CLS] directorate [SEP] production usually. [SEP] a beautiful aidan : gmina hispanic [SEP] care [SEP] her a indy climbed [SEP]. [SEP] [SEP]']
[ 600/2000] tot_loss=3.785 (perp=10.807, rec=0.635, cos=0.989), tot_loss_proj:3.728 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] indra because. province the madeo. 止. her pageant dude [CLS] directorate [SEP] production usually. [SEP] a beautiful aidan : gmina hispanic [SEP] care [SEP] her a indy climbed [SEP]. [SEP] [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.595 (perp=10.069, rec=0.619, cos=0.963), tot_loss_proj:3.579 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] in armor because. province the makeso. moderator. her pageant dude [SEP] [CLS] directorate [SEP] production quite. [SEP] a beautiful aidan : gmina hispanic [SEP] care [SEP] her a federer climbed. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.588 (perp=9.958, rec=0.719, cos=0.878), tot_loss_proj:3.753 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] ( stan because his climbed its makeso was moderator. her [SEP] doc [SEP] [CLS] wolf [SEP] production quite. [SEP]. beautiful aidan : twinned hispanic [SEP] care [SEP] her a criticized province. [SEP] [SEP]']
[ 750/2000] tot_loss=3.114 (perp=9.987, rec=0.655, cos=0.462), tot_loss_proj:3.610 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] ( maybe because his climbed her makesje was 止. her [SEP] doc [SEP] [CLS] wolf [SEP] production quite words [SEP]. beautiful aidan and twinned hispanic [SEP] care [SEP] her a [SEP] province. [SEP] [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.036 (perp=9.816, rec=0.634, cos=0.439), tot_loss_proj:3.497 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber because an climbed her makeso was 止. her ( [SEP] doc [SEP] [CLS] wolf [SEP] production quite. [SEP]. beautiful aidan and twinned hispanic [SEP] care [SEP] her a [SEP] province. [SEP] [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.955 (perp=9.447, rec=0.626, cos=0.439), tot_loss_proj:3.422 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber because an climbed her makeso was 止. her [SEP] doc [SEP] [CLS] wolf [SEP] production quite. [SEP]. beautiful aidan and twinned jared [SEP] care [SEP] her a [SEP] province. [SEP] ( [SEP]']
[ 900/2000] tot_loss=2.973 (perp=9.633, rec=0.606, cos=0.440), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] too because an climbed her makeso was 止. her [SEP] doc [SEP] [CLS] because [SEP] production quite. [SEP]. beautiful aidan and twinned jared [SEP] care [SEP] her a criticized province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.871 (perp=9.140, rec=0.596, cos=0.447), tot_loss_proj:3.484 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber because an climbed her makeso was 止. her [SEP] doc [SEP] [CLS] beautiful. production quite. [SEP]. because aidan and twinned jared [SEP] care [SEP] her a criticized province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.805 (perp=8.879, rec=0.584, cos=0.445), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber because renee climbed her makesi was 止. her [SEP] doc [SEP] [CLS] beautiful. production quite. [SEP] criticized because aidan and twinned jared [SEP] care [SEP] her a. province. [SEP] ( [SEP]']
[1050/2000] tot_loss=2.852 (perp=9.159, rec=0.577, cos=0.444), tot_loss_proj:3.622 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber because [CLS] climbed her makesi was 止. her [SEP] doc [SEP] [CLS] beautiful. production quite. [SEP] criticized because aidan and twinned jared [SEP] care [SEP] her a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.760 (perp=8.666, rec=0.575, cos=0.452), tot_loss_proj:3.575 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber [SEP] [CLS] climbed her makeso was 止. her because doc [SEP] [CLS] great. production quite. [SEP] criticized because aidan and twinned belgarath [SEP] care [SEP] her a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.836 (perp=9.086, rec=0.568, cos=0.450), tot_loss_proj:3.669 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber [SEP] [CLS] climbed her makesi was 止. her because doc [SEP] [CLS] great hand production quite. [SEP] criticized because merely and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
[1200/2000] tot_loss=2.827 (perp=9.086, rec=0.565, cos=0.445), tot_loss_proj:3.670 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber [SEP] [CLS] climbed her makesi was 止. her because doc [SEP] [CLS] great hand production quite. [SEP] criticized because merely and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.747 (perp=8.766, rec=0.563, cos=0.430), tot_loss_proj:3.602 [t=0.22s]
prediction: ['[CLS] [SEP] but the noticed [SEP] amber [SEP] [CLS] quite her makesave was 止. her because doc [SEP] [CLS] great great production climbed. [SEP] criticized because merely and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.948 (perp=9.739, rec=0.559, cos=0.441), tot_loss_proj:3.794 [t=0.22s]
prediction: ['[CLS] husband but the noticed [SEP] amber [SEP] tight quite her makesave was 止. her because doc [SEP] [CLS] great great production climbed. [SEP] criticized because merely and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
[1350/2000] tot_loss=2.941 (perp=9.709, rec=0.553, cos=0.446), tot_loss_proj:3.777 [t=0.22s]
prediction: ['[CLS] husband but the noticed [SEP] amber [SEP] tight quite her madeave was 止. her because doc [SEP] [CLS] great greatest production climbed. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.926 (perp=9.632, rec=0.552, cos=0.447), tot_loss_proj:3.749 [t=0.22s]
prediction: ['[CLS] husband but the noticed [SEP] amber [SEP] tight quite made herave was moderator. her because doc [SEP] [CLS] great greatest production climbed. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.895 (perp=9.508, rec=0.546, cos=0.448), tot_loss_proj:3.726 [t=0.22s]
prediction: ['[CLS] husband but the noticed [SEP] amber [SEP] tight made her quiteave was moderator. her because doc [SEP] [CLS] great greatest production climbed. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
[1500/2000] tot_loss=2.905 (perp=9.557, rec=0.547, cos=0.447), tot_loss_proj:3.750 [t=0.22s]
prediction: ['[CLS] husband but the noticed [SEP] amber [SEP] nedra made her quiteave was moderator. her because doc [SEP] [CLS] great greatest production climbed. [SEP] criticized because ages, twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.853 (perp=9.309, rec=0.543, cos=0.448), tot_loss_proj:3.689 [t=0.22s]
prediction: ['[CLS] great but the noticed [SEP] amber [SEP] nedra made her quiteave was moderator. her because doc [SEP] [CLS] husband greatest production climbed. [SEP] criticized because ages, twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.820 (perp=9.121, rec=0.552, cos=0.443), tot_loss_proj:3.640 [t=0.22s]
prediction: ['[CLS] great but the noticed [SEP] amber [SEP] nedra because her buten was moderator. her made doc [SEP] [CLS] husband greatest production climbed. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] back a. province. [SEP] ( [SEP]']
[1650/2000] tot_loss=2.849 (perp=9.298, rec=0.545, cos=0.444), tot_loss_proj:3.664 [t=0.22s]
prediction: ['[CLS] great but the noticed [SEP] amber [SEP] nedra because her buten was moderator. her makes doc [SEP] [CLS] husband [SEP] production climbed. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.824 (perp=9.165, rec=0.543, cos=0.448), tot_loss_proj:3.619 [t=0.22s]
prediction: ['[CLS] great but the noticed [SEP] amber [SEP] nedra because her husbanden was moderator. her makes doc [SEP] [CLS] quite [SEP] production climbed. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a. province. [SEP] ( [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.791 (perp=9.013, rec=0.541, cos=0.447), tot_loss_proj:3.580 [t=0.22s]
prediction: ['[CLS] great but the noticed [SEP] amber [SEP] nedra because her husbanden was moderator. her makes doc [SEP] [CLS] quite [SEP] climbed production. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a. province. [SEP] ( [SEP]']
[1800/2000] tot_loss=2.767 (perp=8.914, rec=0.541, cos=0.443), tot_loss_proj:3.593 [t=0.22s]
prediction: ['[CLS] great but the noticed [SEP] amber [SEP] cynthia because her husbanden was moderator. her makes doc [SEP] [CLS] but [SEP] climbed production. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a. province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.748 (perp=8.809, rec=0.542, cos=0.445), tot_loss_proj:3.562 [t=0.22s]
prediction: ['[CLS] great but the noticed. amber [SEP] cynthia because her husbanden was moderator. her makes doc [SEP] [CLS] but [SEP] stepped production. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a [SEP] province. [SEP] ( [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.752 (perp=8.828, rec=0.541, cos=0.446), tot_loss_proj:3.572 [t=0.22s]
prediction: ['[CLS] great but the noticed. amber [SEP] cynthia because her husbanden was moderator. her makes stepped [SEP] [CLS] but [SEP] recorded production. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a [SEP] province. [SEP] ( [SEP]']
[1950/2000] tot_loss=2.804 (perp=9.097, rec=0.539, cos=0.446), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] great but the noticed. amber [SEP] cynthia because her husbanden was moderator. her made stepped [SEP] [CLS] but [SEP] doc production. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a [SEP] province. [SEP] ( [SEP]']
Attempt swap
[2000/2000] tot_loss=2.792 (perp=9.058, rec=0.534, cos=0.447), tot_loss_proj:3.634 [t=0.22s]
prediction: ['[CLS] great but the noticed. anyway [SEP] cynthia because her husbanden was moderator. her makes stepped [SEP] [CLS] but [SEP] doc production. [SEP] criticized because ages and twinned belgarath [SEP] care [SEP] kind a [SEP] province. [SEP] ( [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] - but bassett '. before director. makes province before john. many director of rent director before. nominee us how great help twice. great powers ) ; printed< care not care about greatest. world is of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 41.176 | p: 42.424 | r: 40.000
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 26.471 | p: 27.273 | r: 25.714
rougeLsum  | fm: 26.471 | p: 27.273 | r: 25.714
r1fm+r2fm = 47.237

[Aggregate metrics]:
rouge1     | fm: 87.125 | p: 86.300 | r: 88.018
rouge2     | fm: 50.918 | p: 50.814 | r: 51.053
rougeL     | fm: 75.762 | p: 74.985 | r: 76.633
rougeLsum  | fm: 75.790 | p: 75.112 | r: 76.660
r1fm+r2fm = 138.043

input #35 time: 0:08:40 | total time: 5:22:10


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.7118894694423942
highest_index [0]
highest [0.7118894694423942]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9314919114112854 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.915166437625885 for ['[CLS] oscar deep peter ground [SEP]']
[Init] best rec loss: 0.9088126420974731 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.904313325881958 for ['[CLS] addition psychofi astronomer [SEP]']
[Init] best rec loss: 0.890755832195282 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8607612252235413 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8600159287452698 for ['[CLS] dormant known to mckenzie [SEP]']
[Init] best perm rec loss: 0.8584986925125122 for ['[CLS] known mckenzie dormant to [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.555 (perp=9.529, rec=0.154, cos=0.494), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=2.646 (perp=10.380, rec=0.079, cos=0.491), tot_loss_proj:2.979 [t=0.21s]
prediction: ['[CLS] horribly s horribly wrong [SEP]']
[ 150/2000] tot_loss=2.645 (perp=10.380, rec=0.080, cos=0.489), tot_loss_proj:2.980 [t=0.21s]
prediction: ['[CLS] horribly s horribly wrong [SEP]']
[ 200/2000] tot_loss=2.182 (perp=8.115, rec=0.069, cos=0.489), tot_loss_proj:2.199 [t=0.21s]
prediction: ["[CLS]'s horribly wrong [SEP]"]
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.504 (perp=9.451, rec=0.125, cos=0.488), tot_loss_proj:2.957 [t=0.22s]
prediction: ['[CLS] horribly wrong very s [SEP]']
[ 300/2000] tot_loss=2.465 (perp=9.451, rec=0.081, cos=0.494), tot_loss_proj:2.962 [t=0.21s]
prediction: ['[CLS] horribly wrong very s [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.502 (perp=9.698, rec=0.072, cos=0.490), tot_loss_proj:2.969 [t=0.21s]
prediction: ["[CLS]'horribly wrong s [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.999 (perp=7.159, rec=0.075, cos=0.492), tot_loss_proj:2.423 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 450/2000] tot_loss=1.993 (perp=7.159, rec=0.069, cos=0.492), tot_loss_proj:2.432 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.994 (perp=7.159, rec=0.071, cos=0.491), tot_loss_proj:2.429 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.998 (perp=7.159, rec=0.074, cos=0.492), tot_loss_proj:2.435 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.987 (perp=7.159, rec=0.062, cos=0.493), tot_loss_proj:2.438 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.996 (perp=7.159, rec=0.072, cos=0.492), tot_loss_proj:2.431 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.985 (perp=7.159, rec=0.063, cos=0.490), tot_loss_proj:2.434 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.987 (perp=7.159, rec=0.062, cos=0.493), tot_loss_proj:2.432 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.988 (perp=7.159, rec=0.065, cos=0.491), tot_loss_proj:2.431 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.981 (perp=7.159, rec=0.058, cos=0.492), tot_loss_proj:2.428 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.995 (perp=7.159, rec=0.071, cos=0.492), tot_loss_proj:2.429 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.987 (perp=7.159, rec=0.063, cos=0.492), tot_loss_proj:2.435 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.993 (perp=7.159, rec=0.069, cos=0.492), tot_loss_proj:2.430 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.994 (perp=7.159, rec=0.070, cos=0.492), tot_loss_proj:2.433 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.995 (perp=7.159, rec=0.072, cos=0.492), tot_loss_proj:2.425 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.985 (perp=7.159, rec=0.062, cos=0.491), tot_loss_proj:2.433 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.984 (perp=7.159, rec=0.060, cos=0.492), tot_loss_proj:2.437 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.992 (perp=7.159, rec=0.068, cos=0.493), tot_loss_proj:2.437 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.982 (perp=7.159, rec=0.059, cos=0.491), tot_loss_proj:2.436 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.989 (perp=7.159, rec=0.065, cos=0.492), tot_loss_proj:2.430 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.992 (perp=7.159, rec=0.067, cos=0.493), tot_loss_proj:2.432 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.984 (perp=7.159, rec=0.061, cos=0.491), tot_loss_proj:2.438 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.989 (perp=7.159, rec=0.065, cos=0.493), tot_loss_proj:2.428 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.989 (perp=7.159, rec=0.065, cos=0.492), tot_loss_proj:2.432 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.986 (perp=7.159, rec=0.063, cos=0.492), tot_loss_proj:2.432 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.985 (perp=7.159, rec=0.062, cos=0.492), tot_loss_proj:2.427 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.987 (perp=7.159, rec=0.063, cos=0.493), tot_loss_proj:2.431 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.985 (perp=7.159, rec=0.060, cos=0.493), tot_loss_proj:2.423 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.995 (perp=7.159, rec=0.071, cos=0.493), tot_loss_proj:2.429 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.991 (perp=7.159, rec=0.067, cos=0.492), tot_loss_proj:2.436 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.991 (perp=7.159, rec=0.067, cos=0.493), tot_loss_proj:2.424 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.987 (perp=7.159, rec=0.062, cos=0.493), tot_loss_proj:2.431 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.983 (perp=7.159, rec=0.059, cos=0.493), tot_loss_proj:2.431 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 87.315 | p: 86.556 | r: 88.314
rouge2     | fm: 50.245 | p: 50.108 | r: 50.412
rougeL     | fm: 75.809 | p: 75.108 | r: 76.646
rougeLsum  | fm: 75.915 | p: 75.264 | r: 76.725
r1fm+r2fm = 137.560

input #36 time: 0:08:29 | total time: 5:30:40


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.708640958286314
highest_index [0]
highest [0.708640958286314]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7971371412277222 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7654107213020325 for ['[CLS] child past [SEP]']
[Init] best rec loss: 0.7623812556266785 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.7179730534553528 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.7040489912033081 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 0.6436048746109009 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6229950785636902 for ['[CLS] molecule buddhism [SEP]']
[Init] best rec loss: 0.6041220426559448 for ['[CLS] beer city [SEP]']
[Init] best perm rec loss: 0.6026854515075684 for ['[CLS] city beer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.530 (perp=14.202, rec=0.217, cos=0.472), tot_loss_proj:3.651 [t=0.21s]
prediction: ['[CLS]ior eccentric [SEP]']
[ 100/2000] tot_loss=2.371 (perp=8.916, rec=0.092, cos=0.495), tot_loss_proj:2.498 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 150/2000] tot_loss=2.342 (perp=8.916, rec=0.071, cos=0.488), tot_loss_proj:2.492 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 200/2000] tot_loss=2.349 (perp=8.916, rec=0.071, cos=0.495), tot_loss_proj:2.487 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.328 (perp=8.916, rec=0.061, cos=0.484), tot_loss_proj:2.500 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=2.336 (perp=8.916, rec=0.063, cos=0.490), tot_loss_proj:2.501 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.340 (perp=8.916, rec=0.060, cos=0.497), tot_loss_proj:2.483 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.350 (perp=8.916, rec=0.068, cos=0.500), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=2.330 (perp=8.916, rec=0.059, cos=0.487), tot_loss_proj:2.502 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.356 (perp=8.916, rec=0.076, cos=0.496), tot_loss_proj:2.483 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.340 (perp=8.916, rec=0.061, cos=0.496), tot_loss_proj:2.501 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=2.351 (perp=8.916, rec=0.071, cos=0.497), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.344 (perp=8.916, rec=0.067, cos=0.494), tot_loss_proj:2.495 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.347 (perp=8.916, rec=0.072, cos=0.492), tot_loss_proj:2.504 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=2.349 (perp=8.916, rec=0.071, cos=0.495), tot_loss_proj:2.497 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.338 (perp=8.916, rec=0.062, cos=0.492), tot_loss_proj:2.510 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.343 (perp=8.916, rec=0.068, cos=0.492), tot_loss_proj:2.502 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=2.354 (perp=8.916, rec=0.076, cos=0.495), tot_loss_proj:2.493 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.349 (perp=8.916, rec=0.075, cos=0.490), tot_loss_proj:2.489 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=2.345 (perp=8.916, rec=0.068, cos=0.493), tot_loss_proj:2.493 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=2.343 (perp=8.916, rec=0.069, cos=0.491), tot_loss_proj:2.497 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=2.351 (perp=8.916, rec=0.073, cos=0.496), tot_loss_proj:2.499 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=2.350 (perp=8.916, rec=0.072, cos=0.494), tot_loss_proj:2.493 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=2.340 (perp=8.916, rec=0.062, cos=0.496), tot_loss_proj:2.486 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.337 (perp=8.916, rec=0.057, cos=0.496), tot_loss_proj:2.492 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=2.338 (perp=8.916, rec=0.061, cos=0.494), tot_loss_proj:2.492 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=2.339 (perp=8.916, rec=0.062, cos=0.494), tot_loss_proj:2.499 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=2.351 (perp=8.916, rec=0.073, cos=0.495), tot_loss_proj:2.501 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=2.337 (perp=8.916, rec=0.058, cos=0.497), tot_loss_proj:2.493 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=2.347 (perp=8.916, rec=0.069, cos=0.495), tot_loss_proj:2.505 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=2.340 (perp=8.916, rec=0.063, cos=0.494), tot_loss_proj:2.504 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=2.349 (perp=8.916, rec=0.070, cos=0.496), tot_loss_proj:2.502 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=2.342 (perp=8.916, rec=0.062, cos=0.496), tot_loss_proj:2.490 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=2.342 (perp=8.916, rec=0.062, cos=0.497), tot_loss_proj:2.499 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=2.341 (perp=8.916, rec=0.064, cos=0.494), tot_loss_proj:2.493 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=2.338 (perp=8.916, rec=0.060, cos=0.495), tot_loss_proj:2.493 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=2.338 (perp=8.916, rec=0.059, cos=0.495), tot_loss_proj:2.494 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=2.337 (perp=8.916, rec=0.058, cos=0.496), tot_loss_proj:2.501 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=2.339 (perp=8.916, rec=0.060, cos=0.496), tot_loss_proj:2.507 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=2.347 (perp=8.916, rec=0.068, cos=0.496), tot_loss_proj:2.497 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.712 | p: 86.958 | r: 88.618
rouge2     | fm: 48.800 | p: 48.671 | r: 48.931
rougeL     | fm: 75.847 | p: 75.237 | r: 76.662
rougeLsum  | fm: 75.817 | p: 75.206 | r: 76.621
r1fm+r2fm = 136.511

input #37 time: 0:08:23 | total time: 5:39:03


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.7373332147708712
highest_index [0]
highest [0.7373332147708712]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8231282830238342 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8160510063171387 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.7454701662063599 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7140145897865295 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6876659989356995 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.6582596302032471 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.360 (perp=14.069, rec=0.095, cos=0.451), tot_loss_proj:3.330 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=3.345 (perp=14.069, rec=0.074, cos=0.457), tot_loss_proj:3.318 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=3.340 (perp=14.069, rec=0.074, cos=0.452), tot_loss_proj:3.327 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=3.328 (perp=14.069, rec=0.067, cos=0.448), tot_loss_proj:3.325 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.343 (perp=14.069, rec=0.066, cos=0.462), tot_loss_proj:3.322 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=3.334 (perp=14.069, rec=0.069, cos=0.452), tot_loss_proj:3.323 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.322 (perp=14.069, rec=0.058, cos=0.450), tot_loss_proj:3.319 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.325 (perp=14.069, rec=0.062, cos=0.449), tot_loss_proj:3.316 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=3.332 (perp=14.069, rec=0.066, cos=0.452), tot_loss_proj:3.340 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.334 (perp=14.069, rec=0.065, cos=0.455), tot_loss_proj:3.339 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.319 (perp=14.069, rec=0.059, cos=0.446), tot_loss_proj:3.318 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=3.330 (perp=14.069, rec=0.063, cos=0.453), tot_loss_proj:3.338 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.331 (perp=14.069, rec=0.065, cos=0.452), tot_loss_proj:3.330 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.335 (perp=14.069, rec=0.069, cos=0.452), tot_loss_proj:3.326 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=3.322 (perp=14.069, rec=0.058, cos=0.450), tot_loss_proj:3.324 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.337 (perp=14.069, rec=0.071, cos=0.453), tot_loss_proj:3.316 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.313 (perp=14.069, rec=0.051, cos=0.449), tot_loss_proj:3.340 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=3.328 (perp=14.069, rec=0.063, cos=0.451), tot_loss_proj:3.338 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.309 (perp=14.069, rec=0.042, cos=0.453), tot_loss_proj:3.323 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=3.319 (perp=14.069, rec=0.054, cos=0.451), tot_loss_proj:3.324 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=3.318 (perp=14.069, rec=0.050, cos=0.454), tot_loss_proj:3.327 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=3.328 (perp=14.069, rec=0.064, cos=0.450), tot_loss_proj:3.329 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=3.336 (perp=14.069, rec=0.067, cos=0.455), tot_loss_proj:3.333 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=3.333 (perp=14.069, rec=0.066, cos=0.454), tot_loss_proj:3.331 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=3.328 (perp=14.069, rec=0.061, cos=0.454), tot_loss_proj:3.337 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=3.334 (perp=14.069, rec=0.068, cos=0.453), tot_loss_proj:3.319 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=3.326 (perp=14.069, rec=0.058, cos=0.454), tot_loss_proj:3.350 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=3.319 (perp=14.069, rec=0.052, cos=0.453), tot_loss_proj:3.320 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=3.321 (perp=14.069, rec=0.051, cos=0.455), tot_loss_proj:3.332 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=3.327 (perp=14.069, rec=0.061, cos=0.453), tot_loss_proj:3.334 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=3.320 (perp=14.069, rec=0.052, cos=0.454), tot_loss_proj:3.326 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=3.334 (perp=14.069, rec=0.067, cos=0.454), tot_loss_proj:3.318 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=3.327 (perp=14.069, rec=0.060, cos=0.454), tot_loss_proj:3.319 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=3.318 (perp=14.069, rec=0.050, cos=0.454), tot_loss_proj:3.336 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=3.327 (perp=14.069, rec=0.059, cos=0.454), tot_loss_proj:3.324 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=3.333 (perp=14.069, rec=0.067, cos=0.453), tot_loss_proj:3.335 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=3.322 (perp=14.069, rec=0.053, cos=0.455), tot_loss_proj:3.339 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=3.323 (perp=14.069, rec=0.055, cos=0.455), tot_loss_proj:3.327 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=3.335 (perp=14.069, rec=0.066, cos=0.455), tot_loss_proj:3.326 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=3.343 (perp=14.069, rec=0.073, cos=0.456), tot_loss_proj:3.334 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.066 | p: 87.362 | r: 88.963
rouge2     | fm: 50.303 | p: 50.144 | r: 50.503
rougeL     | fm: 76.475 | p: 75.783 | r: 77.186
rougeLsum  | fm: 76.497 | p: 75.901 | r: 77.174
r1fm+r2fm = 138.368

input #38 time: 0:08:27 | total time: 5:47:30


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.7349058031580414
highest_index [0]
highest [0.7349058031580414]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8146286010742188 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7939798831939697 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7825846672058105 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7524603605270386 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.7425155639648438 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best perm rec loss: 0.7420957088470459 for ['[CLS] vane local suns fa led brain meadowoof soon alone harmon transportation theried wrap court baseline jarrett taking shortlisted angus frenchiving look shows [SEP]']
[Init] best perm rec loss: 0.7419388890266418 for ['[CLS]iving meadow alone brain fa the taking led wrap showsoof angus baseline vane sunsried transportation local soon shortlisted court look harmon french jarrett [SEP]']
[Init] best perm rec loss: 0.7408578395843506 for ['[CLS] local led suns harmon alone meadow court wrapried look baseline shows transportationoof fa shortlisted jarrett sooniving vane french the angus brain taking [SEP]']
[Init] best perm rec loss: 0.7407339811325073 for ['[CLS] aloneiving meadow brain transportation shows the fa shortlisted suns vane local soonried french jarrett court baselineoof taking harmon led wrap angus look [SEP]']
[Init] best perm rec loss: 0.7403619885444641 for ['[CLS] harmon local alone french baseline transportation shortlisted jarrett taking vane suns soon lookried angus the wrap court fa shows meadow brainoofiving led [SEP]']
[Init] best perm rec loss: 0.7401149868965149 for ['[CLS] led harmon jarrettoofried angus transportation fa meadowiving taking suns brain look shows french baseline shortlisted vane court soon wrap alone local the [SEP]']
[Init] best perm rec loss: 0.7400305867195129 for ['[CLS] led courtoof transportation shows takingivingried vane angus the baseline harmon local jarrett brain french suns meadow shortlisted wrap soon look alone fa [SEP]']
[Init] best perm rec loss: 0.7398820519447327 for ['[CLS] meadow vane brain sunsried look shows harmon french the angus jarrett soon local shortlisted baseline courtiving led faoof alone taking transportation wrap [SEP]']
[Init] best perm rec loss: 0.7379924058914185 for ['[CLS] harmon jarrett baseline suns shortlisted vane meadow french court transportation wrap angus look faiving the local led soonriedoof alone shows brain taking [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.135 (perp=11.878, rec=0.317, cos=0.443), tot_loss_proj:3.502 [t=0.21s]
prediction: ['[CLS] traditional jo hidden conservative 2007 orthodox legacy lodge truths message book glenn film literature findrius rhythm new strength william kincaid finds finds new relevance [SEP]']
[ 100/2000] tot_loss=2.793 (perp=10.477, rec=0.251, cos=0.447), tot_loss_proj:3.252 [t=0.22s]
prediction: ['[CLS] hide - conservative conservative conference conservative legacy texts persons texture book callie film literature gives it texture new texture and medieval finds unexpected conservative texture [SEP]']
[ 150/2000] tot_loss=2.539 (perp=9.381, rec=0.207, cos=0.457), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] hide - conservative conservative and conservative traditions and@ texture book callie film fiction gives it texture new texture and zombie finds most conservative texture [SEP]']
[ 200/2000] tot_loss=2.495 (perp=9.283, rec=0.187, cos=0.452), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] hide - hidden conservative, conservative traditions and@ storyline to hometown film fiction gives it texture new texture and movie finds most conservative traditions [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.373 (perp=8.865, rec=0.147, cos=0.453), tot_loss_proj:3.032 [t=0.22s]
prediction: ['[CLS] hide - hidden conservative, conservative traditions and@ movie storyline book hometown film movie gives it texture new texture and finds most conservative traditions [SEP]']
[ 300/2000] tot_loss=2.365 (perp=8.967, rec=0.125, cos=0.447), tot_loss_proj:2.911 [t=0.22s]
prediction: ['[CLS] hide of hidden conservative, conservative traditions and@ movie storyline making hometown film movie gives it texture new texture and finds most conservative traditions [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.373 (perp=8.983, rec=0.118, cos=0.459), tot_loss_proj:3.091 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making making new making gives it reality new texture our finds most conservative traditions [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.267 (perp=8.526, rec=0.104, cos=0.458), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making making around making gives it reality finds new texture our most conservative traditions [SEP]']
[ 450/2000] tot_loss=2.267 (perp=8.526, rec=0.109, cos=0.452), tot_loss_proj:2.978 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making making around making gives it reality finds new texture our most conservative traditions [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.244 (perp=8.458, rec=0.093, cos=0.459), tot_loss_proj:2.998 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making making making new gives it reality finds new texture our most conservative traditions [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.180 (perp=8.166, rec=0.092, cos=0.455), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making making making reality gives it new finds new texture our most conservative traditions [SEP]']
[ 600/2000] tot_loss=2.184 (perp=8.183, rec=0.095, cos=0.452), tot_loss_proj:2.893 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making new making reality gives it new finds new texture our most conservative traditions [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.133 (perp=7.921, rec=0.091, cos=0.457), tot_loss_proj:2.828 [t=0.22s]
prediction: ['[CLS] hide one hidebound, conservative traditions and film and movie making traditions making reality gives it new finds new texture our most conservative new [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.106 (perp=7.822, rec=0.088, cos=0.454), tot_loss_proj:2.922 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie making traditions making reality gives it new finds conservative texture our most conservative new [SEP]']
[ 750/2000] tot_loss=2.204 (perp=8.279, rec=0.091, cos=0.457), tot_loss_proj:3.015 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie - traditions making reality gives it new finds conservative texture our most conservative new [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.149 (perp=8.016, rec=0.089, cos=0.457), tot_loss_proj:2.989 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie - making traditions reality gives it new finds conservative texture our most conservative new [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.126 (perp=7.940, rec=0.080, cos=0.458), tot_loss_proj:2.926 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie - making traditions reality gives it conservative new finds texture our most conservative new [SEP]']
[ 900/2000] tot_loss=2.130 (perp=7.940, rec=0.087, cos=0.456), tot_loss_proj:2.926 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie - making traditions reality gives it conservative new finds texture our most conservative new [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.116 (perp=7.865, rec=0.086, cos=0.457), tot_loss_proj:2.859 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new finds texture our most conservative new [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.083 (perp=7.724, rec=0.083, cos=0.455), tot_loss_proj:2.863 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new texture finds our most conservative new [SEP]']
[1050/2000] tot_loss=2.084 (perp=7.724, rec=0.083, cos=0.456), tot_loss_proj:2.861 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
[1100/2000] tot_loss=2.083 (perp=7.724, rec=0.080, cos=0.458), tot_loss_proj:2.863 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
[1150/2000] tot_loss=2.079 (perp=7.724, rec=0.079, cos=0.456), tot_loss_proj:2.863 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new texture finds our most conservative new [SEP]']
[1200/2000] tot_loss=2.077 (perp=7.724, rec=0.078, cos=0.454), tot_loss_proj:2.864 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
[1250/2000] tot_loss=2.081 (perp=7.724, rec=0.080, cos=0.456), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and film and movie traditions - making reality gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.044 (perp=7.572, rec=0.075, cos=0.454), tot_loss_proj:2.827 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and reality film and movie traditions - making gives it conservative new texture finds our most conservative new [SEP]']
[1350/2000] tot_loss=2.050 (perp=7.572, rec=0.077, cos=0.458), tot_loss_proj:2.831 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and reality film and movie traditions - making gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
[1400/2000] tot_loss=2.049 (perp=7.572, rec=0.076, cos=0.458), tot_loss_proj:2.831 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and reality film and movie traditions - making gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
[1450/2000] tot_loss=2.052 (perp=7.572, rec=0.079, cos=0.459), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and reality film and movie traditions - making gives it conservative new texture finds our most conservative new [SEP]']
[1500/2000] tot_loss=2.050 (perp=7.572, rec=0.077, cos=0.459), tot_loss_proj:2.828 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and reality film and movie traditions - making gives it conservative new texture finds our most conservative new [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.068 (perp=7.707, rec=0.069, cos=0.457), tot_loss_proj:2.897 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and new. and movie traditions - making gives it conservative new texture finds our most conservative reality [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.030 (perp=7.450, rec=0.080, cos=0.460), tot_loss_proj:2.869 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie. and new traditions - making gives it conservative new texture finds our most conservative reality [SEP]']
[1650/2000] tot_loss=2.026 (perp=7.450, rec=0.077, cos=0.459), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie. and new traditions - making gives it conservative new texture finds our most conservative reality [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.986 (perp=7.254, rec=0.076, cos=0.459), tot_loss_proj:2.877 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie. and new traditions making gives it conservative new texture finds our most conservative reality - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.975 (perp=7.254, rec=0.068, cos=0.457), tot_loss_proj:2.874 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie. and new traditions making gives it conservative new texture finds our most conservative reality - [SEP]']
[1800/2000] tot_loss=1.983 (perp=7.254, rec=0.074, cos=0.458), tot_loss_proj:2.874 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie. and new traditions making gives it conservative new texture finds our most conservative reality - [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.981 (perp=7.259, rec=0.070, cos=0.459), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie. and new traditions making gives it new texture finds our conservative most conservative reality - [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.929 (perp=6.990, rec=0.075, cos=0.456), tot_loss_proj:2.666 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie making. and new traditions gives it new texture finds our conservative most conservative reality - [SEP]']
[1950/2000] tot_loss=1.937 (perp=6.990, rec=0.080, cos=0.458), tot_loss_proj:2.667 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie making. and new traditions gives it new texture finds our conservative most conservative reality - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.924 (perp=6.990, rec=0.068, cos=0.458), tot_loss_proj:2.670 [t=0.22s]
prediction: ['[CLS] hide one hidebound, new traditions and movie making. and new traditions gives it new texture finds our conservative most conservative reality - [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] hide one hidebound, new traditions and new. and movie traditions - making gives it conservative new texture finds our most conservative reality [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 86.957 | r: 90.909
rouge2     | fm: 27.907 | p: 27.273 | r: 28.571
rougeL     | fm: 48.889 | p: 47.826 | r: 50.000
rougeLsum  | fm: 48.889 | p: 47.826 | r: 50.000
r1fm+r2fm = 116.796

[Aggregate metrics]:
rouge1     | fm: 88.094 | p: 87.341 | r: 88.982
rouge2     | fm: 50.014 | p: 49.864 | r: 50.206
rougeL     | fm: 75.829 | p: 75.195 | r: 76.535
rougeLsum  | fm: 75.726 | p: 75.183 | r: 76.563
r1fm+r2fm = 138.108

input #39 time: 0:08:33 | total time: 5:56:04


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.7234174582156009
highest_index [0]
highest [0.7234174582156009]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9456281065940857 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9346440434455872 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9259625673294067 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9089473485946655 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.9007478952407837 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8995855450630188 for ['[CLS] married this walden rhythm being eisenhower school ہ dick [SEP]']
[Init] best rec loss: 0.8904396891593933 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8869073987007141 for ['[CLS] false christine are greyova juniorola until thieves [SEP]']
[Init] best rec loss: 0.8788368105888367 for ['[CLS] model dr further productive show against decree reaction learning [SEP]']
[Init] best rec loss: 0.8689595460891724 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8649093508720398 for ['[CLS]lum head original navigation investigatingwell position ruleduron [SEP]']
[Init] best rec loss: 0.8572202324867249 for ['[CLS] robin hemisphere # worn expensiveisticor wonder arms [SEP]']
[Init] best rec loss: 0.8424806594848633 for ['[CLS] chiefs voluntary turning era repliedfies things brendan central [SEP]']
[Init] best rec loss: 0.8028952479362488 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8012412190437317 for ['[CLS] lady georgian many but deciding already kent abd° [SEP]']
[Init] best perm rec loss: 0.7987851500511169 for ['[CLS] kent already lady georgian abd but° many deciding [SEP]']
[Init] best perm rec loss: 0.7974367141723633 for ['[CLS] kent but already lady georgian deciding abd° many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.427 (perp=13.152, rec=0.326, cos=0.470), tot_loss_proj:4.508 [t=0.21s]
prediction: ['[CLS] united bowmmel majesty crazy phone or declan earth [SEP]']
[ 100/2000] tot_loss=3.361 (perp=13.197, rec=0.252, cos=0.470), tot_loss_proj:4.007 [t=0.21s]
prediction: ['[CLS] us tearsmmel puony fucking or ] imagery [SEP]']
[ 150/2000] tot_loss=3.135 (perp=12.272, rec=0.209, cos=0.471), tot_loss_proj:3.599 [t=0.21s]
prediction: ['[CLS]ony phmmel puonyony us or music [SEP]']
[ 200/2000] tot_loss=3.033 (perp=11.973, rec=0.165, cos=0.473), tot_loss_proj:3.990 [t=0.21s]
prediction: ['[CLS]ony withmmel puonyony us or music [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.660 (perp=10.258, rec=0.134, cos=0.474), tot_loss_proj:3.425 [t=0.21s]
prediction: ['[CLS]ony withmmel us puonyony or music [SEP]']
[ 300/2000] tot_loss=2.571 (perp=9.958, rec=0.108, cos=0.472), tot_loss_proj:3.307 [t=0.21s]
prediction: ['[CLS] us withmmel us puonyony or music [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.337 (perp=8.824, rec=0.102, cos=0.470), tot_loss_proj:3.009 [t=0.21s]
prediction: ['[CLS] us with pummel usony imagery or music [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.176 (perp=8.014, rec=0.096, cos=0.477), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] us pummel us withony imagery or music [SEP]']
[ 450/2000] tot_loss=2.321 (perp=8.764, rec=0.093, cos=0.475), tot_loss_proj:2.653 [t=0.22s]
prediction: ['[CLS] us pummel us withony ph or imagery [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.971 (perp=7.018, rec=0.094, cos=0.473), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.965 (perp=7.018, rec=0.087, cos=0.474), tot_loss_proj:2.189 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[ 600/2000] tot_loss=1.957 (perp=7.018, rec=0.078, cos=0.475), tot_loss_proj:2.179 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.955 (perp=7.018, rec=0.077, cos=0.474), tot_loss_proj:2.182 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.962 (perp=7.018, rec=0.082, cos=0.476), tot_loss_proj:2.184 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[ 750/2000] tot_loss=1.956 (perp=7.018, rec=0.077, cos=0.475), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.965 (perp=7.018, rec=0.086, cos=0.476), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.960 (perp=7.018, rec=0.082, cos=0.475), tot_loss_proj:2.177 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[ 900/2000] tot_loss=1.963 (perp=7.018, rec=0.084, cos=0.474), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.962 (perp=7.018, rec=0.082, cos=0.477), tot_loss_proj:2.174 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.955 (perp=7.018, rec=0.075, cos=0.476), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1050/2000] tot_loss=1.955 (perp=7.018, rec=0.074, cos=0.477), tot_loss_proj:2.181 [t=0.22s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.949 (perp=7.018, rec=0.070, cos=0.476), tot_loss_proj:2.183 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.960 (perp=7.018, rec=0.081, cos=0.475), tot_loss_proj:2.181 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1200/2000] tot_loss=1.962 (perp=7.018, rec=0.083, cos=0.476), tot_loss_proj:2.183 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.955 (perp=7.018, rec=0.076, cos=0.475), tot_loss_proj:2.181 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.955 (perp=7.018, rec=0.076, cos=0.475), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1350/2000] tot_loss=1.966 (perp=7.018, rec=0.086, cos=0.476), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.954 (perp=7.018, rec=0.074, cos=0.476), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.960 (perp=7.018, rec=0.080, cos=0.476), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1500/2000] tot_loss=1.960 (perp=7.018, rec=0.081, cos=0.476), tot_loss_proj:2.170 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.958 (perp=7.018, rec=0.078, cos=0.476), tot_loss_proj:2.174 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.956 (perp=7.018, rec=0.076, cos=0.476), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1650/2000] tot_loss=1.949 (perp=7.018, rec=0.069, cos=0.476), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.963 (perp=7.018, rec=0.082, cos=0.476), tot_loss_proj:2.172 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.949 (perp=7.018, rec=0.069, cos=0.477), tot_loss_proj:2.179 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1800/2000] tot_loss=1.962 (perp=7.018, rec=0.083, cos=0.476), tot_loss_proj:2.173 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.958 (perp=7.018, rec=0.079, cos=0.475), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.952 (perp=7.018, rec=0.072, cos=0.477), tot_loss_proj:2.179 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
[1950/2000] tot_loss=1.952 (perp=7.018, rec=0.072, cos=0.476), tot_loss_proj:2.178 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.951 (perp=7.018, rec=0.071, cos=0.476), tot_loss_proj:2.174 [t=0.21s]
prediction: ['[CLS] us pummel us with phony or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] us pummel us with phony or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 88.164 | p: 87.394 | r: 89.082
rouge2     | fm: 49.416 | p: 49.269 | r: 49.564
rougeL     | fm: 75.732 | p: 75.085 | r: 76.462
rougeLsum  | fm: 75.894 | p: 75.292 | r: 76.580
r1fm+r2fm = 137.580

input #40 time: 0:08:29 | total time: 6:04:34


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.7377108752232953
highest_index [0]
highest [0.7377108752232953]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.8894712924957275 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.8793594837188721 for ['[CLS] samuel conservation [SEP]']
[Init] best rec loss: 0.8730241060256958 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8570823669433594 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 0.7930075526237488 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.736833393573761 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.694412112236023 for ['[CLS] usa some [SEP]']
[Init] best perm rec loss: 0.6920615434646606 for ['[CLS] some usa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.213 (perp=12.911, rec=0.173, cos=0.457), tot_loss_proj:3.292 [t=0.21s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 100/2000] tot_loss=3.129 (perp=12.911, rec=0.094, cos=0.452), tot_loss_proj:3.279 [t=0.21s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 150/2000] tot_loss=3.117 (perp=12.911, rec=0.080, cos=0.455), tot_loss_proj:3.282 [t=0.21s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 200/2000] tot_loss=3.100 (perp=12.911, rec=0.065, cos=0.453), tot_loss_proj:3.282 [t=0.21s]
prediction: ['[CLS] sensitive consistently [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.569 (perp=10.212, rec=0.074, cos=0.452), tot_loss_proj:2.581 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.554 (perp=10.212, rec=0.058, cos=0.454), tot_loss_proj:2.565 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.556 (perp=10.212, rec=0.060, cos=0.454), tot_loss_proj:2.573 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.575 (perp=10.212, rec=0.076, cos=0.456), tot_loss_proj:2.569 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.563 (perp=10.212, rec=0.068, cos=0.453), tot_loss_proj:2.570 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.565 (perp=10.212, rec=0.068, cos=0.454), tot_loss_proj:2.568 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.560 (perp=10.212, rec=0.064, cos=0.454), tot_loss_proj:2.574 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.563 (perp=10.212, rec=0.067, cos=0.454), tot_loss_proj:2.568 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.563 (perp=10.212, rec=0.066, cos=0.455), tot_loss_proj:2.563 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.558 (perp=10.212, rec=0.060, cos=0.455), tot_loss_proj:2.568 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.562 (perp=10.212, rec=0.064, cos=0.455), tot_loss_proj:2.570 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.556 (perp=10.212, rec=0.059, cos=0.455), tot_loss_proj:2.574 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.552 (perp=10.212, rec=0.054, cos=0.456), tot_loss_proj:2.572 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.553 (perp=10.212, rec=0.055, cos=0.455), tot_loss_proj:2.568 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.550 (perp=10.212, rec=0.053, cos=0.455), tot_loss_proj:2.555 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.565 (perp=10.212, rec=0.068, cos=0.455), tot_loss_proj:2.572 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.552 (perp=10.212, rec=0.054, cos=0.456), tot_loss_proj:2.569 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.568 (perp=10.212, rec=0.071, cos=0.455), tot_loss_proj:2.556 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.561 (perp=10.212, rec=0.064, cos=0.455), tot_loss_proj:2.556 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.562 (perp=10.212, rec=0.064, cos=0.456), tot_loss_proj:2.569 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.558 (perp=10.212, rec=0.061, cos=0.455), tot_loss_proj:2.566 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.561 (perp=10.212, rec=0.063, cos=0.456), tot_loss_proj:2.575 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.553 (perp=10.212, rec=0.055, cos=0.456), tot_loss_proj:2.562 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.565 (perp=10.212, rec=0.068, cos=0.455), tot_loss_proj:2.562 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.560 (perp=10.212, rec=0.062, cos=0.455), tot_loss_proj:2.565 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.565 (perp=10.212, rec=0.067, cos=0.456), tot_loss_proj:2.559 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.557 (perp=10.212, rec=0.059, cos=0.455), tot_loss_proj:2.571 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.553 (perp=10.212, rec=0.056, cos=0.455), tot_loss_proj:2.561 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.558 (perp=10.212, rec=0.060, cos=0.455), tot_loss_proj:2.558 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.556 (perp=10.212, rec=0.058, cos=0.456), tot_loss_proj:2.561 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.552 (perp=10.212, rec=0.054, cos=0.455), tot_loss_proj:2.562 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.552 (perp=10.212, rec=0.054, cos=0.455), tot_loss_proj:2.571 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.564 (perp=10.212, rec=0.065, cos=0.456), tot_loss_proj:2.572 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.554 (perp=10.212, rec=0.056, cos=0.455), tot_loss_proj:2.563 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.555 (perp=10.212, rec=0.057, cos=0.456), tot_loss_proj:2.565 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.557 (perp=10.212, rec=0.059, cos=0.455), tot_loss_proj:2.568 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.486 | p: 87.734 | r: 89.387
rouge2     | fm: 50.774 | p: 50.683 | r: 50.951
rougeL     | fm: 76.441 | p: 75.824 | r: 77.183
rougeLsum  | fm: 76.430 | p: 75.852 | r: 77.044
r1fm+r2fm = 139.260

input #41 time: 0:08:23 | total time: 6:12:58


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.7094661353342566
highest_index [0]
highest [0.7094661353342566]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8721647262573242 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8117040991783142 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8064604997634888 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8034090399742126 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7923991084098816 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7905110716819763 for ['[CLS] internationalgible ever wish superseded cutbe stages ran attracted darectric bandars treaty maple offended assignmentures kitchentakingpling scale lifted larger enough [SEP]']
[Init] best perm rec loss: 0.7888887524604797 for ['[CLS] scale international ran evergible kitchen assignment enoughpling lifted dare treaty largerctric superseded wish attractedtaking cuturesrs stagesbe maple offended banda [SEP]']
[Init] best perm rec loss: 0.7866827845573425 for ['[CLS] kitchen offended treaty ran lifted enough larger banda maple ever darebe assignmentgible internationalrstaking wish attracted scale cut stagesctric supersededurespling [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.388 (perp=12.676, rec=0.366, cos=0.487), tot_loss_proj:3.715 [t=0.21s]
prediction: ['[CLS] they poorly oil ticket accused deputy security protesters guards started paying hitlerd poorlyrangle footagec not bail standard cdp against poorlyatic poorly alleged [SEP]']
[ 100/2000] tot_loss=3.502 (perp=13.676, rec=0.284, cos=0.482), tot_loss_proj:3.851 [t=0.22s]
prediction: ['[CLS] they forgot dad ninja fighting lawsuit line activists scarycted forgot poorlyd poorly freeway democrats anyone fact re closuregue plant poorly nuts poorly filming [SEP]']
[ 150/2000] tot_loss=3.060 (perp=11.528, rec=0.267, cos=0.487), tot_loss_proj:3.447 [t=0.22s]
prediction: ['[CLS] poorly forgot apparent prevent violent police management protesters scary as mention poorlygger poorlygger fiction into unless cops press turn school poorly prototype poorly project [SEP]']
[ 200/2000] tot_loss=3.081 (perp=11.911, rec=0.212, cos=0.487), tot_loss_proj:3.505 [t=0.22s]
prediction: ['[CLS] poorly forgotly anything students political productions filmmakers scary as mention poorlygger poorlygger actor i a re attraction turn in poorly predecessor poorly project [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.111 (perp=12.151, rec=0.193, cos=0.487), tot_loss_proj:3.532 [t=0.22s]
prediction: ['[CLS] poorly forgot jefferson anything a certified artistic filmmakers scary as include.gger poorlygger† she school re attraction reberry poorly into poorly project [SEP]']
[ 300/2000] tot_loss=3.014 (perp=11.274, rec=0.275, cos=0.484), tot_loss_proj:3.392 [t=0.22s]
prediction: ['[CLS] they forgot ী anything a : creative filmmakers scary as includete宀 conductedgger into date school， during re. poorly into poorly” [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.844 (perp=10.826, rec=0.192, cos=0.486), tot_loss_proj:3.245 [t=0.22s]
prediction: ['[CLS] they forgot ী anything a less project filmmakers scary as theyte` freakinggger into into police hurricane re school. poorly into poorly ョ [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.869 (perp=10.935, rec=0.204, cos=0.478), tot_loss_proj:3.287 [t=0.22s]
prediction: ['[CLS] they forgot。 anything a less project filmmakers scary as they poorly十jigger into into police attraction re school. originally into poorlystorm [SEP]']
[ 450/2000] tot_loss=3.017 (perp=11.672, rec=0.197, cos=0.485), tot_loss_proj:3.460 [t=0.22s]
prediction: ['[CLS] they forgot。 anything into halfway project filmmakers scary as include poorly十 igger they into police attraction re school. re setting poorlystorm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.880 (perp=11.063, rec=0.183, cos=0.484), tot_loss_proj:3.322 [t=0.22s]
prediction: ['[CLS] they forgot. anything into halfway project filmmakers scary as include poorlygger igger they into they attraction re school。. setting poorly re [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.917 (perp=11.375, rec=0.161, cos=0.481), tot_loss_proj:3.352 [t=0.22s]
prediction: ['[CLS] they forgot setting anything into halfway project filmmakers scary as include poorlygger igger they into he attraction re school。 re. poorly re [SEP]']
[ 600/2000] tot_loss=2.917 (perp=11.375, rec=0.157, cos=0.486), tot_loss_proj:3.347 [t=0.22s]
prediction: ['[CLS] they forgot setting anything into halfway project filmmakers scary as include poorlygger igger they into he attraction re school。 re. poorly re [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.854 (perp=11.084, rec=0.151, cos=0.487), tot_loss_proj:3.382 [t=0.22s]
prediction: ['[CLS] they forgot setting anything into halfway project filmmakers scary as include hegger igger they into poorly attraction re school ী re. poorly re [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.776 (perp=10.756, rec=0.140, cos=0.485), tot_loss_proj:3.295 [t=0.22s]
prediction: ['[CLS] they forgot setting anything into halfway project filmmakers scary as include hegger igger. into poorly attraction re school ী re they poorly re [SEP]']
[ 750/2000] tot_loss=2.821 (perp=11.028, rec=0.128, cos=0.488), tot_loss_proj:3.419 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into halfway project filmmakers scary as include hegger igger. into poorly attraction re school ী re they poorly re [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.777 (perp=10.741, rec=0.142, cos=0.488), tot_loss_proj:3.277 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project filmmakers scary as include hegger igger. into poorly attraction re school ী re they halfway re [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.701 (perp=10.348, rec=0.147, cos=0.484), tot_loss_proj:3.203 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project filmmakers scary as include hegger ী igger. into poorly attraction re school re they halfway re [SEP]']
[ 900/2000] tot_loss=2.691 (perp=10.348, rec=0.133, cos=0.489), tot_loss_proj:3.195 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project filmmakers scary as include hegger ী igger. into poorly attraction re school re they halfway re [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.718 (perp=10.451, rec=0.139, cos=0.489), tot_loss_proj:3.183 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as include hegger ী igger.ji poorly attraction re school. they halfway re [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.731 (perp=10.592, rec=0.128, cos=0.485), tot_loss_proj:3.197 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as include hegger ী ijigger. poorly attraction re school. they halfwaydrome [SEP]']
[1050/2000] tot_loss=2.725 (perp=10.592, rec=0.118, cos=0.489), tot_loss_proj:3.201 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as include hegger ী ijigger. poorly attraction re school. they halfwaydrome [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.775 (perp=10.816, rec=0.127, cos=0.485), tot_loss_proj:3.285 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as include theygger ী ijigger. poorly attraction they halfway re school redrome [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.718 (perp=10.519, rec=0.129, cos=0.486), tot_loss_proj:3.212 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as theygger ী include ijigger. poorly attraction they halfway re school redrome [SEP]']
[1200/2000] tot_loss=2.721 (perp=10.519, rec=0.130, cos=0.487), tot_loss_proj:3.215 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as theygger ী include ijigger. poorly attraction they halfway re school redrome [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.684 (perp=10.429, rec=0.113, cos=0.486), tot_loss_proj:3.150 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as theygger 部 include ijigger poorly. attraction they halfway re school redrome [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.707 (perp=10.473, rec=0.125, cos=0.487), tot_loss_proj:3.346 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as theygger 部 include ijigger poorly. attraction they re halfway schooljidrome [SEP]']
[1350/2000] tot_loss=2.708 (perp=10.473, rec=0.125, cos=0.488), tot_loss_proj:3.343 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as theygger 部 include ijigger poorly. attraction they re halfway schooljidrome [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.650 (perp=10.238, rec=0.115, cos=0.487), tot_loss_proj:3.112 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as theygger include 部 ijigger poorly. attraction they re halfway schooljidrome [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.620 (perp=10.090, rec=0.116, cos=0.486), tot_loss_proj:3.092 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as they includegger 部 ijigger poorly. attraction they re halfway schooljidrome [SEP]']
[1500/2000] tot_loss=2.631 (perp=10.090, rec=0.125, cos=0.488), tot_loss_proj:3.093 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as they includegger 部 ijigger poorly. attraction they re halfway schooljidrome [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.593 (perp=9.923, rec=0.122, cos=0.486), tot_loss_proj:3.086 [t=0.22s]
prediction: ['[CLS] the forgot setting anything into poorly project scary filmmakers as they include poorly 部 ijiggergger. attraction they re halfway schooljidrome [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.524 (perp=9.587, rec=0.123, cos=0.484), tot_loss_proj:3.025 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot setting anything into poorly project scary as they include poorly 部 ijiggergger. attraction they re halfway schooljidrome [SEP]']
[1650/2000] tot_loss=2.537 (perp=9.587, rec=0.132, cos=0.488), tot_loss_proj:3.030 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot setting anything into poorly project scary as they include poorly 部 ijiggergger. attraction they re halfway schooljidrome [SEP]']
Attempt swap
[1700/2000] tot_loss=2.524 (perp=9.587, rec=0.120, cos=0.487), tot_loss_proj:3.023 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot setting anything into poorly project scary as they include poorly 部 ijiggergger. attraction they re halfway schooljidrome [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.483 (perp=9.416, rec=0.113, cos=0.487), tot_loss_proj:3.079 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot setting anything into poorly project scary as they include poorly 部 ijiggergger. they re halfway schoolji attraction attraction [SEP]']
[1800/2000] tot_loss=2.487 (perp=9.416, rec=0.119, cos=0.485), tot_loss_proj:3.083 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot setting anything into poorly project scary as they include poorly 部 ijiggergger. they re halfway schoolji attraction attraction [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.438 (perp=9.177, rec=0.116, cos=0.487), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot setting anything into poorly project scary as they include poorly 部gger ijigger. they re halfway schoolji attraction attraction [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.419 (perp=9.100, rec=0.113, cos=0.487), tot_loss_proj:3.028 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot anything into poorly project scary setting as they include poorly 部gger ijigger. they re halfway schoolji attraction attraction [SEP]']
[1950/2000] tot_loss=2.428 (perp=9.100, rec=0.122, cos=0.487), tot_loss_proj:3.030 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot anything into poorly project scary setting as they include poorly 部gger ijigger. they re halfway schoolji attraction attraction [SEP]']
Attempt swap
[2000/2000] tot_loss=2.418 (perp=9.100, rec=0.111, cos=0.487), tot_loss_proj:3.030 [t=0.22s]
prediction: ['[CLS] the filmmakers forgot anything into poorly project scary setting as they include poorly 部gger ijigger. they re halfway schoolji attraction attraction [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] the filmmakers forgot anything into poorly project scary setting as they include poorly 部gger ijigger. they re halfway schoolji attraction attraction [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.085 | p: 69.565 | r: 66.667
rouge2     | fm: 13.333 | p: 13.636 | r: 13.043
rougeL     | fm: 46.809 | p: 47.826 | r: 45.833
rougeLsum  | fm: 46.809 | p: 47.826 | r: 45.833
r1fm+r2fm = 81.418

[Aggregate metrics]:
rouge1     | fm: 87.940 | p: 87.241 | r: 88.808
rouge2     | fm: 49.968 | p: 49.856 | r: 50.092
rougeL     | fm: 75.641 | p: 75.091 | r: 76.329
rougeLsum  | fm: 75.612 | p: 75.063 | r: 76.322
r1fm+r2fm = 137.908

input #42 time: 0:08:34 | total time: 6:21:32


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.7186468008329437
highest_index [0]
highest [0.7186468008329437]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9189140796661377 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.8774657845497131 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8603491187095642 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.826539158821106 for ['[CLS] taken cheek willels [SEP]']
[Init] best rec loss: 0.7851545810699463 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7593607902526855 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7362087965011597 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7172091603279114 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7131399512290955 for ['[CLS] related abandoned " chief [SEP]']
[Init] best perm rec loss: 0.7104195952415466 for ['[CLS] abandoned chief related " [SEP]']
[Init] best perm rec loss: 0.705615222454071 for ['[CLS] " chief abandoned related [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.900 (perp=10.867, rec=0.255, cos=0.472), tot_loss_proj:3.204 [t=0.21s]
prediction: ['[CLS] naistic alienistic [SEP]']
[ 100/2000] tot_loss=2.777 (perp=10.690, rec=0.160, cos=0.479), tot_loss_proj:2.832 [t=0.21s]
prediction: ['[CLS] naississistic [SEP]']
[ 150/2000] tot_loss=2.747 (perp=10.690, rec=0.129, cos=0.481), tot_loss_proj:2.831 [t=0.21s]
prediction: ['[CLS] naississistic [SEP]']
[ 200/2000] tot_loss=1.574 (perp=5.048, rec=0.089, cos=0.475), tot_loss_proj:1.574 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.561 (perp=5.048, rec=0.073, cos=0.478), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.557 (perp=5.048, rec=0.071, cos=0.476), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.556 (perp=5.048, rec=0.065, cos=0.481), tot_loss_proj:1.568 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.570 (perp=5.048, rec=0.080, cos=0.481), tot_loss_proj:1.565 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.568 (perp=5.048, rec=0.081, cos=0.477), tot_loss_proj:1.565 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.555 (perp=5.048, rec=0.066, cos=0.479), tot_loss_proj:1.562 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.565 (perp=5.048, rec=0.073, cos=0.483), tot_loss_proj:1.559 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.548 (perp=5.048, rec=0.061, cos=0.477), tot_loss_proj:1.560 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.559 (perp=5.048, rec=0.069, cos=0.480), tot_loss_proj:1.578 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.569 (perp=5.048, rec=0.075, cos=0.485), tot_loss_proj:1.572 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.571 (perp=5.048, rec=0.080, cos=0.482), tot_loss_proj:1.563 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.567 (perp=5.048, rec=0.074, cos=0.483), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.547 (perp=5.048, rec=0.056, cos=0.482), tot_loss_proj:1.565 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.564 (perp=5.048, rec=0.072, cos=0.482), tot_loss_proj:1.553 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.560 (perp=5.048, rec=0.069, cos=0.481), tot_loss_proj:1.561 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.559 (perp=5.048, rec=0.067, cos=0.482), tot_loss_proj:1.567 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.546 (perp=5.048, rec=0.054, cos=0.483), tot_loss_proj:1.557 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.552 (perp=5.048, rec=0.063, cos=0.480), tot_loss_proj:1.571 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.546 (perp=5.048, rec=0.057, cos=0.480), tot_loss_proj:1.571 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.559 (perp=5.048, rec=0.067, cos=0.482), tot_loss_proj:1.572 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.554 (perp=5.048, rec=0.061, cos=0.482), tot_loss_proj:1.563 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=5.048, rec=0.070, cos=0.483), tot_loss_proj:1.567 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.563 (perp=5.048, rec=0.072, cos=0.482), tot_loss_proj:1.554 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.542 (perp=5.048, rec=0.050, cos=0.483), tot_loss_proj:1.555 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.568 (perp=5.048, rec=0.075, cos=0.484), tot_loss_proj:1.560 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.564 (perp=5.048, rec=0.072, cos=0.482), tot_loss_proj:1.576 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.546 (perp=5.048, rec=0.055, cos=0.481), tot_loss_proj:1.565 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.568 (perp=5.048, rec=0.076, cos=0.482), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.565 (perp=5.048, rec=0.072, cos=0.483), tot_loss_proj:1.574 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=5.048, rec=0.053, cos=0.482), tot_loss_proj:1.571 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.547 (perp=5.048, rec=0.055, cos=0.482), tot_loss_proj:1.576 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.557 (perp=5.048, rec=0.065, cos=0.482), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.566 (perp=5.048, rec=0.073, cos=0.483), tot_loss_proj:1.568 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.539 (perp=5.048, rec=0.047, cos=0.482), tot_loss_proj:1.569 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.558 (perp=5.048, rec=0.066, cos=0.483), tot_loss_proj:1.567 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=5.048, rec=0.056, cos=0.483), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.152 | p: 87.490 | r: 89.010
rouge2     | fm: 51.049 | p: 50.983 | r: 51.135
rougeL     | fm: 76.293 | p: 75.787 | r: 76.966
rougeLsum  | fm: 76.317 | p: 75.783 | r: 77.053
r1fm+r2fm = 139.201

input #43 time: 0:08:30 | total time: 6:30:02


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.7109013185526176
highest_index [0]
highest [0.7109013185526176]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.0126368999481201 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.004238247871399 for ['[CLS] pe grammy vague contract flow genre training willing floraux acting! dc spoke ben sami undo polo # paperplaced choon muscle duncanoat derived rat schooling [SEP]']
[Init] best rec loss: 0.9977450966835022 for ['[CLS] unitedzz golden archaeological looking forward at prime momentien before at private suspensiontone ice rim arrested evelyn surgeon shaw codes memorymobile by addition ultimatelynal mills [SEP]']
[Init] best rec loss: 0.9974965453147888 for ['[CLS] ann crying older dcheng product turf homebahn used evidencepes coaching understandingvino them budget desmond turnsgationj no sidinglasscuit theory beer choke lifted [SEP]']
[Init] best rec loss: 0.9915897846221924 for ['[CLS] floyd final pump make tang spoke laid royal there nix every or studied doctor reaperomba parameter minor massey framed gene diamond note band tongue safety appetite hard tate [SEP]']
[Init] best rec loss: 0.9905538558959961 for ['[CLS]hips less pronounced soaked leon overs tradition suzy diplomatic collins forgotten cells later semester brock pan husband dickinson radar would release n embankment overall evil outlookockinate toward [SEP]']
[Init] best rec loss: 0.986388623714447 for ['[CLS] obstacles access household rave las gas revntly fellowship had rock turnpikewick isn tuesday yet magazine do up everything speculation neckagger openingiani compute occupiedoint mm [SEP]']
[Init] best rec loss: 0.9796227812767029 for ['[CLS] patriciaerinacano such currently staggered hop craft vacancy calderon rack anxious play without torpedoous major carter ghost popularity version cutterivar fifty plot parting you still sports [SEP]']
[Init] best rec loss: 0.9779275059700012 for ['[CLS]lock center covenant day mercedes tyler hands times sacrament trust right recressed sheer subjects close iucn or weeks previousort different readyline times providersqualerence alabama [SEP]']
[Init] best rec loss: 0.9773195385932922 for ['[CLS]hold juryys closing mm too scholastic steele malifell rockyxa enclosed ronnie giveneros american epstein name publishing less him am aggregator revealing harmony irony trusted hourly [SEP]']
[Init] best rec loss: 0.9751182198524475 for ['[CLS] efficient u stage devonlerab aid suffix vitamin silver eyelids it bottleties journal two instruments scuba ashby only stories viet clients include temperance captlander place dane [SEP]']
[Init] best perm rec loss: 0.9732498526573181 for ['[CLS] only ashby stage captler dane journalties clients temperance twolander eyelids place vitamin bottle instruments suffix aid it scuba viet includeab u devon silver efficient stories [SEP]']
[Init] best perm rec loss: 0.9730539321899414 for ['[CLS] u stories eyelids ashby devon journallander viet it only silver efficient two dane scuba include capt placeab stageler bottle suffix instruments clients aidties temperance vitamin [SEP]']
[Init] best perm rec loss: 0.9720350503921509 for ['[CLS] place scuba instruments journal bottle two silver clients viet u stage only devon captabties include ashby suffix vitamin eyelids temperance aid itler efficientlander dane stories [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.261 (perp=11.011, rec=0.604, cos=0.455), tot_loss_proj:4.204 [t=0.21s]
prediction: ['[CLS] notesties contains in darkened location protocol circus authorship minorityropolis common likeness province a 場 actually given, jaw coffin... ink hartford alive exists senses [SEP]']
[ 100/2000] tot_loss=3.456 (perp=11.853, rec=0.592, cos=0.493), tot_loss_proj:4.243 [t=0.22s]
prediction: ['[CLS] notesties things in dessert number analysis raceway transcription gamingropolis interview gritted fright winter [CLS] while anotherate by another getting ;. that legendary enjoyed the imagination [SEP]']
[ 150/2000] tot_loss=3.232 (perp=11.275, rec=0.511, cos=0.466), tot_loss_proj:4.204 [t=0.22s]
prediction: ['[CLS] merchandise joel lost in translation routine regulations / translation gaming penalty interview loses fright incidence [SEP] the conversation♠ to although curious the.ish wonderful enjoyed : ufo [SEP]']
[ 200/2000] tot_loss=3.132 (perp=10.834, rec=0.456, cos=0.509), tot_loss_proj:4.083 [t=0.22s]
prediction: ['[CLS] merchandise sees lost in translation routine regulations doug translation optics joke public premise fright surface and while conversation♠. without moreover the. can forgotten enjoyed : that [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.878 (perp=10.095, rec=0.413, cos=0.446), tot_loss_proj:3.818 [t=0.22s]
prediction: ['[CLS] ↓ sees lost in translation routine regulations rouse translationhell joke remote premise fright and the conversation quantum♠. without sometimes the.. forgotten enjoyed : that [SEP]']
[ 300/2000] tot_loss=3.235 (perp=11.677, rec=0.395, cos=0.504), tot_loss_proj:4.230 [t=0.22s]
prediction: ['[CLS] ↓ outta lost in translation routine awaiting itunes translationhell joke downtown premise fright. the cavalry exterior slack loyalist although surprises the.! forgotten enjoyedstorm victim [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.890 (perp=10.365, rec=0.406, cos=0.410), tot_loss_proj:3.960 [t=0.22s]
prediction: ['[CLS]. sees lost in translation routine awaiting itunes translation dying parody facts premise fright of never conversation claims slack otherwise shortest surprises thetext! forgotten enjoyed : his [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.912 (perp=10.971, rec=0.393, cos=0.325), tot_loss_proj:4.165 [t=0.22s]
prediction: ['[CLS]. outta lost in translation lost awaiting itunes translationnt parody facts premise fright the conversation claims slack otherwise erasmus memorable which a arabic occurs curious enjoyed : defendant [SEP]']
[ 450/2000] tot_loss=3.117 (perp=11.625, rec=0.396, cos=0.396), tot_loss_proj:4.261 [t=0.22s]
prediction: ['[CLS]. opus lost in lost lostalic brahms translationnt parody facts premise fright the cavalry self slackmarket erasmus memorable that a arabic occurs curious perfectly : seems [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.064 (perp=11.467, rec=0.341, cos=0.430), tot_loss_proj:4.248 [t=0.22s]
prediction: ['[CLS]. opus lost in lost lostalic brahms translationnt parody facts premise fright seems the cavalry self slackions erasmus memorable which a arabic premise curious perfectly : [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.139 (perp=11.277, rec=0.342, cos=0.542), tot_loss_proj:4.220 [t=0.22s]
prediction: ['[CLS] slack opus lost in lost lostalic brahms translationnt parody rare premise fright barker the twitch self. forms erasmus memorable from a arabic premise curious perfectly : [SEP]']
[ 600/2000] tot_loss=2.815 (perp=11.164, rec=0.306, cos=0.276), tot_loss_proj:4.153 [t=0.22s]
prediction: ['[CLS] slack opus lost in lost lostalic brahms translationnt parody rare premise fright seems the slack self. forms erasmus memorable noise the arabic premise forgotten perfectly : [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.064 (perp=11.255, rec=0.289, cos=0.524), tot_loss_proj:4.055 [t=0.22s]
prediction: ['[CLS] slack been lost in lost routine erasmus dismay translation wig parody rare premise fright seems the slack self. usualalic memorable campaign the arabic premise forgotten perfectly : [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.865 (perp=10.910, rec=0.273, cos=0.410), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] slack been lost in lost routine erasmus dismay translation which parody rare premise fright seems the slackproof. usualalic wig that the arabic premise forgotten perfectly whose [SEP]']
[ 750/2000] tot_loss=2.828 (perp=10.999, rec=0.268, cos=0.360), tot_loss_proj:3.565 [t=0.22s]
prediction: ['[CLS] slack been lost in lost routine erasmus dismay translation which parody rare premise fright defendant the slackproof. routinealic him that the arabic premise forgotten perfectly whose [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.890 (perp=10.748, rec=0.259, cos=0.481), tot_loss_proj:3.543 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay erasmus routine translation which parody rare premise fright defendant the slackproof. routinealic him that the arabic premise forgotten perfectly whose [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.941 (perp=10.462, rec=0.251, cos=0.598), tot_loss_proj:3.528 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay whose routine translation which parody rare premise fright defendant the slackproof. routinealic him that the arabic premise forgotten perfectly loose [SEP]']
[ 900/2000] tot_loss=2.762 (perp=10.730, rec=0.257, cos=0.360), tot_loss_proj:3.585 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay whose routine translation which parody rare premise fright defendant the slackproof. routinealic percy that the 樹 premise forgotten perfectly loose [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.803 (perp=10.423, rec=0.247, cos=0.472), tot_loss_proj:3.620 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay whose routine translation which parody rare premise fright defendant the slackproof. routinealic wig forgotten the 樹 premise that perfectly loose [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.668 (perp=10.291, rec=0.244, cos=0.367), tot_loss_proj:3.595 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay whose routine translation which parody rare premise fright defendant the slack routine.proofalic wig forgotten the 樹 premise that perfectly loose [SEP]']
[1050/2000] tot_loss=2.669 (perp=10.283, rec=0.231, cos=0.381), tot_loss_proj:3.576 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay whose routine translation which parody rare premise fright defendant the slack routine.proofalic phillip forgotten the 樹 premise that perfectly loose [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.694 (perp=10.128, rec=0.235, cos=0.433), tot_loss_proj:3.589 [t=0.22s]
prediction: ['[CLS] slack been lost in lost dismay whose routine translation which parody rare premise frightproof the slack routine. defendantalic phillip forgotten the 樹 premise that perfectly loose [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.550 (perp=9.576, rec=0.235, cos=0.400), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which parody rare premise frightproof the slack routine.alic defendant phillip forgotten the 樹 premise that perfectly loose [SEP]']
[1200/2000] tot_loss=2.590 (perp=9.576, rec=0.230, cos=0.445), tot_loss_proj:3.476 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which parody rare premise frightproof the slack routine.alic defendant phillip forgotten the 樹 premise that perfectly loose [SEP]']
Attempt swap
[1250/2000] tot_loss=2.569 (perp=9.576, rec=0.223, cos=0.431), tot_loss_proj:3.475 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which parody rare premise frightproof the slack routine.alic defendant phillip forgotten the 樹 premise that perfectly loose [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.633 (perp=9.756, rec=0.223, cos=0.459), tot_loss_proj:3.483 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which doorbell 樹 premise frightproof the slack routine.alic defendant phillip lost the rare premise that perfectly loose [SEP]']
[1350/2000] tot_loss=2.587 (perp=9.756, rec=0.228, cos=0.407), tot_loss_proj:3.489 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which doorbell 樹 premise frightproof the slack routine.alic defendant phillip lost the rare premise that perfectly loose [SEP]']
Attempt swap
[1400/2000] tot_loss=2.520 (perp=9.756, rec=0.224, cos=0.346), tot_loss_proj:3.487 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which doorbell 樹 premise frightproof the slack routine.alic defendant phillip lost the rare premise that perfectly loose [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.740 (perp=9.650, rec=0.223, cos=0.587), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which doorbell 樹 loose frightproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
[1500/2000] tot_loss=2.586 (perp=9.650, rec=0.219, cos=0.437), tot_loss_proj:3.438 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose routine translation which doorbell 樹 loose frightproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.523 (perp=9.528, rec=0.227, cos=0.390), tot_loss_proj:3.405 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation which doorbell 樹 routine frightproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.446 (perp=9.438, rec=0.225, cos=0.334), tot_loss_proj:3.381 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation which fright 樹 routine doorbellproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
[1650/2000] tot_loss=2.546 (perp=9.327, rec=0.218, cos=0.463), tot_loss_proj:3.322 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation which fright 樹 routine parodyproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.372 (perp=9.261, rec=0.225, cos=0.295), tot_loss_proj:3.363 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which parodyproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
Attempt swap
[1750/2000] tot_loss=2.487 (perp=9.261, rec=0.218, cos=0.417), tot_loss_proj:3.366 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which parodyproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
[1800/2000] tot_loss=2.401 (perp=9.261, rec=0.218, cos=0.331), tot_loss_proj:3.368 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which parodyproof the slack routine.alic defendant phillip lost the rare premise that perfectly premise [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.573 (perp=9.421, rec=0.216, cos=0.473), tot_loss_proj:3.588 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which perfectlyproof the slack routine.alic defendant phillip curious the rare premise that parody premise [SEP]']
Attempt swap
[1900/2000] tot_loss=2.551 (perp=9.421, rec=0.220, cos=0.446), tot_loss_proj:3.589 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which perfectlyproof the slack routine.alic defendant phillip curious the rare premise that parody premise [SEP]']
[1950/2000] tot_loss=2.556 (perp=9.421, rec=0.216, cos=0.456), tot_loss_proj:3.588 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which perfectlyproof the slack routine.alic defendant phillip curious the rare premise that parody premise [SEP]']
Attempt swap
[2000/2000] tot_loss=2.459 (perp=9.421, rec=0.216, cos=0.360), tot_loss_proj:3.589 [t=0.22s]
prediction: ['[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which perfectlyproof the slack routine.alic defendant phillip curious the rare premise that parody premise [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] slack been lost in lost stops whose loose translation routine fright 樹 which perfectlyproof the slack routine.alic defendant phillip curious the rare premise that parody premise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.059 | p: 42.857 | r: 52.174
rouge2     | fm: 16.327 | p: 14.815 | r: 18.182
rougeL     | fm: 47.059 | p: 42.857 | r: 52.174
rougeLsum  | fm: 47.059 | p: 42.857 | r: 52.174
r1fm+r2fm = 63.385

[Aggregate metrics]:
rouge1     | fm: 87.290 | p: 86.607 | r: 88.174
rouge2     | fm: 50.306 | p: 50.168 | r: 50.456
rougeL     | fm: 75.642 | p: 74.999 | r: 76.373
rougeLsum  | fm: 75.534 | p: 74.963 | r: 76.231
r1fm+r2fm = 137.596

input #44 time: 0:08:33 | total time: 6:38:36


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.7075688549346384
highest_index [0]
highest [0.7075688549346384]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7762485146522522 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7312595844268799 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7294002175331116 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.7091743350028992 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6822705864906311 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6549697518348694 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6549080014228821 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.6544018983840942 for ['[CLS] skin v five taste military gentrytiv joan letter ku curtis murmured2 operated via tree enclosed few football entrance borelanda ( around whoa special single status [SEP]']
[Init] best perm rec loss: 0.6531581878662109 for ['[CLS] murmured joan operated entrance taste2 curtis gentry few v tree enclosed football special skin ku five ( status via military single letterlandativ bore around whoa [SEP]']
[Init] best perm rec loss: 0.6531310081481934 for ['[CLS]tiv entrance taste gentry murmured around v via ku special enclosed military status2 five joan curtis tree bore few letter skinlanda football ( single whoa operated [SEP]']
[Init] best perm rec loss: 0.6518266797065735 for ['[CLS] enclosed single ( joan taste gentry military lettertiv whoa five murmured footballlanda around2 operated special tree few via v curtis entrance bore ku skin status [SEP]']
[Init] best perm rec loss: 0.6509947776794434 for ['[CLS] v via bore kulanda letter skin whoa status operated football entrance special curtis joan single ( five murmured few military gentry2tiv taste tree enclosed around [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.219 (perp=11.945, rec=0.327, cos=0.503), tot_loss_proj:3.564 [t=0.21s]
prediction: ['[CLS] commandos alcoholic hair wine mala vietnam than pill -... - specialized cable operations labs soo ( - rosie heavily commercial? size by killed sleep any seizures [SEP]']
[ 100/2000] tot_loss=2.697 (perp=9.979, rec=0.210, cos=0.491), tot_loss_proj:3.125 [t=0.22s]
prediction: ['[CLS] sleepel movements cheung - combat than this - - - in - movements surface particularly - -ggles stiff commercial - gesture by killed paper this drama [SEP]']
[ 150/2000] tot_loss=2.629 (perp=9.661, rec=0.194, cos=0.503), tot_loss_proj:3.182 [t=0.22s]
prediction: ['[CLS] bowel movementsி - crime than this - in - long shelf movements surfacemm - -gglesick exercise - assistant by - advisor the drama [SEP]']
[ 200/2000] tot_loss=2.344 (perp=8.555, rec=0.145, cos=0.488), tot_loss_proj:2.867 [t=0.22s]
prediction: ['[CLS] bowel movementsி - crime than this - in - long shelf movements surfacemm - -mmick exercise - shoot - - exercise the drama [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.306 (perp=8.422, rec=0.134, cos=0.488), tot_loss_proj:2.755 [t=0.22s]
prediction: ['[CLS] bowel movementsick - crime than this - in the long shelf movements shelfmm - -mmick exercise - shoot - - exercise - drama [SEP]']
[ 300/2000] tot_loss=2.333 (perp=8.614, rec=0.116, cos=0.495), tot_loss_proj:2.785 [t=0.22s]
prediction: ['[CLS] bowel movements gi - crime than this - in the long shelf movements shelfmm - -mmick exercise - shoot - - exercise - drama [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.188 (perp=7.850, rec=0.118, cos=0.500), tot_loss_proj:2.629 [t=0.22s]
prediction: ['[CLS] bowel movementsy - than this, in the long shelf movements - crimemm - -mmick exercise shelf shoot - - shoot - drama [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.314 (perp=8.548, rec=0.109, cos=0.495), tot_loss_proj:2.683 [t=0.22s]
prediction: ['[CLS] bowel movements - than this, in a long shelf movements of crime gi gi - -mmick exercise shelf shoot - - shoot - drama [SEP]']
[ 450/2000] tot_loss=2.193 (perp=7.954, rec=0.107, cos=0.496), tot_loss_proj:2.686 [t=0.22s]
prediction: ['[CLS] bowel movements - than this, in and long shelf exercise the crime giy - -mmick exercise shelf shoot - - shoot - drama [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.145 (perp=7.800, rec=0.091, cos=0.494), tot_loss_proj:2.636 [t=0.22s]
prediction: ['[CLS] bowel movements - than this, in crime the long shelf exercise the giy - -mmick exercise shelf shoot - - shoot - drama [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.067 (perp=7.409, rec=0.090, cos=0.495), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] bowel movements - than this, in - the long shelf exercise crime giy - -mmick exercise - shoot - - shoot - drama [SEP]']
[ 600/2000] tot_loss=2.030 (perp=7.268, rec=0.077, cos=0.499), tot_loss_proj:2.443 [t=0.22s]
prediction: ['[CLS] bowel movements - than this, in the the long shelf exercise crime giy - -mmick exercise - shoot - - shoot - drama [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.038 (perp=7.338, rec=0.074, cos=0.497), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] bowel movements - than this, in the the long shelf crime giy movements - -mmick exercise and shoot - - point - drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.007 (perp=7.126, rec=0.084, cos=0.498), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy movements - -mmick exercise and shoot - on point - drama [SEP]']
[ 750/2000] tot_loss=2.003 (perp=7.126, rec=0.082, cos=0.496), tot_loss_proj:2.492 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy movements - -mmick exercise and shoot - on point - drama [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.974 (perp=7.001, rec=0.077, cos=0.497), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.966 (perp=7.001, rec=0.068, cos=0.498), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
[ 900/2000] tot_loss=1.974 (perp=7.001, rec=0.076, cos=0.498), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.972 (perp=7.001, rec=0.074, cos=0.498), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
[1000/2000] tot_loss=1.966 (perp=7.001, rec=0.068, cos=0.498), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
[1050/2000] tot_loss=1.969 (perp=7.001, rec=0.071, cos=0.498), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] bowel movements - than this crime in the the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.958 (perp=6.952, rec=0.072, cos=0.496), tot_loss_proj:2.441 [t=0.22s]
prediction: ['[CLS] bowel movements - than the this crime in the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.933 (perp=6.827, rec=0.069, cos=0.499), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
[1200/2000] tot_loss=1.925 (perp=6.827, rec=0.062, cos=0.498), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in the long shelf, giy point - -mmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.013 (perp=7.223, rec=0.071, cos=0.498), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - long shelf, giy point - -mmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
[1300/2000] tot_loss=2.015 (perp=7.223, rec=0.074, cos=0.496), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - long shelf, giy point - -mmick exercise and shoot - movements on - drama [SEP]']
[1350/2000] tot_loss=2.007 (perp=7.223, rec=0.066, cos=0.497), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - long shelf, giy point - -mmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
[1400/2000] tot_loss=2.016 (perp=7.223, rec=0.074, cos=0.498), tot_loss_proj:2.447 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - long shelf, giy point - -mmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.979 (perp=7.054, rec=0.073, cos=0.495), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - - shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
[1500/2000] tot_loss=1.978 (perp=7.054, rec=0.071, cos=0.496), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - - shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
[1550/2000] tot_loss=1.977 (perp=7.054, rec=0.070, cos=0.496), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - - shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.976 (perp=7.054, rec=0.069, cos=0.496), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - - shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
[1650/2000] tot_loss=1.980 (perp=7.054, rec=0.073, cos=0.497), tot_loss_proj:2.382 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime in - - shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.956 (perp=6.946, rec=0.069, cos=0.497), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=6.946, rec=0.076, cos=0.497), tot_loss_proj:2.399 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
[1800/2000] tot_loss=1.957 (perp=6.946, rec=0.071, cos=0.497), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
[1850/2000] tot_loss=1.960 (perp=6.946, rec=0.073, cos=0.497), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - movements on - drama [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.942 (perp=6.886, rec=0.068, cos=0.497), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - on movements - drama [SEP]']
[1950/2000] tot_loss=1.949 (perp=6.886, rec=0.075, cos=0.497), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - on movements - drama [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.936 (perp=6.886, rec=0.060, cos=0.499), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] bowel movements - than this the crime - - in shelf, giy point - longmmick exercise and shoot - on movements - drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] bowel movements - than this the crime in - long shelf, giy point - -mmick exercise and shoot - movements on - drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.474 | p: 85.000 | r: 94.444
rouge2     | fm: 33.333 | p: 31.579 | r: 35.294
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 122.807

[Aggregate metrics]:
rouge1     | fm: 87.337 | p: 86.546 | r: 88.333
rouge2     | fm: 49.999 | p: 49.891 | r: 50.175
rougeL     | fm: 75.349 | p: 74.697 | r: 76.178
rougeLsum  | fm: 75.406 | p: 74.676 | r: 76.190
r1fm+r2fm = 137.336

input #45 time: 0:08:34 | total time: 6:47:10


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.7350120480347644
highest_index [0]
highest [0.7350120480347644]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9536163806915283 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9495308995246887 for ['[CLS] medicine follows idol cereal run active [SEP]']
[Init] best rec loss: 0.94780433177948 for ['[CLS] upcoming trim grease settled g dallas [SEP]']
[Init] best rec loss: 0.9287865161895752 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9283309578895569 for ['[CLS] worldwide fork packaging touched might fantastic [SEP]']
[Init] best rec loss: 0.9241440892219543 for ['[CLS] autism prince angles luna objectshol [SEP]']
[Init] best rec loss: 0.915471613407135 for ['[CLS] giants alley told hurricane und : [SEP]']
[Init] best perm rec loss: 0.9149813055992126 for ['[CLS] : und giants told alley hurricane [SEP]']
[Init] best perm rec loss: 0.914586067199707 for ['[CLS] told hurricane giants und : alley [SEP]']
[Init] best perm rec loss: 0.9125814437866211 for ['[CLS] hurricane : told giants und alley [SEP]']
[Init] best perm rec loss: 0.9113295674324036 for ['[CLS] und : told hurricane alley giants [SEP]']
[Init] best perm rec loss: 0.9105356931686401 for ['[CLS] told hurricane und giants alley : [SEP]']
[Init] best perm rec loss: 0.9087201952934265 for ['[CLS] hurricane told giants : und alley [SEP]']
[Init] best perm rec loss: 0.9075775146484375 for ['[CLS] hurricane told und giants : alley [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.312 (perp=8.458, rec=0.162, cos=0.458), tot_loss_proj:2.459 [t=0.21s]
prediction: ['[CLS] visually striking striking, slick staged [SEP]']
[ 100/2000] tot_loss=2.249 (perp=8.422, rec=0.105, cos=0.460), tot_loss_proj:2.458 [t=0.21s]
prediction: ['[CLS] visually striking striking and slick staged [SEP]']
[ 150/2000] tot_loss=2.307 (perp=8.707, rec=0.107, cos=0.459), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] visually striking slick and slick staged [SEP]']
[ 200/2000] tot_loss=2.278 (perp=8.707, rec=0.079, cos=0.458), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] visually striking slick and slick staged [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.283 (perp=8.707, rec=0.083, cos=0.459), tot_loss_proj:2.580 [t=0.21s]
prediction: ['[CLS] visually striking slick and slick staged [SEP]']
[ 300/2000] tot_loss=2.277 (perp=8.707, rec=0.079, cos=0.457), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS] visually striking slick and slick staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.296 (perp=8.769, rec=0.083, cos=0.460), tot_loss_proj:2.602 [t=0.21s]
prediction: ['[CLS] visually striking slick andly staged [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.719 (perp=5.916, rec=0.078, cos=0.458), tot_loss_proj:1.704 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.702 (perp=5.916, rec=0.060, cos=0.459), tot_loss_proj:1.703 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.699 (perp=5.916, rec=0.056, cos=0.460), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.712 (perp=5.916, rec=0.069, cos=0.460), tot_loss_proj:1.704 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.700 (perp=5.916, rec=0.058, cos=0.459), tot_loss_proj:1.705 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.709 (perp=5.916, rec=0.069, cos=0.457), tot_loss_proj:1.709 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.705 (perp=5.916, rec=0.063, cos=0.459), tot_loss_proj:1.709 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.702 (perp=5.916, rec=0.060, cos=0.459), tot_loss_proj:1.704 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.708 (perp=5.916, rec=0.065, cos=0.460), tot_loss_proj:1.707 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.712 (perp=5.916, rec=0.069, cos=0.460), tot_loss_proj:1.714 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.701 (perp=5.916, rec=0.058, cos=0.459), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.706 (perp=5.916, rec=0.064, cos=0.459), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.709 (perp=5.916, rec=0.066, cos=0.460), tot_loss_proj:1.700 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.708 (perp=5.916, rec=0.066, cos=0.459), tot_loss_proj:1.708 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.697 (perp=5.916, rec=0.055, cos=0.458), tot_loss_proj:1.715 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.718 (perp=5.916, rec=0.075, cos=0.459), tot_loss_proj:1.703 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.709 (perp=5.916, rec=0.066, cos=0.460), tot_loss_proj:1.708 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.706 (perp=5.916, rec=0.063, cos=0.460), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.711 (perp=5.916, rec=0.069, cos=0.459), tot_loss_proj:1.712 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.710 (perp=5.916, rec=0.067, cos=0.460), tot_loss_proj:1.708 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.715 (perp=5.916, rec=0.073, cos=0.459), tot_loss_proj:1.707 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.706 (perp=5.916, rec=0.063, cos=0.460), tot_loss_proj:1.710 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.696 (perp=5.916, rec=0.054, cos=0.459), tot_loss_proj:1.714 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.706 (perp=5.916, rec=0.064, cos=0.459), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.697 (perp=5.916, rec=0.054, cos=0.459), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.699 (perp=5.916, rec=0.056, cos=0.459), tot_loss_proj:1.710 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.695 (perp=5.916, rec=0.052, cos=0.459), tot_loss_proj:1.719 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=5.916, rec=0.058, cos=0.459), tot_loss_proj:1.702 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.703 (perp=5.916, rec=0.060, cos=0.459), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.710 (perp=5.916, rec=0.068, cos=0.459), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.705 (perp=5.916, rec=0.062, cos=0.459), tot_loss_proj:1.711 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.705 (perp=5.916, rec=0.063, cos=0.460), tot_loss_proj:1.703 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.702 (perp=5.916, rec=0.059, cos=0.460), tot_loss_proj:1.714 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.636 | p: 86.881 | r: 88.648
rouge2     | fm: 51.175 | p: 51.044 | r: 51.383
rougeL     | fm: 75.750 | p: 75.094 | r: 76.488
rougeLsum  | fm: 75.738 | p: 75.171 | r: 76.544
r1fm+r2fm = 138.811

input #46 time: 0:08:29 | total time: 6:55:39


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.7342210697703686
highest_index [0]
highest [0.7342210697703686]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6809883713722229 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6527493000030518 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6480637192726135 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6351944208145142 for ['[CLS] we processgon [SEP]']
[Init] best perm rec loss: 0.6275135278701782 for ['[CLS] process wegon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.149 (perp=12.488, rec=0.219, cos=0.433), tot_loss_proj:3.507 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=3.068 (perp=12.488, rec=0.139, cos=0.432), tot_loss_proj:3.526 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=3.061 (perp=12.488, rec=0.112, cos=0.451), tot_loss_proj:3.531 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=3.042 (perp=12.488, rec=0.099, cos=0.445), tot_loss_proj:3.555 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.028 (perp=12.488, rec=0.092, cos=0.438), tot_loss_proj:3.553 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=3.042 (perp=12.488, rec=0.100, cos=0.445), tot_loss_proj:3.561 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.030 (perp=12.488, rec=0.091, cos=0.442), tot_loss_proj:3.564 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.024 (perp=12.488, rec=0.085, cos=0.441), tot_loss_proj:3.572 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=3.040 (perp=12.488, rec=0.094, cos=0.448), tot_loss_proj:3.581 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.023 (perp=12.488, rec=0.090, cos=0.436), tot_loss_proj:3.572 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.029 (perp=12.488, rec=0.088, cos=0.444), tot_loss_proj:3.575 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=3.040 (perp=12.488, rec=0.091, cos=0.451), tot_loss_proj:3.582 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.039 (perp=12.488, rec=0.091, cos=0.451), tot_loss_proj:3.580 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.020 (perp=12.488, rec=0.082, cos=0.441), tot_loss_proj:3.583 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 750/2000] tot_loss=3.023 (perp=12.488, rec=0.077, cos=0.448), tot_loss_proj:3.580 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.022 (perp=12.488, rec=0.078, cos=0.447), tot_loss_proj:3.583 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.027 (perp=12.488, rec=0.084, cos=0.446), tot_loss_proj:3.588 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 900/2000] tot_loss=3.041 (perp=12.488, rec=0.085, cos=0.458), tot_loss_proj:3.583 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.028 (perp=12.488, rec=0.075, cos=0.455), tot_loss_proj:3.586 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=3.028 (perp=12.488, rec=0.078, cos=0.453), tot_loss_proj:3.589 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1050/2000] tot_loss=3.042 (perp=12.488, rec=0.092, cos=0.452), tot_loss_proj:3.588 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=3.030 (perp=12.488, rec=0.081, cos=0.451), tot_loss_proj:3.592 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=3.028 (perp=12.488, rec=0.074, cos=0.456), tot_loss_proj:3.589 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1200/2000] tot_loss=3.037 (perp=12.488, rec=0.084, cos=0.455), tot_loss_proj:3.590 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=3.035 (perp=12.488, rec=0.082, cos=0.456), tot_loss_proj:3.593 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=3.045 (perp=12.488, rec=0.093, cos=0.455), tot_loss_proj:3.584 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1350/2000] tot_loss=3.035 (perp=12.488, rec=0.077, cos=0.460), tot_loss_proj:3.588 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=3.037 (perp=12.488, rec=0.082, cos=0.457), tot_loss_proj:3.601 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=3.039 (perp=12.488, rec=0.080, cos=0.461), tot_loss_proj:3.592 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1500/2000] tot_loss=3.027 (perp=12.488, rec=0.076, cos=0.454), tot_loss_proj:3.599 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=3.031 (perp=12.488, rec=0.080, cos=0.453), tot_loss_proj:3.591 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=3.039 (perp=12.488, rec=0.085, cos=0.457), tot_loss_proj:3.598 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1650/2000] tot_loss=3.040 (perp=12.488, rec=0.085, cos=0.457), tot_loss_proj:3.592 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=3.039 (perp=12.488, rec=0.083, cos=0.459), tot_loss_proj:3.593 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=3.031 (perp=12.488, rec=0.076, cos=0.458), tot_loss_proj:3.591 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1800/2000] tot_loss=3.036 (perp=12.488, rec=0.082, cos=0.457), tot_loss_proj:3.590 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=3.041 (perp=12.488, rec=0.091, cos=0.452), tot_loss_proj:3.593 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=3.025 (perp=12.488, rec=0.073, cos=0.454), tot_loss_proj:3.594 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1950/2000] tot_loss=3.040 (perp=12.488, rec=0.088, cos=0.455), tot_loss_proj:3.596 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=3.020 (perp=12.488, rec=0.069, cos=0.454), tot_loss_proj:3.595 [t=0.21s]
prediction: ['[CLS]right transparent transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS]right transparent transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 87.182 | p: 86.160 | r: 88.319
rouge2     | fm: 50.635 | p: 50.364 | r: 50.884
rougeL     | fm: 75.603 | p: 74.850 | r: 76.620
rougeLsum  | fm: 75.513 | p: 74.709 | r: 76.500
r1fm+r2fm = 137.817

input #47 time: 0:08:26 | total time: 7:04:06


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.733950215046046
highest_index [0]
highest [0.733950215046046]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8484975099563599 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8386347889900208 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.836141049861908 for ['[CLS] tonightste breadim [SEP]']
[Init] best rec loss: 0.7888472676277161 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7810201644897461 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7794700264930725 for ['[CLS] runs graveyarddinetute [SEP]']
[Init] best perm rec loss: 0.7788980007171631 for ['[CLS]dine graveyardtute runs [SEP]']
[Init] best perm rec loss: 0.7767862677574158 for ['[CLS] graveyard runsdinetute [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.125 (perp=12.133, rec=0.253, cos=0.445), tot_loss_proj:3.322 [t=0.21s]
prediction: ['[CLS] liver rotting rotting beneath [SEP]']
[ 100/2000] tot_loss=2.581 (perp=9.779, rec=0.167, cos=0.458), tot_loss_proj:2.804 [t=0.21s]
prediction: ['[CLS]belly rotting beneath [SEP]']
[ 150/2000] tot_loss=2.509 (perp=9.700, rec=0.111, cos=0.459), tot_loss_proj:2.741 [t=0.22s]
prediction: ['[CLS]belly rotting under [SEP]']
[ 200/2000] tot_loss=2.496 (perp=9.700, rec=0.102, cos=0.453), tot_loss_proj:2.749 [t=0.21s]
prediction: ['[CLS]belly rotting under [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.944 (perp=7.028, rec=0.081, cos=0.457), tot_loss_proj:2.146 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 300/2000] tot_loss=1.948 (perp=7.028, rec=0.082, cos=0.460), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.944 (perp=7.028, rec=0.077, cos=0.462), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.941 (perp=7.028, rec=0.075, cos=0.460), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.938 (perp=7.028, rec=0.075, cos=0.457), tot_loss_proj:2.133 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.936 (perp=7.028, rec=0.070, cos=0.461), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.940 (perp=7.028, rec=0.075, cos=0.460), tot_loss_proj:2.147 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.940 (perp=7.028, rec=0.075, cos=0.460), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.925 (perp=7.028, rec=0.059, cos=0.460), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.931 (perp=7.028, rec=0.064, cos=0.461), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.940 (perp=7.028, rec=0.078, cos=0.456), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.936 (perp=7.028, rec=0.069, cos=0.461), tot_loss_proj:2.145 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.930 (perp=7.028, rec=0.064, cos=0.460), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.933 (perp=7.028, rec=0.066, cos=0.461), tot_loss_proj:2.145 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.938 (perp=7.028, rec=0.071, cos=0.461), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.931 (perp=7.028, rec=0.068, cos=0.457), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.929 (perp=7.028, rec=0.062, cos=0.460), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.930 (perp=7.028, rec=0.066, cos=0.459), tot_loss_proj:2.149 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.925 (perp=7.028, rec=0.061, cos=0.458), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.932 (perp=7.028, rec=0.067, cos=0.459), tot_loss_proj:2.144 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.941 (perp=7.028, rec=0.075, cos=0.460), tot_loss_proj:2.151 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.931 (perp=7.028, rec=0.067, cos=0.459), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.933 (perp=7.028, rec=0.068, cos=0.460), tot_loss_proj:2.141 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.933 (perp=7.028, rec=0.068, cos=0.460), tot_loss_proj:2.146 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.929 (perp=7.028, rec=0.063, cos=0.461), tot_loss_proj:2.144 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.926 (perp=7.028, rec=0.059, cos=0.461), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.925 (perp=7.028, rec=0.059, cos=0.460), tot_loss_proj:2.145 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.930 (perp=7.028, rec=0.064, cos=0.460), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.933 (perp=7.028, rec=0.067, cos=0.460), tot_loss_proj:2.143 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.931 (perp=7.028, rec=0.066, cos=0.460), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.941 (perp=7.028, rec=0.073, cos=0.461), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.944 (perp=7.028, rec=0.077, cos=0.461), tot_loss_proj:2.150 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.940 (perp=7.028, rec=0.074, cos=0.460), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.933 (perp=7.028, rec=0.067, cos=0.461), tot_loss_proj:2.146 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.931 (perp=7.028, rec=0.064, cos=0.461), tot_loss_proj:2.147 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.931 (perp=7.028, rec=0.066, cos=0.460), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.369 | p: 86.461 | r: 88.473
rouge2     | fm: 49.749 | p: 49.546 | r: 50.056
rougeL     | fm: 75.719 | p: 74.952 | r: 76.571
rougeLsum  | fm: 75.580 | p: 74.741 | r: 76.527
r1fm+r2fm = 137.119

input #48 time: 0:08:30 | total time: 7:12:36


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.7417950498664023
highest_index [0]
highest [0.7417950498664023]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8172858953475952 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7921950221061707 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7852723002433777 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 0.7694727182388306 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7639095187187195 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.758571207523346 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 0.7549780607223511 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7497106194496155 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best perm rec loss: 0.7482577562332153 for ['[CLS]uous perrin where things our sheepanial accompanied hetani major tried [SEP]']
[Init] best perm rec loss: 0.7475262880325317 for ['[CLS] accompanied major sheepanialuous perrin tried wheretani he things our [SEP]']
[Init] best perm rec loss: 0.746356189250946 for ['[CLS] major tried accompaniedanial sheeptani perrinuous where things our he [SEP]']
[Init] best perm rec loss: 0.7447184324264526 for ['[CLS]uoustani things tried majoranial sheep perrin where he our accompanied [SEP]']
[Init] best perm rec loss: 0.7445497512817383 for ['[CLS] perrin tried ouruoustanianial where accompanied major he sheep things [SEP]']
[Init] best perm rec loss: 0.7442910075187683 for ['[CLS]uous our major accompaniedanial wheretani sheep things tried perrin he [SEP]']
[Init] best perm rec loss: 0.7439329624176025 for ['[CLS] sheeptani our thingsuous perrin where accompanied major tried heanial [SEP]']
[Init] best perm rec loss: 0.7431036829948425 for ['[CLS]uousanialtani he major accompanied where perrin tried sheep things our [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.267 (perp=12.424, rec=0.340, cos=0.443), tot_loss_proj:3.799 [t=0.21s]
prediction: ['[CLS] more contempt female population contemptvialn crowd [SEP] contempt less [SEP]']
[ 100/2000] tot_loss=3.043 (perp=11.774, rec=0.259, cos=0.429), tot_loss_proj:3.472 [t=0.22s]
prediction: ['[CLS] possibly contempt female population contemptuous datingm individuals be contempt more [SEP]']
[ 150/2000] tot_loss=2.931 (perp=11.616, rec=0.179, cos=0.428), tot_loss_proj:3.462 [t=0.22s]
prediction: ['[CLS] possibly contempt female population contemptuousem population be contempt more [SEP]']
[ 200/2000] tot_loss=2.849 (perp=11.291, rec=0.150, cos=0.441), tot_loss_proj:3.462 [t=0.22s]
prediction: ['[CLS] possibly contempt female its contemptuous experiencem population be single more [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.420 (perp=9.294, rec=0.128, cos=0.434), tot_loss_proj:2.962 [t=0.22s]
prediction: ['[CLS] possibly contemptm the contemptuous of female population be single more [SEP]']
[ 300/2000] tot_loss=2.457 (perp=9.530, rec=0.108, cos=0.443), tot_loss_proj:3.053 [t=0.22s]
prediction: ['[CLS] possiblyuousm the contemptuous of female population be single more [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.251 (perp=8.520, rec=0.108, cos=0.440), tot_loss_proj:2.695 [t=0.22s]
prediction: ['[CLS] possibly bem the contemptuous of female populationuous single more [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.326 (perp=8.897, rec=0.106, cos=0.441), tot_loss_proj:2.814 [t=0.22s]
prediction: ['[CLS] possibly.m the contemptuous of female population more singleuous [SEP]']
[ 450/2000] tot_loss=2.313 (perp=8.827, rec=0.102, cos=0.445), tot_loss_proj:2.785 [t=0.22s]
prediction: ['[CLS] possibly.d the contemptuous of female population more singleuous [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.142 (perp=8.023, rec=0.101, cos=0.437), tot_loss_proj:2.812 [t=0.22s]
prediction: ['[CLS] possiblyuousd the contemptuous of female population more single. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.150 (perp=8.023, rec=0.097, cos=0.448), tot_loss_proj:2.812 [t=0.22s]
prediction: ['[CLS] possiblyuousd the contemptuous of female population more single. [SEP]']
[ 600/2000] tot_loss=2.144 (perp=8.023, rec=0.096, cos=0.443), tot_loss_proj:2.812 [t=0.22s]
prediction: ['[CLS] possiblyuousd the contemptuous of female population more single. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.927 (perp=6.983, rec=0.095, cos=0.435), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] possibly bed the contemptuous of more single female population. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.785 (perp=6.281, rec=0.085, cos=0.444), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] possibly bed more contemptuous of the single female population. [SEP]']
[ 750/2000] tot_loss=1.781 (perp=6.281, rec=0.086, cos=0.439), tot_loss_proj:2.233 [t=0.22s]
prediction: ['[CLS] possibly bed more contemptuous of the single female population. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.713 (perp=5.945, rec=0.084, cos=0.441), tot_loss_proj:1.941 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.724 (perp=5.945, rec=0.089, cos=0.446), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[ 900/2000] tot_loss=1.723 (perp=5.945, rec=0.091, cos=0.443), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.718 (perp=5.945, rec=0.086, cos=0.443), tot_loss_proj:1.945 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=5.945, rec=0.086, cos=0.441), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[1050/2000] tot_loss=1.721 (perp=5.945, rec=0.087, cos=0.445), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=5.945, rec=0.087, cos=0.443), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.721 (perp=5.945, rec=0.087, cos=0.445), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[1200/2000] tot_loss=1.718 (perp=5.945, rec=0.083, cos=0.446), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.718 (perp=5.945, rec=0.086, cos=0.443), tot_loss_proj:1.941 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.724 (perp=5.945, rec=0.090, cos=0.444), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[1350/2000] tot_loss=1.723 (perp=5.945, rec=0.090, cos=0.444), tot_loss_proj:1.945 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.723 (perp=5.945, rec=0.088, cos=0.447), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.715 (perp=5.945, rec=0.079, cos=0.447), tot_loss_proj:1.945 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[1500/2000] tot_loss=1.723 (perp=5.945, rec=0.088, cos=0.446), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.718 (perp=5.945, rec=0.083, cos=0.447), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.721 (perp=5.945, rec=0.085, cos=0.447), tot_loss_proj:1.950 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[1650/2000] tot_loss=1.715 (perp=5.945, rec=0.082, cos=0.444), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.728 (perp=5.945, rec=0.092, cos=0.447), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.766 (perp=6.156, rec=0.089, cos=0.445), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of the single female populationd. [SEP]']
[1800/2000] tot_loss=1.769 (perp=6.156, rec=0.095, cos=0.443), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of the single female populationd. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.717 (perp=5.945, rec=0.079, cos=0.448), tot_loss_proj:1.947 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.722 (perp=5.945, rec=0.084, cos=0.449), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
[1950/2000] tot_loss=1.721 (perp=5.945, rec=0.083, cos=0.449), tot_loss_proj:1.951 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.725 (perp=5.945, rec=0.087, cos=0.450), tot_loss_proj:1.946 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuousd of the single female population. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly be more contemptuousd of the single female population. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 90.909 | r: 83.333
rouge2     | fm: 66.667 | p: 70.000 | r: 63.636
rougeL     | fm: 86.957 | p: 90.909 | r: 83.333
rougeLsum  | fm: 86.957 | p: 90.909 | r: 83.333
r1fm+r2fm = 153.623

[Aggregate metrics]:
rouge1     | fm: 87.375 | p: 86.537 | r: 88.429
rouge2     | fm: 50.026 | p: 49.902 | r: 50.211
rougeL     | fm: 75.943 | p: 75.268 | r: 76.735
rougeLsum  | fm: 75.866 | p: 75.176 | r: 76.665
r1fm+r2fm = 137.401

input #49 time: 0:08:35 | total time: 7:21:12


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.7274746584603361
highest_index [0]
highest [0.7274746584603361]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8050569891929626 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.7968947291374207 for ['[CLS] felt defended drop ring richard spade frank beds₁ [SEP]']
[Init] best rec loss: 0.7913461327552795 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7731713056564331 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7710395455360413 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best rec loss: 0.7543400526046753 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.752075731754303 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.7491505742073059 for ['[CLS] ing grade over good fishsil champion woolf state [SEP]']
[Init] best perm rec loss: 0.7488715052604675 for ['[CLS] fish grade woolf over state good championsil ing [SEP]']
[Init] best perm rec loss: 0.7480344176292419 for ['[CLS] good state over grade ingsil fish woolf champion [SEP]']
[Init] best perm rec loss: 0.7471809983253479 for ['[CLS] fish oversil ing champion good state woolf grade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.111 (perp=11.506, rec=0.364, cos=0.446), tot_loss_proj:3.833 [t=0.21s]
prediction: ['[CLS] too whereas rear could by probably now clever clever [SEP]']
[ 100/2000] tot_loss=2.688 (perp=9.807, rec=0.292, cos=0.434), tot_loss_proj:3.025 [t=0.21s]
prediction: ['[CLS] too the ` could by called half clever clever [SEP]']
[ 150/2000] tot_loss=2.822 (perp=10.756, rec=0.227, cos=0.445), tot_loss_proj:3.309 [t=0.21s]
prediction: ['[CLS] too english ` box by call half clever clever [SEP]']
[ 200/2000] tot_loss=2.874 (perp=11.192, rec=0.186, cos=0.449), tot_loss_proj:3.357 [t=0.21s]
prediction: ['[CLS] too english ` components by call half clever clever [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.452 (perp=9.231, rec=0.137, cos=0.470), tot_loss_proj:3.032 [t=0.21s]
prediction: ['[CLS] too english ` if call by half clever clever [SEP]']
[ 300/2000] tot_loss=2.597 (perp=10.095, rec=0.132, cos=0.446), tot_loss_proj:3.193 [t=0.22s]
prediction: ['[CLS] too english ` components call by half clever clever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.515 (perp=9.628, rec=0.125, cos=0.464), tot_loss_proj:3.077 [t=0.21s]
prediction: ['[CLS] too what english ` call by half clever clever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.483 (perp=9.448, rec=0.115, cos=0.478), tot_loss_proj:2.996 [t=0.21s]
prediction: ['[CLS] too what ` english call by half clever clever [SEP]']
[ 450/2000] tot_loss=2.445 (perp=9.448, rec=0.104, cos=0.452), tot_loss_proj:2.992 [t=0.21s]
prediction: ['[CLS] too what ` english call by half clever clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.443 (perp=9.448, rec=0.091, cos=0.463), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] too what ` english call by half clever clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.444 (perp=9.448, rec=0.086, cos=0.468), tot_loss_proj:2.991 [t=0.21s]
prediction: ['[CLS] too what ` english call by half clever clever [SEP]']
[ 600/2000] tot_loss=2.434 (perp=9.448, rec=0.086, cos=0.459), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] too what ` english call by half clever clever [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.341 (perp=9.009, rec=0.078, cos=0.460), tot_loss_proj:2.910 [t=0.21s]
prediction: ['[CLS] too half what ` english call by clever clever [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.315 (perp=8.909, rec=0.075, cos=0.458), tot_loss_proj:2.877 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[ 750/2000] tot_loss=2.316 (perp=8.909, rec=0.072, cos=0.463), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.325 (perp=8.909, rec=0.077, cos=0.466), tot_loss_proj:2.874 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.309 (perp=8.909, rec=0.071, cos=0.456), tot_loss_proj:2.872 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[ 900/2000] tot_loss=2.316 (perp=8.909, rec=0.074, cos=0.460), tot_loss_proj:2.871 [t=0.22s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.318 (perp=8.909, rec=0.070, cos=0.465), tot_loss_proj:2.878 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1000/2000] tot_loss=2.327 (perp=8.909, rec=0.083, cos=0.463), tot_loss_proj:2.872 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1050/2000] tot_loss=2.329 (perp=8.909, rec=0.079, cos=0.469), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1100/2000] tot_loss=2.310 (perp=8.909, rec=0.061, cos=0.467), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1150/2000] tot_loss=2.319 (perp=8.909, rec=0.070, cos=0.467), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1200/2000] tot_loss=2.314 (perp=8.909, rec=0.067, cos=0.466), tot_loss_proj:2.874 [t=0.22s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1250/2000] tot_loss=2.312 (perp=8.909, rec=0.064, cos=0.466), tot_loss_proj:2.874 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1300/2000] tot_loss=2.326 (perp=8.909, rec=0.080, cos=0.464), tot_loss_proj:2.879 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1350/2000] tot_loss=2.309 (perp=8.909, rec=0.061, cos=0.466), tot_loss_proj:2.876 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1400/2000] tot_loss=2.322 (perp=8.909, rec=0.073, cos=0.466), tot_loss_proj:2.875 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1450/2000] tot_loss=2.314 (perp=8.909, rec=0.067, cos=0.465), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1500/2000] tot_loss=2.315 (perp=8.909, rec=0.070, cos=0.463), tot_loss_proj:2.866 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1550/2000] tot_loss=2.319 (perp=8.909, rec=0.067, cos=0.470), tot_loss_proj:2.881 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1600/2000] tot_loss=2.316 (perp=8.909, rec=0.066, cos=0.467), tot_loss_proj:2.868 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1650/2000] tot_loss=2.317 (perp=8.909, rec=0.068, cos=0.467), tot_loss_proj:2.874 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1700/2000] tot_loss=2.316 (perp=8.909, rec=0.065, cos=0.469), tot_loss_proj:2.877 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1750/2000] tot_loss=2.318 (perp=8.909, rec=0.068, cos=0.468), tot_loss_proj:2.873 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1800/2000] tot_loss=2.327 (perp=8.909, rec=0.078, cos=0.467), tot_loss_proj:2.874 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1850/2000] tot_loss=2.320 (perp=8.909, rec=0.072, cos=0.466), tot_loss_proj:2.878 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[1900/2000] tot_loss=2.314 (perp=8.909, rec=0.065, cos=0.467), tot_loss_proj:2.872 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
[1950/2000] tot_loss=2.321 (perp=8.909, rec=0.072, cos=0.467), tot_loss_proj:2.871 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Attempt swap
[2000/2000] tot_loss=2.316 (perp=8.909, rec=0.065, cos=0.469), tot_loss_proj:2.873 [t=0.21s]
prediction: ['[CLS] too half what ` call by clever english clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] too half what ` call by clever english clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 90.000

[Aggregate metrics]:
rouge1     | fm: 87.453 | p: 86.654 | r: 88.455
rouge2     | fm: 48.812 | p: 48.624 | r: 49.045
rougeL     | fm: 75.488 | p: 74.850 | r: 76.301
rougeLsum  | fm: 75.193 | p: 74.516 | r: 76.046
r1fm+r2fm = 136.265

input #50 time: 0:08:30 | total time: 7:29:43


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.739604936480544
highest_index [0]
highest [0.739604936480544]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7959101796150208 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7626432776451111 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7429550886154175 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7341609001159668 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7161489725112915 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.714031457901001 for ['[CLS] acute jay outies harbor recognitionitung annezzled hughes [SEP]']
[Init] best rec loss: 0.7051675915718079 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best perm rec loss: 0.7050603032112122 for ['[CLS]dro anymore premisesno customer minute hugh nothing thomas nuclear [SEP]']
[Init] best perm rec loss: 0.7042301297187805 for ['[CLS]dro thomas nuclear hugh nothingno premises minute anymore customer [SEP]']
[Init] best perm rec loss: 0.7040098905563354 for ['[CLS] premises thomas minutedro customer hughno anymore nothing nuclear [SEP]']
[Init] best perm rec loss: 0.7035050988197327 for ['[CLS] nothing premises hugh nuclear minuteno anymore thomasdro customer [SEP]']
[Init] best perm rec loss: 0.703450083732605 for ['[CLS] nothing anymoredro hugh premises minuteno customer nuclear thomas [SEP]']
[Init] best perm rec loss: 0.7033847570419312 for ['[CLS] premises minute anymoreno nothing nucleardro hugh thomas customer [SEP]']
[Init] best perm rec loss: 0.7033686637878418 for ['[CLS] minutedro anymore hugh customer nuclear nothing thomasno premises [SEP]']
[Init] best perm rec loss: 0.7026039958000183 for ['[CLS]no nothing minutedro premises customer thomas anymore nuclear hugh [SEP]']
[Init] best perm rec loss: 0.7021891474723816 for ['[CLS] thomas nothingdro nuclearno premises hugh anymore minute customer [SEP]']
[Init] best perm rec loss: 0.7012367844581604 for ['[CLS] hughno thomas nothing premises nuclear anymore minute customerdro [SEP]']
[Init] best perm rec loss: 0.7009060978889465 for ['[CLS] anymore premises customer minute nuclear nothingno hughdro thomas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.252 (perp=12.312, rec=0.345, cos=0.444), tot_loss_proj:4.220 [t=0.22s]
prediction: ['[CLS] sucks sucks creek decides months not a funny sucks sucks [SEP]']
[ 100/2000] tot_loss=2.792 (perp=10.645, rec=0.231, cos=0.432), tot_loss_proj:3.689 [t=0.22s]
prediction: ['[CLS] sucks sucks funny but has not a funny sucks sucks [SEP]']
[ 150/2000] tot_loss=2.403 (perp=9.019, rec=0.159, cos=0.440), tot_loss_proj:3.248 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has without a funny or sucks [SEP]']
[ 200/2000] tot_loss=2.315 (perp=8.770, rec=0.128, cos=0.432), tot_loss_proj:3.240 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has without a funny or two [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.247 (perp=8.409, rec=0.112, cos=0.452), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has a funny or drops two [SEP]']
[ 300/2000] tot_loss=2.243 (perp=8.446, rec=0.111, cos=0.443), tot_loss_proj:2.697 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has a funny or without two [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.143 (perp=8.015, rec=0.103, cos=0.437), tot_loss_proj:2.536 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has a funny or two without [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.093 (perp=7.761, rec=0.107, cos=0.433), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has a funny moment or without [SEP]']
[ 450/2000] tot_loss=2.088 (perp=7.761, rec=0.090, cos=0.445), tot_loss_proj:2.608 [t=0.22s]
prediction: ['[CLS] sucks sucks, but has a funny moment or without [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.718 (perp=5.940, rec=0.088, cos=0.443), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.721 (perp=5.940, rec=0.087, cos=0.446), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[ 600/2000] tot_loss=1.725 (perp=5.940, rec=0.095, cos=0.442), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.711 (perp=5.940, rec=0.087, cos=0.437), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.894 (perp=6.352, rec=0.172, cos=0.452), tot_loss_proj:2.279 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
[ 750/2000] tot_loss=1.841 (perp=6.352, rec=0.122, cos=0.448), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.838 (perp=6.352, rec=0.114, cos=0.453), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or two sucks [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.751 (perp=5.940, rec=0.112, cos=0.451), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[ 900/2000] tot_loss=1.742 (perp=5.940, rec=0.104, cos=0.450), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.740 (perp=5.940, rec=0.101, cos=0.450), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.739 (perp=5.940, rec=0.100, cos=0.452), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1050/2000] tot_loss=1.737 (perp=5.940, rec=0.099, cos=0.450), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.736 (perp=5.940, rec=0.096, cos=0.452), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.733 (perp=5.940, rec=0.093, cos=0.452), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1200/2000] tot_loss=1.729 (perp=5.940, rec=0.088, cos=0.452), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=5.940, rec=0.093, cos=0.451), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.728 (perp=5.940, rec=0.090, cos=0.450), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1350/2000] tot_loss=1.731 (perp=5.940, rec=0.093, cos=0.451), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.726 (perp=5.940, rec=0.088, cos=0.450), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.728 (perp=5.940, rec=0.090, cos=0.451), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1500/2000] tot_loss=1.721 (perp=5.940, rec=0.083, cos=0.450), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=5.940, rec=0.093, cos=0.450), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.719 (perp=5.940, rec=0.081, cos=0.450), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1650/2000] tot_loss=1.719 (perp=5.940, rec=0.081, cos=0.450), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.713 (perp=5.940, rec=0.074, cos=0.451), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.718 (perp=5.940, rec=0.080, cos=0.450), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1800/2000] tot_loss=1.716 (perp=5.940, rec=0.077, cos=0.451), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.720 (perp=5.940, rec=0.081, cos=0.451), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.722 (perp=5.940, rec=0.083, cos=0.451), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
[1950/2000] tot_loss=1.729 (perp=5.940, rec=0.090, cos=0.451), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.718 (perp=5.940, rec=0.079, cos=0.451), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] sucks, but has a funny moment or sucks. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks, but has a funny moment or sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 77.778 | p: 77.778 | r: 77.778
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 167.778

[Aggregate metrics]:
rouge1     | fm: 87.475 | p: 86.654 | r: 88.460
rouge2     | fm: 49.571 | p: 49.382 | r: 49.804
rougeL     | fm: 75.624 | p: 75.010 | r: 76.453
rougeLsum  | fm: 75.588 | p: 74.897 | r: 76.456
r1fm+r2fm = 137.045

input #51 time: 0:08:35 | total time: 7:38:18


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.7242920791238255
highest_index [0]
highest [0.7242920791238255]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9430301189422607 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9329515099525452 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.9290280938148499 for ['[CLS]fa bear gun [SEP]']
[Init] best rec loss: 0.9289098381996155 for ['[CLS] : hate fra [SEP]']
[Init] best rec loss: 0.9128550291061401 for ['[CLS] news implies lack [SEP]']
[Init] best rec loss: 0.8902817964553833 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.8846871852874756 for ['[CLS] nations gazette probability [SEP]']
[Init] best rec loss: 0.7577667236328125 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7468885779380798 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7444660067558289 for ['[CLS] expected football vocabulary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.766 (perp=10.655, rec=0.167, cos=0.468), tot_loss_proj:2.877 [t=0.21s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 100/2000] tot_loss=2.716 (perp=10.655, rec=0.111, cos=0.474), tot_loss_proj:2.882 [t=0.21s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 150/2000] tot_loss=2.708 (perp=10.655, rec=0.105, cos=0.472), tot_loss_proj:2.874 [t=0.21s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 200/2000] tot_loss=2.696 (perp=10.655, rec=0.091, cos=0.474), tot_loss_proj:2.880 [t=0.21s]
prediction: ['[CLS] trailer trailer trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.323 (perp=8.541, rec=0.142, cos=0.473), tot_loss_proj:2.603 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
[ 300/2000] tot_loss=2.302 (perp=8.541, rec=0.124, cos=0.469), tot_loss_proj:2.596 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.283 (perp=8.541, rec=0.103, cos=0.472), tot_loss_proj:2.597 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.280 (perp=8.541, rec=0.099, cos=0.473), tot_loss_proj:2.600 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
[ 450/2000] tot_loss=2.275 (perp=8.541, rec=0.094, cos=0.473), tot_loss_proj:2.601 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.278 (perp=8.541, rec=0.095, cos=0.475), tot_loss_proj:2.606 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.273 (perp=8.541, rec=0.091, cos=0.474), tot_loss_proj:2.604 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
[ 600/2000] tot_loss=2.249 (perp=8.541, rec=0.068, cos=0.474), tot_loss_proj:2.607 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.251 (perp=8.541, rec=0.069, cos=0.474), tot_loss_proj:2.601 [t=0.21s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.242 (perp=8.482, rec=0.075, cos=0.471), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=2.240 (perp=8.482, rec=0.070, cos=0.474), tot_loss_proj:2.583 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.239 (perp=8.482, rec=0.070, cos=0.472), tot_loss_proj:2.574 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.241 (perp=8.482, rec=0.070, cos=0.474), tot_loss_proj:2.581 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=2.235 (perp=8.482, rec=0.064, cos=0.475), tot_loss_proj:2.576 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.239 (perp=8.482, rec=0.068, cos=0.474), tot_loss_proj:2.588 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=2.245 (perp=8.482, rec=0.074, cos=0.474), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=2.242 (perp=8.482, rec=0.072, cos=0.474), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=2.238 (perp=8.482, rec=0.066, cos=0.475), tot_loss_proj:2.577 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=2.240 (perp=8.482, rec=0.068, cos=0.475), tot_loss_proj:2.580 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=2.229 (perp=8.482, rec=0.057, cos=0.475), tot_loss_proj:2.581 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=2.225 (perp=8.482, rec=0.054, cos=0.475), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=2.241 (perp=8.482, rec=0.070, cos=0.474), tot_loss_proj:2.577 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=2.240 (perp=8.482, rec=0.069, cos=0.474), tot_loss_proj:2.580 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=2.237 (perp=8.482, rec=0.065, cos=0.475), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=2.240 (perp=8.482, rec=0.069, cos=0.474), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=2.237 (perp=8.482, rec=0.066, cos=0.475), tot_loss_proj:2.571 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=2.247 (perp=8.482, rec=0.076, cos=0.475), tot_loss_proj:2.576 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=2.236 (perp=8.482, rec=0.065, cos=0.475), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=2.235 (perp=8.482, rec=0.063, cos=0.475), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=2.236 (perp=8.482, rec=0.065, cos=0.474), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=2.235 (perp=8.482, rec=0.063, cos=0.475), tot_loss_proj:2.577 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=2.235 (perp=8.482, rec=0.063, cos=0.475), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=2.242 (perp=8.482, rec=0.071, cos=0.475), tot_loss_proj:2.585 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=2.239 (perp=8.482, rec=0.068, cos=0.475), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=2.235 (perp=8.482, rec=0.064, cos=0.475), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=2.238 (perp=8.482, rec=0.067, cos=0.475), tot_loss_proj:2.584 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.796 | p: 86.998 | r: 88.747
rouge2     | fm: 48.549 | p: 48.411 | r: 48.794
rougeL     | fm: 75.732 | p: 75.053 | r: 76.538
rougeLsum  | fm: 75.459 | p: 74.883 | r: 76.295
r1fm+r2fm = 136.345

input #52 time: 0:08:26 | total time: 7:46:45


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.708841354695791
highest_index [0]
highest [0.708841354695791]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.8173406720161438 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8086414337158203 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 0.7960662841796875 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 0.7195197939872742 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7030947804450989 for ['[CLS] annually ability [SEP]']
[Init] best rec loss: 0.6784656643867493 for ['[CLS] praising won [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.183 (perp=12.493, rec=0.187, cos=0.497), tot_loss_proj:3.652 [t=0.21s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=3.118 (perp=12.493, rec=0.137, cos=0.482), tot_loss_proj:3.666 [t=0.21s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=3.116 (perp=12.493, rec=0.120, cos=0.498), tot_loss_proj:3.668 [t=0.21s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.186 (perp=8.090, rec=0.074, cos=0.494), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.166 (perp=8.090, rec=0.057, cos=0.491), tot_loss_proj:2.189 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=2.164 (perp=8.090, rec=0.051, cos=0.495), tot_loss_proj:2.186 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.188 (perp=8.090, rec=0.075, cos=0.495), tot_loss_proj:2.188 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.174 (perp=8.090, rec=0.066, cos=0.490), tot_loss_proj:2.186 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=2.178 (perp=8.090, rec=0.062, cos=0.498), tot_loss_proj:2.191 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.176 (perp=8.090, rec=0.063, cos=0.495), tot_loss_proj:2.196 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.168 (perp=8.090, rec=0.057, cos=0.493), tot_loss_proj:2.201 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=2.173 (perp=8.090, rec=0.064, cos=0.491), tot_loss_proj:2.194 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.172 (perp=8.090, rec=0.062, cos=0.492), tot_loss_proj:2.192 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.169 (perp=8.090, rec=0.059, cos=0.492), tot_loss_proj:2.198 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=2.175 (perp=8.090, rec=0.062, cos=0.495), tot_loss_proj:2.199 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.170 (perp=8.090, rec=0.060, cos=0.492), tot_loss_proj:2.191 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.188 (perp=8.090, rec=0.073, cos=0.497), tot_loss_proj:2.202 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=2.181 (perp=8.090, rec=0.068, cos=0.494), tot_loss_proj:2.195 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.175 (perp=8.090, rec=0.063, cos=0.495), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=2.171 (perp=8.090, rec=0.059, cos=0.493), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=2.181 (perp=8.090, rec=0.065, cos=0.497), tot_loss_proj:2.182 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=2.179 (perp=8.090, rec=0.068, cos=0.492), tot_loss_proj:2.197 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=2.176 (perp=8.090, rec=0.063, cos=0.495), tot_loss_proj:2.191 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=2.176 (perp=8.090, rec=0.061, cos=0.497), tot_loss_proj:2.198 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=2.174 (perp=8.090, rec=0.061, cos=0.494), tot_loss_proj:2.196 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=2.167 (perp=8.090, rec=0.059, cos=0.490), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=2.179 (perp=8.090, rec=0.064, cos=0.497), tot_loss_proj:2.198 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=2.179 (perp=8.090, rec=0.065, cos=0.496), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=2.172 (perp=8.090, rec=0.058, cos=0.496), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=2.179 (perp=8.090, rec=0.066, cos=0.495), tot_loss_proj:2.199 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=2.165 (perp=8.090, rec=0.051, cos=0.496), tot_loss_proj:2.195 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=2.166 (perp=8.090, rec=0.053, cos=0.495), tot_loss_proj:2.200 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=2.173 (perp=8.090, rec=0.059, cos=0.496), tot_loss_proj:2.199 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=2.172 (perp=8.090, rec=0.058, cos=0.496), tot_loss_proj:2.189 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=2.172 (perp=8.090, rec=0.059, cos=0.495), tot_loss_proj:2.195 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=2.175 (perp=8.090, rec=0.060, cos=0.497), tot_loss_proj:2.196 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=2.181 (perp=8.090, rec=0.066, cos=0.497), tot_loss_proj:2.197 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=2.184 (perp=8.090, rec=0.069, cos=0.496), tot_loss_proj:2.188 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=2.178 (perp=8.090, rec=0.064, cos=0.496), tot_loss_proj:2.200 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=2.180 (perp=8.090, rec=0.066, cos=0.496), tot_loss_proj:2.199 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.992 | p: 87.248 | r: 88.960
rouge2     | fm: 49.454 | p: 49.355 | r: 49.708
rougeL     | fm: 76.101 | p: 75.478 | r: 76.853
rougeLsum  | fm: 75.945 | p: 75.244 | r: 76.807
r1fm+r2fm = 137.446

input #53 time: 0:08:22 | total time: 7:55:08


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.7119138221027428
highest_index [0]
highest [0.7119138221027428]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.7812143564224243 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7670609951019287 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 0.7389241456985474 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6966016888618469 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6939648985862732 for ['[CLS]sil shall [SEP]']
[Init] best rec loss: 0.6651608347892761 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6415593028068542 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6345136761665344 for ['[CLS] wild exercised [SEP]']
[Init] best perm rec loss: 0.6339712142944336 for ['[CLS] exercised wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.298 (perp=8.197, rec=0.153, cos=0.506), tot_loss_proj:2.230 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=2.213 (perp=8.197, rec=0.082, cos=0.491), tot_loss_proj:2.219 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=2.190 (perp=8.197, rec=0.065, cos=0.486), tot_loss_proj:2.213 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=2.205 (perp=8.197, rec=0.071, cos=0.494), tot_loss_proj:2.211 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.191 (perp=8.197, rec=0.063, cos=0.488), tot_loss_proj:2.221 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=2.196 (perp=8.197, rec=0.062, cos=0.495), tot_loss_proj:2.211 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.184 (perp=8.197, rec=0.060, cos=0.485), tot_loss_proj:2.218 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.204 (perp=8.197, rec=0.068, cos=0.497), tot_loss_proj:2.219 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=2.179 (perp=8.197, rec=0.052, cos=0.488), tot_loss_proj:2.219 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.188 (perp=8.197, rec=0.060, cos=0.488), tot_loss_proj:2.215 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.182 (perp=8.197, rec=0.057, cos=0.486), tot_loss_proj:2.211 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=2.191 (perp=8.197, rec=0.056, cos=0.496), tot_loss_proj:2.214 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.194 (perp=8.197, rec=0.067, cos=0.487), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.182 (perp=8.197, rec=0.051, cos=0.491), tot_loss_proj:2.203 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=2.191 (perp=8.197, rec=0.060, cos=0.492), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.207 (perp=8.197, rec=0.076, cos=0.491), tot_loss_proj:2.223 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.208 (perp=8.197, rec=0.071, cos=0.497), tot_loss_proj:2.227 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=2.181 (perp=8.197, rec=0.054, cos=0.487), tot_loss_proj:2.213 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.185 (perp=8.197, rec=0.058, cos=0.488), tot_loss_proj:2.212 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=2.190 (perp=8.197, rec=0.061, cos=0.490), tot_loss_proj:2.208 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=2.189 (perp=8.197, rec=0.060, cos=0.490), tot_loss_proj:2.222 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=2.198 (perp=8.197, rec=0.070, cos=0.489), tot_loss_proj:2.217 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=2.193 (perp=8.197, rec=0.059, cos=0.494), tot_loss_proj:2.212 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=2.190 (perp=8.197, rec=0.061, cos=0.489), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=2.187 (perp=8.197, rec=0.058, cos=0.490), tot_loss_proj:2.212 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=2.192 (perp=8.197, rec=0.060, cos=0.493), tot_loss_proj:2.214 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=2.202 (perp=8.197, rec=0.069, cos=0.493), tot_loss_proj:2.221 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=2.182 (perp=8.197, rec=0.053, cos=0.489), tot_loss_proj:2.221 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=2.191 (perp=8.197, rec=0.065, cos=0.487), tot_loss_proj:2.225 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=2.194 (perp=8.197, rec=0.062, cos=0.492), tot_loss_proj:2.214 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=2.192 (perp=8.197, rec=0.059, cos=0.494), tot_loss_proj:2.228 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=2.192 (perp=8.197, rec=0.063, cos=0.489), tot_loss_proj:2.219 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=2.195 (perp=8.197, rec=0.063, cos=0.493), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=2.192 (perp=8.197, rec=0.067, cos=0.485), tot_loss_proj:2.228 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=2.191 (perp=8.197, rec=0.061, cos=0.490), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=2.183 (perp=8.197, rec=0.052, cos=0.491), tot_loss_proj:2.226 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=2.198 (perp=8.197, rec=0.068, cos=0.491), tot_loss_proj:2.215 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=2.184 (perp=8.197, rec=0.052, cos=0.493), tot_loss_proj:2.214 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=2.191 (perp=8.197, rec=0.059, cos=0.492), tot_loss_proj:2.217 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=2.182 (perp=8.197, rec=0.052, cos=0.491), tot_loss_proj:2.225 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.196 | p: 87.464 | r: 89.099
rouge2     | fm: 50.685 | p: 50.573 | r: 50.932
rougeL     | fm: 76.541 | p: 75.947 | r: 77.318
rougeLsum  | fm: 76.451 | p: 75.836 | r: 77.224
r1fm+r2fm = 138.881

input #54 time: 0:08:23 | total time: 8:03:32


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.724701371123168
highest_index [0]
highest [0.724701371123168]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8539469838142395 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7459869980812073 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7409271597862244 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7317299246788025 for ['[CLS] beneath besides milo [SEP]']
[Init] best rec loss: 0.7216024398803711 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7073600888252258 for ['[CLS] top trades events [SEP]']
[Init] best rec loss: 0.7063947319984436 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7046013474464417 for ['[CLS] holly post stride [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.626 (perp=9.584, rec=0.251, cos=0.459), tot_loss_proj:2.764 [t=0.21s]
prediction: ['[CLS] too settles easily [SEP]']
[ 100/2000] tot_loss=2.476 (perp=9.584, rec=0.090, cos=0.470), tot_loss_proj:2.772 [t=0.21s]
prediction: ['[CLS] too settles easily [SEP]']
[ 150/2000] tot_loss=2.463 (perp=9.584, rec=0.074, cos=0.472), tot_loss_proj:2.770 [t=0.21s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=2.451 (perp=9.584, rec=0.068, cos=0.467), tot_loss_proj:2.768 [t=0.21s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.274 (perp=8.670, rec=0.077, cos=0.463), tot_loss_proj:2.281 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=2.268 (perp=8.670, rec=0.065, cos=0.469), tot_loss_proj:2.273 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.268 (perp=8.670, rec=0.067, cos=0.468), tot_loss_proj:2.274 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.272 (perp=8.670, rec=0.064, cos=0.474), tot_loss_proj:2.272 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=2.276 (perp=8.670, rec=0.071, cos=0.470), tot_loss_proj:2.272 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.266 (perp=8.670, rec=0.065, cos=0.466), tot_loss_proj:2.270 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.269 (perp=8.670, rec=0.070, cos=0.464), tot_loss_proj:2.266 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=2.272 (perp=8.670, rec=0.066, cos=0.472), tot_loss_proj:2.274 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.265 (perp=8.670, rec=0.060, cos=0.471), tot_loss_proj:2.268 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.274 (perp=8.670, rec=0.070, cos=0.469), tot_loss_proj:2.274 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=2.269 (perp=8.670, rec=0.062, cos=0.473), tot_loss_proj:2.270 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.267 (perp=8.670, rec=0.060, cos=0.473), tot_loss_proj:2.273 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.276 (perp=8.670, rec=0.070, cos=0.472), tot_loss_proj:2.279 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=2.276 (perp=8.670, rec=0.068, cos=0.473), tot_loss_proj:2.282 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.272 (perp=8.670, rec=0.063, cos=0.475), tot_loss_proj:2.278 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=2.266 (perp=8.670, rec=0.059, cos=0.473), tot_loss_proj:2.284 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=2.266 (perp=8.670, rec=0.061, cos=0.471), tot_loss_proj:2.276 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=2.271 (perp=8.670, rec=0.060, cos=0.476), tot_loss_proj:2.276 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=2.263 (perp=8.670, rec=0.057, cos=0.472), tot_loss_proj:2.277 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=2.275 (perp=8.670, rec=0.069, cos=0.473), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=2.273 (perp=8.670, rec=0.066, cos=0.473), tot_loss_proj:2.274 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=2.272 (perp=8.670, rec=0.064, cos=0.474), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=2.276 (perp=8.670, rec=0.069, cos=0.473), tot_loss_proj:2.269 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=2.270 (perp=8.670, rec=0.063, cos=0.472), tot_loss_proj:2.270 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=2.272 (perp=8.670, rec=0.065, cos=0.473), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=2.272 (perp=8.670, rec=0.065, cos=0.473), tot_loss_proj:2.266 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=2.265 (perp=8.670, rec=0.057, cos=0.474), tot_loss_proj:2.274 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=2.269 (perp=8.670, rec=0.062, cos=0.473), tot_loss_proj:2.281 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=2.264 (perp=8.670, rec=0.058, cos=0.472), tot_loss_proj:2.279 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=2.265 (perp=8.670, rec=0.060, cos=0.471), tot_loss_proj:2.272 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=2.277 (perp=8.670, rec=0.070, cos=0.472), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=2.271 (perp=8.670, rec=0.063, cos=0.474), tot_loss_proj:2.271 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=2.268 (perp=8.670, rec=0.061, cos=0.474), tot_loss_proj:2.271 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=2.272 (perp=8.670, rec=0.064, cos=0.474), tot_loss_proj:2.268 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=2.273 (perp=8.670, rec=0.065, cos=0.474), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=2.275 (perp=8.670, rec=0.066, cos=0.474), tot_loss_proj:2.276 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.429 | p: 87.674 | r: 89.313
rouge2     | fm: 51.304 | p: 51.142 | r: 51.479
rougeL     | fm: 76.937 | p: 76.370 | r: 77.698
rougeLsum  | fm: 76.819 | p: 76.198 | r: 77.598
r1fm+r2fm = 139.732

input #55 time: 0:08:26 | total time: 8:11:58


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.7147573818349284
highest_index [0]
highest [0.7147573818349284]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8398758769035339 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.8222991824150085 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8164841532707214 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.816481351852417 for ['[CLS] charter technique unfortunately blame depression ; k sense backedured strike laid bear avid iron sympathy reflection en tis determined code [SEP]']
[Init] best perm rec loss: 0.8156955242156982 for ['[CLS] tis technique laid unfortunately blame charter strike bear sense k sympathy ; enured backed reflection avid depression code iron determined [SEP]']
[Init] best perm rec loss: 0.8148080110549927 for ['[CLS] backed bear iron sympathy k avidured charter strike code tis technique en unfortunately blame depression laid determined ; sense reflection [SEP]']
[Init] best perm rec loss: 0.8143869638442993 for ['[CLS] avid technique en k tis bear blame unfortunately depression strike reflection codeured sense iron determined sympathy ; laid backed charter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.308 (perp=12.483, rec=0.334, cos=0.477), tot_loss_proj:3.767 [t=0.21s]
prediction: ['[CLS] fund damage king mansion damage wastectum damage not destroyed : justified month heat horrible in curse throw hilda tournament bombs [SEP]']
[ 100/2000] tot_loss=3.132 (perp=12.052, rec=0.236, cos=0.486), tot_loss_proj:3.742 [t=0.22s]
prediction: ['[CLS] films american coming that damage costly analysis damage not destroyed ( justified films damage tons films curse loads hilda tournament damage [SEP]']
[ 150/2000] tot_loss=3.051 (perp=11.876, rec=0.188, cos=0.487), tot_loss_proj:3.633 [t=0.22s]
prediction: ['[CLS] films mls which of damage costly analysis damage that destroyed ( almost films caused loads decades repeal loads upper tournament damage [SEP]']
[ 200/2000] tot_loss=3.063 (perp=12.042, rec=0.169, cos=0.485), tot_loss_proj:3.845 [t=0.22s]
prediction: ['[CLS] filmsstellar which cause damage costly analysis damage that never yearsble analysis caused loads decades fix loads of tournament homes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.823 (perp=10.817, rec=0.171, cos=0.489), tot_loss_proj:3.291 [t=0.22s]
prediction: ['[CLS] films which cause damage costly analysis damage that never years obviously analysis cause loads decades of fix loadsial tournament damage [SEP]']
[ 300/2000] tot_loss=2.754 (perp=10.630, rec=0.142, cos=0.485), tot_loss_proj:3.145 [t=0.22s]
prediction: ['[CLS] films which will damage costly analysis damage that never years obviously analysis cause loads decades of fix loads never tournament never [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.760 (perp=10.750, rec=0.122, cos=0.488), tot_loss_proj:3.194 [t=0.22s]
prediction: ['[CLS] films which will tournament costly analysis damage that never years obviously analysis cause loads ರ of fix would could damage never [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.649 (perp=10.253, rec=0.111, cos=0.487), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] films which will tournament costly analysis damage that never years of analysis cause loads excuse obviously fix would could damage never [SEP]']
[ 450/2000] tot_loss=2.647 (perp=10.253, rec=0.108, cos=0.488), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] films which will tournament costly analysis damage that never years of analysis cause loads excuse obviously fix would could damage never [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.684 (perp=10.454, rec=0.106, cos=0.487), tot_loss_proj:3.018 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years of analysis tournament loads excusepara fix would could damage never [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.414 (perp=9.127, rec=0.100, cos=0.488), tot_loss_proj:2.798 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years of analysisble loads could ir fix would excuse damage never [SEP]']
[ 600/2000] tot_loss=2.472 (perp=9.455, rec=0.096, cos=0.485), tot_loss_proj:3.003 [t=0.22s]
prediction: ['[CLS] films which will cause costlypara damage that never years of analysisble loads could and fix could excuse damage never [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.236 (perp=8.284, rec=0.091, cos=0.488), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of and fix could excuse damage never [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.235 (perp=8.284, rec=0.091, cos=0.488), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of and fix could excuse damage never [SEP]']
[ 750/2000] tot_loss=2.235 (perp=8.284, rec=0.090, cos=0.488), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of and fix could excuse damage never [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.261 (perp=8.431, rec=0.087, cos=0.488), tot_loss_proj:2.641 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of originating and fix could damage never [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.195 (perp=8.071, rec=0.095, cos=0.486), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damage excuse and fix could never [SEP]']
[ 900/2000] tot_loss=2.192 (perp=8.071, rec=0.090, cos=0.488), tot_loss_proj:2.510 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damage excuse and fix could never [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.188 (perp=8.071, rec=0.085, cos=0.489), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damage excuse and fix could never [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.282 (perp=8.506, rec=0.092, cos=0.488), tot_loss_proj:2.726 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damagepara could fix and never [SEP]']
[1050/2000] tot_loss=2.273 (perp=8.506, rec=0.084, cos=0.488), tot_loss_proj:2.727 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damagepara could fix and never [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.234 (perp=8.307, rec=0.085, cos=0.488), tot_loss_proj:2.602 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damage couldpara fix and never [SEP]']
Attempt swap
[1150/2000] tot_loss=2.233 (perp=8.307, rec=0.083, cos=0.488), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damage couldpara fix and never [SEP]']
[1200/2000] tot_loss=2.229 (perp=8.307, rec=0.080, cos=0.487), tot_loss_proj:2.602 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that never years ofparable loads of damage couldpara fix and never [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.181 (perp=8.056, rec=0.082, cos=0.488), tot_loss_proj:2.442 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparable loads of damage couldpara fix and never [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.119 (perp=7.741, rec=0.084, cos=0.486), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage could fix and never [SEP]']
[1350/2000] tot_loss=2.120 (perp=7.741, rec=0.083, cos=0.488), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage could fix and never [SEP]']
Attempt swap
[1400/2000] tot_loss=2.119 (perp=7.741, rec=0.083, cos=0.488), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage could fix and never [SEP]']
Attempt swap
[1450/2000] tot_loss=2.121 (perp=7.741, rec=0.085, cos=0.488), tot_loss_proj:2.385 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage could fix and never [SEP]']
[1500/2000] tot_loss=2.122 (perp=7.741, rec=0.085, cos=0.489), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage could fix and never [SEP]']
Attempt swap
[1550/2000] tot_loss=2.119 (perp=7.741, rec=0.082, cos=0.489), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage could fix and never [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.109 (perp=7.680, rec=0.085, cos=0.488), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage fix and could never [SEP]']
[1650/2000] tot_loss=2.107 (perp=7.680, rec=0.083, cos=0.488), tot_loss_proj:2.395 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage fix and could never [SEP]']
Attempt swap
[1700/2000] tot_loss=2.108 (perp=7.680, rec=0.083, cos=0.489), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage that years of neverparaparable loads of damage fix and could never [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.071 (perp=7.494, rec=0.086, cos=0.486), tot_loss_proj:2.377 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]']
[1800/2000] tot_loss=2.068 (perp=7.494, rec=0.082, cos=0.487), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]']
Attempt swap
[1850/2000] tot_loss=2.066 (perp=7.494, rec=0.079, cos=0.488), tot_loss_proj:2.374 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]']
Attempt swap
[1900/2000] tot_loss=2.072 (perp=7.494, rec=0.085, cos=0.488), tot_loss_proj:2.374 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]']
[1950/2000] tot_loss=2.068 (perp=7.494, rec=0.082, cos=0.488), tot_loss_proj:2.376 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]']
Attempt swap
[2000/2000] tot_loss=2.065 (perp=7.494, rec=0.078, cos=0.488), tot_loss_proj:2.376 [t=0.22s]
prediction: ['[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films which will cause costly analysis damage and years of neverparaparable loads of damage fix that could never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 47.368 | p: 47.368 | r: 47.368
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 137.368

[Aggregate metrics]:
rouge1     | fm: 88.438 | p: 87.698 | r: 89.275
rouge2     | fm: 51.271 | p: 51.140 | r: 51.468
rougeL     | fm: 76.674 | p: 76.072 | r: 77.370
rougeLsum  | fm: 76.347 | p: 75.833 | r: 77.154
r1fm+r2fm = 139.710

input #56 time: 0:08:33 | total time: 8:20:32


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.7588243187750877
highest_index [0]
highest [0.7588243187750877]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8754433393478394 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.8575196862220764 for ['[CLS] their [SEP]']
[Init] best rec loss: 0.7977811098098755 for ['[CLS]on [SEP]']
[Init] best rec loss: 0.748296320438385 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6892183423042297 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6866894364356995 for ['[CLS] doubt [SEP]']
[Init] best rec loss: 0.6850098967552185 for ['[CLS] silk [SEP]']
[Init] best rec loss: 0.6805447936058044 for ['[CLS] beethoven [SEP]']
[Init] best rec loss: 0.6556513905525208 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.998 (perp=12.282, rec=0.142, cos=0.399), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.939 (perp=12.282, rec=0.071, cos=0.412), tot_loss_proj:2.943 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.936 (perp=12.282, rec=0.061, cos=0.418), tot_loss_proj:2.936 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.946 (perp=12.282, rec=0.070, cos=0.420), tot_loss_proj:2.944 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.936 (perp=12.282, rec=0.061, cos=0.418), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.940 (perp=12.282, rec=0.062, cos=0.422), tot_loss_proj:2.942 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.943 (perp=12.282, rec=0.069, cos=0.417), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.948 (perp=12.282, rec=0.071, cos=0.421), tot_loss_proj:2.936 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.930 (perp=12.282, rec=0.056, cos=0.417), tot_loss_proj:2.930 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.929 (perp=12.282, rec=0.054, cos=0.419), tot_loss_proj:2.942 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.946 (perp=12.282, rec=0.067, cos=0.423), tot_loss_proj:2.943 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.942 (perp=12.282, rec=0.070, cos=0.416), tot_loss_proj:2.938 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.933 (perp=12.282, rec=0.058, cos=0.419), tot_loss_proj:2.935 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.940 (perp=12.282, rec=0.060, cos=0.424), tot_loss_proj:2.938 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.925 (perp=12.282, rec=0.053, cos=0.415), tot_loss_proj:2.936 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.948 (perp=12.282, rec=0.068, cos=0.423), tot_loss_proj:2.942 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.945 (perp=12.282, rec=0.071, cos=0.418), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.929 (perp=12.282, rec=0.052, cos=0.421), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.947 (perp=12.282, rec=0.069, cos=0.422), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.938 (perp=12.282, rec=0.062, cos=0.420), tot_loss_proj:2.944 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.943 (perp=12.282, rec=0.064, cos=0.423), tot_loss_proj:2.936 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.952 (perp=12.282, rec=0.076, cos=0.420), tot_loss_proj:2.930 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.924 (perp=12.282, rec=0.047, cos=0.420), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.935 (perp=12.282, rec=0.058, cos=0.421), tot_loss_proj:2.949 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.936 (perp=12.282, rec=0.058, cos=0.422), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.940 (perp=12.282, rec=0.066, cos=0.417), tot_loss_proj:2.951 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.942 (perp=12.282, rec=0.062, cos=0.424), tot_loss_proj:2.938 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.934 (perp=12.282, rec=0.058, cos=0.420), tot_loss_proj:2.939 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.936 (perp=12.282, rec=0.057, cos=0.422), tot_loss_proj:2.946 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.940 (perp=12.282, rec=0.062, cos=0.422), tot_loss_proj:2.947 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.940 (perp=12.282, rec=0.062, cos=0.422), tot_loss_proj:2.934 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.944 (perp=12.282, rec=0.066, cos=0.422), tot_loss_proj:2.943 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.938 (perp=12.282, rec=0.059, cos=0.422), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.935 (perp=12.282, rec=0.055, cos=0.423), tot_loss_proj:2.943 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.931 (perp=12.282, rec=0.054, cos=0.421), tot_loss_proj:2.937 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.936 (perp=12.282, rec=0.058, cos=0.423), tot_loss_proj:2.942 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.941 (perp=12.282, rec=0.061, cos=0.424), tot_loss_proj:2.950 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.942 (perp=12.282, rec=0.062, cos=0.423), tot_loss_proj:2.939 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.951 (perp=12.282, rec=0.072, cos=0.423), tot_loss_proj:2.933 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.948 (perp=12.282, rec=0.069, cos=0.423), tot_loss_proj:2.945 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.636 | p: 87.970 | r: 89.496
rouge2     | fm: 52.078 | p: 51.967 | r: 52.305
rougeL     | fm: 77.053 | p: 76.444 | r: 77.827
rougeLsum  | fm: 76.856 | p: 76.236 | r: 77.583
r1fm+r2fm = 140.714

input #57 time: 0:08:27 | total time: 8:28:59


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.7395883803587022
highest_index [0]
highest [0.7395883803587022]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.0177767276763916 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.992488443851471 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9792225956916809 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9770839214324951 for ['[CLS]ety spider gmina hypothesisjali brett endorsedhof avoid " joinsop programme friends designated looks [SEP]']
[Init] best rec loss: 0.960149347782135 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9534997344017029 for ['[CLS] sure tel china lose neutral central never an there after louis concentratione jack boysnted [SEP]']
[Init] best rec loss: 0.9436283111572266 for ['[CLS] shield anything damon venom sitting led trumppole purdue bigاural failed proposal sketch lea [SEP]']
[Init] best rec loss: 0.9352499842643738 for ['[CLS] bellsignant river animals don cracked ace behind lid tasha des aden reception add bu fully [SEP]']
[Init] best perm rec loss: 0.9350971579551697 for ['[CLS] cracked animals bu behind tasha ace river add aden fully don lid bells receptionignant des [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.604 (perp=12.508, rec=0.642, cos=0.460), tot_loss_proj:4.449 [t=0.21s]
prediction: ['[CLS] funny asked my awful [SEP] june battlefield drowning ex another camp survivor sports shit arrival kylie [SEP]']
[ 100/2000] tot_loss=3.524 (perp=12.541, rec=0.573, cos=0.443), tot_loss_proj:4.417 [t=0.21s]
prediction: ['[CLS] nothing denied her tissue beer environmental officials eating animal another parliament on sports evil present kylie [SEP]']
[ 150/2000] tot_loss=3.236 (perp=11.740, rec=0.490, cos=0.398), tot_loss_proj:4.315 [t=0.21s]
prediction: ['[CLS] nothing denied her killing just encounter officials the animal alive parliament on providing courage chaplain kylie [SEP]']
[ 200/2000] tot_loss=3.261 (perp=11.609, rec=0.494, cos=0.445), tot_loss_proj:4.260 [t=0.21s]
prediction: ['[CLS] disbelief of compilation about [SEP] seating officials campus friend alive prison cd presents love chaplain kylie [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.315 (perp=12.295, rec=0.427, cos=0.429), tot_loss_proj:4.098 [t=0.21s]
prediction: ['[CLS] [SEP] of story about filmed friendship officials inspirational love love littletale prize love chaplain kylie [SEP]']
[ 300/2000] tot_loss=3.411 (perp=12.950, rec=0.426, cos=0.396), tot_loss_proj:4.126 [t=0.21s]
prediction: ['[CLS] game for story capturing filmed friendship officials inspirational love love reservedtale prize love chaplain mysteries [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.489 (perp=13.109, rec=0.438, cos=0.429), tot_loss_proj:4.558 [t=0.21s]
prediction: ['[CLS] childhood for compilation capturing sucker friendship emotional inspirational analogysezer most product love thing mysteries [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.030 (perp=10.984, rec=0.405, cos=0.428), tot_loss_proj:3.726 [t=0.21s]
prediction: ['[CLS] childhood of compilation capturing : issued emotional inspirational appreciatesezer approach story love moment mysteries [SEP]']
[ 450/2000] tot_loss=3.308 (perp=12.578, rec=0.377, cos=0.415), tot_loss_proj:3.960 [t=0.21s]
prediction: ['[CLS] inspirational of compilation the is unexpected emotional inspirationaloration aib approach story love moment mysteries [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.004 (perp=11.060, rec=0.368, cos=0.424), tot_loss_proj:3.814 [t=0.21s]
prediction: ['[CLS] inspirational of compilation the is unexpected emotional inspirational praised a moment approach story loveib mysteries [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.063 (perp=11.140, rec=0.358, cos=0.477), tot_loss_proj:3.911 [t=0.21s]
prediction: ['[CLS] inspirational compilation of the is continuous emotional inspirationalnal a moment approach [SEP] loveib mysteries [SEP]']
[ 600/2000] tot_loss=3.144 (perp=11.854, rec=0.351, cos=0.421), tot_loss_proj:4.073 [t=0.21s]
prediction: ['[CLS] inspirational compilation of the is continuous officials inspirationalnal themming approach [SEP] loveibhe [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.289 (perp=12.367, rec=0.345, cos=0.470), tot_loss_proj:4.168 [t=0.21s]
prediction: ['[CLS] inspirational compilation of the is continuous officials inspirational themming approach [SEP] parry love interactionhe [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.395 (perp=12.338, rec=0.478, cos=0.450), tot_loss_proj:4.285 [t=0.21s]
prediction: ['[CLS] inspirational compilation of officialsgingly continuous capturing inspirational anmming story shooting [SEP] love interaction mysteries [SEP]']
[ 750/2000] tot_loss=3.279 (perp=12.319, rec=0.382, cos=0.433), tot_loss_proj:3.922 [t=0.22s]
prediction: ['[CLS] inspirational compilation of medical several continuous capturing inspirational amming story honor [SEP] love interaction mysteries [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.951 (perp=10.804, rec=0.366, cos=0.425), tot_loss_proj:3.818 [t=0.21s]
prediction: ['[CLS] a compilation of medical was continuous the inspirational inspirationalmming approach sovereignty [SEP] love interaction mysteries [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.010 (perp=11.196, rec=0.359, cos=0.412), tot_loss_proj:4.197 [t=0.21s]
prediction: ['[CLS] a compilation nonsense medical was continuous the inspirational story approachmming storytelling [SEP] love interaction mysteries [SEP]']
[ 900/2000] tot_loss=3.049 (perp=11.328, rec=0.353, cos=0.431), tot_loss_proj:4.267 [t=0.21s]
prediction: ['[CLS] an story nonsense medical was continuous the inspirational story approachmming storytelling [SEP] love interaction mysteries [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.908 (perp=10.718, rec=0.344, cos=0.421), tot_loss_proj:4.153 [t=0.21s]
prediction: ['[CLS] an story nonsense medical continuous was the inspirational story approachmming storytelling [SEP] love interaction mysteries [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.914 (perp=10.877, rec=0.361, cos=0.378), tot_loss_proj:4.101 [t=0.21s]
prediction: ['[CLS] an story nonsense lovers continuous was the inspirational love inspirational approachmming sovereignty [SEP]bians mysteries [SEP]']
[1050/2000] tot_loss=2.956 (perp=10.877, rec=0.343, cos=0.438), tot_loss_proj:4.100 [t=0.21s]
prediction: ['[CLS] an story nonsense lovers continuous was the inspirational love inspirational approachmming sovereignty [SEP]bians mysteries [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.878 (perp=10.486, rec=0.341, cos=0.440), tot_loss_proj:4.009 [t=0.21s]
prediction: ['[CLS] an story lovers nonsense continuous was the inspirational love inspirational approachmming storytelling [SEP]bians mysteries [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.721 (perp=9.717, rec=0.338, cos=0.440), tot_loss_proj:3.938 [t=0.21s]
prediction: ['[CLS] an medical story nonsense continuous was the inspirational love story approachmming storytelling [SEP]bians mysteries [SEP]']
[1200/2000] tot_loss=2.713 (perp=9.717, rec=0.335, cos=0.434), tot_loss_proj:3.940 [t=0.21s]
prediction: ['[CLS] an medical story nonsense continuous was the inspirational love story approachmming storytelling [SEP]bians mysteries [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.896 (perp=10.555, rec=0.353, cos=0.432), tot_loss_proj:4.040 [t=0.21s]
prediction: ['[CLS] the account story nonsense identity was an inspirational love story approachmming creature [SEP]bianshe [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.800 (perp=10.055, rec=0.352, cos=0.437), tot_loss_proj:3.964 [t=0.21s]
prediction: ['[CLS] the account story nonsense identity was an inspirational love story approach creature [SEP]bians mysteriesmming [SEP]']
[1350/2000] tot_loss=2.740 (perp=9.740, rec=0.342, cos=0.449), tot_loss_proj:3.874 [t=0.21s]
prediction: ['[CLS] the account story nonsense continuous was an inspirational love story story creature [SEP]bians mysteriesmming [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.793 (perp=10.033, rec=0.333, cos=0.453), tot_loss_proj:3.871 [t=0.21s]
prediction: ['[CLS] the account story nonsense continuous was any inspirational story love story creature [SEP]bians mysteriesmming [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.757 (perp=9.960, rec=0.332, cos=0.433), tot_loss_proj:3.870 [t=0.21s]
prediction: ['[CLS] the account story nonsense identity was any inspirational story love story creature [SEP]biansmming mysteries [SEP]']
[1500/2000] tot_loss=2.749 (perp=9.884, rec=0.332, cos=0.441), tot_loss_proj:3.929 [t=0.21s]
prediction: ['[CLS] the lovers story nonsense identity was any inspirational story love story creature [SEP]biansmming mysteries [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.698 (perp=9.721, rec=0.326, cos=0.428), tot_loss_proj:3.866 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]biansmming mysteries [SEP]']
Attempt swap
[1600/2000] tot_loss=2.696 (perp=9.721, rec=0.328, cos=0.423), tot_loss_proj:3.869 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]biansmming mysteries [SEP]']
[1650/2000] tot_loss=2.704 (perp=9.721, rec=0.324, cos=0.436), tot_loss_proj:3.867 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]biansmming mysteries [SEP]']
Attempt swap
[1700/2000] tot_loss=2.722 (perp=9.824, rec=0.327, cos=0.430), tot_loss_proj:3.881 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]bians existence mysteries [SEP]']
Attempt swap
[1750/2000] tot_loss=2.721 (perp=9.824, rec=0.321, cos=0.435), tot_loss_proj:3.879 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]bians existence mysteries [SEP]']
[1800/2000] tot_loss=2.732 (perp=9.824, rec=0.325, cos=0.442), tot_loss_proj:3.880 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]bians existence mysteries [SEP]']
Attempt swap
[1850/2000] tot_loss=2.737 (perp=9.824, rec=0.323, cos=0.448), tot_loss_proj:3.878 [t=0.21s]
prediction: ['[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]bians existence mysteries [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.758 (perp=9.896, rec=0.326, cos=0.453), tot_loss_proj:3.891 [t=0.21s]
prediction: ['[CLS] the struggles lovers nonsense identity was any inspirational story love story existence bounds [SEP]bians mysteries [SEP]']
[1950/2000] tot_loss=2.758 (perp=9.896, rec=0.322, cos=0.456), tot_loss_proj:3.892 [t=0.21s]
prediction: ['[CLS] the struggles lovers nonsense identity was any inspirational story love story existence bounds [SEP]bians mysteries [SEP]']
Attempt swap
[2000/2000] tot_loss=2.752 (perp=9.896, rec=0.324, cos=0.449), tot_loss_proj:3.891 [t=0.21s]
prediction: ['[CLS] the struggles lovers nonsense identity was any inspirational story love story existence bounds [SEP]bians mysteries [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] the story lovers nonsense identity was any inspirational story love story bounds [SEP]bians existence mysteries [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 35.294 | p: 33.333 | r: 37.500
rouge2     | fm: 6.250 | p: 5.882 | r: 6.667
rougeL     | fm: 29.412 | p: 27.778 | r: 31.250
rougeLsum  | fm: 29.412 | p: 27.778 | r: 31.250
r1fm+r2fm = 41.544

[Aggregate metrics]:
rouge1     | fm: 87.624 | p: 86.930 | r: 88.585
rouge2     | fm: 51.456 | p: 51.323 | r: 51.630
rougeL     | fm: 76.456 | p: 75.794 | r: 77.169
rougeLsum  | fm: 76.188 | p: 75.562 | r: 76.939
r1fm+r2fm = 139.080

input #58 time: 0:08:28 | total time: 8:37:28


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.7348618358664076
highest_index [0]
highest [0.7348618358664076]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8944907784461975 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8553522229194641 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8468482494354248 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8287674784660339 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8080728650093079 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.7944597601890564 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.7855666279792786 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best perm rec loss: 0.7851386666297913 for ['[CLS] fringe war pepper knightsonate cricket counterpart tasting elitecoat vs warm helped mortal dinner creator [SEP]']
[Init] best perm rec loss: 0.7833107709884644 for ['[CLS] war creatoronate fringe elite warm knights helped mortal vscoat dinner pepper cricket tasting counterpart [SEP]']
[Init] best perm rec loss: 0.7831985354423523 for ['[CLS]coat vs creator cricket helped war counterpart warm fringe dinner pepper mortalonate knights tasting elite [SEP]']
[Init] best perm rec loss: 0.7822942733764648 for ['[CLS] pepper vs helped waronate creator mortal knights elite tastingcoat counterpart cricket fringe warm dinner [SEP]']
[Init] best perm rec loss: 0.7818005084991455 for ['[CLS] helped vs elite knights mortal war fringeonate tasting counterpart dinner cricket peppercoat warm creator [SEP]']
[Init] best perm rec loss: 0.7808988690376282 for ['[CLS] knights pepper counterpart war helped elite dinnercoat tasting fringe mortalonate vs warm creator cricket [SEP]']
[Init] best perm rec loss: 0.7806767225265503 for ['[CLS] vs creatoronate cricket warm elite counterpart fringe pepper war helpedcoat knights mortal dinner tasting [SEP]']
[Init] best perm rec loss: 0.7805486917495728 for ['[CLS] tasting fringe creator counterpartonate mortal war peppercoat warm knights dinner helped vs cricket elite [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.017 (perp=11.240, rec=0.312, cos=0.457), tot_loss_proj:3.440 [t=0.21s]
prediction: ['[CLS] indigenous ballet craft dominated cool young woman the has love trueo spirit of maternity australia [SEP]']
[ 100/2000] tot_loss=2.956 (perp=11.459, rec=0.208, cos=0.456), tot_loss_proj:3.405 [t=0.21s]
prediction: ['[CLS] young has char has the a woman the has feels charism ability ofism woman [SEP]']
[ 150/2000] tot_loss=2.763 (perp=10.680, rec=0.174, cos=0.452), tot_loss_proj:3.330 [t=0.21s]
prediction: ['[CLS] young has char has the a woman the who feels charism knows ofism woman [SEP]']
[ 200/2000] tot_loss=2.774 (perp=10.861, rec=0.133, cos=0.470), tot_loss_proj:3.613 [t=0.21s]
prediction: ['[CLS] young has char screen the a woman the who knows charism knows ofa screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.125 (perp=7.772, rec=0.117, cos=0.453), tot_loss_proj:3.011 [t=0.21s]
prediction: ['[CLS] young has char screen of a woman the who knows charisma knows of screen [SEP]']
[ 300/2000] tot_loss=2.145 (perp=7.924, rec=0.105, cos=0.455), tot_loss_proj:3.096 [t=0.21s]
prediction: ['[CLS] young has char screen of a woman the who how charisma knows of screen [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.947 (perp=6.977, rec=0.092, cos=0.460), tot_loss_proj:2.766 [t=0.21s]
prediction: ['[CLS] the young has char screen of a woman who how charisma knows of screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.938 (perp=6.977, rec=0.085, cos=0.458), tot_loss_proj:2.765 [t=0.21s]
prediction: ['[CLS] the young has char screen of a woman who how charisma knows of screen [SEP]']
[ 450/2000] tot_loss=1.927 (perp=6.977, rec=0.076, cos=0.456), tot_loss_proj:2.767 [t=0.21s]
prediction: ['[CLS] the young has char screen of a woman who how charisma knows of screen [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.890 (perp=6.699, rec=0.095, cos=0.455), tot_loss_proj:2.412 [t=0.21s]
prediction: ['[CLS] the young has char screen of a woman who knows how charisma of hold [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.868 (perp=6.699, rec=0.070, cos=0.458), tot_loss_proj:2.411 [t=0.21s]
prediction: ['[CLS] the young has char screen of a woman who knows how charisma of hold [SEP]']
[ 600/2000] tot_loss=1.883 (perp=6.699, rec=0.082, cos=0.461), tot_loss_proj:2.403 [t=0.21s]
prediction: ['[CLS] the young has char screen of a woman who knows how charisma of hold [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.859 (perp=6.648, rec=0.071, cos=0.458), tot_loss_proj:2.272 [t=0.21s]
prediction: ['[CLS] the young the char screen has a woman who knows how charisma of hold [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.778 (perp=6.218, rec=0.074, cos=0.460), tot_loss_proj:2.194 [t=0.21s]
prediction: ['[CLS] the young char screen has a woman who knows how the charisma of hold [SEP]']
[ 750/2000] tot_loss=1.784 (perp=6.218, rec=0.080, cos=0.460), tot_loss_proj:2.194 [t=0.21s]
prediction: ['[CLS] the young char screen has a woman who knows how the charisma of hold [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.732 (perp=6.010, rec=0.073, cos=0.457), tot_loss_proj:2.152 [t=0.21s]
prediction: ['[CLS] the char young screen has a woman who knows how the charisma of hold [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.735 (perp=6.010, rec=0.075, cos=0.458), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] the char young screen has a woman who knows how the charisma of hold [SEP]']
[ 900/2000] tot_loss=1.720 (perp=6.010, rec=0.062, cos=0.455), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] the char young screen has a woman who knows how the charisma of hold [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.624 (perp=5.472, rec=0.072, cos=0.458), tot_loss_proj:2.020 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows how the charisma of hold [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.585 (perp=5.281, rec=0.072, cos=0.456), tot_loss_proj:1.971 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1050/2000] tot_loss=1.585 (perp=5.281, rec=0.070, cos=0.459), tot_loss_proj:1.969 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1100/2000] tot_loss=1.586 (perp=5.281, rec=0.074, cos=0.456), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1150/2000] tot_loss=1.591 (perp=5.281, rec=0.076, cos=0.459), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1200/2000] tot_loss=1.576 (perp=5.281, rec=0.063, cos=0.457), tot_loss_proj:1.968 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1250/2000] tot_loss=1.585 (perp=5.281, rec=0.069, cos=0.459), tot_loss_proj:1.965 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1300/2000] tot_loss=1.594 (perp=5.281, rec=0.078, cos=0.460), tot_loss_proj:1.969 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1350/2000] tot_loss=1.581 (perp=5.281, rec=0.066, cos=0.459), tot_loss_proj:1.971 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1400/2000] tot_loss=1.591 (perp=5.281, rec=0.077, cos=0.458), tot_loss_proj:1.968 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1450/2000] tot_loss=1.585 (perp=5.281, rec=0.070, cos=0.459), tot_loss_proj:1.962 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1500/2000] tot_loss=1.582 (perp=5.281, rec=0.066, cos=0.460), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1550/2000] tot_loss=1.584 (perp=5.281, rec=0.069, cos=0.459), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1600/2000] tot_loss=1.582 (perp=5.281, rec=0.066, cos=0.459), tot_loss_proj:1.967 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1650/2000] tot_loss=1.585 (perp=5.281, rec=0.070, cos=0.459), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1700/2000] tot_loss=1.579 (perp=5.281, rec=0.064, cos=0.459), tot_loss_proj:1.966 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1750/2000] tot_loss=1.584 (perp=5.281, rec=0.069, cos=0.459), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1800/2000] tot_loss=1.578 (perp=5.281, rec=0.062, cos=0.460), tot_loss_proj:1.970 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1850/2000] tot_loss=1.587 (perp=5.281, rec=0.072, cos=0.458), tot_loss_proj:1.966 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.580 (perp=5.281, rec=0.065, cos=0.459), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
[1950/2000] tot_loss=1.580 (perp=5.281, rec=0.064, cos=0.459), tot_loss_proj:1.967 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.574 (perp=5.281, rec=0.059, cos=0.459), tot_loss_proj:1.970 [t=0.21s]
prediction: ['[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] the char screen has a young woman who knows the charisma of how hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 133.750

[Aggregate metrics]:
rouge1     | fm: 87.771 | p: 87.080 | r: 88.660
rouge2     | fm: 51.096 | p: 50.934 | r: 51.304
rougeL     | fm: 76.013 | p: 75.441 | r: 76.768
rougeLsum  | fm: 75.916 | p: 75.315 | r: 76.661
r1fm+r2fm = 138.867

input #59 time: 0:08:28 | total time: 8:45:57


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.7072260904028735
highest_index [0]
highest [0.7072260904028735]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9771099090576172 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9489021301269531 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.934065043926239 for ['[CLS] eddiedding whenly became northeast theo solid sighed signsrral frozen [SEP]']
[Init] best rec loss: 0.9160119891166687 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.9040629267692566 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.9025723934173584 for ['[CLS] bars bing sir set lyon nueva shutter hon featuring maybe voting land [SEP]']
[Init] best rec loss: 0.8944029808044434 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8904098868370056 for ['[CLS]chemist myselfkar waiting locking ribbon tear dreams mosaic dorothy sure... [SEP]']
[Init] best perm rec loss: 0.8900722861289978 for ['[CLS] waitingkar mosaic locking dorothychemist... tear sure ribbon myself dreams [SEP]']
[Init] best perm rec loss: 0.8870416879653931 for ['[CLS] waiting myself sure mosaic ribbon lockingchemist tear dreams dorothykar... [SEP]']
[Init] best perm rec loss: 0.8868128061294556 for ['[CLS] dreams waiting locking ribbon tearkar sure dorothy myself... mosaicchemist [SEP]']
[Init] best perm rec loss: 0.8861560821533203 for ['[CLS] mosaic tear dorothy ribbonchemist sure myself locking dreams waiting...kar [SEP]']
[Init] best perm rec loss: 0.8853963017463684 for ['[CLS] dreamschemist dorothy locking mosaic myself... sure waiting ribbon tearkar [SEP]']
[Init] best perm rec loss: 0.8847359418869019 for ['[CLS] dreams waiting dorothy locking tearchemist mosaic myself...kar ribbon sure [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.084 (perp=11.738, rec=0.245, cos=0.491), tot_loss_proj:3.711 [t=0.21s]
prediction: ['[CLS] circuit palestine yet awkwardly soap the is circuit fiction comic awkwardly monster [SEP]']
[ 100/2000] tot_loss=2.991 (perp=11.611, rec=0.172, cos=0.496), tot_loss_proj:3.536 [t=0.22s]
prediction: ['[CLS] circuit correspondser awkwardly soap is is is story was awkwardly story [SEP]']
[ 150/2000] tot_loss=3.030 (perp=11.892, rec=0.157, cos=0.494), tot_loss_proj:3.437 [t=0.22s]
prediction: ['[CLS] circuit wasping awkwardly soap is is is story was awkwardly opera [SEP]']
[ 200/2000] tot_loss=2.953 (perp=11.656, rec=0.128, cos=0.493), tot_loss_proj:3.675 [t=0.22s]
prediction: ['[CLS] circuit wash awkwardly soap is is is story was paced opera [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.624 (perp=10.041, rec=0.124, cos=0.492), tot_loss_proj:3.473 [t=0.22s]
prediction: ['[CLS] circuit ish awkwardly soap is is opera is story - paced [SEP]']
[ 300/2000] tot_loss=2.610 (perp=10.041, rec=0.106, cos=0.495), tot_loss_proj:3.474 [t=0.22s]
prediction: ['[CLS] circuit ish awkwardly soap is is opera is story - paced [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.495 (perp=9.520, rec=0.096, cos=0.496), tot_loss_proj:3.351 [t=0.22s]
prediction: ['[CLS] circuit ish awkwardly soap is - opera is story is paced [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.336 (perp=8.477, rec=0.149, cos=0.492), tot_loss_proj:2.974 [t=0.22s]
prediction: ['[CLS] is - circuit ish awkwardly soap opera is story is paced [SEP]']
[ 450/2000] tot_loss=2.283 (perp=8.477, rec=0.094, cos=0.493), tot_loss_proj:2.969 [t=0.22s]
prediction: ['[CLS] is - circuit ish awkwardly soap opera is story is paced [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.254 (perp=8.323, rec=0.094, cos=0.495), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] is - circuit ish soap opera is story is awkwardly paced [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.197 (perp=7.872, rec=0.128, cos=0.495), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] is - ish circuit soap opera is story is awkwardly paced [SEP]']
[ 600/2000] tot_loss=2.166 (perp=7.872, rec=0.092, cos=0.499), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] is - ish circuit soap opera is story is awkwardly paced [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.159 (perp=7.872, rec=0.088, cos=0.496), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] is - ish circuit soap opera is story is awkwardly paced [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.157 (perp=7.872, rec=0.086, cos=0.496), tot_loss_proj:2.478 [t=0.22s]
prediction: ['[CLS] is - ish circuit soap opera is story is awkwardly paced [SEP]']
[ 750/2000] tot_loss=2.153 (perp=7.872, rec=0.083, cos=0.496), tot_loss_proj:2.477 [t=0.22s]
prediction: ['[CLS] is - ish circuit soap opera is story is awkwardly paced [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.384 (perp=9.027, rec=0.082, cos=0.497), tot_loss_proj:2.721 [t=0.22s]
prediction: ['[CLS] is -.h circuit soap opera is story is awkwardly paced [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.266 (perp=8.354, rec=0.097, cos=0.498), tot_loss_proj:2.524 [t=0.22s]
prediction: ['[CLS] the - ish circuit soap opera is story is awkwardly paced [SEP]']
[ 900/2000] tot_loss=2.248 (perp=8.354, rec=0.079, cos=0.498), tot_loss_proj:2.530 [t=0.22s]
prediction: ['[CLS] the - ish circuit soap opera is story is awkwardly paced [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.183 (perp=8.029, rec=0.079, cos=0.498), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1000/2000] tot_loss=2.185 (perp=8.029, rec=0.082, cos=0.497), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1050/2000] tot_loss=2.184 (perp=8.029, rec=0.082, cos=0.496), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1100/2000] tot_loss=2.183 (perp=8.029, rec=0.081, cos=0.496), tot_loss_proj:2.488 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1150/2000] tot_loss=2.181 (perp=8.029, rec=0.079, cos=0.496), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1200/2000] tot_loss=2.183 (perp=8.029, rec=0.080, cos=0.497), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1250/2000] tot_loss=2.181 (perp=8.029, rec=0.079, cos=0.496), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1300/2000] tot_loss=2.178 (perp=8.029, rec=0.076, cos=0.496), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1350/2000] tot_loss=2.175 (perp=8.029, rec=0.073, cos=0.496), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.182 (perp=8.029, rec=0.080, cos=0.496), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1450/2000] tot_loss=2.179 (perp=8.029, rec=0.076, cos=0.497), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1500/2000] tot_loss=2.182 (perp=8.029, rec=0.080, cos=0.496), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1550/2000] tot_loss=2.179 (perp=8.029, rec=0.077, cos=0.496), tot_loss_proj:2.495 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1600/2000] tot_loss=2.175 (perp=8.029, rec=0.073, cos=0.497), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1650/2000] tot_loss=2.178 (perp=8.029, rec=0.075, cos=0.497), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1700/2000] tot_loss=2.180 (perp=8.029, rec=0.078, cos=0.496), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1750/2000] tot_loss=2.184 (perp=8.029, rec=0.082, cos=0.497), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1800/2000] tot_loss=2.172 (perp=8.029, rec=0.069, cos=0.496), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1850/2000] tot_loss=2.187 (perp=8.029, rec=0.084, cos=0.497), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[1900/2000] tot_loss=2.181 (perp=8.029, rec=0.079, cos=0.496), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
[1950/2000] tot_loss=2.178 (perp=8.029, rec=0.076, cos=0.497), tot_loss_proj:2.501 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Attempt swap
[2000/2000] tot_loss=2.176 (perp=8.029, rec=0.074, cos=0.496), tot_loss_proj:2.496 [t=0.22s]
prediction: ['[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] the - ish soap opera circuit is story is awkwardly paced [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 28.571 | p: 27.273 | r: 30.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 124.224

[Aggregate metrics]:
rouge1     | fm: 87.906 | p: 87.141 | r: 88.883
rouge2     | fm: 50.801 | p: 50.697 | r: 51.032
rougeL     | fm: 75.594 | p: 74.995 | r: 76.394
rougeLsum  | fm: 75.487 | p: 74.834 | r: 76.276
r1fm+r2fm = 138.707

input #60 time: 0:08:35 | total time: 8:54:32


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.7355328645108741
highest_index [0]
highest [0.7355328645108741]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9725897908210754 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9715805053710938 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9588899612426758 for ['[CLS] alta http cocked [SEP]']
[Init] best rec loss: 0.9548115134239197 for ['[CLS] tiny poor rail [SEP]']
[Init] best rec loss: 0.9476250410079956 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 0.9251911044120789 for ['[CLS] mouth lastless [SEP]']
[Init] best rec loss: 0.9173107743263245 for ['[CLS] readyppetphonic [SEP]']
[Init] best rec loss: 0.88209068775177 for ['[CLS] says -vino [SEP]']
[Init] best rec loss: 0.870582640171051 for ['[CLS] vehicle surrounding south [SEP]']
[Init] best perm rec loss: 0.8681391477584839 for ['[CLS] surrounding vehicle south [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.209 (perp=7.752, rec=0.197, cos=0.462), tot_loss_proj:2.314 [t=0.21s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=2.172 (perp=7.752, rec=0.162, cos=0.460), tot_loss_proj:2.305 [t=0.21s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 150/2000] tot_loss=2.170 (perp=7.752, rec=0.159, cos=0.461), tot_loss_proj:2.307 [t=0.21s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 200/2000] tot_loss=2.158 (perp=7.752, rec=0.149, cos=0.459), tot_loss_proj:2.311 [t=0.21s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.153 (perp=7.752, rec=0.143, cos=0.459), tot_loss_proj:2.317 [t=0.21s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 300/2000] tot_loss=2.132 (perp=7.752, rec=0.123, cos=0.458), tot_loss_proj:2.311 [t=0.21s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.184 (perp=8.296, rec=0.068, cos=0.456), tot_loss_proj:2.397 [t=0.21s]
prediction: ['[CLS] beautiful, scene [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.947 (perp=7.102, rec=0.070, cos=0.457), tot_loss_proj:2.096 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.943 (perp=7.102, rec=0.064, cos=0.458), tot_loss_proj:2.102 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.948 (perp=7.102, rec=0.070, cos=0.458), tot_loss_proj:2.098 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.952 (perp=7.102, rec=0.072, cos=0.459), tot_loss_proj:2.092 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.942 (perp=7.102, rec=0.063, cos=0.459), tot_loss_proj:2.101 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.941 (perp=7.102, rec=0.062, cos=0.459), tot_loss_proj:2.104 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.938 (perp=7.102, rec=0.059, cos=0.458), tot_loss_proj:2.094 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.951 (perp=7.102, rec=0.072, cos=0.459), tot_loss_proj:2.104 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.954 (perp=7.102, rec=0.075, cos=0.459), tot_loss_proj:2.103 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.941 (perp=7.102, rec=0.062, cos=0.459), tot_loss_proj:2.104 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.939 (perp=7.102, rec=0.059, cos=0.459), tot_loss_proj:2.098 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.945 (perp=7.102, rec=0.066, cos=0.459), tot_loss_proj:2.092 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.947 (perp=7.102, rec=0.068, cos=0.459), tot_loss_proj:2.096 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.943 (perp=7.102, rec=0.064, cos=0.459), tot_loss_proj:2.100 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.933 (perp=7.102, rec=0.054, cos=0.459), tot_loss_proj:2.110 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.939 (perp=7.102, rec=0.060, cos=0.458), tot_loss_proj:2.101 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.945 (perp=7.102, rec=0.066, cos=0.458), tot_loss_proj:2.094 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.936 (perp=7.102, rec=0.057, cos=0.459), tot_loss_proj:2.105 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.944 (perp=7.102, rec=0.065, cos=0.459), tot_loss_proj:2.095 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.954 (perp=7.102, rec=0.075, cos=0.459), tot_loss_proj:2.102 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.946 (perp=7.102, rec=0.067, cos=0.459), tot_loss_proj:2.099 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.937 (perp=7.102, rec=0.058, cos=0.458), tot_loss_proj:2.099 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.947 (perp=7.102, rec=0.068, cos=0.458), tot_loss_proj:2.104 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.943 (perp=7.102, rec=0.064, cos=0.459), tot_loss_proj:2.095 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.944 (perp=7.102, rec=0.065, cos=0.459), tot_loss_proj:2.099 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.939 (perp=7.102, rec=0.060, cos=0.459), tot_loss_proj:2.095 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.942 (perp=7.102, rec=0.063, cos=0.459), tot_loss_proj:2.095 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.951 (perp=7.102, rec=0.071, cos=0.459), tot_loss_proj:2.095 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.932 (perp=7.102, rec=0.053, cos=0.459), tot_loss_proj:2.108 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.941 (perp=7.102, rec=0.062, cos=0.459), tot_loss_proj:2.100 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.938 (perp=7.102, rec=0.059, cos=0.459), tot_loss_proj:2.096 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.937 (perp=7.102, rec=0.058, cos=0.459), tot_loss_proj:2.093 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.950 (perp=7.102, rec=0.071, cos=0.459), tot_loss_proj:2.099 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.050 | p: 87.310 | r: 89.018
rouge2     | fm: 51.729 | p: 51.578 | r: 51.909
rougeL     | fm: 76.117 | p: 75.497 | r: 76.825
rougeLsum  | fm: 75.914 | p: 75.287 | r: 76.687
r1fm+r2fm = 139.778

input #61 time: 0:08:26 | total time: 9:02:59


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.7317994572448763
highest_index [0]
highest [0.7317994572448763]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9210729002952576 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.905992329120636 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.9051110148429871 for ['[CLS] young dance sacrifice cross regular drove huffington trip client gloss chosen butte actually t running buywide sms custom floating mug [SEP]']
[Init] best rec loss: 0.8967021107673645 for ['[CLS] potential sub practice had e european recruitingsight probable conversion plates rubang taxes braced theorem themselves nu us wolfe mid [SEP]']
[Init] best rec loss: 0.8963715434074402 for ['[CLS] did is ruled shooting boarding craters verseverse cartoon mickey counts jones period opposed inside incentiveshua together circle nw 16 [SEP]']
[Init] best rec loss: 0.894221305847168 for ['[CLS]ining strata won suitedtis near isaac bull worship here techp perhaps assistant kerman negative fisulsion ash too skill [SEP]']
[Init] best rec loss: 0.8912068605422974 for ['[CLS] largest absent prize viewer onradbius sector pastoral servant grown [CLS]oire meant utc academy forces closed laid clock full [SEP]']
[Init] best rec loss: 0.8899855017662048 for ['[CLS]ecure armedria obvious commission symbol echo drinking testified mothergaard reacher executive dressed playing but name ups [SEP] [MASK] kala [SEP]']
[Init] best rec loss: 0.8800894618034363 for ['[CLS] part remembered victor jayne imagined♭ basket against cheeks barrow battalion whilefold informed had higher outstanding ezio ramirez malta pinyin [SEP]']
[Init] best perm rec loss: 0.8783897161483765 for ['[CLS]♭ battalion jayne barrow malta informed victor remembered ramirez cheeks imagined hadfold basket against outstanding part while ezio higher pinyin [SEP]']
[Init] best perm rec loss: 0.8767086863517761 for ['[CLS] battalion♭ while higher barrow against pinyin informed victor basketfold ezio jayne had remembered ramirez malta part cheeks outstanding imagined [SEP]']
[Init] best perm rec loss: 0.8766442537307739 for ['[CLS] part had basket informed ezio cheeks while outstandingfold battalion pinyin imagined jayne victor ramirez♭ malta higher remembered against barrow [SEP]']
[Init] best perm rec loss: 0.8753459453582764 for ['[CLS] higher basket barrow battalion while maltafold against jayne ramirez informed victor pinyin ezio♭ outstanding remembered had imagined part cheeks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.194 (perp=11.885, rec=0.367, cos=0.450), tot_loss_proj:3.623 [t=0.21s]
prediction: ['[CLS] wonderful produce atlantic even co r prevention episode grace broncos grace values such super performances cool calculated of : documentary handling [SEP]']
[ 100/2000] tot_loss=2.996 (perp=11.407, rec=0.274, cos=0.441), tot_loss_proj:3.968 [t=0.22s]
prediction: ['[CLS] best produce traffic even without for prevention episode grace war seeing blame among something grace - war it best usual movies [SEP]']
[ 150/2000] tot_loss=2.804 (perp=10.668, rec=0.220, cos=0.450), tot_loss_proj:3.520 [t=0.22s]
prediction: ['[CLS] best making traffic to without for prevention although grace grace grace prevention of one grace of war it best brave movies [SEP]']
[ 200/2000] tot_loss=2.546 (perp=9.558, rec=0.182, cos=0.452), tot_loss_proj:3.842 [t=0.22s]
prediction: ['[CLS] best making call to without for prevention than grace grace to prevention of one grace the war to ever war movies [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.314 (perp=8.537, rec=0.154, cos=0.453), tot_loss_proj:3.607 [t=0.22s]
prediction: ['[CLS] best making call to grace for prevention than grace grace to prevention of one to the war to ever war movies [SEP]']
[ 300/2000] tot_loss=2.538 (perp=9.786, rec=0.124, cos=0.457), tot_loss_proj:3.861 [t=0.22s]
prediction: ['[CLS] best making to to grace for prevention than grace grace of prevention of one call the war made ever war movies [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.459 (perp=9.436, rec=0.111, cos=0.460), tot_loss_proj:3.732 [t=0.22s]
prediction: ['[CLS] best making to grace for prevention rather grace to grace it prevention of one call the war made ever ever movies [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.267 (perp=8.574, rec=0.089, cos=0.464), tot_loss_proj:3.408 [t=0.22s]
prediction: ['[CLS] best making to grace for prevention rather grace, grace it prevention of one call the war movies ever ever made [SEP]']
[ 450/2000] tot_loss=2.263 (perp=8.574, rec=0.085, cos=0.463), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS] best making to grace for prevention rather grace, grace it prevention of one call the war movies ever ever made [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.180 (perp=8.158, rec=0.086, cos=0.463), tot_loss_proj:3.398 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, grace it prevention of one call the war movies ever ever made [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.113 (perp=7.831, rec=0.083, cos=0.464), tot_loss_proj:3.230 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, grace it prevention of call one the war movies ever ever made [SEP]']
[ 600/2000] tot_loss=2.106 (perp=7.831, rec=0.077, cos=0.463), tot_loss_proj:3.229 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, grace it prevention of call one the war movies ever ever made [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.152 (perp=7.994, rec=0.090, cos=0.463), tot_loss_proj:3.447 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, blame it prevention call of one the war movies ever ever made [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.087 (perp=7.678, rec=0.088, cos=0.463), tot_loss_proj:3.419 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, blame it one prevention call of the war movies ever ever made [SEP]']
[ 750/2000] tot_loss=2.078 (perp=7.678, rec=0.079, cos=0.463), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, blame it one prevention call of the war movies ever ever made [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.069 (perp=7.678, rec=0.071, cos=0.463), tot_loss_proj:3.418 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, blame it one prevention call of the war movies ever ever made [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.010 (perp=7.327, rec=0.081, cos=0.464), tot_loss_proj:3.164 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, blame it call prevention one of the war movies ever ever made [SEP]']
[ 900/2000] tot_loss=2.001 (perp=7.327, rec=0.072, cos=0.463), tot_loss_proj:3.165 [t=0.22s]
prediction: ['[CLS] best making to grace for grace rather prevention, blame it call prevention one of the war movies ever ever made [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.982 (perp=7.188, rec=0.081, cos=0.463), tot_loss_proj:3.120 [t=0.22s]
prediction: ['[CLS] best to grace for making grace rather prevention, blame it call prevention one of the war movies ever ever made [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.958 (perp=7.112, rec=0.072, cos=0.463), tot_loss_proj:3.078 [t=0.22s]
prediction: ['[CLS] best to grace for making grace rather prevention, blame it call prevention one of the war movies ever made ever [SEP]']
[1050/2000] tot_loss=2.023 (perp=7.420, rec=0.075, cos=0.464), tot_loss_proj:3.251 [t=0.22s]
prediction: ['[CLS] best to grace for making grace rather prevention, blame it call prevention one of the war movies ever made should [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=7.420, rec=0.075, cos=0.464), tot_loss_proj:3.253 [t=0.22s]
prediction: ['[CLS] best to grace for making grace rather prevention, blame it call prevention one of the war movies ever made should [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.979 (perp=7.226, rec=0.072, cos=0.461), tot_loss_proj:3.271 [t=0.22s]
prediction: ['[CLS] best to grace for should grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
[1200/2000] tot_loss=1.984 (perp=7.226, rec=0.074, cos=0.464), tot_loss_proj:3.271 [t=0.22s]
prediction: ['[CLS] best to grace for should grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
[1250/2000] tot_loss=1.986 (perp=7.226, rec=0.076, cos=0.464), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS] best to grace for should grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.008 (perp=7.349, rec=0.075, cos=0.463), tot_loss_proj:3.217 [t=0.22s]
prediction: ['[CLS] best to blame for grace grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
[1350/2000] tot_loss=2.009 (perp=7.349, rec=0.076, cos=0.463), tot_loss_proj:3.215 [t=0.22s]
prediction: ['[CLS] best to blame for grace grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.993 (perp=7.263, rec=0.076, cos=0.464), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
[1450/2000] tot_loss=1.995 (perp=7.263, rec=0.078, cos=0.464), tot_loss_proj:3.319 [t=0.22s]
prediction: ['[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
[1500/2000] tot_loss=1.989 (perp=7.263, rec=0.072, cos=0.464), tot_loss_proj:3.320 [t=0.22s]
prediction: ['[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
[1550/2000] tot_loss=1.989 (perp=7.263, rec=0.073, cos=0.464), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
[1600/2000] tot_loss=1.997 (perp=7.263, rec=0.081, cos=0.464), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
[1650/2000] tot_loss=1.990 (perp=7.263, rec=0.074, cos=0.464), tot_loss_proj:3.320 [t=0.22s]
prediction: ['[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.970 (perp=7.185, rec=0.069, cos=0.464), tot_loss_proj:3.165 [t=0.22s]
prediction: ['[CLS] grace to blame best for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.956 (perp=7.063, rec=0.079, cos=0.464), tot_loss_proj:3.093 [t=0.22s]
prediction: ['[CLS] grace to blame best for grace rather prevention, blame it call prevention one of the making war movies ever made [SEP]']
[1800/2000] tot_loss=1.950 (perp=7.063, rec=0.073, cos=0.464), tot_loss_proj:3.090 [t=0.22s]
prediction: ['[CLS] grace to blame best for grace rather prevention, blame it call prevention one of the making war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.863 (perp=6.643, rec=0.070, cos=0.464), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] grace to blame making for grace rather prevention, blame it call prevention one of the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.868 (perp=6.643, rec=0.075, cos=0.464), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] grace to blame making for grace rather prevention, blame it call prevention one of the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.859 (perp=6.643, rec=0.066, cos=0.464), tot_loss_proj:2.729 [t=0.22s]
prediction: ['[CLS] grace to blame making for grace rather prevention, blame it call prevention one of the best war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.867 (perp=6.643, rec=0.075, cos=0.464), tot_loss_proj:2.721 [t=0.22s]
prediction: ['[CLS] grace to blame making for grace rather prevention, blame it call prevention one of the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] best to blame grace for grace rather prevention, blame it call prevention one of the war movies ever made making [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.364 | p: 86.364 | r: 86.364
rouge2     | fm: 23.810 | p: 23.810 | r: 23.810
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 110.173

[Aggregate metrics]:
rouge1     | fm: 88.029 | p: 87.288 | r: 88.982
rouge2     | fm: 51.074 | p: 50.957 | r: 51.255
rougeL     | fm: 75.868 | p: 75.282 | r: 76.616
rougeLsum  | fm: 75.605 | p: 74.987 | r: 76.366
r1fm+r2fm = 139.102

input #62 time: 0:08:33 | total time: 9:11:32


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.7123452051600621
highest_index [0]
highest [0.7123452051600621]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8033862113952637 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7174710631370544 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.6863371729850769 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best perm rec loss: 0.6834084987640381 for ['[CLS] written workingism brighter spend [SEP]']
[Init] best perm rec loss: 0.6822679042816162 for ['[CLS] written spend working brighterism [SEP]']
[Init] best perm rec loss: 0.6815295815467834 for ['[CLS] brighter writtenism spend working [SEP]']
[Init] best perm rec loss: 0.6810320615768433 for ['[CLS] working brighterism spend written [SEP]']
[Init] best perm rec loss: 0.6807101368904114 for ['[CLS] working writtenism spend brighter [SEP]']
[Init] best perm rec loss: 0.6798429489135742 for ['[CLS] brighter writtenism working spend [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.512 (perp=9.429, rec=0.144, cos=0.483), tot_loss_proj:2.805 [t=0.21s]
prediction: ['[CLS] looking return for return ticket [SEP]']
[ 100/2000] tot_loss=2.464 (perp=9.429, rec=0.087, cos=0.492), tot_loss_proj:2.832 [t=0.21s]
prediction: ['[CLS] looking return for return ticket [SEP]']
[ 150/2000] tot_loss=2.465 (perp=9.429, rec=0.089, cos=0.490), tot_loss_proj:2.851 [t=0.21s]
prediction: ['[CLS] looking return for return ticket [SEP]']
[ 200/2000] tot_loss=2.500 (perp=9.657, rec=0.076, cos=0.493), tot_loss_proj:2.636 [t=0.22s]
prediction: ['[CLS] looking a for return ticket [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.781 (perp=6.111, rec=0.069, cos=0.490), tot_loss_proj:1.805 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 300/2000] tot_loss=1.778 (perp=6.111, rec=0.069, cos=0.487), tot_loss_proj:1.796 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.779 (perp=6.111, rec=0.063, cos=0.494), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.770 (perp=6.111, rec=0.059, cos=0.489), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.781 (perp=6.111, rec=0.072, cos=0.487), tot_loss_proj:1.801 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.765 (perp=6.111, rec=0.051, cos=0.492), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.781 (perp=6.111, rec=0.071, cos=0.488), tot_loss_proj:1.800 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.773 (perp=6.111, rec=0.060, cos=0.490), tot_loss_proj:1.800 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.771 (perp=6.111, rec=0.059, cos=0.489), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.778 (perp=6.111, rec=0.064, cos=0.492), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.778 (perp=6.111, rec=0.064, cos=0.491), tot_loss_proj:1.789 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.763 (perp=6.111, rec=0.050, cos=0.490), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=6.111, rec=0.060, cos=0.491), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.791 (perp=6.111, rec=0.076, cos=0.493), tot_loss_proj:1.796 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.776 (perp=6.111, rec=0.062, cos=0.492), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.781 (perp=6.111, rec=0.067, cos=0.492), tot_loss_proj:1.799 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.778 (perp=6.111, rec=0.065, cos=0.491), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.774 (perp=6.111, rec=0.060, cos=0.491), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.779 (perp=6.111, rec=0.065, cos=0.491), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.771 (perp=6.111, rec=0.058, cos=0.491), tot_loss_proj:1.805 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.783 (perp=6.111, rec=0.070, cos=0.491), tot_loss_proj:1.799 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.773 (perp=6.111, rec=0.060, cos=0.491), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.777 (perp=6.111, rec=0.064, cos=0.490), tot_loss_proj:1.800 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.776 (perp=6.111, rec=0.063, cos=0.491), tot_loss_proj:1.807 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.773 (perp=6.111, rec=0.060, cos=0.491), tot_loss_proj:1.801 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.774 (perp=6.111, rec=0.061, cos=0.491), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.774 (perp=6.111, rec=0.061, cos=0.491), tot_loss_proj:1.794 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.772 (perp=6.111, rec=0.058, cos=0.491), tot_loss_proj:1.801 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.775 (perp=6.111, rec=0.062, cos=0.491), tot_loss_proj:1.800 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.776 (perp=6.111, rec=0.062, cos=0.492), tot_loss_proj:1.799 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.773 (perp=6.111, rec=0.058, cos=0.492), tot_loss_proj:1.802 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.781 (perp=6.111, rec=0.066, cos=0.493), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.778 (perp=6.111, rec=0.064, cos=0.492), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.770 (perp=6.111, rec=0.056, cos=0.491), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.786 (perp=6.111, rec=0.072, cos=0.492), tot_loss_proj:1.806 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.769 (perp=6.111, rec=0.056, cos=0.491), tot_loss_proj:1.802 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.254 | p: 87.525 | r: 89.224
rouge2     | fm: 51.711 | p: 51.578 | r: 51.930
rougeL     | fm: 76.262 | p: 75.749 | r: 76.883
rougeLsum  | fm: 75.995 | p: 75.356 | r: 76.760
r1fm+r2fm = 139.965

input #63 time: 0:08:29 | total time: 9:20:02


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.7208703479260095
highest_index [0]
highest [0.7208703479260095]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8799864053726196 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8242798447608948 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.811712384223938 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.7265528440475464 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6764474511146545 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6737751364707947 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.376 (perp=8.653, rec=0.169, cos=0.476), tot_loss_proj:2.504 [t=0.21s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=2.702 (perp=10.665, rec=0.088, cos=0.480), tot_loss_proj:2.881 [t=0.21s]
prediction: ['[CLS] strange horror the [SEP]']
[ 150/2000] tot_loss=2.678 (perp=10.665, rec=0.075, cos=0.470), tot_loss_proj:2.890 [t=0.21s]
prediction: ['[CLS] strange horror the [SEP]']
[ 200/2000] tot_loss=2.678 (perp=10.665, rec=0.068, cos=0.476), tot_loss_proj:2.891 [t=0.21s]
prediction: ['[CLS] strange horror the [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.167 (perp=8.065, rec=0.078, cos=0.476), tot_loss_proj:2.183 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=2.154 (perp=8.065, rec=0.067, cos=0.473), tot_loss_proj:2.194 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.158 (perp=8.065, rec=0.069, cos=0.476), tot_loss_proj:2.185 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.148 (perp=8.065, rec=0.061, cos=0.473), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=2.147 (perp=8.065, rec=0.056, cos=0.478), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.159 (perp=8.065, rec=0.067, cos=0.479), tot_loss_proj:2.197 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.154 (perp=8.065, rec=0.063, cos=0.477), tot_loss_proj:2.182 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=2.150 (perp=8.065, rec=0.066, cos=0.471), tot_loss_proj:2.198 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.145 (perp=8.065, rec=0.054, cos=0.478), tot_loss_proj:2.182 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.144 (perp=8.065, rec=0.056, cos=0.474), tot_loss_proj:2.190 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=2.165 (perp=8.065, rec=0.074, cos=0.479), tot_loss_proj:2.182 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.151 (perp=8.065, rec=0.065, cos=0.473), tot_loss_proj:2.197 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.161 (perp=8.065, rec=0.069, cos=0.480), tot_loss_proj:2.172 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=2.156 (perp=8.065, rec=0.068, cos=0.474), tot_loss_proj:2.186 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.150 (perp=8.065, rec=0.059, cos=0.477), tot_loss_proj:2.188 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=2.156 (perp=8.065, rec=0.065, cos=0.478), tot_loss_proj:2.185 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=2.155 (perp=8.065, rec=0.064, cos=0.478), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=2.137 (perp=8.065, rec=0.046, cos=0.478), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=2.150 (perp=8.065, rec=0.060, cos=0.477), tot_loss_proj:2.188 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=2.148 (perp=8.065, rec=0.056, cos=0.479), tot_loss_proj:2.195 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=2.157 (perp=8.065, rec=0.064, cos=0.480), tot_loss_proj:2.191 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=2.157 (perp=8.065, rec=0.065, cos=0.479), tot_loss_proj:2.181 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=2.148 (perp=8.065, rec=0.056, cos=0.479), tot_loss_proj:2.181 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=2.150 (perp=8.065, rec=0.059, cos=0.478), tot_loss_proj:2.192 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=2.142 (perp=8.065, rec=0.049, cos=0.480), tot_loss_proj:2.188 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=2.145 (perp=8.065, rec=0.055, cos=0.478), tot_loss_proj:2.181 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=2.153 (perp=8.065, rec=0.062, cos=0.478), tot_loss_proj:2.182 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=2.150 (perp=8.065, rec=0.058, cos=0.479), tot_loss_proj:2.178 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=2.152 (perp=8.065, rec=0.060, cos=0.479), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=2.138 (perp=8.065, rec=0.046, cos=0.479), tot_loss_proj:2.190 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=2.149 (perp=8.065, rec=0.057, cos=0.480), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=2.155 (perp=8.065, rec=0.063, cos=0.479), tot_loss_proj:2.191 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=2.159 (perp=8.065, rec=0.065, cos=0.480), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=2.146 (perp=8.065, rec=0.054, cos=0.478), tot_loss_proj:2.183 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=2.147 (perp=8.065, rec=0.054, cos=0.479), tot_loss_proj:2.190 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=2.166 (perp=8.065, rec=0.073, cos=0.480), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.479 | p: 87.795 | r: 89.354
rouge2     | fm: 52.622 | p: 52.460 | r: 52.796
rougeL     | fm: 76.606 | p: 76.038 | r: 77.341
rougeLsum  | fm: 76.604 | p: 76.021 | r: 77.379
r1fm+r2fm = 141.100

input #64 time: 0:08:26 | total time: 9:28:29


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.737056379502266
highest_index [0]
highest [0.737056379502266]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8885520100593567 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.8764046430587769 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8636805415153503 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8565331697463989 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 0.856127142906189 for ['[CLS] pale far expert interval pr che gonna time united [SEP]']
[Init] best rec loss: 0.8447593450546265 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.8445899486541748 for ['[CLS] society djs dry beltryn cockpit [MASK] tiger an [SEP]']
[Init] best rec loss: 0.8386068344116211 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.819873571395874 for ['[CLS] dancer relative being bar shoulder allmusic original eatingolic [SEP]']
[Init] best rec loss: 0.7941717505455017 for ['[CLS] graphic - oxygen jessie go distinguished they alt decommissioned [SEP]']
[Init] best rec loss: 0.7667328715324402 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.7652024030685425 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.7626421451568604 for ['[CLS] fun someday general puhoff even oversmament news [SEP]']
[Init] best perm rec loss: 0.7626366019248962 for ['[CLS] news evenhoff someday pumament general overs fun [SEP]']
[Init] best perm rec loss: 0.7620970606803894 for ['[CLS] news general somedaymament overs fun puhoff even [SEP]']
[Init] best perm rec loss: 0.761713981628418 for ['[CLS] even pu general oversmamenthoff someday fun news [SEP]']
[Init] best perm rec loss: 0.7612455487251282 for ['[CLS] generalmament pu overs even somedayhoff fun news [SEP]']
[Init] best perm rec loss: 0.7612327933311462 for ['[CLS] general someday pu overs evenmamenthoff news fun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.686 (perp=9.647, rec=0.301, cos=0.455), tot_loss_proj:2.994 [t=0.21s]
prediction: ['[CLS] joy movie joyous joy story joy, joy [SEP]']
[ 100/2000] tot_loss=1.992 (perp=6.733, rec=0.191, cos=0.455), tot_loss_proj:2.451 [t=0.21s]
prediction: ['[CLS] joy film joyous joyous joy, film [SEP]']
[ 150/2000] tot_loss=2.515 (perp=9.538, rec=0.154, cos=0.454), tot_loss_proj:3.041 [t=0.21s]
prediction: ['[CLS] joyp joyous joy of rom, film [SEP]']
[ 200/2000] tot_loss=2.232 (perp=8.211, rec=0.130, cos=0.459), tot_loss_proj:2.656 [t=0.21s]
prediction: ['[CLS] rom a joyous joy of rom, film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.182 (perp=7.878, rec=0.153, cos=0.454), tot_loss_proj:2.589 [t=0.21s]
prediction: ['[CLS] rom a joyous joy, rom of film [SEP]']
[ 300/2000] tot_loss=2.134 (perp=7.878, rec=0.103, cos=0.455), tot_loss_proj:2.569 [t=0.21s]
prediction: ['[CLS] rom a joyous joy, rom of film [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.826 (perp=6.354, rec=0.099, cos=0.457), tot_loss_proj:2.291 [t=0.21s]
prediction: ['[CLS] rom joy, a joyous rom of film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.027 (perp=7.447, rec=0.084, cos=0.454), tot_loss_proj:2.389 [t=0.21s]
prediction: ['[CLS]p joy, a joyous rom of film [SEP]']
[ 450/2000] tot_loss=2.034 (perp=7.447, rec=0.090, cos=0.455), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS]p joy, a joyous rom of film [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.646 (perp=5.499, rec=0.093, cos=0.454), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.633 (perp=5.499, rec=0.078, cos=0.455), tot_loss_proj:2.005 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[ 600/2000] tot_loss=1.632 (perp=5.499, rec=0.078, cos=0.454), tot_loss_proj:2.004 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.630 (perp=5.499, rec=0.076, cos=0.454), tot_loss_proj:2.002 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.630 (perp=5.499, rec=0.075, cos=0.455), tot_loss_proj:2.001 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[ 750/2000] tot_loss=1.633 (perp=5.499, rec=0.078, cos=0.455), tot_loss_proj:1.999 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.625 (perp=5.499, rec=0.071, cos=0.454), tot_loss_proj:2.002 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.639 (perp=5.499, rec=0.084, cos=0.456), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[ 900/2000] tot_loss=1.636 (perp=5.499, rec=0.081, cos=0.456), tot_loss_proj:2.006 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.633 (perp=5.499, rec=0.078, cos=0.455), tot_loss_proj:1.998 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.626 (perp=5.499, rec=0.070, cos=0.456), tot_loss_proj:1.995 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1050/2000] tot_loss=1.627 (perp=5.499, rec=0.072, cos=0.455), tot_loss_proj:1.991 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.631 (perp=5.499, rec=0.076, cos=0.455), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.636 (perp=5.499, rec=0.081, cos=0.455), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1200/2000] tot_loss=1.626 (perp=5.499, rec=0.072, cos=0.455), tot_loss_proj:1.995 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.630 (perp=5.499, rec=0.075, cos=0.455), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.627 (perp=5.499, rec=0.073, cos=0.454), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1350/2000] tot_loss=1.630 (perp=5.499, rec=0.075, cos=0.454), tot_loss_proj:1.993 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.629 (perp=5.499, rec=0.074, cos=0.456), tot_loss_proj:1.999 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.636 (perp=5.499, rec=0.081, cos=0.455), tot_loss_proj:1.989 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1500/2000] tot_loss=1.636 (perp=5.499, rec=0.080, cos=0.455), tot_loss_proj:1.997 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.632 (perp=5.499, rec=0.077, cos=0.455), tot_loss_proj:1.994 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.634 (perp=5.499, rec=0.080, cos=0.455), tot_loss_proj:1.991 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1650/2000] tot_loss=1.632 (perp=5.499, rec=0.077, cos=0.455), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.621 (perp=5.499, rec=0.066, cos=0.455), tot_loss_proj:1.998 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.638 (perp=5.499, rec=0.083, cos=0.455), tot_loss_proj:1.997 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1800/2000] tot_loss=1.633 (perp=5.499, rec=0.078, cos=0.455), tot_loss_proj:1.991 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.626 (perp=5.499, rec=0.071, cos=0.455), tot_loss_proj:1.998 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.627 (perp=5.499, rec=0.072, cos=0.455), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
[1950/2000] tot_loss=1.625 (perp=5.499, rec=0.071, cos=0.455), tot_loss_proj:1.991 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.614 (perp=5.499, rec=0.059, cos=0.455), tot_loss_proj:1.997 [t=0.21s]
prediction: ['[CLS] joy, a joyous romp of film [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joy, a joyous romp of film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 88.550 | p: 87.729 | r: 89.470
rouge2     | fm: 52.275 | p: 52.056 | r: 52.495
rougeL     | fm: 76.653 | p: 76.050 | r: 77.478
rougeLsum  | fm: 76.750 | p: 76.163 | r: 77.485
r1fm+r2fm = 140.825

input #65 time: 0:08:30 | total time: 9:36:59


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.732885094455469
highest_index [0]
highest [0.732885094455469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8504238128662109 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.8343098759651184 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.8226848244667053 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8061898350715637 for ['[CLS] riot equal private peculiar [SEP]']
[Init] best rec loss: 0.8027597665786743 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.7988579869270325 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.7759223580360413 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 0.7636436820030212 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.7428296208381653 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best perm rec loss: 0.7427991032600403 for ['[CLS] game scout shoulders juliet [SEP]']
[Init] best perm rec loss: 0.7403432130813599 for ['[CLS] juliet shoulders game scout [SEP]']
[Init] best perm rec loss: 0.738042950630188 for ['[CLS] juliet scout game shoulders [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.088 (perp=11.949, rec=0.245, cos=0.454), tot_loss_proj:3.684 [t=0.21s]
prediction: ['[CLS] tolkien werewolf fan fan [SEP]']
[ 100/2000] tot_loss=2.989 (perp=12.070, rec=0.123, cos=0.452), tot_loss_proj:3.529 [t=0.21s]
prediction: ['[CLS] tolkien longtime fan longtime [SEP]']
[ 150/2000] tot_loss=2.681 (perp=10.722, rec=0.083, cos=0.454), tot_loss_proj:3.191 [t=0.21s]
prediction: ['[CLS] tolkien longtime fan a [SEP]']
[ 200/2000] tot_loss=2.688 (perp=10.722, rec=0.079, cos=0.464), tot_loss_proj:3.193 [t=0.21s]
prediction: ['[CLS] tolkien longtime fan a [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.325 (perp=8.912, rec=0.079, cos=0.464), tot_loss_proj:2.653 [t=0.21s]
prediction: ['[CLS] longtime tolkien fan a [SEP]']
[ 300/2000] tot_loss=2.315 (perp=8.912, rec=0.076, cos=0.456), tot_loss_proj:2.660 [t=0.22s]
prediction: ['[CLS] longtime tolkien fan a [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.066 (perp=7.672, rec=0.070, cos=0.462), tot_loss_proj:2.053 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.065 (perp=7.672, rec=0.071, cos=0.459), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=2.050 (perp=7.672, rec=0.054, cos=0.462), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.065 (perp=7.672, rec=0.074, cos=0.457), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.063 (perp=7.672, rec=0.065, cos=0.464), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=2.060 (perp=7.672, rec=0.065, cos=0.461), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.063 (perp=7.672, rec=0.066, cos=0.462), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.061 (perp=7.672, rec=0.066, cos=0.461), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=2.060 (perp=7.672, rec=0.065, cos=0.460), tot_loss_proj:2.063 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.051 (perp=7.672, rec=0.058, cos=0.459), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.057 (perp=7.672, rec=0.063, cos=0.460), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=2.055 (perp=7.672, rec=0.061, cos=0.460), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.042 (perp=7.672, rec=0.047, cos=0.460), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=2.059 (perp=7.672, rec=0.064, cos=0.461), tot_loss_proj:2.067 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=2.063 (perp=7.672, rec=0.067, cos=0.462), tot_loss_proj:2.067 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=2.066 (perp=7.672, rec=0.068, cos=0.463), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=2.052 (perp=7.672, rec=0.056, cos=0.462), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=2.055 (perp=7.672, rec=0.060, cos=0.461), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=2.065 (perp=7.672, rec=0.070, cos=0.461), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=2.047 (perp=7.672, rec=0.051, cos=0.461), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=2.064 (perp=7.672, rec=0.068, cos=0.462), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=2.060 (perp=7.672, rec=0.063, cos=0.463), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=2.057 (perp=7.672, rec=0.061, cos=0.462), tot_loss_proj:2.065 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=2.060 (perp=7.672, rec=0.064, cos=0.462), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=2.056 (perp=7.672, rec=0.059, cos=0.463), tot_loss_proj:2.065 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=2.062 (perp=7.672, rec=0.065, cos=0.462), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=2.066 (perp=7.672, rec=0.069, cos=0.462), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=2.065 (perp=7.672, rec=0.068, cos=0.462), tot_loss_proj:2.066 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=2.061 (perp=7.672, rec=0.066, cos=0.461), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=2.052 (perp=7.672, rec=0.056, cos=0.462), tot_loss_proj:2.068 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=2.055 (perp=7.672, rec=0.058, cos=0.463), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=2.059 (perp=7.672, rec=0.062, cos=0.462), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=2.046 (perp=7.672, rec=0.051, cos=0.461), tot_loss_proj:2.068 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=2.057 (perp=7.672, rec=0.060, cos=0.462), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.744 | p: 87.986 | r: 89.663
rouge2     | fm: 53.377 | p: 53.170 | r: 53.627
rougeL     | fm: 76.908 | p: 76.310 | r: 77.675
rougeLsum  | fm: 77.073 | p: 76.442 | r: 77.798
r1fm+r2fm = 142.121

input #66 time: 0:08:30 | total time: 9:45:29


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.7350978589871058
highest_index [0]
highest [0.7350978589871058]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9497545957565308 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.934689462184906 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9163415431976318 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.9129219651222229 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.8993821740150452 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.8923628926277161 for ['[CLS] carries garden deputy creation attitudes victim mine waitingapugh [SEP]']
[Init] best rec loss: 0.8895390033721924 for ['[CLS] holyvy war hingesozuche tessa ] commentary justice [SEP]']
[Init] best perm rec loss: 0.8885389566421509 for ['[CLS] hinges war tessa justice commentaryuche ]vy holyoz [SEP]']
[Init] best perm rec loss: 0.8882704973220825 for ['[CLS]vy commentary justice holy waruche ]oz hinges tessa [SEP]']
[Init] best perm rec loss: 0.8870825171470642 for ['[CLS] tessauche justice ] commentary hingesvy waroz holy [SEP]']
[Init] best perm rec loss: 0.8849522471427917 for ['[CLS] hinges holy justiceuche war tessaoz commentaryvy ] [SEP]']
[Init] best perm rec loss: 0.8848327398300171 for ['[CLS] tessa hinges holy ] warozvy commentary justiceuche [SEP]']
[Init] best perm rec loss: 0.8847729563713074 for ['[CLS]uche hingesvy holy tessa commentary justice ]oz war [SEP]']
[Init] best perm rec loss: 0.8844455480575562 for ['[CLS] ] tessa justicevy hingesuche commentary holy waroz [SEP]']
[Init] best perm rec loss: 0.8843865990638733 for ['[CLS] hinges justiceuchevy tessa ] commentaryoz holy war [SEP]']
[Init] best perm rec loss: 0.8834700584411621 for ['[CLS] tessavy ] hinges war holy commentary justiceozuche [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.204 (perp=12.195, rec=0.309, cos=0.457), tot_loss_proj:3.896 [t=0.21s]
prediction: ['[CLS] kind kind kind heart multideworm conversation mood eh [SEP]']
[ 100/2000] tot_loss=2.998 (perp=11.565, rec=0.224, cos=0.461), tot_loss_proj:3.613 [t=0.22s]
prediction: ['[CLS] kind kind kind heartwar nonjuentalwarwar [SEP]']
[ 150/2000] tot_loss=2.867 (perp=11.118, rec=0.182, cos=0.461), tot_loss_proj:3.359 [t=0.22s]
prediction: ['[CLS] kind kind kind heartming nonjuentalwarming [SEP]']
[ 200/2000] tot_loss=2.689 (perp=10.456, rec=0.139, cos=0.458), tot_loss_proj:3.239 [t=0.22s]
prediction: ['[CLS] kind kind kind heartming nongmentalwarming [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.242 (perp=8.266, rec=0.129, cos=0.460), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] kindming kindming nongmental heartwarming [SEP]']
[ 300/2000] tot_loss=2.612 (perp=10.196, rec=0.115, cos=0.458), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS] kindming kindming nongmental heartwarscreen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.953 (perp=6.937, rec=0.107, cos=0.458), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] kind, kindming nongmental heartwarming [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.248 (perp=8.376, rec=0.116, cos=0.457), tot_loss_proj:2.790 [t=0.22s]
prediction: ['[CLS] kindming nongmental trees kind heartwarming [SEP]']
[ 450/2000] tot_loss=1.855 (perp=6.491, rec=0.097, cos=0.460), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] kindming nongmental, kind heartwarming [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.859 (perp=6.491, rec=0.101, cos=0.460), tot_loss_proj:2.366 [t=0.22s]
prediction: ['[CLS] kindming nongmental, kind heartwarming [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.861 (perp=6.491, rec=0.104, cos=0.460), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] kindming nongmental, kind heartwarming [SEP]']
[ 600/2000] tot_loss=1.847 (perp=6.491, rec=0.091, cos=0.458), tot_loss_proj:2.364 [t=0.22s]
prediction: ['[CLS] kindming nongmental, kind heartwarming [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.840 (perp=6.491, rec=0.084, cos=0.458), tot_loss_proj:2.375 [t=0.22s]
prediction: ['[CLS] kindming nongmental, kind heartwarming [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.746 (perp=6.015, rec=0.085, cos=0.458), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS], kindming nongmental, heartwarming [SEP]']
[ 750/2000] tot_loss=2.262 (perp=8.550, rec=0.095, cos=0.457), tot_loss_proj:3.118 [t=0.22s]
prediction: ['[CLS], kindming nongmentalju heartwarming [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.036 (perp=7.456, rec=0.087, cos=0.458), tot_loss_proj:2.589 [t=0.22s]
prediction: ['[CLS], kindming nonjugmental heartwarming [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.040 (perp=7.456, rec=0.089, cos=0.460), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS], kindming nonjugmental heartwarming [SEP]']
[ 900/2000] tot_loss=2.231 (perp=8.470, rec=0.079, cos=0.458), tot_loss_proj:3.141 [t=0.22s]
prediction: ['[CLS], kindming nonjugmental heartward [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.238 (perp=8.470, rec=0.085, cos=0.459), tot_loss_proj:3.140 [t=0.22s]
prediction: ['[CLS], kindming nonjugmental heartward [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.037 (perp=7.461, rec=0.086, cos=0.459), tot_loss_proj:2.888 [t=0.22s]
prediction: ['[CLS], kindming nonjudgmental heartwar [SEP]']
[1050/2000] tot_loss=2.034 (perp=7.461, rec=0.083, cos=0.459), tot_loss_proj:2.889 [t=0.22s]
prediction: ['[CLS], kindming nonjudgmental heartwar [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.900 (perp=6.789, rec=0.083, cos=0.459), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS], kindwarming nonjudgmental heart [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.806 (perp=6.352, rec=0.078, cos=0.458), tot_loss_proj:2.171 [t=0.22s]
prediction: ['[CLS] kindwarming, nonjudgmental heart [SEP]']
[1200/2000] tot_loss=1.809 (perp=6.352, rec=0.080, cos=0.459), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] kindwarming, nonjudgmental heart [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.605 (perp=5.307, rec=0.086, cos=0.458), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=5.307, rec=0.082, cos=0.458), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1350/2000] tot_loss=1.597 (perp=5.307, rec=0.077, cos=0.459), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1400/2000] tot_loss=1.605 (perp=5.307, rec=0.084, cos=0.459), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1450/2000] tot_loss=1.600 (perp=5.307, rec=0.079, cos=0.460), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1500/2000] tot_loss=1.600 (perp=5.307, rec=0.080, cos=0.458), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=5.307, rec=0.073, cos=0.458), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.594 (perp=5.307, rec=0.074, cos=0.459), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1650/2000] tot_loss=1.589 (perp=5.307, rec=0.068, cos=0.459), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=5.307, rec=0.075, cos=0.459), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.594 (perp=5.307, rec=0.073, cos=0.459), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1800/2000] tot_loss=1.601 (perp=5.307, rec=0.081, cos=0.459), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=5.307, rec=0.070, cos=0.459), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=5.307, rec=0.077, cos=0.459), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1950/2000] tot_loss=1.599 (perp=5.307, rec=0.079, cos=0.459), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.599 (perp=5.307, rec=0.079, cos=0.459), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming, nonjudgmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.835 | p: 88.085 | r: 89.756
rouge2     | fm: 52.872 | p: 52.719 | r: 53.135
rougeL     | fm: 76.924 | p: 76.310 | r: 77.711
rougeLsum  | fm: 77.048 | p: 76.482 | r: 77.821
r1fm+r2fm = 141.707

input #67 time: 0:08:36 | total time: 9:54:05


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.714747220059992
highest_index [0]
highest [0.714747220059992]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9293202757835388 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.905373215675354 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.8961409330368042 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.8943108916282654 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 0.8750324249267578 for ['[CLS] feelings stole besides spoil bit type decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.8412432670593262 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8331930637359619 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8324552178382874 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.825832188129425 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.825507402420044 for ['[CLS]. comfort formiferousyn died medal possibly view beth councils riding floor [SEP]']
[Init] best perm rec loss: 0.8248582482337952 for ['[CLS]iferous riding possibly councils form diedyn comfort. beth medal view floor [SEP]']
[Init] best perm rec loss: 0.8219690322875977 for ['[CLS] flooryn diediferous beth riding councils form. medal view possibly comfort [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.075 (perp=11.609, rec=0.265, cos=0.489), tot_loss_proj:3.473 [t=0.22s]
prediction: ['[CLS] destroyed or conductetched crops, random ill absurd devils noise... about [SEP]']
[ 100/2000] tot_loss=3.119 (perp=12.204, rec=0.193, cos=0.486), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS] destroyed, signs shareholder vicious, gross absurd absurd accused (tti important [SEP]']
[ 150/2000] tot_loss=2.622 (perp=9.849, rec=0.166, cos=0.485), tot_loss_proj:2.894 [t=0.22s]
prediction: ['[CLS] vicious and conductuted vicious, vicious absurd absurd unuthcouth [SEP]']
[ 200/2000] tot_loss=2.840 (perp=11.049, rec=0.142, cos=0.488), tot_loss_proj:3.099 [t=0.22s]
prediction: ['[CLS] vicious and incuted vicious, vicious absurd absurd unuthcosible [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.583 (perp=9.762, rec=0.145, cos=0.485), tot_loss_proj:2.943 [t=0.22s]
prediction: ['[CLS] vicious and incuth vicious, vicioussible absurd uncouthsible [SEP]']
[ 300/2000] tot_loss=2.563 (perp=9.762, rec=0.123, cos=0.487), tot_loss_proj:2.948 [t=0.22s]
prediction: ['[CLS] vicious and incuth vicious, vicioussible absurd uncouthsible [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.832 (perp=11.065, rec=0.133, cos=0.485), tot_loss_proj:3.338 [t=0.22s]
prediction: ['[CLS]sible and incuth vicious, vicioussible absurd unomputh vicious [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.638 (perp=9.985, rec=0.154, cos=0.487), tot_loss_proj:2.999 [t=0.22s]
prediction: ['[CLS] vicious assassination absurd unomputhsible and incuth vicious, vicious [SEP]']
[ 450/2000] tot_loss=2.320 (perp=8.577, rec=0.117, cos=0.488), tot_loss_proj:2.711 [t=0.22s]
prediction: ['[CLS] vicious and absurd unomputhsible andcouth vicious, vicious [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.103 (perp=7.489, rec=0.120, cos=0.485), tot_loss_proj:2.454 [t=0.22s]
prediction: ['[CLS] vicious and absurdcouthsible and uncouth vicious, vicious [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.380 (perp=8.876, rec=0.119, cos=0.486), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS] vicious and viciouscouthsible and un incuth absurd, vicious [SEP]']
[ 600/2000] tot_loss=2.098 (perp=7.570, rec=0.098, cos=0.486), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] vicious andsiblecouthsible and uncouth absurd, vicious [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.715 (perp=10.612, rec=0.108, cos=0.485), tot_loss_proj:3.084 [t=0.22s]
prediction: ['[CLS] vicioussibleitatedcouthsible and unomputh absurd, vicious [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.322 (perp=8.653, rec=0.106, cos=0.485), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsible and andomputh absurd, vicious [SEP]']
[ 750/2000] tot_loss=2.310 (perp=8.653, rec=0.094, cos=0.486), tot_loss_proj:2.611 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsible and andomputh absurd, vicious [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.395 (perp=9.047, rec=0.101, cos=0.485), tot_loss_proj:2.809 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsible andzen absurdomputh, vicious [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.206 (perp=8.091, rec=0.102, cos=0.486), tot_loss_proj:2.554 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsible and and absurdomputh, vicious [SEP]']
[ 900/2000] tot_loss=2.235 (perp=8.299, rec=0.088, cos=0.487), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsiblezen and absurdomputh, vicious [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.231 (perp=8.249, rec=0.095, cos=0.487), tot_loss_proj:2.552 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthzensible and absurdomputh, vicious [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.230 (perp=8.299, rec=0.084, cos=0.487), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsiblezen and absurdomputh, vicious [SEP]']
[1050/2000] tot_loss=2.500 (perp=9.599, rec=0.094, cos=0.486), tot_loss_proj:2.861 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthsiblehen and absurdomputh, vicious [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.212 (perp=8.164, rec=0.091, cos=0.488), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] vicioushensible uncouthsible and absurdomputh, vicious [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.085 (perp=7.515, rec=0.094, cos=0.488), tot_loss_proj:2.384 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
[1200/2000] tot_loss=2.073 (perp=7.515, rec=0.083, cos=0.487), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1250/2000] tot_loss=2.086 (perp=7.515, rec=0.095, cos=0.488), tot_loss_proj:2.384 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1300/2000] tot_loss=2.080 (perp=7.515, rec=0.089, cos=0.488), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
[1350/2000] tot_loss=2.079 (perp=7.515, rec=0.088, cos=0.488), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1400/2000] tot_loss=2.074 (perp=7.515, rec=0.084, cos=0.488), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1450/2000] tot_loss=2.079 (perp=7.515, rec=0.089, cos=0.487), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
[1500/2000] tot_loss=2.076 (perp=7.515, rec=0.085, cos=0.488), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1550/2000] tot_loss=2.075 (perp=7.515, rec=0.084, cos=0.488), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1600/2000] tot_loss=2.080 (perp=7.515, rec=0.090, cos=0.487), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
[1650/2000] tot_loss=2.079 (perp=7.515, rec=0.088, cos=0.488), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1700/2000] tot_loss=2.077 (perp=7.515, rec=0.086, cos=0.488), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1750/2000] tot_loss=2.083 (perp=7.515, rec=0.092, cos=0.488), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
[1800/2000] tot_loss=2.088 (perp=7.515, rec=0.098, cos=0.488), tot_loss_proj:2.385 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1850/2000] tot_loss=2.081 (perp=7.515, rec=0.090, cos=0.488), tot_loss_proj:2.384 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[1900/2000] tot_loss=2.081 (perp=7.515, rec=0.090, cos=0.488), tot_loss_proj:2.384 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
[1950/2000] tot_loss=2.077 (perp=7.515, rec=0.087, cos=0.488), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Attempt swap
[2000/2000] tot_loss=2.079 (perp=7.515, rec=0.088, cos=0.488), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] vicioussible uncouthhensible and absurdomputh, vicious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 88.484 | p: 87.791 | r: 89.402
rouge2     | fm: 52.064 | p: 51.838 | r: 52.334
rougeL     | fm: 76.477 | p: 75.840 | r: 77.221
rougeLsum  | fm: 76.572 | p: 75.928 | r: 77.349
r1fm+r2fm = 140.548

input #68 time: 0:08:39 | total time: 10:02:44


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.7393934733658232
highest_index [0]
highest [0.7393934733658232]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.969987690448761 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9693111181259155 for ['[CLS] new nod none left bryson gainering state chris pay league teams dea set during store [SEP]']
[Init] best rec loss: 0.9552406668663025 for ['[CLS]aver grandson cleared sergei spare reserve / earthquake mouse loudly student celebrated pill till le tunnel [SEP]']
[Init] best rec loss: 0.9349761605262756 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9314336180686951 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.9275965094566345 for ['[CLS] states depended past am (ll mess liz stock dead bragg passes close rangeleinrga [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.321 (perp=11.195, rec=0.622, cos=0.460), tot_loss_proj:4.199 [t=0.21s]
prediction: ['[CLS] the bought trail mafia electorate really. africa espn country testified a close wealthy learned when [SEP]']
[ 100/2000] tot_loss=3.063 (perp=10.477, rec=0.535, cos=0.432), tot_loss_proj:4.027 [t=0.21s]
prediction: ['[CLS] the ; profile gareth doorbell,. armed espn silence ;, because ; damn - [SEP]']
[ 150/2000] tot_loss=3.373 (perp=10.196, rec=0.703, cos=0.631), tot_loss_proj:3.858 [t=0.21s]
prediction: ['[CLS] decent ;, monsterc, inadequate northern www silence ;, accurate ; good as [SEP]']
[ 200/2000] tot_loss=3.440 (perp=12.023, rec=0.541, cos=0.494), tot_loss_proj:4.379 [t=0.21s]
prediction: ['[CLS] decent ( starkhopper ( is inadequatelassified website - ;,alo and dash matched [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.420 (perp=12.666, rec=0.525, cos=0.362), tot_loss_proj:4.262 [t=0.22s]
prediction: ['[CLS] decent...yhopper when we. human funny its ;,alo willbilis intense [SEP]']
[ 300/2000] tot_loss=3.075 (perp=10.562, rec=0.469, cos=0.494), tot_loss_proj:3.604 [t=0.21s]
prediction: ['[CLS] smart initially /cheon when is. human funny -,, volume,bilis intense [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.878 (perp=9.887, rec=0.455, cos=0.446), tot_loss_proj:3.643 [t=0.21s]
prediction: ['[CLS] when smart initially / bullshit is. asteroid kind -,, volume and funny intense [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.605 (perp=8.814, rec=0.452, cos=0.390), tot_loss_proj:3.528 [t=0.21s]
prediction: ['[CLS] when, initially / bullshit is. asteroid funny -, smart volume and smart intense [SEP]']
[ 450/2000] tot_loss=2.573 (perp=8.901, rec=0.428, cos=0.365), tot_loss_proj:3.542 [t=0.21s]
prediction: ['[CLS] when, ) / bullshit is. asteroid recognize :, smart volume and smart intense [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.339 (perp=7.506, rec=0.425, cos=0.412), tot_loss_proj:3.435 [t=0.21s]
prediction: ['[CLS] when, ), bullshit is. known recognize : / smart volume and smart, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.152 (perp=6.809, rec=0.414, cos=0.376), tot_loss_proj:3.270 [t=0.21s]
prediction: ['[CLS] when, ), bullshit is. known : funny / smart volume and smart, [SEP]']
[ 600/2000] tot_loss=2.284 (perp=7.289, rec=0.401, cos=0.426), tot_loss_proj:3.420 [t=0.21s]
prediction: ['[CLS] when, ), bullshit is, " : recognize / smart volume and smart, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.122 (perp=6.975, rec=0.400, cos=0.328), tot_loss_proj:3.343 [t=0.21s]
prediction: ['[CLS] before, ), bullshit is. " smart ( recognize / volume and smart, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.502 (perp=8.608, rec=0.406, cos=0.375), tot_loss_proj:3.684 [t=0.21s]
prediction: ['[CLS] when,,, bullshit is. distributed smart ( recognize, volume genuinely smart, [SEP]']
[ 750/2000] tot_loss=2.402 (perp=7.694, rec=0.391, cos=0.472), tot_loss_proj:3.414 [t=0.21s]
prediction: ['[CLS] before, and, bullshit is. distributed smart ( recognize, success ) smart, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.212 (perp=7.083, rec=0.390, cos=0.405), tot_loss_proj:3.157 [t=0.21s]
prediction: ['[CLS] before, distributed, bullshit is. and smart ( recognize, success ) smart, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.186 (perp=7.135, rec=0.384, cos=0.376), tot_loss_proj:3.346 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is smart and smart ( recognize, success )., [SEP]']
[ 900/2000] tot_loss=2.199 (perp=7.247, rec=0.378, cos=0.371), tot_loss_proj:3.295 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is smart, smart - funny, success )., [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.260 (perp=7.291, rec=0.375, cos=0.427), tot_loss_proj:3.400 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is smart,,, funny,, ). ( [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.089 (perp=6.804, rec=0.371, cos=0.358), tot_loss_proj:3.254 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is, smart,, funny,, ). ( [SEP]']
[1050/2000] tot_loss=2.097 (perp=6.804, rec=0.367, cos=0.369), tot_loss_proj:3.252 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is, smart,, funny,, ). ( [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.019 (perp=6.410, rec=0.366, cos=0.371), tot_loss_proj:3.115 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is, smart,, funny (,, ). [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.016 (perp=6.266, rec=0.363, cos=0.399), tot_loss_proj:3.054 [t=0.21s]
prediction: ['[CLS]stown, distributed, bullshit is, smart, funny, (,, ). [SEP]']
[1200/2000] tot_loss=2.080 (perp=6.205, rec=0.358, cos=0.481), tot_loss_proj:2.931 [t=0.21s]
prediction: ['[CLS]stown, distributed, monster is, funny, funny, (,, ). [SEP]']
Attempt swap
[1250/2000] tot_loss=1.954 (perp=6.091, rec=0.357, cos=0.378), tot_loss_proj:2.383 [t=0.21s]
prediction: ['[CLS]stown, quality, monster is, funny, funny, (,, ). [SEP]']
Attempt swap
[1300/2000] tot_loss=1.976 (perp=6.091, rec=0.358, cos=0.400), tot_loss_proj:2.385 [t=0.21s]
prediction: ['[CLS]stown, quality, monster is, funny, funny, (,, ). [SEP]']
[1350/2000] tot_loss=2.102 (perp=6.451, rec=0.354, cos=0.458), tot_loss_proj:2.942 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, -,, ). [SEP]']
Attempt swap
[1400/2000] tot_loss=2.089 (perp=6.645, rec=0.353, cos=0.407), tot_loss_proj:2.802 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, -, success ). [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.996 (perp=6.162, rec=0.355, cos=0.409), tot_loss_proj:2.552 [t=0.22s]
prediction: ['[CLS]stown, video, monster is, funny, funny, success, ( ). [SEP]']
[1500/2000] tot_loss=2.017 (perp=6.162, rec=0.349, cos=0.436), tot_loss_proj:2.546 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, success, ( ). [SEP]']
Attempt swap
[1550/2000] tot_loss=1.988 (perp=6.162, rec=0.350, cos=0.405), tot_loss_proj:2.548 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, success, ( ). [SEP]']
Attempt swap
[1600/2000] tot_loss=2.048 (perp=6.127, rec=0.349, cos=0.474), tot_loss_proj:2.603 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, success, - ). [SEP]']
[1650/2000] tot_loss=1.994 (perp=6.127, rec=0.350, cos=0.418), tot_loss_proj:2.598 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, success, - ). [SEP]']
Attempt swap
[1700/2000] tot_loss=1.999 (perp=6.127, rec=0.350, cos=0.424), tot_loss_proj:2.599 [t=0.21s]
prediction: ['[CLS]stown, video, monster is, funny, funny, success, - ). [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.080 (perp=6.358, rec=0.379, cos=0.429), tot_loss_proj:2.811 [t=0.21s]
prediction: ['[CLS]stown video, monster, is, funny, funny,,, ( ). [SEP]']
[1800/2000] tot_loss=2.074 (perp=6.363, rec=0.357, cos=0.444), tot_loss_proj:2.860 [t=0.21s]
prediction: ['[CLS]stown video, monster, is, funny, funny,,, - ). [SEP]']
Attempt swap
[1850/2000] tot_loss=2.078 (perp=6.363, rec=0.353, cos=0.452), tot_loss_proj:2.863 [t=0.21s]
prediction: ['[CLS]stown video, monster, is, funny, funny,,, - ). [SEP]']
Attempt swap
[1900/2000] tot_loss=2.064 (perp=6.363, rec=0.353, cos=0.438), tot_loss_proj:2.863 [t=0.21s]
prediction: ['[CLS]stown video, monster, is, funny, funny,,, - ). [SEP]']
[1950/2000] tot_loss=2.074 (perp=6.363, rec=0.354, cos=0.447), tot_loss_proj:2.858 [t=0.21s]
prediction: ['[CLS]stown video, monster, is, funny, funny,,, - ). [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.924 (perp=5.525, rec=0.368, cos=0.451), tot_loss_proj:2.848 [t=0.21s]
prediction: ['[CLS], video, monster, is, funny, funny,stown, - ). [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS]stown, video, monster is, funny, funny, success, - ). [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 31.579 | p: 33.333 | r: 30.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 31.579 | p: 33.333 | r: 30.000
rougeLsum  | fm: 31.579 | p: 33.333 | r: 30.000
r1fm+r2fm = 31.579

[Aggregate metrics]:
rouge1     | fm: 87.628 | p: 86.903 | r: 88.517
rouge2     | fm: 51.362 | p: 51.192 | r: 51.618
rougeL     | fm: 75.829 | p: 75.305 | r: 76.540
rougeLsum  | fm: 75.859 | p: 75.258 | r: 76.611
r1fm+r2fm = 138.990

input #69 time: 0:08:30 | total time: 10:11:15


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.7291147619276197
highest_index [0]
highest [0.7291147619276197]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8027496933937073 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7712742686271667 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7476715445518494 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7433110475540161 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.7309445738792419 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7061299681663513 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6895534992218018 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 0.6880224347114563 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 0.6850546598434448 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 0.6829368472099304 for ['[CLS] muscle guybution party bob modern ি [SEP]']
[Init] best perm rec loss: 0.6820260286331177 for ['[CLS] ি muscle modernbution guy bob party [SEP]']
[Init] best perm rec loss: 0.6815065741539001 for ['[CLS] muscle modern party ি guybution bob [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.595 (perp=14.183, rec=0.307, cos=0.451), tot_loss_proj:4.324 [t=0.21s]
prediction: ['[CLS]iferous rangunk cl cl passenger on [SEP]']
[ 100/2000] tot_loss=3.385 (perp=13.859, rec=0.166, cos=0.447), tot_loss_proj:4.240 [t=0.21s]
prediction: ['[CLS]yunkunk cl gets screen on [SEP]']
[ 150/2000] tot_loss=3.330 (perp=13.859, rec=0.097, cos=0.462), tot_loss_proj:4.253 [t=0.21s]
prediction: ['[CLS]yunkunk cl gets screen on [SEP]']
[ 200/2000] tot_loss=3.322 (perp=13.859, rec=0.088, cos=0.462), tot_loss_proj:4.277 [t=0.21s]
prediction: ['[CLS]yunkunk cl gets screen on [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.378 (perp=9.154, rec=0.085, cos=0.462), tot_loss_proj:3.085 [t=0.21s]
prediction: ['[CLS] clunkunky gets screen on [SEP]']
[ 300/2000] tot_loss=2.363 (perp=9.154, rec=0.074, cos=0.459), tot_loss_proj:3.146 [t=0.21s]
prediction: ['[CLS] clunkunky gets screen on [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.102 (perp=7.852, rec=0.073, cos=0.459), tot_loss_proj:2.897 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.102 (perp=7.852, rec=0.071, cos=0.461), tot_loss_proj:2.892 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 450/2000] tot_loss=2.113 (perp=7.852, rec=0.076, cos=0.467), tot_loss_proj:2.878 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.105 (perp=7.852, rec=0.073, cos=0.461), tot_loss_proj:2.858 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.111 (perp=7.852, rec=0.077, cos=0.464), tot_loss_proj:2.851 [t=0.22s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 600/2000] tot_loss=2.105 (perp=7.852, rec=0.067, cos=0.467), tot_loss_proj:2.844 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.104 (perp=7.852, rec=0.073, cos=0.461), tot_loss_proj:2.844 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.102 (perp=7.852, rec=0.067, cos=0.465), tot_loss_proj:2.839 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 750/2000] tot_loss=2.099 (perp=7.852, rec=0.065, cos=0.464), tot_loss_proj:2.840 [t=0.21s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.117 (perp=7.950, rec=0.064, cos=0.462), tot_loss_proj:2.837 [t=0.21s]
prediction: ['[CLS] cl theunky gets on screen [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.904 (perp=6.843, rec=0.070, cos=0.466), tot_loss_proj:2.345 [t=0.21s]
prediction: ['[CLS] the clunky gets on screen [SEP]']
[ 900/2000] tot_loss=1.891 (perp=6.843, rec=0.063, cos=0.460), tot_loss_proj:2.351 [t=0.21s]
prediction: ['[CLS] the clunky gets on screen [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.825 (perp=6.453, rec=0.073, cos=0.462), tot_loss_proj:1.952 [t=0.21s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.765 (perp=6.139, rec=0.074, cos=0.463), tot_loss_proj:1.773 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1050/2000] tot_loss=1.764 (perp=6.139, rec=0.069, cos=0.468), tot_loss_proj:1.773 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.760 (perp=6.139, rec=0.069, cos=0.463), tot_loss_proj:1.775 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.747 (perp=6.139, rec=0.055, cos=0.464), tot_loss_proj:1.785 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1200/2000] tot_loss=1.757 (perp=6.139, rec=0.060, cos=0.469), tot_loss_proj:1.778 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.757 (perp=6.139, rec=0.065, cos=0.464), tot_loss_proj:1.785 [t=0.22s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.766 (perp=6.139, rec=0.072, cos=0.466), tot_loss_proj:1.785 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1350/2000] tot_loss=1.757 (perp=6.139, rec=0.065, cos=0.465), tot_loss_proj:1.783 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.759 (perp=6.139, rec=0.065, cos=0.466), tot_loss_proj:1.773 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.760 (perp=6.139, rec=0.066, cos=0.467), tot_loss_proj:1.774 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1500/2000] tot_loss=1.754 (perp=6.139, rec=0.060, cos=0.466), tot_loss_proj:1.782 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.759 (perp=6.139, rec=0.063, cos=0.468), tot_loss_proj:1.780 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.759 (perp=6.139, rec=0.064, cos=0.468), tot_loss_proj:1.778 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1650/2000] tot_loss=1.759 (perp=6.139, rec=0.067, cos=0.465), tot_loss_proj:1.781 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.754 (perp=6.139, rec=0.060, cos=0.465), tot_loss_proj:1.784 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.755 (perp=6.139, rec=0.060, cos=0.467), tot_loss_proj:1.780 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1800/2000] tot_loss=1.758 (perp=6.139, rec=0.064, cos=0.465), tot_loss_proj:1.773 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.764 (perp=6.139, rec=0.071, cos=0.466), tot_loss_proj:1.780 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.764 (perp=6.139, rec=0.069, cos=0.467), tot_loss_proj:1.783 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1950/2000] tot_loss=1.749 (perp=6.139, rec=0.056, cos=0.466), tot_loss_proj:1.783 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.755 (perp=6.139, rec=0.060, cos=0.467), tot_loss_proj:1.775 [t=0.21s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets clunky on the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.765 | p: 87.068 | r: 88.617
rouge2     | fm: 51.898 | p: 51.714 | r: 52.146
rougeL     | fm: 76.195 | p: 75.670 | r: 76.923
rougeLsum  | fm: 76.205 | p: 75.687 | r: 76.947
r1fm+r2fm = 139.663

input #70 time: 0:08:30 | total time: 10:19:45


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.715979824091689
highest_index [0]
highest [0.715979824091689]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8949810862541199 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.887344479560852 for ['[CLS]kledclaiming solid due tear stakesaint flight ken keel receiver living duval us tottenham [SEP]']
[Init] best rec loss: 0.8816795945167542 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8778720498085022 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8670638799667358 for ['[CLS] composed warsselle ty urbantist empireneas amendment broadbandcat murdereo money appoint [SEP]']
[Init] best rec loss: 0.8587639331817627 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8502165079116821 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8495179414749146 for ['[CLS]lon dictionary short prairie mayatypic conditioning flyingto etc men provided star cassidy gems [SEP]']
[Init] best rec loss: 0.8469364047050476 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 0.8468524217605591 for ['[CLS] sur over fewer professorhear marshall liam molly bed jean fall creatures ram of queens [SEP]']
[Init] best perm rec loss: 0.8439019322395325 for ['[CLS] over professor marshall of creatures molly sur bed ram fewer liam queens fallhear jean [SEP]']
[Init] best perm rec loss: 0.843402624130249 for ['[CLS] molly professor liam marshall ramhear creatures of bed queens sur fewer over jean fall [SEP]']
[Init] best perm rec loss: 0.8432877063751221 for ['[CLS] sur fall creatureshear marshall liam ram of professor over queens fewer bed molly jean [SEP]']
[Init] best perm rec loss: 0.8419389128684998 for ['[CLS] fewer molly jean sur creatures marshallhear ram liam professor of queens bed over fall [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.484 (perp=8.522, rec=0.301, cos=0.478), tot_loss_proj:2.999 [t=0.21s]
prediction: ["[CLS] for'' from your touchdown landed not moment single your moment moment - not [SEP]"]
[ 100/2000] tot_loss=2.409 (perp=8.664, rec=0.203, cos=0.473), tot_loss_proj:3.215 [t=0.21s]
prediction: ["[CLS] nose'' - seat jump is not moment single your first moment - and [SEP]"]
[ 150/2000] tot_loss=2.218 (perp=7.942, rec=0.152, cos=0.477), tot_loss_proj:3.023 [t=0.21s]
prediction: ["[CLS] hands'- - seat jump is not jump single your - moment - and [SEP]"]
[ 200/2000] tot_loss=2.294 (perp=8.471, rec=0.110, cos=0.490), tot_loss_proj:3.045 [t=0.21s]
prediction: ["[CLS] a'' - seat there s not jump single your - moment - and [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.314 (perp=8.691, rec=0.094, cos=0.481), tot_loss_proj:3.364 [t=0.21s]
prediction: ["[CLS] a'there in seat - s not jump single your - moment - and [SEP]"]
[ 300/2000] tot_loss=2.141 (perp=7.886, rec=0.081, cos=0.483), tot_loss_proj:2.919 [t=0.21s]
prediction: ["[CLS] a'there in seat's not jump single your - moment - and [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.121 (perp=7.741, rec=0.095, cos=0.478), tot_loss_proj:3.102 [t=0.21s]
prediction: ["[CLS] a'there in - seat - s not jump single your moment - and [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.024 (perp=7.277, rec=0.091, cos=0.478), tot_loss_proj:3.165 [t=0.21s]
prediction: ["[CLS] his single'there in - seat - s not jump your moment - and [SEP]"]
[ 450/2000] tot_loss=2.017 (perp=7.263, rec=0.079, cos=0.485), tot_loss_proj:3.128 [t=0.21s]
prediction: ["[CLS] a single'there in - seat - s not jump your moment - and [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.938 (perp=6.915, rec=0.073, cos=0.483), tot_loss_proj:3.092 [t=0.21s]
prediction: ["[CLS] a single seat there in -'- s not jump your moment - and [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.842 (perp=6.333, rec=0.099, cos=0.476), tot_loss_proj:2.647 [t=0.21s]
prediction: ["[CLS] a single seat jump in -'- s not there your moment - and [SEP]"]
[ 600/2000] tot_loss=1.828 (perp=6.333, rec=0.080, cos=0.481), tot_loss_proj:2.662 [t=0.21s]
prediction: ["[CLS] a single seat jump in -'- s not there your moment - and [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.770 (perp=6.091, rec=0.072, cos=0.480), tot_loss_proj:2.710 [t=0.21s]
prediction: ["[CLS] a single seat jump in - -'s not there your moment - and [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.763 (perp=6.024, rec=0.074, cos=0.484), tot_loss_proj:2.774 [t=0.21s]
prediction: ["[CLS] a single seat jump in -'s - not there your moment - and [SEP]"]
[ 750/2000] tot_loss=1.761 (perp=6.024, rec=0.072, cos=0.484), tot_loss_proj:2.773 [t=0.21s]
prediction: ["[CLS] a single seat jump in -'s - not there your moment - and [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.735 (perp=5.843, rec=0.085, cos=0.481), tot_loss_proj:2.733 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - not there your moment - and [SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.706 (perp=5.691, rec=0.086, cos=0.482), tot_loss_proj:2.724 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
[ 900/2000] tot_loss=1.699 (perp=5.691, rec=0.077, cos=0.484), tot_loss_proj:2.726 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.695 (perp=5.691, rec=0.076, cos=0.481), tot_loss_proj:2.718 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.692 (perp=5.691, rec=0.068, cos=0.486), tot_loss_proj:2.721 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
[1050/2000] tot_loss=1.700 (perp=5.691, rec=0.080, cos=0.481), tot_loss_proj:2.723 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.695 (perp=5.691, rec=0.075, cos=0.482), tot_loss_proj:2.727 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.688 (perp=5.691, rec=0.065, cos=0.484), tot_loss_proj:2.724 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s - there not your moment - and [SEP]"]
[1200/2000] tot_loss=1.888 (perp=6.688, rec=0.066, cos=0.485), tot_loss_proj:3.034 [t=0.21s]
prediction: ["[CLS] a single seat in jump'' s - there not your moment - and [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.695 (perp=5.743, rec=0.065, cos=0.482), tot_loss_proj:2.647 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s'there not your moment - and [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.697 (perp=5.743, rec=0.067, cos=0.481), tot_loss_proj:2.656 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s'there not your moment - and [SEP]"]
[1350/2000] tot_loss=1.701 (perp=5.743, rec=0.069, cos=0.484), tot_loss_proj:2.652 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'s'there not your moment - and [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.677 (perp=5.576, rec=0.079, cos=0.484), tot_loss_proj:2.676 [t=0.21s]
prediction: ["[CLS] a single seat in jump -'there's not your moment - and [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.624 (perp=5.388, rec=0.068, cos=0.479), tot_loss_proj:2.505 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
[1500/2000] tot_loss=1.637 (perp=5.388, rec=0.078, cos=0.482), tot_loss_proj:2.510 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.631 (perp=5.388, rec=0.071, cos=0.483), tot_loss_proj:2.508 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.628 (perp=5.388, rec=0.067, cos=0.483), tot_loss_proj:2.508 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
[1650/2000] tot_loss=1.636 (perp=5.388, rec=0.075, cos=0.483), tot_loss_proj:2.510 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.628 (perp=5.388, rec=0.066, cos=0.485), tot_loss_proj:2.503 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.624 (perp=5.388, rec=0.062, cos=0.484), tot_loss_proj:2.508 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
[1800/2000] tot_loss=1.625 (perp=5.388, rec=0.062, cos=0.485), tot_loss_proj:2.506 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.631 (perp=5.388, rec=0.070, cos=0.484), tot_loss_proj:2.507 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.633 (perp=5.388, rec=0.071, cos=0.484), tot_loss_proj:2.507 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
[1950/2000] tot_loss=1.630 (perp=5.388, rec=0.069, cos=0.484), tot_loss_proj:2.508 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.630 (perp=5.388, rec=0.068, cos=0.484), tot_loss_proj:2.508 [t=0.21s]
prediction: ["[CLS] a single moment in jump -'there's not your seat - and [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] a single moment in jump -'there's not your seat - and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 41.667 | p: 41.667 | r: 41.667
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 141.667

[Aggregate metrics]:
rouge1     | fm: 87.905 | p: 87.201 | r: 88.763
rouge2     | fm: 51.732 | p: 51.548 | r: 51.974
rougeL     | fm: 76.021 | p: 75.413 | r: 76.759
rougeLsum  | fm: 76.009 | p: 75.415 | r: 76.726
r1fm+r2fm = 139.637

input #71 time: 0:08:26 | total time: 10:28:12


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.7164831176549935
highest_index [0]
highest [0.7164831176549935]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.772716760635376 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7648209929466248 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7371431589126587 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7364096641540527 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7261108756065369 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7006204128265381 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.6985036134719849 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.6969229578971863 for ['[CLS] lifeboat support nonetheless reserveungen except van! dna pork walking accidentally zone ta orbital [SEP]']
[Init] best perm rec loss: 0.6960539817810059 for ['[CLS] van pork accidentally walking orbitalungen ta reserve nonetheless support dna lifeboat zone except! [SEP]']
[Init] best perm rec loss: 0.6959899067878723 for ['[CLS] ta nonetheless lifeboat except van! reserve support dna zone pork accidentallyungen walking orbital [SEP]']
[Init] best perm rec loss: 0.6958935856819153 for ['[CLS] walking lifeboat van pork orbital dna zone reserve accidentally! nonetheless support ta exceptungen [SEP]']
[Init] best perm rec loss: 0.6947269439697266 for ['[CLS]ungen accidentally support zone except! ta nonetheless dna lifeboat orbital reserve van walking pork [SEP]']
[Init] best perm rec loss: 0.6943534016609192 for ['[CLS]ungen support dna ta reserve lifeboat walking van orbital accidentally pork zone nonetheless except! [SEP]']
[Init] best perm rec loss: 0.6936701536178589 for ['[CLS] except nonetheless lifeboatungen dna! pork accidentally reserve support zone ta walking orbital van [SEP]']
[Init] best perm rec loss: 0.6928852200508118 for ['[CLS] zone accidentally lifeboat dna except ta porkungen support van nonetheless walking orbital reserve! [SEP]']
[Init] best perm rec loss: 0.6913304924964905 for ['[CLS]!ungen lifeboat nonetheless orbital ta zone dna except pork walking reserve support van accidentally [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.330 (perp=12.709, rec=0.312, cos=0.476), tot_loss_proj:3.774 [t=0.21s]
prediction: ['[CLS] harder process tougher tough with racial tough ideas political crazy resortberry tendencies disguise [SEP]']
[ 100/2000] tot_loss=2.997 (perp=11.706, rec=0.193, cos=0.463), tot_loss_proj:3.768 [t=0.21s]
prediction: ['[CLS] tough has tougherer time violence tough philosophy political crazy fighting inspired violence disguise [SEP]']
[ 150/2000] tot_loss=2.681 (perp=10.460, rec=0.137, cos=0.452), tot_loss_proj:3.369 [t=0.21s]
prediction: ['[CLS] tough has tougherer time its tough balancing a mad point philosophy violence philosophy [SEP]']
[ 200/2000] tot_loss=2.721 (perp=10.739, rec=0.108, cos=0.465), tot_loss_proj:3.347 [t=0.21s]
prediction: ['[CLS] tough has tougher balancing time its violence balancing a mad balance philosophy violence philosophy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.606 (perp=10.111, rec=0.102, cos=0.481), tot_loss_proj:3.260 [t=0.28s]
prediction: ['[CLS] tough has tougher a time balancing its violence a inspired phased philosophy violence philosophy [SEP]']
[ 300/2000] tot_loss=2.396 (perp=9.180, rec=0.080, cos=0.480), tot_loss_proj:2.775 [t=0.21s]
prediction: ['[CLS] tough has tougher a time balancing its violence with inspired phased philosophy violence philosophy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.199 (perp=8.161, rec=0.091, cos=0.476), tot_loss_proj:2.500 [t=0.21s]
prediction: ['[CLS] tough has a tougher time balancing its violence with inspired phased philosophy violence philosophy [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.058 (perp=7.450, rec=0.085, cos=0.483), tot_loss_proj:2.347 [t=0.21s]
prediction: ['[CLS] tough has a tougher time balancing its violence with violence inspired politicalfk philosophy [SEP]']
[ 450/2000] tot_loss=2.043 (perp=7.450, rec=0.071, cos=0.482), tot_loss_proj:2.358 [t=0.21s]
prediction: ['[CLS] tough has a tougher time balancing its violence with violence inspired politicalfk philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.952 (perp=6.957, rec=0.078, cos=0.483), tot_loss_proj:2.303 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence inspired politicalfk philosophy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.162 (perp=8.042, rec=0.071, cos=0.483), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence phasedfk inspired philosophy [SEP]']
[ 600/2000] tot_loss=1.840 (perp=6.431, rec=0.074, cos=0.480), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.840 (perp=6.431, rec=0.075, cos=0.478), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.841 (perp=6.431, rec=0.078, cos=0.477), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.844 (perp=6.431, rec=0.077, cos=0.481), tot_loss_proj:2.172 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.838 (perp=6.431, rec=0.072, cos=0.480), tot_loss_proj:2.181 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.842 (perp=6.431, rec=0.076, cos=0.480), tot_loss_proj:2.164 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[ 900/2000] tot_loss=1.842 (perp=6.431, rec=0.072, cos=0.484), tot_loss_proj:2.160 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.833 (perp=6.431, rec=0.067, cos=0.480), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.844 (perp=6.431, rec=0.074, cos=0.484), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1050/2000] tot_loss=1.838 (perp=6.431, rec=0.068, cos=0.484), tot_loss_proj:2.166 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.840 (perp=6.431, rec=0.069, cos=0.484), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.831 (perp=6.431, rec=0.064, cos=0.481), tot_loss_proj:2.178 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1200/2000] tot_loss=1.840 (perp=6.431, rec=0.070, cos=0.484), tot_loss_proj:2.178 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.834 (perp=6.431, rec=0.067, cos=0.480), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.844 (perp=6.431, rec=0.075, cos=0.483), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1350/2000] tot_loss=1.845 (perp=6.431, rec=0.074, cos=0.485), tot_loss_proj:2.162 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.850 (perp=6.431, rec=0.081, cos=0.483), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.839 (perp=6.431, rec=0.069, cos=0.484), tot_loss_proj:2.164 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1500/2000] tot_loss=1.834 (perp=6.431, rec=0.062, cos=0.486), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.837 (perp=6.431, rec=0.066, cos=0.485), tot_loss_proj:2.173 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.835 (perp=6.431, rec=0.065, cos=0.483), tot_loss_proj:2.162 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1650/2000] tot_loss=1.829 (perp=6.431, rec=0.062, cos=0.481), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.843 (perp=6.431, rec=0.077, cos=0.480), tot_loss_proj:2.165 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.832 (perp=6.431, rec=0.065, cos=0.481), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1800/2000] tot_loss=1.830 (perp=6.431, rec=0.061, cos=0.483), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.834 (perp=6.431, rec=0.065, cos=0.483), tot_loss_proj:2.174 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.838 (perp=6.431, rec=0.069, cos=0.483), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
[1950/2000] tot_loss=1.839 (perp=6.431, rec=0.071, cos=0.482), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.833 (perp=6.431, rec=0.064, cos=0.483), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] tougher has a tough time balancing its violence with violence -fk inspired philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 80.000 | r: 92.308
rouge2     | fm: 53.846 | p: 50.000 | r: 58.333
rougeL     | fm: 78.571 | p: 73.333 | r: 84.615
rougeLsum  | fm: 78.571 | p: 73.333 | r: 84.615
r1fm+r2fm = 139.560

[Aggregate metrics]:
rouge1     | fm: 87.885 | p: 87.126 | r: 88.826
rouge2     | fm: 51.827 | p: 51.589 | r: 52.111
rougeL     | fm: 75.995 | p: 75.424 | r: 76.735
rougeLsum  | fm: 76.041 | p: 75.439 | r: 76.768
r1fm+r2fm = 139.711

input #72 time: 0:08:26 | total time: 10:36:39


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.7081894789809513
highest_index [0]
highest [0.7081894789809513]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.958734393119812 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9357547760009766 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.9063217639923096 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 0.8986206650733948 for ['[CLS] role breton [SEP]']
[Init] best rec loss: 0.895497739315033 for ['[CLS] zhang body [SEP]']
[Init] best rec loss: 0.8855562210083008 for ['[CLS] pass society [SEP]']
[Init] best rec loss: 0.8729764223098755 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.868474006652832 for ['[CLS]ɛ society [SEP]']
[Init] best rec loss: 0.8279026746749878 for ['[CLS] massachusetts gun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.634 (perp=9.723, rec=0.192, cos=0.497), tot_loss_proj:2.526 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.530 (perp=9.723, rec=0.087, cos=0.498), tot_loss_proj:2.521 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.503 (perp=9.723, rec=0.061, cos=0.497), tot_loss_proj:2.537 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.505 (perp=9.723, rec=0.065, cos=0.495), tot_loss_proj:2.515 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.502 (perp=9.723, rec=0.060, cos=0.498), tot_loss_proj:2.516 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.501 (perp=9.723, rec=0.060, cos=0.496), tot_loss_proj:2.520 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.506 (perp=9.723, rec=0.064, cos=0.498), tot_loss_proj:2.527 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.522 (perp=9.723, rec=0.081, cos=0.497), tot_loss_proj:2.521 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.489 (perp=9.723, rec=0.046, cos=0.499), tot_loss_proj:2.523 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.509 (perp=9.723, rec=0.068, cos=0.497), tot_loss_proj:2.523 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.502 (perp=9.723, rec=0.059, cos=0.498), tot_loss_proj:2.524 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.506 (perp=9.723, rec=0.063, cos=0.498), tot_loss_proj:2.512 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.500 (perp=9.723, rec=0.059, cos=0.497), tot_loss_proj:2.520 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.517 (perp=9.723, rec=0.074, cos=0.498), tot_loss_proj:2.509 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.506 (perp=9.723, rec=0.063, cos=0.498), tot_loss_proj:2.525 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.498 (perp=9.723, rec=0.057, cos=0.497), tot_loss_proj:2.523 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.500 (perp=9.723, rec=0.058, cos=0.498), tot_loss_proj:2.517 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.509 (perp=9.723, rec=0.065, cos=0.499), tot_loss_proj:2.515 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.509 (perp=9.723, rec=0.066, cos=0.498), tot_loss_proj:2.522 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.501 (perp=9.723, rec=0.059, cos=0.497), tot_loss_proj:2.522 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.499 (perp=9.723, rec=0.057, cos=0.498), tot_loss_proj:2.522 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.500 (perp=9.723, rec=0.059, cos=0.497), tot_loss_proj:2.505 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.499 (perp=9.723, rec=0.056, cos=0.498), tot_loss_proj:2.521 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.509 (perp=9.723, rec=0.067, cos=0.498), tot_loss_proj:2.508 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.498 (perp=9.723, rec=0.055, cos=0.498), tot_loss_proj:2.513 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.506 (perp=9.723, rec=0.063, cos=0.498), tot_loss_proj:2.529 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.506 (perp=9.723, rec=0.064, cos=0.498), tot_loss_proj:2.518 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.512 (perp=9.723, rec=0.069, cos=0.498), tot_loss_proj:2.513 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.509 (perp=9.723, rec=0.067, cos=0.498), tot_loss_proj:2.519 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.497 (perp=9.723, rec=0.054, cos=0.498), tot_loss_proj:2.529 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.505 (perp=9.723, rec=0.063, cos=0.497), tot_loss_proj:2.513 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.504 (perp=9.723, rec=0.061, cos=0.498), tot_loss_proj:2.518 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.513 (perp=9.723, rec=0.070, cos=0.498), tot_loss_proj:2.515 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.503 (perp=9.723, rec=0.061, cos=0.498), tot_loss_proj:2.520 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.498 (perp=9.723, rec=0.055, cos=0.499), tot_loss_proj:2.522 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.497 (perp=9.723, rec=0.054, cos=0.498), tot_loss_proj:2.521 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.502 (perp=9.723, rec=0.060, cos=0.498), tot_loss_proj:2.522 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.498 (perp=9.723, rec=0.055, cos=0.498), tot_loss_proj:2.510 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.511 (perp=9.723, rec=0.068, cos=0.498), tot_loss_proj:2.510 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.518 (perp=9.723, rec=0.076, cos=0.498), tot_loss_proj:2.526 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.083 | p: 87.294 | r: 89.016
rouge2     | fm: 52.614 | p: 52.371 | r: 52.834
rougeL     | fm: 76.446 | p: 75.872 | r: 77.147
rougeLsum  | fm: 76.335 | p: 75.688 | r: 77.049
r1fm+r2fm = 140.698

input #73 time: 0:08:24 | total time: 10:45:03


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.7260036475981224
highest_index [0]
highest [0.7260036475981224]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8141483664512634 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6225752234458923 for ['[CLS] storage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.232 (perp=8.177, rec=0.120, cos=0.477), tot_loss_proj:2.430 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=2.176 (perp=8.177, rec=0.072, cos=0.469), tot_loss_proj:2.245 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=2.169 (perp=8.177, rec=0.066, cos=0.468), tot_loss_proj:2.236 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=2.167 (perp=8.177, rec=0.063, cos=0.468), tot_loss_proj:2.233 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.165 (perp=8.177, rec=0.063, cos=0.467), tot_loss_proj:2.246 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=2.171 (perp=8.177, rec=0.066, cos=0.470), tot_loss_proj:2.234 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.173 (perp=8.177, rec=0.068, cos=0.469), tot_loss_proj:2.229 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.172 (perp=8.177, rec=0.066, cos=0.471), tot_loss_proj:2.228 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.170 (perp=8.177, rec=0.063, cos=0.471), tot_loss_proj:2.237 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.166 (perp=8.177, rec=0.061, cos=0.470), tot_loss_proj:2.240 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.167 (perp=8.177, rec=0.063, cos=0.469), tot_loss_proj:2.238 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.166 (perp=8.177, rec=0.058, cos=0.472), tot_loss_proj:2.233 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.162 (perp=8.177, rec=0.057, cos=0.469), tot_loss_proj:2.234 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.168 (perp=8.177, rec=0.063, cos=0.469), tot_loss_proj:2.230 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.155 (perp=8.177, rec=0.051, cos=0.468), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.164 (perp=8.177, rec=0.057, cos=0.472), tot_loss_proj:2.228 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.169 (perp=8.177, rec=0.064, cos=0.469), tot_loss_proj:2.221 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.167 (perp=8.177, rec=0.060, cos=0.472), tot_loss_proj:2.223 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.163 (perp=8.177, rec=0.059, cos=0.468), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.163 (perp=8.177, rec=0.055, cos=0.472), tot_loss_proj:2.236 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.164 (perp=8.177, rec=0.055, cos=0.473), tot_loss_proj:2.223 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.172 (perp=8.177, rec=0.062, cos=0.475), tot_loss_proj:2.239 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.171 (perp=8.177, rec=0.063, cos=0.472), tot_loss_proj:2.227 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.163 (perp=8.177, rec=0.056, cos=0.472), tot_loss_proj:2.231 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.157 (perp=8.177, rec=0.051, cos=0.470), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.168 (perp=8.177, rec=0.062, cos=0.470), tot_loss_proj:2.228 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.170 (perp=8.177, rec=0.064, cos=0.470), tot_loss_proj:2.221 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.165 (perp=8.177, rec=0.057, cos=0.472), tot_loss_proj:2.231 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.175 (perp=8.177, rec=0.068, cos=0.472), tot_loss_proj:2.223 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.165 (perp=8.177, rec=0.058, cos=0.472), tot_loss_proj:2.225 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.169 (perp=8.177, rec=0.063, cos=0.470), tot_loss_proj:2.229 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.163 (perp=8.177, rec=0.055, cos=0.472), tot_loss_proj:2.223 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.170 (perp=8.177, rec=0.062, cos=0.472), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.171 (perp=8.177, rec=0.064, cos=0.472), tot_loss_proj:2.234 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.162 (perp=8.177, rec=0.055, cos=0.471), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.164 (perp=8.177, rec=0.057, cos=0.471), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.163 (perp=8.177, rec=0.056, cos=0.472), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.169 (perp=8.177, rec=0.061, cos=0.472), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.172 (perp=8.177, rec=0.064, cos=0.473), tot_loss_proj:2.236 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.178 (perp=8.177, rec=0.070, cos=0.473), tot_loss_proj:2.228 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.307 | p: 87.529 | r: 89.222
rouge2     | fm: 53.116 | p: 52.855 | r: 53.441
rougeL     | fm: 76.700 | p: 76.088 | r: 77.461
rougeLsum  | fm: 76.689 | p: 76.092 | r: 77.430
r1fm+r2fm = 141.423

input #74 time: 0:08:27 | total time: 10:53:31


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.7271292055519818
highest_index [0]
highest [0.7271292055519818]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8856006264686584 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.883551836013794 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 0.8564025163650513 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.831136167049408 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 0.8302717208862305 for ['[CLS] chaintrybro savings path part accolades truck visa chenses stateach foundation speak theme rather utter english [SEP]']
[Init] best rec loss: 0.8273686170578003 for ['[CLS] cabin titled feedbi humble wbning translation chance tempo area true trailing legislative be yellowish popular granite midwest [SEP]']
[Init] best perm rec loss: 0.8267591595649719 for ['[CLS] legislative humble temponing midwest yellowish areabi true feed granite wb trailing chance cabin popular be titled translation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.301 (perp=12.605, rec=0.318, cos=0.462), tot_loss_proj:4.297 [t=0.21s]
prediction: ['[CLS] tech visual dayonus easily into kidnappingosity t alongside medical t my the courthouse throughout dismissed not considered [SEP]']
[ 100/2000] tot_loss=3.055 (perp=11.689, rec=0.255, cos=0.462), tot_loss_proj:4.064 [t=0.21s]
prediction: ['[CLS]dine exercise research knife easily or instability juliusය of event imp curriculum this telescope not dismissed not easily [SEP]']
[ 150/2000] tot_loss=2.922 (perp=11.332, rec=0.186, cos=0.470), tot_loss_proj:3.804 [t=0.21s]
prediction: ['[CLS]scopic programming focus knife easily or instability upon. of mused is educational this instability not dismissed not easily [SEP]']
[ 200/2000] tot_loss=3.078 (perp=12.156, rec=0.165, cos=0.482), tot_loss_proj:4.240 [t=0.21s]
prediction: ['[CLS]dineesian focus knife easily or instabilityregion. of sensors is educational this instabilitysibility forgotten not easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.906 (perp=11.434, rec=0.152, cos=0.468), tot_loss_proj:4.060 [t=0.21s]
prediction: ['[CLS]scopic excursion focus knife easily or instabilityrdial.enter ishaven is this instability。 forgotten not easily [SEP]']
[ 300/2000] tot_loss=2.967 (perp=11.859, rec=0.138, cos=0.457), tot_loss_proj:4.136 [t=0.21s]
prediction: ['[CLS]nivorous excursion focus knife easily or instabilityiving.enter ishaven is this excursion ₕ forgotten not easily [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.862 (perp=11.221, rec=0.147, cos=0.471), tot_loss_proj:4.041 [t=0.21s]
prediction: ['[CLS] of excursion focus exclusive easily or instabilitycola ளenter is mental is this excursionnction forgotten not easily [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.674 (perp=10.461, rec=0.126, cos=0.456), tot_loss_proj:3.886 [t=0.21s]
prediction: ['[CLS] is of excursion of exclusive or instabilitycola easilycola is mental is this excursionedly forgotten not easily [SEP]']
[ 450/2000] tot_loss=2.668 (perp=10.441, rec=0.122, cos=0.458), tot_loss_proj:3.889 [t=0.21s]
prediction: ['[CLS] is into excursion of exclusive or instabilitycola easilycola is mental is this excursionedly forgotten not easily [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.494 (perp=9.570, rec=0.120, cos=0.460), tot_loss_proj:3.718 [t=0.21s]
prediction: ['[CLS] is of excursion of nemesis or instabilitycola is easilycola mental is this excursion is forgotten not easily [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.362 (perp=8.876, rec=0.123, cos=0.463), tot_loss_proj:3.559 [t=0.21s]
prediction: ['[CLS] is of excursion of intro orcola is easilycola mental instability is this excursion is forgotten not easily [SEP]']
[ 600/2000] tot_loss=2.446 (perp=9.386, rec=0.106, cos=0.464), tot_loss_proj:3.655 [t=0.28s]
prediction: ['[CLS] is of excursion of intro orcola is easilyenter mental instability is this excursion is forgotten not easily [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.488 (perp=9.588, rec=0.106, cos=0.464), tot_loss_proj:3.705 [t=0.21s]
prediction: ['[CLS] is of excursion of intro orcola is easily excursionenter mental instability is thisentation forgotten not easily [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.392 (perp=9.090, rec=0.113, cos=0.462), tot_loss_proj:3.551 [t=0.21s]
prediction: ['[CLS] is of excursion of forgotten orcola is easily excursionenter mental instability is thisentation not easily forgotten [SEP]']
[ 750/2000] tot_loss=2.433 (perp=9.333, rec=0.103, cos=0.464), tot_loss_proj:3.193 [t=0.21s]
prediction: ['[CLS] is into excursion of finale orcola is easily excursionenter mental instability is thisentation not easily forgotten [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.374 (perp=9.014, rec=0.107, cos=0.465), tot_loss_proj:3.115 [t=0.21s]
prediction: ['[CLS] is excursion of finale orcola is dismissed excursionenter of mental instability is this ₕ not easily forgotten [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.191 (perp=8.078, rec=0.114, cos=0.462), tot_loss_proj:2.749 [t=0.21s]
prediction: ['[CLS] is excursion of epic orcola is excursionenter of mental instability is thisted not easily forgotten. [SEP]']
[ 900/2000] tot_loss=2.010 (perp=7.238, rec=0.104, cos=0.458), tot_loss_proj:2.386 [t=0.21s]
prediction: ['[CLS] is excursion of epic orcola is excursionenter of mental instability is this is not easily forgotten. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.180 (perp=8.027, rec=0.113, cos=0.461), tot_loss_proj:2.771 [t=0.21s]
prediction: ['[CLS] is excursion of epic mental instability is orcola is excursionenter of thisted not easily forgotten. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.061 (perp=7.480, rec=0.105, cos=0.461), tot_loss_proj:2.704 [t=0.21s]
prediction: ['[CLS] is excursion of epicenter mental instability is orcola is excursion of thisted not easily forgotten. [SEP]']
[1050/2000] tot_loss=2.062 (perp=7.480, rec=0.103, cos=0.463), tot_loss_proj:2.702 [t=0.21s]
prediction: ['[CLS] is excursion of epicenter mental instability is orcola is excursion of thisted not easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.038 (perp=7.389, rec=0.096, cos=0.464), tot_loss_proj:2.585 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter mental instabilityted orcola is excursion of this is not easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.025 (perp=7.321, rec=0.097, cos=0.464), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] is excursion of epicenter mental instability is orcolated excursion into this is not easily forgotten. [SEP]']
[1200/2000] tot_loss=2.015 (perp=7.279, rec=0.097, cos=0.463), tot_loss_proj:2.472 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter mental instability is orcolated excursion into this is not easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.989 (perp=7.119, rec=0.102, cos=0.463), tot_loss_proj:2.396 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter or instability is mentalcolated excursion into this is not easily forgotten. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.936 (perp=6.852, rec=0.101, cos=0.464), tot_loss_proj:2.300 [t=0.21s]
prediction: ['[CLS] is excursion excursion. epicenter or instability is mentalcolated into this is not easily forgotten. [SEP]']
[1350/2000] tot_loss=2.062 (perp=7.467, rec=0.105, cos=0.463), tot_loss_proj:2.424 [t=0.21s]
prediction: ['[CLS] is excursion excursion. causalenter or instability is mentalcolated into this is not easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.880 (perp=6.600, rec=0.098, cos=0.462), tot_loss_proj:2.238 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or instability is mentalcolated into this is not easily forgotten. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.881 (perp=6.600, rec=0.097, cos=0.464), tot_loss_proj:2.231 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or instability is mentalcolated into this is not easily forgotten. [SEP]']
[1500/2000] tot_loss=1.882 (perp=6.600, rec=0.098, cos=0.464), tot_loss_proj:2.231 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or instability is mentalcolated into this is not easily forgotten. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.852 (perp=6.462, rec=0.095, cos=0.464), tot_loss_proj:2.187 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or mental instability iscolated into this is not easily forgotten. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.861 (perp=6.462, rec=0.103, cos=0.465), tot_loss_proj:2.180 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or mental instability iscolated into this is not easily forgotten. [SEP]']
[1650/2000] tot_loss=1.846 (perp=6.462, rec=0.089, cos=0.464), tot_loss_proj:2.188 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or mental instability iscolated into this is not easily forgotten. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.848 (perp=6.462, rec=0.091, cos=0.464), tot_loss_proj:2.183 [t=0.21s]
prediction: ['[CLS] excursion is excursion. epicenter or mental instability iscolated into this is not easily forgotten. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.825 (perp=6.321, rec=0.097, cos=0.464), tot_loss_proj:2.236 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]']
[1800/2000] tot_loss=1.823 (perp=6.321, rec=0.094, cos=0.464), tot_loss_proj:2.239 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.823 (perp=6.321, rec=0.094, cos=0.465), tot_loss_proj:2.237 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.818 (perp=6.321, rec=0.090, cos=0.464), tot_loss_proj:2.242 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]']
[1950/2000] tot_loss=1.826 (perp=6.321, rec=0.096, cos=0.466), tot_loss_proj:2.238 [t=0.22s]
prediction: ['[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.816 (perp=6.321, rec=0.087, cos=0.465), tot_loss_proj:2.241 [t=0.21s]
prediction: ['[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] is excursion. epicenter or excursion mental instability iscolated into this is not easily forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.788 | p: 81.250 | r: 76.471
rouge2     | fm: 25.806 | p: 26.667 | r: 25.000
rougeL     | fm: 60.606 | p: 62.500 | r: 58.824
rougeLsum  | fm: 60.606 | p: 62.500 | r: 58.824
r1fm+r2fm = 104.594

[Aggregate metrics]:
rouge1     | fm: 88.158 | p: 87.442 | r: 89.064
rouge2     | fm: 52.613 | p: 52.404 | r: 52.943
rougeL     | fm: 76.387 | p: 75.851 | r: 77.105
rougeLsum  | fm: 76.407 | p: 75.844 | r: 77.180
r1fm+r2fm = 140.771

input #75 time: 0:08:28 | total time: 11:01:59


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.7295125917226154
highest_index [0]
highest [0.7295125917226154]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.8870353698730469 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8841953873634338 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.873711347579956 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8544380068778992 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.851813793182373 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8471713066101074 for ['[CLS] commune turkey commercially both barker body guantanamo shay away fortune 3d user also paper [SEP]']
[Init] best perm rec loss: 0.8457096815109253 for ['[CLS] away turkey paper user guantanamo barker body commune 3d commercially shay also fortune both [SEP]']
[Init] best perm rec loss: 0.8446983695030212 for ['[CLS] 3d shay away barker commune also fortune guantanamo paper user body both turkey commercially [SEP]']
[Init] best perm rec loss: 0.844135582447052 for ['[CLS] barker body commune fortune 3d commercially shay guantanamo user paper turkey both away also [SEP]']
[Init] best perm rec loss: 0.8432176113128662 for ['[CLS] turkey shay guantanamo commune barker commercially 3d away paper body also both fortune user [SEP]']
[Init] best perm rec loss: 0.8422098159790039 for ['[CLS] shay also barker paper away 3d turkey commune guantanamo commercially fortune user body both [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.192 (perp=11.965, rec=0.324, cos=0.475), tot_loss_proj:4.121 [t=0.21s]
prediction: ['[CLS] aloud stopped by team stopped stopped pastor over stopped challenging killingless handcuffs challenging [SEP]']
[ 100/2000] tot_loss=2.967 (perp=11.229, rec=0.275, cos=0.446), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] playback cbc has challenging him stopped while any stopped challenging ⇄ and requirements himself [SEP]']
[ 150/2000] tot_loss=2.826 (perp=10.879, rec=0.190, cos=0.460), tot_loss_proj:3.665 [t=0.22s]
prediction: ['[CLS] gives himself has challenging his stopped 66 has stopped challenging chan and breakdown himself [SEP]']
[ 200/2000] tot_loss=2.831 (perp=11.086, rec=0.153, cos=0.460), tot_loss_proj:3.614 [t=0.22s]
prediction: ['[CLS] gives himself has challenging himself stopped 66 has stopped challenging major. teeth himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.481 (perp=9.424, rec=0.136, cos=0.461), tot_loss_proj:3.438 [t=0.22s]
prediction: ['[CLS] gives himself if stopped himself challenging 66 has stopped challenging 66. randolph himself [SEP]']
[ 300/2000] tot_loss=2.473 (perp=9.486, rec=0.113, cos=0.462), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] allen himself if stopped himself twenty 66 has stopped challenging 66.. himself [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.289 (perp=8.613, rec=0.108, cos=0.458), tot_loss_proj:3.395 [t=0.22s]
prediction: ['[CLS] allen himself if stopped at twenty 66 has stopped challenging 66. himself. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.177 (perp=8.074, rec=0.101, cos=0.460), tot_loss_proj:3.364 [t=0.22s]
prediction: ['[CLS] allen himself if stopped at twenty 66 has stopped 66. challenging himself. [SEP]']
[ 450/2000] tot_loss=2.177 (perp=8.074, rec=0.102, cos=0.460), tot_loss_proj:3.359 [t=0.22s]
prediction: ['[CLS] allen himself if stopped at twenty 66 has stopped 66. challenging himself. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.170 (perp=8.074, rec=0.094, cos=0.461), tot_loss_proj:3.355 [t=0.22s]
prediction: ['[CLS] allen himself if stopped at twenty 66 has stopped 66. challenging himself. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.179 (perp=8.125, rec=0.096, cos=0.459), tot_loss_proj:3.310 [t=0.22s]
prediction: ['[CLS] allen himself as stopped 66 at 15 has stopped 66. challenging himself. [SEP]']
[ 600/2000] tot_loss=2.056 (perp=7.514, rec=0.092, cos=0.461), tot_loss_proj:3.336 [t=0.22s]
prediction: ['[CLS] allen himself if stopped 66 at 15 has stopped 66, challenging himself. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.127 (perp=7.871, rec=0.090, cos=0.463), tot_loss_proj:3.221 [t=0.22s]
prediction: ['[CLS] allen is if stopped 66 at 15 has stopped 66, challenging himself. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.051 (perp=7.531, rec=0.085, cos=0.461), tot_loss_proj:3.216 [t=0.22s]
prediction: ['[CLS] is as allen stopped 66 at 15 has stopped 66, challenging himself. [SEP]']
[ 750/2000] tot_loss=2.003 (perp=7.252, rec=0.088, cos=0.465), tot_loss_proj:3.197 [t=0.22s]
prediction: ['[CLS] is as allen stopped 66 at allen has stopped 66, challenging himself. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.077 (perp=7.635, rec=0.087, cos=0.463), tot_loss_proj:3.339 [t=0.22s]
prediction: ['[CLS] s as allen stopped at at 66 has stopped 66, challenging himself. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.028 (perp=7.380, rec=0.087, cos=0.465), tot_loss_proj:3.117 [t=0.22s]
prediction: ['[CLS] s as allen stopped at 66 has stopped at 66 as challenging himself. [SEP]']
[ 900/2000] tot_loss=1.951 (perp=7.000, rec=0.088, cos=0.463), tot_loss_proj:3.207 [t=0.22s]
prediction: ['[CLS] s as allen stopped at 66 has stopped at 66, challenging himself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.943 (perp=7.000, rec=0.077, cos=0.465), tot_loss_proj:3.207 [t=0.22s]
prediction: ['[CLS] s as allen stopped at 66 has stopped at 66, challenging himself. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.080 (perp=7.605, rec=0.097, cos=0.462), tot_loss_proj:3.119 [t=0.22s]
prediction: ['[CLS] as allen stopped allen 66 has stopped at s 66 as challenging himself. [SEP]']
[1050/2000] tot_loss=1.975 (perp=7.124, rec=0.088, cos=0.462), tot_loss_proj:3.067 [t=0.22s]
prediction: ['[CLS] as allen stopped at 66 has stopped at s 66 as challenging himself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.975 (perp=7.124, rec=0.088, cos=0.462), tot_loss_proj:3.070 [t=0.22s]
prediction: ['[CLS] as allen stopped at 66 has stopped at s 66 as challenging himself. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.960 (perp=7.124, rec=0.073, cos=0.462), tot_loss_proj:3.070 [t=0.22s]
prediction: ['[CLS] as allen stopped at 66 has stopped at s 66 as challenging himself. [SEP]']
[1200/2000] tot_loss=1.966 (perp=7.124, rec=0.079, cos=0.462), tot_loss_proj:3.070 [t=0.22s]
prediction: ['[CLS] as allen stopped at 66 has stopped at s 66 as challenging himself. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.977 (perp=7.124, rec=0.087, cos=0.465), tot_loss_proj:3.069 [t=0.22s]
prediction: ['[CLS] as allen stopped at 66 has stopped at s 66 as challenging himself. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.074 (perp=7.693, rec=0.072, cos=0.463), tot_loss_proj:3.152 [t=0.22s]
prediction: ["[CLS] as allen stopped'66 has stopped at s 66 as challenging himself. [SEP]"]
[1350/2000] tot_loss=2.085 (perp=7.693, rec=0.082, cos=0.464), tot_loss_proj:3.146 [t=0.22s]
prediction: ["[CLS] as allen stopped'66 has stopped at s 66 as challenging himself. [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.119 (perp=7.809, rec=0.092, cos=0.465), tot_loss_proj:3.332 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped's challenged as challenging himself. [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=2.068 (perp=7.613, rec=0.083, cos=0.462), tot_loss_proj:3.341 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has challenged stopped's as challenging himself. [SEP]"]
[1500/2000] tot_loss=2.122 (perp=7.880, rec=0.084, cos=0.463), tot_loss_proj:3.208 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has 66 stopped's as challenging himself. [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.993 (perp=7.238, rec=0.081, cos=0.465), tot_loss_proj:2.884 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.992 (perp=7.238, rec=0.078, cos=0.465), tot_loss_proj:2.887 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
[1650/2000] tot_loss=1.996 (perp=7.238, rec=0.083, cos=0.466), tot_loss_proj:2.884 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.999 (perp=7.238, rec=0.087, cos=0.465), tot_loss_proj:2.880 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.992 (perp=7.238, rec=0.079, cos=0.465), tot_loss_proj:2.878 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
[1800/2000] tot_loss=1.986 (perp=7.238, rec=0.073, cos=0.465), tot_loss_proj:2.886 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.994 (perp=7.238, rec=0.081, cos=0.466), tot_loss_proj:2.880 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.993 (perp=7.238, rec=0.079, cos=0.466), tot_loss_proj:2.885 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
[1950/2000] tot_loss=1.990 (perp=7.238, rec=0.076, cos=0.466), tot_loss_proj:2.880 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.997 (perp=7.238, rec=0.084, cos=0.465), tot_loss_proj:2.882 [t=0.22s]
prediction: ["[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]"]
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as allen stopped at 66 has stopped 66's as challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 78.571 | r: 91.667
rouge2     | fm: 50.000 | p: 46.154 | r: 54.545
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 134.615

[Aggregate metrics]:
rouge1     | fm: 87.973 | p: 87.184 | r: 88.968
rouge2     | fm: 52.676 | p: 52.457 | r: 52.989
rougeL     | fm: 76.455 | p: 75.821 | r: 77.206
rougeLsum  | fm: 76.449 | p: 75.794 | r: 77.217
r1fm+r2fm = 140.648

input #76 time: 0:08:35 | total time: 11:10:35


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.7236236452492558
highest_index [0]
highest [0.7236236452492558]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.8037549257278442 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.7923843264579773 for ["[CLS] it got tracking holmes internal aboriginal communist seek manifested surface basket nicky cut 'ane [SEP]"]
[Init] best rec loss: 0.7691016793251038 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.7321845293045044 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.7266615629196167 for ['[CLS] too type bred cold crowd more elements lips critique leather under battlefield simple lot pony [SEP]']
[Init] best perm rec loss: 0.7251994013786316 for ['[CLS] crowd cold pony under critique bred simple lips elements battlefield more too leather lot type [SEP]']
[Init] best perm rec loss: 0.7243950963020325 for ['[CLS] elements bred lips type under simple crowd too battlefield leather lot cold more critique pony [SEP]']
[Init] best perm rec loss: 0.7241435050964355 for ['[CLS] more pony leather critique simple under cold type battlefield crowd too lips bred lot elements [SEP]']
[Init] best perm rec loss: 0.7240110039710999 for ['[CLS] too more battlefield lot pony elements crowd type simple critique under bred leather lips cold [SEP]']
[Init] best perm rec loss: 0.7232730984687805 for ['[CLS] lips critique more under lot bred leather crowd battlefield type simple pony cold too elements [SEP]']
[Init] best perm rec loss: 0.7217786312103271 for ['[CLS] type pony cold elements under bred critique battlefield simple more lips crowd lot leather too [SEP]']
[Init] best perm rec loss: 0.72129887342453 for ['[CLS] lot pony bred critique leather under lips simple battlefield more elements too crowd cold type [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.491 (perp=13.049, rec=0.383, cos=0.498), tot_loss_proj:4.500 [t=0.21s]
prediction: ['[CLS] longer collapse after experimental aircraft capable woman above standard las aerial patientxi conditions indoor [SEP]']
[ 100/2000] tot_loss=3.031 (perp=11.601, rec=0.234, cos=0.476), tot_loss_proj:4.168 [t=0.21s]
prediction: ['[CLS] so collapse his utopia aircraft environment forth above side new event colton above beyond climb [SEP]']
[ 150/2000] tot_loss=2.621 (perp=9.848, rec=0.186, cos=0.465), tot_loss_proj:3.854 [t=0.21s]
prediction: ['[CLS] is collapse its promise material lifears above life the such colton material realm make [SEP]']
[ 200/2000] tot_loss=2.773 (perp=10.727, rec=0.154, cos=0.473), tot_loss_proj:4.035 [t=0.21s]
prediction: ['[CLS] is collapse its promise material realmars above life life souted material realm believe [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.476 (perp=9.228, rec=0.151, cos=0.479), tot_loss_proj:3.258 [t=0.21s]
prediction: ['[CLS] is believe its make material realmars above that the soars material realm believe [SEP]']
[ 300/2000] tot_loss=2.511 (perp=9.603, rec=0.121, cos=0.469), tot_loss_proj:3.145 [t=0.21s]
prediction: ['[CLS] is believe its make material realmars above that life soars material promise believe [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.274 (perp=8.477, rec=0.109, cos=0.469), tot_loss_proj:2.957 [t=0.21s]
prediction: ['[CLS] is believe its promise material realmars above that life soars material make believe [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.223 (perp=8.231, rec=0.105, cos=0.472), tot_loss_proj:2.787 [t=0.21s]
prediction: ['[CLS] is life its promise material realmars above that life soars material make believe [SEP]']
[ 450/2000] tot_loss=2.237 (perp=8.306, rec=0.096, cos=0.480), tot_loss_proj:2.833 [t=0.21s]
prediction: ['[CLS] is believe its promise material realmars above that life soars the make believe [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.328 (perp=8.844, rec=0.089, cos=0.470), tot_loss_proj:2.699 [t=0.21s]
prediction: ['[CLS] is of its promise material realmars above life that soars the make believe [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.132 (perp=7.840, rec=0.086, cos=0.478), tot_loss_proj:2.520 [t=0.21s]
prediction: ['[CLS] is its promise of material realmars above life that so believe the make believe [SEP]']
[ 600/2000] tot_loss=2.126 (perp=7.840, rec=0.077, cos=0.481), tot_loss_proj:2.515 [t=0.21s]
prediction: ['[CLS] is its promise of material realmars above life that so believe the make believe [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.066 (perp=7.539, rec=0.085, cos=0.473), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] is its promise of material lifears above realm that so above the make believe [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.993 (perp=7.191, rec=0.078, cos=0.477), tot_loss_proj:2.492 [t=0.21s]
prediction: ['[CLS] is its promise of material lifears above realm so that above the make believe [SEP]']
[ 750/2000] tot_loss=1.987 (perp=7.191, rec=0.075, cos=0.473), tot_loss_proj:2.490 [t=0.21s]
prediction: ['[CLS] is its promise of material lifears above realm so that above the make believe [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.929 (perp=6.959, rec=0.065, cos=0.472), tot_loss_proj:2.426 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that above the make believe [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.897 (perp=6.720, rec=0.080, cos=0.473), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
[ 900/2000] tot_loss=1.895 (perp=6.720, rec=0.077, cos=0.474), tot_loss_proj:2.346 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.886 (perp=6.720, rec=0.069, cos=0.473), tot_loss_proj:2.351 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[1000/2000] tot_loss=1.882 (perp=6.720, rec=0.065, cos=0.474), tot_loss_proj:2.351 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
[1050/2000] tot_loss=1.884 (perp=6.720, rec=0.068, cos=0.472), tot_loss_proj:2.346 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[1100/2000] tot_loss=1.888 (perp=6.720, rec=0.072, cos=0.472), tot_loss_proj:2.348 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[1150/2000] tot_loss=1.891 (perp=6.720, rec=0.071, cos=0.475), tot_loss_proj:2.349 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
[1200/2000] tot_loss=1.888 (perp=6.720, rec=0.074, cos=0.470), tot_loss_proj:2.351 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[1250/2000] tot_loss=1.890 (perp=6.720, rec=0.072, cos=0.474), tot_loss_proj:2.350 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[1300/2000] tot_loss=1.889 (perp=6.720, rec=0.072, cos=0.472), tot_loss_proj:2.352 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
[1350/2000] tot_loss=1.886 (perp=6.720, rec=0.068, cos=0.474), tot_loss_proj:2.353 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
[1400/2000] tot_loss=1.889 (perp=6.720, rec=0.069, cos=0.476), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] is its promise of lifears above material realm so that the make believe above [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.814 (perp=6.352, rec=0.069, cos=0.475), tot_loss_proj:2.101 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above material realm that the make believe above [SEP]']
[1500/2000] tot_loss=1.815 (perp=6.352, rec=0.071, cos=0.474), tot_loss_proj:2.098 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above material realm that the make believe above [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.781 (perp=6.146, rec=0.077, cos=0.475), tot_loss_proj:2.018 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
Attempt swap
[1600/2000] tot_loss=1.780 (perp=6.146, rec=0.077, cos=0.473), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
[1650/2000] tot_loss=1.777 (perp=6.146, rec=0.076, cos=0.472), tot_loss_proj:2.018 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
Attempt swap
[1700/2000] tot_loss=1.762 (perp=6.146, rec=0.060, cos=0.473), tot_loss_proj:2.015 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
Attempt swap
[1750/2000] tot_loss=1.767 (perp=6.146, rec=0.064, cos=0.474), tot_loss_proj:2.021 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
[1800/2000] tot_loss=1.773 (perp=6.146, rec=0.070, cos=0.474), tot_loss_proj:2.006 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
Attempt swap
[1850/2000] tot_loss=1.767 (perp=6.146, rec=0.064, cos=0.473), tot_loss_proj:2.007 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe above [SEP]']
Attempt swap
[1900/2000] tot_loss=1.715 (perp=5.839, rec=0.073, cos=0.475), tot_loss_proj:1.923 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe - [SEP]']
[1950/2000] tot_loss=1.715 (perp=5.839, rec=0.073, cos=0.474), tot_loss_proj:1.913 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.715 (perp=5.839, rec=0.072, cos=0.476), tot_loss_proj:1.930 [t=0.21s]
prediction: ['[CLS] is its promise of life soars above the material realm that make believe - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is its promise of life soars above the material realm that make believe above [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 62.069 | p: 60.000 | r: 64.286
rougeL     | fm: 77.419 | p: 75.000 | r: 80.000
rougeLsum  | fm: 77.419 | p: 75.000 | r: 80.000
r1fm+r2fm = 158.843

[Aggregate metrics]:
rouge1     | fm: 88.177 | p: 87.285 | r: 89.251
rouge2     | fm: 52.927 | p: 52.654 | r: 53.245
rougeL     | fm: 76.413 | p: 75.766 | r: 77.272
rougeLsum  | fm: 76.509 | p: 75.892 | r: 77.246
r1fm+r2fm = 141.104

input #77 time: 0:08:26 | total time: 11:19:02


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.7230097242511264
highest_index [0]
highest [0.7230097242511264]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9496431350708008 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9168174266815186 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.801803469657898 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8010314106941223 for ['[CLS] frontuting grace [SEP]']
[Init] best rec loss: 0.7653054594993591 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.7592409253120422 for ['[CLS] le grant screens [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.475 (perp=8.971, rec=0.206, cos=0.474), tot_loss_proj:2.920 [t=0.21s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=2.397 (perp=9.116, rec=0.100, cos=0.473), tot_loss_proj:3.045 [t=0.21s]
prediction: ['[CLS] exit theater theater [SEP]']
[ 150/2000] tot_loss=2.144 (perp=7.958, rec=0.077, cos=0.474), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=2.135 (perp=7.958, rec=0.067, cos=0.476), tot_loss_proj:2.152 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.138 (perp=7.958, rec=0.070, cos=0.477), tot_loss_proj:2.151 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=2.133 (perp=7.958, rec=0.065, cos=0.476), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.132 (perp=7.958, rec=0.065, cos=0.475), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.130 (perp=7.958, rec=0.063, cos=0.476), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=2.122 (perp=7.958, rec=0.055, cos=0.476), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.132 (perp=7.958, rec=0.064, cos=0.476), tot_loss_proj:2.156 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.134 (perp=7.958, rec=0.066, cos=0.477), tot_loss_proj:2.157 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=2.130 (perp=7.958, rec=0.063, cos=0.475), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.131 (perp=7.958, rec=0.064, cos=0.475), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.136 (perp=7.958, rec=0.069, cos=0.476), tot_loss_proj:2.149 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=2.134 (perp=7.958, rec=0.067, cos=0.475), tot_loss_proj:2.144 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.131 (perp=7.958, rec=0.063, cos=0.476), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.120 (perp=7.958, rec=0.054, cos=0.475), tot_loss_proj:2.146 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=2.131 (perp=7.958, rec=0.063, cos=0.476), tot_loss_proj:2.147 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.142 (perp=7.958, rec=0.075, cos=0.475), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=2.127 (perp=7.958, rec=0.060, cos=0.476), tot_loss_proj:2.155 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=2.133 (perp=7.958, rec=0.065, cos=0.476), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=2.131 (perp=7.958, rec=0.063, cos=0.477), tot_loss_proj:2.152 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=2.135 (perp=7.958, rec=0.067, cos=0.476), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=2.123 (perp=7.958, rec=0.054, cos=0.477), tot_loss_proj:2.159 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=2.123 (perp=7.958, rec=0.055, cos=0.476), tot_loss_proj:2.145 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=2.130 (perp=7.958, rec=0.062, cos=0.476), tot_loss_proj:2.155 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=2.133 (perp=7.958, rec=0.064, cos=0.477), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=2.133 (perp=7.958, rec=0.066, cos=0.475), tot_loss_proj:2.156 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=2.131 (perp=7.958, rec=0.062, cos=0.477), tot_loss_proj:2.143 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=2.129 (perp=7.958, rec=0.060, cos=0.477), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=2.131 (perp=7.958, rec=0.063, cos=0.477), tot_loss_proj:2.146 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=2.128 (perp=7.958, rec=0.059, cos=0.477), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=2.127 (perp=7.958, rec=0.059, cos=0.476), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=2.132 (perp=7.958, rec=0.064, cos=0.476), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=2.123 (perp=7.958, rec=0.055, cos=0.476), tot_loss_proj:2.158 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=2.130 (perp=7.958, rec=0.062, cos=0.476), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=2.123 (perp=7.958, rec=0.055, cos=0.476), tot_loss_proj:2.148 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=2.132 (perp=7.958, rec=0.063, cos=0.477), tot_loss_proj:2.146 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=2.134 (perp=7.958, rec=0.065, cos=0.477), tot_loss_proj:2.155 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=2.140 (perp=7.958, rec=0.071, cos=0.477), tot_loss_proj:2.146 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.385 | p: 87.585 | r: 89.353
rouge2     | fm: 53.402 | p: 53.100 | r: 53.718
rougeL     | fm: 76.740 | p: 76.133 | r: 77.557
rougeLsum  | fm: 76.729 | p: 76.140 | r: 77.591
r1fm+r2fm = 141.786

input #78 time: 0:08:26 | total time: 11:27:28


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.7363638263479299
highest_index [0]
highest [0.7363638263479299]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9673061370849609 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9604708552360535 for ['[CLS] chicago militia [SEP]']
[Init] best rec loss: 0.9476644396781921 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 0.943590521812439 for ['[CLS] neither tokyo [SEP]']
[Init] best rec loss: 0.8789163827896118 for ['[CLS] clay starts [SEP]']
[Init] best rec loss: 0.8560734987258911 for ['[CLS] armada containing [SEP]']
[Init] best rec loss: 0.8158507347106934 for ['[CLS] amount volumes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.941 (perp=11.427, rec=0.198, cos=0.457), tot_loss_proj:3.119 [t=0.21s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.893 (perp=11.427, rec=0.150, cos=0.457), tot_loss_proj:3.095 [t=0.21s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.888 (perp=11.427, rec=0.145, cos=0.458), tot_loss_proj:3.089 [t=0.21s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.426 (perp=9.381, rec=0.091, cos=0.458), tot_loss_proj:2.413 [t=0.21s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.277 (perp=8.695, rec=0.083, cos=0.455), tot_loss_proj:2.450 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=2.257 (perp=8.695, rec=0.061, cos=0.457), tot_loss_proj:2.442 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.263 (perp=8.695, rec=0.067, cos=0.458), tot_loss_proj:2.425 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.260 (perp=8.695, rec=0.065, cos=0.456), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=2.261 (perp=8.695, rec=0.066, cos=0.456), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.265 (perp=8.695, rec=0.069, cos=0.457), tot_loss_proj:2.427 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.259 (perp=8.695, rec=0.063, cos=0.457), tot_loss_proj:2.432 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=2.255 (perp=8.695, rec=0.059, cos=0.457), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.263 (perp=8.695, rec=0.067, cos=0.458), tot_loss_proj:2.420 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.270 (perp=8.695, rec=0.074, cos=0.457), tot_loss_proj:2.427 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=2.268 (perp=8.695, rec=0.073, cos=0.457), tot_loss_proj:2.422 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.265 (perp=8.695, rec=0.070, cos=0.456), tot_loss_proj:2.423 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.262 (perp=8.695, rec=0.066, cos=0.457), tot_loss_proj:2.427 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=2.255 (perp=8.695, rec=0.059, cos=0.457), tot_loss_proj:2.423 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.269 (perp=8.695, rec=0.074, cos=0.457), tot_loss_proj:2.424 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=2.255 (perp=8.695, rec=0.059, cos=0.457), tot_loss_proj:2.420 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=2.257 (perp=8.695, rec=0.060, cos=0.458), tot_loss_proj:2.424 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=2.259 (perp=8.695, rec=0.063, cos=0.457), tot_loss_proj:2.420 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=2.260 (perp=8.695, rec=0.063, cos=0.458), tot_loss_proj:2.417 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=2.261 (perp=8.695, rec=0.065, cos=0.457), tot_loss_proj:2.419 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=2.266 (perp=8.695, rec=0.069, cos=0.458), tot_loss_proj:2.425 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.257 (perp=8.695, rec=0.061, cos=0.457), tot_loss_proj:2.417 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=2.262 (perp=8.695, rec=0.066, cos=0.457), tot_loss_proj:2.420 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.250 (perp=8.695, rec=0.054, cos=0.457), tot_loss_proj:2.422 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.258 (perp=8.695, rec=0.062, cos=0.457), tot_loss_proj:2.420 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=2.248 (perp=8.695, rec=0.052, cos=0.458), tot_loss_proj:2.424 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.265 (perp=8.695, rec=0.069, cos=0.457), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.265 (perp=8.695, rec=0.068, cos=0.458), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=2.249 (perp=8.695, rec=0.053, cos=0.457), tot_loss_proj:2.414 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.272 (perp=8.695, rec=0.076, cos=0.458), tot_loss_proj:2.421 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.261 (perp=8.695, rec=0.065, cos=0.458), tot_loss_proj:2.434 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=2.259 (perp=8.695, rec=0.063, cos=0.458), tot_loss_proj:2.422 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.268 (perp=8.695, rec=0.071, cos=0.458), tot_loss_proj:2.426 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.258 (perp=8.695, rec=0.062, cos=0.458), tot_loss_proj:2.415 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=2.263 (perp=8.695, rec=0.067, cos=0.457), tot_loss_proj:2.415 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.260 (perp=8.695, rec=0.064, cos=0.458), tot_loss_proj:2.413 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.469 | p: 87.640 | r: 89.443
rouge2     | fm: 52.801 | p: 52.552 | r: 53.133
rougeL     | fm: 76.725 | p: 76.114 | r: 77.559
rougeLsum  | fm: 76.863 | p: 76.249 | r: 77.664
r1fm+r2fm = 141.270

input #79 time: 0:08:23 | total time: 11:35:52


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.7353553518052489
highest_index [0]
highest [0.7353553518052489]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9797466993331909 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9582498073577881 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.941961407661438 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.912851870059967 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.905197024345398 for ['[CLS] harvest neutron bye ottawa [SEP]']
[Init] best rec loss: 0.8831847310066223 for ['[CLS] heard pavilionplane ian tu [SEP]']
[Init] best perm rec loss: 0.8823471665382385 for ['[CLS] heardplane ian tu pavilion [SEP]']
[Init] best perm rec loss: 0.8814973831176758 for ['[CLS] pavilion tuplane heard ian [SEP]']
[Init] best perm rec loss: 0.8810059428215027 for ['[CLS] ian heard tu pavilionplane [SEP]']
[Init] best perm rec loss: 0.8801438808441162 for ['[CLS] heardplane ian pavilion tu [SEP]']
[Init] best perm rec loss: 0.8792060613632202 for ['[CLS] ianplane tu pavilion heard [SEP]']
[Init] best perm rec loss: 0.8779330253601074 for ['[CLS] tu ianplane pavilion heard [SEP]']
[Init] best perm rec loss: 0.8749815225601196 for ['[CLS] ianplane heard pavilion tu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.357 (perp=11.300, rec=0.629, cos=0.468), tot_loss_proj:4.220 [t=0.21s]
prediction: ['[CLS]tie ofwg permitted visitors [SEP]']
[ 100/2000] tot_loss=3.274 (perp=11.250, rec=0.544, cos=0.480), tot_loss_proj:4.223 [t=0.21s]
prediction: ['[CLS] wizard of torture recommended wi [SEP]']
[ 150/2000] tot_loss=3.406 (perp=12.437, rec=0.520, cos=0.398), tot_loss_proj:4.356 [t=0.21s]
prediction: ['[CLS] sid in rank seeing wi [SEP]']
[ 200/2000] tot_loss=3.037 (perp=10.790, rec=0.495, cos=0.384), tot_loss_proj:3.932 [t=0.22s]
prediction: ['[CLS] wi referees torture seeing wi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.282 (perp=11.976, rec=0.474, cos=0.413), tot_loss_proj:4.348 [t=0.21s]
prediction: ['[CLS] wi handsome grey holder wi [SEP]']
[ 300/2000] tot_loss=3.391 (perp=12.474, rec=0.446, cos=0.450), tot_loss_proj:4.282 [t=0.22s]
prediction: ['[CLS] wi wi grey holderzen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.186 (perp=11.778, rec=0.438, cos=0.392), tot_loss_proj:4.270 [t=0.22s]
prediction: ['[CLS] candidate wifoil wizen [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.956 (perp=10.748, rec=0.423, cos=0.383), tot_loss_proj:3.792 [t=0.21s]
prediction: ['[CLS] wise wifoil wizen [SEP]']
[ 450/2000] tot_loss=3.080 (perp=11.532, rec=0.414, cos=0.360), tot_loss_proj:3.939 [t=0.21s]
prediction: ['[CLS] wise wi milos wizen [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.232 (perp=11.532, rec=0.397, cos=0.529), tot_loss_proj:3.933 [t=0.22s]
prediction: ['[CLS] wise wi milos wizen [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.829 (perp=10.376, rec=0.399, cos=0.354), tot_loss_proj:3.450 [t=0.22s]
prediction: ['[CLS] wise wi y wizen [SEP]']
[ 600/2000] tot_loss=2.820 (perp=10.376, rec=0.387, cos=0.358), tot_loss_proj:3.453 [t=0.22s]
prediction: ['[CLS] wise wi y wizen [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.883 (perp=10.376, rec=0.389, cos=0.418), tot_loss_proj:3.450 [t=0.22s]
prediction: ['[CLS] wise wi y wizen [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.137 (perp=11.945, rec=0.383, cos=0.365), tot_loss_proj:4.010 [t=0.22s]
prediction: ['[CLS] wise wisus wizen [SEP]']
[ 750/2000] tot_loss=2.965 (perp=10.945, rec=0.381, cos=0.395), tot_loss_proj:3.682 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.985 (perp=10.945, rec=0.372, cos=0.423), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.045 (perp=10.945, rec=0.373, cos=0.483), tot_loss_proj:3.684 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[ 900/2000] tot_loss=2.926 (perp=10.945, rec=0.362, cos=0.375), tot_loss_proj:3.691 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.984 (perp=10.945, rec=0.369, cos=0.426), tot_loss_proj:3.690 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1000/2000] tot_loss=2.957 (perp=10.945, rec=0.362, cos=0.406), tot_loss_proj:3.684 [t=0.21s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1050/2000] tot_loss=3.128 (perp=11.390, rec=0.360, cos=0.490), tot_loss_proj:3.977 [t=0.22s]
prediction: ['[CLS] wise wi blu wizen [SEP]']
Attempt swap
[1100/2000] tot_loss=2.960 (perp=10.945, rec=0.364, cos=0.407), tot_loss_proj:3.687 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1150/2000] tot_loss=2.945 (perp=10.945, rec=0.360, cos=0.396), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1200/2000] tot_loss=3.004 (perp=10.945, rec=0.356, cos=0.459), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1250/2000] tot_loss=2.971 (perp=10.945, rec=0.347, cos=0.435), tot_loss_proj:3.691 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1300/2000] tot_loss=2.978 (perp=10.945, rec=0.355, cos=0.434), tot_loss_proj:3.679 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1350/2000] tot_loss=2.985 (perp=10.945, rec=0.357, cos=0.439), tot_loss_proj:3.688 [t=0.21s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1400/2000] tot_loss=2.981 (perp=10.945, rec=0.346, cos=0.446), tot_loss_proj:3.697 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1450/2000] tot_loss=2.966 (perp=10.945, rec=0.351, cos=0.426), tot_loss_proj:3.680 [t=0.21s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1500/2000] tot_loss=2.952 (perp=10.945, rec=0.354, cos=0.409), tot_loss_proj:3.685 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1550/2000] tot_loss=2.970 (perp=10.945, rec=0.356, cos=0.425), tot_loss_proj:3.682 [t=0.21s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1600/2000] tot_loss=2.986 (perp=10.945, rec=0.351, cos=0.446), tot_loss_proj:3.693 [t=0.21s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1650/2000] tot_loss=2.999 (perp=10.945, rec=0.353, cos=0.457), tot_loss_proj:3.680 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1700/2000] tot_loss=2.980 (perp=10.945, rec=0.351, cos=0.440), tot_loss_proj:3.686 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1750/2000] tot_loss=2.983 (perp=10.945, rec=0.354, cos=0.440), tot_loss_proj:3.693 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1800/2000] tot_loss=3.009 (perp=10.945, rec=0.350, cos=0.470), tot_loss_proj:3.695 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1850/2000] tot_loss=2.971 (perp=10.945, rec=0.345, cos=0.437), tot_loss_proj:3.691 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[1900/2000] tot_loss=2.993 (perp=10.945, rec=0.352, cos=0.452), tot_loss_proj:3.692 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
[1950/2000] tot_loss=2.992 (perp=10.945, rec=0.345, cos=0.458), tot_loss_proj:3.688 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Attempt swap
[2000/2000] tot_loss=2.990 (perp=10.945, rec=0.353, cos=0.448), tot_loss_proj:3.685 [t=0.22s]
prediction: ['[CLS] wise wiwn wizen [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise wiwn wizen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 88.192 | p: 87.310 | r: 89.270
rouge2     | fm: 52.545 | p: 52.210 | r: 52.951
rougeL     | fm: 76.652 | p: 75.913 | r: 77.504
rougeLsum  | fm: 76.705 | p: 75.968 | r: 77.563
r1fm+r2fm = 140.737

input #80 time: 0:08:30 | total time: 11:44:22


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.7125623080896436
highest_index [0]
highest [0.7125623080896436]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9537726640701294 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9258322715759277 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.8797597885131836 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8459808230400085 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8420710563659668 for ['[CLS]eering dominance sectional cummings lil yankee [SEP]']
[Init] best rec loss: 0.8046067357063293 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.7955604195594788 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7772215604782104 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best perm rec loss: 0.7749865651130676 for ['[CLS] threads approval modelled bandsitating missing [SEP]']
[Init] best perm rec loss: 0.774967610836029 for ['[CLS] missingitating threads bands modelled approval [SEP]']
[Init] best perm rec loss: 0.7746109366416931 for ['[CLS] bands modelled approval missingitating threads [SEP]']
[Init] best perm rec loss: 0.7742177248001099 for ['[CLS] approval missing threadsitating bands modelled [SEP]']
[Init] best perm rec loss: 0.7734448313713074 for ['[CLS]itating modelled bands approval missing threads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.489 (perp=8.709, rec=0.272, cos=0.474), tot_loss_proj:2.841 [t=0.21s]
prediction: ['[CLS] player is the little not impressive [SEP]']
[ 100/2000] tot_loss=2.301 (perp=8.308, rec=0.147, cos=0.492), tot_loss_proj:3.206 [t=0.21s]
prediction: ['[CLS] player is the impressive not impressive [SEP]']
[ 150/2000] tot_loss=1.979 (perp=7.073, rec=0.080, cos=0.484), tot_loss_proj:2.532 [t=0.22s]
prediction: ['[CLS] player is the most not impressive [SEP]']
[ 200/2000] tot_loss=1.991 (perp=7.073, rec=0.083, cos=0.493), tot_loss_proj:2.524 [t=0.21s]
prediction: ['[CLS] player is the most not impressive [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.762 (perp=5.946, rec=0.081, cos=0.492), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[ 300/2000] tot_loss=1.762 (perp=5.946, rec=0.083, cos=0.489), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.755 (perp=5.946, rec=0.074, cos=0.493), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.749 (perp=5.946, rec=0.074, cos=0.486), tot_loss_proj:2.067 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[ 450/2000] tot_loss=1.757 (perp=5.946, rec=0.074, cos=0.494), tot_loss_proj:2.059 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.751 (perp=5.946, rec=0.075, cos=0.488), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.742 (perp=5.946, rec=0.061, cos=0.491), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[ 600/2000] tot_loss=1.751 (perp=5.946, rec=0.071, cos=0.491), tot_loss_proj:2.063 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.743 (perp=5.946, rec=0.064, cos=0.490), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.750 (perp=5.946, rec=0.071, cos=0.490), tot_loss_proj:2.059 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[ 750/2000] tot_loss=1.748 (perp=5.946, rec=0.069, cos=0.489), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.748 (perp=5.946, rec=0.068, cos=0.491), tot_loss_proj:2.070 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.744 (perp=5.946, rec=0.064, cos=0.490), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[ 900/2000] tot_loss=1.749 (perp=5.946, rec=0.071, cos=0.489), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.745 (perp=5.946, rec=0.065, cos=0.490), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.739 (perp=5.946, rec=0.058, cos=0.492), tot_loss_proj:2.065 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1050/2000] tot_loss=1.741 (perp=5.946, rec=0.062, cos=0.490), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.750 (perp=5.946, rec=0.070, cos=0.491), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.745 (perp=5.946, rec=0.065, cos=0.490), tot_loss_proj:2.067 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1200/2000] tot_loss=1.737 (perp=5.946, rec=0.058, cos=0.490), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.743 (perp=5.946, rec=0.064, cos=0.490), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.747 (perp=5.946, rec=0.067, cos=0.491), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1350/2000] tot_loss=1.749 (perp=5.946, rec=0.069, cos=0.490), tot_loss_proj:2.062 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.744 (perp=5.946, rec=0.064, cos=0.491), tot_loss_proj:2.054 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.747 (perp=5.946, rec=0.067, cos=0.491), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1500/2000] tot_loss=1.750 (perp=5.946, rec=0.070, cos=0.490), tot_loss_proj:2.067 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.737 (perp=5.946, rec=0.056, cos=0.491), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.748 (perp=5.946, rec=0.067, cos=0.491), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1650/2000] tot_loss=1.753 (perp=5.946, rec=0.073, cos=0.491), tot_loss_proj:2.056 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.743 (perp=5.946, rec=0.062, cos=0.492), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.746 (perp=5.946, rec=0.066, cos=0.491), tot_loss_proj:2.061 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1800/2000] tot_loss=1.744 (perp=5.946, rec=0.063, cos=0.492), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.746 (perp=5.946, rec=0.066, cos=0.491), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.737 (perp=5.946, rec=0.057, cos=0.492), tot_loss_proj:2.063 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1950/2000] tot_loss=1.744 (perp=5.946, rec=0.063, cos=0.492), tot_loss_proj:2.065 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.748 (perp=5.946, rec=0.067, cos=0.492), tot_loss_proj:2.063 [t=0.21s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] player is not the most impressive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 88.386 | p: 87.545 | r: 89.402
rouge2     | fm: 52.617 | p: 52.315 | r: 53.006
rougeL     | fm: 76.756 | p: 76.045 | r: 77.632
rougeLsum  | fm: 76.750 | p: 76.086 | r: 77.598
r1fm+r2fm = 141.003

input #81 time: 0:08:29 | total time: 11:52:52


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.7118845830777596
highest_index [0]
highest [0.7118845830777596]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9496618509292603 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9484602212905884 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9474796652793884 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.943726122379303 for ['[CLS] seminetive facing toward victor trance grown [SEP]']
[Init] best rec loss: 0.9390313625335693 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9272831678390503 for ['[CLS] firmly wilder after weighted ninection latter i [SEP]']
[Init] best rec loss: 0.9052798748016357 for ['[CLS] seaside ray moved throat traitor mistake ports homage [SEP]']
[Init] best rec loss: 0.8950904011726379 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best perm rec loss: 0.8932612538337708 for ['[CLS] soft ericturn distribution letter aesian baby [SEP]']
[Init] best perm rec loss: 0.8931149244308472 for ['[CLS] baby ericturnesian distribution a letter soft [SEP]']
[Init] best perm rec loss: 0.892227053642273 for ['[CLS] distribution baby letter eric softesian aturn [SEP]']
[Init] best perm rec loss: 0.8914644718170166 for ['[CLS] letter distributionturnesian soft a eric baby [SEP]']
[Init] best perm rec loss: 0.8911721706390381 for ['[CLS] baby aturn distribution eric letteresian soft [SEP]']
[Init] best perm rec loss: 0.8907532095909119 for ['[CLS]turnesian eric distribution letter a soft baby [SEP]']
[Init] best perm rec loss: 0.8906834125518799 for ['[CLS] babyturnesian letter eric a distribution soft [SEP]']
[Init] best perm rec loss: 0.890588641166687 for ['[CLS]turn distributionesian eric baby soft a letter [SEP]']
[Init] best perm rec loss: 0.8891643285751343 for ['[CLS] letter a softesianturn eric distribution baby [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.212 (perp=12.514, rec=0.220, cos=0.490), tot_loss_proj:3.845 [t=0.21s]
prediction: ['[CLS] edited script its dammit a are script undone [SEP]']
[ 100/2000] tot_loss=2.557 (perp=9.817, rec=0.103, cos=0.491), tot_loss_proj:2.951 [t=0.21s]
prediction: ['[CLS] sloppy sloppy its undone by a script undone [SEP]']
[ 150/2000] tot_loss=2.685 (perp=10.497, rec=0.093, cos=0.492), tot_loss_proj:3.188 [t=0.21s]
prediction: ['[CLS] sloppy sloppy s undone by a script undone [SEP]']
[ 200/2000] tot_loss=2.320 (perp=8.735, rec=0.081, cos=0.492), tot_loss_proj:2.789 [t=0.21s]
prediction: ['[CLS] it sloppy s undone by a script undone [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.473 (perp=9.234, rec=0.128, cos=0.498), tot_loss_proj:2.870 [t=0.21s]
prediction: ['[CLS] it s ( by a sloppy script undone [SEP]']
[ 300/2000] tot_loss=2.432 (perp=9.234, rec=0.094, cos=0.491), tot_loss_proj:2.873 [t=0.21s]
prediction: ['[CLS] it s ( by a sloppy script undone [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.004 (perp=7.202, rec=0.074, cos=0.490), tot_loss_proj:2.153 [t=0.21s]
prediction: ['[CLS] it s undone by a sloppy script ( [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.929 (perp=6.799, rec=0.080, cos=0.489), tot_loss_proj:2.173 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[ 450/2000] tot_loss=1.932 (perp=6.799, rec=0.080, cos=0.492), tot_loss_proj:2.162 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.918 (perp=6.799, rec=0.066, cos=0.493), tot_loss_proj:2.166 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.926 (perp=6.799, rec=0.075, cos=0.491), tot_loss_proj:2.159 [t=0.22s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[ 600/2000] tot_loss=1.923 (perp=6.799, rec=0.070, cos=0.493), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.917 (perp=6.799, rec=0.065, cos=0.492), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.923 (perp=6.799, rec=0.072, cos=0.492), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[ 750/2000] tot_loss=1.917 (perp=6.799, rec=0.065, cos=0.492), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.922 (perp=6.799, rec=0.070, cos=0.493), tot_loss_proj:2.165 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.917 (perp=6.799, rec=0.065, cos=0.492), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[ 900/2000] tot_loss=1.922 (perp=6.799, rec=0.069, cos=0.494), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.921 (perp=6.799, rec=0.070, cos=0.492), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1000/2000] tot_loss=1.919 (perp=6.799, rec=0.068, cos=0.491), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1050/2000] tot_loss=1.927 (perp=6.799, rec=0.075, cos=0.491), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1100/2000] tot_loss=1.921 (perp=6.799, rec=0.070, cos=0.491), tot_loss_proj:2.171 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.923 (perp=6.799, rec=0.070, cos=0.493), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1200/2000] tot_loss=1.920 (perp=6.799, rec=0.068, cos=0.492), tot_loss_proj:2.162 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.920 (perp=6.799, rec=0.068, cos=0.492), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1300/2000] tot_loss=1.924 (perp=6.799, rec=0.072, cos=0.492), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1350/2000] tot_loss=1.916 (perp=6.799, rec=0.064, cos=0.493), tot_loss_proj:2.166 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1400/2000] tot_loss=1.921 (perp=6.799, rec=0.069, cos=0.493), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1450/2000] tot_loss=1.921 (perp=6.799, rec=0.069, cos=0.492), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1500/2000] tot_loss=1.919 (perp=6.799, rec=0.066, cos=0.493), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1550/2000] tot_loss=1.912 (perp=6.799, rec=0.060, cos=0.493), tot_loss_proj:2.164 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1600/2000] tot_loss=1.917 (perp=6.799, rec=0.064, cos=0.493), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1650/2000] tot_loss=1.918 (perp=6.799, rec=0.066, cos=0.493), tot_loss_proj:2.159 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1700/2000] tot_loss=1.920 (perp=6.799, rec=0.068, cos=0.493), tot_loss_proj:2.164 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1750/2000] tot_loss=1.928 (perp=6.799, rec=0.075, cos=0.493), tot_loss_proj:2.168 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1800/2000] tot_loss=1.921 (perp=6.799, rec=0.068, cos=0.493), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1850/2000] tot_loss=1.924 (perp=6.799, rec=0.072, cos=0.493), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[1900/2000] tot_loss=1.916 (perp=6.799, rec=0.064, cos=0.492), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
[1950/2000] tot_loss=1.913 (perp=6.799, rec=0.061, cos=0.492), tot_loss_proj:2.165 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Attempt swap
[2000/2000] tot_loss=1.930 (perp=6.799, rec=0.078, cos=0.493), tot_loss_proj:2.161 [t=0.21s]
prediction: ['[CLS] it undone by a sloppy script ( s [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it undone by a sloppy script ( s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 88.472 | p: 87.620 | r: 89.522
rouge2     | fm: 52.676 | p: 52.376 | r: 53.041
rougeL     | fm: 76.910 | p: 76.188 | r: 77.790
rougeLsum  | fm: 76.953 | p: 76.237 | r: 77.824
r1fm+r2fm = 141.147

input #82 time: 0:08:29 | total time: 12:01:21


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.725587372929831
highest_index [0]
highest [0.725587372929831]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8523553013801575 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8508415222167969 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8324490785598755 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.8292710185050964 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 0.7959343791007996 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.7912304401397705 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.7903756499290466 for ['[CLS] envelope residence neck stew vice nearly follows comprehensive pitch boys [SEP]']
[Init] best perm rec loss: 0.7890905737876892 for ['[CLS] residence pitch follows neck boys vice nearly comprehensive envelope stew [SEP]']
[Init] best perm rec loss: 0.7852483987808228 for ['[CLS] pitch residence comprehensive stew vice follows nearly neck envelope boys [SEP]']
[Init] best perm rec loss: 0.7801233530044556 for ['[CLS] nearly vice pitch follows comprehensive neck boys stew residence envelope [SEP]']
[Init] best perm rec loss: 0.7799180150032043 for ['[CLS] pitch envelope nearly vice stew neck follows boys residence comprehensive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.025 (perp=10.858, rec=0.382, cos=0.471), tot_loss_proj:3.824 [t=0.21s]
prediction: ['[CLS] ghana offer when young january culture when when when britain [SEP]']
[ 100/2000] tot_loss=2.717 (perp=9.977, rec=0.252, cos=0.470), tot_loss_proj:3.743 [t=0.22s]
prediction: ['[CLS] what wants when wants 1016 wants when when know it [SEP]']
[ 150/2000] tot_loss=2.649 (perp=10.088, rec=0.164, cos=0.468), tot_loss_proj:3.702 [t=0.22s]
prediction: ['[CLS] what be it grows would wants grows when know it [SEP]']
[ 200/2000] tot_loss=2.278 (perp=8.500, rec=0.106, cos=0.472), tot_loss_proj:3.179 [t=0.22s]
prediction: ['[CLS] what be it grows when wants grows when know it [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.500 (perp=9.466, rec=0.130, cos=0.476), tot_loss_proj:3.558 [t=0.22s]
prediction: ['[CLS] what be it grows wants grows when when know it [SEP]']
[ 300/2000] tot_loss=2.319 (perp=8.751, rec=0.096, cos=0.473), tot_loss_proj:3.438 [t=0.22s]
prediction: ['[CLS] what be it up wants grows when when know it [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.186 (perp=8.152, rec=0.087, cos=0.469), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] what be it when wants grows up when know it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.040 (perp=7.432, rec=0.080, cos=0.474), tot_loss_proj:2.765 [t=0.22s]
prediction: ['[CLS] what when it be wants grows up when know it [SEP]']
[ 450/2000] tot_loss=2.037 (perp=7.432, rec=0.078, cos=0.472), tot_loss_proj:2.761 [t=0.22s]
prediction: ['[CLS] what when it be wants grows up when know it [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.864 (perp=6.600, rec=0.073, cos=0.472), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] what when it be wants and know it grows up [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.808 (perp=6.059, rec=0.122, cos=0.474), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] what it be wants and know when it grows up [SEP]']
[ 600/2000] tot_loss=1.774 (perp=6.059, rec=0.091, cos=0.472), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] what it be wants and know when it grows up [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.694 (perp=5.717, rec=0.079, cos=0.471), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] know what it be wants and when it grows up [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.597 (perp=5.215, rec=0.083, cos=0.471), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[ 750/2000] tot_loss=1.589 (perp=5.215, rec=0.074, cos=0.472), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=5.215, rec=0.073, cos=0.471), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.585 (perp=5.215, rec=0.071, cos=0.471), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[ 900/2000] tot_loss=1.584 (perp=5.215, rec=0.068, cos=0.473), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.588 (perp=5.215, rec=0.072, cos=0.473), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.593 (perp=5.215, rec=0.078, cos=0.472), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1050/2000] tot_loss=1.590 (perp=5.215, rec=0.075, cos=0.472), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=5.215, rec=0.072, cos=0.473), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.590 (perp=5.215, rec=0.076, cos=0.471), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1200/2000] tot_loss=1.586 (perp=5.215, rec=0.070, cos=0.474), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.593 (perp=5.215, rec=0.077, cos=0.473), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.593 (perp=5.215, rec=0.076, cos=0.473), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1350/2000] tot_loss=1.592 (perp=5.215, rec=0.076, cos=0.473), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.593 (perp=5.215, rec=0.077, cos=0.473), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.592 (perp=5.215, rec=0.076, cos=0.474), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1500/2000] tot_loss=1.585 (perp=5.215, rec=0.069, cos=0.473), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.587 (perp=5.215, rec=0.071, cos=0.473), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.592 (perp=5.215, rec=0.076, cos=0.473), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1650/2000] tot_loss=1.587 (perp=5.215, rec=0.071, cos=0.473), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.581 (perp=5.215, rec=0.065, cos=0.473), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.580 (perp=5.215, rec=0.065, cos=0.472), tot_loss_proj:1.988 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1800/2000] tot_loss=1.589 (perp=5.215, rec=0.073, cos=0.473), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.587 (perp=5.215, rec=0.070, cos=0.474), tot_loss_proj:1.986 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.581 (perp=5.215, rec=0.065, cos=0.473), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
[1950/2000] tot_loss=1.588 (perp=5.215, rec=0.072, cos=0.473), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=5.215, rec=0.070, cos=0.474), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] be know what it wants and when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] be know what it wants and when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 63.636 | p: 63.636 | r: 63.636
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 155.303

[Aggregate metrics]:
rouge1     | fm: 88.525 | p: 87.688 | r: 89.571
rouge2     | fm: 52.661 | p: 52.354 | r: 53.097
rougeL     | fm: 77.094 | p: 76.373 | r: 77.937
rougeLsum  | fm: 76.933 | p: 76.259 | r: 77.825
r1fm+r2fm = 141.186

input #83 time: 0:08:38 | total time: 12:09:59


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.7252250150618575
highest_index [0]
highest [0.7252250150618575]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.8983954191207886 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8730149865150452 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8601345419883728 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8567259311676025 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.8447322845458984 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.833433985710144 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8276147246360779 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8232232332229614 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8205681443214417 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8152706623077393 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8144674301147461 for ['[CLS] acacia horatio netflix house max supplieduin [SEP]']
[Init] best rec loss: 0.7965165376663208 for ['[CLS] hometails para hundreds sexy couple chinese [SEP]']
[Init] best perm rec loss: 0.7960189580917358 for ['[CLS] chinese sexy hundreds paratails couple home [SEP]']
[Init] best perm rec loss: 0.7948487401008606 for ['[CLS] chinesetails para couple home sexy hundreds [SEP]']
[Init] best perm rec loss: 0.7939887046813965 for ['[CLS]tails chinese sexy para hundreds home couple [SEP]']
[Init] best perm rec loss: 0.7938946485519409 for ['[CLS]tails couple chinese sexy para home hundreds [SEP]']
[Init] best perm rec loss: 0.7936350703239441 for ['[CLS] home couple para hundredstails chinese sexy [SEP]']
[Init] best perm rec loss: 0.7930968403816223 for ['[CLS] couple sexy para hundredstails chinese home [SEP]']
[Init] best perm rec loss: 0.7911797165870667 for ['[CLS] sexy couple para hundredstails chinese home [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.027 (perp=10.292, rec=0.381, cos=0.589), tot_loss_proj:3.262 [t=0.21s]
prediction: ['[CLS] - think ability lost lost think lost [SEP]']
[ 100/2000] tot_loss=2.853 (perp=11.261, rec=0.128, cos=0.473), tot_loss_proj:3.412 [t=0.21s]
prediction: ['[CLS] have think ability lost lost ability people [SEP]']
[ 150/2000] tot_loss=2.525 (perp=9.809, rec=0.092, cos=0.471), tot_loss_proj:3.244 [t=0.21s]
prediction: ['[CLS] have think the lost lost ability people [SEP]']
[ 200/2000] tot_loss=2.515 (perp=9.809, rec=0.084, cos=0.469), tot_loss_proj:3.250 [t=0.22s]
prediction: ['[CLS] have think the lost lost ability people [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.138 (perp=7.895, rec=0.088, cos=0.471), tot_loss_proj:2.712 [t=0.21s]
prediction: ['[CLS] have the lost lost ability people think [SEP]']
[ 300/2000] tot_loss=2.122 (perp=7.895, rec=0.072, cos=0.471), tot_loss_proj:2.712 [t=0.21s]
prediction: ['[CLS] have the lost lost ability people think [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.194 (perp=8.240, rec=0.074, cos=0.472), tot_loss_proj:2.739 [t=0.21s]
prediction: ['[CLS] have lost the to ability people think [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.653 (perp=5.493, rec=0.082, cos=0.472), tot_loss_proj:1.983 [t=0.21s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
[ 450/2000] tot_loss=1.640 (perp=5.493, rec=0.069, cos=0.472), tot_loss_proj:1.978 [t=0.21s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.643 (perp=5.493, rec=0.070, cos=0.474), tot_loss_proj:1.987 [t=0.21s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.477 (perp=4.681, rec=0.068, cos=0.473), tot_loss_proj:1.504 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.475 (perp=4.681, rec=0.066, cos=0.473), tot_loss_proj:1.503 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.478 (perp=4.681, rec=0.070, cos=0.471), tot_loss_proj:1.508 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.475 (perp=4.681, rec=0.065, cos=0.474), tot_loss_proj:1.501 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.471 (perp=4.681, rec=0.063, cos=0.472), tot_loss_proj:1.505 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.476 (perp=4.681, rec=0.066, cos=0.474), tot_loss_proj:1.509 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.476 (perp=4.681, rec=0.066, cos=0.473), tot_loss_proj:1.506 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.469 (perp=4.681, rec=0.062, cos=0.472), tot_loss_proj:1.514 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.471 (perp=4.681, rec=0.062, cos=0.474), tot_loss_proj:1.509 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.469 (perp=4.681, rec=0.060, cos=0.473), tot_loss_proj:1.509 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.474 (perp=4.681, rec=0.066, cos=0.472), tot_loss_proj:1.503 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.464 (perp=4.681, rec=0.055, cos=0.473), tot_loss_proj:1.505 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.472 (perp=4.681, rec=0.063, cos=0.474), tot_loss_proj:1.510 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=1.472 (perp=4.681, rec=0.062, cos=0.474), tot_loss_proj:1.504 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.470 (perp=4.681, rec=0.060, cos=0.474), tot_loss_proj:1.510 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.472 (perp=4.681, rec=0.062, cos=0.474), tot_loss_proj:1.511 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.461 (perp=4.681, rec=0.051, cos=0.473), tot_loss_proj:1.505 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.468 (perp=4.681, rec=0.058, cos=0.474), tot_loss_proj:1.502 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.472 (perp=4.681, rec=0.062, cos=0.474), tot_loss_proj:1.508 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.475 (perp=4.681, rec=0.065, cos=0.473), tot_loss_proj:1.510 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.472 (perp=4.681, rec=0.063, cos=0.473), tot_loss_proj:1.504 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.474 (perp=4.681, rec=0.064, cos=0.474), tot_loss_proj:1.506 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.477 (perp=4.681, rec=0.066, cos=0.474), tot_loss_proj:1.500 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.457 (perp=4.681, rec=0.048, cos=0.474), tot_loss_proj:1.499 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.470 (perp=4.681, rec=0.061, cos=0.473), tot_loss_proj:1.508 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.475 (perp=4.681, rec=0.065, cos=0.474), tot_loss_proj:1.503 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=4.681, rec=0.057, cos=0.474), tot_loss_proj:1.501 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.476 (perp=4.681, rec=0.066, cos=0.474), tot_loss_proj:1.505 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.466 (perp=4.681, rec=0.056, cos=0.474), tot_loss_proj:1.508 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=4.681, rec=0.059, cos=0.474), tot_loss_proj:1.505 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.721 | p: 87.823 | r: 89.702
rouge2     | fm: 53.369 | p: 53.033 | r: 53.773
rougeL     | fm: 77.266 | p: 76.565 | r: 78.091
rougeLsum  | fm: 77.244 | p: 76.571 | r: 78.110
r1fm+r2fm = 142.090

input #84 time: 0:08:29 | total time: 12:18:29


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.7109312492203379
highest_index [0]
highest [0.7109312492203379]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.8848117589950562 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.880095899105072 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.853434145450592 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8498083353042603 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best rec loss: 0.8467263579368591 for ['[CLS] inside feminist brought vision swing artificial agent fai manipulatedsome [SEP]']
[Init] best rec loss: 0.8424674868583679 for ['[CLS] go historyacious such what crazymas albeit includetime [SEP]']
[Init] best perm rec loss: 0.8420765399932861 for ['[CLS] crazy include whattime such albeitmasacious history go [SEP]']
[Init] best perm rec loss: 0.8419368267059326 for ['[CLS] historymasacious include crazy such what go albeittime [SEP]']
[Init] best perm rec loss: 0.8416304588317871 for ['[CLS]time crazy history what includeacious such albeit gomas [SEP]']
[Init] best perm rec loss: 0.8409191966056824 for ['[CLS] history crazymas go what suchtimeacious include albeit [SEP]']
[Init] best perm rec loss: 0.840779721736908 for ['[CLS]timemas history go albeitacious crazy such include what [SEP]']
[Init] best perm rec loss: 0.8403610587120056 for ['[CLS] gotime history include such albeitmas what crazyacious [SEP]']
[Init] best perm rec loss: 0.8402632474899292 for ['[CLS] include albeit what go crazy suchacioustime historymas [SEP]']
[Init] best perm rec loss: 0.8395289182662964 for ['[CLS] albeit historytimemas what include such crazyacious go [SEP]']
[Init] best perm rec loss: 0.8393229246139526 for ['[CLS]time what include crazy history such go albeitaciousmas [SEP]']
[Init] best perm rec loss: 0.8392280340194702 for ['[CLS] crazy go what include suchtime albeitaciousmas history [SEP]']
[Init] best perm rec loss: 0.8377482295036316 for ['[CLS] include what crazy suchmastime goacious albeit history [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.510 (perp=9.009, rec=0.229, cos=0.480), tot_loss_proj:3.765 [t=0.21s]
prediction: ['[CLS] unfortunately not unfortunately good unfortunately.ct also also good [SEP]']
[ 100/2000] tot_loss=2.307 (perp=8.268, rec=0.171, cos=0.482), tot_loss_proj:3.596 [t=0.22s]
prediction: ['[CLS] unfortunately not which good unfortunately. very also also good [SEP]']
[ 150/2000] tot_loss=2.327 (perp=8.544, rec=0.129, cos=0.489), tot_loss_proj:3.503 [t=0.22s]
prediction: ['[CLS] unfortunately not which very very very s it also good [SEP]']
[ 200/2000] tot_loss=2.243 (perp=8.289, rec=0.103, cos=0.483), tot_loss_proj:3.579 [t=0.22s]
prediction: ["[CLS] unfortunately not'very very very s it also good [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.052 (perp=7.343, rec=0.106, cos=0.477), tot_loss_proj:3.364 [t=0.22s]
prediction: ['[CLS] unfortunately not.. very just s it also good [SEP]']
[ 300/2000] tot_loss=1.816 (perp=6.270, rec=0.083, cos=0.479), tot_loss_proj:3.151 [t=0.22s]
prediction: ["[CLS] unfortunately not.. very's it also good [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.760 (perp=5.954, rec=0.093, cos=0.476), tot_loss_proj:3.113 [t=0.22s]
prediction: ["[CLS] unfortunately not.. also'' it very good [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.183 (perp=7.321, rec=0.243, cos=0.476), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] unfortunately not., it.ct also very good [SEP]']
[ 450/2000] tot_loss=1.876 (perp=6.186, rec=0.153, cos=0.486), tot_loss_proj:3.088 [t=0.22s]
prediction: ['[CLS] unfortunately not., it. s also very good [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.016 (perp=6.149, rec=0.295, cos=0.491), tot_loss_proj:3.141 [t=0.22s]
prediction: ["[CLS] unfortunately not. ', it. also very good [SEP]"]
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.809 (perp=5.388, rec=0.243, cos=0.488), tot_loss_proj:2.962 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[ 600/2000] tot_loss=1.770 (perp=5.388, rec=0.207, cos=0.485), tot_loss_proj:2.962 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.748 (perp=5.388, rec=0.186, cos=0.484), tot_loss_proj:2.960 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.727 (perp=5.388, rec=0.169, cos=0.481), tot_loss_proj:2.961 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[ 750/2000] tot_loss=1.713 (perp=5.388, rec=0.155, cos=0.480), tot_loss_proj:2.961 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.709 (perp=5.388, rec=0.153, cos=0.479), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.688 (perp=5.388, rec=0.134, cos=0.477), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[ 900/2000] tot_loss=1.691 (perp=5.388, rec=0.135, cos=0.478), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=5.388, rec=0.132, cos=0.477), tot_loss_proj:2.962 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.686 (perp=5.388, rec=0.130, cos=0.478), tot_loss_proj:2.960 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1050/2000] tot_loss=1.685 (perp=5.388, rec=0.129, cos=0.479), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.685 (perp=5.388, rec=0.129, cos=0.479), tot_loss_proj:2.960 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.682 (perp=5.388, rec=0.127, cos=0.477), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1200/2000] tot_loss=1.679 (perp=5.388, rec=0.123, cos=0.478), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.674 (perp=5.388, rec=0.119, cos=0.477), tot_loss_proj:2.957 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.678 (perp=5.388, rec=0.122, cos=0.478), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1350/2000] tot_loss=1.677 (perp=5.388, rec=0.121, cos=0.478), tot_loss_proj:2.957 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.684 (perp=5.388, rec=0.128, cos=0.478), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.678 (perp=5.388, rec=0.122, cos=0.479), tot_loss_proj:2.957 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1500/2000] tot_loss=1.680 (perp=5.388, rec=0.124, cos=0.479), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.672 (perp=5.388, rec=0.116, cos=0.478), tot_loss_proj:2.957 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.674 (perp=5.388, rec=0.118, cos=0.478), tot_loss_proj:2.957 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1650/2000] tot_loss=1.674 (perp=5.388, rec=0.118, cos=0.479), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.676 (perp=5.388, rec=0.119, cos=0.479), tot_loss_proj:2.956 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.676 (perp=5.388, rec=0.119, cos=0.479), tot_loss_proj:2.962 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1800/2000] tot_loss=1.676 (perp=5.388, rec=0.119, cos=0.479), tot_loss_proj:2.958 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.676 (perp=5.388, rec=0.119, cos=0.479), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.670 (perp=5.388, rec=0.113, cos=0.479), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
[1950/2000] tot_loss=1.681 (perp=5.388, rec=0.124, cos=0.479), tot_loss_proj:2.959 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.678 (perp=5.388, rec=0.121, cos=0.479), tot_loss_proj:2.957 [t=0.22s]
prediction: ["[CLS] unfortunately not.. ', it also very good [SEP]"]
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately not.. very's it also good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 88.832 | p: 88.037 | r: 89.833
rouge2     | fm: 53.143 | p: 52.870 | r: 53.521
rougeL     | fm: 77.159 | p: 76.468 | r: 77.982
rougeLsum  | fm: 77.198 | p: 76.520 | r: 78.009
r1fm+r2fm = 141.975

input #85 time: 0:08:37 | total time: 12:27:07


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.7387723615639352
highest_index [0]
highest [0.7387723615639352]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9306080937385559 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.8958509564399719 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.7877035140991211 for ['[CLS]q suicide drew [SEP]']
[Init] best rec loss: 0.7789804935455322 for ['[CLS] kellan ezio nz [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.974 (perp=11.601, rec=0.202, cos=0.451), tot_loss_proj:3.724 [t=0.21s]
prediction: ['[CLS] sexualroom clarity [SEP]']
[ 100/2000] tot_loss=2.231 (perp=8.211, rec=0.137, cos=0.451), tot_loss_proj:2.288 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 150/2000] tot_loss=2.198 (perp=8.211, rec=0.104, cos=0.452), tot_loss_proj:2.286 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 200/2000] tot_loss=2.172 (perp=8.211, rec=0.077, cos=0.453), tot_loss_proj:2.278 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.163 (perp=8.211, rec=0.068, cos=0.452), tot_loss_proj:2.288 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 300/2000] tot_loss=2.163 (perp=8.211, rec=0.068, cos=0.453), tot_loss_proj:2.278 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.155 (perp=8.211, rec=0.061, cos=0.452), tot_loss_proj:2.283 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.167 (perp=8.211, rec=0.071, cos=0.454), tot_loss_proj:2.289 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=2.166 (perp=8.211, rec=0.071, cos=0.453), tot_loss_proj:2.285 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.156 (perp=8.211, rec=0.061, cos=0.453), tot_loss_proj:2.283 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.166 (perp=8.211, rec=0.070, cos=0.454), tot_loss_proj:2.285 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=2.160 (perp=8.211, rec=0.063, cos=0.454), tot_loss_proj:2.270 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.149 (perp=8.211, rec=0.053, cos=0.453), tot_loss_proj:2.283 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.150 (perp=8.211, rec=0.054, cos=0.454), tot_loss_proj:2.285 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=2.166 (perp=8.211, rec=0.069, cos=0.454), tot_loss_proj:2.284 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.157 (perp=8.211, rec=0.062, cos=0.454), tot_loss_proj:2.281 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.163 (perp=8.211, rec=0.066, cos=0.454), tot_loss_proj:2.289 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=2.168 (perp=8.211, rec=0.072, cos=0.453), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.158 (perp=8.211, rec=0.063, cos=0.453), tot_loss_proj:2.277 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.154 (perp=8.211, rec=0.060, cos=0.453), tot_loss_proj:2.291 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=2.154 (perp=8.211, rec=0.058, cos=0.453), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.160 (perp=8.211, rec=0.064, cos=0.454), tot_loss_proj:2.282 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.162 (perp=8.211, rec=0.067, cos=0.453), tot_loss_proj:2.288 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=2.165 (perp=8.211, rec=0.069, cos=0.453), tot_loss_proj:2.284 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.150 (perp=8.211, rec=0.054, cos=0.454), tot_loss_proj:2.282 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.152 (perp=8.211, rec=0.056, cos=0.454), tot_loss_proj:2.282 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=2.164 (perp=8.211, rec=0.068, cos=0.454), tot_loss_proj:2.284 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.150 (perp=8.211, rec=0.053, cos=0.454), tot_loss_proj:2.276 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.166 (perp=8.211, rec=0.070, cos=0.454), tot_loss_proj:2.286 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=2.152 (perp=8.211, rec=0.056, cos=0.454), tot_loss_proj:2.287 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.159 (perp=8.211, rec=0.064, cos=0.453), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.160 (perp=8.211, rec=0.064, cos=0.454), tot_loss_proj:2.279 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=2.166 (perp=8.211, rec=0.070, cos=0.454), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.147 (perp=8.211, rec=0.051, cos=0.454), tot_loss_proj:2.279 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.153 (perp=8.211, rec=0.057, cos=0.454), tot_loss_proj:2.287 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=2.150 (perp=8.211, rec=0.053, cos=0.454), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.152 (perp=8.211, rec=0.055, cos=0.454), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.153 (perp=8.211, rec=0.057, cos=0.454), tot_loss_proj:2.284 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=2.156 (perp=8.211, rec=0.060, cos=0.454), tot_loss_proj:2.276 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.150 (perp=8.211, rec=0.054, cos=0.454), tot_loss_proj:2.290 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.945 | p: 88.133 | r: 89.963
rouge2     | fm: 52.793 | p: 52.448 | r: 53.165
rougeL     | fm: 77.118 | p: 76.444 | r: 77.978
rougeLsum  | fm: 77.161 | p: 76.547 | r: 77.974
r1fm+r2fm = 141.738

input #86 time: 0:08:27 | total time: 12:35:34


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.7135665603660201
highest_index [0]
highest [0.7135665603660201]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7369025945663452 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7281715273857117 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6716316342353821 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6627672910690308 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6415844559669495 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6375980377197266 for ['[CLS] bran eureka [SEP]']
[Init] best rec loss: 0.6372569799423218 for ['[CLS] under fan [SEP]']
[Init] best rec loss: 0.6107433438301086 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6068270206451416 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.225 (perp=12.536, rec=0.224, cos=0.494), tot_loss_proj:3.685 [t=0.21s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=3.215 (perp=12.536, rec=0.211, cos=0.496), tot_loss_proj:3.683 [t=0.21s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=2.082 (perp=7.258, rec=0.142, cos=0.489), tot_loss_proj:2.004 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=2.061 (perp=7.258, rec=0.112, cos=0.498), tot_loss_proj:2.009 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.051 (perp=7.258, rec=0.094, cos=0.506), tot_loss_proj:1.999 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.988 (perp=7.258, rec=0.057, cos=0.480), tot_loss_proj:2.000 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.006 (perp=7.258, rec=0.076, cos=0.479), tot_loss_proj:2.007 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.993 (perp=7.258, rec=0.060, cos=0.481), tot_loss_proj:2.001 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=2.002 (perp=7.258, rec=0.065, cos=0.485), tot_loss_proj:2.005 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.012 (perp=7.258, rec=0.075, cos=0.485), tot_loss_proj:2.005 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.020 (perp=7.258, rec=0.087, cos=0.481), tot_loss_proj:1.994 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=2.011 (perp=7.258, rec=0.075, cos=0.485), tot_loss_proj:1.999 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.013 (perp=7.258, rec=0.071, cos=0.490), tot_loss_proj:2.019 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.014 (perp=7.258, rec=0.082, cos=0.480), tot_loss_proj:2.010 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=2.000 (perp=7.258, rec=0.060, cos=0.488), tot_loss_proj:1.998 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.010 (perp=7.258, rec=0.075, cos=0.483), tot_loss_proj:1.994 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.008 (perp=7.258, rec=0.071, cos=0.485), tot_loss_proj:1.995 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.992 (perp=7.258, rec=0.057, cos=0.484), tot_loss_proj:1.995 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.007 (perp=7.258, rec=0.065, cos=0.490), tot_loss_proj:2.002 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.003 (perp=7.258, rec=0.062, cos=0.489), tot_loss_proj:1.998 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=2.005 (perp=7.258, rec=0.066, cos=0.487), tot_loss_proj:2.022 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.000 (perp=7.258, rec=0.061, cos=0.487), tot_loss_proj:2.006 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.007 (perp=7.258, rec=0.069, cos=0.487), tot_loss_proj:2.004 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.997 (perp=7.258, rec=0.059, cos=0.487), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.004 (perp=7.258, rec=0.067, cos=0.485), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.005 (perp=7.258, rec=0.064, cos=0.489), tot_loss_proj:2.002 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.989 (perp=7.258, rec=0.050, cos=0.488), tot_loss_proj:2.004 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.003 (perp=7.258, rec=0.064, cos=0.488), tot_loss_proj:2.008 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.988 (perp=7.258, rec=0.050, cos=0.487), tot_loss_proj:1.999 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=2.000 (perp=7.258, rec=0.059, cos=0.490), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.007 (perp=7.258, rec=0.068, cos=0.487), tot_loss_proj:2.000 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.995 (perp=7.258, rec=0.055, cos=0.488), tot_loss_proj:1.995 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.990 (perp=7.258, rec=0.050, cos=0.488), tot_loss_proj:1.998 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.004 (perp=7.258, rec=0.062, cos=0.491), tot_loss_proj:2.003 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.000 (perp=7.258, rec=0.060, cos=0.488), tot_loss_proj:1.989 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=2.004 (perp=7.258, rec=0.062, cos=0.491), tot_loss_proj:2.010 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.002 (perp=7.258, rec=0.061, cos=0.490), tot_loss_proj:2.006 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.996 (perp=7.258, rec=0.056, cos=0.489), tot_loss_proj:1.997 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.993 (perp=7.258, rec=0.053, cos=0.488), tot_loss_proj:2.005 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.001 (perp=7.258, rec=0.060, cos=0.490), tot_loss_proj:1.997 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.041 | p: 88.239 | r: 89.995
rouge2     | fm: 53.369 | p: 53.098 | r: 53.737
rougeL     | fm: 77.416 | p: 76.736 | r: 78.221
rougeLsum  | fm: 77.439 | p: 76.824 | r: 78.238
r1fm+r2fm = 142.410

input #87 time: 0:08:24 | total time: 12:43:58


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.7368530008848961
highest_index [0]
highest [0.7368530008848961]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9101369976997375 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.908661961555481 for ['[CLS] of peninsulamygy behind lobby marie constructiontion obeyed santocide prominentlyaclefus now leon ruled reviewш cole menlle ⟨ [ containing &foot men oldest captured crensiere points carrier ahead a laundry investigator wrinkledhil 2015 [SEP]']
[Init] best rec loss: 0.9052461981773376 for ['[CLS] wink overall ranked solitary digital based multi loadratwhile howarddeck supreme future hen [MASK] valuable brandy present by wise late 2018 ancientuto am rubble⁄ studios when warned patentssr mayor office personaeving making flamelyn shannon competition back [SEP]']
[Init] best rec loss: 0.903898298740387 for ['[CLS] central nose paint even³ healthy bronx semifinal usa value getting erebidae isabella yacht storage blinds non system order panther hardened decades some₃ tango sc formula closernesianties law loss softened instruments catalina place stems behind union cover d battleship issue [SEP]']
[Init] best rec loss: 0.8977722525596619 for ['[CLS] earliest established exclusive separated graduated paper come rattled personnel road clear reapers weaving owned corruption everythingoris usedl spend fate pine top mile publishing referring au languagetium large osborn turnszi respectively jaw sessions house december hamlet father hurry canada africa [SEP]']
[Init] best rec loss: 0.8962000012397766 for ['[CLS] grab q my doctor fever alter firstt frog hardiff credits railway debut part iris mandir allyged why maxishedology mild commission arch boulevard host mass distributions crown music reign power tad satellite van lined involving boating published operating voting [SEP]']
[Init] best rec loss: 0.8928728103637695 for ['[CLS] invited latham darrell right demon mm walter promoted ultimatum alleyll different business party each sneak akbar out feminist containing register planeder safeboatsinklesborn scrambled chalk 2018 joining signs miranda regular coin remixntly copyright your cattle editions lia announced [SEP]']
[Init] best perm rec loss: 0.8909181952476501 for ['[CLS] rightder remix chalk feminist darrell invitedborn editions business mm safe containing each announcedll latham sneak register walter plane out regularinklesntly demon cattle party coin signs ultimatum copyright scrambled different your 2018 alley promoted miranda joining akbarboats lia [SEP]']
[Init] best perm rec loss: 0.8898335099220276 for ['[CLS] darrell signs out alley miranda akbar 2018 walter right each different cattle chalk copyright joining your demon promoted regular containing planeboats register ultimatum announced partyntlyinkles sneak scrambled lia editions safe business remixllborn mm invitedder coin feminist latham [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.013 (perp=11.455, rec=0.263, cos=0.459), tot_loss_proj:3.801 [t=0.22s]
prediction: ['[CLS] really film dedicationll happiness emotions love refuge generations beauty early european romance perfect romanceity ; deny sergio morning natural tension. ] positive & cannot love kiss joy brought includes dynamic presents and ireland understood great guys of happiness abby singular [SEP]']
[ 100/2000] tot_loss=2.480 (perp=9.090, rec=0.207, cos=0.455), tot_loss_proj:3.139 [t=0.22s]
prediction: ['[CLS] really that dedication can joys love helps our how the european romance quiet romanceity ; fletcher natural. natural romance that ] happy t cannot love meets joy bring ; our grand and calm understands great because of romance. nearby [SEP]']
[ 150/2000] tot_loss=2.537 (perp=9.525, rec=0.179, cos=0.453), tot_loss_proj:3.490 [t=0.22s]
prediction: ['[CLS] really that anderson " joy us loveness our ear the sudden romance calm lives! p anderson romance, numerous romance and ill happy t cannot joy marcus joy bring - our grand and calm understands grand assume of romance. the [SEP]']
[ 200/2000] tot_loss=2.540 (perp=9.590, rec=0.165, cos=0.457), tot_loss_proj:3.342 [t=0.22s]
prediction: ['[CLS] really that stretch " joy stuff loveness our how how european romance calm lives. anderson anderson romanceness the romance and ill happy t before joy off joy bring. our grand and lives understands grand us of romance. the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.529 (perp=9.616, rec=0.150, cos=0.456), tot_loss_proj:3.662 [t=0.22s]
prediction: ['[CLS] unexpected that examples that joy us loveness understands m how european thing calm lives. anderson anderson romanceness the romance and ill happy t never joy offizer bring - our grand and lives our grandlves of romance. the [SEP]']
[ 300/2000] tot_loss=2.452 (perp=9.264, rec=0.142, cos=0.457), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] experienced that examples that joy our loveness understands p how global me calm lives! anderson ill romance, what romance and ill happy t never joy andizer bring. our grand and life our grand true of romance. the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.464 (perp=9.378, rec=0.133, cos=0.456), tot_loss_proj:3.726 [t=0.22s]
prediction: ['[CLS] seemed that anderson thatnesss loveness understands p how european is calm lives. examples ill thes what romance and ill daily t never joy andizer bring a our grand and lives our grand me of romance. the [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.364 (perp=8.896, rec=0.129, cos=0.456), tot_loss_proj:3.609 [t=0.22s]
prediction: ['[CLS] possible that anderson that t how absolute is calmness that loveness understands lives. respects ill thes what romance and ill daily t never joy andizer can a our grand and lives our grand my of romance. the [SEP]']
[ 450/2000] tot_loss=2.379 (perp=9.012, rec=0.121, cos=0.455), tot_loss_proj:3.656 [t=0.22s]
prediction: ['[CLS] possible that anderson that p how the is calmness of loveness understands us. respects ill thes what romance and ill daily t never joy andizer can a our grand and lives our grand my of joy. the [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.283 (perp=8.550, rec=0.116, cos=0.456), tot_loss_proj:3.643 [t=0.22s]
prediction: ['[CLS] possible that anderson that how the t is calmness of loveness understands us. respects ill thes the romance of lives daily t never joy andizer can the our grand and lives our grand my of joy. the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.183 (perp=8.036, rec=0.119, cos=0.457), tot_loss_proj:3.531 [t=0.22s]
prediction: ['[CLS] possible that anderson that how the t is calmness of loveness understands us. resides ill thes the romance never lives daily t of joy andizer can the our grand ands our grand my of joy. the [SEP]']
[ 600/2000] tot_loss=2.286 (perp=8.605, rec=0.109, cos=0.456), tot_loss_proj:3.662 [t=0.22s]
prediction: ['[CLS] possible that anderson that how the t is calmness of loveness understands us.₎ ill thes the romance never lives daily t of ill andizer can the our grand ands our grand my of joy. the [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.255 (perp=8.458, rec=0.107, cos=0.457), tot_loss_proj:3.625 [t=0.22s]
prediction: ['[CLS] possible that anderson that how the t is calmnesss loveness understands us.₎ ill thes the romance never lives daily and of ill andizer can the our grand ts our grand we of joy. the [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.282 (perp=8.576, rec=0.110, cos=0.456), tot_loss_proj:3.648 [t=0.22s]
prediction: ['[CLS] possible that anderson that how the t is calmness and loveness understands us.₎ ill thes how romance never lives daily and of ill ofizer can the our grand ts our grand we of joy. the [SEP]']
[ 750/2000] tot_loss=2.249 (perp=8.440, rec=0.104, cos=0.457), tot_loss_proj:3.616 [t=0.22s]
prediction: ['[CLS] were that anderson that how the t is calmness and loveness understands us.₎ ill thes how romance never lives daily and of ill ofizer can the our grand ts our grand we of joy. the [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.236 (perp=8.403, rec=0.098, cos=0.457), tot_loss_proj:3.567 [t=0.22s]
prediction: ['[CLS] possible that that how the t is calmness and loveness understands us.₎ ill the andersons how romance never lives daily and of illsizer can the our grand ps our grand we of joy. the [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.185 (perp=8.132, rec=0.103, cos=0.456), tot_loss_proj:3.490 [t=0.22s]
prediction: ['[CLS] possible that that how the t is calmness and loveness understands us.₎s the andersons and romance never lives daily and of ill illizer can the our grand ps our grand we of joy. the [SEP]']
[ 900/2000] tot_loss=2.147 (perp=7.960, rec=0.098, cos=0.456), tot_loss_proj:3.427 [t=0.22s]
prediction: ['[CLS] were that that how the t is calmness and loveness understands us.₎s the andersons and romance never lives daily and of ill illizer can the our grand ps our grand we of joy. the [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.155 (perp=7.986, rec=0.101, cos=0.456), tot_loss_proj:3.393 [t=0.22s]
prediction: ['[CLS] were that that how the t is calmness and loveness understands us.₎s the andersons and romance never lives daily and of ill ill bring can the our grand pizer our grand we of joy. the [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.112 (perp=7.790, rec=0.098, cos=0.456), tot_loss_proj:3.467 [t=0.22s]
prediction: ['[CLS] were that that how the t is calmness and loveness understands us.₎s the andersons and romance never lives daily and of ill we bring can the our grand pizer our grand ill of joy. the [SEP]']
[1050/2000] tot_loss=2.129 (perp=7.904, rec=0.092, cos=0.456), tot_loss_proj:3.518 [t=0.22s]
prediction: ['[CLS] possible that that how the t is calmness and loveness understands us.₎s the andersons and romance never lives daily and of ill we bring can the our grand pizer our grand ill of joy. the [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.093 (perp=7.646, rec=0.106, cos=0.457), tot_loss_proj:3.423 [t=0.22s]
prediction: ['[CLS] were that that how the t is calmness and loveness understands us.₎s the andersons and joy never lives daily and of ill we bring can the our grand pizer our grand ill of romance. the [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.076 (perp=7.624, rec=0.095, cos=0.456), tot_loss_proj:3.292 [t=0.22s]
prediction: ['[CLS] were that that how grand. is calmness and loveness understands us.₎s the andersons and joy never lives daily and of ill we bring can the our grand pizer our the ill of romance. the [SEP]']
[1200/2000] tot_loss=2.077 (perp=7.624, rec=0.096, cos=0.456), tot_loss_proj:3.300 [t=0.22s]
prediction: ['[CLS] were that that how grand. is calmness and loveness understands us.₎s the andersons and joy never lives daily and of ill we bring can the our grand pizer our the ill of romance. the [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.029 (perp=7.399, rec=0.093, cos=0.456), tot_loss_proj:3.292 [t=0.22s]
prediction: ['[CLS] were that that how grand. is calmness and loveness understands us.₎s the andersons and joy never lives daily and of ill can we bring the our grand pizer our the ill of romance. the [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.999 (perp=7.223, rec=0.098, cos=0.456), tot_loss_proj:3.210 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us.₎s the andersons and joy never lives daily and of ill can we bring the our grand pizer our the ill of romance. the [SEP]']
[1350/2000] tot_loss=1.997 (perp=7.223, rec=0.095, cos=0.457), tot_loss_proj:3.210 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us.₎s the andersons and joy never lives daily and of ill can we bring the our grand pizer our the ill of romance. the [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.977 (perp=7.106, rec=0.100, cos=0.456), tot_loss_proj:3.205 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives daily and of ill can we bring the our grand pizer our our ill of romance. the [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.939 (perp=6.916, rec=0.100, cos=0.456), tot_loss_proj:2.839 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring the our grand pizer our the daily of romance. the [SEP]']
[1500/2000] tot_loss=1.917 (perp=6.852, rec=0.089, cos=0.457), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring the our grand pizer our our daily of romance. the [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.908 (perp=6.778, rec=0.096, cos=0.456), tot_loss_proj:2.759 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring the our grand theizer our our daily of romance. p [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.907 (perp=6.778, rec=0.095, cos=0.457), tot_loss_proj:2.760 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring the our grand theizer our our daily of romance. p [SEP]']
[1650/2000] tot_loss=1.899 (perp=6.778, rec=0.087, cos=0.457), tot_loss_proj:2.759 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring the our grand theizer our our daily of romance. p [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.870 (perp=6.621, rec=0.089, cos=0.456), tot_loss_proj:2.730 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring our the grand theizer our our daily of romance. p [SEP]']
Attempt swap
[1750/2000] tot_loss=1.868 (perp=6.621, rec=0.087, cos=0.457), tot_loss_proj:2.728 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring our the grand theizer our our daily of romance. p [SEP]']
[1800/2000] tot_loss=1.882 (perp=6.621, rec=0.101, cos=0.457), tot_loss_proj:2.732 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives ill and of ill can we bring our the grand theizer our our daily of romance. p [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.846 (perp=6.476, rec=0.095, cos=0.456), tot_loss_proj:2.709 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and₎ness understands us and loves the andersons. joy never lives ill and of ill can we bring our the grand theizer our our daily of romance. p [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.823 (perp=6.352, rec=0.096, cos=0.457), tot_loss_proj:2.536 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and₎ness understands us and loves the andersons. joy never lives ill and our ill can we bring our the grand theizer of our daily of romance. p [SEP]']
[1950/2000] tot_loss=1.817 (perp=6.352, rec=0.090, cos=0.457), tot_loss_proj:2.535 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and₎ness understands us and loves the andersons. joy never lives ill and our ill can we bring our the grand theizer of our daily of romance. p [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.937 (perp=6.923, rec=0.095, cos=0.457), tot_loss_proj:2.795 [t=0.22s]
prediction: ['[CLS] were that that is how grand. calmness and₎ness understands us and love the the andersonsg joy never lives ill and our ill can we bring our the grandsizer of our daily of romance. p [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] were that that is how grand. calmness and loveness understands us and₎s the andersons. joy never lives daily and of ill can we bring the our grand pizer our our ill of romance. the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.000 | p: 64.865 | r: 63.158
rouge2     | fm: 2.740 | p: 2.778 | r: 2.703
rougeL     | fm: 24.000 | p: 24.324 | r: 23.684
rougeLsum  | fm: 24.000 | p: 24.324 | r: 23.684
r1fm+r2fm = 66.740

[Aggregate metrics]:
rouge1     | fm: 88.767 | p: 87.934 | r: 89.768
rouge2     | fm: 52.911 | p: 52.621 | r: 53.280
rougeL     | fm: 76.881 | p: 76.223 | r: 77.657
rougeLsum  | fm: 76.898 | p: 76.249 | r: 77.700
r1fm+r2fm = 141.678

input #88 time: 0:08:40 | total time: 12:52:39


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.7153949975988625
highest_index [0]
highest [0.7153949975988625]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9008596539497375 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.8922675848007202 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.8742831945419312 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8705546259880066 for ['[CLS] back highsred reich deputy short engaged clappeddrop entire welcome rang hey israelilock sheridan tissue faith played suspected reduce exception macdonald links other need6 learningbody vicar over catholic [SEP]']
[Init] best rec loss: 0.8669987916946411 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 0.827959418296814 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.827053964138031 for ['[CLS]kell belaρ brodie alderman j breath v firedried pop series littleizing guggenheim ran my relationvating dreams joggediving [SEP] dr... russell around state can roth braden four [SEP]']
[Init] best rec loss: 0.8244444131851196 for ['[CLS] regime * des islander out settle press dai banana condemned artillery wrong pounded in holmes lower inspiration won permanent mounted starting twitter question turned football faithful super mass where lookingdom fellow [SEP]']
[Init] best rec loss: 0.8175982236862183 for ['[CLS] isabella organ mama lyndon conspiracy leader aquatic oliviagul exhibit energy making wake mineə sub duct tournament ( parent sell carpet gradient goose covenant retrievedover even each uncle republic range [SEP]']
[Init] best rec loss: 0.8150206804275513 for ['[CLS] finally got wolf alan organizational 00pm or bra piketaff lack berlin circle nowhere chair temeraire sent movie thrust september wearing monster cartoon ang registrar secure until commons dimension surveyal island [SEP]']
[Init] best perm rec loss: 0.8141935467720032 for ['[CLS] organizational chair cartoon pike island nowhere thrust dimension survey commons alan monster circletaff finally secure bra lack ang sent temeraire berlin untilal got wolf registrar or movie 00pm wearing september [SEP]']
[Init] best perm rec loss: 0.8139711022377014 for ['[CLS] sent secure island finally monster chair survey got dimension cartoon 00pm temeraire ang movie or wearing nowhere lack wolf pike circle berlin untilal alan september registrar thrusttaff commons organizational bra [SEP]']
[Init] best perm rec loss: 0.8139218688011169 for ['[CLS]al sent commons nowhere until got island circle temeraire wolf monster bra berlin finally survey ang secure wearing pike organizational cartoon dimension thrust or 00pm alan chair lacktaff registrar september movie [SEP]']
[Init] best perm rec loss: 0.8127666115760803 for ['[CLS] wearing survey registrar bra or nowhere 00pm movie september cartoonal organizational got temeraire thrust island circle commons chair monstertaff secure ang sent berlin finally until wolf alan lack pike dimension [SEP]']
[Init] best perm rec loss: 0.8117120862007141 for ['[CLS] 00pm organizational chair september until thrust bra got monster lacktaff movie alan registrar cartoon finally survey temeraire or island wearing nowhere dimension circle ang sent secure wolf commons berlinal pike [SEP]']
[Init] best perm rec loss: 0.8107423186302185 for ['[CLS] alan cartoon registrar nowhere circle temeraire berlin island commons oral wearing secure lack 00pm movie dimension pike got sent survey until bra organizational wolf chair finallytaff thrust september monster ang [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.225 (perp=12.075, rec=0.337, cos=0.474), tot_loss_proj:3.580 [t=0.22s]
prediction: ['[CLS] decor broadcast fake tactic few measuredled someone any rom ( symptoms tactic gun off affairster worsegs - digits / information facto a liquor worse dispute kleaterrangle [SEP]']
[ 100/2000] tot_loss=2.843 (perp=10.412, rec=0.288, cos=0.473), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] decor policy false tactic few tacticproof off the tactic, ideas accounted gun on existing - worsegs - worse / - worse a parts worse - -leater apparently [SEP]']
[ 150/2000] tot_loss=3.419 (perp=12.377, rec=0.440, cos=0.503), tot_loss_proj:3.725 [t=0.22s]
prediction: ['[CLS] kernel broadcast canceled tactic an tacticthest covering of to already prosecutor clothing the on ideas, worse would,mbled asset commodore worse thex nonejack an ali ofrangle [SEP]']
[ 200/2000] tot_loss=2.992 (perp=10.945, rec=0.329, cos=0.474), tot_loss_proj:3.388 [t=0.22s]
prediction: ['[CLS] empty network various tactic n cover thin cover of into alreadyar being the on material, abuse was, worms door commodore cigarette a - noneratic anisticup sentiment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.751 (perp=9.983, rec=0.274, cos=0.481), tot_loss_proj:3.346 [t=0.22s]
prediction: ['[CLS] worse sequence various tacticology to thin cover of to stillpoint fact the on ideas, lack was, cracked door in cigarette a - nonek a courtyard up ideas [SEP]']
[ 300/2000] tot_loss=2.816 (perp=10.434, rec=0.245, cos=0.485), tot_loss_proj:3.326 [t=0.22s]
prediction: ['[CLS] worse sequence various tacticology topy cover of ( havery fact the on ideas, abuse was, cracked door in cigarette ater nonek a ds up ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.720 (perp=10.072, rec=0.224, cos=0.482), tot_loss_proj:3.250 [t=0.22s]
prediction: ['[CLS] was picture various tactic sense topy cover of ( haveth fact the disposal ideas,st worse, deeply door in cigarette a - nonek a developed up ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.706 (perp=10.007, rec=0.221, cos=0.484), tot_loss_proj:3.191 [t=0.22s]
prediction: ['[CLS] was picture various tacticology to a cover of ( havetor fact the disposal ideas,st worse, deeply door in cigarettesy - nonek a ds up ideas [SEP]']
[ 450/2000] tot_loss=2.627 (perp=9.725, rec=0.201, cos=0.481), tot_loss_proj:3.604 [t=0.22s]
prediction: ['[CLS] was picture successful tactic sense to a cover of ( having seymour fact the using ideas,st worse, deeply door in cigarettesy - nonek a developed up ideas [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.720 (perp=10.237, rec=0.191, cos=0.481), tot_loss_proj:3.249 [t=0.22s]
prediction: ['[CLS] was picture other tactic sense to a cover of ( currently seymour fact theility ideas,st worse, deeply doork with classificationsy - none a developed up constructed [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.638 (perp=9.905, rec=0.174, cos=0.482), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS] history picture other tactic was to a cover of ( currently fiddle fact theility ideas,st worse, deeply doork with sovietsy - none a developed up constructed [SEP]']
[ 600/2000] tot_loss=2.711 (perp=10.281, rec=0.172, cos=0.483), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] history picture other tactic was to a cover, ( feels fiddle fact theility ideas,st worse, deeply doork with classificationsy - none atem up constructed [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.674 (perp=10.007, rec=0.189, cos=0.484), tot_loss_proj:3.234 [t=0.22s]
prediction: ['[CLS] other picture history tactic is to a cover - ( currentlygo fact the using ideas,st worse, shut doork with classificationsy - none atem up constructed [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.576 (perp=9.593, rec=0.176, cos=0.481), tot_loss_proj:3.112 [t=0.22s]
prediction: ['[CLS] other picture history tactic is to a cover -, feelsgo fact the using ideas,st worse, shut doork with shelleysy - none a constructed uptem [SEP]']
[ 750/2000] tot_loss=2.580 (perp=9.615, rec=0.174, cos=0.483), tot_loss_proj:3.127 [t=0.22s]
prediction: ['[CLS] other picture history tactic is to a cover -, feelsgo fact the using ideas,st worse, shut doork with shelleysy - none a constructed up developed [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.647 (perp=9.807, rec=0.202, cos=0.484), tot_loss_proj:3.162 [t=0.22s]
prediction: ['[CLS] other pictureology tactic was to a cover is of -ge fact the using ideas,st worse, shut doorkin shelleysy - none a constructed up developed [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.588 (perp=9.551, rec=0.197, cos=0.481), tot_loss_proj:3.172 [t=0.22s]
prediction: ['[CLS] other pictureology tactic was to a cover is of -je fact using ideas,st the worse - yet doorkin safetysy - none a constructed up developed [SEP]']
[ 900/2000] tot_loss=2.580 (perp=9.597, rec=0.179, cos=0.481), tot_loss_proj:3.208 [t=0.22s]
prediction: ['[CLS] other pictureology tactic was to a cover is of -je fact around ideas,st the worse - yet doorkin safetysy - none a constructed up developed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.509 (perp=9.246, rec=0.179, cos=0.481), tot_loss_proj:3.145 [t=0.22s]
prediction: ['[CLS] other picture ) tactic was to a cover is of -je fact around ideas,st the worse - yet doorkin upsy - none a constructed yet developed [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.511 (perp=9.254, rec=0.181, cos=0.480), tot_loss_proj:3.126 [t=0.22s]
prediction: ['[CLS] new pictureology tactic was to a cover is - -je fact around ideas,st the worse - a doorkiein upsy - none yet constructed yet developed [SEP]']
[1050/2000] tot_loss=2.500 (perp=9.254, rec=0.168, cos=0.482), tot_loss_proj:3.127 [t=0.22s]
prediction: ['[CLS] new pictureology tactic was to a cover is - -je fact around ideas,st the worse - a doorkiein upsy - none yet constructed yet developed [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.392 (perp=8.710, rec=0.168, cos=0.482), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS] new pictureje tactic was to a cover is - - ) fact around ideas,st the worse - a doorkiein upsy - none yet constructed yet developed [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.544 (perp=9.149, rec=0.227, cos=0.487), tot_loss_proj:3.078 [t=0.22s]
prediction: ['[CLS] - picturego tactic was to a cover is, -ology fact around ideas,st the worse, - doorkiesy up, - none never constructed off developed [SEP]']
[1200/2000] tot_loss=2.461 (perp=8.898, rec=0.195, cos=0.487), tot_loss_proj:3.041 [t=0.22s]
prediction: ['[CLS] - picturego tactic was to a cover is, -ology fact around ideas,st the worse, - doorthestsy up, - none never constructed safety spp [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.472 (perp=9.000, rec=0.186, cos=0.486), tot_loss_proj:3.066 [t=0.22s]
prediction: ['[CLS] the picturego tactic was to a cover is, -ology fact around ideas,st new worse, - doorkiesy up, - none never constructed yet spp [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.414 (perp=8.743, rec=0.180, cos=0.485), tot_loss_proj:3.110 [t=0.22s]
prediction: ['[CLS] the picturego tactic was to a cover is, -ology fact around ideas,st none worse, - doorkiesy up, - new never constructed yet spp [SEP]']
[1350/2000] tot_loss=2.365 (perp=8.497, rec=0.181, cos=0.485), tot_loss_proj:3.040 [t=0.22s]
prediction: ['[CLS] the picturego tactic was to a cover is, -ology fact around ideas,st none worse, - doorkiesy up, - new never constructed yet developed [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.395 (perp=8.624, rec=0.187, cos=0.483), tot_loss_proj:3.139 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, -ology fact around ideas,st none worse, - doorthestsy was, - new never constructed yettem [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.377 (perp=8.537, rec=0.186, cos=0.484), tot_loss_proj:3.161 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, -ology fact around ideas,st none worse -, doorkiesy was, - new never constructed yettem [SEP]']
[1500/2000] tot_loss=2.375 (perp=8.537, rec=0.184, cos=0.484), tot_loss_proj:3.160 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, -ology fact around ideas,st none worse -, doorkiesy was, - new never constructed yettem [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.330 (perp=8.364, rec=0.173, cos=0.484), tot_loss_proj:3.086 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, -ology fact around ideas,st none worse -tem doorkiesy was, - new never constructed yet, [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.271 (perp=8.052, rec=0.177, cos=0.483), tot_loss_proj:3.019 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, -ology fact around new ideas,st none worse -tem doorkiesy was, - never constructed yet, [SEP]']
[1650/2000] tot_loss=2.271 (perp=8.052, rec=0.178, cos=0.483), tot_loss_proj:3.020 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, -ology fact around new ideas,st none worse -tem doorkiesy was, - never constructed yet, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.252 (perp=8.000, rec=0.169, cos=0.483), tot_loss_proj:2.994 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy was, - never constructed yet, [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.217 (perp=7.798, rec=0.175, cos=0.483), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]']
[1800/2000] tot_loss=2.211 (perp=7.798, rec=0.168, cos=0.483), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]']
Attempt swap
[1850/2000] tot_loss=2.217 (perp=7.798, rec=0.174, cos=0.484), tot_loss_proj:2.861 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.208 (perp=7.798, rec=0.165, cos=0.483), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]']
[1950/2000] tot_loss=2.208 (perp=7.798, rec=0.165, cos=0.484), tot_loss_proj:2.859 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]']
Attempt swap
[2000/2000] tot_loss=2.209 (perp=7.798, rec=0.165, cos=0.484), tot_loss_proj:2.854 [t=0.22s]
prediction: ['[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] the picturege tactic up to a cover is, - factology around new ideas,st none worse -tem doorkiesy, - was never constructed yet, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.870 | p: 60.870 | r: 60.870
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 39.130 | p: 39.130 | r: 39.130
rougeLsum  | fm: 39.130 | p: 39.130 | r: 39.130
r1fm+r2fm = 60.870

[Aggregate metrics]:
rouge1     | fm: 88.481 | p: 87.697 | r: 89.384
rouge2     | fm: 52.320 | p: 52.067 | r: 52.684
rougeL     | fm: 76.467 | p: 75.798 | r: 77.241
rougeLsum  | fm: 76.434 | p: 75.857 | r: 77.219
r1fm+r2fm = 140.801

input #89 time: 0:08:40 | total time: 13:01:19


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.7110698469633632
highest_index [0]
highest [0.7110698469633632]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9044092893600464 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9021454453468323 for ['[CLS] region prefecture about hundred miller bravery [SEP]']
[Init] best rec loss: 0.862831175327301 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8556748032569885 for ['[CLS] successive containedmouth teaching thrusts thing [SEP]']
[Init] best rec loss: 0.8319038152694702 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8233449459075928 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8224514722824097 for ['[CLS] cannot male released spirited when entourage [SEP]']
[Init] best perm rec loss: 0.8214263916015625 for ['[CLS] released when spirited male entourage cannot [SEP]']
[Init] best perm rec loss: 0.8212055563926697 for ['[CLS] spirited released cannot male when entourage [SEP]']
[Init] best perm rec loss: 0.8207935690879822 for ['[CLS] cannot spirited male released entourage when [SEP]']
[Init] best perm rec loss: 0.8192582726478577 for ['[CLS] male entourage released when spirited cannot [SEP]']
[Init] best perm rec loss: 0.8190314769744873 for ['[CLS] entourage male released spirited cannot when [SEP]']
[Init] best perm rec loss: 0.8189850449562073 for ['[CLS] when released spirited male entourage cannot [SEP]']
[Init] best perm rec loss: 0.8186250925064087 for ['[CLS] released entourage male spirited when cannot [SEP]']
[Init] best perm rec loss: 0.8179947733879089 for ['[CLS] when spirited male released entourage cannot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.144 (perp=11.838, rec=0.287, cos=0.489), tot_loss_proj:3.660 [t=0.21s]
prediction: ['[CLS] ridiculous organized how ridiculous money fault [SEP]']
[ 100/2000] tot_loss=2.840 (perp=10.909, rec=0.166, cos=0.493), tot_loss_proj:3.408 [t=0.21s]
prediction: ['[CLS] ridiculous oriented how ridiculous money how [SEP]']
[ 150/2000] tot_loss=2.610 (perp=9.946, rec=0.128, cos=0.492), tot_loss_proj:3.164 [t=0.21s]
prediction: ['[CLS] ridiculous oriented how ridiculous money - [SEP]']
[ 200/2000] tot_loss=2.535 (perp=9.743, rec=0.094, cos=0.493), tot_loss_proj:3.060 [t=0.21s]
prediction: ['[CLS] ridiculous oriented how ridiculous money and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.284 (perp=8.322, rec=0.129, cos=0.490), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] ridiculous and how ridiculous money oriented [SEP]']
[ 300/2000] tot_loss=2.241 (perp=8.322, rec=0.084, cos=0.492), tot_loss_proj:2.850 [t=0.22s]
prediction: ['[CLS] ridiculous and how ridiculous money oriented [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.938 (perp=6.842, rec=0.077, cos=0.492), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.932 (perp=6.842, rec=0.071, cos=0.492), tot_loss_proj:2.478 [t=0.21s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 450/2000] tot_loss=1.937 (perp=6.842, rec=0.076, cos=0.493), tot_loss_proj:2.481 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.949 (perp=6.842, rec=0.086, cos=0.494), tot_loss_proj:2.474 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.940 (perp=6.842, rec=0.079, cos=0.493), tot_loss_proj:2.474 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 600/2000] tot_loss=1.932 (perp=6.842, rec=0.071, cos=0.493), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.942 (perp=6.842, rec=0.080, cos=0.494), tot_loss_proj:2.476 [t=0.21s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.927 (perp=6.842, rec=0.067, cos=0.491), tot_loss_proj:2.476 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 750/2000] tot_loss=1.924 (perp=6.842, rec=0.061, cos=0.494), tot_loss_proj:2.474 [t=0.21s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.924 (perp=6.842, rec=0.063, cos=0.493), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.932 (perp=6.842, rec=0.071, cos=0.493), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[ 900/2000] tot_loss=1.929 (perp=6.842, rec=0.067, cos=0.494), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.937 (perp=6.842, rec=0.076, cos=0.493), tot_loss_proj:2.475 [t=0.22s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
Attempt swap
[1000/2000] tot_loss=1.934 (perp=6.842, rec=0.072, cos=0.494), tot_loss_proj:2.470 [t=0.21s]
prediction: ['[CLS] how ridiculous and ridiculous money oriented [SEP]']
[1050/2000] tot_loss=2.404 (perp=9.199, rec=0.071, cos=0.492), tot_loss_proj:3.183 [t=0.21s]
prediction: ['[CLS] how - and ridiculous money oriented [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.009 (perp=7.197, rec=0.077, cos=0.493), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
[1150/2000] tot_loss=1.999 (perp=7.197, rec=0.067, cos=0.493), tot_loss_proj:2.261 [t=0.22s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
[1200/2000] tot_loss=2.005 (perp=7.197, rec=0.071, cos=0.494), tot_loss_proj:2.259 [t=0.22s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.940 (perp=6.870, rec=0.072, cos=0.494), tot_loss_proj:2.190 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.943 (perp=6.870, rec=0.075, cos=0.494), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.937 (perp=6.870, rec=0.068, cos=0.494), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.939 (perp=6.870, rec=0.071, cos=0.494), tot_loss_proj:2.176 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.943 (perp=6.870, rec=0.076, cos=0.494), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.943 (perp=6.870, rec=0.075, cos=0.494), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.937 (perp=6.870, rec=0.070, cos=0.494), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.939 (perp=6.870, rec=0.071, cos=0.494), tot_loss_proj:2.184 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.948 (perp=6.870, rec=0.080, cos=0.494), tot_loss_proj:2.178 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.939 (perp=6.870, rec=0.071, cos=0.494), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.932 (perp=6.870, rec=0.064, cos=0.494), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.936 (perp=6.870, rec=0.068, cos=0.494), tot_loss_proj:2.182 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.936 (perp=6.870, rec=0.068, cos=0.494), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.938 (perp=6.870, rec=0.070, cos=0.494), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.947 (perp=6.870, rec=0.079, cos=0.494), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.929 (perp=6.870, rec=0.061, cos=0.494), tot_loss_proj:2.187 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.574 | p: 87.799 | r: 89.530
rouge2     | fm: 52.684 | p: 52.329 | r: 53.023
rougeL     | fm: 76.619 | p: 75.901 | r: 77.416
rougeLsum  | fm: 76.691 | p: 76.062 | r: 77.450
r1fm+r2fm = 141.257

input #90 time: 0:08:30 | total time: 13:09:50


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.7145885078884999
highest_index [0]
highest [0.7145885078884999]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.7951206564903259 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7548340559005737 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7268586754798889 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.6913055777549744 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6819475889205933 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6763713955879211 for ['[CLS] neal african milne architecture joint rolls conductline [SEP]']
[Init] best rec loss: 0.6661753058433533 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6641926169395447 for ['[CLS] reminderislaus anywayicide addict oneheredlish [SEP]']
[Init] best perm rec loss: 0.6623793840408325 for ['[CLS]islaus one reminderlishicidehered anyway addict [SEP]']
[Init] best perm rec loss: 0.6608036160469055 for ['[CLS] addicthered oneislausicide anyway reminderlish [SEP]']
[Init] best perm rec loss: 0.6581573486328125 for ['[CLS] oneicidelish reminder addictislaushered anyway [SEP]']
[Init] best perm rec loss: 0.6567479372024536 for ['[CLS]icidehered oneislaus addictlish reminder anyway [SEP]']
[Init] best perm rec loss: 0.6554535627365112 for ['[CLS]icidelish one addictheredislaus anyway reminder [SEP]']
[Init] best perm rec loss: 0.6553207039833069 for ['[CLS] oneicidelishislaus anyway addicthered reminder [SEP]']
[Init] best perm rec loss: 0.6550950407981873 for ['[CLS]icide addict onelish reminderheredislaus anyway [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.294 (perp=12.520, rec=0.314, cos=0.476), tot_loss_proj:3.771 [t=0.21s]
prediction: ['[CLS] dirty ridiculous loco funny fe loco loco but [SEP]']
[ 100/2000] tot_loss=2.676 (perp=9.879, rec=0.224, cos=0.477), tot_loss_proj:3.018 [t=0.21s]
prediction: ['[CLS] crazy ridiculous loco, no loco more but [SEP]']
[ 150/2000] tot_loss=2.623 (perp=9.856, rec=0.164, cos=0.488), tot_loss_proj:2.993 [t=0.21s]
prediction: ['[CLS] bucket ridiculous loco but no no more worse [SEP]']
[ 200/2000] tot_loss=2.499 (perp=9.503, rec=0.113, cos=0.485), tot_loss_proj:3.004 [t=0.21s]
prediction: ['[CLS]y ridiculous loco but no no more, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.613 (perp=10.159, rec=0.111, cos=0.470), tot_loss_proj:3.347 [t=0.21s]
prediction: ['[CLS]e ridiculous loco but no more morey [SEP]']
[ 300/2000] tot_loss=2.440 (perp=9.327, rec=0.092, cos=0.483), tot_loss_proj:3.032 [t=0.21s]
prediction: ['[CLS], ridiculous loco but no more morey [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.334 (perp=8.785, rec=0.091, cos=0.486), tot_loss_proj:2.909 [t=0.21s]
prediction: ['[CLS] ridiculous loco but no no, morey [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.207 (perp=8.127, rec=0.098, cos=0.484), tot_loss_proj:2.794 [t=0.21s]
prediction: ['[CLS] ridiculous loco, but no more morey [SEP]']
[ 450/2000] tot_loss=2.323 (perp=8.715, rec=0.096, cos=0.484), tot_loss_proj:2.759 [t=0.21s]
prediction: ['[CLS] ridiculous loco, but no mu morey [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.203 (perp=8.159, rec=0.090, cos=0.481), tot_loss_proj:2.695 [t=0.21s]
prediction: ['[CLS] ridiculous mu loco, but no morey [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.200 (perp=8.159, rec=0.080, cos=0.488), tot_loss_proj:2.691 [t=0.21s]
prediction: ['[CLS] ridiculous mu loco, but no morey [SEP]']
[ 600/2000] tot_loss=2.194 (perp=8.159, rec=0.075, cos=0.488), tot_loss_proj:2.694 [t=0.21s]
prediction: ['[CLS] ridiculous mu loco, but no morey [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.099 (perp=7.686, rec=0.078, cos=0.484), tot_loss_proj:2.560 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.095 (perp=7.686, rec=0.074, cos=0.484), tot_loss_proj:2.556 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[ 750/2000] tot_loss=2.091 (perp=7.686, rec=0.068, cos=0.486), tot_loss_proj:2.559 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.096 (perp=7.686, rec=0.074, cos=0.485), tot_loss_proj:2.554 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.091 (perp=7.686, rec=0.068, cos=0.486), tot_loss_proj:2.556 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[ 900/2000] tot_loss=2.092 (perp=7.686, rec=0.070, cos=0.485), tot_loss_proj:2.556 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.087 (perp=7.686, rec=0.062, cos=0.489), tot_loss_proj:2.560 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1000/2000] tot_loss=2.092 (perp=7.686, rec=0.070, cos=0.486), tot_loss_proj:2.554 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1050/2000] tot_loss=2.090 (perp=7.686, rec=0.067, cos=0.487), tot_loss_proj:2.557 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1100/2000] tot_loss=2.088 (perp=7.686, rec=0.064, cos=0.487), tot_loss_proj:2.552 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1150/2000] tot_loss=2.091 (perp=7.686, rec=0.066, cos=0.488), tot_loss_proj:2.558 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1200/2000] tot_loss=2.085 (perp=7.686, rec=0.061, cos=0.487), tot_loss_proj:2.551 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1250/2000] tot_loss=2.091 (perp=7.686, rec=0.069, cos=0.484), tot_loss_proj:2.556 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1300/2000] tot_loss=2.101 (perp=7.686, rec=0.076, cos=0.488), tot_loss_proj:2.557 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1350/2000] tot_loss=2.095 (perp=7.686, rec=0.070, cos=0.488), tot_loss_proj:2.548 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1400/2000] tot_loss=2.091 (perp=7.686, rec=0.066, cos=0.488), tot_loss_proj:2.555 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1450/2000] tot_loss=2.090 (perp=7.686, rec=0.067, cos=0.486), tot_loss_proj:2.548 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1500/2000] tot_loss=2.091 (perp=7.686, rec=0.065, cos=0.488), tot_loss_proj:2.557 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1550/2000] tot_loss=2.089 (perp=7.686, rec=0.065, cos=0.486), tot_loss_proj:2.553 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1600/2000] tot_loss=2.091 (perp=7.686, rec=0.067, cos=0.487), tot_loss_proj:2.555 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1650/2000] tot_loss=2.086 (perp=7.686, rec=0.062, cos=0.487), tot_loss_proj:2.552 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1700/2000] tot_loss=2.084 (perp=7.686, rec=0.058, cos=0.488), tot_loss_proj:2.551 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1750/2000] tot_loss=2.084 (perp=7.686, rec=0.057, cos=0.489), tot_loss_proj:2.550 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1800/2000] tot_loss=2.081 (perp=7.686, rec=0.056, cos=0.488), tot_loss_proj:2.555 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1850/2000] tot_loss=2.086 (perp=7.686, rec=0.060, cos=0.488), tot_loss_proj:2.553 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[1900/2000] tot_loss=2.091 (perp=7.686, rec=0.065, cos=0.488), tot_loss_proj:2.550 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
[1950/2000] tot_loss=2.084 (perp=7.686, rec=0.058, cos=0.488), tot_loss_proj:2.553 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Attempt swap
[2000/2000] tot_loss=2.080 (perp=7.686, rec=0.055, cos=0.488), tot_loss_proj:2.554 [t=0.21s]
prediction: ['[CLS] ridiculous muy, but no more loco [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] ridiculous muy, but no more loco [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 88.646 | p: 87.897 | r: 89.602
rouge2     | fm: 52.412 | p: 52.143 | r: 52.829
rougeL     | fm: 76.733 | p: 76.134 | r: 77.510
rougeLsum  | fm: 76.716 | p: 76.106 | r: 77.492
r1fm+r2fm = 141.058

input #91 time: 0:08:27 | total time: 13:18:18


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.7353500220725665
highest_index [0]
highest [0.7353500220725665]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8293248414993286 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8186209797859192 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.7720073461532593 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7686655521392822 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7330582141876221 for ['[CLS] tank lonely [SEP]']
[Init] best rec loss: 0.7007790803909302 for ['[CLS] paths locked [SEP]']
[Init] best perm rec loss: 0.6981533765792847 for ['[CLS] locked paths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.159 (perp=7.646, rec=0.170, cos=0.459), tot_loss_proj:2.046 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=2.067 (perp=7.646, rec=0.080, cos=0.458), tot_loss_proj:2.053 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=2.061 (perp=7.646, rec=0.075, cos=0.457), tot_loss_proj:2.047 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=2.049 (perp=7.646, rec=0.068, cos=0.451), tot_loss_proj:2.048 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.052 (perp=7.646, rec=0.066, cos=0.456), tot_loss_proj:2.046 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=2.050 (perp=7.646, rec=0.068, cos=0.452), tot_loss_proj:2.047 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.064 (perp=7.646, rec=0.077, cos=0.457), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.052 (perp=7.646, rec=0.068, cos=0.455), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=2.068 (perp=7.646, rec=0.081, cos=0.458), tot_loss_proj:2.049 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.053 (perp=7.646, rec=0.069, cos=0.455), tot_loss_proj:2.047 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.049 (perp=7.646, rec=0.061, cos=0.459), tot_loss_proj:2.057 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=2.060 (perp=7.646, rec=0.075, cos=0.455), tot_loss_proj:2.044 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.051 (perp=7.646, rec=0.067, cos=0.455), tot_loss_proj:2.054 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.061 (perp=7.646, rec=0.075, cos=0.457), tot_loss_proj:2.041 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=2.058 (perp=7.646, rec=0.070, cos=0.458), tot_loss_proj:2.046 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.042 (perp=7.646, rec=0.055, cos=0.458), tot_loss_proj:2.049 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.047 (perp=7.646, rec=0.063, cos=0.455), tot_loss_proj:2.060 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=2.051 (perp=7.646, rec=0.064, cos=0.458), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.049 (perp=7.646, rec=0.065, cos=0.455), tot_loss_proj:2.058 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=2.049 (perp=7.646, rec=0.061, cos=0.458), tot_loss_proj:2.048 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=2.052 (perp=7.646, rec=0.065, cos=0.459), tot_loss_proj:2.060 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=2.055 (perp=7.646, rec=0.067, cos=0.459), tot_loss_proj:2.058 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=2.058 (perp=7.646, rec=0.072, cos=0.457), tot_loss_proj:2.066 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=2.054 (perp=7.646, rec=0.067, cos=0.458), tot_loss_proj:2.048 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=2.056 (perp=7.646, rec=0.068, cos=0.459), tot_loss_proj:2.048 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=2.047 (perp=7.646, rec=0.062, cos=0.457), tot_loss_proj:2.052 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=2.046 (perp=7.646, rec=0.059, cos=0.458), tot_loss_proj:2.055 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=2.047 (perp=7.646, rec=0.060, cos=0.458), tot_loss_proj:2.043 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=2.040 (perp=7.646, rec=0.052, cos=0.458), tot_loss_proj:2.055 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=2.047 (perp=7.646, rec=0.060, cos=0.458), tot_loss_proj:2.038 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=2.055 (perp=7.646, rec=0.067, cos=0.458), tot_loss_proj:2.042 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=2.046 (perp=7.646, rec=0.058, cos=0.458), tot_loss_proj:2.061 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=2.048 (perp=7.646, rec=0.060, cos=0.458), tot_loss_proj:2.055 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=2.036 (perp=7.646, rec=0.049, cos=0.458), tot_loss_proj:2.054 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=2.054 (perp=7.646, rec=0.067, cos=0.458), tot_loss_proj:2.046 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=2.048 (perp=7.646, rec=0.060, cos=0.458), tot_loss_proj:2.051 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=2.051 (perp=7.646, rec=0.064, cos=0.458), tot_loss_proj:2.047 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=2.040 (perp=7.646, rec=0.053, cos=0.458), tot_loss_proj:2.058 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=2.035 (perp=7.646, rec=0.047, cos=0.459), tot_loss_proj:2.053 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=2.043 (perp=7.646, rec=0.055, cos=0.459), tot_loss_proj:2.053 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.866 | p: 88.071 | r: 89.787
rouge2     | fm: 52.991 | p: 52.737 | r: 53.279
rougeL     | fm: 76.860 | p: 76.241 | r: 77.657
rougeLsum  | fm: 76.936 | p: 76.312 | r: 77.702
r1fm+r2fm = 141.858

input #92 time: 0:08:24 | total time: 13:26:42


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.7416563593916989
highest_index [0]
highest [0.7416563593916989]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9365618824958801 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8882136940956116 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.8813174962997437 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 0.8616619110107422 for ['[CLS] thousands fuel conditional scales progressed empowered mar [SEP]']
[Init] best rec loss: 0.85732102394104 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 0.8533540964126587 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 0.8512372374534607 for ['[CLS] furtherrac premiership jeremy madonna colby [CLS] [SEP]']
[Init] best perm rec loss: 0.8508118391036987 for ['[CLS] madonnarac further premiership [CLS] jeremy colby [SEP]']
[Init] best perm rec loss: 0.8482285141944885 for ['[CLS] further madonnarac jeremy colby premiership [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.029 (perp=11.592, rec=0.249, cos=0.461), tot_loss_proj:3.162 [t=0.21s]
prediction: ['[CLS] funny in often funny often sometimes funny [SEP]']
[ 100/2000] tot_loss=2.721 (perp=10.602, rec=0.150, cos=0.451), tot_loss_proj:2.912 [t=0.21s]
prediction: ['[CLS] funny in, funny often sometimes way [SEP]']
[ 150/2000] tot_loss=2.472 (perp=9.506, rec=0.120, cos=0.451), tot_loss_proj:2.840 [t=0.21s]
prediction: ['[CLS] understanding in often funny its sometimes way [SEP]']
[ 200/2000] tot_loss=2.610 (perp=10.302, rec=0.098, cos=0.451), tot_loss_proj:2.839 [t=0.21s]
prediction: ['[CLS] understanding in often funny its often way [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.278 (perp=8.666, rec=0.093, cos=0.452), tot_loss_proj:2.534 [t=0.21s]
prediction: ['[CLS] understanding in its often funny often way [SEP]']
[ 300/2000] tot_loss=2.402 (perp=9.357, rec=0.083, cos=0.448), tot_loss_proj:2.670 [t=0.21s]
prediction: ['[CLS] understanding in its, funny often way [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.080 (perp=7.746, rec=0.081, cos=0.450), tot_loss_proj:2.222 [t=0.21s]
prediction: ['[CLS] understanding in its, often funny way [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.921 (perp=6.938, rec=0.085, cos=0.449), tot_loss_proj:2.082 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 450/2000] tot_loss=1.910 (perp=6.938, rec=0.073, cos=0.449), tot_loss_proj:2.077 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.907 (perp=6.938, rec=0.071, cos=0.449), tot_loss_proj:2.087 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.907 (perp=6.938, rec=0.070, cos=0.449), tot_loss_proj:2.080 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 600/2000] tot_loss=1.901 (perp=6.938, rec=0.064, cos=0.450), tot_loss_proj:2.084 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.909 (perp=6.938, rec=0.073, cos=0.448), tot_loss_proj:2.083 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.859 (perp=6.705, rec=0.069, cos=0.450), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 750/2000] tot_loss=1.860 (perp=6.705, rec=0.070, cos=0.450), tot_loss_proj:2.089 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.854 (perp=6.705, rec=0.064, cos=0.449), tot_loss_proj:2.088 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.860 (perp=6.705, rec=0.071, cos=0.449), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.858 (perp=6.705, rec=0.068, cos=0.449), tot_loss_proj:2.090 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.850 (perp=6.705, rec=0.060, cos=0.449), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.862 (perp=6.705, rec=0.071, cos=0.450), tot_loss_proj:2.089 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.857 (perp=6.705, rec=0.067, cos=0.449), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.856 (perp=6.705, rec=0.066, cos=0.449), tot_loss_proj:2.087 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.856 (perp=6.705, rec=0.066, cos=0.449), tot_loss_proj:2.082 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.850 (perp=6.705, rec=0.060, cos=0.449), tot_loss_proj:2.078 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.856 (perp=6.705, rec=0.065, cos=0.449), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.849 (perp=6.705, rec=0.059, cos=0.449), tot_loss_proj:2.091 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.855 (perp=6.705, rec=0.065, cos=0.450), tot_loss_proj:2.093 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.864 (perp=6.705, rec=0.074, cos=0.450), tot_loss_proj:2.087 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.857 (perp=6.705, rec=0.067, cos=0.449), tot_loss_proj:2.091 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.850 (perp=6.705, rec=0.060, cos=0.449), tot_loss_proj:2.095 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.857 (perp=6.705, rec=0.066, cos=0.450), tot_loss_proj:2.085 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.856 (perp=6.705, rec=0.066, cos=0.449), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.854 (perp=6.705, rec=0.064, cos=0.450), tot_loss_proj:2.088 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.850 (perp=6.705, rec=0.059, cos=0.450), tot_loss_proj:2.085 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.858 (perp=6.705, rec=0.067, cos=0.449), tot_loss_proj:2.087 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.851 (perp=6.705, rec=0.061, cos=0.449), tot_loss_proj:2.088 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.856 (perp=6.705, rec=0.065, cos=0.450), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.856 (perp=6.705, rec=0.066, cos=0.449), tot_loss_proj:2.092 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.860 (perp=6.705, rec=0.070, cos=0.449), tot_loss_proj:2.084 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.860 (perp=6.705, rec=0.070, cos=0.449), tot_loss_proj:2.095 [t=0.21s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 88.963 | p: 88.232 | r: 89.897
rouge2     | fm: 53.112 | p: 52.836 | r: 53.460
rougeL     | fm: 76.999 | p: 76.386 | r: 77.767
rougeLsum  | fm: 77.098 | p: 76.497 | r: 77.813
r1fm+r2fm = 142.075

input #93 time: 0:08:27 | total time: 13:35:10


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.7157910347682943
highest_index [0]
highest [0.7157910347682943]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9497550129890442 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9473702311515808 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.925495982170105 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 0.9252744317054749 for ['[CLS] of pro wanted scientists rayon housing chart close earlier anniversary ni [SEP]']
[Init] best rec loss: 0.9247962236404419 for ['[CLS] quickly frontal form sean frightdah corps hopes or np championship [SEP]']
[Init] best rec loss: 0.9247334599494934 for ['[CLS] same traumatic to blessing surface pac cell carmeter environment sigh [SEP]']
[Init] best rec loss: 0.9227991104125977 for ['[CLS] approximately thereroids addedlga quite part ford jared published universite [SEP]']
[Init] best rec loss: 0.9120351672172546 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9084039330482483 for ['[CLS] enough usingac sur mile ready down maymise majesty assumption [SEP]']
[Init] best rec loss: 0.9069595336914062 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.9034565687179565 for ['[CLS] barber eithertype roador motivefirm trusted ednaack wanted [SEP]']
[Init] best perm rec loss: 0.9017885327339172 for ['[CLS]firm edna eithertypeack barber road wanted trusted motiveor [SEP]']
[Init] best perm rec loss: 0.9002989530563354 for ['[CLS]firm trusted barber road edna motive eithertypeackor wanted [SEP]']
[Init] best perm rec loss: 0.8994547128677368 for ['[CLS]ackor either edna barberfirm road wanted motivetype trusted [SEP]']
[Init] best perm rec loss: 0.8994271755218506 for ['[CLS]ackfirm trusted barber either motive ednaor wanted roadtype [SEP]']
[Init] best perm rec loss: 0.8985564112663269 for ['[CLS]ack road wanted barber motive edna trusted eithertypefirmor [SEP]']
[Init] best perm rec loss: 0.8983983397483826 for ['[CLS] motive barber trusted roadorfirm ednaack either wantedtype [SEP]']
[Init] best perm rec loss: 0.8983328342437744 for ['[CLS] motive edna roador trusted barberacktype wanted eitherfirm [SEP]']
[Init] best perm rec loss: 0.8982440829277039 for ['[CLS] trustedfirm ednatypeor barber motive road wanted eitherack [SEP]']
[Init] best perm rec loss: 0.8978999257087708 for ['[CLS] motive wanted barber road ednaack eitherfirm trustedortype [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.633 (perp=12.964, rec=0.573, cos=0.467), tot_loss_proj:3.820 [t=0.21s]
prediction: ['[CLS]ᴵ might told no cape funny neither funny [SEP] lens volta [SEP]']
[ 100/2000] tot_loss=4.017 (perp=14.929, rec=0.552, cos=0.479), tot_loss_proj:4.494 [t=0.22s]
prediction: ['[CLS] slightly respectively must outstanding cape badly neither funny tide neverumi [SEP]']
[ 150/2000] tot_loss=3.457 (perp=12.144, rec=0.553, cos=0.474), tot_loss_proj:4.409 [t=0.22s]
prediction: ['[CLS] slightly munster described beautiful cape yeah neither funny decision never type [SEP]']
[ 200/2000] tot_loss=3.279 (perp=11.405, rec=0.493, cos=0.504), tot_loss_proj:3.782 [t=0.22s]
prediction: ['[CLS] nor never in beautiful cape yeah neither original original never cape [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.564 (perp=13.281, rec=0.504, cos=0.404), tot_loss_proj:4.601 [t=0.22s]
prediction: ['[CLS] in gripping cape yeah neither original original zane never never cape [SEP]']
[ 300/2000] tot_loss=3.344 (perp=11.906, rec=0.520, cos=0.443), tot_loss_proj:4.316 [t=0.22s]
prediction: ['[CLS] said gripping cape yeah classmate same. zane nevernessy cape [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.944 (perp=10.419, rec=0.476, cos=0.385), tot_loss_proj:3.981 [t=0.22s]
prediction: ['[CLS] that accessible cape yeah both original champ nor nevererly. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.918 (perp=10.103, rec=0.475, cos=0.422), tot_loss_proj:3.933 [t=0.22s]
prediction: ['[CLS] or kind cape¨ both mysterious funny nor original neither. [SEP]']
[ 450/2000] tot_loss=2.787 (perp=9.665, rec=0.445, cos=0.410), tot_loss_proj:3.676 [t=0.22s]
prediction: ['[CLS] or easy cape densely both mysterious funny nor original neither. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.975 (perp=10.881, rec=0.439, cos=0.360), tot_loss_proj:4.042 [t=0.22s]
prediction: ['[CLS] or none cape neither both lack neitheruous beside original. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.913 (perp=9.800, rec=0.430, cos=0.523), tot_loss_proj:3.443 [t=0.22s]
prediction: ['[CLS] neither kind cape or both lack neitheruous beside original. [SEP]']
[ 600/2000] tot_loss=2.745 (perp=9.289, rec=0.414, cos=0.473), tot_loss_proj:3.081 [t=0.22s]
prediction: ['[CLS] neither none cape or both lack neither funny nor original. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.897 (perp=10.181, rec=0.463, cos=0.398), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] neither easy or neither lack cape neither funny nor original zombie [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.862 (perp=10.034, rec=0.401, cos=0.454), tot_loss_proj:3.391 [t=0.22s]
prediction: ['[CLS] neither easy neither lack cape sorry neither funny nor original funny [SEP]']
[ 750/2000] tot_loss=2.865 (perp=10.469, rec=0.390, cos=0.381), tot_loss_proj:3.908 [t=0.22s]
prediction: ['[CLS] neither none neither lack cape or neitheruous nor original funny [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.722 (perp=9.444, rec=0.381, cos=0.452), tot_loss_proj:3.196 [t=0.22s]
prediction: ['[CLS] neither lack neither easy cape definitely neither original nor original funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.630 (perp=9.444, rec=0.373, cos=0.369), tot_loss_proj:3.191 [t=0.22s]
prediction: ['[CLS] neither lack neither easy cape definitely neither original nor original funny [SEP]']
[ 900/2000] tot_loss=2.734 (perp=9.444, rec=0.366, cos=0.478), tot_loss_proj:3.197 [t=0.22s]
prediction: ['[CLS] neither lack neither easy cape definitely neither original nor original funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.649 (perp=9.444, rec=0.360, cos=0.400), tot_loss_proj:3.194 [t=0.22s]
prediction: ['[CLS] neither lack neither easy cape definitely neither original nor original funny [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.890 (perp=10.307, rec=0.357, cos=0.472), tot_loss_proj:3.448 [t=0.22s]
prediction: ['[CLS] neither lack neither none cape definitely original becca nor neither funny [SEP]']
[1050/2000] tot_loss=2.804 (perp=10.534, rec=0.345, cos=0.352), tot_loss_proj:3.532 [t=0.22s]
prediction: ['[CLS] neither lack neither none cape did original becca nor neither funny [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.511 (perp=9.559, rec=0.354, cos=0.246), tot_loss_proj:3.259 [t=0.22s]
prediction: ['[CLS] neither a lack neither none cape original becca nor neither funny [SEP]']
Attempt swap
[1150/2000] tot_loss=2.597 (perp=9.559, rec=0.348, cos=0.338), tot_loss_proj:3.253 [t=0.22s]
prediction: ['[CLS] neither a lack neither none cape original becca nor neither funny [SEP]']
[1200/2000] tot_loss=2.754 (perp=9.600, rec=0.333, cos=0.501), tot_loss_proj:3.037 [t=0.22s]
prediction: ['[CLS] neither a indeed neither none cape original becca nor neither funny [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.661 (perp=9.079, rec=0.335, cos=0.510), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] neither indeed neither a none cape original becca nor neither funny [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.630 (perp=9.051, rec=0.337, cos=0.482), tot_loss_proj:2.896 [t=0.22s]
prediction: ['[CLS] neither indeed neither a none cape becca original nor neither funny [SEP]']
[1350/2000] tot_loss=2.471 (perp=9.051, rec=0.332, cos=0.329), tot_loss_proj:2.895 [t=0.22s]
prediction: ['[CLS] neither indeed neither a none cape becca original nor neither funny [SEP]']
Attempt swap
[1400/2000] tot_loss=2.506 (perp=9.051, rec=0.329, cos=0.367), tot_loss_proj:2.895 [t=0.22s]
prediction: ['[CLS] neither indeed neither a none cape becca original nor neither funny [SEP]']
Attempt swap
[1450/2000] tot_loss=2.570 (perp=9.414, rec=0.324, cos=0.363), tot_loss_proj:2.960 [t=0.22s]
prediction: ['[CLS]uous indeed neither a none cape becca original nor neither funny [SEP]']
[1500/2000] tot_loss=2.690 (perp=9.414, rec=0.323, cos=0.483), tot_loss_proj:2.957 [t=0.22s]
prediction: ['[CLS]uous indeed neither a none cape becca original nor neither funny [SEP]']
Attempt swap
[1550/2000] tot_loss=3.003 (perp=11.158, rec=0.321, cos=0.450), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS]uous dalai neither a none cape becca original nor neither funny [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.821 (perp=10.517, rec=0.329, cos=0.388), tot_loss_proj:3.150 [t=0.22s]
prediction: ['[CLS] dalaiuous neither a none cape becca original nor neither funny [SEP]']
[1650/2000] tot_loss=2.801 (perp=10.507, rec=0.327, cos=0.372), tot_loss_proj:3.143 [t=0.22s]
prediction: ['[CLS] dalaiuous neither a never cape becca original nor neither funny [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.771 (perp=10.364, rec=0.326, cos=0.373), tot_loss_proj:3.101 [t=0.22s]
prediction: ['[CLS] dalaiuous neither never a cape becca original nor neither funny [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.731 (perp=9.716, rec=0.323, cos=0.465), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] indeeduous never neither a cape becca original nor neither funny [SEP]']
[1800/2000] tot_loss=2.719 (perp=9.716, rec=0.318, cos=0.457), tot_loss_proj:3.018 [t=0.22s]
prediction: ['[CLS] indeeduous never neither a cape becca original nor neither funny [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.588 (perp=9.187, rec=0.326, cos=0.425), tot_loss_proj:2.935 [t=0.22s]
prediction: ['[CLS]uous indeed never neither a cape becca original nor neither funny [SEP]']
Attempt swap
[1900/2000] tot_loss=2.606 (perp=9.187, rec=0.317, cos=0.451), tot_loss_proj:2.936 [t=0.22s]
prediction: ['[CLS]uous indeed never neither a cape becca original nor neither funny [SEP]']
[1950/2000] tot_loss=2.648 (perp=9.187, rec=0.315, cos=0.495), tot_loss_proj:2.936 [t=0.22s]
prediction: ['[CLS]uous indeed never neither a cape becca original nor neither funny [SEP]']
Attempt swap
[2000/2000] tot_loss=2.586 (perp=9.187, rec=0.318, cos=0.431), tot_loss_proj:2.932 [t=0.22s]
prediction: ['[CLS]uous indeed never neither a cape becca original nor neither funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS]uous indeed never neither a cape becca original nor neither funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.333 | p: 53.846 | r: 63.636
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 50.000 | p: 46.154 | r: 54.545
rougeLsum  | fm: 50.000 | p: 46.154 | r: 54.545
r1fm+r2fm = 76.515

[Aggregate metrics]:
rouge1     | fm: 88.660 | p: 87.844 | r: 89.623
rouge2     | fm: 52.686 | p: 52.411 | r: 53.048
rougeL     | fm: 76.731 | p: 76.063 | r: 77.526
rougeLsum  | fm: 76.817 | p: 76.161 | r: 77.624
r1fm+r2fm = 141.346

input #94 time: 0:08:36 | total time: 13:43:47


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.7120108835974455
highest_index [0]
highest [0.7120108835974455]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.0224987268447876 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.01156747341156 for ['[CLS] reprinted geographic fairchild clary remains hitler tristanved thumb big hot dates muscle commander funding [SEP]']
[Init] best rec loss: 0.9882541298866272 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9791347980499268 for ['[CLS] sooner rue " pace leagues della smell sul epithet greenon power local concacaf relay [SEP]']
[Init] best rec loss: 0.9708244800567627 for ['[CLS] footprint brain arrival rec [MASK] 45 reverse if pal struggled spanning caleb born day classic [SEP]']
[Init] best rec loss: 0.9678860306739807 for ['[CLS] gas somewhereator bulk aka unlessssee actual como deliver? jockuble occasion [SEP]']
[Init] best perm rec loss: 0.9659432768821716 for ['[CLS] unless jocku aka bulk occasionssee somewhereator actual? como gasble deliver [SEP]']
[Init] best perm rec loss: 0.9658145904541016 for ['[CLS]atorble occasion? akau gas unless como deliver somewhere actualssee bulk jock [SEP]']
[Init] best perm rec loss: 0.9656915664672852 for ['[CLS]ssee akau? occasion deliver actual unless gas bulk somewhere como jockbleator [SEP]']
[Init] best perm rec loss: 0.9648711085319519 for ['[CLS]ator jock unless?sseeu aka somewhere occasion bulk como actual deliverble gas [SEP]']
[Init] best perm rec loss: 0.9640457034111023 for ['[CLS] jock?ssee gas unless como deliver bulku occasionble aka actual somewhereator [SEP]']
[Init] best perm rec loss: 0.9638274312019348 for ['[CLS]u actual unless gasble somewhere bulk? occasion deliverator aka jockssee como [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.634 (perp=12.570, rec=0.619, cos=0.501), tot_loss_proj:4.502 [t=0.21s]
prediction: ['[CLS]iful stunt major idealy emmy looking oakley narrowed clark taylor por rock cp " [SEP]']
[ 100/2000] tot_loss=3.530 (perp=12.577, rec=0.533, cos=0.481), tot_loss_proj:4.407 [t=0.21s]
prediction: ['[CLS]iful female truman cheeky abilities possibilities regimental hopeless is una pass challenges ms expeditions [SEP]']
[ 150/2000] tot_loss=3.677 (perp=13.340, rec=0.520, cos=0.489), tot_loss_proj:3.972 [t=0.21s]
prediction: ['[CLS] becomes becomes. to ) hopeless discontinued regimental hopeless is desperately por challenges arrivedfur [SEP]']
[ 200/2000] tot_loss=3.439 (perp=12.989, rec=0.343, cos=0.498), tot_loss_proj:3.743 [t=0.21s]
prediction: ['[CLS] despair characters grid becomepy orphan app hopeless hopeless bbc undergit hopeless hopelesscast [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.058 (perp=11.557, rec=0.258, cos=0.489), tot_loss_proj:3.394 [t=0.21s]
prediction: ['[CLS] hopelessly hopeless story grid becomes hopeless hopeless hopeless nicholas behind - hopeless hopeless wake [SEP]']
[ 300/2000] tot_loss=3.373 (perp=13.332, rec=0.215, cos=0.492), tot_loss_proj:3.740 [t=0.21s]
prediction: ['[CLS] hopelessnified hopeless story grid becomes hopeless hopeless hopeless denissatdle hopeless hopelessdle [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.496 (perp=14.054, rec=0.196, cos=0.489), tot_loss_proj:3.921 [t=0.21s]
prediction: ['[CLS] hopelessis mud story undle becomes hopeless hopeless hopeless denissatdle hopeless hopeless [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.188 (perp=12.565, rec=0.183, cos=0.492), tot_loss_proj:3.625 [t=0.21s]
prediction: ['[CLS]satis mud story undle becomes hopeless hopeless hopeless denis hopelessdle hopeless hopeless [SEP]']
[ 450/2000] tot_loss=3.087 (perp=12.183, rec=0.158, cos=0.492), tot_loss_proj:3.505 [t=0.21s]
prediction: ['[CLS]satis mud story muddle becomes hopeless hopeless hopeless denis hopelessdle hopeless hopeless [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.875 (perp=11.177, rec=0.151, cos=0.489), tot_loss_proj:3.303 [t=0.21s]
prediction: ['[CLS]satis mud story hopeless hopeless muddle becomes hopeless denis hopelessdle hopeless hopeless [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.159 (perp=12.676, rec=0.132, cos=0.492), tot_loss_proj:3.639 [t=0.21s]
prediction: ['[CLS]satis mud story hopeless hopeless undle becomes hopeless denis hopelessdle hopeless hopeless [SEP]']
[ 600/2000] tot_loss=3.157 (perp=12.676, rec=0.131, cos=0.491), tot_loss_proj:3.637 [t=0.21s]
prediction: ['[CLS]satis mud story hopeless hopeless undle becomes hopeless denis hopelessdle hopeless hopeless [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.959 (perp=11.630, rec=0.140, cos=0.492), tot_loss_proj:3.433 [t=0.21s]
prediction: ['[CLS]satis mud story hopeless hopeless undle becomes hopeless denis muddle hopeless hopeless [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.768 (perp=10.652, rec=0.146, cos=0.491), tot_loss_proj:3.162 [t=0.21s]
prediction: ['[CLS] unsatis dead story hopeless hopelessdle becomes hopeless denis muddle hopeless hopeless [SEP]']
[ 750/2000] tot_loss=2.781 (perp=10.791, rec=0.131, cos=0.492), tot_loss_proj:3.161 [t=0.21s]
prediction: ["[CLS] unsatis dead story hopeless 'dle becomes hopeless denis muddle hopeless hopeless [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=2.744 (perp=10.620, rec=0.129, cos=0.491), tot_loss_proj:3.176 [t=0.21s]
prediction: ["[CLS] unsatis story hopeless hopeless 'dle becomes hopeless denis muddle hopeless hopeless [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.650 (perp=10.175, rec=0.125, cos=0.490), tot_loss_proj:3.139 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless hopeless muddle becomes hopeless denis )dle hopeless hopeless [SEP]']
[ 900/2000] tot_loss=2.648 (perp=10.175, rec=0.121, cos=0.491), tot_loss_proj:3.141 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless hopeless muddle becomes hopeless denis )dle hopeless hopeless [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.588 (perp=9.901, rec=0.117, cos=0.491), tot_loss_proj:3.020 [t=0.21s]
prediction: ["[CLS] unsatis story hopeless dead muddle becomes hopeless denisdle starving hopeless'[SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.475 (perp=9.317, rec=0.120, cos=0.491), tot_loss_proj:2.878 [t=0.21s]
prediction: ["[CLS] unsatis story hopeless dead muddle becomes hopeless denis'hopeless hopelessdle [SEP]"]
[1050/2000] tot_loss=2.478 (perp=9.364, rec=0.114, cos=0.491), tot_loss_proj:2.885 [t=0.21s]
prediction: ["[CLS] unsatis story hopeless dead muddle becomes hopeless denis'starving hopelessdle [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=2.587 (perp=9.900, rec=0.117, cos=0.489), tot_loss_proj:3.057 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle becomes hopeless denis ) starving hopeless muddle [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.401 (perp=8.987, rec=0.111, cos=0.492), tot_loss_proj:2.817 [t=0.21s]
prediction: ["[CLS] unsatis story hopeless deaddle becomes hopeless denis'hopeless starving muddle [SEP]"]
[1200/2000] tot_loss=2.548 (perp=9.728, rec=0.112, cos=0.491), tot_loss_proj:3.013 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle becomes hopeless denis ) hopeless starving muddle [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.448 (perp=9.246, rec=0.108, cos=0.491), tot_loss_proj:2.926 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1300/2000] tot_loss=2.446 (perp=9.246, rec=0.106, cos=0.492), tot_loss_proj:2.925 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
[1350/2000] tot_loss=2.448 (perp=9.246, rec=0.107, cos=0.492), tot_loss_proj:2.922 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1400/2000] tot_loss=2.442 (perp=9.246, rec=0.100, cos=0.492), tot_loss_proj:2.925 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1450/2000] tot_loss=2.450 (perp=9.246, rec=0.109, cos=0.492), tot_loss_proj:2.927 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
[1500/2000] tot_loss=2.451 (perp=9.246, rec=0.110, cos=0.492), tot_loss_proj:2.921 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1550/2000] tot_loss=2.445 (perp=9.246, rec=0.104, cos=0.492), tot_loss_proj:2.931 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1600/2000] tot_loss=2.441 (perp=9.246, rec=0.100, cos=0.492), tot_loss_proj:2.932 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
[1650/2000] tot_loss=2.446 (perp=9.246, rec=0.105, cos=0.492), tot_loss_proj:2.925 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1700/2000] tot_loss=2.452 (perp=9.246, rec=0.110, cos=0.492), tot_loss_proj:2.928 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1750/2000] tot_loss=2.441 (perp=9.246, rec=0.100, cos=0.492), tot_loss_proj:2.926 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
[1800/2000] tot_loss=2.449 (perp=9.246, rec=0.107, cos=0.492), tot_loss_proj:2.926 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1850/2000] tot_loss=2.444 (perp=9.246, rec=0.102, cos=0.492), tot_loss_proj:2.926 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
Attempt swap
[1900/2000] tot_loss=2.450 (perp=9.246, rec=0.108, cos=0.492), tot_loss_proj:2.925 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]']
[1950/2000] tot_loss=2.543 (perp=9.743, rec=0.101, cos=0.493), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] unsatis story hopeless deaddle ) hopeless denis becomesfying starving muddle [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.660 (perp=10.298, rec=0.110, cos=0.491), tot_loss_proj:3.035 [t=0.21s]
prediction: ["[CLS] unsatis hopeless hopeless deaddle'hopeless denis becomes story starving muddle [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] unsatis story hopeless deaddle ) hopeless denis becomes hopeless starving muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 58.333 | r: 77.778
rouge2     | fm: 10.526 | p: 9.091 | r: 12.500
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 77.193

[Aggregate metrics]:
rouge1     | fm: 88.428 | p: 87.570 | r: 89.536
rouge2     | fm: 52.371 | p: 52.057 | r: 52.751
rougeL     | fm: 76.556 | p: 75.849 | r: 77.447
rougeLsum  | fm: 76.548 | p: 75.806 | r: 77.432
r1fm+r2fm = 140.799

input #95 time: 0:08:26 | total time: 13:52:13


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.7188547586971658
highest_index [0]
highest [0.7188547586971658]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8295590877532959 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8154675960540771 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 0.8003637790679932 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7844195365905762 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7743126749992371 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7701741456985474 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 0.7543603181838989 for ['[CLS] foreign x universalhausen ant southeast leave brands ascent perpendicular are article holding wrestling capability [SEP]']
[Init] best perm rec loss: 0.7533021569252014 for ['[CLS] wrestling x article southeast holding perpendicular foreign leavehausen ascent universal capability are ant brands [SEP]']
[Init] best perm rec loss: 0.7520905137062073 for ['[CLS] universal perpendicular article wrestling brands holdinghausen foreign ant capability are leave x southeast ascent [SEP]']
[Init] best perm rec loss: 0.7512003779411316 for ['[CLS] southeast x wrestling perpendicular article capability leave ascenthausen universal brands foreign are holding ant [SEP]']
[Init] best perm rec loss: 0.7511220574378967 for ['[CLS] x article foreign capability ascent ant wrestling perpendicular holdinghausen universal leave southeast are brands [SEP]']
[Init] best perm rec loss: 0.7500433921813965 for ['[CLS] ascent wrestlinghausen ant article perpendicular southeast leave are universal foreign x capability holding brands [SEP]']
[Init] best perm rec loss: 0.7496610879898071 for ['[CLS] ant article perpendicular southeast wrestling holding are capabilityhausen leave brands universal ascent x foreign [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.194 (perp=12.057, rec=0.319, cos=0.464), tot_loss_proj:4.030 [t=0.21s]
prediction: ['[CLS] cover lesser situations become less weak sara force lesser others for delivered situations class person [SEP]']
[ 100/2000] tot_loss=2.735 (perp=10.163, rec=0.233, cos=0.469), tot_loss_proj:3.387 [t=0.21s]
prediction: ['[CLS] cover lesser situations for cover would necessary force lesser men on make situations force himself [SEP]']
[ 150/2000] tot_loss=2.846 (perp=10.966, rec=0.177, cos=0.475), tot_loss_proj:3.462 [t=0.21s]
prediction: ['[CLS] cover lesser run run cover would himself force lesser men on make situations force himself [SEP]']
[ 200/2000] tot_loss=2.471 (perp=9.338, rec=0.123, cos=0.480), tot_loss_proj:3.161 [t=0.21s]
prediction: ['[CLS] cover would run for cover would himself force lesser men on make situations force into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.543 (perp=9.705, rec=0.122, cos=0.481), tot_loss_proj:3.337 [t=0.21s]
prediction: ['[CLS] cover would run for cover himself make force lesser men on make situations on into [SEP]']
[ 300/2000] tot_loss=2.614 (perp=10.143, rec=0.106, cos=0.480), tot_loss_proj:3.289 [t=0.21s]
prediction: ['[CLS] cover would run for cover himself make force lesser men on make situations people into [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.426 (perp=9.276, rec=0.091, cos=0.480), tot_loss_proj:3.065 [t=0.21s]
prediction: ['[CLS] cover would run for cover himself make force lesser men on make people into situations [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.267 (perp=8.370, rec=0.113, cos=0.480), tot_loss_proj:2.897 [t=0.21s]
prediction: ['[CLS] cover would make people run for cover himself make force lesser men on into situations [SEP]']
[ 450/2000] tot_loss=2.247 (perp=8.370, rec=0.090, cos=0.482), tot_loss_proj:2.897 [t=0.21s]
prediction: ['[CLS] cover would make people run for cover himself make force lesser men on into situations [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.224 (perp=8.252, rec=0.092, cos=0.482), tot_loss_proj:2.870 [t=0.21s]
prediction: ['[CLS] cover would make people run for cover himself make force lesser men into situations on [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.139 (perp=7.777, rec=0.102, cos=0.482), tot_loss_proj:2.769 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself make force lesser men into situations [SEP]']
[ 600/2000] tot_loss=2.134 (perp=7.777, rec=0.095, cos=0.483), tot_loss_proj:2.772 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself make force lesser men into situations [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.098 (perp=7.658, rec=0.084, cos=0.483), tot_loss_proj:3.287 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself make into lesser men force situations [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.108 (perp=7.658, rec=0.094, cos=0.482), tot_loss_proj:3.286 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself make into lesser men force situations [SEP]']
[ 750/2000] tot_loss=2.099 (perp=7.658, rec=0.084, cos=0.483), tot_loss_proj:3.286 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself make into lesser men force situations [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.093 (perp=7.658, rec=0.081, cos=0.480), tot_loss_proj:3.282 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself make into lesser men force situations [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.156 (perp=7.969, rec=0.081, cos=0.481), tot_loss_proj:3.362 [t=0.21s]
prediction: ['[CLS] on cover would people run for cover himself make into lesser men into force situations [SEP]']
[ 900/2000] tot_loss=2.156 (perp=7.969, rec=0.079, cos=0.484), tot_loss_proj:3.359 [t=0.21s]
prediction: ['[CLS] on cover would people run for cover himself make into lesser men into force situations [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.156 (perp=7.969, rec=0.082, cos=0.481), tot_loss_proj:3.361 [t=0.21s]
prediction: ['[CLS] on cover would people run for cover himself make into lesser men into force situations [SEP]']
Attempt swap
[1000/2000] tot_loss=2.158 (perp=7.969, rec=0.082, cos=0.482), tot_loss_proj:3.359 [t=0.21s]
prediction: ['[CLS] on cover would people run for cover himself make into lesser men into force situations [SEP]']
[1050/2000] tot_loss=2.150 (perp=7.969, rec=0.073, cos=0.483), tot_loss_proj:3.359 [t=0.21s]
prediction: ['[CLS] on cover would people run for cover himself make into lesser men into force situations [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.036 (perp=7.342, rec=0.086, cos=0.482), tot_loss_proj:3.119 [t=0.21s]
prediction: ['[CLS] on cover would make people run for cover himself into lesser men into force situations [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.011 (perp=7.210, rec=0.087, cos=0.482), tot_loss_proj:3.155 [t=0.21s]
prediction: ['[CLS] on cover would make people run into cover himself for lesser men into force situations [SEP]']
[1200/2000] tot_loss=2.009 (perp=7.210, rec=0.085, cos=0.482), tot_loss_proj:3.156 [t=0.21s]
prediction: ['[CLS] on cover would make people run into cover himself for lesser men into force situations [SEP]']
Attempt swap
[1250/2000] tot_loss=2.009 (perp=7.210, rec=0.085, cos=0.482), tot_loss_proj:3.154 [t=0.21s]
prediction: ['[CLS] on cover would make people run into cover himself for lesser men into force situations [SEP]']
Attempt swap
[1300/2000] tot_loss=2.002 (perp=7.210, rec=0.078, cos=0.483), tot_loss_proj:3.156 [t=0.21s]
prediction: ['[CLS] on cover would make people run into cover himself for lesser men into force situations [SEP]']
[1350/2000] tot_loss=2.083 (perp=7.655, rec=0.069, cos=0.483), tot_loss_proj:3.068 [t=0.21s]
prediction: ['[CLS] on cover would make people run and cover himself for lesser men into force situations [SEP]']
Attempt swap
[1400/2000] tot_loss=2.087 (perp=7.655, rec=0.074, cos=0.483), tot_loss_proj:3.066 [t=0.21s]
prediction: ['[CLS] on cover would make people run and cover himself for lesser men into force situations [SEP]']
Attempt swap
[1450/2000] tot_loss=2.086 (perp=7.655, rec=0.073, cos=0.483), tot_loss_proj:3.069 [t=0.21s]
prediction: ['[CLS] on cover would make people run and cover himself for lesser men into force situations [SEP]']
[1500/2000] tot_loss=2.092 (perp=7.655, rec=0.078, cos=0.483), tot_loss_proj:3.069 [t=0.21s]
prediction: ['[CLS] on cover would make people run and cover himself for lesser men into force situations [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.997 (perp=7.093, rec=0.095, cos=0.483), tot_loss_proj:3.109 [t=0.21s]
prediction: ['[CLS] on cover would make people run into cover himself for lesser men and force situations [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.944 (perp=6.850, rec=0.090, cos=0.484), tot_loss_proj:2.534 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
[1650/2000] tot_loss=1.938 (perp=6.850, rec=0.085, cos=0.483), tot_loss_proj:2.533 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
Attempt swap
[1700/2000] tot_loss=1.935 (perp=6.850, rec=0.082, cos=0.483), tot_loss_proj:2.532 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
Attempt swap
[1750/2000] tot_loss=1.944 (perp=6.850, rec=0.091, cos=0.483), tot_loss_proj:2.532 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
[1800/2000] tot_loss=1.932 (perp=6.850, rec=0.079, cos=0.483), tot_loss_proj:2.532 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
Attempt swap
[1850/2000] tot_loss=1.933 (perp=6.850, rec=0.080, cos=0.483), tot_loss_proj:2.536 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.930 (perp=6.850, rec=0.077, cos=0.483), tot_loss_proj:2.535 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
[1950/2000] tot_loss=1.936 (perp=6.850, rec=0.083, cos=0.483), tot_loss_proj:2.533 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
Attempt swap
[2000/2000] tot_loss=1.931 (perp=6.850, rec=0.078, cos=0.483), tot_loss_proj:2.534 [t=0.21s]
prediction: ['[CLS] on situations would make people run into cover situations for lesser men and force himself [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] on cover would make people run and cover himself for lesser men into force situations [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 41.176 | p: 41.176 | r: 41.176
rougeLsum  | fm: 41.176 | p: 41.176 | r: 41.176
r1fm+r2fm = 106.618

[Aggregate metrics]:
rouge1     | fm: 88.481 | p: 87.606 | r: 89.518
rouge2     | fm: 51.842 | p: 51.582 | r: 52.214
rougeL     | fm: 76.170 | p: 75.446 | r: 77.041
rougeLsum  | fm: 76.184 | p: 75.455 | r: 77.096
r1fm+r2fm = 140.322

input #96 time: 0:08:25 | total time: 14:00:39


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.7101732104354417
highest_index [0]
highest [0.7101732104354417]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7420834898948669 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.7209058403968811 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.7182288765907288 for ['[CLS] victoria 2016 which test passten [SEP]']
[Init] best perm rec loss: 0.7181726098060608 for ['[CLS] which testten victoria pass 2016 [SEP]']
[Init] best perm rec loss: 0.7137961983680725 for ['[CLS] passten 2016 test which victoria [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.719 (perp=14.473, rec=0.326, cos=0.498), tot_loss_proj:4.480 [t=0.21s]
prediction: ['[CLS]quefor wayfor true visitor [SEP]']
[ 100/2000] tot_loss=2.125 (perp=7.203, rec=0.185, cos=0.500), tot_loss_proj:2.415 [t=0.21s]
prediction: ['[CLS]get unforgettable characters [SEP]']
[ 150/2000] tot_loss=2.061 (perp=7.203, rec=0.132, cos=0.488), tot_loss_proj:2.426 [t=0.21s]
prediction: ['[CLS]get unforgettable characters [SEP]']
[ 200/2000] tot_loss=2.758 (perp=10.770, rec=0.114, cos=0.491), tot_loss_proj:3.527 [t=0.21s]
prediction: ['[CLS]get unforfortable characters [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.996 (perp=6.939, rec=0.108, cos=0.500), tot_loss_proj:2.080 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[ 300/2000] tot_loss=1.960 (perp=6.939, rec=0.086, cos=0.486), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.977 (perp=6.939, rec=0.097, cos=0.492), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.976 (perp=6.939, rec=0.090, cos=0.499), tot_loss_proj:2.107 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[ 450/2000] tot_loss=1.981 (perp=6.939, rec=0.101, cos=0.492), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.976 (perp=6.939, rec=0.096, cos=0.493), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.967 (perp=6.939, rec=0.085, cos=0.495), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[ 600/2000] tot_loss=1.956 (perp=6.939, rec=0.081, cos=0.487), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.958 (perp=6.939, rec=0.083, cos=0.487), tot_loss_proj:2.122 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=6.939, rec=0.091, cos=0.489), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[ 750/2000] tot_loss=1.970 (perp=6.939, rec=0.093, cos=0.489), tot_loss_proj:2.132 [t=0.21s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.975 (perp=6.939, rec=0.090, cos=0.497), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=6.939, rec=0.086, cos=0.494), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[ 900/2000] tot_loss=1.966 (perp=6.939, rec=0.092, cos=0.486), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.971 (perp=6.939, rec=0.090, cos=0.493), tot_loss_proj:2.139 [t=0.21s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.964 (perp=6.939, rec=0.084, cos=0.492), tot_loss_proj:2.135 [t=0.21s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[1050/2000] tot_loss=1.962 (perp=6.939, rec=0.088, cos=0.486), tot_loss_proj:2.135 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.964 (perp=6.939, rec=0.087, cos=0.489), tot_loss_proj:2.140 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.947 (perp=6.939, rec=0.066, cos=0.493), tot_loss_proj:2.132 [t=0.21s]
prediction: ['[CLS] unforforgettable characters [SEP]']
[1200/2000] tot_loss=1.950 (perp=6.939, rec=0.074, cos=0.488), tot_loss_proj:2.138 [t=0.21s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.941 (perp=6.939, rec=0.065, cos=0.489), tot_loss_proj:2.122 [t=0.22s]
prediction: ['[CLS] unforforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=2.212 (perp=8.226, rec=0.074, cos=0.493), tot_loss_proj:2.781 [t=0.22s]
prediction: ['[CLS] unfor andgettable characters [SEP]']
[1350/2000] tot_loss=2.201 (perp=8.226, rec=0.064, cos=0.492), tot_loss_proj:2.791 [t=0.22s]
prediction: ['[CLS] unfor andgettable characters [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.618 (perp=5.309, rec=0.070, cos=0.487), tot_loss_proj:1.611 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.622 (perp=5.309, rec=0.068, cos=0.492), tot_loss_proj:1.622 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.606 (perp=5.309, rec=0.052, cos=0.493), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.616 (perp=5.309, rec=0.062, cos=0.492), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.629 (perp=5.309, rec=0.074, cos=0.493), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.612 (perp=5.309, rec=0.055, cos=0.495), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.620 (perp=5.309, rec=0.064, cos=0.495), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.612 (perp=5.309, rec=0.059, cos=0.491), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.619 (perp=5.309, rec=0.062, cos=0.495), tot_loss_proj:1.620 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.612 (perp=5.309, rec=0.058, cos=0.493), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.625 (perp=5.309, rec=0.068, cos=0.495), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.618 (perp=5.309, rec=0.062, cos=0.494), tot_loss_proj:1.609 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.624 (perp=5.309, rec=0.066, cos=0.496), tot_loss_proj:1.619 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.525 | p: 87.681 | r: 89.584
rouge2     | fm: 52.432 | p: 52.133 | r: 52.808
rougeL     | fm: 76.433 | p: 75.748 | r: 77.302
rougeLsum  | fm: 76.515 | p: 75.812 | r: 77.384
r1fm+r2fm = 140.957

input #97 time: 0:08:30 | total time: 14:09:09


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.7093005808991499
highest_index [0]
highest [0.7093005808991499]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6574541330337524 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6538828015327454 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.647547721862793 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.142 (perp=12.067, rec=0.244, cos=0.485), tot_loss_proj:3.475 [t=0.21s]
prediction: ['[CLS] unfulful losses [SEP]']
[ 100/2000] tot_loss=2.444 (perp=9.122, rec=0.134, cos=0.486), tot_loss_proj:2.885 [t=0.21s]
prediction: ['[CLS] unfullling employee [SEP]']
[ 150/2000] tot_loss=3.199 (perp=12.919, rec=0.122, cos=0.493), tot_loss_proj:3.461 [t=0.21s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 200/2000] tot_loss=3.147 (perp=12.919, rec=0.080, cos=0.484), tot_loss_proj:3.473 [t=0.22s]
prediction: ['[CLS] unfulllingfi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.554 (perp=4.948, rec=0.071, cos=0.493), tot_loss_proj:1.565 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.581 (perp=4.948, rec=0.094, cos=0.498), tot_loss_proj:1.587 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.571 (perp=4.948, rec=0.080, cos=0.501), tot_loss_proj:1.590 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.553 (perp=4.948, rec=0.073, cos=0.490), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.574 (perp=4.948, rec=0.090, cos=0.495), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.554 (perp=4.948, rec=0.068, cos=0.497), tot_loss_proj:1.578 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.554 (perp=4.948, rec=0.075, cos=0.489), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.555 (perp=4.948, rec=0.070, cos=0.495), tot_loss_proj:1.584 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=4.948, rec=0.078, cos=0.497), tot_loss_proj:1.570 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.538 (perp=4.948, rec=0.058, cos=0.490), tot_loss_proj:1.574 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.549 (perp=4.948, rec=0.066, cos=0.493), tot_loss_proj:1.571 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.545 (perp=4.948, rec=0.059, cos=0.496), tot_loss_proj:1.578 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.544 (perp=4.948, rec=0.060, cos=0.494), tot_loss_proj:1.567 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.552 (perp=4.948, rec=0.071, cos=0.492), tot_loss_proj:1.580 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.549 (perp=4.948, rec=0.070, cos=0.490), tot_loss_proj:1.583 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.545 (perp=4.948, rec=0.060, cos=0.496), tot_loss_proj:1.571 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.549 (perp=4.948, rec=0.067, cos=0.492), tot_loss_proj:1.575 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.548 (perp=4.948, rec=0.069, cos=0.490), tot_loss_proj:1.582 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.534 (perp=4.948, rec=0.051, cos=0.493), tot_loss_proj:1.572 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.542 (perp=4.948, rec=0.058, cos=0.495), tot_loss_proj:1.563 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.544 (perp=4.948, rec=0.059, cos=0.495), tot_loss_proj:1.556 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.543 (perp=4.948, rec=0.061, cos=0.493), tot_loss_proj:1.568 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.540 (perp=4.948, rec=0.056, cos=0.495), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.563 (perp=4.948, rec=0.078, cos=0.496), tot_loss_proj:1.575 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.551 (perp=4.948, rec=0.064, cos=0.497), tot_loss_proj:1.566 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.539 (perp=4.948, rec=0.057, cos=0.493), tot_loss_proj:1.570 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.531 (perp=4.948, rec=0.049, cos=0.492), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.539 (perp=4.948, rec=0.055, cos=0.495), tot_loss_proj:1.570 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.552 (perp=4.948, rec=0.068, cos=0.495), tot_loss_proj:1.575 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.539 (perp=4.948, rec=0.056, cos=0.493), tot_loss_proj:1.569 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=4.948, rec=0.053, cos=0.494), tot_loss_proj:1.560 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.538 (perp=4.948, rec=0.054, cos=0.495), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.541 (perp=4.948, rec=0.057, cos=0.494), tot_loss_proj:1.559 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.540 (perp=4.948, rec=0.054, cos=0.496), tot_loss_proj:1.568 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.531 (perp=4.948, rec=0.046, cos=0.495), tot_loss_proj:1.570 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.533 (perp=4.948, rec=0.049, cos=0.495), tot_loss_proj:1.572 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.608 | p: 87.770 | r: 89.700
rouge2     | fm: 52.768 | p: 52.499 | r: 53.142
rougeL     | fm: 76.679 | p: 75.989 | r: 77.493
rougeLsum  | fm: 76.690 | p: 76.017 | r: 77.568
r1fm+r2fm = 141.376

input #98 time: 0:08:29 | total time: 14:17:39


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.7161016322300564
highest_index [0]
highest [0.7161016322300564]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8017231822013855 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.793131411075592 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7928521633148193 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.7638064622879028 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7554200291633606 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7442561388015747 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7394736409187317 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7344157099723816 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.7339036464691162 for ['[CLS] te services claire thunder bearingˈ tasteaging actually knowledge when himself distance harper temps forced slight cushion right currently still [MASK] synonym ferns dental opposed screenste barbie bet orient rets ratings garcia earliest [SEP]']
[Init] best perm rec loss: 0.732205867767334 for ['[CLS] garciate screens taste slightts ferns thunder orient himself synonym harper cushion ratings teaging barbie earliest dental betˈ re [MASK] still bearing services claire forced opposed right currently when distance knowledge temps actually [SEP]']
[Init] best perm rec loss: 0.7313962578773499 for ['[CLS]ˈ screens te currently earliest still taste re ferns knowledge ratings harper orient [MASK] right barbie cushion services synonym thunder forcedts bet bearingte claire slight distance himself dental when garcia actually opposedaging temps [SEP]']
[Init] best perm rec loss: 0.7310317158699036 for ['[CLS] currently forcedte slight himself right bearing when taste re [MASK] dental harper earliest ferns knowledgets garcia orient services cushion synonymaging opposed te barbie screens distance actually betˈ ratings claire thunder still temps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.378 (perp=12.856, rec=0.349, cos=0.458), tot_loss_proj:3.779 [t=0.22s]
prediction: ["[CLS] joyah committee freessing fun the cigarette junk book'lawyer wroteetched companies prisoners an prisoners repeal reacherssing importantssing chemist syndrome policies ruined not... [ suspicion thenth actually postersenna really [SEP]"]
[ 100/2000] tot_loss=2.929 (perp=10.900, rec=0.311, cos=0.438), tot_loss_proj:3.377 [t=0.22s]
prediction: ["[CLS] blocked themselves funssing fun a elsie scientific film '? wrotessing men stealing'gas toxic ticketssing dissing di they argue ruined not $ war emptyforms but letter protestersoy fun [SEP]"]
[ 150/2000] tot_loss=2.802 (perp=10.617, rec=0.216, cos=0.463), tot_loss_proj:3.335 [t=0.22s]
prediction: ["[CLS] walked committee mindssing fun a phonetic nominee film'` wrotessing company /'` film ticketssing dissing di'argue ruined not the'°c worst. losing had but fun [SEP]"]
[ 200/2000] tot_loss=2.611 (perp=9.869, rec=0.167, cos=0.470), tot_loss_proj:3.229 [t=0.22s]
prediction: ["[CLS] walkedə mindssing fun but corinne very film but ` awful awful, n'`'ticketssing dissing di'muttering that not mind'mind worst'excitement had but fun [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.509 (perp=9.407, rec=0.147, cos=0.481), tot_loss_proj:3.275 [t=0.22s]
prediction: ["[CLS] walked outssing fun but corinne very film but ` awful horrible, n'`'ticket mindssing dissing di'muttering that not mind'mind worst'ticket had still fun [SEP]"]
[ 300/2000] tot_loss=2.603 (perp=10.035, rec=0.124, cos=0.472), tot_loss_proj:3.155 [t=0.22s]
prediction: ["[CLS] walked outssing fun but corinne much film but ` ` horrible, n the ` terrible ticket mindssing dissing di'muttering that t mind'mind worst'ticket had still so [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.551 (perp=9.811, rec=0.113, cos=0.476), tot_loss_proj:3.104 [t=0.22s]
prediction: ["[CLS] walked outssing fun but corinne much film but ` ` horrible'n the ` terrible ticket mindssing dissing di'muttering that t mind, mind worst'ticket had still so [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.588 (perp=10.039, rec=0.105, cos=0.475), tot_loss_proj:3.109 [t=0.22s]
prediction: ["[CLS] walked outssing fun butssing much film but ` ` terrible'n the ` terrible ticket everything horrible thessing di terrible muttering that t mind, mind sure'ticket hadoy so [SEP]"]
[ 450/2000] tot_loss=2.585 (perp=10.039, rec=0.101, cos=0.476), tot_loss_proj:3.102 [t=0.22s]
prediction: ["[CLS] walked outssing fun butssing much film but ` ` terrible'n the ` terrible ticket everything horrible thessing di terrible muttering that t mind, mind sure'ticket hadoy so [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.437 (perp=9.289, rec=0.100, cos=0.479), tot_loss_proj:2.967 [t=0.22s]
prediction: ["[CLS] walked outssing fun but the much film ticket ` ` terrible'n the ` terrible but not horrible muchssing di terrible muttering that t mind, mind sure'ticket had did so [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.424 (perp=9.198, rec=0.101, cos=0.484), tot_loss_proj:2.992 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible'n the'terrible but we horrible muchssing di they muttering that t mind, mind sure'ticket had did so [SEP]"]
[ 600/2000] tot_loss=2.360 (perp=8.984, rec=0.084, cos=0.479), tot_loss_proj:2.969 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible'n the'terrible but not horrible muchssing di they muttering that t mind, mind sure'ticket had did so [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.304 (perp=8.679, rec=0.091, cos=0.477), tot_loss_proj:2.874 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible'n the'terrible but not horrible much they dissing muttering that t mind, mind sure'ticket had did so [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.371 (perp=9.025, rec=0.087, cos=0.479), tot_loss_proj:3.092 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible'n the'terrible but not previous much they dissing muttering that t mind, mind had cost ticket sure did so [SEP]"]
[ 750/2000] tot_loss=2.473 (perp=9.524, rec=0.087, cos=0.481), tot_loss_proj:3.207 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible does n the'horrible but you previous much they dissing muttering that t mind, mind had cost ticket sure did so [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=2.368 (perp=8.992, rec=0.089, cos=0.481), tot_loss_proj:3.059 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible does n the'horrible'we previous much dissing muttering that t mind, mind they had cost ticket sure did so [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.320 (perp=8.771, rec=0.088, cos=0.478), tot_loss_proj:2.911 [t=0.22s]
prediction: ["[CLS] walked terriblessing fun but the much film ticket ` ` terrible does n the'horrible'you so much dissing muttering that t mind, mind they had cost ticket sure did previous [SEP]"]
[ 900/2000] tot_loss=2.296 (perp=8.652, rec=0.084, cos=0.482), tot_loss_proj:2.826 [t=0.22s]
prediction: ["[CLS] walked outssing fun but the much film ticket ` ` terrible does n the'horrible'you so much dissing muttering that t mind, mind they had cost ticket sure did previous [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.237 (perp=8.409, rec=0.073, cos=0.482), tot_loss_proj:2.914 [t=0.22s]
prediction: ["[CLS] walked outssing fun but cost much film ticket ` ` terrible did n the'horrible'you so much dissing muttering that t mind, mind they had the ticket sure did previous [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=2.269 (perp=8.504, rec=0.083, cos=0.485), tot_loss_proj:2.931 [t=0.22s]
prediction: ["[CLS] walked outssing fun but cost much film ticket ` ` terrible did n the particularly'''you so much dissing muttering that t mind, mind they had the ticket did previous [SEP]"]
[1050/2000] tot_loss=2.266 (perp=8.504, rec=0.081, cos=0.484), tot_loss_proj:2.930 [t=0.22s]
prediction: ["[CLS] walked outssing fun but cost much film ticket ` ` terrible did n the particularly'''you so much dissing muttering that t mind, mind they had the ticket did previous [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.172 (perp=8.050, rec=0.081, cos=0.481), tot_loss_proj:2.834 [t=0.22s]
prediction: ["[CLS] walked outssing fun but cost much film ticket ` ` terrible did n the particularly'that'you so much dissing muttering't mind, mind they had the ticket did previous [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.158 (perp=7.990, rec=0.075, cos=0.484), tot_loss_proj:2.797 [t=0.22s]
prediction: ["[CLS] walked out particularly fun but cost much film ticket ` ` terrible did n thessing'that'you so much dissing muttering't mind, mind they had the ticket did previous [SEP]"]
[1200/2000] tot_loss=2.164 (perp=7.990, rec=0.082, cos=0.484), tot_loss_proj:2.802 [t=0.22s]
prediction: ["[CLS] walked out particularly fun but cost much film ticket ` ` terrible did n thessing'that'you so much dissing muttering't mind, mind they had the ticket did previous [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=2.106 (perp=7.734, rec=0.079, cos=0.480), tot_loss_proj:2.723 [t=0.22s]
prediction: ["[CLS] walked out particularly fun but cost much film ticket ` ` terrible did thessing'that'n'so much dissing muttering't mind, mind they had the ticket did previous [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=2.103 (perp=7.683, rec=0.083, cos=0.483), tot_loss_proj:2.699 [t=0.22s]
prediction: ["[CLS] walked out particularly fun but cost much film ticket ` ` terrible did thessing'that'n'so much dissing't mind, mind muttering they had the ticket did previous [SEP]"]
[1350/2000] tot_loss=2.095 (perp=7.683, rec=0.075, cos=0.483), tot_loss_proj:2.704 [t=0.22s]
prediction: ["[CLS] walked out particularly fun but cost much film ticket ` ` terrible did thessing'that'n'so much dissing't mind, mind muttering they had the ticket did previous [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.083 (perp=7.591, rec=0.082, cos=0.482), tot_loss_proj:2.643 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` ` terrible did particularlyssing'that'n'so much dissing't mind, mind muttering they had the ticket did previous [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.079 (perp=7.591, rec=0.075, cos=0.485), tot_loss_proj:2.639 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` ` terrible did particularlyssing'that'n'so much dissing't mind, mind muttering they had the ticket did previous [SEP]"]
[1500/2000] tot_loss=2.080 (perp=7.591, rec=0.079, cos=0.483), tot_loss_proj:2.635 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` ` terrible did particularlyssing'that'n'so much dissing't mind, mind muttering they had the ticket did previous [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.061 (perp=7.499, rec=0.078, cos=0.483), tot_loss_proj:2.635 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` ` terrible did particularlyssing'muttering'n'so much dissing't mind, mind that they had the ticket did previous [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.029 (perp=7.358, rec=0.076, cos=0.481), tot_loss_proj:2.607 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did particularlyssing'muttering'n'so did dissing't mind, mind that they had the ticket much previous [SEP]"]
[1650/2000] tot_loss=2.186 (perp=8.147, rec=0.073, cos=0.484), tot_loss_proj:2.755 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did particularlyssing'muttering'n'so diary dissing horrible t mind, mind that they had the ticket much previous [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.097 (perp=7.687, rec=0.076, cos=0.483), tot_loss_proj:2.675 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did particularlyssing'muttering'n'so diary dissing't mind, mind that they had the ticket much previous [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=2.077 (perp=7.576, rec=0.081, cos=0.481), tot_loss_proj:2.666 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did diary particularlyssing'muttering'n'so dissing't mind, mind that they had the ticket much previous [SEP]"]
[1800/2000] tot_loss=2.076 (perp=7.576, rec=0.078, cos=0.483), tot_loss_proj:2.667 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did diary particularlyssing'muttering'n'so dissing't mind, mind that they had the ticket much previous [SEP]"]
Attempt swap
[1850/2000] tot_loss=2.071 (perp=7.576, rec=0.072, cos=0.484), tot_loss_proj:2.667 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did diary particularlyssing'muttering'n'so dissing't mind, mind that they had the ticket much previous [SEP]"]
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.063 (perp=7.511, rec=0.079, cos=0.483), tot_loss_proj:2.667 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did diary particularlyssing'muttering'n'dissing't mind, mind that they had the ticket much previous so [SEP]"]
[1950/2000] tot_loss=2.044 (perp=7.411, rec=0.078, cos=0.483), tot_loss_proj:2.658 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible did diary particularlyssing'muttering'n'dissing't mind, mind that they had the ticket the previous so [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.041 (perp=7.360, rec=0.084, cos=0.485), tot_loss_proj:2.668 [t=0.22s]
prediction: ["[CLS] walked out the fun but cost much film ticket ` like terrible diary did particularlyssing'muttering'n'dissing't mind, mind that they had the ticket the previous so [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out particularly fun but cost much film ticket ` ` terrible did thessing'that'n'so much dissing't mind, mind muttering they had the ticket did previous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 68.966 | r: 76.923
rouge2     | fm: 18.868 | p: 17.857 | r: 20.000
rougeL     | fm: 43.636 | p: 41.379 | r: 46.154
rougeLsum  | fm: 43.636 | p: 41.379 | r: 46.154
r1fm+r2fm = 91.595

[Aggregate metrics]:
rouge1     | fm: 88.494 | p: 87.653 | r: 89.567
rouge2     | fm: 52.483 | p: 52.207 | r: 52.897
rougeL     | fm: 76.267 | p: 75.553 | r: 77.206
rougeLsum  | fm: 76.420 | p: 75.768 | r: 77.326
r1fm+r2fm = 140.977

input #99 time: 0:08:39 | total time: 14:26:19


Average Cosine Similarity: 0.7249473403342988
Done with all.
