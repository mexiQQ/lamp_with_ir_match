


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.5 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 44.40it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.8816146382685618
highest_index [0]
highest [0.8816146382685618]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9515219926834106 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8165166974067688 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8106261491775513 for ['[CLS] tolerance receiving [SEP]']
[Init] best rec loss: 0.8104701042175293 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.7992174625396729 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.7960134148597717 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.619 (perp=11.087, rec=0.186, cos=0.215), tot_loss_proj:2.785 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 100/2000] tot_loss=2.526 (perp=11.087, rec=0.086, cos=0.222), tot_loss_proj:2.793 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.519 (perp=11.087, rec=0.080, cos=0.221), tot_loss_proj:2.787 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.499 (perp=11.087, rec=0.061, cos=0.221), tot_loss_proj:2.780 [t=0.23s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.348 (perp=10.251, rec=0.080, cos=0.218), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.333 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.341 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.316 (perp=10.251, rec=0.046, cos=0.220), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.334 (perp=10.251, rec=0.062, cos=0.223), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.315 (perp=10.251, rec=0.047, cos=0.219), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.338 (perp=10.251, rec=0.065, cos=0.223), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.333 (perp=10.251, rec=0.064, cos=0.219), tot_loss_proj:2.312 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.343 (perp=10.251, rec=0.070, cos=0.223), tot_loss_proj:2.339 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.324 (perp=10.251, rec=0.051, cos=0.223), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.336 (perp=10.251, rec=0.064, cos=0.222), tot_loss_proj:2.335 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.348 (perp=10.251, rec=0.075, cos=0.223), tot_loss_proj:2.331 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.330 (perp=10.251, rec=0.060, cos=0.220), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.341 (perp=10.251, rec=0.068, cos=0.222), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.318 (perp=10.251, rec=0.045, cos=0.223), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.334 (perp=10.251, rec=0.061, cos=0.223), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.339 (perp=10.251, rec=0.068, cos=0.221), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.339 (perp=10.251, rec=0.067, cos=0.222), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.331 (perp=10.251, rec=0.058, cos=0.223), tot_loss_proj:2.334 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.327 (perp=10.251, rec=0.055, cos=0.222), tot_loss_proj:2.341 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.327 (perp=10.251, rec=0.054, cos=0.222), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.326 (perp=10.251, rec=0.053, cos=0.223), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.334 (perp=10.251, rec=0.062, cos=0.223), tot_loss_proj:2.341 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.319 (perp=10.251, rec=0.046, cos=0.223), tot_loss_proj:2.341 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.354 (perp=10.251, rec=0.082, cos=0.223), tot_loss_proj:2.334 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.333 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.332 (perp=10.251, rec=0.059, cos=0.222), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.336 (perp=10.251, rec=0.063, cos=0.223), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.336 (perp=10.251, rec=0.063, cos=0.223), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.342 (perp=10.251, rec=0.069, cos=0.223), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.333 (perp=10.251, rec=0.062, cos=0.221), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.339 (perp=10.251, rec=0.066, cos=0.222), tot_loss_proj:2.339 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.328 (perp=10.251, rec=0.055, cos=0.222), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.335 (perp=10.251, rec=0.063, cos=0.223), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.326 (perp=10.251, rec=0.053, cos=0.223), tot_loss_proj:2.324 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.342 (perp=10.251, rec=0.069, cos=0.223), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.340 (perp=10.251, rec=0.068, cos=0.223), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:09:12 | total time: 0:09:12


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.8180162734099374
highest_index [0]
highest [0.8180162734099374]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.969803512096405 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9612103700637817 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9568977355957031 for ['[CLS] consist waterloo [SEP]']
[Init] best rec loss: 0.9564882516860962 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.9532542824745178 for ['[CLS] gone honorary [SEP]']
[Init] best rec loss: 0.9522499442100525 for ['[CLS] schedule sensors [SEP]']
[Init] best rec loss: 0.9436572194099426 for ['[CLS] vital conflict [SEP]']
[Init] best rec loss: 0.9348565936088562 for ['[CLS] received mountain [SEP]']
[Init] best rec loss: 0.8794741630554199 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.8456688523292542 for ["[CLS] giant'[SEP]"]
[Init] best perm rec loss: 0.8431999683380127 for ["[CLS]'giant [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.922 (perp=8.864, rec=0.828, cos=0.320), tot_loss_proj:3.718 [t=0.23s]
prediction: ['[CLS] [SEP] other [SEP]']
[ 100/2000] tot_loss=2.681 (perp=8.540, rec=0.648, cos=0.324), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] splendidness [SEP]']
[ 150/2000] tot_loss=3.225 (perp=11.505, rec=0.608, cos=0.316), tot_loss_proj:3.141 [t=0.23s]
prediction: ['[CLS] splendid applies [SEP]']
[ 200/2000] tot_loss=3.242 (perp=11.505, rec=0.599, cos=0.342), tot_loss_proj:3.130 [t=0.23s]
prediction: ['[CLS] splendid applies [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.189 (perp=11.505, rec=0.633, cos=0.255), tot_loss_proj:3.138 [t=0.23s]
prediction: ['[CLS] splendid applies [SEP]']
[ 300/2000] tot_loss=3.266 (perp=12.029, rec=0.556, cos=0.303), tot_loss_proj:3.735 [t=0.23s]
prediction: ['[CLS] splendid pedal [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.910 (perp=10.230, rec=0.555, cos=0.309), tot_loss_proj:2.842 [t=0.23s]
prediction: ['[CLS] splendid favourites [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.911 (perp=10.230, rec=0.551, cos=0.314), tot_loss_proj:2.857 [t=0.23s]
prediction: ['[CLS] splendid favourites [SEP]']
[ 450/2000] tot_loss=2.888 (perp=10.230, rec=0.559, cos=0.283), tot_loss_proj:2.850 [t=0.23s]
prediction: ['[CLS] splendid favourites [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.104 (perp=11.345, rec=0.529, cos=0.306), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.106 (perp=11.345, rec=0.523, cos=0.314), tot_loss_proj:3.262 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[ 600/2000] tot_loss=3.091 (perp=11.345, rec=0.515, cos=0.307), tot_loss_proj:3.269 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.088 (perp=11.345, rec=0.522, cos=0.297), tot_loss_proj:3.263 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.096 (perp=11.345, rec=0.517, cos=0.311), tot_loss_proj:3.264 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[ 750/2000] tot_loss=3.069 (perp=11.345, rec=0.500, cos=0.300), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.090 (perp=11.345, rec=0.517, cos=0.304), tot_loss_proj:3.257 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.071 (perp=11.345, rec=0.506, cos=0.297), tot_loss_proj:3.265 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[ 900/2000] tot_loss=3.073 (perp=11.345, rec=0.500, cos=0.304), tot_loss_proj:3.262 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.099 (perp=11.345, rec=0.495, cos=0.335), tot_loss_proj:3.275 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1000/2000] tot_loss=3.079 (perp=11.345, rec=0.507, cos=0.303), tot_loss_proj:3.260 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1050/2000] tot_loss=3.085 (perp=11.345, rec=0.499, cos=0.317), tot_loss_proj:3.263 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1100/2000] tot_loss=3.095 (perp=11.345, rec=0.497, cos=0.329), tot_loss_proj:3.254 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1150/2000] tot_loss=3.079 (perp=11.345, rec=0.501, cos=0.309), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1200/2000] tot_loss=3.068 (perp=11.345, rec=0.491, cos=0.308), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1250/2000] tot_loss=3.076 (perp=11.345, rec=0.507, cos=0.300), tot_loss_proj:3.266 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1300/2000] tot_loss=3.068 (perp=11.345, rec=0.486, cos=0.313), tot_loss_proj:3.266 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1350/2000] tot_loss=3.070 (perp=11.345, rec=0.485, cos=0.315), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1400/2000] tot_loss=3.067 (perp=11.345, rec=0.493, cos=0.306), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1450/2000] tot_loss=3.070 (perp=11.345, rec=0.489, cos=0.312), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1500/2000] tot_loss=3.071 (perp=11.345, rec=0.484, cos=0.319), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1550/2000] tot_loss=3.072 (perp=11.345, rec=0.488, cos=0.315), tot_loss_proj:3.273 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1600/2000] tot_loss=3.072 (perp=11.345, rec=0.489, cos=0.314), tot_loss_proj:3.269 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1650/2000] tot_loss=3.081 (perp=11.345, rec=0.485, cos=0.327), tot_loss_proj:3.266 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1700/2000] tot_loss=3.077 (perp=11.345, rec=0.479, cos=0.329), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1750/2000] tot_loss=3.068 (perp=11.345, rec=0.477, cos=0.323), tot_loss_proj:3.266 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1800/2000] tot_loss=3.075 (perp=11.345, rec=0.480, cos=0.326), tot_loss_proj:3.269 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1850/2000] tot_loss=3.077 (perp=11.345, rec=0.488, cos=0.320), tot_loss_proj:3.263 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[1900/2000] tot_loss=3.071 (perp=11.345, rec=0.478, cos=0.324), tot_loss_proj:3.262 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
[1950/2000] tot_loss=3.085 (perp=11.345, rec=0.487, cos=0.329), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Attempt swap
[2000/2000] tot_loss=3.070 (perp=11.345, rec=0.484, cos=0.317), tot_loss_proj:3.264 [t=0.23s]
prediction: ['[CLS] splendid self [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendid self [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 78.571 | p: 75.000 | r: 83.333
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 78.571 | p: 75.000 | r: 83.333
rougeLsum  | fm: 78.571 | p: 75.000 | r: 83.333
r1fm+r2fm = 128.571

input #1 time: 0:09:06 | total time: 0:18:19


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.8602985547711477
highest_index [0]
highest [0.8602985547711477]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7206894755363464 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.7200068235397339 for ['[CLS] just percussion universal [SEP]']
[Init] best perm rec loss: 0.7191478610038757 for ['[CLS] percussion universal just [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.204 (perp=8.515, rec=0.242, cos=0.259), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 100/2000] tot_loss=2.044 (perp=8.515, rec=0.082, cos=0.258), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=2.021 (perp=8.515, rec=0.059, cos=0.260), tot_loss_proj:2.035 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=2.029 (perp=8.515, rec=0.067, cos=0.260), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.036 (perp=8.515, rec=0.074, cos=0.259), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=2.031 (perp=8.515, rec=0.069, cos=0.260), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.018 (perp=8.515, rec=0.056, cos=0.259), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=2.021 (perp=8.515, rec=0.059, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=2.022 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.031 (perp=8.515, rec=0.069, cos=0.259), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.031 (perp=8.515, rec=0.069, cos=0.259), tot_loss_proj:2.035 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.021 (perp=8.515, rec=0.059, cos=0.259), tot_loss_proj:2.025 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=2.042 (perp=8.515, rec=0.080, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.019 (perp=8.515, rec=0.056, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.029 (perp=8.515, rec=0.067, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=2.016 (perp=8.515, rec=0.054, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.025 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=2.023 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.026 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.015 (perp=8.515, rec=0.053, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.023 (perp=8.515, rec=0.061, cos=0.259), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.027 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=2.029 (perp=8.515, rec=0.067, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.017 (perp=8.515, rec=0.054, cos=0.259), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.027 (perp=8.515, rec=0.065, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.016 (perp=8.515, rec=0.054, cos=0.259), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.016 (perp=8.515, rec=0.054, cos=0.259), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=2.023 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.026 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.023 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=2.036 (perp=8.515, rec=0.074, cos=0.259), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.031 (perp=8.515, rec=0.068, cos=0.259), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.714 | p: 83.333 | r: 88.889
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 83.333 | r: 88.889
rougeLsum  | fm: 85.714 | p: 83.333 | r: 88.889
r1fm+r2fm = 152.381

input #2 time: 0:08:49 | total time: 0:27:08


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.8246608098056822
highest_index [0]
highest [0.8246608098056822]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9725021719932556 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.8348417282104492 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8278653025627136 for ['[CLS] lancashire isaac [SEP]']
[Init] best rec loss: 0.7945645451545715 for ['[CLS] end depart [SEP]']
[Init] best perm rec loss: 0.7927473187446594 for ['[CLS] depart end [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.681 (perp=10.476, rec=0.265, cos=0.321), tot_loss_proj:2.736 [t=0.23s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 100/2000] tot_loss=2.453 (perp=10.225, rec=0.092, cos=0.315), tot_loss_proj:2.676 [t=0.23s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.432 (perp=10.225, rec=0.070, cos=0.317), tot_loss_proj:2.685 [t=0.23s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.419 (perp=10.225, rec=0.056, cos=0.318), tot_loss_proj:2.685 [t=0.23s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.084 (perp=8.384, rec=0.092, cos=0.315), tot_loss_proj:2.089 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=2.047 (perp=8.384, rec=0.051, cos=0.319), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.061 (perp=8.384, rec=0.064, cos=0.319), tot_loss_proj:2.080 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.046 (perp=8.384, rec=0.050, cos=0.320), tot_loss_proj:2.074 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=2.055 (perp=8.384, rec=0.058, cos=0.320), tot_loss_proj:2.084 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.065 (perp=8.384, rec=0.068, cos=0.320), tot_loss_proj:2.088 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.050 (perp=8.384, rec=0.054, cos=0.320), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=2.062 (perp=8.384, rec=0.065, cos=0.320), tot_loss_proj:2.074 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.063 (perp=8.384, rec=0.066, cos=0.320), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.048 (perp=8.384, rec=0.051, cos=0.320), tot_loss_proj:2.096 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=2.057 (perp=8.384, rec=0.061, cos=0.320), tot_loss_proj:2.081 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.052 (perp=8.384, rec=0.055, cos=0.320), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.057 (perp=8.384, rec=0.060, cos=0.320), tot_loss_proj:2.079 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=2.049 (perp=8.384, rec=0.053, cos=0.320), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.049 (perp=8.384, rec=0.053, cos=0.320), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.049 (perp=8.384, rec=0.052, cos=0.320), tot_loss_proj:2.088 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=2.054 (perp=8.384, rec=0.057, cos=0.320), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.058 (perp=8.384, rec=0.062, cos=0.320), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.063 (perp=8.384, rec=0.066, cos=0.320), tot_loss_proj:2.076 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=2.071 (perp=8.384, rec=0.075, cos=0.320), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.040 (perp=8.384, rec=0.044, cos=0.320), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.050 (perp=8.384, rec=0.053, cos=0.320), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=2.040 (perp=8.384, rec=0.043, cos=0.320), tot_loss_proj:2.087 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.052 (perp=8.384, rec=0.055, cos=0.320), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.049 (perp=8.384, rec=0.053, cos=0.320), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=2.071 (perp=8.384, rec=0.074, cos=0.320), tot_loss_proj:2.070 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.049 (perp=8.384, rec=0.052, cos=0.320), tot_loss_proj:2.083 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.052 (perp=8.384, rec=0.056, cos=0.320), tot_loss_proj:2.083 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=2.061 (perp=8.384, rec=0.064, cos=0.320), tot_loss_proj:2.089 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.067 (perp=8.384, rec=0.070, cos=0.320), tot_loss_proj:2.090 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.049 (perp=8.384, rec=0.053, cos=0.320), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=2.055 (perp=8.384, rec=0.058, cos=0.320), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.058 (perp=8.384, rec=0.062, cos=0.320), tot_loss_proj:2.092 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.063 (perp=8.384, rec=0.067, cos=0.320), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=2.047 (perp=8.384, rec=0.050, cos=0.320), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.047 (perp=8.384, rec=0.051, cos=0.320), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.286 | p: 87.500 | r: 91.667
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 89.286 | p: 87.500 | r: 91.667
rougeLsum  | fm: 89.286 | p: 87.500 | r: 91.667
r1fm+r2fm = 164.286

input #3 time: 0:09:06 | total time: 0:36:15


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.8769018431741973
highest_index [0]
highest [0.8769018431741973]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.9684456586837769 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9360076189041138 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9347110390663147 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9257894158363342 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9204764366149902 for ['[CLS]dge squareaway [SEP]']
[Init] best rec loss: 0.8795543313026428 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8639857769012451 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8586459159851074 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.730 (perp=6.520, rec=0.196, cos=0.229), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] tiresome tires [SEP]']
[ 100/2000] tot_loss=1.826 (perp=7.516, rec=0.095, cos=0.228), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.816 (perp=7.516, rec=0.084, cos=0.229), tot_loss_proj:1.795 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.816 (perp=7.516, rec=0.083, cos=0.229), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.794 (perp=7.516, rec=0.062, cos=0.229), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.800 (perp=7.516, rec=0.066, cos=0.230), tot_loss_proj:1.795 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.801 (perp=7.516, rec=0.069, cos=0.229), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.808 (perp=7.516, rec=0.075, cos=0.230), tot_loss_proj:1.804 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.804 (perp=7.516, rec=0.071, cos=0.230), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.794 (perp=7.516, rec=0.061, cos=0.229), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.798 (perp=7.516, rec=0.065, cos=0.230), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.796 (perp=7.516, rec=0.063, cos=0.229), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.794 (perp=7.516, rec=0.061, cos=0.230), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.796 (perp=7.516, rec=0.063, cos=0.230), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.798 (perp=7.516, rec=0.065, cos=0.230), tot_loss_proj:1.794 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.795 (perp=7.516, rec=0.062, cos=0.230), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.798 (perp=7.516, rec=0.065, cos=0.230), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.794 (perp=7.516, rec=0.061, cos=0.230), tot_loss_proj:1.794 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.804 (perp=7.516, rec=0.071, cos=0.230), tot_loss_proj:1.787 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.798 (perp=7.516, rec=0.065, cos=0.230), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.810 (perp=7.516, rec=0.077, cos=0.230), tot_loss_proj:1.804 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.790 (perp=7.516, rec=0.057, cos=0.230), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.783 (perp=7.516, rec=0.049, cos=0.230), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.792 (perp=7.516, rec=0.059, cos=0.230), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.791 (perp=7.516, rec=0.058, cos=0.230), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.788 (perp=7.516, rec=0.055, cos=0.230), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.803 (perp=7.516, rec=0.070, cos=0.230), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.797 (perp=7.516, rec=0.064, cos=0.230), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.799 (perp=7.516, rec=0.066, cos=0.230), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.795 (perp=7.516, rec=0.062, cos=0.230), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.791 (perp=7.516, rec=0.058, cos=0.230), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.793 (perp=7.516, rec=0.060, cos=0.230), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.798 (perp=7.516, rec=0.065, cos=0.230), tot_loss_proj:1.794 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.787 (perp=7.516, rec=0.054, cos=0.230), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.788 (perp=7.516, rec=0.055, cos=0.230), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.792 (perp=7.516, rec=0.059, cos=0.230), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=7.516, rec=0.061, cos=0.230), tot_loss_proj:1.795 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.796 (perp=7.516, rec=0.062, cos=0.230), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.784 (perp=7.516, rec=0.051, cos=0.230), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.787 (perp=7.516, rec=0.054, cos=0.230), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.429 | p: 90.000 | r: 93.333
rouge2     | fm: 80.000 | p: 80.000 | r: 80.000
rougeL     | fm: 91.429 | p: 90.000 | r: 93.333
rougeLsum  | fm: 91.429 | p: 90.000 | r: 93.333
r1fm+r2fm = 171.429

input #4 time: 0:09:07 | total time: 0:45:23


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.8232135826479889
highest_index [0]
highest [0.8232135826479889]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9778959155082703 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9567394256591797 for ['[CLS] juathic [SEP]']
[Init] best rec loss: 0.9505907297134399 for ['[CLS] those legs [SEP]']
[Init] best rec loss: 0.9439333081245422 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9375807642936707 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.9312766790390015 for ['[CLS] reid supportive [SEP]']
[Init] best rec loss: 0.9156659245491028 for ['[CLS] baby face [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.474 (perp=12.263, rec=0.724, cos=0.298), tot_loss_proj:4.449 [t=0.22s]
prediction: ['[CLS] timingович [SEP]']
[ 100/2000] tot_loss=3.403 (perp=12.423, rec=0.603, cos=0.316), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] emotional certainly [SEP]']
[ 150/2000] tot_loss=2.940 (perp=10.235, rec=0.585, cos=0.309), tot_loss_proj:3.079 [t=0.22s]
prediction: ['[CLS] emotional ease [SEP]']
[ 200/2000] tot_loss=3.197 (perp=11.296, rec=0.623, cos=0.315), tot_loss_proj:4.292 [t=0.22s]
prediction: ['[CLS] ease difficulty [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.102 (perp=11.370, rec=0.541, cos=0.288), tot_loss_proj:3.963 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 300/2000] tot_loss=3.145 (perp=11.370, rec=0.554, cos=0.316), tot_loss_proj:3.963 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.183 (perp=11.296, rec=0.615, cos=0.310), tot_loss_proj:4.297 [t=0.22s]
prediction: ['[CLS] ease difficulty [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.310 (perp=12.417, rec=0.518, cos=0.309), tot_loss_proj:4.402 [t=0.22s]
prediction: ['[CLS] ease slack [SEP]']
[ 450/2000] tot_loss=3.224 (perp=12.127, rec=0.511, cos=0.287), tot_loss_proj:4.149 [t=0.22s]
prediction: ['[CLS] ease ezio [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.305 (perp=12.127, rec=0.591, cos=0.289), tot_loss_proj:4.147 [t=0.22s]
prediction: ['[CLS] ease ezio [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.196 (perp=12.127, rec=0.491, cos=0.279), tot_loss_proj:4.144 [t=0.22s]
prediction: ['[CLS] ease ezio [SEP]']
[ 600/2000] tot_loss=3.216 (perp=12.127, rec=0.482, cos=0.308), tot_loss_proj:4.154 [t=0.22s]
prediction: ['[CLS] ease ezio [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.045 (perp=11.370, rec=0.482, cos=0.289), tot_loss_proj:3.963 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.037 (perp=11.370, rec=0.533, cos=0.231), tot_loss_proj:3.960 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 750/2000] tot_loss=3.027 (perp=11.370, rec=0.471, cos=0.282), tot_loss_proj:3.950 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.010 (perp=11.370, rec=0.476, cos=0.260), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.051 (perp=11.370, rec=0.464, cos=0.313), tot_loss_proj:3.956 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[ 900/2000] tot_loss=3.005 (perp=11.370, rec=0.477, cos=0.254), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.990 (perp=11.370, rec=0.454, cos=0.261), tot_loss_proj:3.962 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.063 (perp=11.370, rec=0.480, cos=0.310), tot_loss_proj:3.962 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1050/2000] tot_loss=3.059 (perp=11.370, rec=0.461, cos=0.324), tot_loss_proj:3.953 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1100/2000] tot_loss=2.995 (perp=11.370, rec=0.443, cos=0.278), tot_loss_proj:3.949 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.022 (perp=11.370, rec=0.446, cos=0.302), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=3.031 (perp=11.370, rec=0.451, cos=0.306), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.026 (perp=11.370, rec=0.452, cos=0.301), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=3.041 (perp=11.370, rec=0.453, cos=0.314), tot_loss_proj:3.963 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1350/2000] tot_loss=3.007 (perp=11.370, rec=0.446, cos=0.287), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1400/2000] tot_loss=3.049 (perp=11.370, rec=0.453, cos=0.323), tot_loss_proj:3.958 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1450/2000] tot_loss=3.014 (perp=11.370, rec=0.448, cos=0.292), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1500/2000] tot_loss=3.040 (perp=11.370, rec=0.446, cos=0.320), tot_loss_proj:3.961 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1550/2000] tot_loss=3.005 (perp=11.370, rec=0.438, cos=0.293), tot_loss_proj:3.957 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1600/2000] tot_loss=3.035 (perp=11.370, rec=0.447, cos=0.314), tot_loss_proj:3.961 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1650/2000] tot_loss=3.016 (perp=11.370, rec=0.440, cos=0.302), tot_loss_proj:3.961 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1700/2000] tot_loss=3.017 (perp=11.370, rec=0.438, cos=0.305), tot_loss_proj:3.955 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1750/2000] tot_loss=3.035 (perp=11.370, rec=0.441, cos=0.320), tot_loss_proj:3.964 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1800/2000] tot_loss=3.038 (perp=11.370, rec=0.456, cos=0.309), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1850/2000] tot_loss=3.019 (perp=11.370, rec=0.441, cos=0.305), tot_loss_proj:3.961 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1900/2000] tot_loss=3.039 (perp=11.370, rec=0.447, cos=0.318), tot_loss_proj:3.960 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
[1950/2000] tot_loss=3.031 (perp=11.370, rec=0.439, cos=0.318), tot_loss_proj:3.954 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[2000/2000] tot_loss=3.036 (perp=11.370, rec=0.449, cos=0.313), tot_loss_proj:3.970 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 88.690 | p: 87.500 | r: 90.278
rouge2     | fm: 72.222 | p: 72.222 | r: 72.222
rougeL     | fm: 88.690 | p: 87.500 | r: 90.278
rougeLsum  | fm: 88.690 | p: 87.500 | r: 90.278
r1fm+r2fm = 160.913

input #5 time: 0:08:49 | total time: 0:54:12


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.8915662885470964
highest_index [0]
highest [0.8915662885470964]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.923570990562439 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9157795310020447 for ['[CLS] main natural [SEP]']
[Init] best rec loss: 0.791347324848175 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.7781184315681458 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7601259350776672 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.7265017032623291 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.6987895965576172 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6908220052719116 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6887596249580383 for ['[CLS] demolition tre [SEP]']
[Init] best rec loss: 0.6539180874824524 for ['[CLS] double deep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.038 (perp=8.089, rec=0.215, cos=0.205), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 100/2000] tot_loss=1.911 (perp=8.089, rec=0.089, cos=0.204), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.884 (perp=8.089, rec=0.063, cos=0.203), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.884 (perp=8.089, rec=0.062, cos=0.205), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.894 (perp=8.089, rec=0.074, cos=0.202), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.882 (perp=8.089, rec=0.060, cos=0.204), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.878 (perp=8.089, rec=0.056, cos=0.205), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.885 (perp=8.089, rec=0.063, cos=0.204), tot_loss_proj:1.885 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.884 (perp=8.089, rec=0.062, cos=0.205), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.867 (perp=8.089, rec=0.044, cos=0.205), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.896 (perp=8.089, rec=0.073, cos=0.205), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.876 (perp=8.089, rec=0.056, cos=0.202), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.868 (perp=8.089, rec=0.046, cos=0.205), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.900 (perp=8.089, rec=0.077, cos=0.205), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.882 (perp=8.089, rec=0.059, cos=0.205), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.870 (perp=8.089, rec=0.047, cos=0.205), tot_loss_proj:1.882 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.884 (perp=8.089, rec=0.061, cos=0.205), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.883 (perp=8.089, rec=0.061, cos=0.204), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.887 (perp=8.089, rec=0.065, cos=0.205), tot_loss_proj:1.905 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.893 (perp=8.089, rec=0.070, cos=0.205), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.867 (perp=8.089, rec=0.045, cos=0.204), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.869 (perp=8.089, rec=0.046, cos=0.205), tot_loss_proj:1.904 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.886 (perp=8.089, rec=0.063, cos=0.205), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.882 (perp=8.089, rec=0.059, cos=0.205), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.883 (perp=8.089, rec=0.061, cos=0.205), tot_loss_proj:1.884 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.874 (perp=8.089, rec=0.051, cos=0.205), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.884 (perp=8.089, rec=0.061, cos=0.205), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.885 (perp=8.089, rec=0.062, cos=0.205), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.887 (perp=8.089, rec=0.064, cos=0.205), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.878 (perp=8.089, rec=0.058, cos=0.203), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.874 (perp=8.089, rec=0.052, cos=0.204), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.882 (perp=8.089, rec=0.059, cos=0.205), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.884 (perp=8.089, rec=0.061, cos=0.205), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.877 (perp=8.089, rec=0.054, cos=0.205), tot_loss_proj:1.905 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.881 (perp=8.089, rec=0.058, cos=0.205), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.887 (perp=8.089, rec=0.064, cos=0.205), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.885 (perp=8.089, rec=0.062, cos=0.205), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.884 (perp=8.089, rec=0.062, cos=0.205), tot_loss_proj:1.886 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.893 (perp=8.089, rec=0.071, cos=0.205), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.893 (perp=8.089, rec=0.070, cos=0.205), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.306 | p: 89.286 | r: 91.667
rouge2     | fm: 76.190 | p: 76.190 | r: 76.190
rougeL     | fm: 90.306 | p: 89.286 | r: 91.667
rougeLsum  | fm: 90.306 | p: 89.286 | r: 91.667
r1fm+r2fm = 166.497

input #6 time: 0:08:48 | total time: 1:03:00


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9032682225613808
highest_index [0]
highest [0.9032682225613808]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.8640726804733276 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8124760985374451 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.804336428642273 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.8042505979537964 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.7907444834709167 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7874070405960083 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best rec loss: 0.7867312431335449 for ['[CLS] loss soup division sloane distress trailision stills jordan rain free⁄ the long o endallmbling live reader bat vaughn joint standing class minute [SEP]']
[Init] best perm rec loss: 0.7861478328704834 for ['[CLS] minuteision end trail reader sloane long vaughn free division soup standing⁄ joint liveall o thembling rain loss jordan class distress bat stills [SEP]']
[Init] best perm rec loss: 0.785529613494873 for ['[CLS]all the minute reader vaughn jordan long joint class batmbling loss division sloane distress rain trailision free live standing end soup o⁄ stills [SEP]']
[Init] best perm rec loss: 0.7831680774688721 for ['[CLS] vaughn loss end o minute reader longmbling classall distress stillsision jordan standing free⁄ rain sloane joint the trail soup division live bat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.734 (perp=11.199, rec=0.346, cos=0.148), tot_loss_proj:3.424 [t=0.22s]
prediction: ['[CLS] topics no any problems or marquis actual male or condoms problem mega problem phone problem fat probablyno?. adible problem recording afford standard [SEP]']
[ 100/2000] tot_loss=2.418 (perp=9.828, rec=0.277, cos=0.175), tot_loss_proj:3.156 [t=0.22s]
prediction: ['[CLS] section no this problem kinds gold class male or chavez problem problem the. problem. no id?ableonoal problem recording drug problem [SEP]']
[ 150/2000] tot_loss=2.436 (perp=10.243, rec=0.215, cos=0.173), tot_loss_proj:3.043 [t=0.22s]
prediction: ['[CLS] not no character character character character. magnus or cute problem probably is. problem. has id characterable.ed stuck grade drug rule [SEP]']
[ 200/2000] tot_loss=2.116 (perp=8.830, rec=0.189, cos=0.161), tot_loss_proj:2.808 [t=0.22s]
prediction: ['[CLS] not no character character character love. not or cute problem he is. problem. has id characterable.al no character drug rule [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.008 (perp=8.310, rec=0.162, cos=0.184), tot_loss_proj:2.703 [t=0.22s]
prediction: ['[CLS] not no factor? character love rulereate or cute problem he is. problem. has fein character.. is no character else. [SEP]']
[ 300/2000] tot_loss=1.958 (perp=8.161, rec=0.149, cos=0.176), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] not no factor? character love rulereate or cute problem he is. problem. has ugly character.. is no cute else. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.652 (perp=10.990, rec=0.281, cos=0.173), tot_loss_proj:3.885 [t=0.22s]
prediction: ['[CLS] figured no addison came [SEP] love hardly boy fancy point problem he is. problem. has - character came “耳™ marine cute although [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.392 (perp=9.951, rec=0.218, cos=0.183), tot_loss_proj:2.942 [t=0.22s]
prediction: ['[CLS] figured no capitals came “ love not love good suit problem he is. problem. has - character came [SEP]耳™ the annoying although [SEP]']
[ 450/2000] tot_loss=2.376 (perp=10.067, rec=0.192, cos=0.170), tot_loss_proj:3.094 [t=0.22s]
prediction: ['[CLS] not no capitals came “ love notpressed good mind problem he is. problem. has - character came [SEP]耳 no the annoying although [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.247 (perp=9.443, rec=0.178, cos=0.180), tot_loss_proj:2.864 [t=0.22s]
prediction: ['[CLS] not no capitals came “ love notpressed good mind problem he is. problem. no - character came [SEP]耳 has the ugly though [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.254 (perp=9.532, rec=0.173, cos=0.174), tot_loss_proj:2.880 [t=0.22s]
prediction: ['[CLS] not nopressed factor comes れ love not good mind problem he is ; problem. no - character came [SEP]耳 has the ugly though [SEP]']
[ 600/2000] tot_loss=2.291 (perp=9.701, rec=0.172, cos=0.179), tot_loss_proj:2.871 [t=0.22s]
prediction: ['[CLS] not noable factor comes れ love not good mind problem he is ; problem. no - character came [SEP]耳 has the ugly though [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.161 (perp=9.133, rec=0.163, cos=0.172), tot_loss_proj:2.917 [t=0.22s]
prediction: ['[CLS] not noable factor comes れ love not fancy mind thought he is ; problem. no - character problem [SEP]耳 has the ugly though [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.122 (perp=8.913, rec=0.159, cos=0.180), tot_loss_proj:3.132 [t=0.22s]
prediction: ['[CLS] not noable factor comes れ love. fancy mind thought he is. problem not no - character problem [SEP]耳 has the ugly though [SEP]']
[ 750/2000] tot_loss=2.126 (perp=9.026, rec=0.147, cos=0.174), tot_loss_proj:3.050 [t=0.22s]
prediction: ['[CLS] not noable factor comes れ love. fancy mind thought he is ; problem not no - character problem [SEP]耳 has the ugly though [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.114 (perp=8.896, rec=0.155, cos=0.180), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] not noable mind comes れ love. fancy factors thought he is ; problem not no - character problem [SEP]耳 has the ugly though [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.063 (perp=8.689, rec=0.143, cos=0.182), tot_loss_proj:3.190 [t=0.22s]
prediction: ['[CLS] not noable mind comes れ love. good factors thought he is ; problem not no problem character - [SEP]耳 has the ugly though [SEP]']
[ 900/2000] tot_loss=2.068 (perp=8.742, rec=0.137, cos=0.183), tot_loss_proj:3.159 [t=0.22s]
prediction: ['[CLS] not noable mind comes れ love. good factors thought he is ; problem not no problem character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.100 (perp=8.859, rec=0.147, cos=0.181), tot_loss_proj:3.435 [t=0.22s]
prediction: ['[CLS] though noable mind comes れ love. good factors thought he is ; problem not no problem character - [SEP]耳 has the ugly not [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.083 (perp=8.842, rec=0.139, cos=0.176), tot_loss_proj:3.261 [t=0.22s]
prediction: ['[CLS] not noable mind comes れ love. nice factors thought he is ; problem not no problem character - [SEP]耳 has the ugly though [SEP]']
[1050/2000] tot_loss=2.017 (perp=8.521, rec=0.132, cos=0.181), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] not noable mind comes れ love. love factors thought he is ; problem not no problem character - [SEP]耳 has the ugly though [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.016 (perp=8.499, rec=0.138, cos=0.178), tot_loss_proj:2.983 [t=0.22s]
prediction: ['[CLS] not noable mind comes れ love. love factors thought he is ; problem not problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.044 (perp=8.633, rec=0.140, cos=0.178), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice factors thought he is ; problem not problem no character - [SEP]耳 has the ugly here [SEP]']
[1200/2000] tot_loss=2.040 (perp=8.633, rec=0.134, cos=0.180), tot_loss_proj:2.855 [t=0.23s]
prediction: ['[CLS] not れable mind comes no love. nice factors thought he is ; problem not problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.998 (perp=8.422, rec=0.133, cos=0.181), tot_loss_proj:2.941 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice thought factors he is ; problem not problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
[1300/2000] tot_loss=2.001 (perp=8.422, rec=0.135, cos=0.181), tot_loss_proj:2.943 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice thought factors he is ; problem not problem no character - [SEP]耳 has the ugly here [SEP]']
[1350/2000] tot_loss=1.997 (perp=8.422, rec=0.131, cos=0.181), tot_loss_proj:2.940 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice thought factors he is ; problem not problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.001 (perp=8.382, rec=0.141, cos=0.184), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice thought factors he is ; problem no problem not character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
[1450/2000] tot_loss=1.990 (perp=8.382, rec=0.131, cos=0.183), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice thought factors he is ; problem no problem not character - [SEP]耳 has the ugly here [SEP]']
[1500/2000] tot_loss=1.990 (perp=8.382, rec=0.131, cos=0.183), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] not れable mind comes no love. nice thought factors he is ; problem no problem not character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
[1550/2000] tot_loss=1.991 (perp=8.375, rec=0.133, cos=0.183), tot_loss_proj:2.788 [t=0.23s]
prediction: ['[CLS] not れable mind comes no love. love thought factors he is ; problem no problem not character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.915 (perp=8.070, rec=0.130, cos=0.171), tot_loss_proj:2.901 [t=0.22s]
prediction: ['[CLS] not れable mind comes not love. love thought factors he is ; problem no problem no character - [SEP]耳 has the ugly here [SEP]']
[1650/2000] tot_loss=1.890 (perp=7.924, rec=0.126, cos=0.179), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] not れable mind comes not love. love thought she he is ; problem no problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.857 (perp=7.727, rec=0.131, cos=0.180), tot_loss_proj:2.838 [t=0.22s]
prediction: ['[CLS] not れable mind comes not love. love she thought he is ; problem no problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
[1750/2000] tot_loss=1.853 (perp=7.727, rec=0.127, cos=0.181), tot_loss_proj:2.842 [t=0.23s]
prediction: ['[CLS] not れable mind comes not love. love she thought he is ; problem no problem no character - [SEP]耳 has the ugly here [SEP]']
[1800/2000] tot_loss=1.860 (perp=7.727, rec=0.134, cos=0.181), tot_loss_proj:2.835 [t=0.22s]
prediction: ['[CLS] not れable mind comes not love. love she thought he is ; problem no problem no character - [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.801 (perp=7.435, rec=0.133, cos=0.181), tot_loss_proj:2.683 [t=0.22s]
prediction: ['[CLS] not れable mind comes not love - love she thought he is ; problem no problem no character. [SEP]耳 has the ugly here [SEP]']
Attempt swap
[1900/2000] tot_loss=1.807 (perp=7.435, rec=0.139, cos=0.181), tot_loss_proj:2.682 [t=0.23s]
prediction: ['[CLS] not れable mind comes not love - love she thought he is ; problem no problem no character. [SEP]耳 has the ugly here [SEP]']
[1950/2000] tot_loss=1.896 (perp=7.971, rec=0.120, cos=0.182), tot_loss_proj:2.729 [t=0.23s]
prediction: ['[CLS] not れable mind component not love - love she thought he is ; problem no problem no character. [SEP]耳 has the ugly here [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.875 (perp=7.799, rec=0.134, cos=0.181), tot_loss_proj:2.671 [t=0.23s]
prediction: ['[CLS] not れable mind - not love component love she thought he is ; problem no problem no character. [SEP]耳 has the ugly here [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] not れable mind comes not love - love she thought he is ; problem no problem no character. [SEP]耳 has the ugly here [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.636 | p: 60.870 | r: 66.667
rouge2     | fm: 4.762 | p: 4.545 | r: 5.000
rougeL     | fm: 31.818 | p: 30.435 | r: 33.333
rougeLsum  | fm: 31.818 | p: 30.435 | r: 33.333
r1fm+r2fm = 68.398

[Aggregate metrics]:
rouge1     | fm: 86.972 | p: 85.734 | r: 88.542
rouge2     | fm: 67.262 | p: 67.235 | r: 67.292
rougeL     | fm: 83.036 | p: 82.609 | r: 85.417
rougeLsum  | fm: 82.995 | p: 81.929 | r: 84.375
r1fm+r2fm = 154.234

input #7 time: 0:08:56 | total time: 1:11:57


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9069466303862985
highest_index [0]
highest [0.9069466303862985]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6736815571784973 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6679466962814331 for ['[CLS] behalf eireann pts ask solutionog rhythm revived sky bonus derek yet affairsstick weird meaning now wellverse beforeα arterial centuries network [SEP]']
[Init] best rec loss: 0.6599639058113098 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6559871435165405 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.6480387449264526 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best perm rec loss: 0.6461073756217957 for ['[CLS] frowned dated won lined judgeencies lindseydant quota treated prize casesmeric colour checkpoint roots perspective conference americas think labor virginia awesome discus [SEP]']
[Init] best perm rec loss: 0.6459020972251892 for ['[CLS] lined americasdant treated colour prize judge discus awesome won perspective checkpoint roots virginia cases conferencemeric quota labor lindsey frowned dated thinkencies [SEP]']
[Init] best perm rec loss: 0.6433313488960266 for ['[CLS] judgemeric roots won lined think treated colourencies frowned cases prize labor lindsey dated virginia quota checkpoint americasdant awesome perspective conference discus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.133 (perp=12.770, rec=0.420, cos=0.159), tot_loss_proj:4.241 [t=0.23s]
prediction: ['[CLS] corpse scotia [SEP] films lacks movie vanity vanity machines nothing estate film litigation vanity material money grossed countryorn snarl eventually x off institute [SEP]']
[ 100/2000] tot_loss=2.894 (perp=12.122, rec=0.313, cos=0.156), tot_loss_proj:3.794 [t=0.23s]
prediction: ['[CLS]partsmont video vanity vanity vanity vanity vanity film silly voices film entirely vanity debt which pays offorn neutral paid when finding institute [SEP]']
[ 150/2000] tot_loss=2.807 (perp=11.901, rec=0.270, cos=0.156), tot_loss_proj:3.851 [t=0.23s]
prediction: ['[CLS] vanity classic video vanity vanity vanity vanity vanity film stupid sox that debt vanity debt which pays off debts 竹 paid what debt revolution [SEP]']
[ 200/2000] tot_loss=2.790 (perp=11.844, rec=0.289, cos=0.133), tot_loss_proj:3.764 [t=0.24s]
prediction: ['[CLS] vanity classic films vanity debt vanity vanity vanity film nothing doubt that no vanity debt debt pays off vampire 15 paid what debt musical [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.671 (perp=11.554, rec=0.200, cos=0.161), tot_loss_proj:3.928 [t=0.23s]
prediction: ['[CLS] vanity a yellowish朝 vanity vanity vanity vanity film ® doubt that no vanity debt debt pays off film fright pay what debt figures [SEP]']
[ 300/2000] tot_loss=2.608 (perp=11.322, rec=0.174, cos=0.169), tot_loss_proj:3.568 [t=0.24s]
prediction: ['[CLS] vanity a felt [SEP] vanity vanity vanity vanity film nothing doubt that no doubt debt debt pays off film fright paid what debt vanity [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.363 (perp=10.204, rec=0.167, cos=0.155), tot_loss_proj:3.350 [t=0.23s]
prediction: ['[CLS] aᅧ the vanity vanity vanity owed film ® doubt that no doubt debt debt pays off film vanity fright owed what debt vanity [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.377 (perp=10.352, rec=0.146, cos=0.161), tot_loss_proj:3.218 [t=0.23s]
prediction: ['[CLS] aᅧ a vanity vanity vanity worldwide film ® doubt that no doubt debt : pays offmax vanity fright owed what debt hoped [SEP]']
[ 450/2000] tot_loss=2.331 (perp=10.162, rec=0.131, cos=0.168), tot_loss_proj:3.174 [t=0.23s]
prediction: ['[CLS] aᅧ a vanity vanity vanityi film ® doubt that no doubt debt, pays offmax vanity fright owed what debt hoped [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.287 (perp=9.933, rec=0.151, cos=0.150), tot_loss_proj:3.047 [t=0.23s]
prediction: ['[CLS] aence a vanitymax vanity vanity film ® doubt that no doubt debt, pays off vanity vanity fright owed what debt desired [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.130 (perp=9.209, rec=0.134, cos=0.154), tot_loss_proj:3.114 [t=0.23s]
prediction: ['[CLS] aless vanity vanitymax vanity vanity film ® doubt that no doubt debt, pays off a vanity fright owed what debt felt [SEP]']
[ 600/2000] tot_loss=2.174 (perp=9.416, rec=0.129, cos=0.163), tot_loss_proj:3.164 [t=0.23s]
prediction: ['[CLS] aless vanity vanitymax vanity vanity film benign doubt that no doubt debt, pays off a vanity fright owed what debt felt [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.179 (perp=9.500, rec=0.114, cos=0.165), tot_loss_proj:3.107 [t=0.23s]
prediction: ['[CLS] aless vanity vanitymax vanity worldwide film vanity doubt that no doubt debt, pays off a benign fright owed what debt felt [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.383 (perp=10.555, rec=0.117, cos=0.154), tot_loss_proj:3.413 [t=0.24s]
prediction: ['[CLS] ai vanity vanitymax vanity film vanity doubt that no doubt vanity debt, pays off, benign fright owed what debt felt [SEP]']
[ 750/2000] tot_loss=2.389 (perp=10.555, rec=0.110, cos=0.168), tot_loss_proj:3.409 [t=0.23s]
prediction: ['[CLS] ai vanity vanitymax vanity film vanity doubt that no doubt vanity debt, pays off, benign fright owed what debt felt [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.423 (perp=10.699, rec=0.116, cos=0.168), tot_loss_proj:3.422 [t=0.23s]
prediction: ['[CLS] ai vanity vanitymax vanity film vanity doubt that no doubt benign debt, pays off,i fright owed what debt felt [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.232 (perp=9.842, rec=0.110, cos=0.154), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] ai vanity vanitymax vanity film doubt that no doubt benign debt, pays off ai vanity fright owed what debt felt [SEP]']
[ 900/2000] tot_loss=2.237 (perp=9.842, rec=0.101, cos=0.167), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] ai vanity vanitymax vanity film doubt that no doubt benign debt, pays off ai vanity fright owed what debt felt [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.205 (perp=9.737, rec=0.107, cos=0.150), tot_loss_proj:3.197 [t=0.23s]
prediction: ['[CLS] ai vanity vanity vanity film doubt thatmax no doubt benign debt, pays off ai vanity fright owed what debt felt [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.161 (perp=9.472, rec=0.104, cos=0.162), tot_loss_proj:3.134 [t=0.24s]
prediction: ['[CLS] ai vanity vanity fright film doubt thatmax no doubt benign debt, pays off ai vanity vanity owed what debt felt [SEP]']
[1050/2000] tot_loss=2.155 (perp=9.472, rec=0.097, cos=0.164), tot_loss_proj:3.136 [t=0.23s]
prediction: ['[CLS] ai vanity vanity fright film doubt thatmax no doubt benign debt, pays off ai vanity vanity owed what debt felt [SEP]']
Attempt swap
[1100/2000] tot_loss=2.165 (perp=9.472, rec=0.104, cos=0.167), tot_loss_proj:3.132 [t=0.24s]
prediction: ['[CLS] ai vanity vanity fright film doubt thatmax no doubt benign debt, pays off ai vanity vanity owed what debt felt [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.134 (perp=9.360, rec=0.099, cos=0.163), tot_loss_proj:3.173 [t=0.23s]
prediction: ['[CLS] a doubti vanity vanity fright film thatmax no doubt benign debt, pays off ai vanity vanity owed what debt felt [SEP]']
[1200/2000] tot_loss=2.015 (perp=8.772, rec=0.092, cos=0.168), tot_loss_proj:2.894 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film thatmax no doubt benign debt, pays off aiful vanity owed what debt felt [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.953 (perp=8.564, rec=0.087, cos=0.153), tot_loss_proj:2.957 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film thatmax no doubt benign debt, pays off ai feltful vanity owed what debt [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.918 (perp=8.372, rec=0.098, cos=0.146), tot_loss_proj:2.876 [t=0.24s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benign debt, pays off aimax feltful vanity owed what debt [SEP]']
[1350/2000] tot_loss=1.921 (perp=8.372, rec=0.093, cos=0.154), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benign debt, pays off aimax feltful vanity owed what debt [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=8.372, rec=0.099, cos=0.158), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benign debt, pays off aimax feltful vanity owed what debt [SEP]']
Attempt swap
[1450/2000] tot_loss=1.928 (perp=8.372, rec=0.093, cos=0.160), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benign debt, pays off aimax feltful vanity owed what debt [SEP]']
[1500/2000] tot_loss=1.930 (perp=8.372, rec=0.095, cos=0.161), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benign debt, pays off aimax feltful vanity owed what debt [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.870 (perp=8.049, rec=0.096, cos=0.164), tot_loss_proj:2.712 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benigni debt, pays off amax feltful vanity owed what debt [SEP]']
Attempt swap
[1600/2000] tot_loss=1.864 (perp=8.049, rec=0.091, cos=0.164), tot_loss_proj:2.719 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benigni debt, pays off amax feltful vanity owed what debt [SEP]']
[1650/2000] tot_loss=1.905 (perp=8.207, rec=0.099, cos=0.164), tot_loss_proj:2.889 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity fright film that no doubt benigni debt, pays off tomax feltful vanity owed what debt [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.849 (perp=8.001, rec=0.088, cos=0.160), tot_loss_proj:2.941 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off tomax felt frightful vanity owed what debt [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.829 (perp=7.859, rec=0.094, cos=0.163), tot_loss_proj:2.815 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off to what felt frightful vanity owedmax debt [SEP]']
[1800/2000] tot_loss=1.828 (perp=7.859, rec=0.094, cos=0.163), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off to what felt frightful vanity owedmax debt [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.808 (perp=7.723, rec=0.097, cos=0.166), tot_loss_proj:2.540 [t=0.24s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off what felt frightful vanity owedmax to debt [SEP]']
Attempt swap
[1900/2000] tot_loss=1.804 (perp=7.723, rec=0.093, cos=0.166), tot_loss_proj:2.544 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off what felt frightful vanity owedmax to debt [SEP]']
[1950/2000] tot_loss=1.804 (perp=7.723, rec=0.093, cos=0.166), tot_loss_proj:2.549 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off what felt frightful vanity owedmax to debt [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.809 (perp=7.723, rec=0.095, cos=0.169), tot_loss_proj:2.540 [t=0.23s]
prediction: ['[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off what felt frightful vanity owedmax to debt [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] a doubtful vanity vanity film that no doubt benigni debt, pays off what felt frightful vanity owedmax to debt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.049 | p: 76.190 | r: 80.000
rouge2     | fm: 35.897 | p: 35.000 | r: 36.842
rougeL     | fm: 63.415 | p: 61.905 | r: 65.000
rougeLsum  | fm: 63.415 | p: 61.905 | r: 65.000
r1fm+r2fm = 113.946

[Aggregate metrics]:
rouge1     | fm: 86.320 | p: 84.806 | r: 87.778
rouge2     | fm: 63.777 | p: 63.653 | r: 63.908
rougeL     | fm: 80.820 | p: 80.308 | r: 82.222
rougeLsum  | fm: 80.856 | p: 80.308 | r: 82.407
r1fm+r2fm = 150.097

input #8 time: 0:09:13 | total time: 1:21:11


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9142605996260793
highest_index [0]
highest [0.9142605996260793]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7713556289672852 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6967096328735352 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6960593461990356 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.6788871884346008 for ['[CLS] military offered fragments gathered leaning sphere rom legs [SEP]']
[Init] best rec loss: 0.6586464047431946 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6514295339584351 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6502890586853027 for ['[CLS] luck outlaw decca deaths arsenal cody edwarddden [SEP]']
[Init] best perm rec loss: 0.6479493379592896 for ['[CLS] outlaw luck decca deaths arsenal edwarddden cody [SEP]']
[Init] best perm rec loss: 0.6470351219177246 for ['[CLS] deathsdden cody decca arsenal edward luck outlaw [SEP]']
[Init] best perm rec loss: 0.6455932259559631 for ['[CLS] outlaw arsenal luck cody decca deathsdden edward [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.566 (perp=15.486, rec=0.304, cos=0.165), tot_loss_proj:4.282 [t=0.23s]
prediction: ['[CLS] battle energy clap track closedtra clap religious [SEP]']
[ 100/2000] tot_loss=3.025 (perp=13.117, rec=0.264, cos=0.138), tot_loss_proj:3.986 [t=0.23s]
prediction: ['[CLS]ed soft clap clap softtra clap metaphysical [SEP]']
[ 150/2000] tot_loss=2.705 (perp=11.893, rec=0.167, cos=0.160), tot_loss_proj:3.775 [t=0.23s]
prediction: ['[CLS] of soft clap clap softtra clap metaphysical [SEP]']
[ 200/2000] tot_loss=2.698 (perp=11.893, rec=0.159, cos=0.160), tot_loss_proj:3.779 [t=0.23s]
prediction: ['[CLS] of soft clap clap softtra clap metaphysical [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.481 (perp=10.856, rec=0.153, cos=0.157), tot_loss_proj:3.232 [t=0.23s]
prediction: ['[CLS] of softhead clap soft claptra metaphysical [SEP]']
[ 300/2000] tot_loss=2.565 (perp=11.474, rec=0.118, cos=0.152), tot_loss_proj:3.394 [t=0.23s]
prediction: ['[CLS] ofheadhead clap soft claptra metaphysical [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.233 (perp=9.866, rec=0.108, cos=0.152), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS] clapheadhead of soft claptra metaphysical [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.183 (perp=9.799, rec=0.112, cos=0.111), tot_loss_proj:3.118 [t=0.23s]
prediction: ['[CLS]headhead clap of soft claptra metaphysical [SEP]']
[ 450/2000] tot_loss=2.207 (perp=9.822, rec=0.088, cos=0.155), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS]headp clap of soft claptra metaphysical [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.061 (perp=9.103, rec=0.083, cos=0.157), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS]head clapp of soft claptra metaphysical [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.856 (perp=8.004, rec=0.098, cos=0.158), tot_loss_proj:2.627 [t=0.23s]
prediction: ['[CLS]head clap of soft claptrap metaphysical [SEP]']
[ 600/2000] tot_loss=1.850 (perp=8.004, rec=0.089, cos=0.160), tot_loss_proj:2.642 [t=0.23s]
prediction: ['[CLS]head clap of soft claptrap metaphysical [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.737 (perp=7.482, rec=0.083, cos=0.158), tot_loss_proj:2.379 [t=0.23s]
prediction: ['[CLS] claphead of soft claptrap metaphysical [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.733 (perp=7.482, rec=0.076, cos=0.161), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] claphead of soft claptrap metaphysical [SEP]']
[ 750/2000] tot_loss=1.740 (perp=7.482, rec=0.082, cos=0.162), tot_loss_proj:2.386 [t=0.23s]
prediction: ['[CLS] claphead of soft claptrap metaphysical [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.735 (perp=7.482, rec=0.076, cos=0.162), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] claphead of soft claptrap metaphysical [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.742 (perp=7.482, rec=0.083, cos=0.163), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] claphead of soft claptrap metaphysical [SEP]']
[ 900/2000] tot_loss=1.732 (perp=7.482, rec=0.073, cos=0.163), tot_loss_proj:2.380 [t=0.23s]
prediction: ['[CLS] claphead of soft claptrap metaphysical [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.944 (perp=8.515, rec=0.078, cos=0.163), tot_loss_proj:2.429 [t=0.23s]
prediction: ['[CLS] clapheaded soft claptrap metaphysical [SEP]']
Attempt swap
[1000/2000] tot_loss=1.932 (perp=8.515, rec=0.066, cos=0.163), tot_loss_proj:2.420 [t=0.30s]
prediction: ['[CLS] clapheaded soft claptrap metaphysical [SEP]']
[1050/2000] tot_loss=1.939 (perp=8.515, rec=0.073, cos=0.164), tot_loss_proj:2.432 [t=0.23s]
prediction: ['[CLS] clapheaded soft claptrap metaphysical [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.835 (perp=8.028, rec=0.071, cos=0.159), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.839 (perp=8.028, rec=0.073, cos=0.160), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
[1200/2000] tot_loss=1.843 (perp=8.028, rec=0.076, cos=0.162), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.833 (perp=8.028, rec=0.065, cos=0.162), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.838 (perp=8.028, rec=0.070, cos=0.162), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
[1350/2000] tot_loss=1.855 (perp=8.028, rec=0.087, cos=0.163), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.847 (perp=8.028, rec=0.079, cos=0.163), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.844 (perp=8.028, rec=0.076, cos=0.163), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
[1500/2000] tot_loss=1.842 (perp=8.028, rec=0.074, cos=0.163), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.845 (perp=8.028, rec=0.077, cos=0.163), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.839 (perp=8.028, rec=0.070, cos=0.163), tot_loss_proj:2.350 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
[1650/2000] tot_loss=1.839 (perp=8.028, rec=0.070, cos=0.163), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.835 (perp=8.028, rec=0.066, cos=0.163), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.834 (perp=8.028, rec=0.065, cos=0.163), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
[1800/2000] tot_loss=1.847 (perp=8.028, rec=0.078, cos=0.163), tot_loss_proj:2.350 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.839 (perp=8.028, rec=0.070, cos=0.163), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.833 (perp=8.028, rec=0.064, cos=0.163), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
[1950/2000] tot_loss=1.833 (perp=8.028, rec=0.064, cos=0.163), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.841 (perp=8.028, rec=0.072, cos=0.163), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] clapheaded metaphysical soft claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] clapheaded metaphysical soft claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 86.667

[Aggregate metrics]:
rouge1     | fm: 83.996 | p: 82.873 | r: 85.500
rouge2     | fm: 59.399 | p: 59.288 | r: 59.518
rougeL     | fm: 79.524 | p: 78.468 | r: 80.667
rougeLsum  | fm: 79.729 | p: 78.690 | r: 80.833
r1fm+r2fm = 143.396

input #9 time: 0:09:06 | total time: 1:30:17


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.8384952649138042
highest_index [0]
highest [0.8384952649138042]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8408904075622559 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8282849788665771 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.7921350598335266 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6847477555274963 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6799366474151611 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6793541312217712 for ['[CLS] places order themes angel blessedoric totally sheep commonblood up sound level [SEP]']
[Init] best perm rec loss: 0.6777877807617188 for ['[CLS] themes order sound up places common totallyoric angel blessedblood level sheep [SEP]']
[Init] best perm rec loss: 0.6770873069763184 for ['[CLS] totally blessed level places themes order up commonoric sound angel sheepblood [SEP]']
[Init] best perm rec loss: 0.6761140823364258 for ['[CLS]oric themes sheep order places common angel blessedblood up totally level sound [SEP]']
[Init] best perm rec loss: 0.6758753061294556 for ['[CLS]oric themes up sheep places sound common order level totally angel blessedblood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.396 (perp=13.463, rec=0.404, cos=0.300), tot_loss_proj:3.989 [t=0.22s]
prediction: ['[CLS] ni meicopic oslo position tack end incorporates excellence quietly told slightlyt [SEP]']
[ 100/2000] tot_loss=3.019 (perp=12.308, rec=0.279, cos=0.279), tot_loss_proj:4.036 [t=0.22s]
prediction: ['[CLS] dealt avoidscopic confronted andulsive reason balance ab balancely premieredulsive [SEP]']
[ 150/2000] tot_loss=2.929 (perp=12.202, rec=0.225, cos=0.264), tot_loss_proj:3.588 [t=0.22s]
prediction: ["[CLS] newton balance'associated relevantulsive time hector ab balancely balancely [SEP]"]
[ 200/2000] tot_loss=2.540 (perp=10.373, rec=0.164, cos=0.302), tot_loss_proj:3.471 [t=0.22s]
prediction: ["[CLS] rhythms balance'incident withulsive rhythmsulsive ab balancely balancely [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.225 (perp=9.027, rec=0.133, cos=0.286), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] rhythms balance real incident withulsive rhythms balance abulsively balancely [SEP]']
[ 300/2000] tot_loss=2.232 (perp=9.125, rec=0.118, cos=0.289), tot_loss_proj:2.888 [t=0.22s]
prediction: ['[CLS] incident balance realulsive with real rhythms balance abulsively balancely [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.124 (perp=8.620, rec=0.113, cos=0.287), tot_loss_proj:2.677 [t=0.22s]
prediction: ['[CLS] incident balance real balance with real rhythms balance abulsivelyulsively [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.102 (perp=8.576, rec=0.100, cos=0.287), tot_loss_proj:2.759 [t=0.22s]
prediction: ['[CLS] incident balance real balance with real balance rhythms abulsivesulsively [SEP]']
[ 450/2000] tot_loss=2.104 (perp=8.576, rec=0.099, cos=0.290), tot_loss_proj:2.759 [t=0.22s]
prediction: ['[CLS] incident balance real balance with real balance rhythms abulsivesulsively [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.113 (perp=8.584, rec=0.113, cos=0.284), tot_loss_proj:2.916 [t=0.22s]
prediction: ['[CLS] incident balance time balance with real balances abulsive rhythmsulsively [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.107 (perp=8.479, rec=0.128, cos=0.284), tot_loss_proj:2.831 [t=0.22s]
prediction: ['[CLS] balance incident time balance with real balances abulsive rhythmsulsively [SEP]']
[ 600/2000] tot_loss=2.083 (perp=8.479, rec=0.096, cos=0.291), tot_loss_proj:2.832 [t=0.22s]
prediction: ['[CLS] balance incident time balance with real balances abulsive rhythmsulsively [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.034 (perp=8.195, rec=0.104, cos=0.291), tot_loss_proj:2.726 [t=0.22s]
prediction: ['[CLS] balance incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.024 (perp=8.195, rec=0.094, cos=0.291), tot_loss_proj:2.726 [t=0.22s]
prediction: ['[CLS] balance incident time balances with real balance abulsive rhythmsulsively [SEP]']
[ 750/2000] tot_loss=2.030 (perp=8.194, rec=0.099, cos=0.292), tot_loss_proj:2.680 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.015 (perp=8.194, rec=0.085, cos=0.291), tot_loss_proj:2.676 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.012 (perp=8.194, rec=0.082, cos=0.291), tot_loss_proj:2.682 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
[ 900/2000] tot_loss=2.028 (perp=8.194, rec=0.098, cos=0.292), tot_loss_proj:2.682 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.019 (perp=8.194, rec=0.089, cos=0.292), tot_loss_proj:2.680 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[1000/2000] tot_loss=2.020 (perp=8.194, rec=0.089, cos=0.292), tot_loss_proj:2.681 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
[1050/2000] tot_loss=2.016 (perp=8.194, rec=0.085, cos=0.292), tot_loss_proj:2.681 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[1100/2000] tot_loss=2.014 (perp=8.194, rec=0.083, cos=0.292), tot_loss_proj:2.680 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[1150/2000] tot_loss=2.027 (perp=8.194, rec=0.096, cos=0.292), tot_loss_proj:2.685 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
[1200/2000] tot_loss=2.006 (perp=8.194, rec=0.076, cos=0.292), tot_loss_proj:2.687 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
[1250/2000] tot_loss=2.016 (perp=8.194, rec=0.085, cos=0.292), tot_loss_proj:2.679 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance abulsive rhythmsulsively [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.226 (perp=9.287, rec=0.083, cos=0.285), tot_loss_proj:2.811 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance ably rhythmsulsiveulsive [SEP]']
[1350/2000] tot_loss=2.231 (perp=9.287, rec=0.083, cos=0.290), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance ably rhythmsulsiveulsive [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.141 (perp=8.825, rec=0.084, cos=0.292), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance ablyulsive prop rhythms [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.917 (perp=7.718, rec=0.085, cos=0.288), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance ably propulsive rhythms [SEP]']
[1500/2000] tot_loss=1.923 (perp=7.718, rec=0.088, cos=0.291), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance ably propulsive rhythms [SEP]']
Attempt swap
[1550/2000] tot_loss=1.920 (perp=7.718, rec=0.084, cos=0.292), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] prop incident time balances with real balance ably propulsive rhythms [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.875 (perp=7.482, rec=0.091, cos=0.287), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
[1650/2000] tot_loss=1.876 (perp=7.482, rec=0.088, cos=0.291), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
Attempt swap
[1700/2000] tot_loss=1.872 (perp=7.482, rec=0.084, cos=0.291), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
Attempt swap
[1750/2000] tot_loss=1.873 (perp=7.482, rec=0.085, cos=0.291), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
[1800/2000] tot_loss=1.872 (perp=7.482, rec=0.085, cos=0.291), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
Attempt swap
[1850/2000] tot_loss=1.866 (perp=7.482, rec=0.078, cos=0.291), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
Attempt swap
[1900/2000] tot_loss=1.869 (perp=7.482, rec=0.082, cos=0.291), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
[1950/2000] tot_loss=1.875 (perp=7.482, rec=0.088, cos=0.291), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.868 (perp=7.428, rec=0.092, cos=0.291), tot_loss_proj:2.288 [t=0.22s]
prediction: ['[CLS] prop balances incident with real time balance ably propulsive rhythms [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] prop incident balances with real time balance ably propulsive rhythms [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 100.909

[Aggregate metrics]:
rouge1     | fm: 84.948 | p: 83.138 | r: 86.818
rouge2     | fm: 54.675 | p: 54.552 | r: 54.915
rougeL     | fm: 77.759 | p: 76.515 | r: 79.091
rougeLsum  | fm: 77.380 | p: 76.082 | r: 78.939
r1fm+r2fm = 139.623

input #10 time: 0:08:44 | total time: 1:39:02


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.8661466098833578
highest_index [0]
highest [0.8661466098833578]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8593660593032837 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8482506275177002 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7811105251312256 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7797141671180725 for ['[CLS] familiar mile drawn tal platformgu mevdture inland [SEP]']
[Init] best perm rec loss: 0.7776311039924622 for ['[CLS]ture me mile inland platformguvd drawn tal familiar [SEP]']
[Init] best perm rec loss: 0.7766623497009277 for ['[CLS] me familiar drawn mile talvd inlandturegu platform [SEP]']
[Init] best perm rec loss: 0.7758474349975586 for ['[CLS]vdture inland tal platform familiargu me drawn mile [SEP]']
[Init] best perm rec loss: 0.773742139339447 for ['[CLS] mile me inlandgu platformture drawn talvd familiar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.134 (perp=12.634, rec=0.369, cos=0.239), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] corn sat because─ meat were ignored volcano that exclusive [SEP]']
[ 100/2000] tot_loss=2.805 (perp=11.436, rec=0.288, cos=0.230), tot_loss_proj:3.830 [t=0.23s]
prediction: ['[CLS] successfully attempted becauselling stubborn was refused gel that refused [SEP]']
[ 150/2000] tot_loss=3.157 (perp=13.485, rec=0.223, cos=0.238), tot_loss_proj:4.046 [t=0.23s]
prediction: ['[CLS] refused attempted because attempted stubborn was refused gel gel refused [SEP]']
[ 200/2000] tot_loss=2.741 (perp=11.490, rec=0.206, cos=0.236), tot_loss_proj:3.365 [t=0.23s]
prediction: ['[CLS] stubborn attempted because attempted stubborn that refused gel to refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.611 (perp=11.056, rec=0.158, cos=0.242), tot_loss_proj:3.292 [t=0.23s]
prediction: ['[CLS] here stubborn stubborn attempted stubborn that refused gel to refused [SEP]']
[ 300/2000] tot_loss=2.607 (perp=11.056, rec=0.150, cos=0.246), tot_loss_proj:3.293 [t=0.23s]
prediction: ['[CLS] here stubborn stubborn attempted stubborn that refused gel to refused [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.498 (perp=10.503, rec=0.147, cos=0.250), tot_loss_proj:2.944 [t=0.23s]
prediction: ['[CLS] here stubborn stubborn attempted stubborn that refused refused to gel [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.374 (perp=9.962, rec=0.139, cos=0.243), tot_loss_proj:3.027 [t=0.23s]
prediction: ['[CLS] here refused stubborn attempted stubborn that stubborn refused to gel [SEP]']
[ 450/2000] tot_loss=2.274 (perp=9.475, rec=0.131, cos=0.248), tot_loss_proj:2.983 [t=0.23s]
prediction: ['[CLS] here refused stubborn attempted attempt that stubborn refused to gel [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.262 (perp=9.475, rec=0.121, cos=0.246), tot_loss_proj:2.981 [t=0.23s]
prediction: ['[CLS] here refused stubborn attempted attempt that stubborn refused to gel [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.254 (perp=9.475, rec=0.114, cos=0.246), tot_loss_proj:2.986 [t=0.23s]
prediction: ['[CLS] here refused stubborn attempted attempt that stubborn refused to gel [SEP]']
[ 600/2000] tot_loss=2.305 (perp=9.721, rec=0.111, cos=0.250), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] here refused stubborn attempted attempt that attempted refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.425 (perp=10.386, rec=0.104, cos=0.244), tot_loss_proj:3.422 [t=0.23s]
prediction: ['[CLS] here refused stubborn attempted attempted that attempted refused to gel [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.396 (perp=10.267, rec=0.100, cos=0.243), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] here stubborn refused attempted attempted that attempted refused to gel [SEP]']
[ 750/2000] tot_loss=2.404 (perp=10.267, rec=0.101, cos=0.249), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] here stubborn refused attempted attempted that attempted refused to gel [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.138 (perp=8.973, rec=0.095, cos=0.249), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] here stubborn refused was attempted attempted that refused to gel [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.903 (perp=7.779, rec=0.099, cos=0.248), tot_loss_proj:2.205 [t=0.23s]
prediction: ['[CLS] here was stubbornly attempted attempted that refused to gel [SEP]']
[ 900/2000] tot_loss=1.892 (perp=7.779, rec=0.088, cos=0.248), tot_loss_proj:2.208 [t=0.23s]
prediction: ['[CLS] here was stubbornly attempted attempted that refused to gel [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.814 (perp=7.433, rec=0.080, cos=0.248), tot_loss_proj:2.173 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.817 (perp=7.433, rec=0.081, cos=0.249), tot_loss_proj:2.166 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
[1050/2000] tot_loss=1.825 (perp=7.433, rec=0.091, cos=0.247), tot_loss_proj:2.160 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.819 (perp=7.433, rec=0.084, cos=0.249), tot_loss_proj:2.167 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.816 (perp=7.433, rec=0.082, cos=0.247), tot_loss_proj:2.169 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
[1200/2000] tot_loss=1.823 (perp=7.433, rec=0.088, cos=0.249), tot_loss_proj:2.159 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.810 (perp=7.433, rec=0.074, cos=0.250), tot_loss_proj:2.161 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=7.433, rec=0.081, cos=0.249), tot_loss_proj:2.165 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
[1350/2000] tot_loss=1.818 (perp=7.433, rec=0.082, cos=0.249), tot_loss_proj:2.172 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.826 (perp=7.433, rec=0.092, cos=0.247), tot_loss_proj:2.159 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.807 (perp=7.433, rec=0.072, cos=0.249), tot_loss_proj:2.164 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
[1500/2000] tot_loss=1.820 (perp=7.433, rec=0.084, cos=0.250), tot_loss_proj:2.171 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.809 (perp=7.433, rec=0.074, cos=0.248), tot_loss_proj:2.167 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly attempted that refused to gel [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.739 (perp=7.066, rec=0.088, cos=0.238), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.741 (perp=7.066, rec=0.081, cos=0.247), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.733 (perp=7.066, rec=0.072, cos=0.248), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.746 (perp=7.066, rec=0.085, cos=0.248), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.740 (perp=7.066, rec=0.079, cos=0.249), tot_loss_proj:2.051 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.741 (perp=7.066, rec=0.079, cos=0.249), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=7.066, rec=0.080, cos=0.249), tot_loss_proj:2.047 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.746 (perp=7.066, rec=0.083, cos=0.249), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.732 (perp=7.066, rec=0.069, cos=0.249), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS] here was attempted attempted that stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted attempted that stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 140.909

[Aggregate metrics]:
rouge1     | fm: 85.256 | p: 83.680 | r: 87.159
rouge2     | fm: 54.638 | p: 54.470 | r: 54.861
rougeL     | fm: 77.863 | p: 76.560 | r: 79.306
rougeLsum  | fm: 77.876 | p: 76.616 | r: 79.444
r1fm+r2fm = 139.894

input #11 time: 0:09:08 | total time: 1:48:10


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9286468447152812
highest_index [0]
highest [0.9286468447152812]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8360828757286072 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8328283429145813 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7844239473342896 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7756980657577515 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7629649043083191 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.7543747425079346 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7290119528770447 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best perm rec loss: 0.7279255390167236 for ['[CLS] gotbank wiseuid friend semi didn richards [MASK] alivethed expression beloved investigation [SEP]']
[Init] best perm rec loss: 0.7266318202018738 for ['[CLS] didnbank gotthed wise semi expressionuid friend investigation beloved [MASK] richards alive [SEP]']
[Init] best perm rec loss: 0.7259836196899414 for ['[CLS] semi beloved wisebank investigationtheduid didn friend [MASK] richards expression alive got [SEP]']
[Init] best perm rec loss: 0.7233153581619263 for ['[CLS] friend alivetheduid investigationbank semi expression wise richards got beloved didn [MASK] [SEP]']
[Init] best perm rec loss: 0.7226487398147583 for ['[CLS] investigation didn semithedbank got friend beloved wise alive expression [MASK] richardsuid [SEP]']
[Init] best perm rec loss: 0.7224600315093994 for ['[CLS] got [MASK] wise alivethedbankuid friend expression investigation didn beloved semi richards [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.985 (perp=12.623, rec=0.355, cos=0.105), tot_loss_proj:3.709 [t=0.23s]
prediction: ['[CLS] politics, top compact cablegger prevented low better after problem phone almost thin [SEP]']
[ 100/2000] tot_loss=2.235 (perp=9.427, rec=0.228, cos=0.122), tot_loss_proj:3.027 [t=0.23s]
prediction: ['[CLS] is on best advantage cable deviation barely barely better on cable cable its barely [SEP]']
[ 150/2000] tot_loss=2.414 (perp=10.664, rec=0.161, cos=0.121), tot_loss_proj:3.114 [t=0.23s]
prediction: ['[CLS] is to seen advantage cable trading advantage barely better on see cable its barely [SEP]']
[ 200/2000] tot_loss=2.376 (perp=10.655, rec=0.125, cos=0.121), tot_loss_proj:3.165 [t=0.23s]
prediction: ['[CLS] will to seen advantage cable crazy advantage barely better on considering cable its barely [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.286 (perp=10.239, rec=0.104, cos=0.134), tot_loss_proj:3.268 [t=0.23s]
prediction: ['[CLS] will to seen advantage eponymous cable advantage its better on considering cable especially barely [SEP]']
[ 300/2000] tot_loss=2.213 (perp=10.057, rec=0.090, cos=0.112), tot_loss_proj:3.173 [t=0.23s]
prediction: ['[CLS] will to seen advantage eponymous cable advantage its better on considering its especially barely [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.085 (perp=9.295, rec=0.094, cos=0.132), tot_loss_proj:2.965 [t=0.23s]
prediction: ['[CLS] will to seen its that cable advantage advantage better on considering its especially barely [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.971 (perp=8.762, rec=0.084, cos=0.135), tot_loss_proj:2.925 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on considering its especially barely [SEP]']
[ 450/2000] tot_loss=1.963 (perp=8.762, rec=0.074, cos=0.136), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on considering its especially barely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.961 (perp=8.762, rec=0.072, cos=0.137), tot_loss_proj:2.935 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on considering its especially barely [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.964 (perp=8.762, rec=0.080, cos=0.132), tot_loss_proj:2.924 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on considering its especially barely [SEP]']
[ 600/2000] tot_loss=1.966 (perp=8.762, rec=0.078, cos=0.135), tot_loss_proj:2.929 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on considering its especially barely [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.926 (perp=8.553, rec=0.081, cos=0.134), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on especially considering its barely [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.918 (perp=8.553, rec=0.078, cos=0.129), tot_loss_proj:2.888 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on especially considering its barely [SEP]']
[ 750/2000] tot_loss=1.912 (perp=8.553, rec=0.067, cos=0.135), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better on especially considering its barely [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.859 (perp=8.249, rec=0.076, cos=0.133), tot_loss_proj:2.842 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.854 (perp=8.249, rec=0.069, cos=0.135), tot_loss_proj:2.844 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[ 900/2000] tot_loss=1.854 (perp=8.249, rec=0.069, cos=0.135), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.865 (perp=8.249, rec=0.082, cos=0.134), tot_loss_proj:2.853 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.862 (perp=8.249, rec=0.077, cos=0.135), tot_loss_proj:2.848 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1050/2000] tot_loss=1.860 (perp=8.249, rec=0.075, cos=0.136), tot_loss_proj:2.849 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.864 (perp=8.249, rec=0.079, cos=0.136), tot_loss_proj:2.845 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.865 (perp=8.249, rec=0.079, cos=0.136), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1200/2000] tot_loss=1.859 (perp=8.249, rec=0.073, cos=0.136), tot_loss_proj:2.848 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.868 (perp=8.249, rec=0.082, cos=0.136), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.852 (perp=8.249, rec=0.065, cos=0.136), tot_loss_proj:2.843 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1350/2000] tot_loss=1.865 (perp=8.249, rec=0.078, cos=0.137), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.858 (perp=8.249, rec=0.072, cos=0.137), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.849 (perp=8.249, rec=0.063, cos=0.136), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1500/2000] tot_loss=1.869 (perp=8.249, rec=0.082, cos=0.137), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.854 (perp=8.249, rec=0.068, cos=0.136), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.851 (perp=8.249, rec=0.065, cos=0.137), tot_loss_proj:2.836 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1650/2000] tot_loss=1.852 (perp=8.249, rec=0.066, cos=0.137), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.863 (perp=8.249, rec=0.077, cos=0.137), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.859 (perp=8.249, rec=0.073, cos=0.137), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1800/2000] tot_loss=1.864 (perp=8.249, rec=0.078, cos=0.137), tot_loss_proj:2.838 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.862 (perp=8.249, rec=0.076, cos=0.137), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.855 (perp=8.249, rec=0.068, cos=0.137), tot_loss_proj:2.836 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
[1950/2000] tot_loss=1.859 (perp=8.249, rec=0.072, cos=0.137), tot_loss_proj:2.833 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.855 (perp=8.249, rec=0.069, cos=0.137), tot_loss_proj:2.834 [t=0.23s]
prediction: ['[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] will to seen that its cable advantage advantage better especially considering its barely on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 20.690 | p: 20.000 | r: 21.429
rougeL     | fm: 58.065 | p: 56.250 | r: 60.000
rougeLsum  | fm: 58.065 | p: 56.250 | r: 60.000
r1fm+r2fm = 111.012

[Aggregate metrics]:
rouge1     | fm: 85.604 | p: 84.066 | r: 87.727
rouge2     | fm: 52.202 | p: 52.045 | r: 52.396
rougeL     | fm: 76.346 | p: 75.010 | r: 77.821
rougeLsum  | fm: 76.082 | p: 74.788 | r: 77.576
r1fm+r2fm = 137.806

input #12 time: 0:09:06 | total time: 1:57:17


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.902294684139076
highest_index [0]
highest [0.902294684139076]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.6914499998092651 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.684582531452179 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6842166781425476 for ['[CLS] armchairitic from arrived operation negative india [SEP]']
[Init] best rec loss: 0.6821365356445312 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
[Init] best perm rec loss: 0.6820709705352783 for ['[CLS] fraternity heads round bahn colonial dressed et [SEP]']
[Init] best perm rec loss: 0.681689441204071 for ['[CLS] et dressed colonial round bahn fraternity heads [SEP]']
[Init] best perm rec loss: 0.6814907193183899 for ['[CLS] et heads bahn round colonial fraternity dressed [SEP]']
[Init] best perm rec loss: 0.68099445104599 for ['[CLS] round colonial bahn dressed fraternity heads et [SEP]']
[Init] best perm rec loss: 0.6804254055023193 for ['[CLS] dressed bahn fraternity colonial round heads et [SEP]']
[Init] best perm rec loss: 0.6796545386314392 for ['[CLS] colonial dressed heads bahn fraternity round et [SEP]']
[Init] best perm rec loss: 0.6795082092285156 for ['[CLS] colonial heads fraternity et bahn round dressed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.634 (perp=10.865, rec=0.294, cos=0.167), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS] remote flame flame into explode flame towards [SEP]']
[ 100/2000] tot_loss=2.724 (perp=11.467, rec=0.214, cos=0.216), tot_loss_proj:3.588 [t=0.23s]
prediction: ['[CLS] at flame flame into explode flame point [SEP]']
[ 150/2000] tot_loss=2.314 (perp=10.190, rec=0.098, cos=0.178), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] at things flame into explode flame point [SEP]']
[ 200/2000] tot_loss=2.313 (perp=10.190, rec=0.093, cos=0.182), tot_loss_proj:3.114 [t=0.23s]
prediction: ['[CLS] at things flame into explode flame point [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.302 (perp=10.220, rec=0.091, cos=0.167), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] at things explode into explode flame point [SEP]']
[ 300/2000] tot_loss=2.303 (perp=10.220, rec=0.078, cos=0.181), tot_loss_proj:2.999 [t=0.23s]
prediction: ['[CLS] at things explode into explode flame point [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.939 (perp=8.361, rec=0.091, cos=0.176), tot_loss_proj:2.719 [t=0.23s]
prediction: ['[CLS] things explode into that at flame point [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.627 (perp=6.766, rec=0.093, cos=0.181), tot_loss_proj:2.247 [t=0.23s]
prediction: ['[CLS] things explode into flame at that point [SEP]']
[ 450/2000] tot_loss=1.615 (perp=6.766, rec=0.080, cos=0.182), tot_loss_proj:2.239 [t=0.23s]
prediction: ['[CLS] things explode into flame at that point [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.988 (perp=8.623, rec=0.080, cos=0.183), tot_loss_proj:2.532 [t=0.23s]
prediction: ['[CLS] things explode into flame at taken point [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.980 (perp=8.623, rec=0.072, cos=0.183), tot_loss_proj:2.528 [t=0.23s]
prediction: ['[CLS] things explode into flame at taken point [SEP]']
[ 600/2000] tot_loss=1.900 (perp=8.141, rec=0.088, cos=0.184), tot_loss_proj:2.514 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.884 (perp=8.141, rec=0.072, cos=0.184), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.889 (perp=8.141, rec=0.076, cos=0.184), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
[ 750/2000] tot_loss=1.891 (perp=8.141, rec=0.079, cos=0.184), tot_loss_proj:2.506 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.892 (perp=8.141, rec=0.080, cos=0.184), tot_loss_proj:2.517 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.895 (perp=8.141, rec=0.083, cos=0.184), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
[ 900/2000] tot_loss=1.889 (perp=8.141, rec=0.077, cos=0.184), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.888 (perp=8.141, rec=0.076, cos=0.184), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1000/2000] tot_loss=1.879 (perp=8.141, rec=0.067, cos=0.184), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
[1050/2000] tot_loss=1.894 (perp=8.141, rec=0.082, cos=0.184), tot_loss_proj:2.517 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1100/2000] tot_loss=1.885 (perp=8.141, rec=0.073, cos=0.183), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1150/2000] tot_loss=1.889 (perp=8.141, rec=0.078, cos=0.183), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
[1200/2000] tot_loss=1.906 (perp=8.141, rec=0.094, cos=0.183), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1250/2000] tot_loss=1.890 (perp=8.141, rec=0.078, cos=0.183), tot_loss_proj:2.514 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1300/2000] tot_loss=1.889 (perp=8.141, rec=0.077, cos=0.183), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
[1350/2000] tot_loss=1.890 (perp=8.141, rec=0.079, cos=0.183), tot_loss_proj:2.514 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1400/2000] tot_loss=1.902 (perp=8.141, rec=0.091, cos=0.183), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1450/2000] tot_loss=1.882 (perp=8.141, rec=0.070, cos=0.183), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
[1500/2000] tot_loss=1.892 (perp=8.141, rec=0.080, cos=0.184), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] things explode into flame at explode point [SEP]']
Attempt swap
[1550/2000] tot_loss=2.326 (perp=10.332, rec=0.075, cos=0.185), tot_loss_proj:2.982 [t=0.23s]
prediction: ['[CLS] things explode into flame at into point [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.009 (perp=8.675, rec=0.094, cos=0.181), tot_loss_proj:2.535 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
[1650/2000] tot_loss=1.995 (perp=8.675, rec=0.077, cos=0.183), tot_loss_proj:2.530 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
Attempt swap
[1700/2000] tot_loss=1.993 (perp=8.675, rec=0.075, cos=0.183), tot_loss_proj:2.537 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
Attempt swap
[1750/2000] tot_loss=1.998 (perp=8.675, rec=0.080, cos=0.184), tot_loss_proj:2.534 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
[1800/2000] tot_loss=1.996 (perp=8.675, rec=0.078, cos=0.184), tot_loss_proj:2.538 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
Attempt swap
[1850/2000] tot_loss=1.999 (perp=8.675, rec=0.080, cos=0.184), tot_loss_proj:2.532 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
Attempt swap
[1900/2000] tot_loss=1.996 (perp=8.675, rec=0.077, cos=0.184), tot_loss_proj:2.530 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
[1950/2000] tot_loss=2.003 (perp=8.675, rec=0.084, cos=0.184), tot_loss_proj:2.534 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
Attempt swap
[2000/2000] tot_loss=1.996 (perp=8.675, rec=0.077, cos=0.184), tot_loss_proj:2.536 [t=0.23s]
prediction: ['[CLS] into things explode into flame at point [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] things explode into flame at explode point [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 113.889

[Aggregate metrics]:
rouge1     | fm: 85.951 | p: 84.370 | r: 87.682
rouge2     | fm: 49.972 | p: 49.784 | r: 50.123
rougeL     | fm: 75.670 | p: 74.585 | r: 77.024
rougeLsum  | fm: 75.338 | p: 74.225 | r: 76.737
r1fm+r2fm = 135.923

input #13 time: 0:09:08 | total time: 2:06:25


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.8215894737375065
highest_index [0]
highest [0.8215894737375065]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9993202686309814 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9827793836593628 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9743103384971619 for ['[CLS] green stepped one battle rear [SEP]']
[Init] best rec loss: 0.9682168960571289 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9560081958770752 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9523093104362488 for ['[CLS]pace chicago is thrust youth [SEP]']
[Init] best rec loss: 0.938084602355957 for ['[CLS] strategy sigh hk automatically county [SEP]']
[Init] best perm rec loss: 0.9378248453140259 for ['[CLS] automatically hk sigh county strategy [SEP]']
[Init] best perm rec loss: 0.9373423457145691 for ['[CLS] automatically strategy hk sigh county [SEP]']
[Init] best perm rec loss: 0.936640739440918 for ['[CLS] strategy hk automatically sigh county [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=11.621, rec=0.237, cos=0.326), tot_loss_proj:3.598 [t=0.22s]
prediction: ['[CLS] psychology nevertheless firmly intriguing significant [SEP]']
[ 100/2000] tot_loss=2.896 (perp=12.130, rec=0.145, cos=0.324), tot_loss_proj:3.135 [t=0.22s]
prediction: ['[CLS] film intriguingenia intriguing film [SEP]']
[ 150/2000] tot_loss=2.990 (perp=12.769, rec=0.112, cos=0.324), tot_loss_proj:3.938 [t=0.22s]
prediction: ['[CLS]eiablyenia intriguing film [SEP]']
[ 200/2000] tot_loss=2.969 (perp=12.769, rec=0.091, cos=0.324), tot_loss_proj:3.938 [t=0.22s]
prediction: ['[CLS]eiablyenia intriguing film [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.454 (perp=10.257, rec=0.078, cos=0.325), tot_loss_proj:3.316 [t=0.22s]
prediction: ['[CLS]eniablyenia intriguing film [SEP]']
[ 300/2000] tot_loss=2.957 (perp=12.768, rec=0.079, cos=0.324), tot_loss_proj:3.678 [t=0.22s]
prediction: ['[CLS] undblyenia intriguing film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.753 (perp=6.728, rec=0.084, cos=0.323), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.719 (perp=6.728, rec=0.049, cos=0.324), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.723 (perp=6.728, rec=0.053, cos=0.324), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.731 (perp=6.728, rec=0.061, cos=0.325), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.721 (perp=6.728, rec=0.051, cos=0.325), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.721 (perp=6.728, rec=0.051, cos=0.325), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.736 (perp=6.728, rec=0.066, cos=0.325), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.725 (perp=6.728, rec=0.055, cos=0.325), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.729 (perp=6.728, rec=0.059, cos=0.325), tot_loss_proj:1.735 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.746 (perp=6.728, rec=0.075, cos=0.325), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.726 (perp=6.728, rec=0.055, cos=0.325), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.728 (perp=6.728, rec=0.058, cos=0.324), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=6.728, rec=0.055, cos=0.325), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.740 (perp=6.728, rec=0.069, cos=0.325), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.742 (perp=6.728, rec=0.071, cos=0.325), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.730 (perp=6.728, rec=0.060, cos=0.325), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.738 (perp=6.728, rec=0.068, cos=0.325), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.723 (perp=6.728, rec=0.053, cos=0.325), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.729 (perp=6.728, rec=0.058, cos=0.325), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.733 (perp=6.728, rec=0.062, cos=0.325), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.740 (perp=6.728, rec=0.070, cos=0.325), tot_loss_proj:1.724 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.728 (perp=6.728, rec=0.058, cos=0.325), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.743 (perp=6.728, rec=0.072, cos=0.325), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.732 (perp=6.728, rec=0.062, cos=0.325), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=6.728, rec=0.068, cos=0.325), tot_loss_proj:1.724 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.730 (perp=6.728, rec=0.060, cos=0.325), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.728 (perp=6.728, rec=0.058, cos=0.325), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.729 (perp=6.728, rec=0.058, cos=0.325), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.721 (perp=6.728, rec=0.051, cos=0.325), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.725 (perp=6.728, rec=0.054, cos=0.325), tot_loss_proj:1.726 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.727 (perp=6.728, rec=0.056, cos=0.325), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.724 (perp=6.728, rec=0.053, cos=0.325), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.730 (perp=6.728, rec=0.059, cos=0.325), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.732 (perp=6.728, rec=0.062, cos=0.325), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.027 | p: 85.533 | r: 88.820
rouge2     | fm: 53.060 | p: 52.939 | r: 53.190
rougeL     | fm: 77.311 | p: 76.196 | r: 78.687
rougeLsum  | fm: 76.818 | p: 75.737 | r: 78.121
r1fm+r2fm = 140.087

input #14 time: 0:08:44 | total time: 2:15:10


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.8058860798784084
highest_index [0]
highest [0.8058860798784084]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8257195949554443 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8197687864303589 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8088202476501465 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.7958802580833435 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.7873535752296448 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best perm rec loss: 0.7869699001312256 for ['[CLS]gly [CLS] safe consumer diner trooper much martha [SEP]']
[Init] best perm rec loss: 0.7853024005889893 for ['[CLS] [CLS] consumer martha diner much safegly trooper [SEP]']
[Init] best perm rec loss: 0.7852156162261963 for ['[CLS] safe trooper much consumergly diner [CLS] martha [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.412 (perp=9.065, rec=0.249, cos=0.350), tot_loss_proj:2.714 [t=0.22s]
prediction: ['[CLS] efficient efficient suitably yet efficient energy technical [SEP]']
[ 100/2000] tot_loss=2.679 (perp=10.683, rec=0.196, cos=0.347), tot_loss_proj:3.259 [t=0.22s]
prediction: ['[CLS] efficient efficient suitablyer efficient efficient chill [SEP]']
[ 150/2000] tot_loss=2.614 (perp=10.481, rec=0.172, cos=0.346), tot_loss_proj:3.203 [t=0.22s]
prediction: ['[CLS]ably efficient suitablyer efficient. chill [SEP]']
[ 200/2000] tot_loss=2.579 (perp=10.536, rec=0.125, cos=0.347), tot_loss_proj:3.124 [t=0.22s]
prediction: ['[CLS]ably efficient suitablyer anonymous, chill [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.234 (perp=8.810, rec=0.125, cos=0.348), tot_loss_proj:2.574 [t=0.22s]
prediction: ['[CLS]ably efficient suitably anonymous, chiller [SEP]']
[ 300/2000] tot_loss=2.213 (perp=8.810, rec=0.102, cos=0.349), tot_loss_proj:2.566 [t=0.22s]
prediction: ['[CLS]ably efficient suitably anonymous, chiller [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.057 (perp=8.054, rec=0.097, cos=0.349), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS]ably efficient, suitably anonymous chiller [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.361 (perp=9.630, rec=0.086, cos=0.350), tot_loss_proj:2.825 [t=0.22s]
prediction: ['[CLS]ably efficient, suit anonymous. chiller [SEP]']
[ 450/2000] tot_loss=2.346 (perp=9.630, rec=0.073, cos=0.347), tot_loss_proj:2.819 [t=0.22s]
prediction: ['[CLS]ably efficient, suit anonymous. chiller [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.963 (perp=7.730, rec=0.068, cos=0.349), tot_loss_proj:2.186 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous. chiller [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.738 (perp=6.615, rec=0.068, cos=0.347), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.744 (perp=6.615, rec=0.071, cos=0.349), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.738 (perp=6.615, rec=0.065, cos=0.350), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.740 (perp=6.615, rec=0.067, cos=0.349), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.728 (perp=6.615, rec=0.055, cos=0.350), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.730 (perp=6.615, rec=0.057, cos=0.350), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.720 (perp=6.615, rec=0.047, cos=0.350), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.736 (perp=6.615, rec=0.063, cos=0.350), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.737 (perp=6.615, rec=0.064, cos=0.350), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.744 (perp=6.615, rec=0.071, cos=0.350), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.727 (perp=6.615, rec=0.054, cos=0.350), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.728 (perp=6.615, rec=0.054, cos=0.350), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.735 (perp=6.615, rec=0.062, cos=0.350), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.732 (perp=6.615, rec=0.059, cos=0.350), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.728 (perp=6.615, rec=0.055, cos=0.350), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.736 (perp=6.615, rec=0.063, cos=0.350), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.732 (perp=6.615, rec=0.058, cos=0.350), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.725 (perp=6.615, rec=0.052, cos=0.350), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.728 (perp=6.615, rec=0.054, cos=0.350), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.731 (perp=6.615, rec=0.057, cos=0.350), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.738 (perp=6.615, rec=0.064, cos=0.350), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.728 (perp=6.615, rec=0.054, cos=0.350), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.734 (perp=6.615, rec=0.060, cos=0.350), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.723 (perp=6.615, rec=0.049, cos=0.350), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.739 (perp=6.615, rec=0.066, cos=0.350), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.733 (perp=6.615, rec=0.059, cos=0.350), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.726 (perp=6.615, rec=0.053, cos=0.350), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.731 (perp=6.615, rec=0.058, cos=0.350), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.732 (perp=6.615, rec=0.059, cos=0.350), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.737 (perp=6.615, rec=0.064, cos=0.350), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.857 | p: 86.518 | r: 89.389
rouge2     | fm: 56.268 | p: 56.117 | r: 56.452
rougeL     | fm: 78.568 | p: 77.460 | r: 79.853
rougeLsum  | fm: 78.284 | p: 77.386 | r: 79.583
r1fm+r2fm = 144.125

input #15 time: 0:08:48 | total time: 2:23:58


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.8737210068759507
highest_index [0]
highest [0.8737210068759507]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8532114028930664 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8333348631858826 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8282541632652283 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 0.7930406928062439 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7813559770584106 for ['[CLS] south jefferson late guy e sophia [SEP]']
[Init] best rec loss: 0.7490854263305664 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7363131642341614 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 0.7233982682228088 for ['[CLS]worthy eat town normal court earth [SEP]']
[Init] best perm rec loss: 0.7225350737571716 for ['[CLS] town court earth normal eatworthy [SEP]']
[Init] best perm rec loss: 0.7224617600440979 for ['[CLS] eat earthworthy normal court town [SEP]']
[Init] best perm rec loss: 0.7204381227493286 for ['[CLS] earthworthy eat court town normal [SEP]']
[Init] best perm rec loss: 0.7197438478469849 for ['[CLS] normal court earth eat townworthy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.342 (perp=8.902, rec=0.328, cos=0.234), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] wall : these more this and [SEP]']
[ 100/2000] tot_loss=2.396 (perp=10.050, rec=0.174, cos=0.212), tot_loss_proj:3.298 [t=0.22s]
prediction: ['[CLS] line all all more this and [SEP]']
[ 150/2000] tot_loss=1.884 (perp=7.705, rec=0.117, cos=0.226), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] of all all more this and [SEP]']
[ 200/2000] tot_loss=1.916 (perp=7.992, rec=0.084, cos=0.234), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] of of all more this and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.509 (perp=6.001, rec=0.080, cos=0.229), tot_loss_proj:1.882 [t=0.22s]
prediction: ['[CLS] more, all of this and [SEP]']
[ 300/2000] tot_loss=1.505 (perp=6.001, rec=0.070, cos=0.235), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] more, all of this and [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.274 (perp=4.891, rec=0.066, cos=0.230), tot_loss_proj:1.496 [t=0.22s]
prediction: ['[CLS] all of this and more, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.241 (perp=4.697, rec=0.069, cos=0.232), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.238 (perp=4.697, rec=0.064, cos=0.235), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.235), tot_loss_proj:1.348 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.227 (perp=4.697, rec=0.052, cos=0.236), tot_loss_proj:1.353 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.355 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.229 (perp=4.697, rec=0.053, cos=0.236), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.248 (perp=4.697, rec=0.072, cos=0.236), tot_loss_proj:1.343 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.236 (perp=4.697, rec=0.060, cos=0.236), tot_loss_proj:1.353 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.240 (perp=4.697, rec=0.064, cos=0.236), tot_loss_proj:1.340 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.234 (perp=4.697, rec=0.058, cos=0.236), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.237 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.354 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.237 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.340 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.247 (perp=4.697, rec=0.071, cos=0.236), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.227 (perp=4.697, rec=0.051, cos=0.236), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.232 (perp=4.697, rec=0.056, cos=0.236), tot_loss_proj:1.349 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.224 (perp=4.697, rec=0.049, cos=0.236), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.233 (perp=4.697, rec=0.057, cos=0.236), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.236 (perp=4.697, rec=0.060, cos=0.236), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.233 (perp=4.697, rec=0.058, cos=0.236), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.232 (perp=4.697, rec=0.056, cos=0.236), tot_loss_proj:1.337 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.244 (perp=4.697, rec=0.068, cos=0.236), tot_loss_proj:1.351 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.233 (perp=4.697, rec=0.057, cos=0.236), tot_loss_proj:1.351 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.243 (perp=4.697, rec=0.067, cos=0.236), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.234 (perp=4.697, rec=0.058, cos=0.236), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.241 (perp=4.697, rec=0.065, cos=0.236), tot_loss_proj:1.341 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.238 (perp=4.697, rec=0.062, cos=0.236), tot_loss_proj:1.340 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.228 (perp=4.697, rec=0.052, cos=0.236), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.237 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.232 (perp=4.697, rec=0.056, cos=0.236), tot_loss_proj:1.350 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.242 (perp=4.697, rec=0.067, cos=0.236), tot_loss_proj:1.341 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.236 (perp=4.697, rec=0.060, cos=0.236), tot_loss_proj:1.337 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.241 (perp=4.697, rec=0.065, cos=0.236), tot_loss_proj:1.341 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.234 (perp=4.697, rec=0.059, cos=0.236), tot_loss_proj:1.348 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.488 | p: 87.308 | r: 90.097
rouge2     | fm: 58.932 | p: 58.792 | r: 59.090
rougeL     | fm: 79.970 | p: 79.011 | r: 81.176
rougeLsum  | fm: 80.126 | p: 79.274 | r: 81.275
r1fm+r2fm = 147.419

input #16 time: 0:08:47 | total time: 2:32:46


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.8969011956507509
highest_index [0]
highest [0.8969011956507509]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8108862042427063 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.7987611889839172 for ['[CLS] angle bond masonacle cabinachejord right is kiel woman [SEP]']
[Init] best rec loss: 0.7867724299430847 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7813276648521423 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7809726595878601 for ['[CLS] parade letting weeds irritated for competition thick sm jerry● forgotten [SEP]']
[Init] best rec loss: 0.7792971134185791 for ['[CLS] outlined feudal fc draughteim anything treety punch subject dresser [SEP]']
[Init] best rec loss: 0.7718438506126404 for ['[CLS] wild filing curls wandabuck day victor which judicial coach peyton [SEP]']
[Init] best perm rec loss: 0.7663986682891846 for ['[CLS] coach day wanda whichbuck curls peyton filing judicial wild victor [SEP]']
[Init] best perm rec loss: 0.7654511332511902 for ['[CLS] victor coach peyton curls judicial wildbuck which filing wanda day [SEP]']
[Init] best perm rec loss: 0.7641296982765198 for ['[CLS] wild curls peyton filing victor judicial daybuck coach which wanda [SEP]']
[Init] best perm rec loss: 0.7631559371948242 for ['[CLS] victorbuck judicial day wild which coach curls wanda peyton filing [SEP]']
[Init] best perm rec loss: 0.7629164457321167 for ['[CLS] filing coach day wildbuck victor judicial curls wanda peyton which [SEP]']
[Init] best perm rec loss: 0.7622019648551941 for ['[CLS] which coach wild victor daybuck peyton curls wanda filing judicial [SEP]']
[Init] best perm rec loss: 0.761642575263977 for ['[CLS] peyton day wild victor curls judicial coach filing wanda whichbuck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.710 (perp=11.139, rec=0.324, cos=0.157), tot_loss_proj:3.582 [t=0.22s]
prediction: ['[CLS] worried travel crazy too gun much about thought minute what pressure [SEP]']
[ 100/2000] tot_loss=2.208 (perp=9.459, rec=0.123, cos=0.193), tot_loss_proj:3.075 [t=0.22s]
prediction: ['[CLS] to what much too going much want think much about happening [SEP]']
[ 150/2000] tot_loss=2.276 (perp=9.971, rec=0.087, cos=0.194), tot_loss_proj:3.174 [t=0.22s]
prediction: ['[CLS] to what much too going much want think what about going [SEP]']
[ 200/2000] tot_loss=2.223 (perp=9.730, rec=0.084, cos=0.194), tot_loss_proj:3.285 [t=0.22s]
prediction: ['[CLS] to what much too on much want think what about going [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.923 (perp=8.260, rec=0.082, cos=0.189), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS] to what much too much on want think what about going [SEP]']
[ 300/2000] tot_loss=1.910 (perp=8.260, rec=0.064, cos=0.193), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS] to what much too much on want think what about going [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.750 (perp=7.489, rec=0.058, cos=0.194), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] to what much too much on want think about what going [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.483 (perp=6.098, rec=0.076, cos=0.188), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] what much too much on want to think about what going [SEP]']
[ 450/2000] tot_loss=1.479 (perp=6.098, rec=0.066, cos=0.194), tot_loss_proj:2.394 [t=0.22s]
prediction: ['[CLS] what much too much on want to think about what going [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.476 (perp=6.098, rec=0.062, cos=0.194), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] what much too much on want to think about what going [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.340 (perp=5.361, rec=0.078, cos=0.190), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
[ 600/2000] tot_loss=1.338 (perp=5.361, rec=0.072, cos=0.194), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.328 (perp=5.361, rec=0.061, cos=0.195), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.345 (perp=5.361, rec=0.078, cos=0.195), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
[ 750/2000] tot_loss=1.335 (perp=5.361, rec=0.068, cos=0.195), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.341 (perp=5.361, rec=0.074, cos=0.195), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.333 (perp=5.361, rec=0.065, cos=0.195), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
[ 900/2000] tot_loss=1.342 (perp=5.361, rec=0.075, cos=0.195), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.327 (perp=5.361, rec=0.060, cos=0.195), tot_loss_proj:2.179 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.509 (perp=6.167, rec=0.081, cos=0.195), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s on [SEP]']
[1050/2000] tot_loss=1.500 (perp=6.167, rec=0.071, cos=0.195), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.496 (perp=6.167, rec=0.067, cos=0.195), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.468 (perp=5.994, rec=0.074, cos=0.195), tot_loss_proj:2.324 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
[1200/2000] tot_loss=1.458 (perp=5.994, rec=0.064, cos=0.195), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1250/2000] tot_loss=1.464 (perp=5.994, rec=0.070, cos=0.195), tot_loss_proj:2.325 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1300/2000] tot_loss=1.455 (perp=5.994, rec=0.061, cos=0.195), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
[1350/2000] tot_loss=1.466 (perp=5.994, rec=0.072, cos=0.195), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1400/2000] tot_loss=1.462 (perp=5.994, rec=0.068, cos=0.195), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1450/2000] tot_loss=1.462 (perp=5.994, rec=0.068, cos=0.195), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
[1500/2000] tot_loss=1.464 (perp=5.994, rec=0.070, cos=0.195), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1550/2000] tot_loss=1.466 (perp=5.994, rec=0.073, cos=0.195), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1600/2000] tot_loss=1.458 (perp=5.994, rec=0.065, cos=0.195), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
[1650/2000] tot_loss=1.469 (perp=5.994, rec=0.075, cos=0.195), tot_loss_proj:2.332 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1700/2000] tot_loss=1.464 (perp=5.994, rec=0.070, cos=0.195), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1750/2000] tot_loss=1.470 (perp=5.994, rec=0.076, cos=0.195), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
[1800/2000] tot_loss=1.457 (perp=5.994, rec=0.063, cos=0.195), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1850/2000] tot_loss=1.466 (perp=5.994, rec=0.072, cos=0.195), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[1900/2000] tot_loss=1.475 (perp=5.994, rec=0.081, cos=0.195), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
[1950/2000] tot_loss=1.470 (perp=5.994, rec=0.076, cos=0.195), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=5.994, rec=0.071, cos=0.195), tot_loss_proj:2.324 [t=0.22s]
prediction: ['[CLS] what much too much want to think about what s going [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] what much too much want to think about what s on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 52.174 | p: 50.000 | r: 54.545
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 140.174

[Aggregate metrics]:
rouge1     | fm: 88.519 | p: 87.150 | r: 90.081
rouge2     | fm: 58.576 | p: 58.241 | r: 58.787
rougeL     | fm: 79.593 | p: 78.628 | r: 80.673
rougeLsum  | fm: 79.534 | p: 78.418 | r: 80.842
r1fm+r2fm = 147.095

input #17 time: 0:08:48 | total time: 2:41:34


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.8155060226168198
highest_index [0]
highest [0.8155060226168198]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9728102684020996 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.911839485168457 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8733765482902527 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.8731750249862671 for ['[CLS]cs finally long throat [SEP]']
[Init] best rec loss: 0.8523562550544739 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.8323799967765808 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best rec loss: 0.8296888470649719 for ['[CLS] picked motto squadron siam [SEP]']
[Init] best perm rec loss: 0.8265477418899536 for ['[CLS] squadron motto picked siam [SEP]']
[Init] best perm rec loss: 0.826303243637085 for ['[CLS] squadron motto siam picked [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.288 (perp=13.318, rec=0.291, cos=0.333), tot_loss_proj:4.016 [t=0.23s]
prediction: ['[CLS] eventuing edwardgor [SEP]']
[ 100/2000] tot_loss=3.211 (perp=13.438, rec=0.189, cos=0.334), tot_loss_proj:4.563 [t=0.23s]
prediction: ['[CLS]atingvi columbiagor [SEP]']
[ 150/2000] tot_loss=3.542 (perp=15.461, rec=0.115, cos=0.335), tot_loss_proj:4.964 [t=0.23s]
prediction: ['[CLS]atingvi caledoniangor [SEP]']
[ 200/2000] tot_loss=3.528 (perp=15.461, rec=0.101, cos=0.335), tot_loss_proj:4.970 [t=0.23s]
prediction: ['[CLS]atingvi caledoniangor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.876 (perp=11.602, rec=0.228, cos=0.328), tot_loss_proj:3.771 [t=0.23s]
prediction: ['[CLS]vi electrongorating [SEP]']
[ 300/2000] tot_loss=3.013 (perp=12.628, rec=0.153, cos=0.335), tot_loss_proj:3.807 [t=0.23s]
prediction: ['[CLS]vipressgorating [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.389 (perp=9.663, rec=0.125, cos=0.332), tot_loss_proj:3.220 [t=0.23s]
prediction: ['[CLS]vigoratingvi [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.634 (perp=10.969, rec=0.108, cos=0.332), tot_loss_proj:3.373 [t=0.23s]
prediction: ['[CLS]vi2gorating [SEP]']
[ 450/2000] tot_loss=2.622 (perp=10.969, rec=0.094, cos=0.334), tot_loss_proj:3.380 [t=0.23s]
prediction: ['[CLS]vi2gorating [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.042 (perp=8.026, rec=0.104, cos=0.333), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS]vigorating2 [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.041 (perp=8.026, rec=0.103, cos=0.334), tot_loss_proj:2.503 [t=0.23s]
prediction: ['[CLS]vigorating2 [SEP]']
[ 600/2000] tot_loss=1.933 (perp=7.520, rec=0.095, cos=0.334), tot_loss_proj:2.222 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.930 (perp=7.520, rec=0.092, cos=0.334), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.942 (perp=7.520, rec=0.104, cos=0.334), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
[ 750/2000] tot_loss=1.929 (perp=7.520, rec=0.090, cos=0.334), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.931 (perp=7.520, rec=0.093, cos=0.334), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.931 (perp=7.520, rec=0.093, cos=0.334), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
[ 900/2000] tot_loss=1.926 (perp=7.520, rec=0.088, cos=0.334), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.928 (perp=7.520, rec=0.089, cos=0.334), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1000/2000] tot_loss=1.933 (perp=7.520, rec=0.094, cos=0.335), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
[1050/2000] tot_loss=1.938 (perp=7.520, rec=0.100, cos=0.335), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1100/2000] tot_loss=1.916 (perp=7.520, rec=0.077, cos=0.335), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1150/2000] tot_loss=1.944 (perp=7.520, rec=0.105, cos=0.335), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
[1200/2000] tot_loss=1.941 (perp=7.520, rec=0.102, cos=0.335), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1250/2000] tot_loss=1.938 (perp=7.520, rec=0.099, cos=0.335), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1300/2000] tot_loss=1.924 (perp=7.520, rec=0.085, cos=0.335), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
[1350/2000] tot_loss=1.929 (perp=7.520, rec=0.091, cos=0.335), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1400/2000] tot_loss=1.930 (perp=7.520, rec=0.091, cos=0.335), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS]vigorating / [SEP]']
Attempt swap
[1450/2000] tot_loss=1.883 (perp=7.298, rec=0.088, cos=0.335), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS]vigorating in [SEP]']
[1500/2000] tot_loss=1.882 (perp=7.298, rec=0.087, cos=0.335), tot_loss_proj:2.032 [t=0.23s]
prediction: ['[CLS]vigorating in [SEP]']
Attempt swap
Put prefix at the end
[1550/2000] tot_loss=1.543 (perp=5.589, rec=0.093, cos=0.333), tot_loss_proj:1.516 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.545 (perp=5.589, rec=0.094, cos=0.334), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.533 (perp=5.589, rec=0.081, cos=0.334), tot_loss_proj:1.521 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.543 (perp=5.589, rec=0.091, cos=0.335), tot_loss_proj:1.525 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.543 (perp=5.589, rec=0.091, cos=0.335), tot_loss_proj:1.528 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.544 (perp=5.589, rec=0.092, cos=0.335), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.538 (perp=5.589, rec=0.085, cos=0.335), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.544 (perp=5.589, rec=0.092, cos=0.335), tot_loss_proj:1.519 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.543 (perp=5.589, rec=0.091, cos=0.335), tot_loss_proj:1.516 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.552 (perp=5.589, rec=0.100, cos=0.335), tot_loss_proj:1.505 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.101 | p: 87.820 | r: 90.720
rouge2     | fm: 60.527 | p: 60.311 | r: 60.771
rougeL     | fm: 80.502 | p: 79.571 | r: 81.587
rougeLsum  | fm: 80.734 | p: 79.803 | r: 82.030
r1fm+r2fm = 149.628

input #18 time: 0:09:06 | total time: 2:50:40


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9114311637643511
highest_index [0]
highest [0.9114311637643511]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7326551079750061 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7297828793525696 for ['[CLS] progressivetto momentd [SEP]']
[Init] best rec loss: 0.7173165082931519 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7095429301261902 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6746214032173157 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best perm rec loss: 0.6743916273117065 for ['[CLS]zuki interstate selected symmetry [SEP]']
[Init] best perm rec loss: 0.6740121245384216 for ['[CLS] symmetryzuki interstate selected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.485 (perp=14.716, rec=0.377, cos=0.165), tot_loss_proj:4.335 [t=0.23s]
prediction: ['[CLS] conditioningfafaball [SEP]']
[ 100/2000] tot_loss=3.399 (perp=15.211, rec=0.191, cos=0.166), tot_loss_proj:4.488 [t=0.23s]
prediction: ['[CLS]myfafa to [SEP]']
[ 150/2000] tot_loss=3.342 (perp=15.211, rec=0.137, cos=0.163), tot_loss_proj:4.497 [t=0.23s]
prediction: ['[CLS]myfafa to [SEP]']
[ 200/2000] tot_loss=3.312 (perp=15.211, rec=0.112, cos=0.158), tot_loss_proj:4.489 [t=0.23s]
prediction: ['[CLS]myfafa to [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.451 (perp=6.109, rec=0.078, cos=0.151), tot_loss_proj:1.465 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.446 (perp=6.109, rec=0.061, cos=0.163), tot_loss_proj:1.452 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.454 (perp=6.109, rec=0.065, cos=0.166), tot_loss_proj:1.474 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.451 (perp=6.109, rec=0.062, cos=0.167), tot_loss_proj:1.461 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.464 (perp=6.109, rec=0.075, cos=0.167), tot_loss_proj:1.470 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.452 (perp=6.109, rec=0.062, cos=0.168), tot_loss_proj:1.453 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.452 (perp=6.109, rec=0.062, cos=0.168), tot_loss_proj:1.455 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.448 (perp=6.109, rec=0.058, cos=0.168), tot_loss_proj:1.469 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.451 (perp=6.109, rec=0.061, cos=0.168), tot_loss_proj:1.463 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.458 (perp=6.109, rec=0.068, cos=0.168), tot_loss_proj:1.450 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.457 (perp=6.109, rec=0.067, cos=0.168), tot_loss_proj:1.473 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.435 (perp=6.109, rec=0.045, cos=0.168), tot_loss_proj:1.452 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.109, rec=0.063, cos=0.168), tot_loss_proj:1.470 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.451 (perp=6.109, rec=0.061, cos=0.168), tot_loss_proj:1.446 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.446 (perp=6.109, rec=0.056, cos=0.168), tot_loss_proj:1.462 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.454 (perp=6.109, rec=0.064, cos=0.168), tot_loss_proj:1.455 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.440 (perp=6.109, rec=0.050, cos=0.168), tot_loss_proj:1.474 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.438 (perp=6.109, rec=0.048, cos=0.169), tot_loss_proj:1.465 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.445 (perp=6.109, rec=0.055, cos=0.169), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.440 (perp=6.109, rec=0.050, cos=0.168), tot_loss_proj:1.463 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.449 (perp=6.109, rec=0.058, cos=0.169), tot_loss_proj:1.448 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.450 (perp=6.109, rec=0.059, cos=0.169), tot_loss_proj:1.457 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.453 (perp=6.109, rec=0.062, cos=0.169), tot_loss_proj:1.465 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.461 (perp=6.109, rec=0.071, cos=0.169), tot_loss_proj:1.445 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.467 (perp=6.109, rec=0.077, cos=0.169), tot_loss_proj:1.448 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.109, rec=0.055, cos=0.169), tot_loss_proj:1.461 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.109, rec=0.056, cos=0.169), tot_loss_proj:1.465 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.442 (perp=6.109, rec=0.051, cos=0.169), tot_loss_proj:1.456 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.465 (perp=6.109, rec=0.074, cos=0.169), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.457 (perp=6.109, rec=0.067, cos=0.169), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.449 (perp=6.109, rec=0.058, cos=0.169), tot_loss_proj:1.452 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.456 (perp=6.109, rec=0.065, cos=0.169), tot_loss_proj:1.457 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.450 (perp=6.109, rec=0.059, cos=0.169), tot_loss_proj:1.460 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.454 (perp=6.109, rec=0.064, cos=0.169), tot_loss_proj:1.455 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.448 (perp=6.109, rec=0.057, cos=0.169), tot_loss_proj:1.462 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.456 (perp=6.109, rec=0.065, cos=0.169), tot_loss_proj:1.449 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.676 | p: 88.499 | r: 91.148
rouge2     | fm: 62.969 | p: 62.670 | r: 63.221
rougeL     | fm: 81.530 | p: 80.605 | r: 82.667
rougeLsum  | fm: 81.681 | p: 80.816 | r: 82.803
r1fm+r2fm = 152.645

input #19 time: 0:09:05 | total time: 2:59:46


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.8489576788714619
highest_index [0]
highest [0.8489576788714619]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8636435270309448 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7933486104011536 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.7922466397285461 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.7827841639518738 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best rec loss: 0.7807437181472778 for ['[CLS] club provious microphone [SEP]']
[Init] best perm rec loss: 0.7746955752372742 for ['[CLS] pro club microphonevious [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.465 (perp=9.301, rec=0.339, cos=0.266), tot_loss_proj:2.811 [t=0.23s]
prediction: ['[CLS] pleasureverse pleasureverse [SEP]']
[ 100/2000] tot_loss=2.345 (perp=9.738, rec=0.151, cos=0.247), tot_loss_proj:2.784 [t=0.23s]
prediction: ['[CLS] pleasure per pleasureverse [SEP]']
[ 150/2000] tot_loss=2.324 (perp=9.738, rec=0.099, cos=0.277), tot_loss_proj:2.796 [t=0.23s]
prediction: ['[CLS] pleasure per pleasureverse [SEP]']
[ 200/2000] tot_loss=2.333 (perp=9.738, rec=0.109, cos=0.277), tot_loss_proj:2.799 [t=0.23s]
prediction: ['[CLS] pleasure per pleasureverse [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.019 (perp=8.182, rec=0.130, cos=0.253), tot_loss_proj:2.291 [t=0.23s]
prediction: ['[CLS] pleasure perverse pleasure [SEP]']
[ 300/2000] tot_loss=2.006 (perp=8.182, rec=0.094, cos=0.275), tot_loss_proj:2.290 [t=0.23s]
prediction: ['[CLS] pleasure perverse pleasure [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.796 (perp=7.154, rec=0.094, cos=0.272), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] perverse pleasure pleasure [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.955 (perp=8.072, rec=0.076, cos=0.264), tot_loss_proj:2.737 [t=0.23s]
prediction: ['[CLS] perverse per pleasure [SEP]']
[ 450/2000] tot_loss=1.968 (perp=8.072, rec=0.076, cos=0.278), tot_loss_proj:2.712 [t=0.23s]
prediction: ['[CLS] perverse per pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.955 (perp=8.072, rec=0.064, cos=0.277), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] perverse per pleasure [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.870 (perp=7.610, rec=0.077, cos=0.271), tot_loss_proj:1.889 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.861 (perp=7.610, rec=0.063, cos=0.276), tot_loss_proj:1.887 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.852 (perp=7.610, rec=0.053, cos=0.277), tot_loss_proj:1.887 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.852 (perp=7.610, rec=0.053, cos=0.278), tot_loss_proj:1.891 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.871 (perp=7.610, rec=0.071, cos=0.278), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.868 (perp=7.610, rec=0.067, cos=0.278), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.862 (perp=7.610, rec=0.061, cos=0.279), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.866 (perp=7.610, rec=0.065, cos=0.279), tot_loss_proj:1.877 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.869 (perp=7.610, rec=0.068, cos=0.279), tot_loss_proj:1.883 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.864 (perp=7.610, rec=0.063, cos=0.279), tot_loss_proj:1.878 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.862 (perp=7.610, rec=0.068, cos=0.271), tot_loss_proj:1.891 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.860 (perp=7.610, rec=0.060, cos=0.278), tot_loss_proj:1.877 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.851 (perp=7.610, rec=0.050, cos=0.278), tot_loss_proj:1.890 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.865 (perp=7.610, rec=0.064, cos=0.279), tot_loss_proj:1.879 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.862 (perp=7.610, rec=0.061, cos=0.279), tot_loss_proj:1.899 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.849 (perp=7.610, rec=0.048, cos=0.279), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.866 (perp=7.610, rec=0.065, cos=0.279), tot_loss_proj:1.892 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.851 (perp=7.610, rec=0.050, cos=0.279), tot_loss_proj:1.885 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.857 (perp=7.610, rec=0.056, cos=0.279), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.855 (perp=7.610, rec=0.054, cos=0.279), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.863 (perp=7.610, rec=0.062, cos=0.279), tot_loss_proj:1.881 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.854 (perp=7.610, rec=0.053, cos=0.279), tot_loss_proj:1.886 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.858 (perp=7.610, rec=0.057, cos=0.279), tot_loss_proj:1.883 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.867 (perp=7.610, rec=0.066, cos=0.279), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.849 (perp=7.610, rec=0.048, cos=0.279), tot_loss_proj:1.879 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.863 (perp=7.610, rec=0.062, cos=0.279), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.859 (perp=7.610, rec=0.058, cos=0.279), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.867 (perp=7.610, rec=0.067, cos=0.278), tot_loss_proj:1.887 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.873 (perp=7.610, rec=0.073, cos=0.278), tot_loss_proj:1.875 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.854 (perp=7.610, rec=0.053, cos=0.279), tot_loss_proj:1.890 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.211 | p: 89.041 | r: 91.603
rouge2     | fm: 64.452 | p: 64.253 | r: 64.722
rougeL     | fm: 82.595 | p: 81.710 | r: 83.741
rougeLsum  | fm: 82.561 | p: 81.716 | r: 83.810
r1fm+r2fm = 154.663

input #20 time: 0:09:07 | total time: 3:08:53


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.8900857623084235
highest_index [0]
highest [0.8900857623084235]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8413645625114441 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8123053312301636 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.7947864532470703 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.7916337251663208 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7762290835380554 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7692819833755493 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7625495195388794 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.7596845626831055 for ['[CLS] connecticut fauna [UNK] especially dee bent, item there side golden labor stony situations loan baby general according size rights sheback pose viitaking [SEP]']
[Init] best perm rec loss: 0.7594416737556458 for ['[CLS] [UNK]taking there stony rights bent, according fauna size general dee loan connecticut baby side especiallyback vii situations labor golden item pose she [SEP]']
[Init] best perm rec loss: 0.759373664855957 for ['[CLS]taking bent according item especially rights general baby sideback, dee loan pose there golden connecticut vii she fauna size labor stony [UNK] situations [SEP]']
[Init] best perm rec loss: 0.75888991355896 for ['[CLS] connecticut theretaking rights side bent [UNK] general labor loan baby especially, golden viiback size pose item she dee fauna stony situations according [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.941 (perp=11.707, rec=0.432, cos=0.168), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] multiple forced african organ on behave party considered subsequent bankruptcy teenage grounds with wearing security entire bizarre criticized why why any stall on changes located [SEP]']
[ 100/2000] tot_loss=2.726 (perp=11.154, rec=0.344, cos=0.151), tot_loss_proj:3.370 [t=0.23s]
prediction: ['[CLS] the way african organ non working out ruled serious resident teenage grounds instead fender security instead nazi worse complex how more instead on athletes involved [SEP]']
[ 150/2000] tot_loss=2.705 (perp=10.908, rec=0.337, cos=0.187), tot_loss_proj:3.487 [t=0.24s]
prediction: ['[CLS] sheer way african way - worked out instead serious aged teenage years become seemed some subsequently imagetypical paying, it instead the athletes athletes [SEP]']
[ 200/2000] tot_loss=2.725 (perp=11.607, rec=0.218, cos=0.186), tot_loss_proj:3.611 [t=0.23s]
prediction: ['[CLS] the way women way this works out instead serious social seventies serious become looked security subsequentlytypicaltypicalhort instead more instead the athletes athletes [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.575 (perp=11.007, rec=0.192, cos=0.181), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] the way african governmental this works out instead serious social seizure of became lookedtypical encounters makes eachtypicaltypical parents instead of athletes athletes [SEP]']
[ 300/2000] tot_loss=2.526 (perp=10.848, rec=0.167, cos=0.190), tot_loss_proj:3.161 [t=0.24s]
prediction: ['[CLS] the way teacherscuting all works out instead serious social shoulders of became looktypical psychotic makes eachtypicaltypical teachers instead of athletes athletes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.376 (perp=10.220, rec=0.135, cos=0.196), tot_loss_proj:3.031 [t=0.23s]
prediction: ['[CLS] the way teachersverance all works out instead serious caretaker teenage of more looktypical athletes makes moretypicaltypical teachers instead of athletes psychotic [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.301 (perp=9.867, rec=0.133, cos=0.195), tot_loss_proj:3.008 [t=0.23s]
prediction: ['[CLS] the way teachers makes all works out instead serious caretaker those women more looktypical athletescuting moretypicaltypical teachers instead of athletes apparently [SEP]']
[ 450/2000] tot_loss=2.282 (perp=9.812, rec=0.118, cos=0.201), tot_loss_proj:3.129 [t=0.24s]
prediction: ['[CLS] the way teachers makes all works out instead serious caretaker those women the looktypical athletes genetic moretypicaltypical teachers instead of athletes psychotic [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.207 (perp=9.454, rec=0.115, cos=0.201), tot_loss_proj:2.979 [t=0.23s]
prediction: ['[CLS] the way caretaker makes all works out instead genetic caretaker those women the looktypical athletes serious liketypicaltypical teachers instead of athletes psychotic [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.138 (perp=9.119, rec=0.115, cos=0.200), tot_loss_proj:2.759 [t=0.24s]
prediction: ['[CLS] the way caretaker instead all works out makes genetic caretaker those women the looktypical athletes serious liketypicaltypical teachers instead of athletes psychotic [SEP]']
[ 600/2000] tot_loss=2.166 (perp=9.261, rec=0.111, cos=0.203), tot_loss_proj:2.781 [t=0.23s]
prediction: ['[CLS] the way caretaker instead all works out makes genetic caretaker those women the looktypical athletes serious likettypical teachers instead of athletes psychotic [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.114 (perp=9.004, rec=0.107, cos=0.206), tot_loss_proj:2.687 [t=0.24s]
prediction: ['[CLS] the way caretaker instead all works out makes genetic caretaker those women the looktypicalt serious like athletestypical teachers instead of athletes psychotic [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.082 (perp=8.904, rec=0.101, cos=0.200), tot_loss_proj:2.663 [t=0.23s]
prediction: ['[CLS] the way caretaker instead all works out makes genetic caretaker those women the looktypicalt serioustypical like athletes teachers instead of athletes psychotic [SEP]']
[ 750/2000] tot_loss=2.088 (perp=8.904, rec=0.104, cos=0.204), tot_loss_proj:2.655 [t=0.23s]
prediction: ['[CLS] the way caretaker instead all works out makes genetic caretaker those women the looktypicalt serioustypical like athletes teachers instead of athletes psychotic [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.055 (perp=8.743, rec=0.103, cos=0.204), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] the way caretaker of all works out makes genetic caretaker those women the looktypicalt serioustypical like - teachers instead of athletes of [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.919 (perp=8.102, rec=0.098, cos=0.201), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] the way teachers of all works out makes athletes caretaker those women look thetypical of serioustypical like -, instead of athletes of [SEP]']
[ 900/2000] tot_loss=1.924 (perp=8.102, rec=0.101, cos=0.203), tot_loss_proj:2.590 [t=0.23s]
prediction: ['[CLS] the way teachers of all works out makes athletes caretaker those women look thetypical of serioustypical like -, instead of athletes of [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.890 (perp=7.969, rec=0.095, cos=0.201), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] the way teachers of all宣 works out makes caretaker those women look thetypical of serioustypical like -, instead of athletes of [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.881 (perp=7.921, rec=0.094, cos=0.204), tot_loss_proj:2.497 [t=0.24s]
prediction: ['[CLS] the way teachers of all - works out makes caretaker those women look thetypical of serioustypical like宣, instead of athletes of [SEP]']
[1050/2000] tot_loss=1.933 (perp=8.167, rec=0.095, cos=0.204), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] the way teachers of all - works out makes caretaker ones women look thetypical of serioustypical like宣, instead of athletes of [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.894 (perp=7.990, rec=0.092, cos=0.205), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] the way teachers of all - works out makes caretaker women look thetypical of ones serioustypical like宣, instead of athletes of [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.885 (perp=7.902, rec=0.099, cos=0.205), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] the way - of all teachers works out makes caretaker women look thetypical of ones serioustypical like宣, instead of athletes of [SEP]']
[1200/2000] tot_loss=1.880 (perp=7.927, rec=0.089, cos=0.206), tot_loss_proj:2.330 [t=0.24s]
prediction: ['[CLS] the way - of all teachers works out makes caretaker women look thetypical of less serioustypical like moral, instead of athletes of [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.804 (perp=7.547, rec=0.093, cos=0.201), tot_loss_proj:2.340 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of ones - serioustypical like moral, instead of athletes of [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.759 (perp=7.309, rec=0.093, cos=0.205), tot_loss_proj:2.257 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - serious ones like moral, instead of athletes of [SEP]']
[1350/2000] tot_loss=1.768 (perp=7.361, rec=0.091, cos=0.204), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - serious less like moral, instead of athletes of [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.754 (perp=7.283, rec=0.094, cos=0.203), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - less like serious moral, instead of athletes of [SEP]']
Attempt swap
[1450/2000] tot_loss=1.754 (perp=7.283, rec=0.094, cos=0.204), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - less like serious moral, instead of athletes of [SEP]']
[1500/2000] tot_loss=1.746 (perp=7.283, rec=0.086, cos=0.204), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - less like serious moral, instead of athletes of [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=7.283, rec=0.087, cos=0.204), tot_loss_proj:2.159 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - less like serious moral, instead of athletes of [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.731 (perp=7.155, rec=0.095, cos=0.205), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical - less like serious, instead of athletes of [SEP]']
[1650/2000] tot_loss=1.725 (perp=7.155, rec=0.090, cos=0.204), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical - less like serious, instead of athletes of [SEP]']
Attempt swap
[1700/2000] tot_loss=1.715 (perp=7.155, rec=0.080, cos=0.205), tot_loss_proj:2.136 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical - less like serious, instead of athletes of [SEP]']
Attempt swap
[1750/2000] tot_loss=1.725 (perp=7.155, rec=0.090, cos=0.205), tot_loss_proj:2.137 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical - less like serious, instead of athletes of [SEP]']
[1800/2000] tot_loss=1.719 (perp=7.155, rec=0.083, cos=0.205), tot_loss_proj:2.142 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical - less like serious, instead of athletes of [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.672 (perp=6.868, rec=0.098, cos=0.200), tot_loss_proj:2.095 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical - less like athletes, instead of serious of [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.662 (perp=6.833, rec=0.094, cos=0.201), tot_loss_proj:2.104 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical of less like athletes, instead of serious - [SEP]']
[1950/2000] tot_loss=1.661 (perp=6.833, rec=0.091, cos=0.203), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical of less like athletes, instead of serious - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.670 (perp=6.833, rec=0.100, cos=0.203), tot_loss_proj:2.103 [t=0.24s]
prediction: ['[CLS] the way of all teachers works out makes caretaker women look thetypical of moraltypical of less like athletes, instead of serious - [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the way of all teachers works out makes caretaker women look thetypical oftypical - less like serious moral, instead of athletes of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.913 | p: 73.913 | r: 73.913
rouge2     | fm: 27.273 | p: 27.273 | r: 27.273
rougeL     | fm: 65.217 | p: 65.217 | r: 65.217
rougeLsum  | fm: 65.217 | p: 65.217 | r: 65.217
r1fm+r2fm = 101.186

[Aggregate metrics]:
rouge1     | fm: 89.395 | p: 88.315 | r: 90.663
rouge2     | fm: 62.696 | p: 62.466 | r: 62.989
rougeL     | fm: 81.724 | p: 80.922 | r: 82.734
rougeLsum  | fm: 81.759 | p: 80.829 | r: 82.764
r1fm+r2fm = 152.090

input #21 time: 0:09:15 | total time: 3:18:08


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.8415750838926057
highest_index [0]
highest [0.8415750838926057]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9838346838951111 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9813443422317505 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9744722247123718 for ['[CLS] catalogue scom de respiratory z loose ps eventual cart win [SEP]']
[Init] best rec loss: 0.960681676864624 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 0.9549932479858398 for ['[CLS]dbus leaguedel more arrest able communists confederatedgetsomics [SEP]']
[Init] best rec loss: 0.9540227055549622 for ['[CLS] kali camp missiondio but whispered mining paulaville atmosphere qu [SEP]']
[Init] best rec loss: 0.953637421131134 for ['[CLS]vi dudley sponsored then background che opposition laurencefc feat double [SEP]']
[Init] best rec loss: 0.9532406330108643 for ['[CLS] view masters sheets bar separated emigrated play career traitor marriedory [SEP]']
[Init] best rec loss: 0.9426347017288208 for ['[CLS]ou apartowskilizer teaching collins wolfe sample rite maze kaiser [SEP]']
[Init] best rec loss: 0.9349916577339172 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 0.9344388842582703 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 0.9333361387252808 for ['[CLS] phoenix her laughter over function schedule chinese boarders kids set [SEP]']
[Init] best perm rec loss: 0.9329556822776794 for ['[CLS] phoenix function her set chinese laughter kids boarders over schedule [SEP]']
[Init] best perm rec loss: 0.9327080845832825 for ['[CLS] function schedule chinese laughter seters over her kids board phoenix [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.485 (perp=12.510, rec=0.714, cos=0.269), tot_loss_proj:4.016 [t=0.23s]
prediction: ['[CLS]haus felt revolver marijuana fivb florida. has nazis ) sentence [SEP]']
[ 100/2000] tot_loss=3.413 (perp=13.176, rec=0.577, cos=0.201), tot_loss_proj:4.271 [t=0.23s]
prediction: ['[CLS] powers felt doping marijuana gretchen marineᵍ wedding harta monster consequences [SEP]']
[ 150/2000] tot_loss=3.678 (perp=13.904, rec=0.637, cos=0.260), tot_loss_proj:4.715 [t=0.23s]
prediction: ['[CLS] powers yet psychologistignant gretchen police whom quite banned wrong moral [SEP]']
[ 200/2000] tot_loss=3.301 (perp=12.677, rec=0.523, cos=0.242), tot_loss_proj:4.376 [t=0.23s]
prediction: ['[CLS] almost app autobiography successful adaptation immediately ; purchase filmfare wrong moral [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.349 (perp=13.237, rec=0.513, cos=0.189), tot_loss_proj:4.645 [t=0.23s]
prediction: ['[CLS] almostrgeon successful adaptation adaptation finest successful purchase filmfare failure consequences [SEP]']
[ 300/2000] tot_loss=3.266 (perp=12.942, rec=0.492, cos=0.185), tot_loss_proj:4.571 [t=0.23s]
prediction: ['[CLS] efforts allegro an remake adaptation finest successful venture enjoyable failure consequences [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.968 (perp=11.841, rec=0.462, cos=0.138), tot_loss_proj:4.218 [t=0.29s]
prediction: ['[CLS] efforts an allegro adaptation adaptation finest successful application enjoyable failure enjoyable [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.967 (perp=11.512, rec=0.482, cos=0.182), tot_loss_proj:3.292 [t=0.23s]
prediction: ['[CLS] enjoyable efforts an allegro enjoyable adaptation finest successful thing wonderful kidding [SEP]']
[ 450/2000] tot_loss=3.241 (perp=12.180, rec=0.524, cos=0.280), tot_loss_proj:4.357 [t=0.23s]
prediction: ['[CLS] filmfare powers an allegro remake adaptation received successful film artificial if [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=3.297 (perp=13.043, rec=0.480, cos=0.208), tot_loss_proj:4.241 [t=0.23s]
prediction: ['[CLS] artificial enjoyable enjoyable legislation successful initiate enjoyable adaptation independent eine film [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.054 (perp=11.627, rec=0.459, cos=0.269), tot_loss_proj:4.213 [t=0.23s]
prediction: ['[CLS] failure enjoyable enjoyable legislation enjoyable initiate an adaptationcut successful film [SEP]']
[ 600/2000] tot_loss=3.012 (perp=12.073, rec=0.448, cos=0.149), tot_loss_proj:4.318 [t=0.23s]
prediction: ['[CLS] failure enjoyable enjoyable legislation enjoyableeptive an adaptationcut successful film [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.037 (perp=11.873, rec=0.435, cos=0.226), tot_loss_proj:4.283 [t=0.23s]
prediction: ['[CLS] failure enjoyable enjoyable enjoyable initiate legislation successful adaptationcut successful film [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.956 (perp=11.067, rec=0.479, cos=0.264), tot_loss_proj:4.205 [t=0.23s]
prediction: ['[CLS] failure enjoyable enjoyable enjoyablestrel legislation an adaptation ;cut film [SEP]']
[ 750/2000] tot_loss=2.845 (perp=11.264, rec=0.435, cos=0.157), tot_loss_proj:4.178 [t=0.23s]
prediction: ['[CLS] failure enjoyable enjoyable enjoyable initiate legislation an adaptation successfulcut film [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.026 (perp=11.925, rec=0.422, cos=0.219), tot_loss_proj:3.964 [t=0.23s]
prediction: ['[CLS] artificial enjoyable enjoyable enjoyable legislationeptive an adaptation successfulcut film [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.184 (perp=12.349, rec=0.420, cos=0.294), tot_loss_proj:3.899 [t=0.23s]
prediction: ['[CLS] artificial enjoyable enjoyable enjoyable legislation successfuleptive adaptation successfulcut film [SEP]']
[ 900/2000] tot_loss=2.934 (perp=11.691, rec=0.427, cos=0.169), tot_loss_proj:3.234 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable enjoyable legislation successful £ adaptation successfulcut film [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.987 (perp=11.778, rec=0.413, cos=0.218), tot_loss_proj:3.240 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable enjoyable legislationeptive successful adaptation successfulcut film [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.033 (perp=11.712, rec=0.413, cos=0.278), tot_loss_proj:3.262 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable £ legislation enjoyable successful adaptation successfulcut film [SEP]']
[1050/2000] tot_loss=2.929 (perp=11.712, rec=0.413, cos=0.174), tot_loss_proj:3.262 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable £ legislation enjoyable successful adaptation successfulcut film [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.787 (perp=10.848, rec=0.409, cos=0.209), tot_loss_proj:3.011 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.770 (perp=10.848, rec=0.417, cos=0.183), tot_loss_proj:3.008 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
[1200/2000] tot_loss=2.762 (perp=10.848, rec=0.412, cos=0.181), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.757 (perp=10.848, rec=0.402, cos=0.186), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.758 (perp=10.848, rec=0.398, cos=0.190), tot_loss_proj:3.008 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
[1350/2000] tot_loss=2.759 (perp=10.848, rec=0.392, cos=0.197), tot_loss_proj:3.017 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.702 (perp=10.493, rec=0.398, cos=0.205), tot_loss_proj:2.982 [t=0.23s]
prediction: ['[CLS] an enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.802 (perp=10.867, rec=0.433, cos=0.195), tot_loss_proj:3.098 [t=0.23s]
prediction: ['[CLS] an enjoyable enjoyable film enjoyableeptive successful adaptation successfulcut legislation [SEP]']
[1500/2000] tot_loss=2.835 (perp=10.867, rec=0.409, cos=0.253), tot_loss_proj:3.098 [t=0.23s]
prediction: ['[CLS] an enjoyable enjoyable film enjoyableeptive successful adaptation successfulcut legislation [SEP]']
Attempt swap
[1550/2000] tot_loss=2.787 (perp=10.743, rec=0.408, cos=0.231), tot_loss_proj:3.123 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable enjoyable film enjoyable £ successful adaptation successfulcut legislation [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.894 (perp=11.204, rec=0.406, cos=0.247), tot_loss_proj:3.312 [t=0.23s]
prediction: ['[CLS] wonderful enjoyable film enjoyable enjoyableeptive successful adaptation successfulcut legislation [SEP]']
[1650/2000] tot_loss=2.642 (perp=10.007, rec=0.404, cos=0.237), tot_loss_proj:2.991 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyable enjoyable £ successful adaptation successfulcut legislation [SEP]']
Attempt swap
[1700/2000] tot_loss=2.823 (perp=10.923, rec=0.399, cos=0.239), tot_loss_proj:3.209 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyable enjoyableeptive successful adaptation successfulcut legislation [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.791 (perp=10.728, rec=0.404, cos=0.241), tot_loss_proj:3.174 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyableeptive enjoyable successful adaptation successfulcut legislation [SEP]']
[1800/2000] tot_loss=2.717 (perp=10.316, rec=0.401, cos=0.253), tot_loss_proj:2.958 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyable £ enjoyable successful adaptation successfulcut legislation [SEP]']
Attempt swap
[1850/2000] tot_loss=2.755 (perp=10.316, rec=0.401, cos=0.291), tot_loss_proj:2.951 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyable £ enjoyable successful adaptation successfulcut legislation [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.665 (perp=10.007, rec=0.403, cos=0.260), tot_loss_proj:2.986 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyable enjoyable £ successful adaptation successfulcut legislation [SEP]']
[1950/2000] tot_loss=2.837 (perp=10.923, rec=0.393, cos=0.260), tot_loss_proj:3.204 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyable enjoyableeptive successful adaptation successfulcut legislation [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.838 (perp=10.728, rec=0.401, cos=0.291), tot_loss_proj:3.176 [t=0.23s]
prediction: ['[CLS] an enjoyable film enjoyableeptive enjoyable successful adaptation successfulcut legislation [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] an enjoyable enjoyable legislation enjoyable £ successful adaptation successfulcut film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.333 | p: 63.636 | r: 53.846
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 41.667 | p: 45.455 | r: 38.462
rougeLsum  | fm: 41.667 | p: 45.455 | r: 38.462
r1fm+r2fm = 76.515

[Aggregate metrics]:
rouge1     | fm: 88.188 | p: 87.248 | r: 89.252
rouge2     | fm: 60.757 | p: 60.623 | r: 60.922
rougeL     | fm: 80.027 | p: 79.301 | r: 80.889
rougeLsum  | fm: 79.888 | p: 79.220 | r: 80.703
r1fm+r2fm = 148.945

input #22 time: 0:09:07 | total time: 3:27:16


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.8449401838562637
highest_index [0]
highest [0.8449401838562637]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7154655456542969 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.711201012134552 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 0.7046244740486145 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 0.7021863460540771 for ['[CLS] colony. ana substitute bar advisory a yellow service copiesroud demonarianlawuc networks key months to nextations polly past fitness was congress has forest dr providingee marsh rick georgia { pacific coloured aisles sim wilde over baggagecr tune kirby project punk launch [SEP]']
[Init] best rec loss: 0.7012016177177429 for ['[CLS] opening ring immature karachi spoke given when maxness recommendedaver love amendmenthid newspaper come moist yearηςra albumvating emily army stage dragon council mcc shutter criteria business set themselves hacker qualifiedze country world sometime quality cinemasline mission cabinba voss applied autumn [SEP]']
[Init] best perm rec loss: 0.7010955810546875 for ['[CLS] themselves spoke karachi set council shutter immature love sometime hacker quality applied criteria voss ring when newspaper come worldης max autumn qualifiedba stage missionzeline given amendment moist cabinvating mcc cinemas businessra recommended emily yearaver dragonhid opening album countryness army [SEP]']
[Init] best perm rec loss: 0.6993025541305542 for ['[CLS] qualified emily mcc cinemas love autumn vossline set stage shutter recommended world amendment max openingra spoke mission whenvatingba applied business quality council album ringης cabinhid come country yearaver themselves immature criteriaze hacker newspaper moist dragon army given karachiness sometime [SEP]']
[Init] best perm rec loss: 0.6992083787918091 for ['[CLS]ra hacker qualified recommended voss business immature max appliedhidba when autumn ring world amendment come loveline shutter dragon council themselves sometime moist karachi album mission newspaper mcc stage criteria army openingvating country spoke qualityaver cinemas setness year given cabinze emilyης [SEP]']
[Init] best perm rec loss: 0.6987894773483276 for ['[CLS]ness year voss business dragonra immature ring amendmentηςba stage countryline recommended councilze when world opening hacker moist emily qualityaver set army qualified cinemas karachi mission applied sometime mccvating shutter given autumn max cabin criteriahid come themselves newspaper album spoke love [SEP]']
[Init] best perm rec loss: 0.6987659335136414 for ['[CLS]hidvating hacker council ring amendment mcc autumn stage given voss cinemasης sometime emily come themselves opening love quality cabinze qualified album mission set immatureaverba criteria spoke year karachi appliednessline country newspaper when army dragonra world max recommended moist business shutter [SEP]']
[Init] best perm rec loss: 0.6976071000099182 for ['[CLS] ring year quality newspaper mcc moist applied dragonra business lovevating qualified karachi councilness themselves givenaver criteria sometime album recommended armyzeης emily opening autumn mission spoke world amendment come cinemasline stage shutter immature set vossba country cabin when hackerhid max [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.314 (perp=11.588, rec=0.626, cos=0.371), tot_loss_proj:3.533 [t=0.23s]
prediction: ['[CLS] racing achievement isbn [SEP] choice " principles objective rock. easy communications across hearing motto ridge letter overview witness weapon survivors compiler ruled war track international issues investigation strategic objective of.ring isotopeching position. maintain za operational ra intersection point tracks soft victory villa to [SEP]']
[ 100/2000] tot_loss=3.081 (perp=11.266, rec=0.542, cos=0.285), tot_loss_proj:3.673 [t=0.23s]
prediction: ['[CLS] racing scholarship isbn [SEP] administered " human numerous crazy. mo research board detective motto ak es overview witness weapon mccartney stop ruled hill track position programming. named objective of.ringotideching position.ed lucha for ra intersection point tracks soft victory villa a [SEP]']
[ 150/2000] tot_loss=3.138 (perp=11.766, rec=0.501, cos=0.284), tot_loss_proj:3.666 [t=0.23s]
prediction: ['[CLS] racing scholarship isbn [SEP] administered most child numerous crazy. mo research board detective motto ak song overview witness weapon mccartney compiler fighting hill track position programming. named objective of musicratedotideching position.ed lucha for ra intersection point tracks soft victory villa a [SEP]']
[ 200/2000] tot_loss=3.091 (perp=11.672, rec=0.473, cos=0.284), tot_loss_proj:3.663 [t=0.23s]
prediction: ['[CLS] racing scholarship isbn [SEP] administered. child numerous crazy his mo research board detective motto benny song overview witness weapon mccartney compiler fighting hill track position programming. named objective of musicratedotideching position.ed lucha for ra intersection point tracks soft victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.027 (perp=11.504, rec=0.446, cos=0.281), tot_loss_proj:3.560 [t=0.23s]
prediction: ['[CLS] racing scholarship guiding [SEP] administered. child numerous crazy his mo peterson board detective motto benny song overview witness weapon mccartney compiler intersection french track position programming. named objective of artistsratedotideching position.ed lucha for ra fighting point tracks soft victory villa a [SEP]']
[ 300/2000] tot_loss=3.144 (perp=12.177, rec=0.424, cos=0.286), tot_loss_proj:4.086 [t=0.23s]
prediction: ['[CLS] racing scholarship guiding [SEP] bethany. child numerous shit his mo peterson board detective motto benny song overview witness alt mccartney compiler reminder enemy his km programming. named objective of artiststedotideting position.ed lucha for ra fighting point tracks soft victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.066 (perp=11.990, rec=0.397, cos=0.271), tot_loss_proj:4.030 [t=0.23s]
prediction: ['[CLS] racingotide guiding [SEP] whose.less numerous shit his mo peterson board detective motto benny song overview witness alt mccartney compiler reminder enemy track sports programming. named objective of recordingted scholarshipting position.ed lucha for ra fighting point tracks soft victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.986 (perp=11.663, rec=0.378, cos=0.276), tot_loss_proj:4.008 [t=0.23s]
prediction: ['[CLS] racingotide guiding [SEP] whose.less upper scholarship his mo peterson board detective motto ty song overview witness alt mccartney compiler reminder enemy still career issues. select purpose of recordingted shitting position.ed lucha for ra fighting point tracks soft victory villa a [SEP]']
[ 450/2000] tot_loss=3.000 (perp=11.798, rec=0.358, cos=0.283), tot_loss_proj:3.917 [t=0.23s]
prediction: ['[CLS] racing aluminum guiding [SEP] whose.less upper scholarship his mo peterson board detective motto ty song overview witness alt mccartney compiler reminder her synonymous career issue. named objective of theatreted shitting position.ed lucha for ra fighting point tracks soft victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.997 (perp=11.881, rec=0.345, cos=0.276), tot_loss_proj:3.789 [t=0.23s]
prediction: ['[CLS] racing aluminum guiding [SEP] whose.less successful scholarship his mo enough board detective motto benny crying overview witness alt song compiler reminder her synonymous career mission. named ethical of theatreted shitting position.ed lucha for ra fighting point tracks soft victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.897 (perp=11.410, rec=0.336, cos=0.279), tot_loss_proj:3.736 [t=0.23s]
prediction: ['[CLS] racing ra guiding [SEP] whose.less greater scholarship his mo enough board detective goals ty crying overview witness alt song compiler reminder her synonymous championship objective. named objective of theatreted prostitutionting position.ed lucha for aluminum fighting point tracks soft victory villa a [SEP]']
[ 600/2000] tot_loss=3.055 (perp=12.289, rec=0.320, cos=0.277), tot_loss_proj:3.820 [t=0.23s]
prediction: ['[CLS] sign flame guiding [SEP] whose.less jennings scholarship his mo enough board detective motto ty crying overview witness alt song compiler reminder her synonymous championship objective bogota named ethical of theatreted lieting position.ed lucha for aluminum fighting point tracks soft victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.973 (perp=11.950, rec=0.304, cos=0.279), tot_loss_proj:3.696 [t=0.23s]
prediction: ['[CLS] driving flame guiding [SEP] whose.less jennings scholarship his mo enough board mc motto ty crying overview witness alt song compiler reminder her sienna career objective gaining soft objective of theatreating lieting position.ed lucha for aluminum fighting point tracks named victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.030 (perp=12.360, rec=0.302, cos=0.256), tot_loss_proj:3.764 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose.less significant scholarship his mo enough board mc. benny crying overview witness alt song compiler reminder her sienna career objective gaining soft objective of cinemaating lieting position mottoed lucha for aluminum fighting point tracks named victory villa a [SEP]']
[ 750/2000] tot_loss=3.019 (perp=12.225, rec=0.293, cos=0.282), tot_loss_proj:3.681 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose.less main scholarship his mo communications board mc. bo crying overview witness alt song compiler reminder french sienna career objective gaining soft objective of cinemaating lieting position mottoed lucha forization fighting point tracks named victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.890 (perp=11.678, rec=0.281, cos=0.273), tot_loss_proj:3.603 [t=0.23s]
prediction: ['[CLS] driving flame guiding [SEP] whose.less main scholarship his moting board mc. bo crying overview witness alt song compiler reminder french sienna career objective reaches soft objective of cinemaating lie communications position mottoed lucha forization dance point tracks named victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.866 (perp=11.553, rec=0.280, cos=0.276), tot_loss_proj:3.563 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose.less main objective his moting board mc. bo crying overview witness alt song compiler reminder french sienna career objective reaches soft scholarship of cinemaating lie communications position mottoed lucha forization dance point tracks named victory villa a [SEP]']
[ 900/2000] tot_loss=2.841 (perp=11.435, rec=0.274, cos=0.280), tot_loss_proj:3.549 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose.less main objective his moting board mc. bo crying overview witness alt song compiler reminder soldiers sienna career objective reaches soft scholarship of dramaating lie communications position mottoed lucha forization dance point tracks named victory villa a [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.763 (perp=11.034, rec=0.284, cos=0.272), tot_loss_proj:3.481 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose reachesless main objective his moting board mc. bo crying overview witness alt song compiler reminder soldiers sienna career objective. soft scholarship of dramaating lie communications position mottoed lucha forization dance point tracks named victory villa a [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.705 (perp=10.759, rec=0.275, cos=0.278), tot_loss_proj:3.422 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose reachesless main objective his moting board mc. br crying overview witness alt song compiler a soldiers sienna career objective. soft scholarship of dramaating lie communications position mottoed lucha forization dance point tracks named victory villa reminder [SEP]']
[1050/2000] tot_loss=2.762 (perp=11.095, rec=0.268, cos=0.274), tot_loss_proj:3.669 [t=0.23s]
prediction: ['[CLS] expression flame guiding [SEP] whose reachesless main objective main moneck board mc. br crying overview witness alt song compiler a soldiers sienna career objective. soft poverty of dramaating lie communications position mottoed lucha forization dance point tracks named victory villa reminder [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.730 (perp=10.906, rec=0.273, cos=0.277), tot_loss_proj:3.658 [t=0.24s]
prediction: ['[CLS] expression flame guiding witness whose reachesless main objective main moneck board mc. br crying overview [SEP] alt song compiler a soldiers sienna career objective. soft poverty of dramaating lie communications position mottoed lucha forization dance point tracks named victory villa reminder [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.744 (perp=11.021, rec=0.270, cos=0.270), tot_loss_proj:3.659 [t=0.23s]
prediction: ['[CLS] expressionless guiding witness whose reaches flame main objective main moting board mc. br crying overview [SEP] alt song compiler a soldiers sienna career objective most soft poverty of drama : lie communications position mottoed lucha forization dance point tracks named victory museum reminder [SEP]']
[1200/2000] tot_loss=2.745 (perp=10.980, rec=0.266, cos=0.284), tot_loss_proj:3.672 [t=0.23s]
prediction: ['[CLS] expressionless guiding witness whose reaches ra main objective main moneck board mc. br crying overview [SEP] alt song compiler a soldiers sienna career objective most soft poverty of drama : lie communications position mottoed lucha forization dance point tracks named victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.713 (perp=10.845, rec=0.264, cos=0.280), tot_loss_proj:3.584 [t=0.24s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck board mc. br crying overview [SEP] alt song syria a soldiers sienna career objective. guiding poverty of drama : lie communications position mottoed lucha forization dance point tracks named victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.685 (perp=10.775, rec=0.262, cos=0.268), tot_loss_proj:3.582 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck board mc. br crying overview the alt song compiler a soldiers sienna contemporary objective. guiding poverty of drama : lie communications position mottoed wadi namedization referred point tracks for victory museum reminder [SEP]']
[1350/2000] tot_loss=2.698 (perp=10.800, rec=0.257, cos=0.280), tot_loss_proj:3.573 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck board mc. br crying overview the alt song syria a soldiers sienna contemporary objective. guiding poverty of drama : lie communications position mottoed wadi namedization referred point tracks for victory museum reminder [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.687 (perp=10.724, rec=0.261, cos=0.280), tot_loss_proj:3.579 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck board mc. br overview crying the alt song syria a soldiers sienna contemporary objective most guiding poverty of drama : lie communications position mottoed wadi namedization referred point tracks for victory museum reminder [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.633 (perp=10.490, rec=0.259, cos=0.276), tot_loss_proj:3.474 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck board mc. br overview crying the song alt syria a soldiers sienna contemporary objective most guiding poverty of drama : lie communications position mottoed wadi namedization dance point tracks for victory museum reminder [SEP]']
[1500/2000] tot_loss=2.632 (perp=10.490, rec=0.254, cos=0.280), tot_loss_proj:3.475 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck board mc. br overview crying the song alt syria a soldiers sienna contemporary objective most guiding poverty of drama : lie communications position mottoed wadi namedization dance point tracks for victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.665 (perp=10.626, rec=0.257, cos=0.282), tot_loss_proj:3.514 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose reaches ra main objective main moneck ah mc. br overview crying the song alt syria a soldiers sienna contemporary objective most guiding poverty of drama : board communications position mottoed wadi namedization dance point tracks for victory museum reminder [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.704 (perp=10.831, rec=0.259, cos=0.279), tot_loss_proj:3.578 [t=0.23s]
prediction: ['[CLS] expressionless soft witness whose ra their main objective main moneck ah mc. br overview crying the song alt protect a soldiers sienna contemporary objective most guiding poverty of drama : board communications position mottoed wadi namedization dance point tracks for victory museum reminder [SEP]']
[1650/2000] tot_loss=2.667 (perp=10.655, rec=0.255, cos=0.281), tot_loss_proj:3.485 [t=0.24s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main moneck ah mc. br overview crying the song alt protect a soldiers sienna contemporary objective most guiding poverty of drama : board communications position mottoed wadi namedization dance point tracks for victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.603 (perp=10.327, rec=0.257, cos=0.281), tot_loss_proj:3.421 [t=0.23s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main monecked mc. br overview crying the song alt protect a soldiers sienna contemporary objective. guiding poverty of drama : board communications position motto ah wadi namedization dance point tracks for victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.573 (perp=10.182, rec=0.255, cos=0.281), tot_loss_proj:3.396 [t=0.23s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main protectnecked mc. br overview crying the song alt mo a soldiers sienna contemporary objective most guiding poverty of drama : board communications position motto ah wadi namedization dance point tracks for victory museum reminder [SEP]']
[1800/2000] tot_loss=2.578 (perp=10.182, rec=0.257, cos=0.284), tot_loss_proj:3.398 [t=0.23s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main protectnecked mc. br overview crying the song alt mo a soldiers sienna contemporary objective most guiding poverty of drama : board communications position motto ah wadi namedization dance point tracks for victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.542 (perp=9.974, rec=0.263, cos=0.284), tot_loss_proj:3.386 [t=0.24s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main protectnecked sienna. br overview crying the song alt mo a soldiers mc contemporary objective most guiding poverty of drama : board communications position motto ah wadi namedization dance point tracks for victory museum reminder [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.504 (perp=9.811, rec=0.260, cos=0.282), tot_loss_proj:3.314 [t=0.23s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main protectnecked sienna. br overview crying the tracks alt mo a soldiers mc contemporary objective most guiding poverty of drama : board communications position motto ah wadi namedization dance point song for victory museum reminder [SEP]']
[1950/2000] tot_loss=2.498 (perp=9.811, rec=0.257, cos=0.279), tot_loss_proj:3.317 [t=0.23s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main protectnecked sienna. br overview crying the tracks alt mo a soldiers mc contemporary objective most guiding poverty of drama : board communications position motto ah wadi namedization dance point song for victory museum reminder [SEP]']
Attempt swap
[2000/2000] tot_loss=2.543 (perp=10.017, rec=0.254, cos=0.286), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] expressionless soft witness achieved ra their main objective main protectnecked sienna. br overview crying the tracks alt mo a soldiers mc contemporary objective most guiding poverty of drama : board communications position motto lie lucha namedization dance point song for victory museum reminder [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] expressionless soft witness achieved ra their main objective main protectnecked mc. br overview crying the song alt mo a soldiers sienna contemporary objective most guiding poverty of drama : board communications position motto ah wadi namedization dance point tracks for victory museum reminder [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 19.048 | p: 18.182 | r: 20.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 16.667 | p: 15.909 | r: 17.500
rougeLsum  | fm: 16.667 | p: 15.909 | r: 17.500
r1fm+r2fm = 19.048

[Aggregate metrics]:
rouge1     | fm: 85.285 | p: 84.486 | r: 86.469
rouge2     | fm: 58.285 | p: 58.122 | r: 58.415
rougeL     | fm: 77.328 | p: 76.601 | r: 78.293
rougeLsum  | fm: 77.134 | p: 76.489 | r: 77.953
r1fm+r2fm = 143.570

input #23 time: 0:09:12 | total time: 3:36:29


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.8696351287561953
highest_index [0]
highest [0.8696351287561953]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8340577483177185 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8047112822532654 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.7981670498847961 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7958807349205017 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.7644192576408386 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7578127980232239 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.745235800743103 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7138178944587708 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7104101181030273 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7098547220230103 for ['[CLS] happy no attack arms damned play portwyl younger unless suffer bush bond snow village midaneous county ryu em [SEP]']
[Init] best perm rec loss: 0.7087782621383667 for ['[CLS] younger snow bush unless suffer no attack bond arms midaneouswyl village damned ryu play em county happy port [SEP]']
[Init] best perm rec loss: 0.7081380486488342 for ['[CLS] midwyl no play damned ryu younger happy village attack bush bond port suffer snow emaneous unless county arms [SEP]']
[Init] best perm rec loss: 0.7077124714851379 for ['[CLS] younger happy play no em bush ryu damned port mid attack unless arms village bondaneous suffer countywyl snow [SEP]']
[Init] best perm rec loss: 0.7066810727119446 for ['[CLS] damned younger port noaneous village bondwyl ryu attack mid play county happy arms bush unless suffer em snow [SEP]']
[Init] best perm rec loss: 0.7058477401733398 for ['[CLS] bush ryu no arms port attack em play snowwyl damned bond unless villageaneous happy suffer younger county mid [SEP]']
[Init] best perm rec loss: 0.7050769925117493 for ['[CLS] snow bush bond arms nowyl village suffer attack em county younger mid damned happy play port ryu unlessaneous [SEP]']
[Init] best perm rec loss: 0.7039892673492432 for ['[CLS] attack unless arms no mid snow em village happy damned bond county bush sufferwylaneous ryu port younger play [SEP]']
[Init] best perm rec loss: 0.7033301591873169 for ['[CLS] unless arms county younger happy attack bush bond em village no damnedwyl port play snow suffer midaneous ryu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.593 (perp=10.153, rec=0.363, cos=0.199), tot_loss_proj:3.154 [t=0.23s]
prediction: ['[CLS] outside others headlines context era military global terrorist evil / threat bombes police attack drug criminal involving zombies ears [SEP]']
[ 100/2000] tot_loss=2.533 (perp=9.971, rec=0.322, cos=0.217), tot_loss_proj:2.948 [t=0.23s]
prediction: ['[CLS] outside other evil context political groups political terrorist evil / political evil undergo terrorists attack any are involvingnbc fuse [SEP]']
[ 150/2000] tot_loss=2.506 (perp=10.261, rec=0.224, cos=0.231), tot_loss_proj:3.132 [t=0.24s]
prediction: ['[CLS] outside the [SEP] context climate claim relatively terrorists evil : political evil come terrorists is the ( involving :! [SEP]']
[ 200/2000] tot_loss=2.259 (perp=9.191, rec=0.184, cos=0.237), tot_loss_proj:2.778 [t=0.23s]
prediction: ['[CLS] outside the evil context climate claim political terrorists evil : political evil come terrorists is the taken outside : ) [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.178 (perp=8.928, rec=0.180, cos=0.212), tot_loss_proj:2.793 [t=0.23s]
prediction: ['[CLS] outside the views context climate against the current terrorists evil ( more evil verse terrorists are taken outside : ) [SEP]']
[ 300/2000] tot_loss=2.135 (perp=8.743, rec=0.151, cos=0.235), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] outside the : context climate against the current terrorists evil ( more evil perspective terrorists are taken outside :! [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.135 (perp=8.250, rec=0.243, cos=0.241), tot_loss_proj:2.578 [t=0.23s]
prediction: ['[CLS] outside the the context themed organizations the political terrorists evil / most evil climate terrorists ever taken than :! [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.046 (perp=8.081, rec=0.188, cos=0.242), tot_loss_proj:2.574 [t=0.23s]
prediction: ['[CLS] outside the political context themed troops the - terrorists evil than more evil climate terrorists are taken than : ) [SEP]']
[ 450/2000] tot_loss=1.904 (perp=7.463, rec=0.172, cos=0.240), tot_loss_proj:2.453 [t=0.24s]
prediction: ['[CLS] outside the political context themed troops the - terrorists evil ( more evil climate terrorists are taken than : ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.853 (perp=7.292, rec=0.156, cos=0.238), tot_loss_proj:2.387 [t=0.24s]
prediction: ['[CLS] outside the political context themed troops the evil political - ( more evil climate terrorists are taken than : ) [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.792 (perp=7.045, rec=0.154, cos=0.229), tot_loss_proj:2.358 [t=0.24s]
prediction: ['[CLS] outside the political context themed troops the political evil - ( more evil climate terrorists are taken than : ) [SEP]']
[ 600/2000] tot_loss=1.825 (perp=7.224, rec=0.137, cos=0.243), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] outside the political context facing troops the political evil - ( more evil climate terrorists are taken than : ) [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.766 (perp=6.898, rec=0.147, cos=0.240), tot_loss_proj:2.563 [t=0.24s]
prediction: ['[CLS] outside the political context troops facing the political evil - ( more evil climate terrorists are taken than : ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.732 (perp=6.753, rec=0.145, cos=0.237), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] outside the political context troops facing the political evil - ( more evil climate terrorists are taken than ) : [SEP]']
[ 750/2000] tot_loss=1.701 (perp=6.753, rec=0.120, cos=0.230), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] outside the political context troops facing the political evil - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.692 (perp=6.753, rec=0.122, cos=0.220), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] outside the political context troops facing the political evil - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.691 (perp=6.641, rec=0.133, cos=0.229), tot_loss_proj:2.381 [t=0.24s]
prediction: ['[CLS] outside the political context - facing the political evil troops ( more evil climate terrorists are taken than ) : [SEP]']
[ 900/2000] tot_loss=1.687 (perp=6.641, rec=0.119, cos=0.240), tot_loss_proj:2.383 [t=0.24s]
prediction: ['[CLS] outside the political context - facing the political evil troops ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.681 (perp=6.641, rec=0.128, cos=0.224), tot_loss_proj:2.384 [t=0.24s]
prediction: ['[CLS] outside the political context - facing the political evil troops ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1000/2000] tot_loss=1.676 (perp=6.584, rec=0.120, cos=0.239), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] outside the political context - facing the political evil does ( more evil climate terrorists are taken than ) : [SEP]']
[1050/2000] tot_loss=1.687 (perp=6.649, rec=0.115, cos=0.243), tot_loss_proj:2.286 [t=0.23s]
prediction: ['[CLS] outside the political context - taken the political evil does ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1100/2000] tot_loss=1.688 (perp=6.649, rec=0.121, cos=0.236), tot_loss_proj:2.283 [t=0.24s]
prediction: ['[CLS] outside the political context - taken the political evil does ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.681 (perp=6.615, rec=0.118, cos=0.240), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] outside the political context does taken the current evil - ( more evil climate terrorists are taken than ) : [SEP]']
[1200/2000] tot_loss=1.689 (perp=6.615, rec=0.123, cos=0.243), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] outside the political context does taken the current evil - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.634 (perp=6.369, rec=0.120, cos=0.240), tot_loss_proj:2.414 [t=0.23s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1300/2000] tot_loss=1.635 (perp=6.369, rec=0.119, cos=0.243), tot_loss_proj:2.417 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
[1350/2000] tot_loss=1.626 (perp=6.369, rec=0.113, cos=0.239), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1400/2000] tot_loss=1.628 (perp=6.369, rec=0.112, cos=0.242), tot_loss_proj:2.419 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1450/2000] tot_loss=1.610 (perp=6.369, rec=0.107, cos=0.229), tot_loss_proj:2.416 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
[1500/2000] tot_loss=1.628 (perp=6.369, rec=0.115, cos=0.240), tot_loss_proj:2.415 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1550/2000] tot_loss=1.630 (perp=6.369, rec=0.114, cos=0.242), tot_loss_proj:2.414 [t=0.23s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1600/2000] tot_loss=1.622 (perp=6.369, rec=0.105, cos=0.243), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
[1650/2000] tot_loss=1.623 (perp=6.369, rec=0.110, cos=0.239), tot_loss_proj:2.415 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1700/2000] tot_loss=1.636 (perp=6.369, rec=0.120, cos=0.242), tot_loss_proj:2.415 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1750/2000] tot_loss=1.630 (perp=6.369, rec=0.114, cos=0.242), tot_loss_proj:2.413 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
[1800/2000] tot_loss=1.618 (perp=6.369, rec=0.101, cos=0.243), tot_loss_proj:2.413 [t=0.23s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1850/2000] tot_loss=1.612 (perp=6.369, rec=0.100, cos=0.239), tot_loss_proj:2.417 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[1900/2000] tot_loss=1.621 (perp=6.369, rec=0.106, cos=0.241), tot_loss_proj:2.417 [t=0.23s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
[1950/2000] tot_loss=1.626 (perp=6.369, rec=0.110, cos=0.242), tot_loss_proj:2.415 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=6.626, rec=0.113, cos=0.243), tot_loss_proj:2.447 [t=0.24s]
prediction: ['[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than )! [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] outside the political context does the current evil taken - ( more evil climate terrorists are taken than ) : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 23.529 | p: 23.529 | r: 23.529
rougeL     | fm: 61.111 | p: 61.111 | r: 61.111
rougeLsum  | fm: 61.111 | p: 61.111 | r: 61.111
r1fm+r2fm = 106.863

[Aggregate metrics]:
rouge1     | fm: 85.370 | p: 84.548 | r: 86.436
rouge2     | fm: 56.830 | p: 56.696 | r: 57.083
rougeL     | fm: 76.874 | p: 76.115 | r: 77.768
rougeLsum  | fm: 76.623 | p: 76.151 | r: 77.375
r1fm+r2fm = 142.199

input #24 time: 0:09:14 | total time: 3:45:43


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.8090740885143455
highest_index [0]
highest [0.8090740885143455]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9536852240562439 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9083707928657532 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.9006861448287964 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.8826085329055786 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.8718913197517395 for ['[CLS]iary rooms concerned who [SEP]']
[Init] best rec loss: 0.867173433303833 for ['[CLS] passagelvis hill 7 [SEP]']
[Init] best rec loss: 0.8561800122261047 for ['[CLS] tolerance ba clearffs [SEP]']
[Init] best perm rec loss: 0.8552695512771606 for ['[CLS] tolerance clearffs ba [SEP]']
[Init] best perm rec loss: 0.8545694351196289 for ['[CLS] clear toleranceffs ba [SEP]']
[Init] best perm rec loss: 0.8543810844421387 for ['[CLS]ffs clear tolerance ba [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.659 (perp=10.428, rec=0.231, cos=0.343), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] strange spirituality beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.249 (perp=8.995, rec=0.105, cos=0.345), tot_loss_proj:2.320 [t=0.23s]
prediction: ['[CLS] strangely beautiful film [SEP]']
[ 150/2000] tot_loss=1.758 (perp=6.646, rec=0.084, cos=0.344), tot_loss_proj:1.792 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 200/2000] tot_loss=1.775 (perp=6.646, rec=0.100, cos=0.345), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.765 (perp=6.646, rec=0.090, cos=0.345), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.756 (perp=6.646, rec=0.084, cos=0.343), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.760 (perp=6.646, rec=0.086, cos=0.344), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.752 (perp=6.646, rec=0.079, cos=0.344), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.758 (perp=6.646, rec=0.083, cos=0.346), tot_loss_proj:1.793 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.746 (perp=6.646, rec=0.072, cos=0.345), tot_loss_proj:1.783 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.752 (perp=6.646, rec=0.078, cos=0.345), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.751 (perp=6.646, rec=0.077, cos=0.345), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.741 (perp=6.646, rec=0.067, cos=0.345), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.752 (perp=6.646, rec=0.077, cos=0.345), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.744 (perp=6.646, rec=0.070, cos=0.345), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.735 (perp=6.646, rec=0.061, cos=0.344), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.740 (perp=6.646, rec=0.066, cos=0.345), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.747 (perp=6.646, rec=0.073, cos=0.345), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=6.646, rec=0.057, cos=0.345), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.726 (perp=6.646, rec=0.052, cos=0.345), tot_loss_proj:1.793 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.741 (perp=6.646, rec=0.067, cos=0.345), tot_loss_proj:1.790 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.749 (perp=6.646, rec=0.075, cos=0.345), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.740 (perp=6.646, rec=0.066, cos=0.345), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.745 (perp=6.646, rec=0.071, cos=0.345), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.736 (perp=6.646, rec=0.062, cos=0.345), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.734 (perp=6.646, rec=0.060, cos=0.345), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.736 (perp=6.646, rec=0.061, cos=0.345), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.736 (perp=6.646, rec=0.062, cos=0.345), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.743 (perp=6.646, rec=0.069, cos=0.345), tot_loss_proj:1.798 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.729 (perp=6.646, rec=0.054, cos=0.345), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.728 (perp=6.646, rec=0.054, cos=0.345), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.741 (perp=6.646, rec=0.067, cos=0.345), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.739 (perp=6.646, rec=0.065, cos=0.345), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.738 (perp=6.646, rec=0.063, cos=0.345), tot_loss_proj:1.788 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.740 (perp=6.646, rec=0.066, cos=0.345), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.743 (perp=6.646, rec=0.068, cos=0.345), tot_loss_proj:1.791 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.734 (perp=6.646, rec=0.060, cos=0.345), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=6.646, rec=0.066, cos=0.345), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.735 (perp=6.646, rec=0.060, cos=0.345), tot_loss_proj:1.798 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.730 (perp=6.646, rec=0.055, cos=0.345), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.787 | p: 85.083 | r: 86.873
rouge2     | fm: 58.488 | p: 58.434 | r: 58.559
rougeL     | fm: 77.636 | p: 76.992 | r: 78.479
rougeLsum  | fm: 77.468 | p: 76.851 | r: 78.256
r1fm+r2fm = 144.275

input #25 time: 0:09:07 | total time: 3:54:51


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.8553923414329108
highest_index [0]
highest [0.8553923414329108]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8836743831634521 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8798666000366211 for ['[CLS] occur oxygen wallaceuit inherent drug latvian hers deancrathenko counteranto q for at link renee army born hartabas effect [SEP]']
[Init] best rec loss: 0.8507627844810486 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8401593565940857 for ['[CLS] este letter freedom ‚ whose raid beautyenes [SEP] numbers allsel especially best thought kid internationally picture tu plum cue dutyriam [SEP]']
[Init] best rec loss: 0.831805944442749 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.826084554195404 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8239790201187134 for ['[CLS] polish four death fourth list constituencies theoretical octave moreᆼ souls usually door arrow merely shot discipline officers colonial isotead skan [SEP]']
[Init] best perm rec loss: 0.8229430317878723 for ['[CLS] shot arrow list usually officers more souls iso colonialtead merely constituencies death disciplineᆼ door s polishkan octave fourth four theoretical [SEP]']
[Init] best perm rec loss: 0.8220640420913696 for ['[CLS] disciplineᆼ souls fourth more constituencies officers iso merely colonial polishtead death theoretical octave usually list door arrow skan four shot [SEP]']
[Init] best perm rec loss: 0.8217241764068604 for ['[CLS] usually iso polish door officerskan stead colonial death shot list more theoretical discipline octave four merely fourth arrowᆼ souls constituencies [SEP]']
[Init] best perm rec loss: 0.8173240423202515 for ['[CLS] death constituencies merely shot fourth s theoretical moreᆼ four polish arrow doorkan officers souls iso discipline colonialtead list usually octave [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.236 (perp=13.147, rec=0.349, cos=0.258), tot_loss_proj:3.503 [t=0.23s]
prediction: ['[CLS] pointless dirt her finnish probably flat pointless inspector pointless fu cited exploit newly -by college import article import salaries issue estonian cared [SEP]']
[ 100/2000] tot_loss=2.959 (perp=12.153, rec=0.272, cos=0.256), tot_loss_proj:3.225 [t=0.23s]
prediction: ['[CLS] pointless seeds her french far flat pointlessiter pointless frenchckman origin newly - - ) import import clement 000 loanzzling import [SEP]']
[ 150/2000] tot_loss=2.819 (perp=11.673, rec=0.239, cos=0.245), tot_loss_proj:3.121 [t=0.24s]
prediction: ['[CLS] pointless european ) french far flat pointless french pointless french import origin import - ) from import least clement justin knockedzzling import [SEP]']
[ 200/2000] tot_loss=2.506 (perp=10.286, rec=0.193, cos=0.256), tot_loss_proj:3.076 [t=0.24s]
prediction: ['[CLS] pointless these ) french import flat pointless french pointless french import age import - - from import author french justin age meaning director [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.491 (perp=10.358, rec=0.159, cos=0.261), tot_loss_proj:2.886 [t=0.24s]
prediction: ['[CLS] this import ) mean scoring flat pointless and pointless french bubbling coming import - and from import author writer - age sophie director [SEP]']
[ 300/2000] tot_loss=2.369 (perp=9.843, rec=0.137, cos=0.264), tot_loss_proj:2.810 [t=0.24s]
prediction: ['[CLS] this import ) meaning mean pointless french pointless french author coming import - and from import writer writer - age sophie director [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.320 (perp=9.689, rec=0.126, cos=0.256), tot_loss_proj:2.969 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless french mean coming anne age and from import writer writer - age french director [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.216 (perp=9.150, rec=0.124, cos=0.263), tot_loss_proj:2.794 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne age and from import writer french - age french director [SEP]']
[ 450/2000] tot_loss=2.211 (perp=9.150, rec=0.127, cos=0.254), tot_loss_proj:2.797 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne age and from import writer french - age french director [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.162 (perp=8.898, rec=0.114, cos=0.268), tot_loss_proj:2.719 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne age and from french import writer french - age director [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.156 (perp=8.898, rec=0.109, cos=0.267), tot_loss_proj:2.713 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne age and from french import writer french - age director [SEP]']
[ 600/2000] tot_loss=2.160 (perp=8.898, rec=0.113, cos=0.268), tot_loss_proj:2.722 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne age and from french import writer french - age director [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.122 (perp=8.755, rec=0.106, cos=0.264), tot_loss_proj:2.673 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne and age from french import writer french - age director [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.117 (perp=8.755, rec=0.103, cos=0.263), tot_loss_proj:2.667 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne and age from french import writer french - age director [SEP]']
[ 750/2000] tot_loss=2.166 (perp=8.986, rec=0.103, cos=0.266), tot_loss_proj:2.713 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writer mean coming anne and age from french import director french - age director [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.399 (perp=10.185, rec=0.098, cos=0.264), tot_loss_proj:3.055 [t=0.24s]
prediction: ['[CLS] this - ) meaning mean pointless sophie pointless writernow coming and age from french import - anne french sophie age director [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.390 (perp=10.117, rec=0.105, cos=0.262), tot_loss_proj:3.020 [t=0.24s]
prediction: ['[CLS] this - ) meander mean pointless sophie pointless writernow coming and age from french import - age french sophie anne director [SEP]']
[ 900/2000] tot_loss=2.390 (perp=10.117, rec=0.100, cos=0.267), tot_loss_proj:3.025 [t=0.24s]
prediction: ['[CLS] this - ) meander mean pointless sophie pointless writernow coming and age from french import - age french sophie anne director [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.262 (perp=9.472, rec=0.102, cos=0.266), tot_loss_proj:2.928 [t=0.24s]
prediction: ['[CLS] this - ) meander mean pointless sophie pointless writernow coming and age from french import - age director sophie anne french [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.221 (perp=9.302, rec=0.097, cos=0.264), tot_loss_proj:2.895 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writernow coming and age from french import - age director sophie anne french [SEP]']
[1050/2000] tot_loss=2.228 (perp=9.302, rec=0.102, cos=0.265), tot_loss_proj:2.893 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writernow coming and age from french import - age director sophie anne french [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.103 (perp=8.706, rec=0.097, cos=0.266), tot_loss_proj:2.633 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless of writer coming and age from french import - age director sophie anne french [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.231 (perp=9.364, rec=0.091, cos=0.267), tot_loss_proj:2.856 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless and writer comingnow age from french import - age director sophie anne french [SEP]']
[1200/2000] tot_loss=2.238 (perp=9.364, rec=0.099, cos=0.266), tot_loss_proj:2.866 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless and writer comingnow age from french import - age director sophie anne french [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.207 (perp=9.254, rec=0.090, cos=0.266), tot_loss_proj:2.801 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writer and comingnow age from french import - age director sophie anne french [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.189 (perp=9.157, rec=0.092, cos=0.266), tot_loss_proj:2.729 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writer and coming agenow from french import - age director sophie anne french [SEP]']
[1350/2000] tot_loss=2.183 (perp=9.157, rec=0.086, cos=0.266), tot_loss_proj:2.724 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writer and coming agenow from french import - age director sophie anne french [SEP]']
Attempt swap
[1400/2000] tot_loss=2.191 (perp=9.157, rec=0.093, cos=0.266), tot_loss_proj:2.736 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writer and coming agenow from french import - age director sophie anne french [SEP]']
Attempt swap
[1450/2000] tot_loss=2.185 (perp=9.157, rec=0.087, cos=0.267), tot_loss_proj:2.737 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writer and coming agenow from french import - age director sophie anne french [SEP]']
[1500/2000] tot_loss=2.190 (perp=9.157, rec=0.092, cos=0.266), tot_loss_proj:2.731 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie pointless writer and coming agenow from french import - age director sophie anne french [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.155 (perp=8.986, rec=0.092, cos=0.265), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french import - age director sophie anne french [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.148 (perp=8.986, rec=0.087, cos=0.264), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french import - age director sophie anne french [SEP]']
[1650/2000] tot_loss=2.164 (perp=8.986, rec=0.101, cos=0.265), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french import - age director sophie anne french [SEP]']
Attempt swap
[1700/2000] tot_loss=2.154 (perp=8.986, rec=0.091, cos=0.266), tot_loss_proj:2.525 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french import - age director sophie anne french [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.152 (perp=8.993, rec=0.088, cos=0.265), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french - import age director sophie anne french [SEP]']
[1800/2000] tot_loss=2.159 (perp=8.993, rec=0.094, cos=0.266), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french - import age director sophie anne french [SEP]']
Attempt swap
[1850/2000] tot_loss=2.158 (perp=8.993, rec=0.093, cos=0.266), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french - import age director sophie anne french [SEP]']
Attempt swap
[1900/2000] tot_loss=2.150 (perp=8.993, rec=0.085, cos=0.267), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french - import age director sophie anne french [SEP]']
[1950/2000] tot_loss=2.155 (perp=8.993, rec=0.090, cos=0.267), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french - import age director sophie anne french [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.256 (perp=9.515, rec=0.086, cos=0.267), tot_loss_proj:2.643 [t=0.24s]
prediction: ['[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french import - age director sophierot french [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this - ) mean meander pointless sophie and pointless writer coming agenow from french - import age director sophie anne french [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.676 | p: 70.000 | r: 82.353
rouge2     | fm: 11.429 | p: 10.526 | r: 12.500
rougeL     | fm: 48.649 | p: 45.000 | r: 52.941
rougeLsum  | fm: 48.649 | p: 45.000 | r: 52.941
r1fm+r2fm = 87.104

[Aggregate metrics]:
rouge1     | fm: 85.530 | p: 84.556 | r: 86.721
rouge2     | fm: 56.752 | p: 56.577 | r: 56.942
rougeL     | fm: 76.536 | p: 75.811 | r: 77.496
rougeLsum  | fm: 76.415 | p: 75.686 | r: 77.312
r1fm+r2fm = 142.282

input #26 time: 0:09:15 | total time: 4:04:07


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.8726756060106482
highest_index [0]
highest [0.8726756060106482]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9727705717086792 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9470565319061279 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9461365342140198 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.943061888217926 for ['[CLS] backeddation chancel [SEP]']
[Init] best rec loss: 0.9423965811729431 for ['[CLS] tribune ruler dropping [SEP]']
[Init] best rec loss: 0.9320907592773438 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9155358672142029 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.8926217555999756 for ['[CLS] fat mattream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.366 (perp=9.263, rec=0.273, cos=0.240), tot_loss_proj:3.197 [t=0.23s]
prediction: ['[CLS] less are generic [SEP]']
[ 100/2000] tot_loss=2.212 (perp=9.217, rec=0.135, cos=0.233), tot_loss_proj:2.618 [t=0.23s]
prediction: ['[CLS] so are generic [SEP]']
[ 150/2000] tot_loss=2.153 (perp=9.217, rec=0.074, cos=0.236), tot_loss_proj:2.586 [t=0.23s]
prediction: ['[CLS] so are generic [SEP]']
[ 200/2000] tot_loss=2.141 (perp=9.217, rec=0.063, cos=0.234), tot_loss_proj:2.587 [t=0.23s]
prediction: ['[CLS] so are generic [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.965 (perp=8.320, rec=0.067, cos=0.234), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.966 (perp=8.320, rec=0.070, cos=0.232), tot_loss_proj:1.993 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.969 (perp=8.320, rec=0.070, cos=0.234), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.968 (perp=8.320, rec=0.066, cos=0.238), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.958 (perp=8.320, rec=0.056, cos=0.238), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.951 (perp=8.320, rec=0.052, cos=0.235), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=8.320, rec=0.062, cos=0.238), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.967 (perp=8.320, rec=0.066, cos=0.237), tot_loss_proj:1.988 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.964 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.952 (perp=8.320, rec=0.051, cos=0.238), tot_loss_proj:1.990 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.958 (perp=8.320, rec=0.059, cos=0.235), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.966 (perp=8.320, rec=0.063, cos=0.238), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.948 (perp=8.320, rec=0.048, cos=0.236), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.956 (perp=8.320, rec=0.054, cos=0.238), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.962 (perp=8.320, rec=0.062, cos=0.236), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.969 (perp=8.320, rec=0.066, cos=0.238), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.950 (perp=8.320, rec=0.050, cos=0.236), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.971 (perp=8.320, rec=0.069, cos=0.238), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.955 (perp=8.320, rec=0.053, cos=0.238), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.958 (perp=8.320, rec=0.056, cos=0.238), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.964 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.956 (perp=8.320, rec=0.055, cos=0.237), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.953 (perp=8.320, rec=0.051, cos=0.238), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.970 (perp=8.320, rec=0.068, cos=0.238), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.961 (perp=8.320, rec=0.060, cos=0.237), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.970 (perp=8.320, rec=0.068, cos=0.238), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.965 (perp=8.320, rec=0.062, cos=0.238), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.951 (perp=8.320, rec=0.050, cos=0.237), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.959 (perp=8.320, rec=0.057, cos=0.238), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.962 (perp=8.320, rec=0.060, cos=0.238), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.958 (perp=8.320, rec=0.055, cos=0.238), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.974 (perp=8.320, rec=0.072, cos=0.238), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.965 (perp=8.320, rec=0.063, cos=0.238), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.961 (perp=8.320, rec=0.058, cos=0.238), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.951 (perp=8.320, rec=0.049, cos=0.238), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.960 (perp=8.320, rec=0.058, cos=0.238), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.115 | p: 85.118 | r: 87.303
rouge2     | fm: 58.218 | p: 58.092 | r: 58.368
rougeL     | fm: 77.370 | p: 76.693 | r: 78.304
rougeLsum  | fm: 77.083 | p: 76.500 | r: 77.975
r1fm+r2fm = 144.333

input #27 time: 0:09:07 | total time: 4:13:14


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.8820537723075528
highest_index [0]
highest [0.8820537723075528]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8715556859970093 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.848751425743103 for ['[CLS] easierlnan cow [SEP]']
[Init] best rec loss: 0.8407201170921326 for ['[CLS] done human live quickly [SEP]']
[Init] best rec loss: 0.8353184461593628 for ['[CLS] sick prior spielberggation [SEP]']
[Init] best rec loss: 0.8284849524497986 for ['[CLS] hand delgado laid phoenix [SEP]']
[Init] best rec loss: 0.8217264413833618 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.8158529996871948 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best rec loss: 0.8144204616546631 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.8117538094520569 for ['[CLS] heights roses larvae jeremy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.746 (perp=11.199, rec=0.296, cos=0.211), tot_loss_proj:3.661 [t=0.23s]
prediction: ['[CLS] considering hours minutes minutes [SEP]']
[ 100/2000] tot_loss=2.209 (perp=9.137, rec=0.177, cos=0.205), tot_loss_proj:2.727 [t=0.23s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 150/2000] tot_loss=2.180 (perp=9.137, rec=0.144, cos=0.209), tot_loss_proj:2.727 [t=0.23s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
[ 200/2000] tot_loss=2.173 (perp=9.137, rec=0.126, cos=0.219), tot_loss_proj:2.730 [t=0.23s]
prediction: ['[CLS] only 71 minutes minutes [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.774 (perp=7.445, rec=0.066, cos=0.218), tot_loss_proj:2.085 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.774 (perp=7.445, rec=0.066, cos=0.218), tot_loss_proj:2.081 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.772 (perp=7.445, rec=0.062, cos=0.220), tot_loss_proj:2.081 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.774 (perp=7.445, rec=0.065, cos=0.220), tot_loss_proj:2.069 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.769 (perp=7.445, rec=0.059, cos=0.221), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.778 (perp=7.445, rec=0.068, cos=0.221), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.769 (perp=7.445, rec=0.062, cos=0.218), tot_loss_proj:2.073 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.777 (perp=7.445, rec=0.067, cos=0.221), tot_loss_proj:2.076 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.777 (perp=7.445, rec=0.067, cos=0.221), tot_loss_proj:2.072 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.780 (perp=7.445, rec=0.069, cos=0.222), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.770 (perp=7.445, rec=0.060, cos=0.222), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.765 (perp=7.445, rec=0.054, cos=0.222), tot_loss_proj:2.072 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.764 (perp=7.445, rec=0.053, cos=0.222), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.771 (perp=7.445, rec=0.061, cos=0.222), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.779 (perp=7.445, rec=0.069, cos=0.222), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.765 (perp=7.445, rec=0.054, cos=0.222), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.773 (perp=7.445, rec=0.063, cos=0.222), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.769 (perp=7.445, rec=0.058, cos=0.222), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.767 (perp=7.445, rec=0.056, cos=0.222), tot_loss_proj:2.072 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.770 (perp=7.445, rec=0.059, cos=0.222), tot_loss_proj:2.068 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=7.445, rec=0.060, cos=0.222), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.764 (perp=7.445, rec=0.053, cos=0.222), tot_loss_proj:2.072 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.783 (perp=7.445, rec=0.072, cos=0.222), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.767 (perp=7.445, rec=0.056, cos=0.222), tot_loss_proj:2.069 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.779 (perp=7.445, rec=0.068, cos=0.222), tot_loss_proj:2.069 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.780 (perp=7.445, rec=0.069, cos=0.222), tot_loss_proj:2.079 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.779 (perp=7.445, rec=0.068, cos=0.222), tot_loss_proj:2.083 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.775 (perp=7.445, rec=0.064, cos=0.222), tot_loss_proj:2.072 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.783 (perp=7.445, rec=0.072, cos=0.222), tot_loss_proj:2.069 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.773 (perp=7.445, rec=0.063, cos=0.222), tot_loss_proj:2.076 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.763 (perp=7.445, rec=0.052, cos=0.222), tot_loss_proj:2.071 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.778 (perp=7.445, rec=0.067, cos=0.222), tot_loss_proj:2.071 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.781 (perp=7.445, rec=0.070, cos=0.222), tot_loss_proj:2.075 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.761 (perp=7.445, rec=0.051, cos=0.222), tot_loss_proj:2.073 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.780 (perp=7.445, rec=0.070, cos=0.222), tot_loss_proj:2.073 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.772 (perp=7.445, rec=0.061, cos=0.222), tot_loss_proj:2.078 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 86.463 | p: 85.590 | r: 87.644
rouge2     | fm: 57.585 | p: 57.450 | r: 57.747
rougeL     | fm: 77.651 | p: 76.896 | r: 78.530
rougeLsum  | fm: 77.425 | p: 76.837 | r: 78.249
r1fm+r2fm = 144.048

input #28 time: 0:09:07 | total time: 4:22:22


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.8995383005864166
highest_index [0]
highest [0.8995383005864166]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8700668215751648 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8561669588088989 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8492873907089233 for ['[CLS] protected leadlto arose ec along sunset pay everywhere county [SEP]']
[Init] best rec loss: 0.8121121525764465 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.7795106172561646 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7741786241531372 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best perm rec loss: 0.7730233669281006 for ['[CLS] apart joyah epicbeat fk crap fork historia extra cape [SEP]']
[Init] best perm rec loss: 0.7718632221221924 for ['[CLS] apart fk fork extra epicbeat joyah cape crap historia [SEP]']
[Init] best perm rec loss: 0.771755039691925 for ['[CLS] cape epic fk crap extrabeat joyah apart fork historia [SEP]']
[Init] best perm rec loss: 0.7705010175704956 for ['[CLS] fork historia epic joyah extra fkbeat crap cape apart [SEP]']
[Init] best perm rec loss: 0.769933819770813 for ['[CLS] epic cape joyah fork historiabeat apart crap fk extra [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.002 (perp=11.781, rec=0.453, cos=0.193), tot_loss_proj:3.470 [t=0.23s]
prediction: ['[CLS] leave fakerdsugh nwa not this american his committee [SEP]']
[ 100/2000] tot_loss=2.684 (perp=11.059, rec=0.296, cos=0.176), tot_loss_proj:3.940 [t=0.23s]
prediction: ['[CLS] believe not windows devi it not it bad not committee [SEP]']
[ 150/2000] tot_loss=1.998 (perp=8.035, rec=0.207, cos=0.185), tot_loss_proj:2.914 [t=0.23s]
prediction: ['[CLS] believe is it evil it not it resident is believed [SEP]']
[ 200/2000] tot_loss=2.037 (perp=8.396, rec=0.175, cos=0.182), tot_loss_proj:3.037 [t=0.23s]
prediction: ['[CLS] believe is it evil it not it resident is believe [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.944 (perp=8.021, rec=0.160, cos=0.180), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] believe is it evil it not it believe is resident [SEP]']
[ 300/2000] tot_loss=2.028 (perp=8.475, rec=0.151, cos=0.182), tot_loss_proj:3.039 [t=0.23s]
prediction: ['[CLS] believe i it evil it not that believe is resident [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.904 (perp=7.950, rec=0.136, cos=0.177), tot_loss_proj:3.054 [t=0.23s]
prediction: ['[CLS] believe old it believed it not that evil is resident [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.600 (perp=6.447, rec=0.130, cos=0.181), tot_loss_proj:3.132 [t=0.23s]
prediction: ['[CLS] i believe it believe. not that evil is resident [SEP]']
[ 450/2000] tot_loss=1.618 (perp=6.530, rec=0.125, cos=0.187), tot_loss_proj:3.119 [t=0.23s]
prediction: ['[CLS] i believe it i. not that evil is resident [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.506 (perp=6.026, rec=0.113, cos=0.188), tot_loss_proj:3.077 [t=0.23s]
prediction: ['[CLS] i believe it. i not that evil is resident [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.406 (perp=5.599, rec=0.102, cos=0.184), tot_loss_proj:3.023 [t=0.23s]
prediction: ['[CLS] i believe it. i not that resident evil is [SEP]']
[ 600/2000] tot_loss=1.400 (perp=5.599, rec=0.097, cos=0.183), tot_loss_proj:3.014 [t=0.23s]
prediction: ['[CLS] i believe it. i not that resident evil is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.386 (perp=5.599, rec=0.085, cos=0.182), tot_loss_proj:3.020 [t=0.23s]
prediction: ['[CLS] i believe it. i not that resident evil is [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.398 (perp=5.632, rec=0.092, cos=0.179), tot_loss_proj:2.775 [t=0.23s]
prediction: ['[CLS] i believe it. i that not resident evil is [SEP]']
[ 750/2000] tot_loss=1.387 (perp=5.632, rec=0.083, cos=0.178), tot_loss_proj:2.776 [t=0.23s]
prediction: ['[CLS] i believe it. i that not resident evil is [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.386 (perp=5.599, rec=0.087, cos=0.179), tot_loss_proj:3.016 [t=0.23s]
prediction: ['[CLS] i believe it. i not that resident evil is [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.652 (perp=5.348, rec=0.310, cos=0.272), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] i believe it is i not that resident evil, [SEP]']
[ 900/2000] tot_loss=1.508 (perp=5.348, rec=0.247, cos=0.191), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] i believe it is i not that resident evil, [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.448 (perp=5.212, rec=0.215, cos=0.191), tot_loss_proj:2.195 [t=0.23s]
prediction: ['[CLS] i believe it is that also not resident evil, [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.356 (perp=4.865, rec=0.197, cos=0.186), tot_loss_proj:2.124 [t=0.23s]
prediction: ['[CLS] i believe that it is also not resident evil, [SEP]']
[1050/2000] tot_loss=1.342 (perp=4.865, rec=0.180, cos=0.190), tot_loss_proj:2.133 [t=0.23s]
prediction: ['[CLS] i believe that it is also not resident evil, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.302 (perp=4.689, rec=0.176, cos=0.189), tot_loss_proj:1.933 [t=0.23s]
prediction: ['[CLS] i also believe that it is not resident evil, [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.434 (perp=5.405, rec=0.171, cos=0.181), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
[1200/2000] tot_loss=1.428 (perp=5.405, rec=0.161, cos=0.186), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.426 (perp=5.405, rec=0.158, cos=0.187), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.421 (perp=5.405, rec=0.153, cos=0.188), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
[1350/2000] tot_loss=1.420 (perp=5.405, rec=0.151, cos=0.188), tot_loss_proj:1.976 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.413 (perp=5.405, rec=0.144, cos=0.188), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.419 (perp=5.405, rec=0.150, cos=0.188), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
[1500/2000] tot_loss=1.407 (perp=5.405, rec=0.138, cos=0.188), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.404 (perp=5.405, rec=0.134, cos=0.188), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.404 (perp=5.405, rec=0.135, cos=0.189), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
[1650/2000] tot_loss=1.402 (perp=5.405, rec=0.133, cos=0.189), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.407 (perp=5.405, rec=0.137, cos=0.189), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.398 (perp=5.405, rec=0.128, cos=0.189), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
[1800/2000] tot_loss=1.411 (perp=5.405, rec=0.141, cos=0.189), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.403 (perp=5.405, rec=0.133, cos=0.189), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.398 (perp=5.405, rec=0.128, cos=0.189), tot_loss_proj:1.984 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
[1950/2000] tot_loss=1.401 (perp=5.405, rec=0.131, cos=0.189), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.398 (perp=5.405, rec=0.128, cos=0.189), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] also believe that it is not my resident evil, [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe it. i not that resident evil is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 86.679 | p: 85.684 | r: 87.739
rouge2     | fm: 56.980 | p: 56.883 | r: 57.140
rougeL     | fm: 77.455 | p: 76.780 | r: 78.302
rougeLsum  | fm: 77.195 | p: 76.499 | r: 78.059
r1fm+r2fm = 143.659

input #29 time: 0:09:08 | total time: 4:31:30


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.871105558176117
highest_index [0]
highest [0.871105558176117]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8302841186523438 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.6900761127471924 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.6529802680015564 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6484426259994507 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6474772691726685 for ['[CLS] mom who spent [SEP]']
[Init] best perm rec loss: 0.644134521484375 for ['[CLS] who mom spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.498 (perp=10.102, rec=0.244, cos=0.234), tot_loss_proj:3.739 [t=0.23s]
prediction: ['[CLS] fibilitybility [SEP]']
[ 100/2000] tot_loss=2.254 (perp=9.539, rec=0.118, cos=0.228), tot_loss_proj:2.211 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.208 (perp=9.539, rec=0.071, cos=0.229), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.211 (perp=9.539, rec=0.077, cos=0.226), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.256 (perp=9.539, rec=0.088, cos=0.261), tot_loss_proj:2.203 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.209 (perp=9.539, rec=0.065, cos=0.236), tot_loss_proj:2.211 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.227 (perp=9.539, rec=0.091, cos=0.229), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.208 (perp=9.539, rec=0.064, cos=0.237), tot_loss_proj:2.201 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.194 (perp=9.539, rec=0.046, cos=0.241), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.204 (perp=9.539, rec=0.059, cos=0.237), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.208 (perp=9.539, rec=0.062, cos=0.238), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=2.205 (perp=9.539, rec=0.057, cos=0.240), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.204 (perp=9.539, rec=0.060, cos=0.237), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.213 (perp=9.539, rec=0.064, cos=0.241), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=2.211 (perp=9.539, rec=0.062, cos=0.241), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.204 (perp=9.539, rec=0.057, cos=0.240), tot_loss_proj:2.215 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.207 (perp=9.539, rec=0.059, cos=0.241), tot_loss_proj:2.213 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=2.203 (perp=9.539, rec=0.055, cos=0.241), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.202 (perp=9.539, rec=0.053, cos=0.241), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=2.205 (perp=9.539, rec=0.060, cos=0.238), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=2.210 (perp=9.539, rec=0.062, cos=0.240), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=2.212 (perp=9.539, rec=0.063, cos=0.241), tot_loss_proj:2.207 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.200 (perp=9.539, rec=0.052, cos=0.240), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=2.206 (perp=9.539, rec=0.059, cos=0.239), tot_loss_proj:2.216 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=2.207 (perp=9.539, rec=0.058, cos=0.240), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=2.219 (perp=9.539, rec=0.071, cos=0.240), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=2.203 (perp=9.539, rec=0.055, cos=0.241), tot_loss_proj:2.207 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.212 (perp=9.539, rec=0.063, cos=0.241), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=2.213 (perp=9.539, rec=0.064, cos=0.241), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.211 (perp=9.539, rec=0.062, cos=0.241), tot_loss_proj:2.205 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=2.204 (perp=9.539, rec=0.055, cos=0.241), tot_loss_proj:2.207 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=2.207 (perp=9.539, rec=0.059, cos=0.241), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=2.207 (perp=9.539, rec=0.060, cos=0.239), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=2.195 (perp=9.539, rec=0.047, cos=0.240), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.202 (perp=9.539, rec=0.054, cos=0.241), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=2.210 (perp=9.539, rec=0.061, cos=0.241), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.201 (perp=9.539, rec=0.053, cos=0.241), tot_loss_proj:2.215 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=2.209 (perp=9.539, rec=0.060, cos=0.241), tot_loss_proj:2.211 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=2.217 (perp=9.539, rec=0.068, cos=0.241), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=2.204 (perp=9.539, rec=0.055, cos=0.241), tot_loss_proj:2.205 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.137 | p: 86.249 | r: 88.188
rouge2     | fm: 58.585 | p: 58.484 | r: 58.731
rougeL     | fm: 78.101 | p: 77.457 | r: 78.913
rougeLsum  | fm: 77.898 | p: 77.269 | r: 78.709
r1fm+r2fm = 145.722

input #30 time: 0:09:06 | total time: 4:40:37


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9001631420065341
highest_index [0]
highest [0.9001631420065341]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8848101496696472 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.820710301399231 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8145573735237122 for ['[CLS] song spectators then [SEP]']
[Init] best rec loss: 0.811718225479126 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.7793372869491577 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7784581780433655 for ['[CLS] lil number belmont [SEP]']
[Init] best rec loss: 0.7678128480911255 for ['[CLS] lad crossing all [SEP]']
[Init] best rec loss: 0.7658048868179321 for ['[CLS] golf rollichi [SEP]']
[Init] best rec loss: 0.7439934611320496 for ['[CLS] lighthouse peace case [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.248 (perp=9.046, rec=0.251, cos=0.187), tot_loss_proj:2.607 [t=0.23s]
prediction: ['[CLS] better cooper vehicle [SEP]']
[ 100/2000] tot_loss=2.273 (perp=9.658, rec=0.154, cos=0.187), tot_loss_proj:2.504 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.253 (perp=9.658, rec=0.133, cos=0.188), tot_loss_proj:2.499 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 200/2000] tot_loss=2.623 (perp=11.600, rec=0.120, cos=0.183), tot_loss_proj:3.774 [t=0.23s]
prediction: ['[CLS] better an vehicle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.478 (perp=10.760, rec=0.142, cos=0.184), tot_loss_proj:3.168 [t=0.23s]
prediction: ['[CLS] nearly better vehicle [SEP]']
[ 300/2000] tot_loss=2.473 (perp=10.760, rec=0.141, cos=0.180), tot_loss_proj:3.152 [t=0.23s]
prediction: ['[CLS] nearly better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.318 (perp=10.061, rec=0.118, cos=0.188), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] an better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.309 (perp=10.061, rec=0.109, cos=0.188), tot_loss_proj:2.333 [t=0.24s]
prediction: ['[CLS] an better vehicle [SEP]']
[ 450/2000] tot_loss=1.812 (perp=7.603, rec=0.105, cos=0.187), tot_loss_proj:1.817 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.822 (perp=7.603, rec=0.113, cos=0.189), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.792 (perp=7.603, rec=0.085, cos=0.186), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.772 (perp=7.603, rec=0.064, cos=0.187), tot_loss_proj:1.792 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.766 (perp=7.603, rec=0.057, cos=0.189), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.774 (perp=7.603, rec=0.064, cos=0.189), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.775 (perp=7.603, rec=0.065, cos=0.189), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.786 (perp=7.603, rec=0.076, cos=0.190), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.765 (perp=7.603, rec=0.057, cos=0.187), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.773 (perp=7.603, rec=0.064, cos=0.189), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.768 (perp=7.603, rec=0.058, cos=0.189), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.766 (perp=7.603, rec=0.057, cos=0.189), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.783 (perp=7.603, rec=0.073, cos=0.190), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.763 (perp=7.603, rec=0.053, cos=0.189), tot_loss_proj:1.824 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.769 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.781 (perp=7.603, rec=0.071, cos=0.189), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.771 (perp=7.603, rec=0.061, cos=0.189), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.770 (perp=7.603, rec=0.060, cos=0.189), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.765 (perp=7.603, rec=0.055, cos=0.189), tot_loss_proj:1.794 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.768 (perp=7.603, rec=0.058, cos=0.189), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.773 (perp=7.603, rec=0.063, cos=0.189), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=7.603, rec=0.058, cos=0.189), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.776 (perp=7.603, rec=0.066, cos=0.189), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.775 (perp=7.603, rec=0.065, cos=0.189), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.771 (perp=7.603, rec=0.061, cos=0.189), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.770 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.782 (perp=7.603, rec=0.072, cos=0.189), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.780 (perp=7.603, rec=0.070, cos=0.189), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.477 | p: 86.654 | r: 88.622
rouge2     | fm: 59.876 | p: 59.760 | r: 60.006
rougeL     | fm: 78.847 | p: 78.225 | r: 79.633
rougeLsum  | fm: 78.684 | p: 78.102 | r: 79.471
r1fm+r2fm = 147.354

input #31 time: 0:09:06 | total time: 4:49:43


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.8062384202987993
highest_index [0]
highest [0.8062384202987993]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9192174077033997 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.916033923625946 for ['[CLS] actver⋅ bond dimebruck nocus " happy california marine [SEP]']
[Init] best rec loss: 0.9066216945648193 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9053809642791748 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8978495001792908 for ['[CLS] metriety general newcious would varies stretchaneous jesus spurs alliance [SEP]']
[Init] best rec loss: 0.883175790309906 for ['[CLS] sub trials milk park casual two emma pocket breed against defending tenor [SEP]']
[Init] best rec loss: 0.8702411651611328 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8659924268722534 for ['[CLS] between mud let unanimous lips ″ gods baptism inclination forth airport alongside [SEP]']
[Init] best perm rec loss: 0.86571204662323 for ['[CLS] unanimous alongside forth baptism inclination between lips airport gods mud ″ let [SEP]']
[Init] best perm rec loss: 0.86461341381073 for ['[CLS] alongside unanimous between mud baptism forth airport lips inclination ″ let gods [SEP]']
[Init] best perm rec loss: 0.863536536693573 for ['[CLS] gods mud unanimous baptism airport forth ″ inclination let alongside lips between [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.306 (perp=13.288, rec=0.315, cos=0.333), tot_loss_proj:4.072 [t=0.23s]
prediction: ['[CLS] strongct communicate easily world innate visit divert consistent creating accessible information [SEP]']
[ 100/2000] tot_loss=2.836 (perp=11.132, rec=0.263, cos=0.347), tot_loss_proj:3.431 [t=0.23s]
prediction: ['[CLS] easily resonate easily story instinctively accessible pull together creating accessible information [SEP]']
[ 150/2000] tot_loss=2.889 (perp=11.553, rec=0.236, cos=0.342), tot_loss_proj:3.732 [t=0.23s]
prediction: ['[CLS] easilyonateonate easily stories immediately stories pullonate allowing accessible stories [SEP]']
[ 200/2000] tot_loss=2.521 (perp=9.933, rec=0.190, cos=0.344), tot_loss_proj:3.215 [t=0.23s]
prediction: ['[CLS] easily resonate easily stories immediately stories pullonate with accessible stories [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.281 (perp=8.805, rec=0.176, cos=0.344), tot_loss_proj:2.929 [t=0.23s]
prediction: ['[CLS] stories easily resonate easily stories reaching pull together with accessible stories [SEP]']
[ 300/2000] tot_loss=2.151 (perp=8.193, rec=0.168, cos=0.344), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] stories easily resonate easily stories immediately pull together with accessible stories [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.206 (perp=8.608, rec=0.140, cos=0.345), tot_loss_proj:2.783 [t=0.23s]
prediction: ['[CLS] stories easily resonate with storiesund pull together easily accessible stories [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.139 (perp=8.293, rec=0.136, cos=0.345), tot_loss_proj:2.821 [t=0.23s]
prediction: ['[CLS] stories easily resonate with stories easily pull togetherund accessible stories [SEP]']
[ 450/2000] tot_loss=2.134 (perp=8.293, rec=0.131, cos=0.344), tot_loss_proj:2.823 [t=0.23s]
prediction: ['[CLS] stories easily resonate with stories easily pull togetherund accessible stories [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.117 (perp=8.293, rec=0.114, cos=0.345), tot_loss_proj:2.830 [t=0.23s]
prediction: ['[CLS] stories easily resonate with stories easily pull togetherund accessible stories [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.117 (perp=8.293, rec=0.113, cos=0.346), tot_loss_proj:2.829 [t=0.23s]
prediction: ['[CLS] stories easily resonate with stories easily pull togetherund accessible stories [SEP]']
[ 600/2000] tot_loss=2.243 (perp=8.948, rec=0.107, cos=0.346), tot_loss_proj:2.960 [t=0.23s]
prediction: ['[CLS] together easily resonate with stories easily pull togetherund accessible stories [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.236 (perp=8.948, rec=0.100, cos=0.347), tot_loss_proj:2.965 [t=0.23s]
prediction: ['[CLS] together easily resonate with stories easily pull togetherund accessible stories [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.232 (perp=8.948, rec=0.094, cos=0.348), tot_loss_proj:2.969 [t=0.23s]
prediction: ['[CLS] together easily resonate with stories easily pull togetherund accessible stories [SEP]']
[ 750/2000] tot_loss=2.581 (perp=10.718, rec=0.090, cos=0.347), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] together easily resonate with prof easily pull togetherund accessible stories [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.459 (perp=10.119, rec=0.087, cos=0.348), tot_loss_proj:3.356 [t=0.23s]
prediction: ['[CLS] together easily resonate with prof pull easily togetherund accessible stories [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.462 (perp=10.119, rec=0.090, cos=0.348), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] together easily resonate with prof pull easily togetherund accessible stories [SEP]']
[ 900/2000] tot_loss=2.584 (perp=10.722, rec=0.091, cos=0.348), tot_loss_proj:3.678 [t=0.23s]
prediction: ['[CLS] together easily resonate with prof pull easilyityund accessible stories [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.402 (perp=9.877, rec=0.079, cos=0.348), tot_loss_proj:3.462 [t=0.23s]
prediction: ['[CLS] together easily resonate with prof pull easily accessibleundity stories [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.197 (perp=8.678, rec=0.115, cos=0.347), tot_loss_proj:2.973 [t=0.23s]
prediction: ['[CLS] together easily resonate with pull easily accessible profundity stories [SEP]']
[1050/2000] tot_loss=2.301 (perp=9.347, rec=0.083, cos=0.348), tot_loss_proj:3.112 [t=0.23s]
prediction: ['[CLS] together easily resonate with pulltiv accessible profundity stories [SEP]']
Attempt swap
Put prefix at the end
[1100/2000] tot_loss=2.147 (perp=8.595, rec=0.081, cos=0.348), tot_loss_proj:2.827 [t=0.23s]
prediction: ['[CLS] stories together easily resonate with pulltiv accessible profundity [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.126 (perp=8.499, rec=0.077, cos=0.349), tot_loss_proj:2.855 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pulltiv accessible profundity [SEP]']
[1200/2000] tot_loss=2.135 (perp=8.499, rec=0.087, cos=0.349), tot_loss_proj:2.857 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pulltiv accessible profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.124 (perp=8.499, rec=0.076, cos=0.349), tot_loss_proj:2.853 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pulltiv accessible profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.070 (perp=8.218, rec=0.078, cos=0.349), tot_loss_proj:2.800 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
[1350/2000] tot_loss=2.067 (perp=8.218, rec=0.074, cos=0.349), tot_loss_proj:2.803 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.070 (perp=8.218, rec=0.078, cos=0.349), tot_loss_proj:2.801 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.072 (perp=8.218, rec=0.079, cos=0.349), tot_loss_proj:2.806 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
[1500/2000] tot_loss=2.062 (perp=8.218, rec=0.069, cos=0.349), tot_loss_proj:2.802 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.069 (perp=8.218, rec=0.076, cos=0.349), tot_loss_proj:2.805 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.069 (perp=8.218, rec=0.076, cos=0.349), tot_loss_proj:2.804 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
[1650/2000] tot_loss=2.058 (perp=8.218, rec=0.065, cos=0.349), tot_loss_proj:2.799 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.072 (perp=8.218, rec=0.079, cos=0.349), tot_loss_proj:2.802 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.059 (perp=8.218, rec=0.067, cos=0.349), tot_loss_proj:2.800 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
[1800/2000] tot_loss=2.061 (perp=8.218, rec=0.068, cos=0.349), tot_loss_proj:2.802 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.065 (perp=8.218, rec=0.072, cos=0.349), tot_loss_proj:2.806 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.067 (perp=8.218, rec=0.074, cos=0.349), tot_loss_proj:2.804 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
[1950/2000] tot_loss=2.064 (perp=8.218, rec=0.071, cos=0.349), tot_loss_proj:2.808 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.066 (perp=8.218, rec=0.073, cos=0.349), tot_loss_proj:2.808 [t=0.23s]
prediction: ['[CLS] together stories easily resonate with pull res accessible profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] together stories easily resonate with pull res accessible profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 87.537 | p: 86.733 | r: 88.534
rouge2     | fm: 58.933 | p: 58.887 | r: 59.065
rougeL     | fm: 78.191 | p: 77.601 | r: 79.025
rougeLsum  | fm: 78.300 | p: 77.662 | r: 79.082
r1fm+r2fm = 146.470

input #32 time: 0:09:07 | total time: 4:58:51


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.8600729077074931
highest_index [0]
highest [0.8600729077074931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9755745530128479 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8364646434783936 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8359479308128357 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.7690913081169128 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7533591985702515 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7344409227371216 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7300316691398621 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7265579104423523 for ['[CLS] railroad [SEP]']
[Init] best rec loss: 0.6977664232254028 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.6577978134155273 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.622 (perp=11.231, rec=0.117, cos=0.259), tot_loss_proj:2.692 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.572 (perp=11.231, rec=0.066, cos=0.260), tot_loss_proj:2.605 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.579 (perp=11.231, rec=0.073, cos=0.260), tot_loss_proj:2.602 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.564 (perp=11.231, rec=0.060, cos=0.258), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.569 (perp=11.231, rec=0.064, cos=0.259), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.573 (perp=11.231, rec=0.066, cos=0.260), tot_loss_proj:2.600 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.560 (perp=11.231, rec=0.054, cos=0.260), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.580 (perp=11.231, rec=0.074, cos=0.260), tot_loss_proj:2.614 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.566 (perp=11.231, rec=0.059, cos=0.260), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.579 (perp=11.231, rec=0.076, cos=0.257), tot_loss_proj:2.607 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.567 (perp=11.231, rec=0.063, cos=0.258), tot_loss_proj:2.604 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.553 (perp=11.231, rec=0.047, cos=0.260), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.584 (perp=11.231, rec=0.078, cos=0.260), tot_loss_proj:2.609 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.561 (perp=11.231, rec=0.055, cos=0.260), tot_loss_proj:2.616 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.577 (perp=11.231, rec=0.070, cos=0.260), tot_loss_proj:2.592 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.546 (perp=11.231, rec=0.040, cos=0.260), tot_loss_proj:2.608 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.574 (perp=11.231, rec=0.067, cos=0.260), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.565 (perp=11.231, rec=0.059, cos=0.260), tot_loss_proj:2.598 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.564 (perp=11.231, rec=0.058, cos=0.260), tot_loss_proj:2.606 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.563 (perp=11.231, rec=0.057, cos=0.260), tot_loss_proj:2.606 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.553 (perp=11.231, rec=0.047, cos=0.260), tot_loss_proj:2.607 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.583 (perp=11.231, rec=0.077, cos=0.260), tot_loss_proj:2.594 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.575 (perp=11.231, rec=0.069, cos=0.260), tot_loss_proj:2.600 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.572 (perp=11.231, rec=0.065, cos=0.260), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.564 (perp=11.231, rec=0.058, cos=0.260), tot_loss_proj:2.604 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.558 (perp=11.231, rec=0.052, cos=0.260), tot_loss_proj:2.620 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.567 (perp=11.231, rec=0.061, cos=0.260), tot_loss_proj:2.597 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.568 (perp=11.231, rec=0.062, cos=0.260), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.560 (perp=11.231, rec=0.055, cos=0.259), tot_loss_proj:2.604 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.576 (perp=11.231, rec=0.070, cos=0.260), tot_loss_proj:2.605 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.573 (perp=11.231, rec=0.066, cos=0.260), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.553 (perp=11.231, rec=0.046, cos=0.260), tot_loss_proj:2.589 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.572 (perp=11.231, rec=0.065, cos=0.260), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.574 (perp=11.231, rec=0.067, cos=0.260), tot_loss_proj:2.606 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.556 (perp=11.231, rec=0.049, cos=0.260), tot_loss_proj:2.628 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.564 (perp=11.231, rec=0.057, cos=0.260), tot_loss_proj:2.604 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.561 (perp=11.231, rec=0.055, cos=0.260), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.593 (perp=11.231, rec=0.087, cos=0.260), tot_loss_proj:2.607 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.568 (perp=11.231, rec=0.062, cos=0.260), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.564 (perp=11.231, rec=0.057, cos=0.260), tot_loss_proj:2.608 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.693 | p: 86.888 | r: 88.716
rouge2     | fm: 59.959 | p: 59.831 | r: 60.068
rougeL     | fm: 78.818 | p: 78.263 | r: 79.583
rougeLsum  | fm: 78.721 | p: 78.146 | r: 79.529
r1fm+r2fm = 147.652

input #33 time: 0:09:00 | total time: 5:07:51


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.8269665502505079
highest_index [0]
highest [0.8269665502505079]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8663134574890137 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8615774512290955 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8514212369918823 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.7921451926231384 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.7715184688568115 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7529025673866272 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.7279881834983826 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7264242172241211 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.7255047559738159 for ['[CLS]ibe lissa field worth founder along ship statue driversask slight who okay [SEP]']
[Init] best perm rec loss: 0.724553644657135 for ['[CLS] slight lissaask ship drivers worth okay who statueibe along founder field [SEP]']
[Init] best perm rec loss: 0.7244176268577576 for ['[CLS] slight lissa alongibe okay drivers statue fieldask ship worth founder who [SEP]']
[Init] best perm rec loss: 0.7225678563117981 for ['[CLS] okay lissa slight along whoask drivers ship statue founder worth fieldibe [SEP]']
[Init] best perm rec loss: 0.7204803824424744 for ['[CLS] alongibe slightask founder who lissa statue ship field worth drivers okay [SEP]']
[Init] best perm rec loss: 0.720477283000946 for ['[CLS]ibe whoask statue slight okay along founder lissa field ship drivers worth [SEP]']
[Init] best perm rec loss: 0.7200827598571777 for ['[CLS]ibe slight okayask along statue lissa field founder worth who drivers ship [SEP]']
[Init] best perm rec loss: 0.719726026058197 for ['[CLS] along founder okay slight ship who driversask worth statue lissa fieldibe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.250 (perp=12.711, rec=0.382, cos=0.326), tot_loss_proj:3.758 [t=0.23s]
prediction: ['[CLS] defiant urgency reach jessie kim family extreme attack technical extreme become power such [SEP]']
[ 100/2000] tot_loss=2.355 (perp=9.371, rec=0.197, cos=0.284), tot_loss_proj:3.210 [t=0.23s]
prediction: ['[CLS] urgency urgency build viewers : and extreme take extreme extreme take urgency. [SEP]']
[ 150/2000] tot_loss=2.210 (perp=8.771, rec=0.152, cos=0.304), tot_loss_proj:3.142 [t=0.23s]
prediction: ['[CLS] urgency urgency build viewer : the extreme take extreme extreme take urgency. [SEP]']
[ 200/2000] tot_loss=2.338 (perp=9.532, rec=0.119, cos=0.313), tot_loss_proj:3.088 [t=0.23s]
prediction: ['[CLS] urgency urgency build viewer mind the extreme take extreme on take urgency. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.049 (perp=8.126, rec=0.114, cos=0.309), tot_loss_proj:2.804 [t=0.23s]
prediction: ['[CLS] mind urgency build viewer in the extreme take extreme on mind urgency. [SEP]']
[ 300/2000] tot_loss=2.030 (perp=8.122, rec=0.093, cos=0.312), tot_loss_proj:2.737 [t=0.23s]
prediction: ['[CLS] mind urgency build viewer and the extreme take extreme on mind urgency. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.880 (perp=7.406, rec=0.096, cos=0.303), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] mind urgency build viewer and the extreme extreme take on mind urgency. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.871 (perp=7.196, rec=0.115, cos=0.317), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] extreme urgency build viewer and the extreme mind take on mind urgency. [SEP]']
[ 450/2000] tot_loss=1.857 (perp=7.196, rec=0.107, cos=0.311), tot_loss_proj:2.339 [t=0.23s]
prediction: ['[CLS] extreme urgency build viewer and the extreme mind take on mind urgency. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.858 (perp=7.196, rec=0.109, cos=0.310), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] extreme urgency build viewer and the extreme mind take on mind urgency. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.789 (perp=6.917, rec=0.098, cos=0.308), tot_loss_proj:2.097 [t=0.23s]
prediction: ['[CLS] extreme urgency build viewer and the mind mind take on extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.778 (perp=6.917, rec=0.088, cos=0.307), tot_loss_proj:2.096 [t=0.23s]
prediction: ['[CLS] extreme urgency build viewer and the mind mind take on extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.738 (perp=6.756, rec=0.078, cos=0.308), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] extreme urgency build viewer and mind the mind take on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.743 (perp=6.631, rec=0.107, cos=0.309), tot_loss_proj:2.157 [t=0.23s]
prediction: ['[CLS] extreme urgency viewer and mind build the mind take on extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.713 (perp=6.631, rec=0.079, cos=0.308), tot_loss_proj:2.151 [t=0.23s]
prediction: ['[CLS] extreme urgency viewer and mind build the mind take on extreme urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.716 (perp=6.631, rec=0.077, cos=0.313), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] extreme urgency viewer and mind build the mind take on extreme urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.849 (perp=7.283, rec=0.081, cos=0.312), tot_loss_proj:2.229 [t=0.23s]
prediction: ['[CLS] extreme in viewer and of build the mind take on extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.847 (perp=7.283, rec=0.078, cos=0.312), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS] extreme in viewer and of build the mind take on extreme urgency. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.810 (perp=7.109, rec=0.079, cos=0.309), tot_loss_proj:2.172 [t=0.23s]
prediction: ['[CLS] in extreme viewer and of build the mind take on extreme urgency. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.717 (perp=6.645, rec=0.080, cos=0.308), tot_loss_proj:2.067 [t=0.23s]
prediction: ['[CLS] in extreme viewer and build of the mind take on extreme urgency. [SEP]']
[1050/2000] tot_loss=1.721 (perp=6.645, rec=0.077, cos=0.315), tot_loss_proj:2.059 [t=0.23s]
prediction: ['[CLS] in extreme viewer and build of the mind take on extreme urgency. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.640 (perp=6.236, rec=0.081, cos=0.312), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.647 (perp=6.236, rec=0.086, cos=0.314), tot_loss_proj:1.921 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
[1200/2000] tot_loss=1.631 (perp=6.236, rec=0.074, cos=0.310), tot_loss_proj:1.916 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.641 (perp=6.236, rec=0.080, cos=0.314), tot_loss_proj:1.912 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.630 (perp=6.236, rec=0.072, cos=0.312), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
[1350/2000] tot_loss=1.643 (perp=6.236, rec=0.081, cos=0.315), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.639 (perp=6.236, rec=0.076, cos=0.316), tot_loss_proj:1.916 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.648 (perp=6.236, rec=0.087, cos=0.314), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
[1500/2000] tot_loss=1.638 (perp=6.236, rec=0.075, cos=0.316), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.645 (perp=6.236, rec=0.084, cos=0.314), tot_loss_proj:1.920 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.645 (perp=6.236, rec=0.082, cos=0.315), tot_loss_proj:1.918 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
[1650/2000] tot_loss=1.648 (perp=6.236, rec=0.088, cos=0.313), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.635 (perp=6.236, rec=0.073, cos=0.315), tot_loss_proj:1.916 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.634 (perp=6.236, rec=0.073, cos=0.313), tot_loss_proj:1.920 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
[1800/2000] tot_loss=1.650 (perp=6.236, rec=0.088, cos=0.315), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.632 (perp=6.236, rec=0.069, cos=0.316), tot_loss_proj:1.924 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.635 (perp=6.236, rec=0.073, cos=0.314), tot_loss_proj:1.923 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
[1950/2000] tot_loss=1.638 (perp=6.236, rec=0.075, cos=0.316), tot_loss_proj:1.909 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.629 (perp=6.236, rec=0.068, cos=0.315), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] in the extreme viewer and build of mind take on extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 92.857 | r: 92.857
rouge2     | fm: 46.154 | p: 46.154 | r: 46.154
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 139.011

[Aggregate metrics]:
rouge1     | fm: 87.887 | p: 87.152 | r: 88.871
rouge2     | fm: 59.500 | p: 59.396 | r: 59.589
rougeL     | fm: 78.687 | p: 78.206 | r: 79.411
rougeLsum  | fm: 78.607 | p: 78.036 | r: 79.297
r1fm+r2fm = 147.387

input #34 time: 0:09:07 | total time: 5:16:58


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.8073943478139856
highest_index [0]
highest [0.8073943478139856]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.8730051517486572 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8619230389595032 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.8486067652702332 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.8479855060577393 for ['[CLS] comet labour saying grant ai rear loss o point open misses trip pyramid offer tone counter revenge coach discovery gr random air have bay ban specific lal charge bright armistice involved jagger " bid cswoman pay eastwood continuation voyage lynn? [SEP]']
[Init] best rec loss: 0.8449650406837463 for ['[CLS]work pun preserved bloodngen staff alivement ocean potter chest km² issue shares 978 lotsorestation jungle lastcript privately anywhere electric aus staff errortite ticketasian block text horse perennialbiotic fightauworth brothers snow sex cathedral bestseller [SEP]']
[Init] best perm rec loss: 0.8443001508712769 for ['[CLS] cathedral snow aus shares text fight lotsworth electric perennial bestsellercript pun alive ocean staff block sexngenment blood anywhere horse privately issueworkbioticasian preserved jungle 978 ticket staff brothers chest last pottertite error km²auorestation [SEP]']
[Init] best perm rec loss: 0.84121173620224 for ['[CLS] lotsngen ticket errorasian texttite block electricwork issue ausau fight sex brothers anywhere 978 last horse oceanworthorestation pun privately snow km² cathedral perennial bestseller alive staff potter blood preservedcriptment shares jungle chestbiotic staff [SEP]']
[Init] best perm rec loss: 0.8406714200973511 for ['[CLS] alivework electric errorasian anywhere lots bestseller issue brothers stafftiteworth km² blood pun last 978 potterment chestcript jungle aus privately ocean horse preserved snow stafforestation ticket sex perennial sharesngen blockbioticau text cathedral fight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.001 (perp=11.528, rec=0.355, cos=0.341), tot_loss_proj:4.158 [t=0.23s]
prediction: ["[CLS] rudd who means excellent be escapes deal extinct,. seat • act private research what st exclusion greatest especially reiis paul james the became canada directed great greatest'lift how north museum special carteruss 1982 ratedicient quality [SEP]"]
[ 100/2000] tot_loss=3.096 (perp=11.840, rec=0.384, cos=0.344), tot_loss_proj:4.204 [t=0.24s]
prediction: ['[CLS] anymore ( great slipped the ) wing property ; ¨ peopleinus - revolves research cold of danny greatest [CLS] rats《 general april the succeeded galleries western great great generally care about visitor instruction concerning presumably countless finn lessicient training [SEP]']
[ 150/2000] tot_loss=2.986 (perp=11.770, rec=0.299, cos=0.333), tot_loss_proj:4.196 [t=0.24s]
prediction: ["[CLS] anymore ( great beennsor ) wing '. { gown aspectdo of director 耳 of danny 2015 but logan《 general neil our added director western great great make care about incarnation teacher concerning help dependent irs recent especially secret [SEP]"]
[ 200/2000] tot_loss=2.752 (perp=10.728, rec=0.261, cos=0.346), tot_loss_proj:3.603 [t=0.24s]
prediction: ['[CLS]placed ( of thosenation ) wing as, before court aspect / of director 耳 of danny surge but logan《 general neil we expanded us world great great make care aboutry teachernation smartphone dependent over recently especially care [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.815 (perp=11.158, rec=0.242, cos=0.342), tot_loss_proj:4.102 [t=0.24s]
prediction: ["[CLS] horizon (, havenation ) wing -, before gown hello / 辶 director of'wolfenation but logan《 general ron we help us world greatest great makes care is sherwood teachernation borrow greatest gabriel theicient care [SEP]"]
[ 300/2000] tot_loss=2.809 (perp=11.258, rec=0.214, cos=0.343), tot_loss_proj:4.130 [t=0.24s]
prediction: ["[CLS] horizon., havenation ) deal as, before gown yeah'poetry director of'wolfenation but we《 general elimination we help us world greatest greatest makes care beencraft teachernation borrow starting he the nouveau care [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.761 (perp=10.572, rec=0.307, cos=0.339), tot_loss_proj:3.713 [t=0.24s]
prediction: ["[CLS] horizon although, havenation ) wing -, before personality yeah'holy director been'gardnernation but weis general paige us help us world greatest greatest makes care ofnation teachernation help starting. thecarbon research [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.744 (perp=10.695, rec=0.263, cos=0.342), tot_loss_proj:3.588 [t=0.24s]
prediction: ["[CLS] addition., have [SEP] when has 止 et, before han sorts landscape benjamin director was'r but heis general millions us greg us this greatest greatest makes care whilensor teacher greatest help owe barack the maneuver research [SEP]"]
[ 450/2000] tot_loss=2.613 (perp=10.227, rec=0.228, cos=0.339), tot_loss_proj:3.425 [t=0.24s]
prediction: ["[CLS] husband., have [SEP] when has 止 in, before gable well'benjamin director was'版 but.ed general paige us also us recent greatest greatest makes care '章 teacher greatest help owe garion with tonight research [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.711 (perp=10.826, rec=0.206, cos=0.340), tot_loss_proj:3.918 [t=0.24s]
prediction: ["[CLS]ill., have [SEP] when and 止 in, before of well'damaged director was shownation but.ed general paige us assistance us latest greatest greatest makes care '章 teachernation help owenation from tonight research [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.686 (perp=10.537, rec=0.235, cos=0.343), tot_loss_proj:3.837 [t=0.24s]
prediction: ["[CLS] husband. of have hoffman when and 止 in, before of well'received director was shownation but.ed us ron general assistance us latest greatest great makes care 'chenko teachernation given owenivorous from tonight research [SEP]"]
[ 600/2000] tot_loss=2.657 (perp=10.561, rec=0.202, cos=0.343), tot_loss_proj:3.861 [t=0.24s]
prediction: ["[CLS] husband. of have hoffman when and 止 in, before of'' destruction director was shownation but.ed us ron general assistance us latest greatest great makes care'lenses teachernation given owenivorous from tonight research [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.740 (perp=10.566, rec=0.282, cos=0.344), tot_loss_proj:3.894 [t=0.24s]
prediction: ["[CLS] colton, stuff have hoffman the has documentary seen, before'of of the director is personalitytaken but,ed us region general assistance that latest greatest greatest makes care'telescope teacher world apps playernivorous from tonight research [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.695 (perp=10.311, rec=0.288, cos=0.345), tot_loss_proj:3.683 [t=0.24s]
prediction: ["[CLS] colton, figure have hoffman the has disc seen, before ', of god director is personalitytaken but assistanceed us memorable general,'latest greatest greatest makes care'telescope teacher world apps typenivorous from tonight research [SEP]"]
[ 750/2000] tot_loss=2.755 (perp=10.852, rec=0.239, cos=0.345), tot_loss_proj:3.983 [t=0.24s]
prediction: ["[CLS] colton, universal have hoffman of has disc seen, before ', about destruction director s personalitytaken but assistancees us ) general,'latest greatest greatest makes care'seen teachernation apps startingnivorous from tonight research [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.644 (perp=10.382, rec=0.222, cos=0.345), tot_loss_proj:3.884 [t=0.24s]
prediction: ["[CLS] apps, universal have hoffman of has disc seen, before ', about destruction director s personalitytaken but assistancees us ) general,'latest greatest greatest makes care'seen teachernation colton startingnivorous from tonight research [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.568 (perp=10.099, rec=0.202, cos=0.347), tot_loss_proj:3.863 [t=0.24s]
prediction: ["[CLS] apps, universal have hoffman of has responsible seen, before ','general director s voicetaken but assistancees us ) destruction,'latest greatest greatest makes care'seen teachernation colton startingnivorous from tonight research [SEP]"]
[ 900/2000] tot_loss=2.605 (perp=10.238, rec=0.211, cos=0.346), tot_loss_proj:3.856 [t=0.24s]
prediction: ["[CLS] apps, universal have hoffman of has responsible seen, before ','general director s voicetaken but assistancees uspool god,'latest greatest greatest makes care'seen teachernation colton startingnivorous from tonight help [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.628 (perp=10.413, rec=0.200, cos=0.345), tot_loss_proj:3.882 [t=0.24s]
prediction: ["[CLS] apps, universal have maddox of has responsible, seen before ','general director s voicetaken but assistanceed uspool god,'latest greatest greatest makes care'seen teachernation colton startingnivorous from tonight help [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.577 (perp=10.168, rec=0.197, cos=0.346), tot_loss_proj:3.807 [t=0.24s]
prediction: ["[CLS]nation, universal have maddox of has responsible, seen before ','general director s voicetaken but assistanceed uspool god,'latest greatest greatest makes care'seen teacher apps colton startingnivorous from tonight help [SEP]"]
[1050/2000] tot_loss=2.523 (perp=9.906, rec=0.196, cos=0.346), tot_loss_proj:3.770 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox of three responsible, seen before ','general director s voicetaken but assistanceed uspool god,'latest greatest greatest makes care'seen teacher apps colton startingnivorous from tonight help [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.557 (perp=10.092, rec=0.193, cos=0.346), tot_loss_proj:3.828 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox of three responsible, seen before, seen'king director s voicetaken but helpes uspool god,'latest greatest greatest makes care ', teacher apps colton startingnivorous from tonight help [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.506 (perp=9.870, rec=0.187, cos=0.345), tot_loss_proj:3.774 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox the three responsible, seen before, seen'greatest director s voicetaken but helpes uspool god,'latest greatest king makes care ', teacher apps colton startingnivorous from tonight help [SEP]"]
[1200/2000] tot_loss=2.530 (perp=9.994, rec=0.185, cos=0.346), tot_loss_proj:3.823 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox of three responsible, seen before'seen'greatest director s voicetaken but helpes uspool god,'latest greatest king makes care ', teacher apps colton startingnivorous from tonight help [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.470 (perp=9.672, rec=0.190, cos=0.346), tot_loss_proj:3.766 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox of three responsible, seen before help seen'greatest director'voicetaken but helpes uspool god,'latest greatest king makes care ', teacher apps colton startingnivorous from tonight, [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.368 (perp=9.210, rec=0.180, cos=0.346), tot_loss_proj:3.664 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox of three responsible, seen before help seen'greatest director'featuretaken but goded uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight, [SEP]"]
[1350/2000] tot_loss=2.445 (perp=9.573, rec=0.184, cos=0.346), tot_loss_proj:3.742 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox of three disc, seen before help seen'greatest director'featurenation but theed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight'[SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=2.391 (perp=9.353, rec=0.174, cos=0.346), tot_loss_proj:3.688 [t=0.24s]
prediction: ["[CLS]nation. universal have maddox, three disc, seen before help seen'greatest director 'nation but the featureed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight, [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.370 (perp=9.172, rec=0.190, cos=0.346), tot_loss_proj:3.639 [t=0.24s]
prediction: ["[CLS]nation. universalnation maddox the three disc, seen before help seen'greatest director'have but the featureed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight, [SEP]"]
[1500/2000] tot_loss=2.362 (perp=9.195, rec=0.178, cos=0.346), tot_loss_proj:3.637 [t=0.24s]
prediction: ["[CLS]nation. universalnation maddox the three disc, seen before help seen'greatest director'have but the featureed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight'[SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.351 (perp=9.083, rec=0.189, cos=0.346), tot_loss_proj:3.566 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox the three disc, seen before have seen'greatest director'help but the featureed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight'[SEP]"]
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.309 (perp=8.917, rec=0.180, cos=0.346), tot_loss_proj:3.551 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox, three disc, seen before have seen'greatest director help'but the featureed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight'[SEP]"]
[1650/2000] tot_loss=2.312 (perp=8.917, rec=0.182, cos=0.346), tot_loss_proj:3.553 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox, three disc, seen before have seen'greatest director help'but the featureed uspool help,'latest greatest king makes care ', teacher apps colton startingnivorous with tonight'[SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=2.334 (perp=9.059, rec=0.176, cos=0.347), tot_loss_proj:3.498 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox the three disc, seen before have seen'greatest director help'but the featureed uspool help,'latest greatest care king makes ', teacher given colton startingnivorous with tonight'[SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.343 (perp=9.101, rec=0.177, cos=0.346), tot_loss_proj:3.523 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox the three disc, seen before have seen'of director help'but the featureed uspool help,'latest greatest care king makes tonight, teacher given colton startingnivorous with'' [SEP]"]
[1800/2000] tot_loss=2.343 (perp=9.101, rec=0.176, cos=0.346), tot_loss_proj:3.519 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox the three disc, seen before have seen'of director help'but the featureed uspool help,'latest greatest care king makes tonight, teacher given colton startingnivorous with'' [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.340 (perp=9.060, rec=0.182, cos=0.346), tot_loss_proj:3.487 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox the three disc, seen before have seen'greatest director help'but the featureed uspool help,'latest greatest care king makes tonight,'given colton bfnivorous with teacher'[SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.334 (perp=8.969, rec=0.194, cos=0.346), tot_loss_proj:3.513 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox the three disc, seen before have seen'of director help'but the featureed uspool help,'latest greatest care king makes tonight,'given with bfnivorous colton teacher'[SEP]"]
[1950/2000] tot_loss=2.287 (perp=8.813, rec=0.179, cos=0.346), tot_loss_proj:3.502 [t=0.24s]
prediction: ["[CLS]nation about universalnation maddox, three disc, seen before have seen'of director help'but the featureed uspool help,'latest greatest care king makes tonight,'given with bfnivorous colton teacher'[SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.254 (perp=8.620, rec=0.186, cos=0.345), tot_loss_proj:3.497 [t=0.24s]
prediction: ["[CLS]nation with universalnation maddox, three disc, seen before have seen'of director help'but the featureed uspool help,'latest greatest care king makes tonight,'given about bfnivorous colton teacher'[SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS]nation about universalnation maddox the three disc, seen before have seen'greatest director help'but the featureed uspool help,'latest greatest care king makes tonight,'given colton bfnivorous with teacher'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.776 | p: 46.875 | r: 42.857
rouge2     | fm: 3.077 | p: 3.226 | r: 2.941
rougeL     | fm: 26.866 | p: 28.125 | r: 25.714
rougeLsum  | fm: 26.866 | p: 28.125 | r: 25.714
r1fm+r2fm = 47.853

[Aggregate metrics]:
rouge1     | fm: 86.692 | p: 85.954 | r: 87.621
rouge2     | fm: 57.752 | p: 57.663 | r: 57.862
rougeL     | fm: 77.258 | p: 76.736 | r: 77.913
rougeLsum  | fm: 77.171 | p: 76.778 | r: 77.794
r1fm+r2fm = 144.444

input #35 time: 0:09:16 | total time: 5:26:15


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.8863904686543064
highest_index [0]
highest [0.8863904686543064]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9311022162437439 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9192414879798889 for ['[CLS] oscar deep peter ground [SEP]']
[Init] best rec loss: 0.9150270819664001 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.900807797908783 for ['[CLS] addition psychofi astronomer [SEP]']
[Init] best rec loss: 0.8774992227554321 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8707877993583679 for ['[CLS] l explain surveys pieces [SEP]']
[Init] best perm rec loss: 0.8693765997886658 for ['[CLS] surveys explain pieces l [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.453 (perp=10.048, rec=0.230, cos=0.213), tot_loss_proj:3.155 [t=0.23s]
prediction: ['[CLS] wrong wrong horribly wrong [SEP]']
[ 100/2000] tot_loss=2.121 (perp=8.844, rec=0.143, cos=0.210), tot_loss_proj:2.555 [t=0.23s]
prediction: ['[CLS] horribly wrong horribly wrong [SEP]']
[ 150/2000] tot_loss=2.232 (perp=9.687, rec=0.086, cos=0.208), tot_loss_proj:2.428 [t=0.23s]
prediction: ['[CLS] s horribly horribly wrong [SEP]']
[ 200/2000] tot_loss=2.228 (perp=9.687, rec=0.079, cos=0.211), tot_loss_proj:2.434 [t=0.23s]
prediction: ['[CLS] s horribly horribly wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.229 (perp=9.687, rec=0.079, cos=0.213), tot_loss_proj:2.440 [t=0.23s]
prediction: ['[CLS] s horribly horribly wrong [SEP]']
[ 300/2000] tot_loss=2.227 (perp=9.687, rec=0.077, cos=0.213), tot_loss_proj:2.440 [t=0.23s]
prediction: ['[CLS] s horribly horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.213 (perp=9.687, rec=0.064, cos=0.212), tot_loss_proj:2.431 [t=0.23s]
prediction: ['[CLS] s horribly horribly wrong [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.228 (perp=9.687, rec=0.078, cos=0.212), tot_loss_proj:2.443 [t=0.23s]
prediction: ['[CLS] s horribly horribly wrong [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.104, rec=0.054, cos=0.213), tot_loss_proj:2.157 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.902 (perp=8.104, rec=0.068, cos=0.213), tot_loss_proj:2.157 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.907 (perp=8.104, rec=0.072, cos=0.214), tot_loss_proj:2.163 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.898 (perp=8.104, rec=0.063, cos=0.214), tot_loss_proj:2.162 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.894 (perp=8.104, rec=0.060, cos=0.213), tot_loss_proj:2.155 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.896 (perp=8.104, rec=0.061, cos=0.214), tot_loss_proj:2.150 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.883 (perp=8.104, rec=0.048, cos=0.214), tot_loss_proj:2.154 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.880 (perp=8.104, rec=0.045, cos=0.214), tot_loss_proj:2.163 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=8.104, rec=0.057, cos=0.214), tot_loss_proj:2.166 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.898 (perp=8.104, rec=0.063, cos=0.214), tot_loss_proj:2.163 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.901 (perp=8.104, rec=0.066, cos=0.214), tot_loss_proj:2.159 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.886 (perp=8.104, rec=0.051, cos=0.214), tot_loss_proj:2.165 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.891 (perp=8.104, rec=0.056, cos=0.214), tot_loss_proj:2.168 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.892 (perp=8.104, rec=0.057, cos=0.214), tot_loss_proj:2.157 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.884 (perp=8.104, rec=0.049, cos=0.214), tot_loss_proj:2.154 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.890 (perp=8.104, rec=0.055, cos=0.214), tot_loss_proj:2.161 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.904 (perp=8.104, rec=0.069, cos=0.214), tot_loss_proj:2.166 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.895 (perp=8.104, rec=0.060, cos=0.214), tot_loss_proj:2.163 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.894 (perp=8.104, rec=0.059, cos=0.214), tot_loss_proj:2.162 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.898 (perp=8.104, rec=0.063, cos=0.214), tot_loss_proj:2.150 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.899 (perp=8.104, rec=0.064, cos=0.214), tot_loss_proj:2.154 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.887 (perp=8.104, rec=0.053, cos=0.214), tot_loss_proj:2.152 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.908 (perp=8.104, rec=0.073, cos=0.214), tot_loss_proj:2.157 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.894 (perp=8.104, rec=0.059, cos=0.214), tot_loss_proj:2.167 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.896 (perp=8.104, rec=0.062, cos=0.214), tot_loss_proj:2.160 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.890 (perp=8.104, rec=0.055, cos=0.214), tot_loss_proj:2.167 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.891 (perp=8.104, rec=0.056, cos=0.214), tot_loss_proj:2.164 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.896 (perp=8.104, rec=0.062, cos=0.214), tot_loss_proj:2.160 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.907 (perp=8.104, rec=0.072, cos=0.214), tot_loss_proj:2.162 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.884 (perp=8.104, rec=0.049, cos=0.214), tot_loss_proj:2.159 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.892 (perp=8.104, rec=0.057, cos=0.214), tot_loss_proj:2.163 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.914 (perp=8.104, rec=0.079, cos=0.214), tot_loss_proj:2.165 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.081 | p: 86.330 | r: 87.948
rouge2     | fm: 58.775 | p: 58.686 | r: 58.879
rougeL     | fm: 78.043 | p: 77.567 | r: 78.627
rougeLsum  | fm: 77.839 | p: 77.344 | r: 78.464
r1fm+r2fm = 145.856

input #36 time: 0:09:06 | total time: 5:35:21


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.8824299325398293
highest_index [0]
highest [0.8824299325398293]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7986452579498291 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7610136270523071 for ['[CLS] child past [SEP]']
[Init] best rec loss: 0.721915066242218 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.7137036919593811 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7024809122085571 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 0.6421507000923157 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.620604932308197 for ['[CLS] molecule buddhism [SEP]']
[Init] best rec loss: 0.5985401272773743 for ['[CLS] beer city [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.588 (perp=10.822, rec=0.214, cos=0.209), tot_loss_proj:2.637 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.626 (perp=10.822, rec=0.191, cos=0.271), tot_loss_proj:2.643 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.486 (perp=10.822, rec=0.112, cos=0.210), tot_loss_proj:2.640 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 200/2000] tot_loss=2.497 (perp=10.822, rec=0.114, cos=0.219), tot_loss_proj:2.644 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.485 (perp=10.822, rec=0.120, cos=0.201), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 300/2000] tot_loss=2.503 (perp=10.822, rec=0.119, cos=0.220), tot_loss_proj:2.642 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.502 (perp=10.822, rec=0.121, cos=0.217), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.484 (perp=10.822, rec=0.106, cos=0.213), tot_loss_proj:2.648 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 450/2000] tot_loss=2.497 (perp=10.822, rec=0.115, cos=0.218), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.493 (perp=10.822, rec=0.107, cos=0.222), tot_loss_proj:2.644 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.468 (perp=10.822, rec=0.103, cos=0.200), tot_loss_proj:2.649 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 600/2000] tot_loss=2.447 (perp=10.822, rec=0.072, cos=0.211), tot_loss_proj:2.639 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.204 (perp=9.583, rec=0.067, cos=0.221), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.054 (perp=8.916, rec=0.080, cos=0.191), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=2.079 (perp=8.916, rec=0.078, cos=0.218), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.060 (perp=8.916, rec=0.058, cos=0.219), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.065 (perp=8.916, rec=0.062, cos=0.220), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=2.067 (perp=8.916, rec=0.064, cos=0.220), tot_loss_proj:2.213 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.074 (perp=8.916, rec=0.070, cos=0.221), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=2.067 (perp=8.916, rec=0.063, cos=0.221), tot_loss_proj:2.215 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=2.070 (perp=8.916, rec=0.066, cos=0.221), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=2.072 (perp=8.916, rec=0.067, cos=0.221), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=2.065 (perp=8.916, rec=0.060, cos=0.221), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=2.069 (perp=8.916, rec=0.065, cos=0.221), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.080 (perp=8.916, rec=0.075, cos=0.221), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=2.063 (perp=8.916, rec=0.059, cos=0.221), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=2.071 (perp=8.916, rec=0.067, cos=0.221), tot_loss_proj:2.237 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=2.052 (perp=8.916, rec=0.052, cos=0.216), tot_loss_proj:2.222 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=2.070 (perp=8.916, rec=0.067, cos=0.220), tot_loss_proj:2.217 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=2.068 (perp=8.916, rec=0.065, cos=0.220), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=2.082 (perp=8.916, rec=0.077, cos=0.221), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=2.069 (perp=8.916, rec=0.065, cos=0.221), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=2.067 (perp=8.916, rec=0.063, cos=0.221), tot_loss_proj:2.218 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=2.063 (perp=8.916, rec=0.059, cos=0.221), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=2.063 (perp=8.916, rec=0.058, cos=0.221), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=2.078 (perp=8.916, rec=0.074, cos=0.221), tot_loss_proj:2.216 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=2.073 (perp=8.916, rec=0.068, cos=0.221), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=2.054 (perp=8.916, rec=0.049, cos=0.221), tot_loss_proj:2.234 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=2.065 (perp=8.916, rec=0.060, cos=0.221), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=2.071 (perp=8.916, rec=0.067, cos=0.221), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.526 | p: 86.794 | r: 88.371
rouge2     | fm: 57.507 | p: 57.454 | r: 57.620
rougeL     | fm: 77.744 | p: 77.230 | r: 78.419
rougeLsum  | fm: 77.784 | p: 77.275 | r: 78.265
r1fm+r2fm = 145.033

input #37 time: 0:09:03 | total time: 5:44:25


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9003231636065835
highest_index [0]
highest [0.9003231636065835]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8205416798591614 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8201466202735901 for ['[CLS] gone [SEP]']
[Init] best rec loss: 0.8139307498931885 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.7464973330497742 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7451398372650146 for ['[CLS] pack [SEP]']
[Init] best rec loss: 0.7119757533073425 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.692825198173523 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.6907451748847961 for ['[CLS] artificial [SEP]']
[Init] best rec loss: 0.6647939682006836 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.080 (perp=14.070, rec=0.107, cos=0.158), tot_loss_proj:3.062 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=3.039 (perp=14.070, rec=0.050, cos=0.175), tot_loss_proj:3.065 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=3.060 (perp=14.070, rec=0.058, cos=0.188), tot_loss_proj:3.066 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=3.070 (perp=14.070, rec=0.070, cos=0.186), tot_loss_proj:3.075 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.071 (perp=14.070, rec=0.069, cos=0.189), tot_loss_proj:3.069 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=3.064 (perp=14.070, rec=0.063, cos=0.187), tot_loss_proj:3.068 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.064 (perp=14.070, rec=0.062, cos=0.188), tot_loss_proj:3.062 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.047 (perp=14.070, rec=0.056, cos=0.177), tot_loss_proj:3.061 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=3.063 (perp=14.070, rec=0.060, cos=0.189), tot_loss_proj:3.050 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.062 (perp=14.070, rec=0.060, cos=0.188), tot_loss_proj:3.069 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.076 (perp=14.070, rec=0.075, cos=0.187), tot_loss_proj:3.063 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=3.065 (perp=14.070, rec=0.062, cos=0.189), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.056 (perp=14.070, rec=0.062, cos=0.180), tot_loss_proj:3.053 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.070 (perp=14.070, rec=0.067, cos=0.189), tot_loss_proj:3.074 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=3.046 (perp=14.070, rec=0.054, cos=0.178), tot_loss_proj:3.055 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.076 (perp=14.070, rec=0.073, cos=0.189), tot_loss_proj:3.061 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.057 (perp=14.070, rec=0.054, cos=0.189), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=3.062 (perp=14.070, rec=0.060, cos=0.188), tot_loss_proj:3.061 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.052 (perp=14.070, rec=0.049, cos=0.189), tot_loss_proj:3.069 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=3.050 (perp=14.070, rec=0.055, cos=0.181), tot_loss_proj:3.045 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=3.062 (perp=14.070, rec=0.059, cos=0.189), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=3.072 (perp=14.070, rec=0.069, cos=0.189), tot_loss_proj:3.062 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=3.058 (perp=14.070, rec=0.055, cos=0.189), tot_loss_proj:3.078 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=3.060 (perp=14.070, rec=0.058, cos=0.188), tot_loss_proj:3.062 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=3.068 (perp=14.070, rec=0.065, cos=0.189), tot_loss_proj:3.066 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=3.052 (perp=14.070, rec=0.049, cos=0.189), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=3.067 (perp=14.070, rec=0.064, cos=0.189), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=3.057 (perp=14.070, rec=0.053, cos=0.189), tot_loss_proj:3.062 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=3.058 (perp=14.070, rec=0.056, cos=0.188), tot_loss_proj:3.072 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=3.063 (perp=14.070, rec=0.060, cos=0.189), tot_loss_proj:3.060 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=3.063 (perp=14.070, rec=0.059, cos=0.189), tot_loss_proj:3.066 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=3.061 (perp=14.070, rec=0.058, cos=0.189), tot_loss_proj:3.065 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=3.068 (perp=14.070, rec=0.065, cos=0.189), tot_loss_proj:3.068 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=3.065 (perp=14.070, rec=0.062, cos=0.189), tot_loss_proj:3.069 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=3.059 (perp=14.070, rec=0.056, cos=0.189), tot_loss_proj:3.069 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=3.076 (perp=14.070, rec=0.072, cos=0.189), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=3.050 (perp=14.070, rec=0.046, cos=0.189), tot_loss_proj:3.062 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=3.078 (perp=14.070, rec=0.075, cos=0.189), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=3.055 (perp=14.070, rec=0.052, cos=0.189), tot_loss_proj:3.057 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=3.056 (perp=14.070, rec=0.052, cos=0.189), tot_loss_proj:3.064 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.740 | p: 86.998 | r: 88.590
rouge2     | fm: 58.553 | p: 58.440 | r: 58.679
rougeL     | fm: 78.379 | p: 77.924 | r: 79.007
rougeLsum  | fm: 78.236 | p: 77.806 | r: 78.879
r1fm+r2fm = 146.293

input #38 time: 0:08:57 | total time: 5:53:22


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.817803228832678
highest_index [0]
highest [0.817803228832678]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.824012279510498 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.798520565032959 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7905541658401489 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7885178327560425 for ['[CLS] nothing fishery published hall temeraireathing earnest cabinet shame supreme illusions drown men quoteolved formation revenge negativeˈ relief legislature growl melissa silk - [SEP]']
[Init] best rec loss: 0.7512299418449402 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.7483335137367249 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best perm rec loss: 0.7456657886505127 for ['[CLS] led frenchiving harmon wrap aloneoof courtried jarrett fa the local angus baseline vane shortlisted taking look suns shows transportation soon brain meadow [SEP]']
[Init] best perm rec loss: 0.7450541257858276 for ['[CLS]iving meadowried transportation wrap fa alone brain courtoof harmon look baseline the shows soon angus suns vane jarrett french shortlisted taking local led [SEP]']
[Init] best perm rec loss: 0.7449625730514526 for ['[CLS] the transportation frenchoof fa wrap alone soon suns vaneried angus taking led brain court shortlisted meadow shows baseline look harmon jarrett localiving [SEP]']
[Init] best perm rec loss: 0.7443941235542297 for ['[CLS] shows vaneiving french suns wrap taking courtried harmon soonoof brain baseline shortlisted local transportation the look jarrett alone fa angus meadow led [SEP]']
[Init] best perm rec loss: 0.7442662715911865 for ['[CLS] fa shows harmon brain court meadow wrap alone look local suns vane ledivingoof taking transportation the shortlisted angusried soon baseline jarrett french [SEP]']
[Init] best perm rec loss: 0.7432662844657898 for ['[CLS] wrap fa angus alone look soonoofried shortlisted meadow suns harmon transportation french shows court localiving vane taking the jarrett brain led baseline [SEP]']
[Init] best perm rec loss: 0.7431412935256958 for ['[CLS] harmon alone shows transportation meadow shortlistedried taking brain vane jarrett soon fa led local court sunsiving baseline wrap angus the lookoof french [SEP]']
[Init] best perm rec loss: 0.742207944393158 for ['[CLS] wrap local fa suns angus led taking brainiving shortlisted french the soon shows meadow court look baselineoof transportation jarrett alone harmonried vane [SEP]']
[Init] best perm rec loss: 0.7409276962280273 for ['[CLS] baseline taking the look led soon court wrap meadowried shortlisted angus aloneoof fa jarrett french suns transportationiving brain local harmon vane shows [SEP]']
[Init] best perm rec loss: 0.7406561374664307 for ['[CLS] shows shortlisted baseline soon alone jarrett transportation meadow theoof wrapried taking court vane suns local fa harmon angus brain lookiving french led [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.016 (perp=12.005, rec=0.310, cos=0.304), tot_loss_proj:3.347 [t=0.23s]
prediction: ['[CLS] new. adventure suburb architecture find unique spirituality new conservative multi phenomenon conservative new the science new our contemporary sustainability maggie changei texture reach [SEP]']
[ 100/2000] tot_loss=2.808 (perp=11.282, rec=0.240, cos=0.312), tot_loss_proj:3.336 [t=0.23s]
prediction: ['[CLS] new bestseller age thoroughbred quebec find, give more conservative ecole traditions conservative new ; paths new gabby contemporary > reality change, texture texture [SEP]']
[ 150/2000] tot_loss=2.507 (perp=10.010, rec=0.179, cos=0.327), tot_loss_proj:3.779 [t=0.23s]
prediction: ['[CLS] new and movie illegal them find, give most conservative hide traditions conservative new and paths new conservative character new reality research, texture reality [SEP]']
[ 200/2000] tot_loss=2.725 (perp=11.097, rec=0.208, cos=0.297), tot_loss_proj:3.740 [t=0.23s]
prediction: ['[CLS] new andbound illegal them find, give most conservative hide traditions conservative new giving adventure new conservative it new reality bound, texture reality [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.578 (perp=10.670, rec=0.122, cos=0.322), tot_loss_proj:3.453 [t=0.23s]
prediction: ['[CLS] new andbound industry our find, tulane most conservative hide traditions conservative new giving movie new give it new realitybound, texture reality [SEP]']
[ 300/2000] tot_loss=2.575 (perp=10.708, rec=0.109, cos=0.324), tot_loss_proj:3.334 [t=0.23s]
prediction: ['[CLS] new andbound industry our finds, tulane most conservative hide traditions conservative new gives movie new gives it new realitybound, texture reality [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.382 (perp=9.849, rec=0.088, cos=0.324), tot_loss_proj:2.885 [t=0.23s]
prediction: ['[CLS] new and traditions making our finds, attention most conservative hidebound conservative one gives movie new gives it new relevancebound, texture reality [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.362 (perp=9.733, rec=0.089, cos=0.327), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] renowned and traditions making our finds, new most conservative hidebound conservative one gives movie new gives it new relevancebound, texture reality [SEP]']
[ 450/2000] tot_loss=2.260 (perp=9.177, rec=0.096, cos=0.328), tot_loss_proj:2.709 [t=0.23s]
prediction: ['[CLS] renowned and traditions making our finds, new most conservative hidebound conservative one gives movie new gives it new relevance., texture reality [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.102 (perp=8.434, rec=0.089, cos=0.326), tot_loss_proj:2.557 [t=0.24s]
prediction: ['[CLS] renowned new traditions making our finds, and most conservative hidebound conservative one gives movie new gives it new relevance., texture reality [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.041 (perp=8.131, rec=0.091, cos=0.324), tot_loss_proj:2.434 [t=0.23s]
prediction: ['[CLS] finds new traditions making our renowned, and most conservative hidebound conservative one gives movie new gives it new relevance., texture reality [SEP]']
[ 600/2000] tot_loss=2.038 (perp=8.131, rec=0.086, cos=0.326), tot_loss_proj:2.436 [t=0.23s]
prediction: ['[CLS] finds new traditions making our renowned, and most conservative hidebound conservative one gives movie new gives it new relevance., texture reality [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.976 (perp=7.846, rec=0.080, cos=0.327), tot_loss_proj:2.421 [t=0.23s]
prediction: ['[CLS] finds new traditions making our renowned, and most conservative hidebound conservative gives one movie new gives it new relevance., texture reality [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.933 (perp=7.631, rec=0.078, cos=0.329), tot_loss_proj:2.427 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most renowned, and conservative hidebound conservative gives one movie new gives it new relevance., texture reality [SEP]']
[ 750/2000] tot_loss=1.935 (perp=7.631, rec=0.078, cos=0.331), tot_loss_proj:2.430 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most renowned, and conservative hidebound conservative gives one movie new gives it new relevance., texture reality [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.914 (perp=7.549, rec=0.075, cos=0.329), tot_loss_proj:2.323 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most renowned, and conservative hidebound conservative gives one movie new gives it new relevance. reality, texture [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.917 (perp=7.551, rec=0.083, cos=0.324), tot_loss_proj:2.308 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most renowned, and conservative hidebound conservative gives one movie new reality, texture gives it new relevance and [SEP]']
[ 900/2000] tot_loss=1.956 (perp=7.764, rec=0.078, cos=0.326), tot_loss_proj:2.312 [t=0.24s]
prediction: ['[CLS] finds new traditions making our most newly, and conservative hidebound conservative gives one movie new reality, texture gives it new relevance and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.892 (perp=7.423, rec=0.080, cos=0.327), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most newly, and conservative hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1000/2000] tot_loss=1.886 (perp=7.423, rec=0.074, cos=0.328), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most newly, and conservative hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]']
[1050/2000] tot_loss=1.883 (perp=7.423, rec=0.071, cos=0.328), tot_loss_proj:2.239 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most newly, and conservative hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.851 (perp=7.246, rec=0.074, cos=0.328), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most conservative, and newly hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1150/2000] tot_loss=1.846 (perp=7.246, rec=0.068, cos=0.328), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most conservative, and newly hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]']
[1200/2000] tot_loss=1.853 (perp=7.246, rec=0.076, cos=0.328), tot_loss_proj:2.219 [t=0.24s]
prediction: ['[CLS] finds new traditions making our most conservative, and newly hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.808 (perp=7.048, rec=0.070, cos=0.328), tot_loss_proj:2.157 [t=0.24s]
prediction: ['[CLS] finds new traditions making our most conservative, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1300/2000] tot_loss=1.805 (perp=7.048, rec=0.067, cos=0.328), tot_loss_proj:2.158 [t=0.23s]
prediction: ['[CLS] finds new traditions making our most conservative, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
[1350/2000] tot_loss=1.804 (perp=7.048, rec=0.066, cos=0.328), tot_loss_proj:2.159 [t=0.24s]
prediction: ['[CLS] finds new traditions making our most conservative, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.770 (perp=6.816, rec=0.077, cos=0.330), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] making our most conservative finds new traditions, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1450/2000] tot_loss=1.775 (perp=6.816, rec=0.082, cos=0.329), tot_loss_proj:2.109 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
[1500/2000] tot_loss=1.764 (perp=6.816, rec=0.071, cos=0.329), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1550/2000] tot_loss=1.760 (perp=6.816, rec=0.068, cos=0.329), tot_loss_proj:2.103 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1600/2000] tot_loss=1.764 (perp=6.816, rec=0.072, cos=0.329), tot_loss_proj:2.102 [t=0.24s]
prediction: ['[CLS] making our most conservative finds new traditions, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
[1650/2000] tot_loss=1.757 (perp=6.816, rec=0.065, cos=0.329), tot_loss_proj:2.103 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions, conservative and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.755 (perp=6.748, rec=0.076, cos=0.329), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
[1750/2000] tot_loss=1.748 (perp=6.748, rec=0.070, cos=0.329), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
[1800/2000] tot_loss=1.748 (perp=6.748, rec=0.070, cos=0.329), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new reality, and gives it new relevance texture [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.722 (perp=6.610, rec=0.073, cos=0.328), tot_loss_proj:2.089 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new relevance, and gives it new reality texture [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.715 (perp=6.593, rec=0.067, cos=0.330), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new relevance, and gives it new texture reality [SEP]']
[1950/2000] tot_loss=1.709 (perp=6.593, rec=0.062, cos=0.329), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new relevance, and gives it new texture reality [SEP]']
Attempt swap
[2000/2000] tot_loss=1.723 (perp=6.593, rec=0.075, cos=0.329), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] making our most conservative finds new traditions conservative, and newly hidebound gives one movie new relevance, and gives it new texture reality [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] finds new traditions making our most conservative, and newly hidebound conservative gives one movie new reality, and gives it new relevance texture [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.304 | p: 87.500 | r: 95.455
rouge2     | fm: 40.909 | p: 39.130 | r: 42.857
rougeL     | fm: 60.870 | p: 58.333 | r: 63.636
rougeLsum  | fm: 60.870 | p: 58.333 | r: 63.636
r1fm+r2fm = 132.213

[Aggregate metrics]:
rouge1     | fm: 87.819 | p: 87.035 | r: 88.783
rouge2     | fm: 58.300 | p: 58.150 | r: 58.519
rougeL     | fm: 77.866 | p: 77.359 | r: 78.574
rougeLsum  | fm: 77.797 | p: 77.287 | r: 78.448
r1fm+r2fm = 146.119

input #39 time: 0:09:13 | total time: 6:02:36


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.8552809984984366
highest_index [0]
highest [0.8552809984984366]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9473408460617065 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.934070348739624 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9220753908157349 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9166745543479919 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.9001129865646362 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8937766551971436 for ['[CLS] married this walden rhythm being eisenhower school ہ dick [SEP]']
[Init] best rec loss: 0.8907806873321533 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.8869670033454895 for ['[CLS] false christine are greyova juniorola until thieves [SEP]']
[Init] best rec loss: 0.8829766511917114 for ['[CLS] model dr further productive show against decree reaction learning [SEP]']
[Init] best rec loss: 0.877191960811615 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8746487498283386 for ['[CLS] north host jay cd transferred hereʔ scale lower [SEP]']
[Init] best rec loss: 0.8744992613792419 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8731074333190918 for ['[CLS] kincaid wellmet foster turning once old elseyle [SEP]']
[Init] best rec loss: 0.8560328483581543 for ['[CLS] robin hemisphere # worn expensiveisticor wonder arms [SEP]']
[Init] best rec loss: 0.855866014957428 for ['[CLS] survived western baskets tank slow ernie demanding epoch born [SEP]']
[Init] best rec loss: 0.8480786681175232 for ['[CLS] chiefs voluntary turning era repliedfies things brendan central [SEP]']
[Init] best rec loss: 0.8038861155509949 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8036515712738037 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8017597198486328 for ['[CLS] kent abd but many already deciding lady georgian° [SEP]']
[Init] best perm rec loss: 0.8003297448158264 for ['[CLS] georgian many kent deciding but lady° abd already [SEP]']
[Init] best perm rec loss: 0.7987333536148071 for ['[CLS] georgian° but already kent many deciding lady abd [SEP]']
[Init] best perm rec loss: 0.7984358668327332 for ['[CLS] abd georgian many lady° already but deciding kent [SEP]']
[Init] best perm rec loss: 0.7980526685714722 for ['[CLS] already lady georgian° but many deciding kent abd [SEP]']
[Init] best perm rec loss: 0.7971987128257751 for ['[CLS] lady georgian but deciding already° abd many kent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.642 (perp=15.315, rec=0.329, cos=0.250), tot_loss_proj:4.155 [t=0.23s]
prediction: ['[CLS] pig bombardmentmmel videommel pr te half acid [SEP]']
[ 100/2000] tot_loss=3.302 (perp=13.992, rec=0.249, cos=0.255), tot_loss_proj:3.869 [t=0.23s]
prediction: ['[CLS] pu worshipmmelgraphmmel usony dirty imagery [SEP]']
[ 150/2000] tot_loss=2.513 (perp=10.353, rec=0.196, cos=0.247), tot_loss_proj:3.234 [t=0.23s]
prediction: ['[CLS] pu imagerymmel ormmel us withony imagery [SEP]']
[ 200/2000] tot_loss=2.461 (perp=10.353, rec=0.127, cos=0.263), tot_loss_proj:3.227 [t=0.23s]
prediction: ['[CLS] pu imagerymmel ormmel us withony imagery [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.145 (perp=8.878, rec=0.103, cos=0.266), tot_loss_proj:2.933 [t=0.23s]
prediction: ['[CLS] imagerymmel or pummel us withony music [SEP]']
[ 300/2000] tot_loss=2.132 (perp=8.878, rec=0.097, cos=0.260), tot_loss_proj:2.935 [t=0.23s]
prediction: ['[CLS] imagerymmel or pummel us withony music [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.068 (perp=8.601, rec=0.083, cos=0.265), tot_loss_proj:2.958 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony imagery [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.072 (perp=8.601, rec=0.087, cos=0.264), tot_loss_proj:2.965 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony imagery [SEP]']
[ 450/2000] tot_loss=2.078 (perp=8.666, rec=0.079, cos=0.266), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony music [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.088 (perp=8.666, rec=0.087, cos=0.267), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony music [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.076 (perp=8.666, rec=0.079, cos=0.264), tot_loss_proj:3.093 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony music [SEP]']
[ 600/2000] tot_loss=2.078 (perp=8.666, rec=0.081, cos=0.264), tot_loss_proj:3.090 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony music [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.072 (perp=8.666, rec=0.071, cos=0.268), tot_loss_proj:3.089 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us with orony music [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.985 (perp=8.191, rec=0.084, cos=0.262), tot_loss_proj:3.434 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[ 750/2000] tot_loss=1.985 (perp=8.191, rec=0.083, cos=0.265), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.969 (perp=8.191, rec=0.065, cos=0.266), tot_loss_proj:3.453 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.966 (perp=8.191, rec=0.062, cos=0.266), tot_loss_proj:3.439 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[ 900/2000] tot_loss=1.987 (perp=8.191, rec=0.083, cos=0.267), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.980 (perp=8.191, rec=0.075, cos=0.267), tot_loss_proj:3.442 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=8.191, rec=0.081, cos=0.267), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1050/2000] tot_loss=1.985 (perp=8.191, rec=0.079, cos=0.267), tot_loss_proj:3.449 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.983 (perp=8.191, rec=0.077, cos=0.267), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.985 (perp=8.191, rec=0.079, cos=0.267), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1200/2000] tot_loss=1.989 (perp=8.191, rec=0.083, cos=0.268), tot_loss_proj:3.448 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.975 (perp=8.191, rec=0.070, cos=0.268), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.977 (perp=8.191, rec=0.071, cos=0.268), tot_loss_proj:3.441 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1350/2000] tot_loss=1.971 (perp=8.191, rec=0.065, cos=0.268), tot_loss_proj:3.449 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.969 (perp=8.191, rec=0.063, cos=0.268), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.972 (perp=8.191, rec=0.066, cos=0.268), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1500/2000] tot_loss=1.972 (perp=8.191, rec=0.066, cos=0.268), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.962 (perp=8.191, rec=0.056, cos=0.268), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.980 (perp=8.191, rec=0.074, cos=0.268), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1650/2000] tot_loss=1.967 (perp=8.191, rec=0.061, cos=0.268), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.975 (perp=8.191, rec=0.069, cos=0.268), tot_loss_proj:3.447 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.982 (perp=8.191, rec=0.076, cos=0.268), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1800/2000] tot_loss=1.977 (perp=8.191, rec=0.071, cos=0.268), tot_loss_proj:3.445 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.983 (perp=8.191, rec=0.077, cos=0.268), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.975 (perp=8.191, rec=0.069, cos=0.268), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
[1950/2000] tot_loss=1.982 (perp=8.191, rec=0.076, cos=0.268), tot_loss_proj:3.444 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Attempt swap
[2000/2000] tot_loss=1.972 (perp=8.191, rec=0.067, cos=0.268), tot_loss_proj:3.450 [t=0.23s]
prediction: ['[CLS] imagerymmel pummel us orony with music [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagerymmel pummel us orony with music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 75.000 | r: 66.667
rouge2     | fm: 26.667 | p: 28.571 | r: 25.000
rougeL     | fm: 70.588 | p: 75.000 | r: 66.667
rougeLsum  | fm: 70.588 | p: 75.000 | r: 66.667
r1fm+r2fm = 97.255

[Aggregate metrics]:
rouge1     | fm: 87.538 | p: 86.846 | r: 88.278
rouge2     | fm: 57.624 | p: 57.542 | r: 57.722
rougeL     | fm: 77.718 | p: 77.334 | r: 78.170
rougeLsum  | fm: 77.551 | p: 77.185 | r: 78.148
r1fm+r2fm = 145.162

input #40 time: 0:09:05 | total time: 6:11:42


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.8333737116108884
highest_index [0]
highest [0.8333737116108884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.8898334503173828 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.8695713877677917 for ['[CLS] samuel conservation [SEP]']
[Init] best rec loss: 0.863533079624176 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8354475498199463 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 0.7855576872825623 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.7726591229438782 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 0.7211963534355164 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.6934728026390076 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.510 (perp=10.212, rec=0.167, cos=0.300), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.416 (perp=10.212, rec=0.069, cos=0.305), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.408 (perp=10.212, rec=0.062, cos=0.304), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.400 (perp=10.212, rec=0.053, cos=0.304), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.415 (perp=10.212, rec=0.068, cos=0.305), tot_loss_proj:2.430 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.404 (perp=10.212, rec=0.058, cos=0.304), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.421 (perp=10.212, rec=0.073, cos=0.305), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.408 (perp=10.212, rec=0.061, cos=0.305), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.406 (perp=10.212, rec=0.058, cos=0.305), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.420 (perp=10.212, rec=0.072, cos=0.305), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.414 (perp=10.212, rec=0.066, cos=0.306), tot_loss_proj:2.432 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.415 (perp=10.212, rec=0.068, cos=0.305), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.410 (perp=10.212, rec=0.062, cos=0.305), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.397 (perp=10.212, rec=0.049, cos=0.305), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.411 (perp=10.212, rec=0.064, cos=0.304), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.404 (perp=10.212, rec=0.056, cos=0.305), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.406 (perp=10.212, rec=0.058, cos=0.305), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.396 (perp=10.212, rec=0.048, cos=0.305), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.398 (perp=10.212, rec=0.050, cos=0.305), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.410 (perp=10.212, rec=0.062, cos=0.305), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.419 (perp=10.212, rec=0.071, cos=0.305), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.405 (perp=10.212, rec=0.058, cos=0.305), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.397 (perp=10.212, rec=0.049, cos=0.305), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.401 (perp=10.212, rec=0.053, cos=0.305), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.400 (perp=10.212, rec=0.052, cos=0.305), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.408 (perp=10.212, rec=0.060, cos=0.305), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.402 (perp=10.212, rec=0.054, cos=0.305), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.413 (perp=10.212, rec=0.065, cos=0.305), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.406 (perp=10.212, rec=0.058, cos=0.305), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.422 (perp=10.212, rec=0.075, cos=0.305), tot_loss_proj:2.409 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.407 (perp=10.212, rec=0.059, cos=0.305), tot_loss_proj:2.428 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.415 (perp=10.212, rec=0.067, cos=0.305), tot_loss_proj:2.416 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.397 (perp=10.212, rec=0.049, cos=0.305), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.406 (perp=10.212, rec=0.059, cos=0.305), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.403 (perp=10.212, rec=0.055, cos=0.305), tot_loss_proj:2.404 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.411 (perp=10.212, rec=0.063, cos=0.305), tot_loss_proj:2.419 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.418 (perp=10.212, rec=0.070, cos=0.305), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.411 (perp=10.212, rec=0.064, cos=0.305), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.413 (perp=10.212, rec=0.065, cos=0.305), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.406 (perp=10.212, rec=0.058, cos=0.305), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.735 | p: 87.227 | r: 88.445
rouge2     | fm: 58.500 | p: 58.398 | r: 58.615
rougeL     | fm: 78.325 | p: 77.973 | r: 78.836
rougeLsum  | fm: 78.198 | p: 77.808 | r: 78.730
r1fm+r2fm = 146.235

input #41 time: 0:08:44 | total time: 6:20:26


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.8922183710568405
highest_index [0]
highest [0.8922183710568405]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8769128918647766 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.81014084815979 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.7978552579879761 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7954130172729492 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7880208492279053 for ['[CLS] internationalgible ever wish superseded cutbe stages ran attracted darectric bandars treaty maple offended assignmentures kitchentakingpling scale lifted larger enough [SEP]']
[Init] best perm rec loss: 0.7877024412155151 for ['[CLS]ures banda larger rangible kitchen wishctrictaking treatypling attracted enough scale maple stages liftedrs offended cut assignment supersededbe international dare ever [SEP]']
[Init] best perm rec loss: 0.7866783142089844 for ['[CLS] kitchen international banda treaty enough wish maple cut supersededctric evergible dare lifted scalerspling ran offendedtakingures attractedbe stages larger assignment [SEP]']
[Init] best perm rec loss: 0.785828709602356 for ['[CLS]ctric ever treaty scaletaking wishures cut dare international largerrs kitchen assignment attracted enough lifted maple rangible banda offended supersededplingbe stages [SEP]']
[Init] best perm rec loss: 0.7823812961578369 for ['[CLS] enough international largerplingbe assignmentctric wish ever attracted offended stages superseded cuttaking dare scale banda liftedrsgible treaty ran kitchenures maple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.230 (perp=13.300, rec=0.363, cos=0.207), tot_loss_proj:3.603 [t=0.22s]
prediction: ['[CLS] bankruptcy bad employees officialsre pay poorly rather caused no poorlyd half hospital between failure board mom drug infections several opera legislation convicted slumped electronics [SEP]']
[ 100/2000] tot_loss=3.025 (perp=12.851, rec=0.272, cos=0.182), tot_loss_proj:3.705 [t=0.22s]
prediction: ['[CLS] cases poorly employees officials朝ki poorly instead forgot no poorlyd half police without un numberggerors into the resort legislation convicted poorly organizations [SEP]']
[ 150/2000] tot_loss=2.851 (perp=12.043, rec=0.265, cos=0.177), tot_loss_proj:3.545 [t=0.22s]
prediction: ['[CLS] cases forgot respondents officials朝 integration poorly soon forgot no poorlyed gun police unless un numbergger guns into a resort legislation. poorlyupt [SEP]']
[ 200/2000] tot_loss=2.727 (perp=11.681, rec=0.202, cos=0.189), tot_loss_proj:3.167 [t=0.22s]
prediction: ['[CLS] scary forgot producers answering朝 integration poorly when forgot no forgoted as school without they asgger guns into a resort event. poorlyupt [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.532 (perp=10.857, rec=0.165, cos=0.196), tot_loss_proj:3.090 [t=0.22s]
prediction: ['[CLS] scary forgot filmmakers anything朝 integration poorly as forgot no poorly schooled as anything they asgger guns into a attraction setting. poorly locations [SEP]']
[ 300/2000] tot_loss=2.668 (perp=11.786, rec=0.153, cos=0.158), tot_loss_proj:3.277 [t=0.22s]
prediction: ['[CLS] scary forgot filmmakers anything lucivar include poorly as forgot no poorly school even as anything they asgger re into a attraction setting school poorly locations [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.488 (perp=10.854, rec=0.128, cos=0.189), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] filmmakers forgot scary anything lucivar include poorly as forgot barely barely school even as scary they asgger re into a attraction setting. poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.413 (perp=10.488, rec=0.118, cos=0.198), tot_loss_proj:3.032 [t=0.22s]
prediction: ['[CLS] filmmakers forgot scary anythingneas include poorly as forgot school even been even as scary they asgger re into a attraction setting. poorly setting [SEP]']
[ 450/2000] tot_loss=2.436 (perp=10.578, rec=0.119, cos=0.201), tot_loss_proj:2.966 [t=0.22s]
prediction: ['[CLS] filmmakers forgot scary anything │ include poorly as forgot school almost been even as scary they asgger re into a attraction setting. poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.367 (perp=10.241, rec=0.112, cos=0.207), tot_loss_proj:2.888 [t=0.22s]
prediction: ['[CLS] filmmakers forgot scary anything │ include poorly been forgot school almost as even as scary they asgger re into a attraction setting. poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.415 (perp=10.557, rec=0.106, cos=0.197), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] filmmakers forgot scary anything │ include poorly been forgot school halfway as even as scary as theygger re into a attraction attraction. poorly setting [SEP]']
[ 600/2000] tot_loss=2.482 (perp=10.888, rec=0.106, cos=0.198), tot_loss_proj:3.047 [t=0.29s]
prediction: ['[CLS] filmmakers forgot scary anything │ include poorly been forgot school halfway as even half scary as theygger re into a attraction attraction. poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.313 (perp=10.111, rec=0.097, cos=0.194), tot_loss_proj:2.883 [t=0.22s]
prediction: ['[CLS] halfway forgot scary anything │ include poorly been forgot school filmmakers as even halfway scary as theygger re into a fatal attraction. poorly setting [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.283 (perp=9.992, rec=0.091, cos=0.193), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] halfway forgot anything scary │ include poorly been forgot school filmmakers as even halfway scary as theygger re into a fatal attraction. poorly setting [SEP]']
[ 750/2000] tot_loss=2.289 (perp=9.940, rec=0.104, cos=0.196), tot_loss_proj:2.783 [t=0.22s]
prediction: ['[CLS] halfway forgot anything scaryji include poorly been forgot school filmmakers as even halfway scary as theygger re into a fatal attraction. poorly setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.231 (perp=9.663, rec=0.103, cos=0.196), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been scary school filmmakers as even halfway scary as theygger re into a fatal attraction. poorly setting [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.163 (perp=9.321, rec=0.108, cos=0.191), tot_loss_proj:2.670 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been scary school filmmakers as even scary as theygger re into a halfway fatal attraction. poorly setting [SEP]']
[ 900/2000] tot_loss=2.177 (perp=9.470, rec=0.090, cos=0.192), tot_loss_proj:2.719 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly barely scary school filmmakers as even scary as theygger re into a halfway fatal attraction. poorly setting [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.144 (perp=9.297, rec=0.091, cos=0.194), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been even scary school filmmakers as scary as theygger re into a halfway fatal attraction. poorly setting [SEP]']
Attempt swap
[1000/2000] tot_loss=2.149 (perp=9.297, rec=0.094, cos=0.196), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been even scary school filmmakers as scary as theygger re into a halfway fatal attraction. poorly setting [SEP]']
[1050/2000] tot_loss=2.155 (perp=9.297, rec=0.100, cos=0.196), tot_loss_proj:2.667 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been even scary school filmmakers as scary as theygger re into a halfway fatal attraction. poorly setting [SEP]']
Attempt swap
[1100/2000] tot_loss=2.171 (perp=9.395, rec=0.095, cos=0.197), tot_loss_proj:2.701 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly half even scary school filmmakers as scary as theygger re into a halfway fatal attraction. poorly setting [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.080 (perp=8.932, rec=0.106, cos=0.189), tot_loss_proj:2.603 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been even scary school filmmakers as scary as they regger into a halfway fatal attraction. poorly setting [SEP]']
[1200/2000] tot_loss=2.083 (perp=8.932, rec=0.102, cos=0.194), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorly been even scary school filmmakers as scary as they regger into a halfway fatal attraction. poorly setting [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.104 (perp=9.104, rec=0.089, cos=0.195), tot_loss_proj:2.621 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorlyji even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
Attempt swap
[1300/2000] tot_loss=2.111 (perp=9.104, rec=0.094, cos=0.196), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorlyji even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
[1350/2000] tot_loss=2.113 (perp=9.104, rec=0.095, cos=0.197), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorlyji even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
Attempt swap
[1400/2000] tot_loss=2.111 (perp=9.104, rec=0.093, cos=0.197), tot_loss_proj:2.630 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotji include poorlyji even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.084 (perp=8.947, rec=0.097, cos=0.198), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
[1500/2000] tot_loss=2.071 (perp=8.947, rec=0.085, cos=0.197), tot_loss_proj:2.622 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
Attempt swap
[1550/2000] tot_loss=2.070 (perp=8.947, rec=0.083, cos=0.198), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly halfway fatal attraction. setting [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.039 (perp=8.743, rec=0.094, cos=0.196), tot_loss_proj:2.598 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
[1650/2000] tot_loss=2.040 (perp=8.743, rec=0.094, cos=0.197), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.037 (perp=8.743, rec=0.091, cos=0.198), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.028 (perp=8.743, rec=0.082, cos=0.198), tot_loss_proj:2.596 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
[1800/2000] tot_loss=2.031 (perp=8.743, rec=0.084, cos=0.198), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.034 (perp=8.743, rec=0.087, cos=0.198), tot_loss_proj:2.596 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.030 (perp=8.743, rec=0.083, cos=0.198), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
[1950/2000] tot_loss=2.036 (perp=8.743, rec=0.089, cos=0.198), tot_loss_proj:2.595 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.035 (perp=8.743, rec=0.087, cos=0.199), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] halfway forgot anything forgotjiji include poorly even scary school filmmakers as scary as they regger into a poorly setting halfway fatal attraction. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 17.391 | p: 17.391 | r: 17.391
rougeL     | fm: 45.833 | p: 45.833 | r: 45.833
rougeLsum  | fm: 45.833 | p: 45.833 | r: 45.833
r1fm+r2fm = 92.391

[Aggregate metrics]:
rouge1     | fm: 87.476 | p: 86.929 | r: 88.303
rouge2     | fm: 57.480 | p: 57.415 | r: 57.569
rougeL     | fm: 77.514 | p: 77.169 | r: 77.979
rougeLsum  | fm: 77.439 | p: 77.047 | r: 77.897
r1fm+r2fm = 144.956

input #42 time: 0:08:53 | total time: 6:29:20


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.8574091426541234
highest_index [0]
highest [0.8574091426541234]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9183802604675293 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.8850346207618713 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8641191720962524 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8262854814529419 for ['[CLS] taken cheek willels [SEP]']
[Init] best rec loss: 0.7912067174911499 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7665098309516907 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7414546608924866 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7127295732498169 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7107979655265808 for ['[CLS]bus second climbck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.691 (perp=10.891, rec=0.260, cos=0.253), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS] na laborist moody [SEP]']
[ 100/2000] tot_loss=2.698 (perp=11.441, rec=0.157, cos=0.253), tot_loss_proj:2.997 [t=0.22s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.642 (perp=11.401, rec=0.100, cos=0.262), tot_loss_proj:3.162 [t=0.22s]
prediction: ['[CLS] narcisticiss [SEP]']
[ 200/2000] tot_loss=2.615 (perp=11.401, rec=0.079, cos=0.256), tot_loss_proj:3.158 [t=0.22s]
prediction: ['[CLS] narcisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.342 (perp=5.048, rec=0.077, cos=0.256), tot_loss_proj:1.350 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.354 (perp=5.048, rec=0.079, cos=0.266), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.344 (perp=5.048, rec=0.072, cos=0.263), tot_loss_proj:1.347 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.340 (perp=5.048, rec=0.067, cos=0.264), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.331 (perp=5.048, rec=0.057, cos=0.264), tot_loss_proj:1.354 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.330 (perp=5.048, rec=0.055, cos=0.265), tot_loss_proj:1.357 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.338 (perp=5.048, rec=0.066, cos=0.262), tot_loss_proj:1.341 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.337 (perp=5.048, rec=0.063, cos=0.264), tot_loss_proj:1.358 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.352 (perp=5.048, rec=0.078, cos=0.265), tot_loss_proj:1.348 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.345 (perp=5.048, rec=0.071, cos=0.265), tot_loss_proj:1.335 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.341 (perp=5.048, rec=0.069, cos=0.262), tot_loss_proj:1.355 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.322 (perp=5.048, rec=0.048, cos=0.264), tot_loss_proj:1.351 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.338 (perp=5.048, rec=0.064, cos=0.264), tot_loss_proj:1.345 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.343 (perp=5.048, rec=0.069, cos=0.265), tot_loss_proj:1.338 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.341 (perp=5.048, rec=0.066, cos=0.265), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.330 (perp=5.048, rec=0.055, cos=0.265), tot_loss_proj:1.338 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.331 (perp=5.048, rec=0.059, cos=0.262), tot_loss_proj:1.349 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.352 (perp=5.048, rec=0.078, cos=0.264), tot_loss_proj:1.329 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.339 (perp=5.048, rec=0.064, cos=0.265), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.332 (perp=5.048, rec=0.058, cos=0.265), tot_loss_proj:1.337 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.341 (perp=5.048, rec=0.067, cos=0.265), tot_loss_proj:1.355 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.329 (perp=5.048, rec=0.056, cos=0.263), tot_loss_proj:1.354 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.326 (perp=5.048, rec=0.052, cos=0.264), tot_loss_proj:1.357 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.344 (perp=5.048, rec=0.070, cos=0.264), tot_loss_proj:1.331 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.329 (perp=5.048, rec=0.055, cos=0.265), tot_loss_proj:1.343 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.334 (perp=5.048, rec=0.060, cos=0.265), tot_loss_proj:1.348 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.327 (perp=5.048, rec=0.053, cos=0.265), tot_loss_proj:1.332 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.332 (perp=5.048, rec=0.058, cos=0.265), tot_loss_proj:1.337 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.337 (perp=5.048, rec=0.063, cos=0.265), tot_loss_proj:1.347 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.330 (perp=5.048, rec=0.055, cos=0.265), tot_loss_proj:1.338 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.331 (perp=5.048, rec=0.057, cos=0.265), tot_loss_proj:1.331 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.338 (perp=5.048, rec=0.064, cos=0.265), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.338 (perp=5.048, rec=0.063, cos=0.265), tot_loss_proj:1.333 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.334 (perp=5.048, rec=0.060, cos=0.265), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.323 (perp=5.048, rec=0.048, cos=0.265), tot_loss_proj:1.338 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.334 (perp=5.048, rec=0.060, cos=0.265), tot_loss_proj:1.346 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.752 | p: 87.196 | r: 88.530
rouge2     | fm: 58.391 | p: 58.310 | r: 58.504
rougeL     | fm: 78.152 | p: 77.755 | r: 78.649
rougeLsum  | fm: 78.037 | p: 77.638 | r: 78.608
r1fm+r2fm = 146.143

input #43 time: 0:08:47 | total time: 6:38:07


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.878039863159191
highest_index [0]
highest [0.878039863159191]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.0339637994766235 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.0119436979293823 for ['[CLS] pe grammy vague contract flow genre training willing floraux acting! dc spoke ben sami undo polo # paperplaced choon muscle duncanoat derived rat schooling [SEP]']
[Init] best rec loss: 1.0092235803604126 for ['[CLS] unitedzz golden archaeological looking forward at prime momentien before at private suspensiontone ice rim arrested evelyn surgeon shaw codes memorymobile by addition ultimatelynal mills [SEP]']
[Init] best rec loss: 1.0050387382507324 for ['[CLS]hips less pronounced soaked leon overs tradition suzy diplomatic collins forgotten cells later semester brock pan husband dickinson radar would release n embankment overall evil outlookockinate toward [SEP]']
[Init] best rec loss: 1.0048739910125732 for ['[CLS] shore s > jameson posture ezra charity appliedchua drew attraction all courses corner y inside cover respectively ] to farrell competed 1st beit link gao dickson with mean [SEP]']
[Init] best rec loss: 1.0023577213287354 for ['[CLS] obstacles access household rave las gas revntly fellowship had rock turnpikewick isn tuesday yet magazine do up everything speculation neckagger openingiani compute occupiedoint mm [SEP]']
[Init] best rec loss: 0.9864624738693237 for ['[CLS] patriciaerinacano such currently staggered hop craft vacancy calderon rack anxious play without torpedoous major carter ghost popularity version cutterivar fifty plot parting you still sports [SEP]']
[Init] best rec loss: 0.9822972416877747 for ['[CLS]hold juryys closing mm too scholastic steele malifell rockyxa enclosed ronnie giveneros american epstein name publishing less him am aggregator revealing harmony irony trusted hourly [SEP]']
[Init] best perm rec loss: 0.9819666147232056 for ['[CLS] harmony given scholastic less irony revealing enclosed mali epstein am name ronnie jury hourlyfell aggregatorys closing rockyhold american publishing trusted himxa steele mm tooeros [SEP]']
[Init] best perm rec loss: 0.980453610420227 for ['[CLS]fell ronnie enclosed closing american epstein trusted irony rockyxa hourly given harmony steele am jury tooeros aggregator name less mmys him revealing publishinghold scholastic mali [SEP]']
[Init] best perm rec loss: 0.980434238910675 for ['[CLS] mm given enclosedfellhold steele american hourly publishing jury rocky epsteinys him am scholastic less closing irony tooxa trusted ronnie mali name revealing harmony aggregatoreros [SEP]']
[Init] best perm rec loss: 0.979276180267334 for ['[CLS] too scholastic harmony irony ronnie publishing trustedfell enclosed mali aggregator american rocky given jury mmeros am less revealing epstein steelexa hourlyys name himhold closing [SEP]']
[Init] best perm rec loss: 0.9792377948760986 for ['[CLS] juryeros amys irony given hourly name harmony trusted aggregator too ronnie closing less mm revealing enclosed himhold rocky scholasticfell steele epstein american mali publishingxa [SEP]']
[Init] best perm rec loss: 0.978118896484375 for ['[CLS] less jury mmeros epstein enclosed harmony revealingholdfellxa aggregator steele irony too closing am scholasticys rocky hourly name him mali given trusted american ronnie publishing [SEP]']
[Init] best perm rec loss: 0.9779162406921387 for ['[CLS] less epstein jury scholasticfell am giveneros revealing ironyxa too enclosed himys rocky hourly american mm ronnie harmony closinghold aggregator publishing trusted steele name mali [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.546 (perp=13.422, rec=0.638, cos=0.223), tot_loss_proj:4.235 [t=0.22s]
prediction: ['[CLS] restaurant bergman the cara intensity wilderness what kind handling innocent every thaturne prescriptionghton grape itv fa you design worth touching ali pure positive tomorrow humane lasting created [SEP]']
[ 100/2000] tot_loss=3.173 (perp=11.897, rec=0.603, cos=0.191), tot_loss_proj:4.270 [t=0.22s]
prediction: ['[CLS] rao boredom the plastic fully painting what kind doing charitable every goodflict prescriptioncolor bartender itv fa theatre. yes its entertaining pure melville tonight realism percussion created [SEP]']
[ 150/2000] tot_loss=3.148 (perp=11.544, rec=0.625, cos=0.214), tot_loss_proj:4.336 [t=0.23s]
prediction: ['[CLS]oir await being plastic sweetness juan not kind every charitable passage that geometridae package welles authentic. :fest. yes its dir. scientific tonight assumption having artist [SEP]']
[ 200/2000] tot_loss=2.890 (perp=11.402, rec=0.480, cos=0.129), tot_loss_proj:3.910 [t=0.23s]
prediction: ['[CLS]oir boredom was plastic fully script. another talk charitable passage the resorts incident lucius thirds. anotherfest. yesity goddard another rational loses assumption ). [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.785 (perp=10.662, rec=0.472, cos=0.181), tot_loss_proj:3.844 [t=0.22s]
prediction: ['[CLS]mined boredom was plastic easily translation across : the charitable fiction that resorts incident lucius thirds into kind hollywood. yeszed kowalski another that loses assumption lost. [SEP]']
[ 300/2000] tot_loss=2.845 (perp=10.784, rec=0.520, cos=0.169), tot_loss_proj:3.855 [t=0.23s]
prediction: ['[CLS]oir outta was plastic easily translation across. the charitable fiction another resorts thesis lucius thirds into kindfest. yes its routine another of golden premise lost. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.935 (perp=11.306, rec=0.435, cos=0.239), tot_loss_proj:3.818 [t=0.23s]
prediction: ['[CLS]oir lost been plastic easily translation across. the charitable routine another resorts situation into thirds lucius kindfest. yes hectares routine another absurd golden premise lost. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.778 (perp=11.092, rec=0.419, cos=0.141), tot_loss_proj:3.653 [t=0.23s]
prediction: ['[CLS]oir lost premisecius easily translation across. the bet routine another ridiculous situation into thirds slack kindfest. yes hectares routine another absurd golden been lost in [SEP]']
[ 450/2000] tot_loss=2.927 (perp=11.489, rec=0.431, cos=0.198), tot_loss_proj:3.654 [t=0.23s]
prediction: ['[CLS]oir lost premise grandpa could translation across cheeks the bet routine another ridiculous situation into thirds slack occurredfest execution yes hectares routine another absurd golden been lost in [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.753 (perp=11.081, rec=0.396, cos=0.141), tot_loss_proj:3.498 [t=0.22s]
prediction: ["[CLS]oir lost absurd grandpa easily translation'routine another ridiculous situation into thirds lucius occurredfest execution cheeks the those yes routine routine another absurd loses been lost in [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.887 (perp=11.859, rec=0.393, cos=0.122), tot_loss_proj:3.850 [t=0.23s]
prediction: ['[CLS]oir lost neurons traditional easily translation. routine another abbess situation. thirds slack occurred hollywood execution cheeks the those yes routine been another absurd lost routine lost in [SEP]']
[ 600/2000] tot_loss=2.967 (perp=11.871, rec=0.371, cos=0.222), tot_loss_proj:3.851 [t=0.22s]
prediction: ['[CLS]oir lost neurons traditional could translation. routine another abbess situation. thirds slack sees hollywood execution cheeks the those yes routine been another absurd lost routine lost in [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.763 (perp=11.255, rec=0.358, cos=0.153), tot_loss_proj:3.654 [t=0.23s]
prediction: ['[CLS]oir lost premiseties could translation. routine another abbess situation. those slack seesfest execution cheeks the thirds yesizes been another absurd lost routine lost in [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.948 (perp=11.564, rec=0.410, cos=0.225), tot_loss_proj:3.846 [t=0.23s]
prediction: ['[CLS]oran lost premise unreleased spirit translation loses routine another abbess spa. those slack 《fest execution cheeks the thirds yesizes been another alternative. spun lost in [SEP]']
[ 750/2000] tot_loss=2.670 (perp=10.893, rec=0.377, cos=0.114), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS]oran lost premise unreleased spirit translation lost routine another ridiculous spa. those slack needsfest execution ª the thirds yesizes been another alternative. routine lost in [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.761 (perp=11.028, rec=0.360, cos=0.195), tot_loss_proj:3.430 [t=0.23s]
prediction: ['[CLS]sible lost absurd unreleased spirit translation lost routine another ridiculous spa. the slack needsfest execution cheeks torture brows yesizes been another is. routine lost in [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.660 (perp=11.134, rec=0.357, cos=0.076), tot_loss_proj:3.369 [t=0.22s]
prediction: ['[CLS]riated lost absurd routine spirit translation lost routine another ridiculous spa. the slack needsfest execution cheeks torture. lostizes been another is brows routine lost in [SEP]']
[ 900/2000] tot_loss=2.599 (perp=10.790, rec=0.343, cos=0.098), tot_loss_proj:3.367 [t=0.22s]
prediction: ['[CLS]riated lost absurd unreleased spirit translation lost routine another ridiculous spa. the slack needsfest execution cheeks torture. lostizes been another isitaire wherein lost in [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.671 (perp=10.569, rec=0.369, cos=0.188), tot_loss_proj:3.158 [t=0.22s]
prediction: ['[CLS]riated lost premise unreleased spirit translation lost in another ridiculous we. the slack needsfest execution cheeks torture. lostizes been another isitaire random lost routine [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.620 (perp=10.548, rec=0.343, cos=0.167), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS]riated lost spa unreleased spirit translation lost in another ridiculous absurd. the slack needsfest execution cheeks torture. lostizes been another is brows random lost routine [SEP]']
[1050/2000] tot_loss=2.495 (perp=10.265, rec=0.340, cos=0.102), tot_loss_proj:3.010 [t=0.22s]
prediction: ['[CLS]riated lost spa unreleased spirit translation lost in another ridiculous absurd. the slack needsfest execution cheeks torture. lost routine been another isitaire random lost routine [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.596 (perp=10.318, rec=0.334, cos=0.198), tot_loss_proj:3.116 [t=0.22s]
prediction: ['[CLS]riated lost spirit unreleased we translation lost in another ridiculous absurd. the slack needsfest execution cheeks torture. lost routine been another isitaire random lost routine [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.505 (perp=10.254, rec=0.337, cos=0.117), tot_loss_proj:3.063 [t=0.22s]
prediction: ['[CLS]riated lost spirit unreleased we translation brows in another ridiculous absurd. the slack needsfest execution cheeks torture. lost execution been another is lost random lost routine [SEP]']
[1200/2000] tot_loss=2.464 (perp=10.194, rec=0.338, cos=0.087), tot_loss_proj:3.133 [t=0.22s]
prediction: ['[CLS]riated lost spirit unreleased we translationitaire in another ridiculous absurd. the slack needsfest execution cheeks torture. lost routine been another is lost random lost routine [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.482 (perp=10.161, rec=0.329, cos=0.121), tot_loss_proj:3.136 [t=0.23s]
prediction: ['[CLS]riated lostative spirit we translationitaire in another ridiculous absurd. the slack needsfest execution cheeksris. lost routine been another is lost random lost routine [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.648 (perp=10.793, rec=0.327, cos=0.163), tot_loss_proj:3.166 [t=0.22s]
prediction: ['[CLS]riated lostative spirit spa translation brows in the ridiculous absurd. another slack needsfest execution cheeks character. lost which been another is lost random lost routine [SEP]']
[1350/2000] tot_loss=2.585 (perp=10.286, rec=0.316, cos=0.212), tot_loss_proj:3.071 [t=0.22s]
prediction: ['[CLS]riated lostative spirit we translation brows in the ridiculous absurd. another slack needsfest execution cheeks character. lost execution been another is lost random lost routine [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.480 (perp=10.309, rec=0.322, cos=0.096), tot_loss_proj:2.905 [t=0.22s]
prediction: ['[CLS]riated lostative spirit spa translationitaire in the ridiculous absurd. another slack needsfest execution cheeks character. lost execution is another been lost random lost routine [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.467 (perp=9.891, rec=0.328, cos=0.160), tot_loss_proj:2.807 [t=0.22s]
prediction: ['[CLS]riated lost execution spirit spa translationitaire in the ridiculous absurdizes another slack needsfestative cheeks character. lost execution is another been lost random lost routine [SEP]']
[1500/2000] tot_loss=2.397 (perp=9.923, rec=0.312, cos=0.100), tot_loss_proj:2.805 [t=0.22s]
prediction: ['[CLS]riated lost execution spirit spa translation brows in the ridiculous absurd. another slack needsfestative cheeks character. lost execution is another been lost random lost routine [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.327 (perp=9.523, rec=0.319, cos=0.103), tot_loss_proj:2.695 [t=0.22s]
prediction: ['[CLS]riated lost execution spirit spa translation cheeks in the ridiculous absurd. another slack needsfestative brows character. lost execution is another been lost random lost routine [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.476 (perp=9.834, rec=0.333, cos=0.176), tot_loss_proj:2.809 [t=0.22s]
prediction: ['[CLS] censorshipriated lost execution spirit spa translation cheeks in the absurdizes another slack needsfestative brows character. lost execution is another been lost random lost routine [SEP]']
[1650/2000] tot_loss=2.369 (perp=9.622, rec=0.308, cos=0.136), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] censorshipriated lost execution spirit spa translation cheeks in the absurd. another slack needsfestative brows character. lost execution is another been lost random lost routine [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.317 (perp=9.540, rec=0.315, cos=0.094), tot_loss_proj:2.749 [t=0.22s]
prediction: ['[CLS] censorshipriated lost execution spirit spa translation cheeks in the absurd. another slack needsfestative character brows. lost execution is another been lost random lost routine [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.448 (perp=9.851, rec=0.308, cos=0.170), tot_loss_proj:3.160 [t=0.22s]
prediction: ['[CLS] lostriated lost execution spirit spa translation cheeks in the premise. another slack needsfestative character brows. lost wherein is another been lost random censorship routine [SEP]']
[1800/2000] tot_loss=2.393 (perp=9.962, rec=0.306, cos=0.095), tot_loss_proj:3.303 [t=0.22s]
prediction: ['[CLS] lostriated lost execution spirit spa translation cheeks in the premise. another slack needsfestative character brows. lost wherein is another been lost wherein censorship routine [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.377 (perp=9.631, rec=0.309, cos=0.142), tot_loss_proj:3.244 [t=0.22s]
prediction: ['[CLS] lostriated lost premise spirit spa translation cheeks in the execution. another slack needsfestative character brows. lost wherein is another been lost wherein censorship routine [SEP]']
Attempt swap
[1900/2000] tot_loss=2.338 (perp=9.516, rec=0.302, cos=0.133), tot_loss_proj:3.131 [t=0.22s]
prediction: ['[CLS] lostriated lost premise spirit spa translation cheeks in the execution. another slack needsfestative character brows. lost execution is another been lost wherein censorship routine [SEP]']
[1950/2000] tot_loss=2.454 (perp=9.631, rec=0.305, cos=0.223), tot_loss_proj:3.242 [t=0.22s]
prediction: ['[CLS] lostriated lost premise spirit spa translation cheeks in the execution. another slack needsfestative character brows. lost wherein is another been lost wherein censorship routine [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.370 (perp=9.692, rec=0.305, cos=0.127), tot_loss_proj:3.147 [t=0.22s]
prediction: ['[CLS] lostriated lost premise spirit spa translation〈 in the brows. another slack needsfestative character execution. lost wherein is another been lost wherein censorship routine [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] lostriated lost premise spirit spa translation cheeks in the execution. another slack needsfestative character brows. lost execution is another been lost wherein censorship routine [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.980 | p: 46.154 | r: 52.174
rouge2     | fm: 8.511 | p: 8.000 | r: 9.091
rougeL     | fm: 32.653 | p: 30.769 | r: 34.783
rougeLsum  | fm: 32.653 | p: 30.769 | r: 34.783
r1fm+r2fm = 57.490

[Aggregate metrics]:
rouge1     | fm: 86.921 | p: 86.356 | r: 87.717
rouge2     | fm: 57.561 | p: 57.490 | r: 57.691
rougeL     | fm: 77.124 | p: 76.788 | r: 77.643
rougeLsum  | fm: 77.004 | p: 76.570 | r: 77.457
r1fm+r2fm = 144.481

input #44 time: 0:08:57 | total time: 6:47:05


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.8794056761903584
highest_index [0]
highest [0.8794056761903584]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7822833061218262 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7345097661018372 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7307437658309937 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.7177940011024475 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6859051585197449 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6646600961685181 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6621635556221008 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.6611813306808472 for ['[CLS] enclosed five whoa ku joan letter tree few curtis via skin football murmured military bore statuslanda2 around ( special single entrance gentry taste operatedtiv v [SEP]']
[Init] best perm rec loss: 0.661097526550293 for ['[CLS] five ku joan bore via operatedlanda tree gentry special skin enclosed around whoa single entrance murmured few status2tiv football taste letter ( v curtis military [SEP]']
[Init] best perm rec loss: 0.6590568423271179 for ['[CLS] entrance enclosed joan taste few murmured special letter five football2 ( around v whoativ militarylanda single ku bore status via gentry tree operated curtis skin [SEP]']
[Init] best perm rec loss: 0.6584243774414062 for ['[CLS]2 ( murmured gentry taste whoa enclosed five joan military curtis v single bore entrance ku few status skinlandativ football special operated letter tree around via [SEP]']
[Init] best perm rec loss: 0.6581740975379944 for ['[CLS] vlanda ku football skin single ( bore joan taste special letter five few status murmuredtiv enclosed2 curtis tree operated entrance gentry whoa military via around [SEP]']
[Init] best perm rec loss: 0.6576362252235413 for ['[CLS] military ( around skinlanda bore tree curtis operated letter gentry football murmured single joan five whoa ku via entrance v2 taste fewtiv status special enclosed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.131 (perp=12.864, rec=0.360, cos=0.199), tot_loss_proj:3.551 [t=0.23s]
prediction: ['[CLS] aggression that drug skin stupid components airline floor operated military thousand bullet software muddy prison -ering cart pete euro removed picking electro that investigation political meantime than [SEP]']
[ 100/2000] tot_loss=2.753 (perp=11.348, rec=0.258, cos=0.226), tot_loss_proj:3.477 [t=0.24s]
prediction: ['[CLS] norte - off than - chemicals chain movements operated your - crime hackerick prisony on gip arrest bubba privacy movements - movements religious movements than [SEP]']
[ 150/2000] tot_loss=2.327 (perp=9.427, rec=0.242, cos=0.200), tot_loss_proj:3.051 [t=0.24s]
prediction: ['[CLS] - - off - - movements stage movements - this their - thisick - ohing gimm exercise bubba an movements - press movie movements than [SEP]']
[ 200/2000] tot_loss=2.340 (perp=9.709, rec=0.180, cos=0.218), tot_loss_proj:2.817 [t=0.24s]
prediction: ['[CLS] drama - off - bowel shelf movements - this their - thisick - shelfing gimm exercise - an movements - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.278 (perp=9.558, rec=0.152, cos=0.214), tot_loss_proj:2.793 [t=0.24s]
prediction: ['[CLS] drama - off - bowel shelf movements - this their - anick exercise shelfing gimm exercise - this movements - point drama movements than [SEP]']
[ 300/2000] tot_loss=2.274 (perp=9.638, rec=0.127, cos=0.220), tot_loss_proj:2.813 [t=0.24s]
prediction: ['[CLS] drama - off - bowel shelf movements - this long - anmm exercise shelfing gimm exercise shoot this movements - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.120 (perp=9.051, rec=0.111, cos=0.199), tot_loss_proj:2.711 [t=0.24s]
prediction: ['[CLS] - - off - bowel shelf movements - this long - inmm exercise shelfing gimm crime drama this movements - point drama movements than [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.073 (perp=8.764, rec=0.102, cos=0.218), tot_loss_proj:2.658 [t=0.24s]
prediction: ['[CLS] and - off - bowel shelf movements - this long - inmm exercise,ing crime drama gimm this movements - point drama movements than [SEP]']
[ 450/2000] tot_loss=2.052 (perp=8.707, rec=0.092, cos=0.219), tot_loss_proj:2.586 [t=0.24s]
prediction: ['[CLS] and - on - bowel shelf movements - this long - inmm exercise,ick crime drama gimm this movements - shoot drama movements than [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.998 (perp=8.432, rec=0.095, cos=0.217), tot_loss_proj:2.496 [t=0.24s]
prediction: ['[CLS] shoot - on - bowel shelf movements - this long - inmm exercise, drama gimmick crime this movements - point drama movements than [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.990 (perp=8.394, rec=0.099, cos=0.212), tot_loss_proj:2.578 [t=0.24s]
prediction: ['[CLS] shoot - on - bowel shelf in movements - the long -mm exercise, drama gimmick crime this movements - point drama movements than [SEP]']
[ 600/2000] tot_loss=1.889 (perp=7.925, rec=0.085, cos=0.219), tot_loss_proj:2.433 [t=0.24s]
prediction: ['[CLS] shoot - on - bowel shelf in movements - the long -mm exercise, drama gimmick crime this shoot - shoot drama movements than [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.055 (perp=8.784, rec=0.077, cos=0.221), tot_loss_proj:2.680 [t=0.24s]
prediction: ['[CLS] shoot - on - bowel shelf drama movements - the long -mm exercise, in giickick crime this shoot - shoot drama movements than [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.046 (perp=8.673, rec=0.088, cos=0.223), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] shoot - on - bowel shelf drama movements - the long -mm, exercise in giickick crime this shoot - shoot drama movements than [SEP]']
[ 750/2000] tot_loss=2.039 (perp=8.673, rec=0.080, cos=0.224), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] shoot - on - bowel shelf drama movements - the long -mm, exercise in giickick crime this shoot - shoot drama movements than [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.991 (perp=8.486, rec=0.072, cos=0.222), tot_loss_proj:2.532 [t=0.24s]
prediction: ['[CLS] shoot - on shelf - bowel drama movements - the long -mm, exercise in giickick crime this shoot - shoot drama movements than [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.996 (perp=8.478, rec=0.077, cos=0.223), tot_loss_proj:2.528 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements - the long -mm, exercise in giickick crime this shoot - point drama movements than [SEP]']
[ 900/2000] tot_loss=1.996 (perp=8.478, rec=0.078, cos=0.223), tot_loss_proj:2.528 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements - the long -mm, exercise in giickick crime this shoot - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.914 (perp=8.092, rec=0.073, cos=0.223), tot_loss_proj:2.450 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements - the long -mmick exercise in giick, crime this shoot - point drama movements than [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.907 (perp=8.005, rec=0.082, cos=0.224), tot_loss_proj:2.496 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements - long -mmick exercise in the giick, crime this shoot - point drama movements than [SEP]']
[1050/2000] tot_loss=1.898 (perp=8.005, rec=0.073, cos=0.224), tot_loss_proj:2.497 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements - long -mmick exercise in the giick, crime this shoot - point drama movements than [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.940 (perp=8.256, rec=0.064, cos=0.224), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements the - longmmick exercise in the giick, crime this shoot - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.892 (perp=7.930, rec=0.083, cos=0.223), tot_loss_proj:2.397 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements, - longmmick exercise in the giick - crime this shoot - point drama movements than [SEP]']
[1200/2000] tot_loss=1.882 (perp=7.930, rec=0.071, cos=0.225), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements, - longmmick exercise in the giick - crime this shoot - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.872 (perp=7.884, rec=0.072, cos=0.223), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements, - longmmick exercise - the giick in crime this shoot - point drama movements than [SEP]']
Attempt swap
[1300/2000] tot_loss=1.871 (perp=7.884, rec=0.071, cos=0.224), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements, - longmmick exercise - the giick in crime this shoot - point drama movements than [SEP]']
[1350/2000] tot_loss=1.918 (perp=8.110, rec=0.072, cos=0.223), tot_loss_proj:2.507 [t=0.24s]
prediction: ['[CLS] and - on shelf - bowel drama movements, - longmmick exercise - - giick in crime this shoot - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.855 (perp=7.810, rec=0.073, cos=0.220), tot_loss_proj:2.485 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and longmmick exercise - the giick in crime this shoot - point drama movements than [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.852 (perp=7.794, rec=0.072, cos=0.221), tot_loss_proj:2.384 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and longmmick exercise - - giick in this crime shoot - point drama movements than [SEP]']
[1500/2000] tot_loss=1.852 (perp=7.794, rec=0.072, cos=0.222), tot_loss_proj:2.379 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and longmmick exercise - - giick in this crime shoot - point drama movements than [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.834 (perp=7.739, rec=0.063, cos=0.223), tot_loss_proj:2.393 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and longmmick exercise - - gi inick this crime shoot - point drama movements than [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.795 (perp=7.459, rec=0.084, cos=0.219), tot_loss_proj:2.243 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick exercise - - long inick this crime shoot - point drama movements than [SEP]']
[1650/2000] tot_loss=1.817 (perp=7.626, rec=0.070, cos=0.221), tot_loss_proj:2.270 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick exercise - the long inick this crime shoot - point drama movements than [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.775 (perp=7.414, rec=0.071, cos=0.221), tot_loss_proj:2.205 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - the long exercise inick this crime shoot - point drama movements than [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.724 (perp=7.161, rec=0.076, cos=0.216), tot_loss_proj:2.125 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - the long exercise in this crime shoot - pointick drama movements than [SEP]']
[1800/2000] tot_loss=1.742 (perp=7.244, rec=0.074, cos=0.219), tot_loss_proj:2.142 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - - long exercise in this crime shoot - pointick drama movements than [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.692 (perp=7.027, rec=0.066, cos=0.220), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - long exercise in this crime - shoot - pointick drama movements than [SEP]']
Attempt swap
[1900/2000] tot_loss=1.699 (perp=7.027, rec=0.073, cos=0.221), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - long exercise in this crime - shoot - pointick drama movements than [SEP]']
[1950/2000] tot_loss=1.699 (perp=7.027, rec=0.072, cos=0.222), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - long exercise in this crime - shoot - pointick drama movements than [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.670 (perp=6.857, rec=0.078, cos=0.221), tot_loss_proj:2.135 [t=0.24s]
prediction: ['[CLS] - - on shelf - bowel drama movements, and gimmick - long exercise in this crime - than shoot - pointick drama movements [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - - on shelf - bowel drama movements, and gimmick - the long exercise inick this crime shoot - point drama movements than [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 5.556 | p: 5.263 | r: 5.882
rougeL     | fm: 42.105 | p: 40.000 | r: 44.444
rougeLsum  | fm: 42.105 | p: 40.000 | r: 44.444
r1fm+r2fm = 89.766

[Aggregate metrics]:
rouge1     | fm: 86.831 | p: 86.208 | r: 87.722
rouge2     | fm: 56.322 | p: 56.260 | r: 56.450
rougeL     | fm: 76.238 | p: 75.804 | r: 76.795
rougeLsum  | fm: 76.258 | p: 75.748 | r: 76.811
r1fm+r2fm = 143.154

input #45 time: 0:09:19 | total time: 6:56:24


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.8270773153155584
highest_index [0]
highest [0.8270773153155584]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9454861283302307 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9453569650650024 for ['[CLS] medicine follows idol cereal run active [SEP]']
[Init] best rec loss: 0.9435918927192688 for ['[CLS] upcoming trim grease settled g dallas [SEP]']
[Init] best rec loss: 0.9198271632194519 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9162930846214294 for ['[CLS] autism prince angles luna objectshol [SEP]']
[Init] best rec loss: 0.9132725596427917 for ['[CLS] giants alley told hurricane und : [SEP]']
[Init] best perm rec loss: 0.9106980562210083 for ['[CLS] giants : hurricane und told alley [SEP]']
[Init] best perm rec loss: 0.9104062914848328 for ['[CLS] : told giants hurricane und alley [SEP]']
[Init] best perm rec loss: 0.9090494513511658 for ['[CLS] und hurricane told : alley giants [SEP]']
[Init] best perm rec loss: 0.9081403613090515 for ['[CLS] und hurricane : told giants alley [SEP]']
[Init] best perm rec loss: 0.9075942039489746 for ['[CLS] und hurricane told giants alley : [SEP]']
[Init] best perm rec loss: 0.9074808359146118 for ['[CLS] told hurricane giants und alley : [SEP]']
[Init] best perm rec loss: 0.9072793126106262 for ['[CLS] und told : hurricane giants alley [SEP]']
[Init] best perm rec loss: 0.9071041941642761 for ['[CLS] told hurricane alley giants und : [SEP]']
[Init] best perm rec loss: 0.9070432186126709 for ['[CLS] und hurricane told : giants alley [SEP]']
[Init] best perm rec loss: 0.9068366289138794 for ['[CLS] : hurricane giants told alley und [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.349 (perp=9.332, rec=0.168, cos=0.315), tot_loss_proj:2.474 [t=0.23s]
prediction: ['[CLS] visually striking and visually staged slick [SEP]']
[ 100/2000] tot_loss=2.297 (perp=9.332, rec=0.116, cos=0.314), tot_loss_proj:2.467 [t=0.23s]
prediction: ['[CLS] visually striking and visually staged slick [SEP]']
[ 150/2000] tot_loss=2.344 (perp=9.657, rec=0.099, cos=0.314), tot_loss_proj:2.523 [t=0.23s]
prediction: ['[CLS] visually striking andly staged slick [SEP]']
[ 200/2000] tot_loss=2.313 (perp=9.657, rec=0.067, cos=0.314), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS] visually striking andly staged slick [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.569 (perp=5.916, rec=0.071, cos=0.315), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 300/2000] tot_loss=1.579 (perp=5.916, rec=0.081, cos=0.314), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.562 (perp=5.916, rec=0.063, cos=0.315), tot_loss_proj:1.555 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.562 (perp=5.916, rec=0.063, cos=0.316), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.572 (perp=5.916, rec=0.073, cos=0.316), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.569 (perp=5.916, rec=0.071, cos=0.316), tot_loss_proj:1.566 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.555 (perp=5.916, rec=0.056, cos=0.316), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.560 (perp=5.916, rec=0.061, cos=0.316), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.559 (perp=5.916, rec=0.061, cos=0.315), tot_loss_proj:1.574 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.556 (perp=5.916, rec=0.057, cos=0.316), tot_loss_proj:1.556 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.555 (perp=5.916, rec=0.056, cos=0.316), tot_loss_proj:1.571 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.560 (perp=5.916, rec=0.061, cos=0.316), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.563 (perp=5.916, rec=0.064, cos=0.316), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.564 (perp=5.916, rec=0.065, cos=0.315), tot_loss_proj:1.554 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.574 (perp=5.916, rec=0.075, cos=0.316), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=5.916, rec=0.066, cos=0.316), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.566 (perp=5.916, rec=0.067, cos=0.316), tot_loss_proj:1.559 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=5.916, rec=0.055, cos=0.316), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.553 (perp=5.916, rec=0.054, cos=0.316), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.561 (perp=5.916, rec=0.062, cos=0.316), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.563 (perp=5.916, rec=0.064, cos=0.316), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=5.916, rec=0.064, cos=0.316), tot_loss_proj:1.566 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.566 (perp=5.916, rec=0.068, cos=0.315), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.560 (perp=5.916, rec=0.061, cos=0.316), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.567 (perp=5.916, rec=0.068, cos=0.316), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.555 (perp=5.916, rec=0.056, cos=0.316), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.559 (perp=5.916, rec=0.060, cos=0.316), tot_loss_proj:1.557 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.554 (perp=5.916, rec=0.055, cos=0.316), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.550 (perp=5.916, rec=0.051, cos=0.316), tot_loss_proj:1.573 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.558 (perp=5.916, rec=0.059, cos=0.316), tot_loss_proj:1.559 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.562 (perp=5.916, rec=0.063, cos=0.316), tot_loss_proj:1.571 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.552 (perp=5.916, rec=0.053, cos=0.316), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.567 (perp=5.916, rec=0.068, cos=0.316), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.557 (perp=5.916, rec=0.058, cos=0.316), tot_loss_proj:1.561 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.547 (perp=5.916, rec=0.048, cos=0.316), tot_loss_proj:1.558 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.550 (perp=5.916, rec=0.051, cos=0.316), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.128 | p: 86.401 | r: 87.977
rouge2     | fm: 57.367 | p: 57.260 | r: 57.472
rougeL     | fm: 76.600 | p: 76.196 | r: 77.192
rougeLsum  | fm: 76.658 | p: 76.279 | r: 77.207
r1fm+r2fm = 144.495

input #46 time: 0:09:11 | total time: 7:05:35


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9210111614082186
highest_index [0]
highest [0.9210111614082186]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.679526150226593 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6568878293037415 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.649709165096283 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6444882750511169 for ['[CLS] desert elementsfulness [SEP]']
[Init] best rec loss: 0.637500524520874 for ['[CLS] we processgon [SEP]']
[Init] best perm rec loss: 0.6286724805831909 for ['[CLS] process wegon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.877 (perp=12.488, rec=0.250, cos=0.130), tot_loss_proj:3.310 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.782 (perp=12.488, rec=0.161, cos=0.124), tot_loss_proj:3.312 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.755 (perp=12.488, rec=0.110, cos=0.147), tot_loss_proj:3.346 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.767 (perp=12.488, rec=0.157, cos=0.113), tot_loss_proj:3.349 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.736 (perp=12.488, rec=0.096, cos=0.143), tot_loss_proj:3.357 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.729 (perp=12.488, rec=0.084, cos=0.148), tot_loss_proj:3.366 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.733 (perp=12.488, rec=0.085, cos=0.150), tot_loss_proj:3.373 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.737 (perp=12.488, rec=0.097, cos=0.142), tot_loss_proj:3.381 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.723 (perp=12.488, rec=0.092, cos=0.133), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.741 (perp=12.488, rec=0.091, cos=0.153), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.727 (perp=12.488, rec=0.078, cos=0.151), tot_loss_proj:3.389 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=2.716 (perp=12.488, rec=0.068, cos=0.151), tot_loss_proj:3.391 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.718 (perp=12.488, rec=0.078, cos=0.142), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.726 (perp=12.488, rec=0.077, cos=0.151), tot_loss_proj:3.396 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 750/2000] tot_loss=2.721 (perp=12.488, rec=0.074, cos=0.150), tot_loss_proj:3.395 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.700 (perp=12.488, rec=0.068, cos=0.134), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.735 (perp=12.488, rec=0.087, cos=0.150), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 900/2000] tot_loss=2.723 (perp=12.488, rec=0.073, cos=0.152), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.737 (perp=12.488, rec=0.090, cos=0.150), tot_loss_proj:3.413 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=2.720 (perp=12.488, rec=0.071, cos=0.151), tot_loss_proj:3.395 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1050/2000] tot_loss=2.724 (perp=12.488, rec=0.088, cos=0.138), tot_loss_proj:3.413 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=2.715 (perp=12.488, rec=0.068, cos=0.150), tot_loss_proj:3.416 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=2.724 (perp=12.488, rec=0.075, cos=0.151), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1200/2000] tot_loss=2.746 (perp=12.488, rec=0.097, cos=0.152), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=2.720 (perp=12.488, rec=0.075, cos=0.148), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=2.725 (perp=12.488, rec=0.077, cos=0.150), tot_loss_proj:3.417 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1350/2000] tot_loss=2.724 (perp=12.488, rec=0.075, cos=0.151), tot_loss_proj:3.409 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=2.730 (perp=12.488, rec=0.081, cos=0.151), tot_loss_proj:3.414 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=2.718 (perp=12.488, rec=0.077, cos=0.144), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1500/2000] tot_loss=2.718 (perp=12.488, rec=0.070, cos=0.150), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=2.733 (perp=12.488, rec=0.085, cos=0.151), tot_loss_proj:3.419 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=2.732 (perp=12.488, rec=0.083, cos=0.151), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1650/2000] tot_loss=2.718 (perp=12.488, rec=0.069, cos=0.151), tot_loss_proj:3.409 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=2.729 (perp=12.488, rec=0.080, cos=0.152), tot_loss_proj:3.412 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=2.728 (perp=12.488, rec=0.079, cos=0.152), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1800/2000] tot_loss=2.725 (perp=12.488, rec=0.076, cos=0.152), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=2.727 (perp=12.488, rec=0.081, cos=0.148), tot_loss_proj:3.415 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=2.728 (perp=12.488, rec=0.081, cos=0.150), tot_loss_proj:3.413 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[1950/2000] tot_loss=2.734 (perp=12.488, rec=0.086, cos=0.151), tot_loss_proj:3.414 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=2.726 (perp=12.488, rec=0.077, cos=0.151), tot_loss_proj:3.419 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS]right transparent transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 28.571 | p: 25.000 | r: 33.333
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 86.682 | p: 85.872 | r: 87.722
rouge2     | fm: 56.581 | p: 56.451 | r: 56.783
rougeL     | fm: 76.557 | p: 75.952 | r: 77.360
rougeLsum  | fm: 76.441 | p: 75.919 | r: 77.294
r1fm+r2fm = 143.263

input #47 time: 0:09:10 | total time: 7:14:45


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.866525317630496
highest_index [0]
highest [0.866525317630496]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8437593579292297 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8358170390129089 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.8356500864028931 for ['[CLS] tonightste breadim [SEP]']
[Init] best rec loss: 0.7908868789672852 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7715094089508057 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.768515408039093 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7655714750289917 for ['[CLS]dinetute graveyard runs [SEP]']
[Init] best perm rec loss: 0.7654394507408142 for ['[CLS] graveyarddine runstute [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.249 (perp=13.742, rec=0.257, cos=0.244), tot_loss_proj:3.613 [t=0.23s]
prediction: ['[CLS] rotting rottingoo waste [SEP]']
[ 100/2000] tot_loss=2.938 (perp=12.538, rec=0.188, cos=0.242), tot_loss_proj:3.307 [t=0.23s]
prediction: ['[CLS] rotting underbell beneath [SEP]']
[ 150/2000] tot_loss=3.242 (perp=14.356, rec=0.129, cos=0.241), tot_loss_proj:3.471 [t=0.23s]
prediction: ['[CLS] rotting underbell under [SEP]']
[ 200/2000] tot_loss=3.237 (perp=14.356, rec=0.120, cos=0.246), tot_loss_proj:3.469 [t=0.23s]
prediction: ['[CLS] rotting underbell under [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.464 (perp=10.471, rec=0.125, cos=0.244), tot_loss_proj:2.996 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
[ 300/2000] tot_loss=2.447 (perp=10.471, rec=0.104, cos=0.249), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.433 (perp=10.471, rec=0.094, cos=0.245), tot_loss_proj:3.010 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.420 (perp=10.471, rec=0.079, cos=0.247), tot_loss_proj:3.019 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
[ 450/2000] tot_loss=2.417 (perp=10.471, rec=0.075, cos=0.247), tot_loss_proj:3.012 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.415 (perp=10.471, rec=0.073, cos=0.247), tot_loss_proj:3.013 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.427 (perp=10.471, rec=0.085, cos=0.247), tot_loss_proj:3.000 [t=0.23s]
prediction: ['[CLS] under underbell rotting [SEP]']
[ 600/2000] tot_loss=2.447 (perp=10.622, rec=0.074, cos=0.249), tot_loss_proj:2.690 [t=0.29s]
prediction: ['[CLS]y underbell rotting [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.731 (perp=7.028, rec=0.081, cos=0.245), tot_loss_proj:1.937 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.734 (perp=7.028, rec=0.081, cos=0.247), tot_loss_proj:1.942 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.723 (perp=7.028, rec=0.069, cos=0.248), tot_loss_proj:1.939 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=7.028, rec=0.072, cos=0.249), tot_loss_proj:1.938 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.716 (perp=7.028, rec=0.061, cos=0.249), tot_loss_proj:1.932 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.724 (perp=7.028, rec=0.069, cos=0.249), tot_loss_proj:1.931 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=7.028, rec=0.072, cos=0.248), tot_loss_proj:1.941 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.721 (perp=7.028, rec=0.066, cos=0.249), tot_loss_proj:1.941 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.723 (perp=7.028, rec=0.069, cos=0.247), tot_loss_proj:1.939 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.714 (perp=7.028, rec=0.060, cos=0.249), tot_loss_proj:1.944 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.718 (perp=7.028, rec=0.063, cos=0.249), tot_loss_proj:1.948 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.718 (perp=7.028, rec=0.063, cos=0.249), tot_loss_proj:1.947 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.724 (perp=7.028, rec=0.069, cos=0.249), tot_loss_proj:1.936 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.720 (perp=7.028, rec=0.065, cos=0.249), tot_loss_proj:1.942 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.721 (perp=7.028, rec=0.066, cos=0.249), tot_loss_proj:1.944 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=7.028, rec=0.058, cos=0.248), tot_loss_proj:1.931 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.716 (perp=7.028, rec=0.062, cos=0.249), tot_loss_proj:1.930 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.713 (perp=7.028, rec=0.058, cos=0.249), tot_loss_proj:1.945 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.719 (perp=7.028, rec=0.064, cos=0.249), tot_loss_proj:1.935 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.719 (perp=7.028, rec=0.064, cos=0.249), tot_loss_proj:1.940 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.719 (perp=7.028, rec=0.064, cos=0.249), tot_loss_proj:1.940 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.719 (perp=7.028, rec=0.065, cos=0.249), tot_loss_proj:1.946 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.722 (perp=7.028, rec=0.068, cos=0.249), tot_loss_proj:1.942 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.721 (perp=7.028, rec=0.067, cos=0.249), tot_loss_proj:1.944 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.727 (perp=7.028, rec=0.072, cos=0.249), tot_loss_proj:1.937 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.715 (perp=7.028, rec=0.060, cos=0.249), tot_loss_proj:1.938 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.720 (perp=7.028, rec=0.066, cos=0.249), tot_loss_proj:1.929 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=7.028, rec=0.055, cos=0.249), tot_loss_proj:1.932 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 86.952 | p: 86.215 | r: 87.939
rouge2     | fm: 55.583 | p: 55.423 | r: 55.782
rougeL     | fm: 76.571 | p: 75.970 | r: 77.224
rougeLsum  | fm: 76.412 | p: 75.828 | r: 77.175
r1fm+r2fm = 142.535

input #48 time: 0:09:10 | total time: 7:23:55


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.8814287387941213
highest_index [0]
highest [0.8814287387941213]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8195677995681763 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7914352416992188 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7909244298934937 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 0.765215277671814 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7589893937110901 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 0.7516859769821167 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7501074075698853 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best perm rec loss: 0.7484123110771179 for ['[CLS]uous perrin where things our sheepanial accompanied hetani major tried [SEP]']
[Init] best perm rec loss: 0.7475859522819519 for ['[CLS] things accompanied major ourtani trieduousanial perrin where sheep he [SEP]']
[Init] best perm rec loss: 0.7471495866775513 for ['[CLS] wheretani sheep things our trieduousanial major perrin he accompanied [SEP]']
[Init] best perm rec loss: 0.7466826438903809 for ['[CLS] thingstani major our sheepanial accompanied he tried where perrinuous [SEP]']
[Init] best perm rec loss: 0.7457041144371033 for ['[CLS] where he sheepanial accompanied perrintani tried our majoruous things [SEP]']
[Init] best perm rec loss: 0.7450333833694458 for ['[CLS] sheep our accompanieduous majoranial where he perrintani things tried [SEP]']
[Init] best perm rec loss: 0.743495762348175 for ['[CLS] thingstani sheep perrinanial tried major accompanieduous our where he [SEP]']
[Init] best perm rec loss: 0.7434243559837341 for ['[CLS] accompanied our perrin trieduousanial wheretani things sheep major he [SEP]']
[Init] best perm rec loss: 0.7432034611701965 for ['[CLS] our tried accompaniedtani things majoranial he perrin sheep whereuous [SEP]']
[Init] best perm rec loss: 0.7427840232849121 for ['[CLS] our tried sheeptani accompanieduous where thingsanial perrin he major [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.966 (perp=12.341, rec=0.312, cos=0.186), tot_loss_proj:3.650 [t=0.23s]
prediction: ['[CLS] more coverage hate likely contemptable women contempt easily enthusiasts population contempt [SEP]']
[ 100/2000] tot_loss=2.549 (perp=10.700, rec=0.186, cos=0.223), tot_loss_proj:3.247 [t=0.23s]
prediction: ['[CLS] more slip be female contemptuous female contempt possiblyuous population contempt [SEP]']
[ 150/2000] tot_loss=2.347 (perp=10.114, rec=0.135, cos=0.190), tot_loss_proj:3.075 [t=0.23s]
prediction: ['[CLS] more net be female contemptuous female single possibly of population contempt [SEP]']
[ 200/2000] tot_loss=2.467 (perp=10.724, rec=0.098, cos=0.225), tot_loss_proj:3.100 [t=0.23s]
prediction: ['[CLS] more performance be be contemptuous female single possibly of population contempt [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.159 (perp=9.303, rec=0.111, cos=0.187), tot_loss_proj:2.787 [t=0.23s]
prediction: ['[CLS] performance be more the contemptuous female single possibly of population contempt [SEP]']
[ 300/2000] tot_loss=2.454 (perp=10.739, rec=0.088, cos=0.218), tot_loss_proj:3.504 [t=0.23s]
prediction: ['[CLS] ability be more the possiblyuous female single possibly of population contempt [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.187 (perp=9.518, rec=0.082, cos=0.201), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] possible be more the coulduous single female possibly of population contempt [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.114 (perp=9.040, rec=0.085, cos=0.221), tot_loss_proj:2.817 [t=0.23s]
prediction: ['[CLS] possible be the more coulduous single female possibly of population contempt [SEP]']
[ 450/2000] tot_loss=2.104 (perp=9.040, rec=0.074, cos=0.223), tot_loss_proj:2.820 [t=0.23s]
prediction: ['[CLS] possible be the more coulduous single female possibly of population contempt [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.030 (perp=8.703, rec=0.067, cos=0.222), tot_loss_proj:2.762 [t=0.23s]
prediction: ['[CLS] possible be the more ofuous single female possibly could population contempt [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.914 (perp=8.035, rec=0.085, cos=0.222), tot_loss_proj:2.555 [t=0.23s]
prediction: ['[CLS] possible be the more ofuous single female population could possibly contempt [SEP]']
[ 600/2000] tot_loss=1.893 (perp=8.035, rec=0.070, cos=0.216), tot_loss_proj:2.562 [t=0.23s]
prediction: ['[CLS] possible be the more ofuous single female population could possibly contempt [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.733 (perp=7.268, rec=0.062, cos=0.217), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] possible be the more contemptuous single female population could possibly of [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.597 (perp=6.543, rec=0.075, cos=0.214), tot_loss_proj:2.443 [t=0.23s]
prediction: ['[CLS] file of the more contemptuous single female population could possibly be [SEP]']
[ 750/2000] tot_loss=1.593 (perp=6.543, rec=0.062, cos=0.222), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] file of the more contemptuous single female population could possibly be [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.596 (perp=6.543, rec=0.070, cos=0.217), tot_loss_proj:2.446 [t=0.23s]
prediction: ['[CLS] file of the more contemptuous single female population could possibly be [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.607 (perp=6.543, rec=0.076, cos=0.222), tot_loss_proj:2.444 [t=0.23s]
prediction: ['[CLS] file of the more contemptuous single female population could possibly be [SEP]']
[ 900/2000] tot_loss=1.600 (perp=6.543, rec=0.074, cos=0.217), tot_loss_proj:2.455 [t=0.23s]
prediction: ['[CLS] file of the more contemptuous single female population could possibly be [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.619 (perp=6.656, rec=0.066, cos=0.222), tot_loss_proj:2.331 [t=0.23s]
prediction: ['[CLS] ; of the more contemptuous single female population could possibly be [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.506 (perp=6.131, rec=0.072, cos=0.208), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] be of the more contemptuous single female population could possibly. [SEP]']
[1050/2000] tot_loss=1.512 (perp=6.131, rec=0.064, cos=0.222), tot_loss_proj:2.107 [t=0.23s]
prediction: ['[CLS] be of the more contemptuous single female population could possibly. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.474 (perp=5.960, rec=0.062, cos=0.220), tot_loss_proj:2.028 [t=0.23s]
prediction: ['[CLS] possibly of the more contemptuous single female population could be. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.771 (perp=7.215, rec=0.115, cos=0.213), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] of possibly the more contemptuous single female population could be load [SEP]']
[1200/2000] tot_loss=1.758 (perp=7.215, rec=0.094, cos=0.221), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] of possibly the more contemptuous single female population could be load [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.721 (perp=7.054, rec=0.088, cos=0.223), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1300/2000] tot_loss=1.714 (perp=7.054, rec=0.082, cos=0.222), tot_loss_proj:2.335 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
[1350/2000] tot_loss=1.721 (perp=7.054, rec=0.088, cos=0.223), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=7.054, rec=0.080, cos=0.221), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1450/2000] tot_loss=1.718 (perp=7.054, rec=0.086, cos=0.222), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
[1500/2000] tot_loss=1.707 (perp=7.054, rec=0.074, cos=0.222), tot_loss_proj:2.334 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1550/2000] tot_loss=1.712 (perp=7.054, rec=0.079, cos=0.222), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1600/2000] tot_loss=1.701 (perp=7.054, rec=0.067, cos=0.223), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
[1650/2000] tot_loss=1.705 (perp=7.054, rec=0.072, cos=0.222), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1700/2000] tot_loss=1.706 (perp=7.054, rec=0.073, cos=0.222), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1750/2000] tot_loss=1.709 (perp=7.054, rec=0.076, cos=0.222), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
[1800/2000] tot_loss=1.705 (perp=7.054, rec=0.073, cos=0.222), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1850/2000] tot_loss=1.708 (perp=7.054, rec=0.074, cos=0.223), tot_loss_proj:2.335 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[1900/2000] tot_loss=1.707 (perp=7.054, rec=0.073, cos=0.223), tot_loss_proj:2.334 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
[1950/2000] tot_loss=1.711 (perp=7.054, rec=0.077, cos=0.223), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Attempt swap
[2000/2000] tot_loss=1.715 (perp=7.054, rec=0.082, cos=0.222), tot_loss_proj:2.339 [t=0.23s]
prediction: ['[CLS] of the possibly more contemptuous single female population could be load [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] be of the more contemptuous single female population could possibly. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 45.455 | p: 45.455 | r: 45.455
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 145.455

[Aggregate metrics]:
rouge1     | fm: 87.297 | p: 86.504 | r: 88.230
rouge2     | fm: 55.291 | p: 55.083 | r: 55.566
rougeL     | fm: 76.434 | p: 75.918 | r: 77.096
rougeLsum  | fm: 76.063 | p: 75.487 | r: 76.869
r1fm+r2fm = 142.588

input #49 time: 0:09:10 | total time: 7:33:06


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9130845221613639
highest_index [0]
highest [0.9130845221613639]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8136794567108154 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8097649812698364 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.8047932386398315 for ['[CLS] felt defended drop ring richard spade frank beds₁ [SEP]']
[Init] best rec loss: 0.7907085418701172 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7780745625495911 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7710089683532715 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best rec loss: 0.7564131617546082 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7524946331977844 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.752380907535553 for ['[CLS] state over woolf fish gradesil good ing champion [SEP]']
[Init] best perm rec loss: 0.7520831227302551 for ['[CLS] ing state fish oversil good grade champion woolf [SEP]']
[Init] best perm rec loss: 0.7512040734291077 for ['[CLS] over champion good woolfsil state ing grade fish [SEP]']
[Init] best perm rec loss: 0.7501760721206665 for ['[CLS] ing woolfsil over state good grade fish champion [SEP]']
[Init] best perm rec loss: 0.7492452263832092 for ['[CLS]sil fish state champion good ing over grade woolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.861 (perp=11.441, rec=0.432, cos=0.141), tot_loss_proj:3.544 [t=0.23s]
prediction: ['[CLS] the hardly some borders playing american grayc clever [SEP]']
[ 100/2000] tot_loss=2.498 (perp=10.231, rec=0.322, cos=0.130), tot_loss_proj:3.218 [t=0.23s]
prediction: ['[CLS] the too most borders half skin too of clever [SEP]']
[ 150/2000] tot_loss=2.524 (perp=10.683, rec=0.252, cos=0.136), tot_loss_proj:3.716 [t=0.23s]
prediction: ['[CLS] clever too call even half ` too by clever [SEP]']
[ 200/2000] tot_loss=2.453 (perp=10.800, rec=0.153, cos=0.140), tot_loss_proj:3.197 [t=0.23s]
prediction: ['[CLS] what too call what half ` too by clever [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.327 (perp=10.162, rec=0.150, cos=0.144), tot_loss_proj:3.294 [t=0.23s]
prediction: ['[CLS] what too ` english half call too by clever [SEP]']
[ 300/2000] tot_loss=2.295 (perp=10.162, rec=0.096, cos=0.166), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] what too ` english half call too by clever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.197 (perp=9.662, rec=0.101, cos=0.164), tot_loss_proj:2.932 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.185 (perp=9.662, rec=0.090, cos=0.162), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
[ 450/2000] tot_loss=2.163 (perp=9.662, rec=0.066, cos=0.165), tot_loss_proj:2.930 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.170 (perp=9.662, rec=0.081, cos=0.156), tot_loss_proj:2.927 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.174 (perp=9.662, rec=0.078, cos=0.163), tot_loss_proj:2.939 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
[ 600/2000] tot_loss=2.171 (perp=9.662, rec=0.073, cos=0.165), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.172 (perp=9.662, rec=0.073, cos=0.166), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.170 (perp=9.662, rec=0.072, cos=0.166), tot_loss_proj:2.937 [t=0.23s]
prediction: ['[CLS] what too ` english too call half by clever [SEP]']
[ 750/2000] tot_loss=2.065 (perp=9.217, rec=0.060, cos=0.162), tot_loss_proj:2.945 [t=0.23s]
prediction: ['[CLS] what the ` english too call half by clever [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.007 (perp=8.843, rec=0.077, cos=0.161), tot_loss_proj:2.857 [t=0.23s]
prediction: ['[CLS] what the english ` too call half by clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.997 (perp=8.843, rec=0.063, cos=0.165), tot_loss_proj:2.849 [t=0.23s]
prediction: ['[CLS] what the english ` too call half by clever [SEP]']
[ 900/2000] tot_loss=2.017 (perp=8.843, rec=0.083, cos=0.166), tot_loss_proj:2.844 [t=0.23s]
prediction: ['[CLS] what the english ` too call half by clever [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.971 (perp=8.751, rec=0.061, cos=0.160), tot_loss_proj:2.704 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=8.751, rec=0.073, cos=0.163), tot_loss_proj:2.711 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1050/2000] tot_loss=1.983 (perp=8.751, rec=0.069, cos=0.163), tot_loss_proj:2.695 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.985 (perp=8.751, rec=0.071, cos=0.164), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.986 (perp=8.751, rec=0.072, cos=0.164), tot_loss_proj:2.707 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1200/2000] tot_loss=1.984 (perp=8.751, rec=0.069, cos=0.164), tot_loss_proj:2.703 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.975 (perp=8.751, rec=0.060, cos=0.165), tot_loss_proj:2.702 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=8.751, rec=0.060, cos=0.165), tot_loss_proj:2.700 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1350/2000] tot_loss=1.983 (perp=8.751, rec=0.068, cos=0.165), tot_loss_proj:2.703 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.975 (perp=8.751, rec=0.059, cos=0.165), tot_loss_proj:2.704 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.981 (perp=8.751, rec=0.066, cos=0.165), tot_loss_proj:2.708 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1500/2000] tot_loss=1.981 (perp=8.751, rec=0.066, cos=0.165), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.984 (perp=8.751, rec=0.069, cos=0.165), tot_loss_proj:2.702 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.982 (perp=8.751, rec=0.067, cos=0.165), tot_loss_proj:2.714 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1650/2000] tot_loss=1.984 (perp=8.751, rec=0.068, cos=0.165), tot_loss_proj:2.701 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.991 (perp=8.751, rec=0.076, cos=0.165), tot_loss_proj:2.703 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.979 (perp=8.751, rec=0.064, cos=0.165), tot_loss_proj:2.697 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1800/2000] tot_loss=1.977 (perp=8.751, rec=0.061, cos=0.165), tot_loss_proj:2.708 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.972 (perp=8.751, rec=0.056, cos=0.165), tot_loss_proj:2.708 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.966 (perp=8.751, rec=0.050, cos=0.165), tot_loss_proj:2.713 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
[1950/2000] tot_loss=1.970 (perp=8.751, rec=0.054, cos=0.165), tot_loss_proj:2.704 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.980 (perp=8.751, rec=0.064, cos=0.165), tot_loss_proj:2.710 [t=0.23s]
prediction: ['[CLS] what the english too ` call half by clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the english too ` call half by clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 87.448 | p: 86.707 | r: 88.399
rouge2     | fm: 55.039 | p: 54.949 | r: 55.212
rougeL     | fm: 76.247 | p: 75.724 | r: 76.902
rougeLsum  | fm: 76.102 | p: 75.634 | r: 76.826
r1fm+r2fm = 142.487

input #50 time: 0:09:10 | total time: 7:42:17


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9203956480061708
highest_index [0]
highest [0.9203956480061708]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7934821844100952 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7635475993156433 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7411625981330872 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7378477454185486 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7311080694198608 for ['[CLS] elder 35 coach henry thing clay note demon potential signal [SEP]']
[Init] best rec loss: 0.7155443429946899 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.7146629691123962 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7072237133979797 for ['[CLS] acute jay outies harbor recognitionitung annezzled hughes [SEP]']
[Init] best rec loss: 0.7045004367828369 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best perm rec loss: 0.7037935256958008 for ['[CLS] anymore nothing thomas nuclearnodro hugh minute customer premises [SEP]']
[Init] best perm rec loss: 0.7022849321365356 for ['[CLS] thomas nothing nuclear customerno anymore premises hugh minutedro [SEP]']
[Init] best perm rec loss: 0.7007537484169006 for ['[CLS]dro hugh minuteno premises nuclear anymore thomas customer nothing [SEP]']
[Init] best perm rec loss: 0.7002935409545898 for ['[CLS] premises hugh nothingdrono thomas anymore nuclear minute customer [SEP]']
[Init] best perm rec loss: 0.6997675895690918 for ['[CLS] thomas premises hughdro nuclearno minute anymore nothing customer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.617 (perp=10.696, rec=0.365, cos=0.113), tot_loss_proj:3.824 [t=0.23s]
prediction: ['[CLS] funny funny wooden funny? has bits funny sucks funny [SEP]']
[ 100/2000] tot_loss=2.374 (perp=9.685, rec=0.296, cos=0.141), tot_loss_proj:3.671 [t=0.23s]
prediction: ['[CLS] funny funny or moment or has a funny sucks funny [SEP]']
[ 150/2000] tot_loss=2.232 (perp=9.461, rec=0.198, cos=0.142), tot_loss_proj:3.659 [t=0.23s]
prediction: ['[CLS] funny funny / moment or has a funny sucks funny [SEP]']
[ 200/2000] tot_loss=2.174 (perp=9.453, rec=0.145, cos=0.138), tot_loss_proj:3.648 [t=0.23s]
prediction: ['[CLS] funny funny, moment or but a funny sucks funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.942 (perp=8.330, rec=0.132, cos=0.144), tot_loss_proj:2.853 [t=0.23s]
prediction: ['[CLS] funny has a moment or but, funny sucks funny [SEP]']
[ 300/2000] tot_loss=1.926 (perp=8.458, rec=0.092, cos=0.143), tot_loss_proj:2.771 [t=0.23s]
prediction: ['[CLS] funny has a moment or but, funny sucks two [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.701 (perp=7.345, rec=0.092, cos=0.140), tot_loss_proj:2.304 [t=0.23s]
prediction: ['[CLS] moment has a moment or but two, funny sucks [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.488 (perp=6.305, rec=0.091, cos=0.137), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] moment has a moment or two, but funny sucks [SEP]']
[ 450/2000] tot_loss=1.494 (perp=6.305, rec=0.083, cos=0.151), tot_loss_proj:2.050 [t=0.23s]
prediction: ['[CLS] moment has a moment or two, but funny sucks [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.479 (perp=6.239, rec=0.092, cos=0.139), tot_loss_proj:2.301 [t=0.23s]
prediction: ['[CLS] funny has a funny moment or two, but sucks [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.459 (perp=6.239, rec=0.064, cos=0.147), tot_loss_proj:2.304 [t=0.23s]
prediction: ['[CLS] funny has a funny moment or two, but sucks [SEP]']
[ 600/2000] tot_loss=1.379 (perp=5.739, rec=0.081, cos=0.150), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS]. has a funny moment or two, but sucks [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.472 (perp=6.303, rec=0.075, cos=0.136), tot_loss_proj:2.186 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.267 (perp=5.228, rec=0.076, cos=0.146), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
[ 750/2000] tot_loss=1.271 (perp=5.228, rec=0.077, cos=0.148), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.275 (perp=5.228, rec=0.081, cos=0.148), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.268 (perp=5.228, rec=0.073, cos=0.149), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
[ 900/2000] tot_loss=1.270 (perp=5.228, rec=0.074, cos=0.150), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.259 (perp=5.228, rec=0.062, cos=0.151), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.275 (perp=5.228, rec=0.078, cos=0.151), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks. [SEP]']
[1050/2000] tot_loss=1.562 (perp=6.500, rec=0.105, cos=0.156), tot_loss_proj:2.277 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but sucks s [SEP]']
Attempt swap
Put prefix at the end
[1100/2000] tot_loss=1.594 (perp=6.848, rec=0.086, cos=0.139), tot_loss_proj:2.417 [t=0.23s]
prediction: ['[CLS]½ has a funny moment or two, but sucks [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.549 (perp=6.598, rec=0.083, cos=0.146), tot_loss_proj:2.375 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
[1200/2000] tot_loss=1.544 (perp=6.598, rec=0.076, cos=0.149), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
Attempt swap
[1250/2000] tot_loss=1.556 (perp=6.598, rec=0.086, cos=0.151), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
Attempt swap
[1300/2000] tot_loss=1.553 (perp=6.598, rec=0.082, cos=0.152), tot_loss_proj:2.370 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
[1350/2000] tot_loss=1.547 (perp=6.598, rec=0.075, cos=0.153), tot_loss_proj:2.375 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=6.598, rec=0.075, cos=0.150), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
Attempt swap
[1450/2000] tot_loss=1.538 (perp=6.598, rec=0.066, cos=0.152), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
[1500/2000] tot_loss=1.544 (perp=6.598, rec=0.072, cos=0.153), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
Attempt swap
[1550/2000] tot_loss=1.544 (perp=6.598, rec=0.074, cos=0.151), tot_loss_proj:2.372 [t=0.23s]
prediction: ['[CLS] has a½ funny moment or two, but sucks [SEP]']
Attempt swap
[1600/2000] tot_loss=1.621 (perp=6.948, rec=0.079, cos=0.152), tot_loss_proj:2.440 [t=0.23s]
prediction: ['[CLS] has a - funny moment or two, but sucks [SEP]']
[1650/2000] tot_loss=1.616 (perp=6.948, rec=0.075, cos=0.151), tot_loss_proj:2.444 [t=0.23s]
prediction: ['[CLS] has a - funny moment or two, but sucks [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.497 (perp=6.320, rec=0.083, cos=0.150), tot_loss_proj:2.272 [t=0.23s]
prediction: ['[CLS] has a funny moment or two, but - sucks [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.484 (perp=6.289, rec=0.076, cos=0.151), tot_loss_proj:2.190 [t=0.23s]
prediction: ['[CLS] has a funny moment - or two, but sucks [SEP]']
[1800/2000] tot_loss=1.495 (perp=6.289, rec=0.086, cos=0.151), tot_loss_proj:2.187 [t=0.23s]
prediction: ['[CLS] has a funny moment - or two, but sucks [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.421 (perp=5.946, rec=0.088, cos=0.144), tot_loss_proj:1.846 [t=0.23s]
prediction: ['[CLS] but has a funny moment - or two, sucks [SEP]']
Attempt swap
[1900/2000] tot_loss=1.402 (perp=5.946, rec=0.068, cos=0.145), tot_loss_proj:1.843 [t=0.23s]
prediction: ['[CLS] but has a funny moment - or two, sucks [SEP]']
[1950/2000] tot_loss=1.409 (perp=5.946, rec=0.074, cos=0.146), tot_loss_proj:1.844 [t=0.23s]
prediction: ['[CLS] but has a funny moment - or two, sucks [SEP]']
Attempt swap
[2000/2000] tot_loss=1.414 (perp=5.946, rec=0.079, cos=0.147), tot_loss_proj:1.846 [t=0.23s]
prediction: ['[CLS] but has a funny moment - or two, sucks [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] has a funny moment or two, but sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 55.556 | p: 55.556 | r: 55.556
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 155.556

[Aggregate metrics]:
rouge1     | fm: 87.720 | p: 86.988 | r: 88.636
rouge2     | fm: 54.815 | p: 54.628 | r: 55.029
rougeL     | fm: 76.259 | p: 75.715 | r: 76.926
rougeLsum  | fm: 76.277 | p: 75.758 | r: 76.931
r1fm+r2fm = 142.535

input #51 time: 0:09:10 | total time: 7:51:27


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.8747381148974832
highest_index [0]
highest [0.8747381148974832]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9368476867675781 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9272552132606506 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.9258742332458496 for ['[CLS]fa bear gun [SEP]']
[Init] best rec loss: 0.9221250414848328 for ['[CLS] tree partition themed [SEP]']
[Init] best rec loss: 0.9062890410423279 for ['[CLS] news implies lack [SEP]']
[Init] best rec loss: 0.8857901096343994 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.875905454158783 for ['[CLS] nations gazette probability [SEP]']
[Init] best rec loss: 0.7515986561775208 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7463980913162231 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7406363487243652 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.7374377250671387 for ['[CLS] football vocabulary expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.629 (perp=10.989, rec=0.204, cos=0.228), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] trailer trash draft [SEP]']
[ 100/2000] tot_loss=2.718 (perp=11.737, rec=0.137, cos=0.233), tot_loss_proj:2.917 [t=0.23s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.163 (perp=9.179, rec=0.104, cos=0.224), tot_loss_proj:2.431 [t=0.23s]
prediction: ['[CLS] trailer trash trailer [SEP]']
[ 200/2000] tot_loss=2.414 (perp=10.491, rec=0.095, cos=0.222), tot_loss_proj:2.667 [t=0.23s]
prediction: ['[CLS] trailer trash - [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.044 (perp=8.483, rec=0.121, cos=0.226), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=2.002 (perp=8.483, rec=0.074, cos=0.232), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=8.483, rec=0.084, cos=0.230), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.994 (perp=8.483, rec=0.065, cos=0.233), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.994 (perp=8.483, rec=0.063, cos=0.234), tot_loss_proj:2.334 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=8.483, rec=0.075, cos=0.225), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.993 (perp=8.483, rec=0.063, cos=0.233), tot_loss_proj:2.335 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.991 (perp=8.483, rec=0.061, cos=0.234), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.989 (perp=8.483, rec=0.058, cos=0.234), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.002 (perp=8.483, rec=0.071, cos=0.234), tot_loss_proj:2.339 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=2.000 (perp=8.483, rec=0.069, cos=0.234), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.997 (perp=8.483, rec=0.066, cos=0.234), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.997 (perp=8.483, rec=0.066, cos=0.234), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.990 (perp=8.483, rec=0.058, cos=0.235), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.987 (perp=8.483, rec=0.056, cos=0.234), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.992 (perp=8.483, rec=0.061, cos=0.234), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=2.004 (perp=8.483, rec=0.073, cos=0.235), tot_loss_proj:2.350 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.993 (perp=8.483, rec=0.062, cos=0.235), tot_loss_proj:2.341 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.996 (perp=8.483, rec=0.064, cos=0.235), tot_loss_proj:2.339 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.993 (perp=8.483, rec=0.062, cos=0.235), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.990 (perp=8.483, rec=0.059, cos=0.235), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.994 (perp=8.483, rec=0.063, cos=0.235), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.984 (perp=8.483, rec=0.053, cos=0.235), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.986 (perp=8.483, rec=0.055, cos=0.235), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=2.004 (perp=8.483, rec=0.073, cos=0.235), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.999 (perp=8.483, rec=0.068, cos=0.235), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.987 (perp=8.483, rec=0.056, cos=0.235), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.992 (perp=8.483, rec=0.061, cos=0.235), tot_loss_proj:2.329 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.999 (perp=8.483, rec=0.068, cos=0.235), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.997 (perp=8.483, rec=0.066, cos=0.235), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.998 (perp=8.483, rec=0.067, cos=0.235), tot_loss_proj:2.335 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.984 (perp=8.483, rec=0.053, cos=0.235), tot_loss_proj:2.336 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.996 (perp=8.483, rec=0.065, cos=0.235), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.996 (perp=8.483, rec=0.065, cos=0.235), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.989 (perp=8.483, rec=0.058, cos=0.235), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.996 (perp=8.483, rec=0.064, cos=0.235), tot_loss_proj:2.342 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.955 | p: 87.267 | r: 88.880
rouge2     | fm: 54.075 | p: 53.947 | r: 54.271
rougeL     | fm: 76.259 | p: 75.789 | r: 76.911
rougeLsum  | fm: 76.027 | p: 75.547 | r: 76.705
r1fm+r2fm = 142.030

input #52 time: 0:09:08 | total time: 8:00:36


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9183360639304378
highest_index [0]
highest [0.9183360639304378]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.812782347202301 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8111477494239807 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 0.7999987006187439 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 0.7123621702194214 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.707427978515625 for ['[CLS] annually ability [SEP]']
[Init] best rec loss: 0.6877499222755432 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6824959516525269 for ['[CLS] nick design [SEP]']
[Init] best perm rec loss: 0.6816561222076416 for ['[CLS] design nick [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.827 (perp=12.492, rec=0.179, cos=0.149), tot_loss_proj:3.408 [t=0.23s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.735 (perp=12.413, rec=0.097, cos=0.156), tot_loss_proj:3.333 [t=0.23s]
prediction: ['[CLS]ing flinch [SEP]']
[ 150/2000] tot_loss=2.716 (perp=12.413, rec=0.078, cos=0.155), tot_loss_proj:3.333 [t=0.23s]
prediction: ['[CLS]ing flinch [SEP]']
[ 200/2000] tot_loss=2.702 (perp=12.413, rec=0.063, cos=0.156), tot_loss_proj:3.328 [t=0.23s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.828 (perp=8.090, rec=0.070, cos=0.139), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.829 (perp=8.090, rec=0.057, cos=0.154), tot_loss_proj:1.865 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.828 (perp=8.090, rec=0.054, cos=0.155), tot_loss_proj:1.872 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.839 (perp=8.090, rec=0.065, cos=0.156), tot_loss_proj:1.857 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.831 (perp=8.090, rec=0.056, cos=0.157), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.850 (perp=8.090, rec=0.075, cos=0.156), tot_loss_proj:1.849 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.841 (perp=8.090, rec=0.067, cos=0.156), tot_loss_proj:1.878 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.831 (perp=8.090, rec=0.057, cos=0.156), tot_loss_proj:1.869 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.835 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.830 (perp=8.090, rec=0.062, cos=0.150), tot_loss_proj:1.880 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.830 (perp=8.090, rec=0.056, cos=0.156), tot_loss_proj:1.863 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.830 (perp=8.090, rec=0.056, cos=0.156), tot_loss_proj:1.872 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.837 (perp=8.090, rec=0.063, cos=0.156), tot_loss_proj:1.849 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.835 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.872 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.818 (perp=8.090, rec=0.043, cos=0.157), tot_loss_proj:1.849 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.821 (perp=8.090, rec=0.053, cos=0.150), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.838 (perp=8.090, rec=0.064, cos=0.156), tot_loss_proj:1.852 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.830 (perp=8.090, rec=0.056, cos=0.156), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.838 (perp=8.090, rec=0.064, cos=0.157), tot_loss_proj:1.860 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.834 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.862 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.835 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.855 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.831 (perp=8.090, rec=0.056, cos=0.157), tot_loss_proj:1.859 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.826 (perp=8.090, rec=0.057, cos=0.151), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.826 (perp=8.090, rec=0.053, cos=0.155), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.836 (perp=8.090, rec=0.062, cos=0.156), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.829 (perp=8.090, rec=0.055, cos=0.156), tot_loss_proj:1.862 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.840 (perp=8.090, rec=0.065, cos=0.156), tot_loss_proj:1.849 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.827 (perp=8.090, rec=0.053, cos=0.156), tot_loss_proj:1.855 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.838 (perp=8.090, rec=0.064, cos=0.156), tot_loss_proj:1.871 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.851 (perp=8.090, rec=0.076, cos=0.156), tot_loss_proj:1.852 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.829 (perp=8.090, rec=0.055, cos=0.157), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.838 (perp=8.090, rec=0.063, cos=0.156), tot_loss_proj:1.850 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.841 (perp=8.090, rec=0.066, cos=0.156), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.853 (perp=8.090, rec=0.079, cos=0.156), tot_loss_proj:1.846 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.849 (perp=8.090, rec=0.074, cos=0.156), tot_loss_proj:1.855 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.834 (perp=8.090, rec=0.060, cos=0.157), tot_loss_proj:1.848 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.050 | p: 87.387 | r: 89.039
rouge2     | fm: 54.846 | p: 54.674 | r: 55.067
rougeL     | fm: 76.739 | p: 76.241 | r: 77.350
rougeLsum  | fm: 76.576 | p: 76.051 | r: 77.192
r1fm+r2fm = 142.896

input #53 time: 0:09:08 | total time: 8:09:45


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.8482047341866372
highest_index [0]
highest [0.8482047341866372]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.7841770052909851 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7723703384399414 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 0.7476627826690674 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6985732316970825 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6666059494018555 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6606222987174988 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.6549310088157654 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6438218355178833 for ['[CLS] wild exercised [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.134 (perp=8.198, rec=0.228, cos=0.267), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=1.999 (perp=8.198, rec=0.082, cos=0.277), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.983 (perp=8.198, rec=0.065, cos=0.279), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.970 (perp=8.198, rec=0.052, cos=0.279), tot_loss_proj:1.990 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.991 (perp=8.198, rec=0.072, cos=0.280), tot_loss_proj:1.997 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.979 (perp=8.198, rec=0.062, cos=0.278), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.975 (perp=8.198, rec=0.057, cos=0.279), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.979 (perp=8.198, rec=0.059, cos=0.280), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.983 (perp=8.198, rec=0.073, cos=0.271), tot_loss_proj:1.995 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.982 (perp=8.198, rec=0.063, cos=0.279), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.985 (perp=8.198, rec=0.071, cos=0.275), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.984 (perp=8.198, rec=0.066, cos=0.279), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.979 (perp=8.198, rec=0.059, cos=0.280), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.974 (perp=8.198, rec=0.055, cos=0.280), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.972 (perp=8.198, rec=0.052, cos=0.280), tot_loss_proj:1.997 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.992 (perp=8.198, rec=0.075, cos=0.278), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.981 (perp=8.198, rec=0.062, cos=0.279), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.971 (perp=8.198, rec=0.051, cos=0.280), tot_loss_proj:2.003 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.979 (perp=8.198, rec=0.059, cos=0.280), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.973 (perp=8.198, rec=0.060, cos=0.273), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.981 (perp=8.198, rec=0.062, cos=0.279), tot_loss_proj:1.995 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.981 (perp=8.198, rec=0.061, cos=0.280), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.980 (perp=8.198, rec=0.060, cos=0.280), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.984 (perp=8.198, rec=0.065, cos=0.280), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.978 (perp=8.198, rec=0.058, cos=0.280), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=8.198, rec=0.056, cos=0.280), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.977 (perp=8.198, rec=0.059, cos=0.279), tot_loss_proj:1.997 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.977 (perp=8.198, rec=0.057, cos=0.280), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.978 (perp=8.198, rec=0.059, cos=0.280), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.958 (perp=8.198, rec=0.038, cos=0.280), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.985 (perp=8.198, rec=0.065, cos=0.280), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.990 (perp=8.198, rec=0.070, cos=0.280), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.972 (perp=8.198, rec=0.052, cos=0.280), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.988 (perp=8.198, rec=0.068, cos=0.280), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.977 (perp=8.198, rec=0.057, cos=0.280), tot_loss_proj:1.992 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.986 (perp=8.198, rec=0.066, cos=0.280), tot_loss_proj:2.002 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.995 (perp=8.198, rec=0.075, cos=0.280), tot_loss_proj:1.995 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.988 (perp=8.198, rec=0.069, cos=0.279), tot_loss_proj:1.990 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.987 (perp=8.198, rec=0.068, cos=0.280), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.983 (perp=8.198, rec=0.063, cos=0.280), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.378 | p: 87.685 | r: 89.265
rouge2     | fm: 55.782 | p: 55.631 | r: 55.925
rougeL     | fm: 77.017 | p: 76.571 | r: 77.703
rougeLsum  | fm: 76.960 | p: 76.420 | r: 77.588
r1fm+r2fm = 144.159

input #54 time: 0:09:09 | total time: 8:18:54


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9161516394279646
highest_index [0]
highest [0.9161516394279646]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.851150631904602 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.743385910987854 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7412436604499817 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7292723655700684 for ['[CLS] beneath besides milo [SEP]']
[Init] best rec loss: 0.7252539396286011 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7100476622581482 for ['[CLS] top trades events [SEP]']
[Init] best perm rec loss: 0.7090590596199036 for ['[CLS] trades events top [SEP]']
[Init] best perm rec loss: 0.7065098881721497 for ['[CLS] events trades top [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.215 (perp=8.688, rec=0.323, cos=0.155), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 100/2000] tot_loss=1.991 (perp=8.688, rec=0.111, cos=0.143), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 150/2000] tot_loss=1.977 (perp=8.688, rec=0.083, cos=0.156), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 200/2000] tot_loss=1.964 (perp=8.688, rec=0.068, cos=0.158), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.975 (perp=8.688, rec=0.079, cos=0.159), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.971 (perp=8.688, rec=0.074, cos=0.159), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.960 (perp=8.688, rec=0.063, cos=0.160), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.961 (perp=8.688, rec=0.064, cos=0.160), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.966 (perp=8.688, rec=0.068, cos=0.160), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.955 (perp=8.688, rec=0.057, cos=0.160), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.952 (perp=8.688, rec=0.054, cos=0.160), tot_loss_proj:2.364 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.965 (perp=8.688, rec=0.067, cos=0.160), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.974 (perp=8.688, rec=0.076, cos=0.160), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.969 (perp=8.688, rec=0.071, cos=0.161), tot_loss_proj:2.366 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.958 (perp=8.688, rec=0.065, cos=0.155), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.960 (perp=8.688, rec=0.064, cos=0.159), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.954 (perp=8.688, rec=0.056, cos=0.160), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.963 (perp=8.688, rec=0.066, cos=0.160), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.960 (perp=8.688, rec=0.062, cos=0.160), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.958 (perp=8.688, rec=0.060, cos=0.160), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.956 (perp=8.688, rec=0.060, cos=0.158), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.957 (perp=8.688, rec=0.060, cos=0.159), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.967 (perp=8.688, rec=0.070, cos=0.160), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.952 (perp=8.688, rec=0.054, cos=0.160), tot_loss_proj:2.361 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.958 (perp=8.688, rec=0.060, cos=0.160), tot_loss_proj:2.349 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.967 (perp=8.688, rec=0.069, cos=0.160), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.975 (perp=8.688, rec=0.077, cos=0.160), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.966 (perp=8.688, rec=0.068, cos=0.160), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.967 (perp=8.688, rec=0.069, cos=0.160), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.967 (perp=8.688, rec=0.069, cos=0.160), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.969 (perp=8.688, rec=0.071, cos=0.161), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.969 (perp=8.688, rec=0.071, cos=0.161), tot_loss_proj:2.355 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.957 (perp=8.688, rec=0.061, cos=0.158), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.963 (perp=8.688, rec=0.066, cos=0.159), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.960 (perp=8.688, rec=0.062, cos=0.160), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.963 (perp=8.688, rec=0.065, cos=0.160), tot_loss_proj:2.360 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.967 (perp=8.688, rec=0.069, cos=0.160), tot_loss_proj:2.362 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.967 (perp=8.688, rec=0.069, cos=0.160), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.968 (perp=8.688, rec=0.070, cos=0.160), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.958 (perp=8.688, rec=0.060, cos=0.160), tot_loss_proj:2.359 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.498 | p: 87.894 | r: 89.343
rouge2     | fm: 55.206 | p: 55.106 | r: 55.418
rougeL     | fm: 77.117 | p: 76.650 | r: 77.760
rougeLsum  | fm: 77.124 | p: 76.607 | r: 77.814
r1fm+r2fm = 143.705

input #55 time: 0:09:08 | total time: 8:28:03


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.8898715703165607
highest_index [0]
highest [0.8898715703165607]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8476168513298035 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.8239401578903198 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8237656950950623 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.8224937915802002 for ['[CLS] reflection determined en laid backed bear tis technique strike sense unfortunatelyured blame avid code ; sympathy iron depression charter k [SEP]']
[Init] best perm rec loss: 0.8224225640296936 for ['[CLS] sense depression ; determined codeured charter backed k unfortunately strike avid en blame reflection technique iron bear tis sympathy laid [SEP]']
[Init] best perm rec loss: 0.821772575378418 for ['[CLS] ironured technique code unfortunately sympathy k avid ; charter strike sense tis en reflection blame determined bear backed depression laid [SEP]']
[Init] best perm rec loss: 0.8197919130325317 for ['[CLS] tis blame sympathy k charter determined technique bearured avid ; en laid strike depression backed reflection unfortunately iron code sense [SEP]']
[Init] best perm rec loss: 0.8197470903396606 for ['[CLS] ; backedured depression tis technique en charter laid reflection strike bear avid unfortunately code sympathy iron blame k determined sense [SEP]']
[Init] best perm rec loss: 0.8197444081306458 for ['[CLS] tis k strike reflection ; laid en iron determined depression avidured blame bear backed charter code sense unfortunately sympathy technique [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.081 (perp=12.770, rec=0.335, cos=0.192), tot_loss_proj:3.662 [t=0.23s]
prediction: ['[CLS] motorway state recorded nothing taxpayer damage truck damage but damaged expensive lossesarns used our damage awful that insult damage brady [SEP]']
[ 100/2000] tot_loss=2.808 (perp=11.689, rec=0.274, cos=0.196), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] films lab recorded nothing taxpayer damagepre damage but damaged films damage հ of which damage loadsride insult years brady [SEP]']
[ 150/2000] tot_loss=2.673 (perp=11.236, rec=0.234, cos=0.192), tot_loss_proj:3.447 [t=0.24s]
prediction: ['[CLS] films lab failed nothing │ which guarantee damage that caused films damage why of that damage costlyride damage years hadley [SEP]']
[ 200/2000] tot_loss=2.444 (perp=10.210, rec=0.197, cos=0.205), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] films analysis costly nothing months which cause damage that caused films damage whose of that damage costly repair damage years surgical [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.485 (perp=10.594, rec=0.169, cos=0.197), tot_loss_proj:3.455 [t=0.24s]
prediction: ['[CLS] films analysis costly nothing months which cause damage of fix of years will films that damage costly repair damage years fein [SEP]']
[ 300/2000] tot_loss=2.539 (perp=10.864, rec=0.164, cos=0.202), tot_loss_proj:3.531 [t=0.24s]
prediction: ['[CLS] films analysis costly nothing months which cause damage of fix of years will films that damage costly repair load years fein [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.386 (perp=10.168, rec=0.147, cos=0.206), tot_loss_proj:3.065 [t=0.24s]
prediction: ['[CLS] films analysis costly nothing fix which cause damage of months of years will analysis that damage costly repair load years fein [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.598 (perp=11.285, rec=0.137, cos=0.204), tot_loss_proj:3.502 [t=0.24s]
prediction: ['[CLS] films fix costly nothingble which cause damage of months loads that years will analysis damage costly repair load yearspara [SEP]']
[ 450/2000] tot_loss=2.726 (perp=11.928, rec=0.141, cos=0.200), tot_loss_proj:3.785 [t=0.24s]
prediction: ['[CLS] films fix costly noneble which cause damage ofplicity loads that years will analysis damage costly repair load yearspara [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.474 (perp=10.747, rec=0.121, cos=0.204), tot_loss_proj:3.344 [t=0.24s]
prediction: ['[CLS] films fix costlyparable which cause damage ofplicity loads that years will analysis damage costly analysis load years never [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.399 (perp=10.344, rec=0.124, cos=0.207), tot_loss_proj:3.059 [t=0.24s]
prediction: ['[CLS] films which fix costlyparable cause damage ofplicity loads that years will analysis damage costly analysis load years never [SEP]']
[ 600/2000] tot_loss=2.437 (perp=10.588, rec=0.112, cos=0.207), tot_loss_proj:3.124 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara cause damage ofplicity loads that years will analysis damage costly analysis load years never [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.320 (perp=10.012, rec=0.113, cos=0.204), tot_loss_proj:2.969 [t=0.24s]
prediction: ['[CLS] films which fix costlyparable cause damage of analysis loads that years willplicity damage costly analysis load years never [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.328 (perp=10.052, rec=0.116, cos=0.202), tot_loss_proj:3.027 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara cause damage of analysis loads years that willplicity damage costly analysis load years never [SEP]']
[ 750/2000] tot_loss=2.318 (perp=10.052, rec=0.102, cos=0.206), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara cause damage of analysis loads years that willplicity damage costly analysis load years never [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.390 (perp=10.418, rec=0.101, cos=0.206), tot_loss_proj:3.537 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara cause fix damage analysis loads years that will months of decades analysis load of never [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.289 (perp=9.874, rec=0.114, cos=0.200), tot_loss_proj:3.490 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loads fix damage analysis cause years that willplicity of decades analysis load of never [SEP]']
[ 900/2000] tot_loss=2.264 (perp=9.793, rec=0.101, cos=0.204), tot_loss_proj:3.451 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loads fix damage analysis cause years that will months of decades analysis load of never [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.230 (perp=9.625, rec=0.100, cos=0.205), tot_loss_proj:3.437 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loads fix damage analysis cause years that will months of decades load analysis of never [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.123 (perp=9.090, rec=0.103, cos=0.203), tot_loss_proj:3.033 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loads fix damage analysis cause years that will months of decades of analysis load never [SEP]']
[1050/2000] tot_loss=2.115 (perp=9.090, rec=0.093, cos=0.204), tot_loss_proj:3.039 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loads fix damage analysis cause years that will months of decades of analysis load never [SEP]']
Attempt swap
[1100/2000] tot_loss=2.112 (perp=9.045, rec=0.098, cos=0.205), tot_loss_proj:3.085 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loadsble damage analysis cause years that will months of decades of analysis years never [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.129 (perp=9.111, rec=0.103, cos=0.205), tot_loss_proj:3.046 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loadsble damage analysis years that will cause ir of decades of analysis years never [SEP]']
[1200/2000] tot_loss=2.127 (perp=9.111, rec=0.100, cos=0.205), tot_loss_proj:3.042 [t=0.24s]
prediction: ['[CLS] films which fix costlyparapara loadsble damage analysis years that will cause ir of decades of analysis years never [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.012 (perp=8.555, rec=0.097, cos=0.204), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] films which fix costlyparaparable damage analysis loads years that will cause ir of decades of analysis years never [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.913 (perp=8.070, rec=0.094, cos=0.205), tot_loss_proj:2.528 [t=0.24s]
prediction: ['[CLS] films which costly fix irparable damage analysis loads years that will cause ir of decades of analysis years never [SEP]']
[1350/2000] tot_loss=1.916 (perp=8.070, rec=0.097, cos=0.205), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] films which costly fix irparable damage analysis loads years that will cause ir of decades of analysis years never [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.823 (perp=7.640, rec=0.092, cos=0.204), tot_loss_proj:2.429 [t=0.24s]
prediction: ['[CLS] films which costly fix irparable damage analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.795 (perp=7.499, rec=0.093, cos=0.202), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
[1500/2000] tot_loss=1.787 (perp=7.499, rec=0.085, cos=0.203), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[1550/2000] tot_loss=1.803 (perp=7.499, rec=0.100, cos=0.203), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[1600/2000] tot_loss=1.788 (perp=7.499, rec=0.085, cos=0.203), tot_loss_proj:2.592 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
[1650/2000] tot_loss=1.792 (perp=7.499, rec=0.089, cos=0.203), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=7.499, rec=0.098, cos=0.203), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[1750/2000] tot_loss=1.805 (perp=7.499, rec=0.102, cos=0.203), tot_loss_proj:2.597 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
[1800/2000] tot_loss=1.796 (perp=7.499, rec=0.093, cos=0.203), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[1850/2000] tot_loss=1.798 (perp=7.499, rec=0.095, cos=0.203), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.806 (perp=7.499, rec=0.103, cos=0.203), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
[1950/2000] tot_loss=1.800 (perp=7.499, rec=0.096, cos=0.203), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Attempt swap
[2000/2000] tot_loss=1.790 (perp=7.499, rec=0.087, cos=0.203), tot_loss_proj:2.586 [t=0.24s]
prediction: ['[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films which fix irparable damage costly analysis loads of years that will cause ir decades of analysis years never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.927 | p: 80.952 | r: 85.000
rouge2     | fm: 25.641 | p: 25.000 | r: 26.316
rougeL     | fm: 48.780 | p: 47.619 | r: 50.000
rougeLsum  | fm: 48.780 | p: 47.619 | r: 50.000
r1fm+r2fm = 108.568

[Aggregate metrics]:
rouge1     | fm: 88.416 | p: 87.724 | r: 89.331
rouge2     | fm: 54.453 | p: 54.300 | r: 54.604
rougeL     | fm: 76.630 | p: 76.122 | r: 77.270
rougeLsum  | fm: 76.519 | p: 76.023 | r: 77.190
r1fm+r2fm = 142.869

input #56 time: 0:09:17 | total time: 8:37:20


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9119960647808707
highest_index [0]
highest [0.9119960647808707]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8720332980155945 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.85975182056427 for ['[CLS] their [SEP]']
[Init] best rec loss: 0.8065431118011475 for ['[CLS]on [SEP]']
[Init] best rec loss: 0.7519755959510803 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6830259561538696 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6769493222236633 for ['[CLS] silk [SEP]']
[Init] best rec loss: 0.6568631529808044 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.776 (perp=12.283, rec=0.153, cos=0.166), tot_loss_proj:2.692 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.686 (perp=12.283, rec=0.065, cos=0.165), tot_loss_proj:2.680 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.690 (perp=12.283, rec=0.092, cos=0.142), tot_loss_proj:2.702 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.680 (perp=12.283, rec=0.066, cos=0.157), tot_loss_proj:2.684 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.695 (perp=12.283, rec=0.074, cos=0.165), tot_loss_proj:2.674 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.681 (perp=12.283, rec=0.058, cos=0.167), tot_loss_proj:2.686 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.678 (perp=12.283, rec=0.054, cos=0.168), tot_loss_proj:2.683 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.691 (perp=12.283, rec=0.066, cos=0.168), tot_loss_proj:2.686 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.680 (perp=12.283, rec=0.055, cos=0.168), tot_loss_proj:2.699 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.682 (perp=12.283, rec=0.058, cos=0.167), tot_loss_proj:2.680 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.691 (perp=12.283, rec=0.066, cos=0.168), tot_loss_proj:2.689 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.686 (perp=12.283, rec=0.062, cos=0.168), tot_loss_proj:2.680 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.680 (perp=12.283, rec=0.055, cos=0.168), tot_loss_proj:2.684 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.681 (perp=12.283, rec=0.060, cos=0.164), tot_loss_proj:2.674 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.679 (perp=12.283, rec=0.055, cos=0.167), tot_loss_proj:2.689 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.679 (perp=12.283, rec=0.055, cos=0.168), tot_loss_proj:2.694 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.691 (perp=12.283, rec=0.067, cos=0.168), tot_loss_proj:2.694 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.694 (perp=12.283, rec=0.069, cos=0.168), tot_loss_proj:2.697 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.684 (perp=12.283, rec=0.060, cos=0.167), tot_loss_proj:2.688 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.681 (perp=12.283, rec=0.057, cos=0.168), tot_loss_proj:2.679 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.679 (perp=12.283, rec=0.054, cos=0.168), tot_loss_proj:2.688 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.678 (perp=12.283, rec=0.053, cos=0.168), tot_loss_proj:2.682 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.680 (perp=12.283, rec=0.056, cos=0.168), tot_loss_proj:2.683 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.680 (perp=12.283, rec=0.055, cos=0.168), tot_loss_proj:2.676 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.690 (perp=12.283, rec=0.065, cos=0.168), tot_loss_proj:2.687 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.691 (perp=12.283, rec=0.069, cos=0.166), tot_loss_proj:2.675 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.670 (perp=12.283, rec=0.046, cos=0.167), tot_loss_proj:2.677 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.677 (perp=12.283, rec=0.052, cos=0.168), tot_loss_proj:2.690 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.676 (perp=12.283, rec=0.052, cos=0.168), tot_loss_proj:2.685 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.685 (perp=12.283, rec=0.061, cos=0.168), tot_loss_proj:2.698 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.687 (perp=12.283, rec=0.063, cos=0.168), tot_loss_proj:2.694 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.685 (perp=12.283, rec=0.060, cos=0.168), tot_loss_proj:2.681 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.692 (perp=12.283, rec=0.067, cos=0.168), tot_loss_proj:2.687 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.672 (perp=12.283, rec=0.050, cos=0.166), tot_loss_proj:2.682 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.687 (perp=12.283, rec=0.063, cos=0.167), tot_loss_proj:2.687 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.666 (perp=12.283, rec=0.042, cos=0.168), tot_loss_proj:2.687 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.680 (perp=12.283, rec=0.056, cos=0.168), tot_loss_proj:2.696 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.674 (perp=12.283, rec=0.050, cos=0.168), tot_loss_proj:2.691 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.683 (perp=12.283, rec=0.058, cos=0.168), tot_loss_proj:2.678 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.681 (perp=12.283, rec=0.057, cos=0.168), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.597 | p: 87.938 | r: 89.504
rouge2     | fm: 55.323 | p: 55.219 | r: 55.500
rougeL     | fm: 77.151 | p: 76.663 | r: 77.738
rougeLsum  | fm: 76.957 | p: 76.432 | r: 77.651
r1fm+r2fm = 143.920

input #57 time: 0:09:02 | total time: 8:46:23


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.8120567678860338
highest_index [0]
highest [0.8120567678860338]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.022125482559204 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9972965121269226 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9840936064720154 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9819465279579163 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9679429531097412 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9610815048217773 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 0.9581647515296936 for ['[CLS] sure tel china lose neutral central never an there after louis concentratione jack boysnted [SEP]']
[Init] best rec loss: 0.9441215395927429 for ['[CLS] shield anything damon venom sitting led trumppole purdue bigاural failed proposal sketch lea [SEP]']
[Init] best rec loss: 0.9381417632102966 for ['[CLS] bellsignant river animals don cracked ace behind lid tasha des aden reception add bu fully [SEP]']
[Init] best perm rec loss: 0.9379392266273499 for ['[CLS] behind bu aceignant cracked fully des river tasha add don bells lid reception animals aden [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.863 (perp=14.795, rec=0.618, cos=0.285), tot_loss_proj:4.514 [t=0.23s]
prediction: ['[CLS] guilty united name make resources is ammunition stricken lame avoidisation began odds uncomfortable possibly conditions [SEP]']
[ 100/2000] tot_loss=3.448 (perp=12.590, rec=0.596, cos=0.335), tot_loss_proj:4.120 [t=0.23s]
prediction: ['[CLS] yellowmarine system make contributed quiet cigarette apology lame stool crambidae husband cost after possibly conditions [SEP]']
[ 150/2000] tot_loss=3.408 (perp=12.948, rec=0.555, cos=0.263), tot_loss_proj:4.134 [t=0.24s]
prediction: ['[CLS] yellowitating fund segregated story. cigarette caution mud thud symptoms relationship contacts ofity death [SEP]']
[ 200/2000] tot_loss=3.220 (perp=12.545, rec=0.534, cos=0.176), tot_loss_proj:4.163 [t=0.24s]
prediction: ['[CLS] poems west between het story an cigarette ballistic mud thud cleopatra. margins ofity death [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.047 (perp=11.529, rec=0.454, cos=0.287), tot_loss_proj:4.170 [t=0.24s]
prediction: ['[CLS] innocencemarine between an story is cigarette of mud topics mood story exposure environmentality system [SEP]']
[ 300/2000] tot_loss=2.971 (perp=11.145, rec=0.477, cos=0.264), tot_loss_proj:4.028 [t=0.24s]
prediction: ['[CLS] poems forces padma an story is cigarette of mud guilty allegro of 5 environmentality system [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.043 (perp=12.334, rec=0.441, cos=0.135), tot_loss_proj:4.422 [t=0.24s]
prediction: ['[CLS] poems forces outcomes an story is cigarette of cheese thud padma story precious environmental absolutely story [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.981 (perp=11.652, rec=0.416, cos=0.235), tot_loss_proj:4.268 [t=0.24s]
prediction: ['[CLS] poems forces an mood story is consecrated of captured guilty padma of amount environmentalness story [SEP]']
[ 450/2000] tot_loss=3.186 (perp=12.110, rec=0.428, cos=0.336), tot_loss_proj:4.286 [t=0.24s]
prediction: ['[CLS] poems forces an beloved story is cigarette of honeymoon guilty padma of amount environmental absolutely story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.065 (perp=12.279, rec=0.415, cos=0.194), tot_loss_proj:4.449 [t=0.24s]
prediction: ['[CLS] poems forces an amount story is cigarette the captured guilty padma story outcomes environmental absolutely story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.429 (perp=13.378, rec=0.511, cos=0.243), tot_loss_proj:4.316 [t=0.24s]
prediction: ['[CLS] prophet forces spent an amount story is cigarette of guilty padma story allegro entire absolutely infection [SEP]']
[ 600/2000] tot_loss=3.255 (perp=12.874, rec=0.397, cos=0.283), tot_loss_proj:4.502 [t=0.24s]
prediction: ['[CLS] prophet mother spent an amount story is cigarette your guilty padma story allegro friendship absolutely story [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.009 (perp=11.983, rec=0.409, cos=0.203), tot_loss_proj:4.365 [t=0.24s]
prediction: ['[CLS] is cigarette prophet forces spent an amount story across guilty padma story allegro environmental absolutely story [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.088 (perp=12.322, rec=0.439, cos=0.184), tot_loss_proj:4.484 [t=0.24s]
prediction: ['[CLS] is padma prophet [SEP] spent an amount story your guilty israeli of allegro entire absolutely experience [SEP]']
[ 750/2000] tot_loss=2.978 (perp=12.151, rec=0.397, cos=0.152), tot_loss_proj:4.108 [t=0.24s]
prediction: ['[CLS] is padma prophet [SEP] spent an amount story love topics israeli story allegro entire absolutely story [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.937 (perp=11.919, rec=0.378, cos=0.175), tot_loss_proj:4.085 [t=0.24s]
prediction: ['[CLS] isation editorial [SEP] spent an amount story absolutely thud israeli story allegro environmental an story [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.901 (perp=12.017, rec=0.388, cos=0.109), tot_loss_proj:4.344 [t=0.24s]
prediction: ['[CLS] isation prophet volta spent an amount story absolutely israeli thud story allegro environmental the experience [SEP]']
[ 900/2000] tot_loss=3.334 (perp=13.289, rec=0.365, cos=0.311), tot_loss_proj:4.640 [t=0.24s]
prediction: ['[CLS] isation inspirational volta spent an amount storyntly israeli thud story allegro environmental these experience [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.096 (perp=12.385, rec=0.373, cos=0.246), tot_loss_proj:4.345 [t=0.24s]
prediction: ['[CLS] ownsation inspirational [SEP] spent an amount storyntly israeli is of allegro environmental these experience [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.958 (perp=11.480, rec=0.366, cos=0.296), tot_loss_proj:4.289 [t=0.24s]
prediction: ['[CLS] owns environmental inspirational [SEP] spent an amount storyntly israeli is of allegroation these experience [SEP]']
[1050/2000] tot_loss=2.965 (perp=11.480, rec=0.357, cos=0.313), tot_loss_proj:4.292 [t=0.24s]
prediction: ['[CLS] owns environmental inspirational [SEP] spent an amount storyntly israeli is of allegroation these experience [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.787 (perp=11.180, rec=0.363, cos=0.188), tot_loss_proj:4.183 [t=0.24s]
prediction: ['[CLS] owns environmental inspirational [SEP] spent an amount storyntly israeliation of allegro is these experience [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.739 (perp=10.956, rec=0.360, cos=0.188), tot_loss_proj:4.124 [t=0.24s]
prediction: ['[CLS] israeli environmental inspirational [SEP] spent an amount storyntly ownsation of allegro is these experience [SEP]']
[1200/2000] tot_loss=2.923 (perp=12.014, rec=0.352, cos=0.168), tot_loss_proj:4.088 [t=0.24s]
prediction: ['[CLS] israeli environmental inspirational [SEP] spent an amount storyntly ownsation story poems is mister experience [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.968 (perp=12.125, rec=0.353, cos=0.190), tot_loss_proj:4.041 [t=0.24s]
prediction: ['[CLS] draw environmental inspirational [SEP] spent an amount story israeli ownsation story poems is mister experience [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.725 (perp=10.938, rec=0.349, cos=0.188), tot_loss_proj:3.726 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] absolutely spent an amount story israeli owns ( story poems is mister experience [SEP]']
[1350/2000] tot_loss=2.794 (perp=11.223, rec=0.354, cos=0.195), tot_loss_proj:3.880 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw spent an amount story israeli owns ( story poems is mister experience [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.729 (perp=10.616, rec=0.346, cos=0.260), tot_loss_proj:3.799 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent mister experience [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.704 (perp=10.442, rec=0.346, cos=0.270), tot_loss_proj:3.753 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
[1500/2000] tot_loss=2.746 (perp=10.442, rec=0.350, cos=0.308), tot_loss_proj:3.750 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[1550/2000] tot_loss=2.748 (perp=10.442, rec=0.341, cos=0.319), tot_loss_proj:3.751 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[1600/2000] tot_loss=2.755 (perp=10.442, rec=0.336, cos=0.331), tot_loss_proj:3.747 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
[1650/2000] tot_loss=2.692 (perp=10.442, rec=0.345, cos=0.258), tot_loss_proj:3.748 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[1700/2000] tot_loss=2.636 (perp=10.442, rec=0.345, cos=0.203), tot_loss_proj:3.752 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[1750/2000] tot_loss=2.642 (perp=10.442, rec=0.341, cos=0.214), tot_loss_proj:3.754 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
[1800/2000] tot_loss=2.648 (perp=10.442, rec=0.346, cos=0.214), tot_loss_proj:3.753 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[1850/2000] tot_loss=2.643 (perp=10.442, rec=0.341, cos=0.214), tot_loss_proj:3.754 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[1900/2000] tot_loss=2.655 (perp=10.442, rec=0.340, cos=0.226), tot_loss_proj:3.749 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
[1950/2000] tot_loss=2.656 (perp=10.442, rec=0.338, cos=0.230), tot_loss_proj:3.752 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Attempt swap
[2000/2000] tot_loss=2.671 (perp=10.442, rec=0.339, cos=0.244), tot_loss_proj:3.748 [t=0.24s]
prediction: ['[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] environmental inspirational [SEP] draw is an amount story israeli owns ( story poems spent experience mister [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 36.364 | p: 35.294 | r: 37.500
rouge2     | fm: 6.452 | p: 6.250 | r: 6.667
rougeL     | fm: 30.303 | p: 29.412 | r: 31.250
rougeLsum  | fm: 30.303 | p: 29.412 | r: 31.250
r1fm+r2fm = 42.815

[Aggregate metrics]:
rouge1     | fm: 87.777 | p: 87.063 | r: 88.681
rouge2     | fm: 54.641 | p: 54.421 | r: 54.814
rougeL     | fm: 76.443 | p: 76.007 | r: 77.084
rougeLsum  | fm: 76.223 | p: 75.727 | r: 76.826
r1fm+r2fm = 142.417

input #58 time: 0:09:15 | total time: 8:55:38


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.8177669919603383
highest_index [0]
highest [0.8177669919603383]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8942493200302124 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8512803316116333 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8435871005058289 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8274869918823242 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8036321997642517 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.7866371273994446 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.7751563191413879 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best perm rec loss: 0.7738718390464783 for ['[CLS] fringe war pepper knightsonate cricket counterpart tasting elitecoat vs warm helped mortal dinner creator [SEP]']
[Init] best perm rec loss: 0.7676537036895752 for ['[CLS] war creatoronate fringe elite warm knights helped mortal vscoat dinner pepper cricket tasting counterpart [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.935 (perp=11.376, rec=0.343, cos=0.317), tot_loss_proj:3.815 [t=0.23s]
prediction: ['[CLS] woman club girl athena inism exclusive resident wi device performed her education. heritage linen [SEP]']
[ 100/2000] tot_loss=2.677 (perp=10.579, rec=0.252, cos=0.309), tot_loss_proj:3.572 [t=0.23s]
prediction: ['[CLS] childrens woman knowledge thatism char who scientificism a women of woman char talks [SEP]']
[ 150/2000] tot_loss=2.558 (perp=10.256, rec=0.202, cos=0.305), tot_loss_proj:3.535 [t=0.24s]
prediction: ['[CLS] young life who how ofism char who scientifica a women of woman char has [SEP]']
[ 200/2000] tot_loss=2.415 (perp=9.722, rec=0.145, cos=0.326), tot_loss_proj:3.181 [t=0.24s]
prediction: ['[CLS] young a who knows theism char who chara a screen of woman char has [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.220 (perp=8.895, rec=0.113, cos=0.328), tot_loss_proj:3.172 [t=0.24s]
prediction: ['[CLS] younge who knows theism char theism has a screen of woman chara [SEP]']
[ 300/2000] tot_loss=2.385 (perp=9.772, rec=0.106, cos=0.325), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] young screen who knows theism char theism has a screen of woman chara [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.264 (perp=9.278, rec=0.080, cos=0.329), tot_loss_proj:3.257 [t=0.24s]
prediction: ['[CLS] young screen who knows theism char the screena has a screen of woman char [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.083 (perp=8.318, rec=0.089, cos=0.330), tot_loss_proj:2.877 [t=0.24s]
prediction: ['[CLS] young who knows the screenism char the screena has a hold of woman char [SEP]']
[ 450/2000] tot_loss=2.139 (perp=8.674, rec=0.076, cos=0.328), tot_loss_proj:2.895 [t=0.24s]
prediction: ['[CLS] young who knows the screenism char the howa has a hold of woman char [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.001 (perp=7.961, rec=0.079, cos=0.330), tot_loss_proj:2.723 [t=0.24s]
prediction: ['[CLS] young who knows the screenism char woman howa has a hold of the char [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.983 (perp=7.890, rec=0.074, cos=0.332), tot_loss_proj:2.649 [t=0.24s]
prediction: ['[CLS] young who knows the screen womanism char howa has a hold of the char [SEP]']
[ 600/2000] tot_loss=1.975 (perp=7.890, rec=0.067, cos=0.329), tot_loss_proj:2.653 [t=0.24s]
prediction: ['[CLS] young who knows the screen womanism char howa has a hold of the char [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.975 (perp=7.890, rec=0.067, cos=0.330), tot_loss_proj:2.652 [t=0.24s]
prediction: ['[CLS] young who knows the screen womanism char howa has a hold of the char [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.758 (perp=6.731, rec=0.083, cos=0.329), tot_loss_proj:2.476 [t=0.24s]
prediction: ['[CLS] young who knows the char how screen womanisma has a hold of the char [SEP]']
[ 750/2000] tot_loss=1.748 (perp=6.731, rec=0.072, cos=0.330), tot_loss_proj:2.481 [t=0.24s]
prediction: ['[CLS] young who knows the char how screen womanisma has a hold of the char [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.681 (perp=6.418, rec=0.067, cos=0.330), tot_loss_proj:2.644 [t=0.24s]
prediction: ['[CLS] how young who knows the char screen womanisma has a hold of the char [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.618 (perp=6.065, rec=0.076, cos=0.330), tot_loss_proj:2.328 [t=0.24s]
prediction: ['[CLS] how young who knows the char screen charisma has a hold of the woman [SEP]']
[ 900/2000] tot_loss=1.611 (perp=6.065, rec=0.067, cos=0.331), tot_loss_proj:2.332 [t=0.24s]
prediction: ['[CLS] how young who knows the char screen charisma has a hold of the woman [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.608 (perp=6.065, rec=0.065, cos=0.330), tot_loss_proj:2.332 [t=0.24s]
prediction: ['[CLS] how young who knows the char screen charisma has a hold of the woman [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.551 (perp=5.814, rec=0.059, cos=0.329), tot_loss_proj:2.262 [t=0.24s]
prediction: ['[CLS] how young who knows the char screen charisma has the hold of a woman [SEP]']
[1050/2000] tot_loss=1.568 (perp=5.814, rec=0.075, cos=0.330), tot_loss_proj:2.261 [t=0.24s]
prediction: ['[CLS] how young who knows the char screen charisma has the hold of a woman [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.524 (perp=5.633, rec=0.067, cos=0.331), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1150/2000] tot_loss=1.525 (perp=5.633, rec=0.068, cos=0.330), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
[1200/2000] tot_loss=1.529 (perp=5.633, rec=0.071, cos=0.331), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1250/2000] tot_loss=1.534 (perp=5.633, rec=0.077, cos=0.331), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1300/2000] tot_loss=1.529 (perp=5.633, rec=0.072, cos=0.331), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
[1350/2000] tot_loss=1.531 (perp=5.633, rec=0.074, cos=0.331), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1400/2000] tot_loss=1.522 (perp=5.633, rec=0.065, cos=0.331), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1450/2000] tot_loss=1.509 (perp=5.633, rec=0.052, cos=0.331), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
[1500/2000] tot_loss=1.516 (perp=5.633, rec=0.059, cos=0.331), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1550/2000] tot_loss=1.516 (perp=5.633, rec=0.059, cos=0.331), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.516 (perp=5.633, rec=0.059, cos=0.331), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
[1650/2000] tot_loss=1.524 (perp=5.633, rec=0.067, cos=0.331), tot_loss_proj:2.000 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1700/2000] tot_loss=1.527 (perp=5.633, rec=0.069, cos=0.331), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.516 (perp=5.633, rec=0.059, cos=0.330), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
[1800/2000] tot_loss=1.518 (perp=5.633, rec=0.061, cos=0.330), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1850/2000] tot_loss=1.531 (perp=5.633, rec=0.074, cos=0.330), tot_loss_proj:2.022 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[1900/2000] tot_loss=1.528 (perp=5.633, rec=0.071, cos=0.330), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
[1950/2000] tot_loss=1.515 (perp=5.633, rec=0.058, cos=0.331), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Attempt swap
[2000/2000] tot_loss=1.510 (perp=5.633, rec=0.053, cos=0.331), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] young who knows how the char screen charisma has the hold of a woman [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 120.417

[Aggregate metrics]:
rouge1     | fm: 87.781 | p: 87.068 | r: 88.669
rouge2     | fm: 54.140 | p: 54.019 | r: 54.363
rougeL     | fm: 75.758 | p: 75.355 | r: 76.409
rougeLsum  | fm: 75.824 | p: 75.332 | r: 76.399
r1fm+r2fm = 141.922

input #59 time: 0:09:15 | total time: 9:04:54


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.8879895044524956
highest_index [0]
highest [0.8879895044524956]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9860947728157043 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9616931080818176 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9437880516052246 for ['[CLS] eddiedding whenly became northeast theo solid sighed signsrral frozen [SEP]']
[Init] best rec loss: 0.921430766582489 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.9140443801879883 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.9098033905029297 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.903898298740387 for ['[CLS]chemist myselfkar waiting locking ribbon tear dreams mosaic dorothy sure... [SEP]']
[Init] best rec loss: 0.9015945792198181 for ['[CLS] wright bought keeper states certainhand worst compiled still noise kids collect [SEP]']
[Init] best perm rec loss: 0.899916410446167 for ['[CLS] wright certain states worst compiled still collecthand noise kids bought keeper [SEP]']
[Init] best perm rec loss: 0.8997805714607239 for ['[CLS] noise kids still worst wrighthand compiled collect states bought keeper certain [SEP]']
[Init] best perm rec loss: 0.8997339606285095 for ['[CLS] kids wright bought states certain worsthand still keeper compiled noise collect [SEP]']
[Init] best perm rec loss: 0.898963212966919 for ['[CLS] kids collect certain keeper noise wright stillhand worst bought compiled states [SEP]']
[Init] best perm rec loss: 0.8986561894416809 for ['[CLS] noise certain kids still states compiled collect worst wrighthand bought keeper [SEP]']
[Init] best perm rec loss: 0.89714115858078 for ['[CLS]hand keeper certain states wright compiled noise collect still worst kids bought [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.422 (perp=13.216, rec=0.625, cos=0.153), tot_loss_proj:4.572 [t=0.23s]
prediction: ['[CLS] offers art casual alcoholic praise happened : patience hanna soulay bite [SEP]']
[ 100/2000] tot_loss=3.199 (perp=12.460, rec=0.552, cos=0.155), tot_loss_proj:4.310 [t=0.23s]
prediction: ['[CLS] draws historyium opera praise happened is uncomfortably railroad intenseay occurs [SEP]']
[ 150/2000] tot_loss=3.270 (perp=13.215, rec=0.490, cos=0.137), tot_loss_proj:4.319 [t=0.23s]
prediction: ['[CLS] draws classic awkwardly opera charitable awkwardly : uncomfortablyville excitementay soap [SEP]']
[ 200/2000] tot_loss=3.360 (perp=13.714, rec=0.462, cos=0.156), tot_loss_proj:4.356 [t=0.23s]
prediction: ['[CLS] draws greatest awkwardly opera charitable india : uncomfortablyville depriveday soap [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.271 (perp=13.463, rec=0.455, cos=0.123), tot_loss_proj:4.026 [t=0.23s]
prediction: ['[CLS] sarcastically because chat opera awkwardly thoughts : uncomfortablytively circuit proposes soap [SEP]']
[ 300/2000] tot_loss=3.096 (perp=12.533, rec=0.433, cos=0.157), tot_loss_proj:3.391 [t=0.23s]
prediction: ['[CLS] sarcastically circuit chatェ awkwardly pradesh : uncomfortably awkwardly awkwardly awkwardly soap [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.387 (perp=13.885, rec=0.473, cos=0.137), tot_loss_proj:4.552 [t=0.23s]
prediction: ['[CLS] dryly circuit forumェ awkwardly sensation fiction uncomfortably loop consonants congratulations soap [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.125 (perp=12.913, rec=0.446, cos=0.096), tot_loss_proj:3.621 [t=0.23s]
prediction: ['[CLS] sarcastically circuit forum storyェ awkwardly awkwardly fiction awkwardly desperately consonants awkwardly [SEP]']
[ 450/2000] tot_loss=3.061 (perp=12.504, rec=0.423, cos=0.138), tot_loss_proj:3.526 [t=0.23s]
prediction: ['[CLS] sarcastically circuit forum soapェ awkwardly awkwardly story awkwardly awkwardly consonants awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.428 (perp=14.257, rec=0.435, cos=0.142), tot_loss_proj:3.855 [t=0.23s]
prediction: ['[CLS] awkwardly circuit denotes soapurity awkwardly awkwardly story uncomfortably awkwardly consonants awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.102 (perp=12.552, rec=0.389, cos=0.202), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly denotes soap opera circuit awkwardly story awkwardly awkwardly consonants awkwardly [SEP]']
[ 600/2000] tot_loss=3.300 (perp=13.562, rec=0.403, cos=0.185), tot_loss_proj:3.787 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly depends story opera circuit awkwardly story uncomfortably awkwardly parliament awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.025 (perp=12.337, rec=0.379, cos=0.178), tot_loss_proj:3.459 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament story opera circuit awkwardly story uncomfortably awkwardly denotes awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.879 (perp=11.846, rec=0.388, cos=0.122), tot_loss_proj:3.320 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit opera story awkwardly story uncomfortably awkwardly derives awkwardly [SEP]']
[ 750/2000] tot_loss=2.916 (perp=11.846, rec=0.375, cos=0.171), tot_loss_proj:3.323 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit opera story awkwardly story uncomfortably awkwardly derives awkwardly [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.866 (perp=11.971, rec=0.364, cos=0.108), tot_loss_proj:3.431 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit opera story story awkwardly awkwardly awkwardly derives awkwardly [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.846 (perp=11.577, rec=0.377, cos=0.153), tot_loss_proj:3.292 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit opera story story uncomfortably awkwardly awkwardly derives awkwardly [SEP]']
[ 900/2000] tot_loss=2.990 (perp=12.614, rec=0.353, cos=0.113), tot_loss_proj:3.558 [t=0.23s]
prediction: ['[CLS] congressman awkwardly parliament circuit opera story story awkwardly awkwardly awkwardly derives awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.150 (perp=12.998, rec=0.349, cos=0.201), tot_loss_proj:3.686 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit ª story story awkwardly awkwardly awkwardly derives congressman [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.993 (perp=12.719, rec=0.361, cos=0.088), tot_loss_proj:3.509 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit the ª story uncomfortably awkwardly awkwardly derives congressman [SEP]']
[1050/2000] tot_loss=3.181 (perp=13.509, rec=0.347, cos=0.132), tot_loss_proj:3.712 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly parliament circuit lies ª story awkwardly awkwardly awkwardly derives congressman [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.103 (perp=12.989, rec=0.350, cos=0.155), tot_loss_proj:3.492 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit awkwardly ª story lies awkwardly awkwardly derives congressman [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.063 (perp=12.611, rec=0.331, cos=0.210), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly derives quiz [SEP]']
[1200/2000] tot_loss=2.978 (perp=12.611, rec=0.319, cos=0.137), tot_loss_proj:3.444 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly derives quiz [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.987 (perp=12.545, rec=0.328, cos=0.150), tot_loss_proj:3.529 [t=0.23s]
prediction: ['[CLS] congressman awkwardly parliament circuit story ª awkwardly lies awkwardly awkwardly derives awkwardly [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.054 (perp=12.737, rec=0.325, cos=0.182), tot_loss_proj:3.469 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly derives cerambycidae [SEP]']
[1350/2000] tot_loss=3.013 (perp=12.737, rec=0.318, cos=0.147), tot_loss_proj:3.473 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly derives cerambycidae [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.975 (perp=12.382, rec=0.322, cos=0.177), tot_loss_proj:3.402 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly cerambycidae derives [SEP]']
Attempt swap
[1450/2000] tot_loss=2.973 (perp=12.382, rec=0.319, cos=0.177), tot_loss_proj:3.398 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly cerambycidae derives [SEP]']
[1500/2000] tot_loss=2.998 (perp=12.382, rec=0.308, cos=0.214), tot_loss_proj:3.400 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly cerambycidae derives [SEP]']
Attempt swap
[1550/2000] tot_loss=2.910 (perp=12.382, rec=0.325, cos=0.109), tot_loss_proj:3.393 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly pradesh circuit story ª awkwardly lies awkwardly awkwardly cerambycidae derives [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=3.177 (perp=13.400, rec=0.331, cos=0.166), tot_loss_proj:3.732 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly congressman pradesh circuit story ª awkwardly story awkwardly awkwardly derives [SEP]']
[1650/2000] tot_loss=2.838 (perp=12.124, rec=0.323, cos=0.090), tot_loss_proj:3.407 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh circuit story ª awkwardly story awkwardly awkwardly derives [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=2.873 (perp=12.246, rec=0.317, cos=0.107), tot_loss_proj:3.364 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh circuit story lies ª awkwardly awkwardly awkwardly derives [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.806 (perp=11.769, rec=0.334, cos=0.118), tot_loss_proj:3.353 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly awkwardly derives [SEP]']
[1800/2000] tot_loss=2.767 (perp=11.769, rec=0.315, cos=0.098), tot_loss_proj:3.359 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly awkwardly derives [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=2.777 (perp=11.769, rec=0.321, cos=0.102), tot_loss_proj:3.352 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly awkwardly derives [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.824 (perp=11.723, rec=0.314, cos=0.166), tot_loss_proj:3.384 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly derives awkwardly [SEP]']
[1950/2000] tot_loss=2.776 (perp=11.723, rec=0.304, cos=0.127), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly derives awkwardly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.752 (perp=11.723, rec=0.303, cos=0.104), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly derives awkwardly [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] awkwardly awkwardly quiz pradesh story circuit story ª awkwardly awkwardly derives awkwardly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 41.667 | p: 38.462 | r: 45.455
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 33.333 | p: 30.769 | r: 36.364
rougeLsum  | fm: 33.333 | p: 30.769 | r: 36.364
r1fm+r2fm = 41.667

[Aggregate metrics]:
rouge1     | fm: 87.132 | p: 86.350 | r: 88.044
rouge2     | fm: 53.093 | p: 52.940 | r: 53.245
rougeL     | fm: 75.320 | p: 74.783 | r: 75.916
rougeLsum  | fm: 74.928 | p: 74.454 | r: 75.613
r1fm+r2fm = 140.225

input #60 time: 0:09:09 | total time: 9:14:03


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.7985734025857449
highest_index [0]
highest [0.7985734025857449]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9695403575897217 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9652366638183594 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9567133188247681 for ['[CLS] alta http cocked [SEP]']
[Init] best rec loss: 0.9498089551925659 for ['[CLS] tiny poor rail [SEP]']
[Init] best rec loss: 0.931925356388092 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 0.920120894908905 for ['[CLS] mouth lastless [SEP]']
[Init] best rec loss: 0.9053359627723694 for ['[CLS] readyppetphonic [SEP]']
[Init] best rec loss: 0.8669896721839905 for ['[CLS] says -vino [SEP]']
[Init] best rec loss: 0.8472865223884583 for ['[CLS] vehicle surrounding south [SEP]']
[Init] best perm rec loss: 0.8443810939788818 for ['[CLS] surrounding vehicle south [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.231 (perp=8.309, rec=0.206, cos=0.362), tot_loss_proj:2.458 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 100/2000] tot_loss=2.176 (perp=8.309, rec=0.154, cos=0.360), tot_loss_proj:2.457 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 150/2000] tot_loss=2.186 (perp=8.309, rec=0.162, cos=0.362), tot_loss_proj:2.450 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 200/2000] tot_loss=2.173 (perp=8.309, rec=0.150, cos=0.362), tot_loss_proj:2.450 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.179 (perp=8.309, rec=0.154, cos=0.363), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 300/2000] tot_loss=2.169 (perp=8.309, rec=0.146, cos=0.361), tot_loss_proj:2.441 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.179 (perp=8.309, rec=0.156, cos=0.361), tot_loss_proj:2.450 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.156 (perp=8.309, rec=0.133, cos=0.361), tot_loss_proj:2.444 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 450/2000] tot_loss=2.047 (perp=7.752, rec=0.135, cos=0.362), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.045 (perp=7.752, rec=0.135, cos=0.360), tot_loss_proj:2.222 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.869 (perp=7.102, rec=0.092, cos=0.357), tot_loss_proj:2.029 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.856 (perp=7.102, rec=0.075, cos=0.361), tot_loss_proj:2.025 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.854 (perp=7.102, rec=0.072, cos=0.361), tot_loss_proj:2.027 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.861 (perp=7.102, rec=0.079, cos=0.361), tot_loss_proj:2.019 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.843 (perp=7.102, rec=0.061, cos=0.362), tot_loss_proj:2.034 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.843 (perp=7.102, rec=0.061, cos=0.362), tot_loss_proj:2.023 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.846 (perp=7.102, rec=0.064, cos=0.362), tot_loss_proj:2.018 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.855 (perp=7.102, rec=0.073, cos=0.362), tot_loss_proj:2.024 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.836 (perp=7.102, rec=0.054, cos=0.362), tot_loss_proj:2.023 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.849 (perp=7.102, rec=0.067, cos=0.362), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.846 (perp=7.102, rec=0.064, cos=0.362), tot_loss_proj:2.022 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.846 (perp=7.102, rec=0.063, cos=0.362), tot_loss_proj:2.021 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.854 (perp=7.102, rec=0.072, cos=0.362), tot_loss_proj:2.024 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.848 (perp=7.102, rec=0.065, cos=0.362), tot_loss_proj:2.022 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.840 (perp=7.102, rec=0.057, cos=0.362), tot_loss_proj:2.025 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.847 (perp=7.102, rec=0.065, cos=0.362), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.852 (perp=7.102, rec=0.069, cos=0.362), tot_loss_proj:2.021 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.849 (perp=7.102, rec=0.067, cos=0.362), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.847 (perp=7.102, rec=0.065, cos=0.362), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.839 (perp=7.102, rec=0.056, cos=0.362), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.843 (perp=7.102, rec=0.061, cos=0.362), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.846 (perp=7.102, rec=0.064, cos=0.362), tot_loss_proj:2.026 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.845 (perp=7.102, rec=0.063, cos=0.362), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.845 (perp=7.102, rec=0.063, cos=0.362), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.841 (perp=7.102, rec=0.058, cos=0.362), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.840 (perp=7.102, rec=0.057, cos=0.362), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.845 (perp=7.102, rec=0.063, cos=0.362), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.851 (perp=7.102, rec=0.068, cos=0.362), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.851 (perp=7.102, rec=0.069, cos=0.362), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.849 (perp=7.102, rec=0.067, cos=0.362), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.245 | p: 86.502 | r: 88.137
rouge2     | fm: 54.104 | p: 53.955 | r: 54.306
rougeL     | fm: 75.658 | p: 75.157 | r: 76.288
rougeLsum  | fm: 75.398 | p: 74.888 | r: 76.021
r1fm+r2fm = 141.349

input #61 time: 0:09:01 | total time: 9:23:04


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.8329747733195756
highest_index [0]
highest [0.8329747733195756]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9149655103683472 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.8893359899520874 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.8874815106391907 for ['[CLS] services te isbnentseye久 researchcreen past sequencingwn can pier precise linda erica monk val contestbe foreign [SEP]']
[Init] best rec loss: 0.882582426071167 for ['[CLS]ining strata won suitedtis near isaac bull worship here techp perhaps assistant kerman negative fisulsion ash too skill [SEP]']
[Init] best rec loss: 0.87846440076828 for ['[CLS]ecure armedria obvious commission symbol echo drinking testified mothergaard reacher executive dressed playing but name ups [SEP] [MASK] kala [SEP]']
[Init] best rec loss: 0.8667653203010559 for ['[CLS] part remembered victor jayne imagined♭ basket against cheeks barrow battalion whilefold informed had higher outstanding ezio ramirez malta pinyin [SEP]']
[Init] best perm rec loss: 0.8663511276245117 for ['[CLS]♭ battalion jayne barrow malta informed victor remembered ramirez cheeks imagined hadfold basket against outstanding part while ezio higher pinyin [SEP]']
[Init] best perm rec loss: 0.8662666082382202 for ['[CLS] while basket cheeks remembered had ezio jayne higher imagined♭ victor pinyinfold ramirez outstanding battalion part barrow against informed malta [SEP]']
[Init] best perm rec loss: 0.863218367099762 for ['[CLS] imagined outstanding♭ informed barrow basket pinyin victor while against cheeksfold part had malta remembered battalion ramirez jayne ezio higher [SEP]']
[Init] best perm rec loss: 0.8630019426345825 for ['[CLS] ezio barrow cheeks higher remembered battalion imagined jayne pinyin ramirez outstanding had basket against part♭ while maltafold informed victor [SEP]']
[Init] best perm rec loss: 0.862498939037323 for ['[CLS] against battalion ramirez part cheeks basket outstanding higher barrowfold informed while pinyin victor had ezio imagined jayne♭ remembered malta [SEP]']
[Init] best perm rec loss: 0.8621318340301514 for ['[CLS] while♭ informed battalion ramirezfold imagined barrow against jayne outstanding basket remembered had pinyin ezio victor part cheeks higher malta [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.143 (perp=12.384, rec=0.364, cos=0.302), tot_loss_proj:4.036 [t=0.22s]
prediction: ['[CLS] paid ability value for thorne derek prevention drama better international acclaimed as nautical energy win accomplished strong silas architecture originally best [SEP]']
[ 100/2000] tot_loss=2.320 (perp=8.800, rec=0.256, cos=0.304), tot_loss_proj:3.114 [t=0.22s]
prediction: ['[CLS] grace grace value to grace to prevention than better its called best war the movies a best war movies now best [SEP]']
[ 150/2000] tot_loss=2.202 (perp=8.626, rec=0.183, cos=0.294), tot_loss_proj:2.856 [t=0.22s]
prediction: ['[CLS] grace grace value to grace to prevention or him especially found among war the movies the best war movies now best [SEP]']
[ 200/2000] tot_loss=2.332 (perp=9.433, rec=0.145, cos=0.300), tot_loss_proj:3.718 [t=0.22s]
prediction: ['[CLS] grace grace crown to grace for prevention rather for rather making among blame the movies a best war movies made ever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.167 (perp=8.634, rec=0.134, cos=0.307), tot_loss_proj:3.184 [t=0.22s]
prediction: ['[CLS] grace grace crown to grace call prevention rather for rather making among earth movies one the best war movies made ever [SEP]']
[ 300/2000] tot_loss=2.197 (perp=8.876, rec=0.117, cos=0.304), tot_loss_proj:2.963 [t=0.22s]
prediction: ['[CLS] grace grace crown to grace call prevention rather for place making among earth movies one the best war movies made ever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.164 (perp=8.749, rec=0.109, cos=0.304), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS] grace grace the to grace call prevention rather for making both one blame movies one the best war movies made ever [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.185 (perp=8.884, rec=0.108, cos=0.300), tot_loss_proj:3.385 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making place one blame the it the best war movies made ever [SEP]']
[ 450/2000] tot_loss=2.180 (perp=8.884, rec=0.099, cos=0.304), tot_loss_proj:3.379 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making place one blame the it the best war movies made ever [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.057 (perp=8.341, rec=0.087, cos=0.302), tot_loss_proj:3.303 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making place one blame the it the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.963 (perp=7.810, rec=0.096, cos=0.305), tot_loss_proj:3.235 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making one of blame the it the best war movies ever made [SEP]']
[ 600/2000] tot_loss=1.961 (perp=7.810, rec=0.094, cos=0.305), tot_loss_proj:3.233 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making one of blame the it the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.817 (perp=7.056, rec=0.102, cos=0.304), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.808 (perp=7.056, rec=0.090, cos=0.306), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making one, the blame it the best war movies ever made [SEP]']
[ 750/2000] tot_loss=1.802 (perp=7.056, rec=0.085, cos=0.305), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.806 (perp=7.056, rec=0.089, cos=0.306), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call prevention rather for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.790 (perp=7.015, rec=0.084, cos=0.303), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[ 900/2000] tot_loss=1.807 (perp=7.015, rec=0.098, cos=0.306), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.795 (perp=7.015, rec=0.087, cos=0.305), tot_loss_proj:2.734 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=7.015, rec=0.097, cos=0.304), tot_loss_proj:2.739 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1050/2000] tot_loss=1.797 (perp=7.015, rec=0.088, cos=0.306), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1100/2000] tot_loss=1.798 (perp=7.015, rec=0.089, cos=0.306), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1150/2000] tot_loss=1.796 (perp=7.015, rec=0.088, cos=0.305), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1200/2000] tot_loss=1.802 (perp=7.015, rec=0.093, cos=0.306), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] grace grace movies to grace call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.769 (perp=6.856, rec=0.093, cos=0.305), tot_loss_proj:2.730 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1300/2000] tot_loss=1.769 (perp=6.856, rec=0.092, cos=0.305), tot_loss_proj:2.729 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1350/2000] tot_loss=1.765 (perp=6.856, rec=0.089, cos=0.305), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1400/2000] tot_loss=1.774 (perp=6.856, rec=0.097, cos=0.306), tot_loss_proj:2.731 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.766 (perp=6.856, rec=0.089, cos=0.306), tot_loss_proj:2.728 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1500/2000] tot_loss=1.767 (perp=6.856, rec=0.090, cos=0.305), tot_loss_proj:2.730 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.765 (perp=6.856, rec=0.088, cos=0.306), tot_loss_proj:2.731 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1600/2000] tot_loss=1.764 (perp=6.856, rec=0.087, cos=0.305), tot_loss_proj:2.728 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1650/2000] tot_loss=1.771 (perp=6.856, rec=0.094, cos=0.306), tot_loss_proj:2.729 [t=0.22s]
prediction: ['[CLS] grace grace to grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.742 (perp=6.737, rec=0.090, cos=0.305), tot_loss_proj:2.651 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.737 (perp=6.737, rec=0.084, cos=0.306), tot_loss_proj:2.650 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1800/2000] tot_loss=1.741 (perp=6.737, rec=0.088, cos=0.306), tot_loss_proj:2.653 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.745 (perp=6.737, rec=0.092, cos=0.306), tot_loss_proj:2.654 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.743 (perp=6.737, rec=0.089, cos=0.306), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.729 (perp=6.737, rec=0.076, cos=0.306), tot_loss_proj:2.653 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.740 (perp=6.737, rec=0.086, cos=0.306), tot_loss_proj:2.654 [t=0.22s]
prediction: ['[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to grace grace movies call rather prevention for making one, the blame it the best war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 38.095 | p: 38.095 | r: 38.095
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 119.913

[Aggregate metrics]:
rouge1     | fm: 87.186 | p: 86.485 | r: 88.055
rouge2     | fm: 53.693 | p: 53.534 | r: 53.861
rougeL     | fm: 75.429 | p: 74.922 | r: 76.030
rougeLsum  | fm: 75.140 | p: 74.640 | r: 75.801
r1fm+r2fm = 140.879

input #62 time: 0:08:54 | total time: 9:31:59


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.8978799556355587
highest_index [0]
highest [0.8978799556355587]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8076167702674866 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7167317271232605 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.6881594657897949 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best perm rec loss: 0.686606764793396 for ['[CLS] written workingism brighter spend [SEP]']
[Init] best perm rec loss: 0.6840464472770691 for ['[CLS] brighter working spendism written [SEP]']
[Init] best perm rec loss: 0.6839225888252258 for ['[CLS] written spend workingism brighter [SEP]']
[Init] best perm rec loss: 0.6823365092277527 for ['[CLS] spend writtenism working brighter [SEP]']
[Init] best perm rec loss: 0.6813101172447205 for ['[CLS]ism written spend brighter working [SEP]']
[Init] best perm rec loss: 0.6796262264251709 for ['[CLS] writtenism spend working brighter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.205 (perp=8.962, rec=0.221, cos=0.191), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS] ticket return ticket return seeking [SEP]']
[ 100/2000] tot_loss=2.174 (perp=9.212, rec=0.145, cos=0.187), tot_loss_proj:3.054 [t=0.22s]
prediction: ['[CLS] ticket return ticket return looking [SEP]']
[ 150/2000] tot_loss=2.047 (perp=8.826, rec=0.090, cos=0.192), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] for return ticket for looking [SEP]']
[ 200/2000] tot_loss=2.034 (perp=8.800, rec=0.080, cos=0.194), tot_loss_proj:2.674 [t=0.22s]
prediction: ['[CLS] a return ticket for looking [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.873 (perp=8.121, rec=0.058, cos=0.191), tot_loss_proj:2.279 [t=0.22s]
prediction: ['[CLS] for a return ticket looking [SEP]']
[ 300/2000] tot_loss=1.889 (perp=8.121, rec=0.071, cos=0.194), tot_loss_proj:2.274 [t=0.22s]
prediction: ['[CLS] for a return ticket looking [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.475 (perp=6.111, rec=0.060, cos=0.192), tot_loss_proj:1.505 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.480 (perp=6.111, rec=0.065, cos=0.193), tot_loss_proj:1.504 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.473 (perp=6.111, rec=0.057, cos=0.193), tot_loss_proj:1.494 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.478 (perp=6.111, rec=0.062, cos=0.194), tot_loss_proj:1.498 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.472 (perp=6.111, rec=0.057, cos=0.193), tot_loss_proj:1.502 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.476 (perp=6.111, rec=0.065, cos=0.189), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.476 (perp=6.111, rec=0.061, cos=0.193), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.475 (perp=6.111, rec=0.060, cos=0.193), tot_loss_proj:1.490 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.469 (perp=6.111, rec=0.053, cos=0.193), tot_loss_proj:1.490 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.480 (perp=6.111, rec=0.065, cos=0.194), tot_loss_proj:1.501 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.488 (perp=6.111, rec=0.072, cos=0.194), tot_loss_proj:1.503 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.466 (perp=6.111, rec=0.052, cos=0.192), tot_loss_proj:1.509 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.472 (perp=6.111, rec=0.056, cos=0.193), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.469 (perp=6.111, rec=0.053, cos=0.193), tot_loss_proj:1.502 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.469 (perp=6.111, rec=0.053, cos=0.194), tot_loss_proj:1.503 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.481 (perp=6.111, rec=0.065, cos=0.193), tot_loss_proj:1.500 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.481 (perp=6.111, rec=0.065, cos=0.194), tot_loss_proj:1.495 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.468 (perp=6.111, rec=0.052, cos=0.194), tot_loss_proj:1.506 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.476 (perp=6.111, rec=0.060, cos=0.194), tot_loss_proj:1.510 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.472 (perp=6.111, rec=0.057, cos=0.194), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.491 (perp=6.111, rec=0.075, cos=0.194), tot_loss_proj:1.501 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.486 (perp=6.111, rec=0.070, cos=0.194), tot_loss_proj:1.516 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.477 (perp=6.111, rec=0.061, cos=0.194), tot_loss_proj:1.506 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.472 (perp=6.111, rec=0.056, cos=0.194), tot_loss_proj:1.495 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.473 (perp=6.111, rec=0.058, cos=0.194), tot_loss_proj:1.504 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.481 (perp=6.111, rec=0.065, cos=0.194), tot_loss_proj:1.503 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.479 (perp=6.111, rec=0.063, cos=0.194), tot_loss_proj:1.508 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.476 (perp=6.111, rec=0.060, cos=0.194), tot_loss_proj:1.499 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.473 (perp=6.111, rec=0.057, cos=0.194), tot_loss_proj:1.495 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.474 (perp=6.111, rec=0.058, cos=0.194), tot_loss_proj:1.502 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=6.111, rec=0.066, cos=0.193), tot_loss_proj:1.493 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.479 (perp=6.111, rec=0.063, cos=0.193), tot_loss_proj:1.493 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.484 (perp=6.111, rec=0.068, cos=0.193), tot_loss_proj:1.501 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.476 (perp=6.111, rec=0.060, cos=0.193), tot_loss_proj:1.487 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.407 | p: 86.711 | r: 88.295
rouge2     | fm: 54.387 | p: 54.211 | r: 54.589
rougeL     | fm: 75.778 | p: 75.331 | r: 76.379
rougeLsum  | fm: 75.565 | p: 75.086 | r: 76.209
r1fm+r2fm = 141.794

input #63 time: 0:08:47 | total time: 9:40:46


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.8568732019342664
highest_index [0]
highest [0.8568732019342664]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8766970634460449 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8228490948677063 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8134066462516785 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.7263128757476807 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.673725962638855 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6718490719795227 for ['[CLS]onale visions water [SEP]']
[Init] best perm rec loss: 0.6699950098991394 for ['[CLS] visionsonale water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.528 (perp=10.304, rec=0.201, cos=0.266), tot_loss_proj:2.663 [t=0.22s]
prediction: ['[CLS] horror strange horror [SEP]']
[ 100/2000] tot_loss=2.450 (perp=10.304, rec=0.132, cos=0.257), tot_loss_proj:2.655 [t=0.22s]
prediction: ['[CLS] horror strange horror [SEP]']
[ 150/2000] tot_loss=2.447 (perp=10.304, rec=0.128, cos=0.258), tot_loss_proj:2.651 [t=0.22s]
prediction: ['[CLS] horror strange horror [SEP]']
[ 200/2000] tot_loss=2.555 (perp=10.874, rec=0.119, cos=0.261), tot_loss_proj:2.972 [t=0.22s]
prediction: ['[CLS] horror strange strange [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.128 (perp=8.961, rec=0.074, cos=0.262), tot_loss_proj:2.464 [t=0.22s]
prediction: ['[CLS] strange the horror [SEP]']
[ 300/2000] tot_loss=2.124 (perp=8.961, rec=0.068, cos=0.264), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] strange the horror [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.943 (perp=8.065, rec=0.069, cos=0.261), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.945 (perp=8.065, rec=0.069, cos=0.264), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.955 (perp=8.065, rec=0.078, cos=0.264), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.940 (perp=8.065, rec=0.063, cos=0.264), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.939 (perp=8.065, rec=0.061, cos=0.265), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.937 (perp=8.065, rec=0.058, cos=0.265), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.934 (perp=8.065, rec=0.056, cos=0.265), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.947 (perp=8.065, rec=0.069, cos=0.265), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.936 (perp=8.065, rec=0.058, cos=0.265), tot_loss_proj:1.957 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.943 (perp=8.065, rec=0.065, cos=0.265), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.944 (perp=8.065, rec=0.066, cos=0.265), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.940 (perp=8.065, rec=0.062, cos=0.265), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.942 (perp=8.065, rec=0.064, cos=0.265), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.939 (perp=8.065, rec=0.061, cos=0.265), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.946 (perp=8.065, rec=0.067, cos=0.266), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.942 (perp=8.065, rec=0.064, cos=0.265), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.940 (perp=8.065, rec=0.062, cos=0.265), tot_loss_proj:1.949 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.931 (perp=8.065, rec=0.053, cos=0.266), tot_loss_proj:1.951 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.947 (perp=8.065, rec=0.068, cos=0.266), tot_loss_proj:1.956 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.937 (perp=8.065, rec=0.059, cos=0.266), tot_loss_proj:1.963 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.932 (perp=8.065, rec=0.053, cos=0.266), tot_loss_proj:1.960 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.922 (perp=8.065, rec=0.044, cos=0.266), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.940 (perp=8.065, rec=0.062, cos=0.266), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.928 (perp=8.065, rec=0.049, cos=0.266), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.942 (perp=8.065, rec=0.064, cos=0.266), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.951 (perp=8.065, rec=0.073, cos=0.266), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.938 (perp=8.065, rec=0.060, cos=0.265), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.943 (perp=8.065, rec=0.065, cos=0.266), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.951 (perp=8.065, rec=0.072, cos=0.266), tot_loss_proj:1.965 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.950 (perp=8.065, rec=0.072, cos=0.266), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.939 (perp=8.065, rec=0.061, cos=0.266), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.941 (perp=8.065, rec=0.062, cos=0.266), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.937 (perp=8.065, rec=0.059, cos=0.266), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.935 (perp=8.065, rec=0.057, cos=0.266), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.646 | p: 86.933 | r: 88.451
rouge2     | fm: 55.133 | p: 55.002 | r: 55.360
rougeL     | fm: 76.102 | p: 75.625 | r: 76.748
rougeLsum  | fm: 76.190 | p: 75.699 | r: 76.853
r1fm+r2fm = 142.779

input #64 time: 0:08:47 | total time: 9:49:34


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.7800051091514505
highest_index [0]
highest [0.7800051091514505]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8897808790206909 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.8780049681663513 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.869213342666626 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8482650518417358 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 0.8375337719917297 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.832327127456665 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8131659626960754 for ['[CLS] dancer relative being bar shoulder allmusic original eatingolic [SEP]']
[Init] best rec loss: 0.7880293130874634 for ['[CLS] graphic - oxygen jessie go distinguished they alt decommissioned [SEP]']
[Init] best rec loss: 0.7574506402015686 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.756237804889679 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.7547119855880737 for ['[CLS] even news pu someday fun general oversmamenthoff [SEP]']
[Init] best perm rec loss: 0.7531959414482117 for ['[CLS] pu news even oversmament someday funhoff general [SEP]']
[Init] best perm rec loss: 0.7512656450271606 for ['[CLS] news generalmament overs pu even funhoff someday [SEP]']
[Init] best perm rec loss: 0.7512330412864685 for ['[CLS]mament news general pu overs someday evenhoff fun [SEP]']
[Init] best perm rec loss: 0.7509897351264954 for ['[CLS]mament news pu even fun overshoff someday general [SEP]']
[Init] best perm rec loss: 0.7509357929229736 for ['[CLS]hoff news overs someday general funmament pu even [SEP]']
[Init] best perm rec loss: 0.7502284049987793 for ['[CLS] news overs even general somedayhoff funmament pu [SEP]']
[Init] best perm rec loss: 0.7500160932540894 for ['[CLS] fun someday oversmament generalhoff even news pu [SEP]']
[Init] best perm rec loss: 0.7495999932289124 for ['[CLS] funmament pu generalhoff news someday overs even [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.639 (perp=10.028, rec=0.252, cos=0.382), tot_loss_proj:2.918 [t=0.22s]
prediction: ['[CLS] joy joyous maximum young, effect based for [SEP]']
[ 100/2000] tot_loss=2.170 (perp=7.978, rec=0.188, cos=0.387), tot_loss_proj:2.434 [t=0.22s]
prediction: ['[CLS] joy joyous film young, effected of [SEP]']
[ 150/2000] tot_loss=2.334 (perp=9.003, rec=0.144, cos=0.389), tot_loss_proj:2.924 [t=0.22s]
prediction: ['[CLS] joy joyous rom a, filmp film [SEP]']
[ 200/2000] tot_loss=2.298 (perp=9.003, rec=0.112, cos=0.386), tot_loss_proj:2.908 [t=0.22s]
prediction: ['[CLS] joy joyous rom a, filmp film [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.979 (perp=7.512, rec=0.089, cos=0.387), tot_loss_proj:2.326 [t=0.22s]
prediction: ['[CLS] joy joyous romp a, film film [SEP]']
[ 300/2000] tot_loss=1.982 (perp=7.512, rec=0.092, cos=0.388), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] joy joyous romp a, film film [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.647 (perp=5.869, rec=0.086, cos=0.387), tot_loss_proj:1.938 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.630 (perp=5.869, rec=0.068, cos=0.388), tot_loss_proj:1.937 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[ 450/2000] tot_loss=1.643 (perp=5.869, rec=0.081, cos=0.389), tot_loss_proj:1.930 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.641 (perp=5.869, rec=0.078, cos=0.389), tot_loss_proj:1.942 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.646 (perp=5.869, rec=0.084, cos=0.389), tot_loss_proj:1.928 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[ 600/2000] tot_loss=1.637 (perp=5.869, rec=0.074, cos=0.389), tot_loss_proj:1.938 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.648 (perp=5.869, rec=0.085, cos=0.389), tot_loss_proj:1.935 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.636 (perp=5.869, rec=0.073, cos=0.389), tot_loss_proj:1.938 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[ 750/2000] tot_loss=1.631 (perp=5.869, rec=0.068, cos=0.389), tot_loss_proj:1.944 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.630 (perp=5.869, rec=0.066, cos=0.390), tot_loss_proj:1.937 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.636 (perp=5.869, rec=0.073, cos=0.389), tot_loss_proj:1.940 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[ 900/2000] tot_loss=1.634 (perp=5.869, rec=0.070, cos=0.390), tot_loss_proj:1.932 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.631 (perp=5.869, rec=0.067, cos=0.390), tot_loss_proj:1.931 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.638 (perp=5.869, rec=0.075, cos=0.390), tot_loss_proj:1.928 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1050/2000] tot_loss=1.643 (perp=5.869, rec=0.080, cos=0.390), tot_loss_proj:1.929 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.638 (perp=5.869, rec=0.075, cos=0.390), tot_loss_proj:1.933 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.641 (perp=5.869, rec=0.078, cos=0.390), tot_loss_proj:1.939 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1200/2000] tot_loss=1.642 (perp=5.869, rec=0.079, cos=0.390), tot_loss_proj:1.935 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.627 (perp=5.869, rec=0.063, cos=0.390), tot_loss_proj:1.926 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.636 (perp=5.869, rec=0.072, cos=0.390), tot_loss_proj:1.933 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1350/2000] tot_loss=1.637 (perp=5.869, rec=0.073, cos=0.390), tot_loss_proj:1.936 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.653 (perp=5.869, rec=0.089, cos=0.390), tot_loss_proj:1.936 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.634 (perp=5.869, rec=0.070, cos=0.390), tot_loss_proj:1.927 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1500/2000] tot_loss=1.641 (perp=5.869, rec=0.077, cos=0.390), tot_loss_proj:1.936 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.637 (perp=5.869, rec=0.073, cos=0.390), tot_loss_proj:1.937 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.650 (perp=5.869, rec=0.086, cos=0.390), tot_loss_proj:1.937 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1650/2000] tot_loss=1.636 (perp=5.869, rec=0.072, cos=0.390), tot_loss_proj:1.927 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.632 (perp=5.869, rec=0.068, cos=0.390), tot_loss_proj:1.931 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.623 (perp=5.869, rec=0.059, cos=0.390), tot_loss_proj:1.940 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1800/2000] tot_loss=1.635 (perp=5.869, rec=0.071, cos=0.390), tot_loss_proj:1.932 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.634 (perp=5.869, rec=0.070, cos=0.390), tot_loss_proj:1.933 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.640 (perp=5.869, rec=0.076, cos=0.390), tot_loss_proj:1.945 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
[1950/2000] tot_loss=1.643 (perp=5.869, rec=0.079, cos=0.390), tot_loss_proj:1.934 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.637 (perp=5.869, rec=0.073, cos=0.390), tot_loss_proj:1.940 [t=0.22s]
prediction: ['[CLS] joy joyous romp film, a film [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joy joyous romp film, a film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 87.521 | p: 86.803 | r: 88.439
rouge2     | fm: 54.944 | p: 54.752 | r: 55.174
rougeL     | fm: 76.107 | p: 75.491 | r: 76.790
rougeLsum  | fm: 76.112 | p: 75.584 | r: 76.874
r1fm+r2fm = 142.465

input #65 time: 0:08:48 | total time: 9:58:23


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.8347387574153533
highest_index [0]
highest [0.8347387574153533]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8482159376144409 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.822351336479187 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.8146589994430542 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8008697032928467 for ['[CLS] riot equal private peculiar [SEP]']
[Init] best rec loss: 0.7910727262496948 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.7643316388130188 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 0.7547487616539001 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.7305448055267334 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best perm rec loss: 0.7265404462814331 for ['[CLS] game scout shoulders juliet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.698 (perp=10.862, rec=0.222, cos=0.304), tot_loss_proj:3.031 [t=0.23s]
prediction: ['[CLS] longtime fan medieval tolkien [SEP]']
[ 100/2000] tot_loss=2.504 (perp=10.451, rec=0.115, cos=0.298), tot_loss_proj:2.907 [t=0.23s]
prediction: ['[CLS] longtime fan tolkien tolkien [SEP]']
[ 150/2000] tot_loss=2.490 (perp=10.451, rec=0.097, cos=0.303), tot_loss_proj:2.911 [t=0.23s]
prediction: ['[CLS] longtime fan tolkien tolkien [SEP]']
[ 200/2000] tot_loss=2.484 (perp=10.451, rec=0.097, cos=0.297), tot_loss_proj:2.914 [t=0.23s]
prediction: ['[CLS] longtime fan tolkien tolkien [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.153 (perp=8.773, rec=0.099, cos=0.299), tot_loss_proj:2.286 [t=0.23s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.910 (perp=7.672, rec=0.073, cos=0.303), tot_loss_proj:1.902 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.895 (perp=7.672, rec=0.057, cos=0.303), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.900 (perp=7.672, rec=0.063, cos=0.302), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.894 (perp=7.672, rec=0.057, cos=0.303), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.892 (perp=7.672, rec=0.055, cos=0.303), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.897 (perp=7.672, rec=0.060, cos=0.303), tot_loss_proj:1.914 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.910 (perp=7.672, rec=0.072, cos=0.303), tot_loss_proj:1.911 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.899 (perp=7.672, rec=0.062, cos=0.303), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.899 (perp=7.672, rec=0.062, cos=0.303), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.907 (perp=7.672, rec=0.069, cos=0.303), tot_loss_proj:1.904 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.906 (perp=7.672, rec=0.069, cos=0.303), tot_loss_proj:1.912 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.899 (perp=7.672, rec=0.061, cos=0.303), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.901 (perp=7.672, rec=0.063, cos=0.303), tot_loss_proj:1.904 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.896 (perp=7.672, rec=0.060, cos=0.302), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.904 (perp=7.672, rec=0.067, cos=0.303), tot_loss_proj:1.909 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.887 (perp=7.672, rec=0.049, cos=0.303), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.893 (perp=7.672, rec=0.056, cos=0.303), tot_loss_proj:1.894 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.903 (perp=7.672, rec=0.066, cos=0.303), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.892 (perp=7.672, rec=0.055, cos=0.303), tot_loss_proj:1.914 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.902 (perp=7.672, rec=0.064, cos=0.303), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.895 (perp=7.672, rec=0.057, cos=0.303), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.894 (perp=7.672, rec=0.056, cos=0.303), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.898 (perp=7.672, rec=0.060, cos=0.303), tot_loss_proj:1.908 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.896 (perp=7.672, rec=0.058, cos=0.303), tot_loss_proj:1.890 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.901 (perp=7.672, rec=0.064, cos=0.303), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.891 (perp=7.672, rec=0.055, cos=0.301), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.885 (perp=7.672, rec=0.048, cos=0.303), tot_loss_proj:1.908 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.904 (perp=7.672, rec=0.066, cos=0.303), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.899 (perp=7.672, rec=0.062, cos=0.303), tot_loss_proj:1.885 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.896 (perp=7.672, rec=0.058, cos=0.303), tot_loss_proj:1.906 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.884 (perp=7.672, rec=0.047, cos=0.303), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.906 (perp=7.672, rec=0.069, cos=0.303), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.895 (perp=7.672, rec=0.057, cos=0.303), tot_loss_proj:1.907 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.896 (perp=7.672, rec=0.059, cos=0.303), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.889 (perp=7.672, rec=0.051, cos=0.303), tot_loss_proj:1.901 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.751 | p: 87.006 | r: 88.630
rouge2     | fm: 55.735 | p: 55.497 | r: 55.961
rougeL     | fm: 76.506 | p: 75.957 | r: 77.216
rougeLsum  | fm: 76.640 | p: 76.017 | r: 77.329
r1fm+r2fm = 143.486

input #66 time: 0:09:06 | total time: 10:07:30


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.7847670359512948
highest_index [0]
highest [0.7847670359512948]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9494969844818115 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9231090545654297 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9068841934204102 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.9058369398117065 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.8890226483345032 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.8840948343276978 for ['[CLS] carries garden deputy creation attitudes victim mine waitingapugh [SEP]']
[Init] best rec loss: 0.8826638460159302 for ['[CLS] holyvy war hingesozuche tessa ] commentary justice [SEP]']
[Init] best rec loss: 0.8768373131752014 for ['[CLS]ism response no productions savagemorphism sports short eugenelika [SEP]']
[Init] best rec loss: 0.8728987574577332 for ['[CLS]ha twenty door cock school tierney inventorneer equal really [SEP]']
[Init] best perm rec loss: 0.8713216185569763 for ['[CLS] inventorneer door equalha cock school really tierney twenty [SEP]']
[Init] best perm rec loss: 0.8698937296867371 for ['[CLS] twentyneer equalha door really inventor school cock tierney [SEP]']
[Init] best perm rec loss: 0.8686997294425964 for ['[CLS]neerha inventor equal twenty really tierney cock door school [SEP]']
[Init] best perm rec loss: 0.8679189085960388 for ['[CLS]neer school equal door really twenty cock inventor tierneyha [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.355 (perp=13.321, rec=0.311, cos=0.380), tot_loss_proj:3.767 [t=0.23s]
prediction: ['[CLS] kindcer reaching marie kind familiar james gratitude boy kind [SEP]']
[ 100/2000] tot_loss=2.866 (perp=11.326, rec=0.221, cos=0.379), tot_loss_proj:3.813 [t=0.23s]
prediction: ['[CLS] kind /mingven kind nonwarwar kind kind [SEP]']
[ 150/2000] tot_loss=2.866 (perp=11.526, rec=0.178, cos=0.382), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS] heartwarmingentalwar nonentalwarental kind [SEP]']
[ 200/2000] tot_loss=2.891 (perp=11.911, rec=0.126, cos=0.382), tot_loss_proj:3.536 [t=0.23s]
prediction: ['[CLS] heartwarminggmwar nonentalwar, kind [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.556 (perp=10.195, rec=0.135, cos=0.382), tot_loss_proj:3.103 [t=0.23s]
prediction: ['[CLS] heartwarminggmentalwar nonwar, kind [SEP]']
[ 300/2000] tot_loss=2.510 (perp=10.195, rec=0.094, cos=0.378), tot_loss_proj:3.119 [t=0.23s]
prediction: ['[CLS] heartwarminggmentalwar nonwar, kind [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.362 (perp=9.422, rec=0.095, cos=0.382), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] heartwarminggmental nonwar, kindwar [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.301 (perp=9.099, rec=0.099, cos=0.382), tot_loss_proj:2.903 [t=0.23s]
prediction: ['[CLS] heartwarming nongmentalwar, kindwar [SEP]']
[ 450/2000] tot_loss=2.301 (perp=9.099, rec=0.098, cos=0.384), tot_loss_proj:2.899 [t=0.23s]
prediction: ['[CLS] heartwarming nongmentalwar, kindwar [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.270 (perp=9.034, rec=0.081, cos=0.383), tot_loss_proj:2.804 [t=0.23s]
prediction: ['[CLS] heartmwarming nongmental, kindwar [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.084 (perp=8.031, rec=0.095, cos=0.384), tot_loss_proj:2.538 [t=0.23s]
prediction: ['[CLS] heartwarwarming nongmental, kindm [SEP]']
[ 600/2000] tot_loss=2.071 (perp=8.031, rec=0.081, cos=0.383), tot_loss_proj:2.543 [t=0.23s]
prediction: ['[CLS] heartwarwarming nongmental, kindm [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.172 (perp=8.510, rec=0.087, cos=0.382), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nongmental kindju [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.165 (perp=8.510, rec=0.080, cos=0.383), tot_loss_proj:2.461 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nongmental kindju [SEP]']
[ 750/2000] tot_loss=2.161 (perp=8.510, rec=0.076, cos=0.383), tot_loss_proj:2.466 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nongmental kindju [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.999 (perp=7.685, rec=0.079, cos=0.382), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.988 (perp=7.685, rec=0.068, cos=0.383), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[ 900/2000] tot_loss=1.993 (perp=7.685, rec=0.073, cos=0.383), tot_loss_proj:2.130 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.995 (perp=7.685, rec=0.075, cos=0.383), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.993 (perp=7.685, rec=0.073, cos=0.383), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1050/2000] tot_loss=1.985 (perp=7.685, rec=0.065, cos=0.383), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.993 (perp=7.685, rec=0.072, cos=0.383), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.991 (perp=7.685, rec=0.070, cos=0.384), tot_loss_proj:2.135 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1200/2000] tot_loss=1.986 (perp=7.685, rec=0.066, cos=0.384), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.997 (perp=7.685, rec=0.077, cos=0.384), tot_loss_proj:2.121 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1300/2000] tot_loss=2.004 (perp=7.685, rec=0.083, cos=0.384), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1350/2000] tot_loss=1.990 (perp=7.685, rec=0.070, cos=0.384), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.985 (perp=7.685, rec=0.065, cos=0.384), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.985 (perp=7.685, rec=0.064, cos=0.384), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1500/2000] tot_loss=1.992 (perp=7.685, rec=0.072, cos=0.384), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.989 (perp=7.685, rec=0.068, cos=0.384), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.991 (perp=7.685, rec=0.070, cos=0.384), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1650/2000] tot_loss=1.984 (perp=7.685, rec=0.064, cos=0.384), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.992 (perp=7.685, rec=0.071, cos=0.384), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.991 (perp=7.685, rec=0.070, cos=0.384), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1800/2000] tot_loss=1.992 (perp=7.685, rec=0.071, cos=0.384), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.996 (perp=7.685, rec=0.075, cos=0.384), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.988 (perp=7.685, rec=0.067, cos=0.384), tot_loss_proj:2.130 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
[1950/2000] tot_loss=1.987 (perp=7.685, rec=0.067, cos=0.384), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=7.685, rec=0.070, cos=0.384), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] heartwarwarming, nonjugmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarwarming, nonjugmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 85.000

[Aggregate metrics]:
rouge1     | fm: 87.230 | p: 86.563 | r: 88.152
rouge2     | fm: 55.100 | p: 54.873 | r: 55.397
rougeL     | fm: 76.225 | p: 75.642 | r: 76.962
rougeLsum  | fm: 76.301 | p: 75.752 | r: 76.983
r1fm+r2fm = 142.330

input #67 time: 0:09:07 | total time: 10:16:37


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.8572846832733702
highest_index [0]
highest [0.8572846832733702]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9582458138465881 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9319241642951965 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.9288263320922852 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.9263553619384766 for ['[CLS] outcome swan national dialed apparently littlechi horror why supply targeted face ahl [SEP]']
[Init] best rec loss: 0.9104787111282349 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.8826110363006592 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8790046572685242 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8789973258972168 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8667331337928772 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8628920316696167 for ['[CLS]yn beth comfort form possiblyiferous died floor view councils riding medal. [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.714 (perp=11.045, rec=0.252, cos=0.253), tot_loss_proj:3.046 [t=0.23s]
prediction: ['[CLS] absurd audience admiral? sim car and badly ( vicious ( absurd absurd [SEP]']
[ 100/2000] tot_loss=2.312 (perp=9.426, rec=0.164, cos=0.263), tot_loss_proj:2.571 [t=0.23s]
prediction: ["[CLS] absurd incuth'absurdh and highly, vicious ( absurd absurd [SEP]"]
[ 150/2000] tot_loss=2.656 (perp=11.304, rec=0.137, cos=0.259), tot_loss_proj:2.937 [t=0.23s]
prediction: ["[CLS] absurd incuth 'onsh and highly, viciouscosible absurd [SEP]"]
[ 200/2000] tot_loss=2.504 (perp=10.559, rec=0.132, cos=0.260), tot_loss_proj:2.786 [t=0.23s]
prediction: ['[CLS] absurdcouth,onsckle and highly, viciouscosible absurd [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.487 (perp=10.517, rec=0.137, cos=0.247), tot_loss_proj:2.832 [t=0.23s]
prediction: ['[CLS] absurdअcouth, inc and highly, viciousompsible absurd [SEP]']
[ 300/2000] tot_loss=2.484 (perp=10.517, rec=0.130, cos=0.251), tot_loss_proj:2.831 [t=0.23s]
prediction: ['[CLS] absurdअcouth, inc and highly, viciousompsible absurd [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.148 (perp=8.933, rec=0.103, cos=0.258), tot_loss_proj:2.375 [t=0.23s]
prediction: ['[CLS] inconscouth, absurd and highly, viciousompsible absurd [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.331 (perp=9.691, rec=0.139, cos=0.253), tot_loss_proj:2.711 [t=0.23s]
prediction: ['[CLS] incberycouth, absurd andudence vicious,ompsible absurd [SEP]']
[ 450/2000] tot_loss=2.312 (perp=9.691, rec=0.117, cos=0.257), tot_loss_proj:2.721 [t=0.23s]
prediction: ['[CLS] incberycouth, absurd andudence vicious,ompsible absurd [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.136 (perp=8.856, rec=0.107, cos=0.258), tot_loss_proj:2.378 [t=0.23s]
prediction: ['[CLS] inconscouth, absurd and vicious vicious,ompsible absurd [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.110 (perp=8.785, rec=0.099, cos=0.253), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] incberycouth, absurd and vicious viciousompsible, absurd [SEP]']
[ 600/2000] tot_loss=2.191 (perp=9.144, rec=0.104, cos=0.258), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] incberycouth,sible and vicious viciousompsible, absurd [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.520 (perp=10.761, rec=0.109, cos=0.259), tot_loss_proj:2.921 [t=0.23s]
prediction: ['[CLS] absurd and vicious incghtcouth,udenceompsible, absurd [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.158 (perp=9.004, rec=0.102, cos=0.256), tot_loss_proj:2.761 [t=0.23s]
prediction: ['[CLS]sible and viciousghtcouth, incmptompsible, absurd [SEP]']
[ 750/2000] tot_loss=2.149 (perp=9.004, rec=0.089, cos=0.259), tot_loss_proj:2.771 [t=0.23s]
prediction: ['[CLS]sible and viciousghtcouth, incmptompsible, absurd [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.054 (perp=8.471, rec=0.100, cos=0.260), tot_loss_proj:2.626 [t=0.23s]
prediction: ['[CLS]sible and viciousghtcouthmpt, incompsible, absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.040 (perp=8.471, rec=0.086, cos=0.260), tot_loss_proj:2.628 [t=0.23s]
prediction: ['[CLS]sible and viciousghtcouthmpt, incompsible, absurd [SEP]']
[ 900/2000] tot_loss=2.045 (perp=8.471, rec=0.091, cos=0.260), tot_loss_proj:2.625 [t=0.23s]
prediction: ['[CLS]sible and viciousghtcouthmpt, incompsible, absurd [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.093 (perp=8.685, rec=0.096, cos=0.261), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS]sible and viciousocationcouthght, incompsible, absurd [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.975 (perp=8.042, rec=0.106, cos=0.260), tot_loss_proj:2.492 [t=0.23s]
prediction: ['[CLS]sible and viciouscouthghtocation, incompsible, absurd [SEP]']
[1050/2000] tot_loss=1.958 (perp=8.042, rec=0.090, cos=0.260), tot_loss_proj:2.488 [t=0.23s]
prediction: ['[CLS]sible and viciouscouthghtocation, incompsible, absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.967 (perp=8.042, rec=0.098, cos=0.260), tot_loss_proj:2.497 [t=0.23s]
prediction: ['[CLS]sible and viciouscouthghtocation, incompsible, absurd [SEP]']
Attempt swap
[1150/2000] tot_loss=1.957 (perp=8.042, rec=0.088, cos=0.260), tot_loss_proj:2.501 [t=0.23s]
prediction: ['[CLS]sible and viciouscouthghtocation, incompsible, absurd [SEP]']
[1200/2000] tot_loss=2.129 (perp=8.862, rec=0.096, cos=0.260), tot_loss_proj:2.810 [t=0.23s]
prediction: ['[CLS]sible and viciouscouthllieocation, incompsible, absurd [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.372 (perp=10.062, rec=0.100, cos=0.260), tot_loss_proj:2.616 [t=0.23s]
prediction: ['[CLS] absurd and viciouscouth extremely, incompghtsible, absurd [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.228 (perp=9.323, rec=0.104, cos=0.260), tot_loss_proj:2.466 [t=0.23s]
prediction: ['[CLS] absurd and extremelycouth vicious, incompghtsible, absurd [SEP]']
[1350/2000] tot_loss=2.003 (perp=8.267, rec=0.088, cos=0.261), tot_loss_proj:2.213 [t=0.23s]
prediction: ['[CLS] absurd and uncouth vicious, incompghtsible, absurd [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.885 (perp=7.628, rec=0.100, cos=0.259), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] absurd uncouth vicious, incompghtsible, and absurd [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.877 (perp=7.599, rec=0.099, cos=0.259), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] vicious uncouthsible, incompghtsible, and absurd [SEP]']
[1500/2000] tot_loss=1.894 (perp=7.661, rec=0.103, cos=0.259), tot_loss_proj:2.139 [t=0.23s]
prediction: ['[CLS] vicious uncouthsible, incomplliesible, and absurd [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.795 (perp=7.146, rec=0.109, cos=0.257), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] vicious, incomplliesible, uncouthsible and absurd [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.776 (perp=7.030, rec=0.110, cos=0.260), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] vicioussible, incomplliesible, uncouth and absurd [SEP]']
[1650/2000] tot_loss=1.772 (perp=7.030, rec=0.107, cos=0.259), tot_loss_proj:2.060 [t=0.23s]
prediction: ['[CLS] vicioussible, incomplliesible, uncouth and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.555 (perp=5.981, rec=0.100, cos=0.259), tot_loss_proj:1.785 [t=0.23s]
prediction: ['[CLS] vicioussible, incompresible, uncouth and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.551 (perp=5.981, rec=0.096, cos=0.259), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] vicioussible, incompresible, uncouth and absurd [SEP]']
[1800/2000] tot_loss=1.548 (perp=5.981, rec=0.092, cos=0.259), tot_loss_proj:1.804 [t=0.23s]
prediction: ['[CLS] vicioussible, incompresible, uncouth and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.552 (perp=5.981, rec=0.096, cos=0.259), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] vicioussible, incompresible, uncouth and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.460 (perp=5.534, rec=0.094, cos=0.260), tot_loss_proj:1.635 [t=0.23s]
prediction: ['[CLS] vicioussible, incomphensible, uncouth and absurd [SEP]']
[1950/2000] tot_loss=1.457 (perp=5.534, rec=0.091, cos=0.260), tot_loss_proj:1.638 [t=0.23s]
prediction: ['[CLS] vicioussible, incomphensible, uncouth and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.453 (perp=5.534, rec=0.086, cos=0.260), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] vicioussible, incomphensible, uncouth and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] absurd and viciouscouth un, incompghtsible, absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 50.000 | r: 57.143
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 53.333 | p: 50.000 | r: 57.143
rougeLsum  | fm: 53.333 | p: 50.000 | r: 57.143
r1fm+r2fm = 68.718

[Aggregate metrics]:
rouge1     | fm: 86.947 | p: 86.180 | r: 87.825
rouge2     | fm: 54.556 | p: 54.393 | r: 54.817
rougeL     | fm: 75.917 | p: 75.314 | r: 76.582
rougeLsum  | fm: 75.993 | p: 75.384 | r: 76.706
r1fm+r2fm = 141.503

input #68 time: 0:09:08 | total time: 10:25:45


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.8099178633719744
highest_index [0]
highest [0.8099178633719744]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.9806555509567261 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9784266352653503 for ['[CLS] new nod none left bryson gainering state chris pay league teams dea set during store [SEP]']
[Init] best rec loss: 0.9759909510612488 for ['[CLS] later dressed creed among label effect pickering servants duc evergreen along [CLS] court afar trey bombay [SEP]']
[Init] best rec loss: 0.9660211205482483 for ['[CLS]aver grandson cleared sergei spare reserve / earthquake mouse loudly student celebrated pill till le tunnel [SEP]']
[Init] best rec loss: 0.94398432970047 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9418237805366516 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.9400326609611511 for ['[CLS] ( passes statesrga am depended liz close bragg mess stockleinll past dead range [SEP]']
[Init] best perm rec loss: 0.9391728639602661 for ['[CLS] passes depended am statesll range mess ( close bragg past dead liz stockrgalein [SEP]']
[Init] best perm rec loss: 0.9377427697181702 for ['[CLS] dead states amrga close passes messll past ( range liz bragg stocklein depended [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.405 (perp=12.387, rec=0.637, cos=0.291), tot_loss_proj:4.227 [t=0.23s]
prediction: ['[CLS] wave not mud throw pop committee without like past brasil sorryless idf assault callie harrison [SEP]']
[ 100/2000] tot_loss=2.660 (perp=9.021, rec=0.594, cos=0.262), tot_loss_proj:3.591 [t=0.23s]
prediction: ['[CLS] murder, badwa funny - -, at... decisions assaulttake harrison [SEP]']
[ 150/2000] tot_loss=2.581 (perp=8.495, rec=0.584, cos=0.299), tot_loss_proj:3.667 [t=0.23s]
prediction: ['[CLS] right, bad mix funny -. or... panel republic offensive roosevelt tennis [SEP]']
[ 200/2000] tot_loss=3.056 (perp=10.665, rec=0.573, cos=0.349), tot_loss_proj:3.813 [t=0.23s]
prediction: ['[CLS] murder, hot... legions -, automatic? which. ; herb threattake grayson [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.833 (perp=10.421, rec=0.537, cos=0.212), tot_loss_proj:3.965 [t=0.23s]
prediction: ['[CLS] murder only wrong -? -. looked funny &. ; herb pretty richiefelt [SEP]']
[ 300/2000] tot_loss=2.900 (perp=10.767, rec=0.519, cos=0.228), tot_loss_proj:3.954 [t=0.23s]
prediction: ['[CLS] murder ( wrong -? -. oh funny and.mmer herb pretty richiefelt [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.412 (perp=8.541, rec=0.474, cos=0.230), tot_loss_proj:3.135 [t=0.23s]
prediction: ['[CLS], not wrong - and -. oh funny herb. ;, pretty richiefelt [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.630 (perp=9.322, rec=0.508, cos=0.258), tot_loss_proj:3.669 [t=0.23s]
prediction: ['[CLS], of wrong -felt -, or funny herb. transparency, lesbian richie and [SEP]']
[ 450/2000] tot_loss=2.405 (perp=8.343, rec=0.462, cos=0.275), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS],, wrong -felt -, or funny herb.,, lesbian richie. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.787 (perp=9.907, rec=0.501, cos=0.305), tot_loss_proj:3.614 [t=0.23s]
prediction: ['[CLS] ( ( -.felt -, or funnygul. prisoners [SEP] sewagewrite. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.488 (perp=8.494, rec=0.518, cos=0.272), tot_loss_proj:3.611 [t=0.24s]
prediction: ['[CLS], ( - smartgulfelt -, or funny.. [SEP] sewagewrite. [SEP]']
[ 600/2000] tot_loss=2.445 (perp=8.560, rec=0.452, cos=0.281), tot_loss_proj:3.591 [t=0.23s]
prediction: ['[CLS], ( - smartgulfelt -, or funny.. [SEP] sewage exterior. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.470 (perp=8.783, rec=0.449, cos=0.264), tot_loss_proj:3.754 [t=0.23s]
prediction: ['[CLS], (felt - -.gul, or funny., [SEP] subtle exterior? [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.489 (perp=8.840, rec=0.431, cos=0.290), tot_loss_proj:3.675 [t=0.23s]
prediction: ['[CLS], (felt - - victory,, or funny., [SEP] subtle charlie? [SEP]']
[ 750/2000] tot_loss=2.493 (perp=8.840, rec=0.414, cos=0.311), tot_loss_proj:3.678 [t=0.23s]
prediction: ['[CLS], (felt - - victory,, or funny., [SEP] subtle charlie? [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.498 (perp=8.894, rec=0.419, cos=0.300), tot_loss_proj:3.194 [t=0.23s]
prediction: ['[CLS],,felt - - victory,, and funny. exteriorkra [SEP] subtle? [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.586 (perp=9.609, rec=0.453, cos=0.211), tot_loss_proj:3.793 [t=0.23s]
prediction: ['[CLS] victory (felt - -,,, or funny. charliekra [SEP] subtle? [SEP]']
[ 900/2000] tot_loss=2.650 (perp=9.609, rec=0.412, cos=0.316), tot_loss_proj:3.799 [t=0.23s]
prediction: ['[CLS] victory (felt - -,,, or funny. charliekra [SEP] subtle? [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.433 (perp=8.887, rec=0.426, cos=0.229), tot_loss_proj:3.605 [t=0.23s]
prediction: ['[CLS] victory (felt - -, charlie, or funny.,kra [SEP] subtle? [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.224 (perp=7.958, rec=0.414, cos=0.218), tot_loss_proj:3.019 [t=0.23s]
prediction: ['[CLS] victory,felt - -, charlie, and funny., [SEP]kra subtle? [SEP]']
[1050/2000] tot_loss=2.255 (perp=7.958, rec=0.422, cos=0.241), tot_loss_proj:3.022 [t=0.23s]
prediction: ['[CLS] victory,felt - -, charlie, and funny., [SEP]kra subtle? [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.248 (perp=8.129, rec=0.402, cos=0.220), tot_loss_proj:3.014 [t=0.23s]
prediction: ['[CLS] victory, - - real charliefelt, and funny., [SEP]kra subtle? [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.173 (perp=7.775, rec=0.400, cos=0.218), tot_loss_proj:2.961 [t=0.23s]
prediction: ['[CLS] charlie, - -, victoryfelt, and funny., [SEP] pts subtle? [SEP]']
[1200/2000] tot_loss=2.166 (perp=7.775, rec=0.393, cos=0.218), tot_loss_proj:2.960 [t=0.23s]
prediction: ['[CLS] charlie, - -, victoryfelt, and funny., [SEP] pts subtle? [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.108 (perp=7.273, rec=0.393, cos=0.260), tot_loss_proj:2.809 [t=0.23s]
prediction: ['[CLS] charlie, - -, victoryfelt, and funny. [SEP] pts, subtle? [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.116 (perp=7.382, rec=0.398, cos=0.241), tot_loss_proj:2.732 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] pts, subtle, [SEP]']
[1350/2000] tot_loss=2.150 (perp=7.136, rec=0.387, cos=0.336), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
[1400/2000] tot_loss=2.158 (perp=7.136, rec=0.390, cos=0.340), tot_loss_proj:2.583 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
[1450/2000] tot_loss=2.131 (perp=7.136, rec=0.383, cos=0.320), tot_loss_proj:2.583 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
[1500/2000] tot_loss=2.120 (perp=7.136, rec=0.380, cos=0.312), tot_loss_proj:2.578 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
[1550/2000] tot_loss=2.115 (perp=7.136, rec=0.376, cos=0.312), tot_loss_proj:2.584 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
[1600/2000] tot_loss=2.111 (perp=7.136, rec=0.381, cos=0.303), tot_loss_proj:2.580 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
[1650/2000] tot_loss=2.088 (perp=7.136, rec=0.372, cos=0.289), tot_loss_proj:2.577 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
[1700/2000] tot_loss=2.099 (perp=7.136, rec=0.380, cos=0.291), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
[1750/2000] tot_loss=2.092 (perp=7.136, rec=0.377, cos=0.288), tot_loss_proj:2.581 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
[1800/2000] tot_loss=2.066 (perp=7.136, rec=0.368, cos=0.271), tot_loss_proj:2.578 [t=0.23s]
prediction: ['[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.125 (perp=7.272, rec=0.380, cos=0.291), tot_loss_proj:2.542 [t=0.23s]
prediction: ['[CLS] charlie, - - championship,felt, and funny, [SEP]kra, subtle, [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.084 (perp=7.028, rec=0.389, cos=0.289), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] charlie, - - subtle,felt, and funny, [SEP]kra, championship, [SEP]']
[1950/2000] tot_loss=2.070 (perp=7.028, rec=0.381, cos=0.283), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] charlie, - - subtle,felt, and funny, [SEP]kra, championship, [SEP]']
Attempt swap
[2000/2000] tot_loss=2.074 (perp=7.028, rec=0.383, cos=0.285), tot_loss_proj:2.418 [t=0.23s]
prediction: ['[CLS] charlie, - - subtle,felt, and funny, [SEP]kra, championship, [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] charlie, - -kra,felt, and funny. [SEP] championship, subtle, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 86.354 | p: 85.578 | r: 87.179
rouge2     | fm: 53.833 | p: 53.624 | r: 54.106
rougeL     | fm: 75.452 | p: 74.874 | r: 76.153
rougeLsum  | fm: 75.419 | p: 74.849 | r: 76.213
r1fm+r2fm = 140.186

input #69 time: 0:09:12 | total time: 10:34:58


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9341836463671368
highest_index [0]
highest [0.9341836463671368]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8009033203125 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7722830772399902 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7453047037124634 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7440521121025085 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.7282273769378662 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7087022066116333 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6864520907402039 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 0.684598982334137 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 0.6827027797698975 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 0.6816635727882385 for ['[CLS]bution guy modern party ি bob muscle [SEP]']
[Init] best perm rec loss: 0.6807163953781128 for ['[CLS] ি guy modern musclebution party bob [SEP]']
[Init] best perm rec loss: 0.6779466867446899 for ['[CLS] guy bob ি partybution muscle modern [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.962 (perp=12.476, rec=0.355, cos=0.112), tot_loss_proj:4.101 [t=0.22s]
prediction: ['[CLS]unk through the facto traffic buenosunk [SEP]']
[ 100/2000] tot_loss=2.798 (perp=12.215, rec=0.239, cos=0.116), tot_loss_proj:3.744 [t=0.22s]
prediction: ['[CLS]unk into clunk doors graphicsunk [SEP]']
[ 150/2000] tot_loss=2.651 (perp=11.897, rec=0.147, cos=0.125), tot_loss_proj:3.240 [t=0.22s]
prediction: ['[CLS]unk gets clunk screen getsy [SEP]']
[ 200/2000] tot_loss=2.465 (perp=11.198, rec=0.103, cos=0.122), tot_loss_proj:3.385 [t=0.22s]
prediction: ['[CLS]unk on clunk screen getsy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.947 (perp=8.329, rec=0.168, cos=0.113), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[ 300/2000] tot_loss=1.873 (perp=8.329, rec=0.088, cos=0.119), tot_loss_proj:2.435 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.869 (perp=8.329, rec=0.080, cos=0.123), tot_loss_proj:2.425 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.862 (perp=8.329, rec=0.072, cos=0.123), tot_loss_proj:2.439 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[ 450/2000] tot_loss=1.875 (perp=8.329, rec=0.086, cos=0.124), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.860 (perp=8.329, rec=0.070, cos=0.124), tot_loss_proj:2.442 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.866 (perp=8.329, rec=0.076, cos=0.124), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[ 600/2000] tot_loss=1.869 (perp=8.329, rec=0.079, cos=0.124), tot_loss_proj:2.441 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.853 (perp=8.329, rec=0.062, cos=0.125), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.872 (perp=8.329, rec=0.081, cos=0.125), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[ 750/2000] tot_loss=1.854 (perp=8.329, rec=0.065, cos=0.123), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.852 (perp=8.329, rec=0.062, cos=0.124), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.856 (perp=8.329, rec=0.066, cos=0.124), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[ 900/2000] tot_loss=1.850 (perp=8.329, rec=0.059, cos=0.125), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.863 (perp=8.329, rec=0.073, cos=0.124), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.852 (perp=8.329, rec=0.061, cos=0.125), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1050/2000] tot_loss=1.854 (perp=8.329, rec=0.063, cos=0.125), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.853 (perp=8.329, rec=0.062, cos=0.125), tot_loss_proj:2.452 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.860 (perp=8.329, rec=0.069, cos=0.125), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1200/2000] tot_loss=1.851 (perp=8.329, rec=0.060, cos=0.125), tot_loss_proj:2.449 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.865 (perp=8.329, rec=0.075, cos=0.125), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.859 (perp=8.329, rec=0.068, cos=0.125), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1350/2000] tot_loss=1.862 (perp=8.329, rec=0.071, cos=0.125), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.853 (perp=8.329, rec=0.062, cos=0.125), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.851 (perp=8.329, rec=0.060, cos=0.125), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1500/2000] tot_loss=1.863 (perp=8.329, rec=0.072, cos=0.125), tot_loss_proj:2.442 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.856 (perp=8.329, rec=0.065, cos=0.125), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.855 (perp=8.329, rec=0.065, cos=0.125), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1650/2000] tot_loss=1.862 (perp=8.329, rec=0.070, cos=0.125), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.844 (perp=8.329, rec=0.053, cos=0.125), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.862 (perp=8.329, rec=0.071, cos=0.126), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1800/2000] tot_loss=1.861 (perp=8.329, rec=0.069, cos=0.125), tot_loss_proj:2.441 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.864 (perp=8.329, rec=0.073, cos=0.126), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.848 (perp=8.329, rec=0.057, cos=0.125), tot_loss_proj:2.457 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
[1950/2000] tot_loss=1.857 (perp=8.329, rec=0.066, cos=0.125), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.875 (perp=8.329, rec=0.084, cos=0.126), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] screen getsunk on clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] screen getsunk on clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 46.154 | p: 50.000 | r: 42.857
rougeLsum  | fm: 46.154 | p: 50.000 | r: 42.857
r1fm+r2fm = 76.923

[Aggregate metrics]:
rouge1     | fm: 86.157 | p: 85.535 | r: 86.944
rouge2     | fm: 52.999 | p: 52.785 | r: 53.236
rougeL     | fm: 74.984 | p: 74.502 | r: 75.660
rougeLsum  | fm: 75.028 | p: 74.570 | r: 75.615
r1fm+r2fm = 139.156

input #70 time: 0:08:44 | total time: 10:43:42


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.8883074335543609
highest_index [0]
highest [0.8883074335543609]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8955236673355103 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8913708925247192 for ['[CLS]kledclaiming solid due tear stakesaint flight ken keel receiver living duval us tottenham [SEP]']
[Init] best rec loss: 0.8819055557250977 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.876947283744812 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8703850507736206 for ['[CLS] composed warsselle ty urbantist empireneas amendment broadbandcat murdereo money appoint [SEP]']
[Init] best rec loss: 0.8602573275566101 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8487130403518677 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8483806252479553 for ['[CLS]lon dictionary short prairie mayatypic conditioning flyingto etc men provided star cassidy gems [SEP]']
[Init] best rec loss: 0.8465399146080017 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 0.8433139324188232 for ['[CLS] sur professor creatures marshall bed mollyhear fewer over queens jean liam ram of fall [SEP]']
[Init] best perm rec loss: 0.8425716161727905 for ['[CLS] molly professor jean creatures over of bed marshall fewer liamhear queens sur fall ram [SEP]']
[Init] best perm rec loss: 0.8420354127883911 for ['[CLS] of over molly sur marshall jeanhear professor fall creatures bed liam fewer queens ram [SEP]']
[Init] best perm rec loss: 0.8409329652786255 for ['[CLS] sur molly liam jean over ramhear professor queens of bed marshall fall creatures fewer [SEP]']
[Init] best perm rec loss: 0.8394250869750977 for ['[CLS] professor jean queens creatures of surhear liam over ram fewer fall molly marshall bed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.933 (perp=11.790, rec=0.375, cos=0.200), tot_loss_proj:3.773 [t=0.22s]
prediction: ['[CLS] expect of der gone thin singletown moment nothing to are double vote by tent [SEP]']
[ 100/2000] tot_loss=2.309 (perp=9.455, rec=0.237, cos=0.182), tot_loss_proj:2.952 [t=0.22s]
prediction: ["[CLS] is ofed'not singlebury moment not single jump - seat your moment [SEP]"]
[ 150/2000] tot_loss=2.196 (perp=9.221, rec=0.150, cos=0.201), tot_loss_proj:3.534 [t=0.22s]
prediction: ['[CLS] there and your and not single - moment not single jump - seat your moment [SEP]']
[ 200/2000] tot_loss=1.941 (perp=8.108, rec=0.113, cos=0.206), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] there and your - not single - moment not single jump - seat your moment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.994 (perp=8.452, rec=0.095, cos=0.209), tot_loss_proj:2.687 [t=0.22s]
prediction: ["[CLS] there and your'not single a not moment - jump - seat your moment [SEP]"]
[ 300/2000] tot_loss=1.959 (perp=8.392, rec=0.076, cos=0.204), tot_loss_proj:3.230 [t=0.22s]
prediction: ["[CLS] there and your'a single a not moment - jump - seat your moment [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.754 (perp=7.341, rec=0.078, cos=0.208), tot_loss_proj:3.025 [t=0.22s]
prediction: ["[CLS] there and your'a not a single moment - jump - seat your moment [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.740 (perp=7.276, rec=0.080, cos=0.205), tot_loss_proj:2.570 [t=0.22s]
prediction: ['[CLS] and there your s a not a single moment - jump - seat your moment [SEP]']
[ 450/2000] tot_loss=1.735 (perp=7.276, rec=0.071, cos=0.209), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] and there your s a not a single moment - jump - seat your moment [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.648 (perp=6.820, rec=0.081, cos=0.204), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] and there your s a not a single moment - jump your seat - moment [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.706 (perp=7.080, rec=0.082, cos=0.208), tot_loss_proj:2.491 [t=0.22s]
prediction: ['[CLS] and there in s a not a single moment - jump your seat - moment [SEP]']
[ 600/2000] tot_loss=1.698 (perp=7.080, rec=0.073, cos=0.209), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] and there in s a not a single moment - jump your seat - moment [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.503 (perp=6.081, rec=0.083, cos=0.203), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] and there - s a not a single moment in jump your seat - moment [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.477 (perp=5.979, rec=0.073, cos=0.208), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS] and there - s a not a single moment jump in your seat - moment [SEP]']
[ 750/2000] tot_loss=1.482 (perp=5.979, rec=0.078, cos=0.209), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] and there - s a not a single moment jump in your seat - moment [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.478 (perp=5.979, rec=0.073, cos=0.209), tot_loss_proj:2.405 [t=0.22s]
prediction: ['[CLS] and there - s a not a single moment jump in your seat - moment [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.409 (perp=5.696, rec=0.068, cos=0.202), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment a jump in your seat - moment [SEP]']
[ 900/2000] tot_loss=1.421 (perp=5.696, rec=0.073, cos=0.208), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment a jump in your seat - moment [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.355 (perp=5.406, rec=0.070, cos=0.205), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1000/2000] tot_loss=1.355 (perp=5.406, rec=0.066, cos=0.207), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1050/2000] tot_loss=1.368 (perp=5.406, rec=0.079, cos=0.208), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1100/2000] tot_loss=1.368 (perp=5.406, rec=0.078, cos=0.208), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1150/2000] tot_loss=1.360 (perp=5.406, rec=0.070, cos=0.209), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1200/2000] tot_loss=1.363 (perp=5.406, rec=0.073, cos=0.209), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1250/2000] tot_loss=1.364 (perp=5.406, rec=0.074, cos=0.209), tot_loss_proj:2.332 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1300/2000] tot_loss=1.370 (perp=5.406, rec=0.079, cos=0.209), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1350/2000] tot_loss=1.361 (perp=5.406, rec=0.071, cos=0.209), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1400/2000] tot_loss=1.358 (perp=5.406, rec=0.068, cos=0.209), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1450/2000] tot_loss=1.359 (perp=5.406, rec=0.069, cos=0.209), tot_loss_proj:2.325 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1500/2000] tot_loss=1.362 (perp=5.406, rec=0.072, cos=0.209), tot_loss_proj:2.320 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1550/2000] tot_loss=1.362 (perp=5.406, rec=0.071, cos=0.209), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1600/2000] tot_loss=1.367 (perp=5.406, rec=0.077, cos=0.209), tot_loss_proj:2.330 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1650/2000] tot_loss=1.356 (perp=5.406, rec=0.066, cos=0.209), tot_loss_proj:2.326 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1700/2000] tot_loss=1.360 (perp=5.406, rec=0.069, cos=0.209), tot_loss_proj:2.326 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1750/2000] tot_loss=1.369 (perp=5.406, rec=0.079, cos=0.209), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1800/2000] tot_loss=1.366 (perp=5.406, rec=0.076, cos=0.209), tot_loss_proj:2.318 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1850/2000] tot_loss=1.368 (perp=5.406, rec=0.078, cos=0.209), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[1900/2000] tot_loss=1.347 (perp=5.406, rec=0.057, cos=0.209), tot_loss_proj:2.326 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
[1950/2000] tot_loss=1.360 (perp=5.406, rec=0.070, cos=0.209), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Attempt swap
[2000/2000] tot_loss=1.349 (perp=5.406, rec=0.058, cos=0.209), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] and there - s not a single moment jump in your seat - a moment [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there - s not a single moment jump in your seat - a moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 86.667 | r: 100.000
rouge2     | fm: 53.846 | p: 50.000 | r: 58.333
rougeL     | fm: 85.714 | p: 80.000 | r: 92.308
rougeLsum  | fm: 85.714 | p: 80.000 | r: 92.308
r1fm+r2fm = 146.703

[Aggregate metrics]:
rouge1     | fm: 86.303 | p: 85.577 | r: 87.167
rouge2     | fm: 52.893 | p: 52.697 | r: 53.142
rougeL     | fm: 75.099 | p: 74.472 | r: 75.893
rougeLsum  | fm: 75.111 | p: 74.505 | r: 75.862
r1fm+r2fm = 139.196

input #71 time: 0:08:50 | total time: 10:52:32


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.855108558281652
highest_index [0]
highest [0.855108558281652]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7744210362434387 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7645195126533508 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7420423030853271 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7373625040054321 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7301428914070129 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7299859523773193 for ['[CLS] rancho baseball tan vaults rule yellow rico creativeden initially album surgical math mine documentary [SEP]']
[Init] best rec loss: 0.7017903923988342 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7013179063796997 for ['[CLS] nonetheless zone! orbital lifeboat van pork support ta reserve dna walking accidentallyungen except [SEP]']
[Init] best perm rec loss: 0.6971724033355713 for ['[CLS] pork dna ta walking support accidentally reserve except nonetheless lifeboatungen van orbital zone! [SEP]']
[Init] best perm rec loss: 0.6969591379165649 for ['[CLS] orbital reserve van lifeboat pork zone! accidentally ta nonetheless except support walking dnaungen [SEP]']
[Init] best perm rec loss: 0.6952635645866394 for ['[CLS] dna walking van orbital except reserve nonetheless! taungen support zone pork lifeboat accidentally [SEP]']
[Init] best perm rec loss: 0.6948657035827637 for ['[CLS] accidentally lifeboat zone support walking dna nonethelessungen except van ta reserve pork orbital! [SEP]']
[Init] best perm rec loss: 0.6938314437866211 for ['[CLS]ungen accidentally nonetheless zone pork lifeboat walking dna reserve! orbital except support ta van [SEP]']
[Init] best perm rec loss: 0.6931201219558716 for ['[CLS] ta lifeboat pork zoneungen dna accidentally walking reserve nonetheless orbital support! except van [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.034 (perp=12.161, rec=0.348, cos=0.253), tot_loss_proj:3.717 [t=0.22s]
prediction: ['[CLS] tough with bloody killing hitler block policy someone blacks taxrator drivers has facing tough [SEP]']
[ 100/2000] tot_loss=2.770 (perp=11.581, rec=0.190, cos=0.264), tot_loss_proj:3.500 [t=0.22s]
prediction: ['[CLS] has more a killingocks time tough time balancing right testimony inspired has concept tough [SEP]']
[ 150/2000] tot_loss=2.330 (perp=9.735, rec=0.127, cos=0.255), tot_loss_proj:3.130 [t=0.22s]
prediction: ['[CLS] haser a violence philosophy time balancing time balancing its violence philosophy with concept tough [SEP]']
[ 200/2000] tot_loss=2.303 (perp=9.735, rec=0.094, cos=0.261), tot_loss_proj:3.134 [t=0.22s]
prediction: ['[CLS] haser a violence philosophy time balancing time balancing its violence philosophy with concept tough [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.147 (perp=8.596, rec=0.162, cos=0.265), tot_loss_proj:2.726 [t=0.22s]
prediction: ['[CLS] haser a toughified time balancing time balancing its violence philosophy with concept violence [SEP]']
[ 300/2000] tot_loss=2.212 (perp=9.252, rec=0.104, cos=0.257), tot_loss_proj:2.992 [t=0.22s]
prediction: ['[CLS] haser a toughified time tough time balancing its violence philosophy with wasp violence [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.861 (perp=7.587, rec=0.083, cos=0.261), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] haser a tough timeified tough time balancing its violence philosophy with - violence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.996 (perp=8.222, rec=0.089, cos=0.263), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS] haser a tough theified tough time balancing its violence with philosophy - philosophy [SEP]']
[ 450/2000] tot_loss=2.085 (perp=8.685, rec=0.086, cos=0.263), tot_loss_proj:3.254 [t=0.22s]
prediction: ['[CLS] haser a tough theified tough time balancing its violence with philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.983 (perp=8.219, rec=0.082, cos=0.258), tot_loss_proj:3.204 [t=0.22s]
prediction: ['[CLS]er has a tough the inspired tough time balancing its violence with philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.974 (perp=8.074, rec=0.097, cos=0.262), tot_loss_proj:3.295 [t=0.22s]
prediction: ['[CLS]er has a toughfk tough time balancing its violence with inspired philosophy inspired inspired [SEP]']
[ 600/2000] tot_loss=1.955 (perp=8.074, rec=0.076, cos=0.264), tot_loss_proj:3.285 [t=0.22s]
prediction: ['[CLS]er has a toughfk tough time balancing its violence with inspired philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.821 (perp=7.398, rec=0.080, cos=0.261), tot_loss_proj:2.956 [t=0.22s]
prediction: ['[CLS]fker has a tough tough time balancing its violence with inspired philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.757 (perp=7.101, rec=0.072, cos=0.265), tot_loss_proj:2.794 [t=0.22s]
prediction: ['[CLS]fker has a tough time balancing its violence with tough inspired philosophy inspired inspired [SEP]']
[ 750/2000] tot_loss=1.754 (perp=7.101, rec=0.070, cos=0.264), tot_loss_proj:2.782 [t=0.22s]
prediction: ['[CLS]fker has a tough time balancing its violence with tough inspired philosophy inspired inspired [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.764 (perp=7.101, rec=0.079, cos=0.265), tot_loss_proj:2.784 [t=0.22s]
prediction: ['[CLS]fker has a tough time balancing its violence with tough inspired philosophy inspired inspired [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.749 (perp=7.101, rec=0.064, cos=0.265), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS]fker has a tough time balancing its violence with tough inspired philosophy inspired inspired [SEP]']
[ 900/2000] tot_loss=1.771 (perp=7.101, rec=0.086, cos=0.265), tot_loss_proj:2.853 [t=0.22s]
prediction: ['[CLS]fker has a tough time balancing its violence with tough inspired philosophy inspired inspired [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.769 (perp=7.101, rec=0.083, cos=0.265), tot_loss_proj:2.842 [t=0.22s]
prediction: ['[CLS]fker has a tough time balancing its violence with tough inspired philosophy inspired inspired [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.758 (perp=7.141, rec=0.071, cos=0.259), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
[1050/2000] tot_loss=1.765 (perp=7.141, rec=0.074, cos=0.262), tot_loss_proj:2.724 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.770 (perp=7.141, rec=0.078, cos=0.264), tot_loss_proj:2.628 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
[1150/2000] tot_loss=1.784 (perp=7.141, rec=0.092, cos=0.264), tot_loss_proj:2.641 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
[1200/2000] tot_loss=1.769 (perp=7.141, rec=0.076, cos=0.265), tot_loss_proj:2.642 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.775 (perp=7.141, rec=0.082, cos=0.265), tot_loss_proj:2.685 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
[1300/2000] tot_loss=1.764 (perp=7.141, rec=0.070, cos=0.266), tot_loss_proj:2.682 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
[1350/2000] tot_loss=1.776 (perp=7.141, rec=0.081, cos=0.266), tot_loss_proj:2.677 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.761 (perp=7.153, rec=0.065, cos=0.266), tot_loss_proj:2.757 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.765 (perp=7.141, rec=0.070, cos=0.267), tot_loss_proj:2.632 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
[1500/2000] tot_loss=1.772 (perp=7.141, rec=0.078, cos=0.266), tot_loss_proj:2.626 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.782 (perp=7.153, rec=0.086, cos=0.266), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.760 (perp=7.141, rec=0.064, cos=0.268), tot_loss_proj:2.634 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
[1650/2000] tot_loss=1.766 (perp=7.141, rec=0.071, cos=0.267), tot_loss_proj:2.631 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.767 (perp=7.153, rec=0.069, cos=0.267), tot_loss_proj:2.610 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
Attempt swap
[1750/2000] tot_loss=1.765 (perp=7.153, rec=0.067, cos=0.267), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
[1800/2000] tot_loss=1.756 (perp=7.153, rec=0.058, cos=0.267), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.764 (perp=7.141, rec=0.069, cos=0.267), tot_loss_proj:2.627 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.769 (perp=7.153, rec=0.071, cos=0.267), tot_loss_proj:2.619 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
[1950/2000] tot_loss=1.769 (perp=7.153, rec=0.071, cos=0.267), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.760 (perp=7.141, rec=0.065, cos=0.267), tot_loss_proj:2.630 [t=0.22s]
prediction: ['[CLS] marketer has a tough time balancing its violence withfk inspired philosophy inspired inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] marketer has a tough time balancing its violence withfk inspired inspired philosophy inspired [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 66.667 | r: 76.923
rouge2     | fm: 38.462 | p: 35.714 | r: 41.667
rougeL     | fm: 71.429 | p: 66.667 | r: 76.923
rougeLsum  | fm: 71.429 | p: 66.667 | r: 76.923
r1fm+r2fm = 109.890

[Aggregate metrics]:
rouge1     | fm: 86.146 | p: 85.372 | r: 87.103
rouge2     | fm: 52.756 | p: 52.438 | r: 53.057
rougeL     | fm: 75.074 | p: 74.474 | r: 75.950
rougeLsum  | fm: 75.092 | p: 74.456 | r: 75.961
r1fm+r2fm = 138.902

input #72 time: 0:08:50 | total time: 11:01:23


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.8492179901633627
highest_index [0]
highest [0.8492179901633627]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9552528262138367 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9460227489471436 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.8998181223869324 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 0.894856870174408 for ['[CLS] zhang body [SEP]']
[Init] best rec loss: 0.8907528519630432 for ['[CLS] pass society [SEP]']
[Init] best rec loss: 0.8901833295822144 for ['[CLS] ocean " [SEP]']
[Init] best rec loss: 0.8887513279914856 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8690165281295776 for ['[CLS]ɛ society [SEP]']
[Init] best rec loss: 0.8455557823181152 for ['[CLS] massachusetts gun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.446 (perp=9.723, rec=0.245, cos=0.256), tot_loss_proj:2.303 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.309 (perp=9.723, rec=0.090, cos=0.274), tot_loss_proj:2.318 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.287 (perp=9.723, rec=0.065, cos=0.278), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.286 (perp=9.723, rec=0.064, cos=0.277), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.296 (perp=9.723, rec=0.075, cos=0.277), tot_loss_proj:2.314 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.280 (perp=9.723, rec=0.059, cos=0.276), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.289 (perp=9.723, rec=0.070, cos=0.274), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.284 (perp=9.723, rec=0.062, cos=0.278), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.276 (perp=9.723, rec=0.053, cos=0.279), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.287 (perp=9.723, rec=0.065, cos=0.277), tot_loss_proj:2.296 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.283 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.285 (perp=9.723, rec=0.062, cos=0.278), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.281 (perp=9.723, rec=0.058, cos=0.279), tot_loss_proj:2.308 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.289 (perp=9.723, rec=0.066, cos=0.279), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.277 (perp=9.723, rec=0.054, cos=0.279), tot_loss_proj:2.314 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.292 (perp=9.723, rec=0.069, cos=0.279), tot_loss_proj:2.329 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.294 (perp=9.723, rec=0.071, cos=0.279), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.279 (perp=9.723, rec=0.056, cos=0.279), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.280 (perp=9.723, rec=0.056, cos=0.279), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.285 (perp=9.723, rec=0.062, cos=0.279), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.287 (perp=9.723, rec=0.064, cos=0.279), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.287 (perp=9.723, rec=0.064, cos=0.279), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.293 (perp=9.723, rec=0.070, cos=0.279), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.272 (perp=9.723, rec=0.049, cos=0.279), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.276 (perp=9.723, rec=0.053, cos=0.279), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.292 (perp=9.723, rec=0.068, cos=0.279), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.267 (perp=9.723, rec=0.043, cos=0.279), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.279 (perp=9.723, rec=0.056, cos=0.279), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.278 (perp=9.723, rec=0.055, cos=0.279), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.286 (perp=9.723, rec=0.063, cos=0.279), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.284 (perp=9.723, rec=0.060, cos=0.279), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.284 (perp=9.723, rec=0.061, cos=0.279), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.276 (perp=9.723, rec=0.053, cos=0.279), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.289 (perp=9.723, rec=0.066, cos=0.279), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.285 (perp=9.723, rec=0.062, cos=0.279), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.272 (perp=9.723, rec=0.049, cos=0.279), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.271 (perp=9.723, rec=0.047, cos=0.279), tot_loss_proj:2.308 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.269 (perp=9.723, rec=0.046, cos=0.279), tot_loss_proj:2.308 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.296 (perp=9.723, rec=0.072, cos=0.279), tot_loss_proj:2.314 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.280 (perp=9.723, rec=0.057, cos=0.279), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.229 | p: 85.433 | r: 87.250
rouge2     | fm: 53.561 | p: 53.270 | r: 53.913
rougeL     | fm: 75.477 | p: 74.854 | r: 76.260
rougeLsum  | fm: 75.435 | p: 74.796 | r: 76.241
r1fm+r2fm = 139.789

input #73 time: 0:08:46 | total time: 11:10:09


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.8616070445858335
highest_index [0]
highest [0.8616070445858335]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8165375590324402 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6207025051116943 for ['[CLS] storage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.002 (perp=8.178, rec=0.121, cos=0.245), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.969 (perp=8.178, rec=0.084, cos=0.250), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.976 (perp=8.178, rec=0.086, cos=0.254), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.974 (perp=8.178, rec=0.082, cos=0.256), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.957 (perp=8.178, rec=0.065, cos=0.257), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.955 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.954 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.951 (perp=8.178, rec=0.065, cos=0.250), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.956 (perp=8.178, rec=0.068, cos=0.253), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.952 (perp=8.178, rec=0.060, cos=0.256), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.966 (perp=8.178, rec=0.074, cos=0.257), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.954 (perp=8.178, rec=0.061, cos=0.257), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.960 (perp=8.178, rec=0.067, cos=0.257), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.943 (perp=8.178, rec=0.057, cos=0.251), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.963 (perp=8.178, rec=0.071, cos=0.257), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.952 (perp=8.178, rec=0.060, cos=0.257), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.955 (perp=8.178, rec=0.063, cos=0.257), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.962 (perp=8.178, rec=0.069, cos=0.257), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.964 (perp=8.178, rec=0.077, cos=0.252), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.962 (perp=8.178, rec=0.070, cos=0.256), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.952 (perp=8.178, rec=0.059, cos=0.257), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.953 (perp=8.178, rec=0.061, cos=0.257), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.948 (perp=8.178, rec=0.055, cos=0.257), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.954 (perp=8.178, rec=0.064, cos=0.254), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.954 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.025 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.955 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.955 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.958 (perp=8.178, rec=0.066, cos=0.257), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.955 (perp=8.178, rec=0.063, cos=0.257), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.956 (perp=8.178, rec=0.063, cos=0.257), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.976 (perp=8.178, rec=0.084, cos=0.257), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.954 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.954 (perp=8.178, rec=0.061, cos=0.257), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.955 (perp=8.178, rec=0.062, cos=0.257), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.954 (perp=8.178, rec=0.061, cos=0.257), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.955 (perp=8.178, rec=0.062, cos=0.258), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.962 (perp=8.178, rec=0.069, cos=0.257), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.948 (perp=8.178, rec=0.056, cos=0.257), tot_loss_proj:2.027 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.968 (perp=8.178, rec=0.075, cos=0.257), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.962 (perp=8.178, rec=0.069, cos=0.257), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.393 | p: 85.644 | r: 87.357
rouge2     | fm: 54.120 | p: 53.841 | r: 54.453
rougeL     | fm: 75.722 | p: 75.128 | r: 76.513
rougeLsum  | fm: 75.727 | p: 75.081 | r: 76.463
r1fm+r2fm = 140.513

input #74 time: 0:08:38 | total time: 11:18:48


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.8751265920162526
highest_index [0]
highest [0.8751265920162526]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8909417390823364 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8616026043891907 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.8327845335006714 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best perm rec loss: 0.8321337699890137 for ['[CLS] double es regiment alfred marlene help reason moth churches malone duties connacht clan zach section meaning rushose lakes [SEP]']
[Init] best perm rec loss: 0.8319919109344482 for ['[CLS] alfred duties clan regiment double zach marlene reason churches es meaning connacht help lakes section rushose moth malone [SEP]']
[Init] best perm rec loss: 0.8298409581184387 for ['[CLS] alfred lakes moth doubleose regiment help es clan connacht zach section malone rush meaning churches duties reason marlene [SEP]']
[Init] best perm rec loss: 0.82928466796875 for ['[CLS] section connacht regiment reason clan duties zach moth churches esose malone help rush double alfred lakes marlene meaning [SEP]']
[Init] best perm rec loss: 0.8283244371414185 for ['[CLS] lakes es alfred connacht churches double regiment meaning moth help clan rush section zach duties maloneose reason marlene [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.063 (perp=12.122, rec=0.409, cos=0.229), tot_loss_proj:4.286 [t=0.22s]
prediction: ['[CLS] flankes bo an business location archived. insight help over protect resource shy individuals or ignore sc society [SEP]']
[ 100/2000] tot_loss=2.621 (perp=10.896, rec=0.214, cos=0.228), tot_loss_proj:3.996 [t=0.22s]
prediction: ['[CLS] musedesop this industrial instability frequented or inheritance upon ) instability easily forgotten typically is not quite forgotten [SEP]']
[ 150/2000] tot_loss=2.371 (perp=10.114, rec=0.124, cos=0.224), tot_loss_proj:3.455 [t=0.22s]
prediction: ['[CLS] excursion excursion into thispled instability frequented or [SEP] destroyed into instability easily dismissed impulse is not easily forgotten [SEP]']
[ 200/2000] tot_loss=2.297 (perp=9.781, rec=0.118, cos=0.223), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS]cola excursion into this dismissed instability secure or. donated into instability easily dismissed impulse is not easily forgotten [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.365 (perp=9.975, rec=0.149, cos=0.221), tot_loss_proj:3.697 [t=0.22s]
prediction: ["[CLS]cola excursion into this excursion instability persistent or [SEP]'instability easily dismissed into which is not easily forgotten [SEP]"]
[ 300/2000] tot_loss=2.588 (perp=11.248, rec=0.110, cos=0.229), tot_loss_proj:3.988 [t=0.22s]
prediction: ['[CLS]cola excursion the this excursion instability intense or. of instability easily dismissedenter │ is not mental forgotten [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.402 (perp=10.322, rec=0.115, cos=0.222), tot_loss_proj:3.753 [t=0.22s]
prediction: ['[CLS]cola excursion instability within orly the this excursion of instability easily dismissedenter inevitable is not mental forgotten [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.420 (perp=10.525, rec=0.094, cos=0.221), tot_loss_proj:3.684 [t=0.22s]
prediction: ['[CLS] attraction excursion playground extending orly the this excursion of instability easily dismissedentercola is not mental forgotten [SEP]']
[ 450/2000] tot_loss=2.296 (perp=9.819, rec=0.108, cos=0.224), tot_loss_proj:3.503 [t=0.22s]
prediction: ['[CLS] begins excursionenterenter or. the this excursion of instability easily dismissedentercola is not mental forgotten [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.224 (perp=9.519, rec=0.095, cos=0.225), tot_loss_proj:3.400 [t=0.22s]
prediction: ['[CLS] begins excursionenterenter or. this the excursion of instability easily dismissedentercola is not mental forgotten [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.230 (perp=9.525, rec=0.102, cos=0.224), tot_loss_proj:3.075 [t=0.22s]
prediction: ['[CLS] began excursionenterenter or mental. this the excursion of instability easily dismissedentercola is not forgotten [SEP]']
[ 600/2000] tot_loss=2.221 (perp=9.525, rec=0.091, cos=0.225), tot_loss_proj:3.077 [t=0.22s]
prediction: ['[CLS] began excursionenterenter or mental. this the excursion of instability easily dismissedentercola is not forgotten [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.294 (perp=9.927, rec=0.085, cos=0.224), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] excursionenterting or mental. this the excursion of instability easily dismissedentercola began is not forgotten [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.232 (perp=9.554, rec=0.094, cos=0.227), tot_loss_proj:2.906 [t=0.22s]
prediction: ['[CLS] excursionenter or mentalting. this the excursion of instability easily dismissedentercola began is not forgotten [SEP]']
[ 750/2000] tot_loss=2.219 (perp=9.554, rec=0.082, cos=0.226), tot_loss_proj:2.914 [t=0.22s]
prediction: ['[CLS] excursionenter or mentalting. this the excursion of instability easily dismissedentercola began is not forgotten [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.149 (perp=9.177, rec=0.088, cos=0.226), tot_loss_proj:2.832 [t=0.22s]
prediction: ['[CLS] excursionting or mentalenter. this the excursion of instability easily dismissedentercola began is not forgotten [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.144 (perp=9.177, rec=0.083, cos=0.226), tot_loss_proj:2.837 [t=0.22s]
prediction: ['[CLS] excursionting or mentalenter. this the excursion of instability easily dismissedentercola began is not forgotten [SEP]']
[ 900/2000] tot_loss=2.271 (perp=9.811, rec=0.083, cos=0.226), tot_loss_proj:3.237 [t=0.22s]
prediction: ['[CLS] excursionting or mentalenter. this into excursion of instability easily dismissedentercola began is not forgotten [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.125 (perp=9.101, rec=0.078, cos=0.227), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] excursionting or mentalenter. this excursion into of instability easily dismissed percola began is not forgotten [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.117 (perp=9.050, rec=0.087, cos=0.220), tot_loss_proj:3.050 [t=0.22s]
prediction: ['[CLS] excursion ofcolating or mentalenter. this excursion into epic instability easily dismissed began is not forgotten [SEP]']
[1050/2000] tot_loss=2.123 (perp=9.068, rec=0.087, cos=0.223), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS] excursion ofcolating or mentalenter. this excursion the of instability easily dismissed began is not forgotten [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.046 (perp=8.707, rec=0.080, cos=0.225), tot_loss_proj:2.947 [t=0.22s]
prediction: ['[CLS] excursion percolating or mentalenter. this excursion of into instability easily dismissed began is not forgotten [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.977 (perp=8.377, rec=0.076, cos=0.225), tot_loss_proj:2.806 [t=0.22s]
prediction: ['[CLS] excursion percolating or mentalenter. this excursion into of instability easily dismissed began is not forgotten [SEP]']
[1200/2000] tot_loss=1.979 (perp=8.377, rec=0.078, cos=0.226), tot_loss_proj:2.806 [t=0.22s]
prediction: ['[CLS] excursion percolating or mentalenter. this excursion into of instability easily dismissed began is not forgotten [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.860 (perp=7.724, rec=0.090, cos=0.225), tot_loss_proj:2.799 [t=0.22s]
prediction: ['[CLS] excursion percolating or epicenter. this excursion into mental instability easily dismissed began is not forgotten [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.795 (perp=7.448, rec=0.079, cos=0.227), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily dismissed is not forgotten [SEP]']
[1350/2000] tot_loss=1.798 (perp=7.448, rec=0.082, cos=0.226), tot_loss_proj:2.888 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily dismissed is not forgotten [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.733 (perp=7.182, rec=0.071, cos=0.226), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
[1450/2000] tot_loss=1.741 (perp=7.182, rec=0.078, cos=0.226), tot_loss_proj:2.768 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
[1500/2000] tot_loss=1.740 (perp=7.182, rec=0.077, cos=0.227), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=7.182, rec=0.076, cos=0.227), tot_loss_proj:2.767 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
[1600/2000] tot_loss=1.743 (perp=7.182, rec=0.080, cos=0.227), tot_loss_proj:2.775 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
[1650/2000] tot_loss=1.745 (perp=7.182, rec=0.082, cos=0.227), tot_loss_proj:2.776 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
[1700/2000] tot_loss=1.734 (perp=7.182, rec=0.070, cos=0.227), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
[1750/2000] tot_loss=1.747 (perp=7.182, rec=0.084, cos=0.227), tot_loss_proj:2.771 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
[1800/2000] tot_loss=1.744 (perp=7.182, rec=0.080, cos=0.228), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
[1850/2000] tot_loss=1.744 (perp=7.182, rec=0.080, cos=0.228), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.720 (perp=7.072, rec=0.078, cos=0.228), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] began excursion percolating into epicenter. this excursion or mental instability easily forgotten is not dismissed [SEP]']
[1950/2000] tot_loss=1.709 (perp=7.072, rec=0.067, cos=0.228), tot_loss_proj:2.609 [t=0.22s]
prediction: ['[CLS] began excursion percolating into epicenter. this excursion or mental instability easily forgotten is not dismissed [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.683 (perp=6.885, rec=0.079, cos=0.227), tot_loss_proj:2.434 [t=0.22s]
prediction: ['[CLS] began this excursion percolating into epicenter. excursion or mental instability easily forgotten is not dismissed [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] began excursion percolating or epicenter. this excursion into mental instability easily forgotten is not dismissed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 113.235

[Aggregate metrics]:
rouge1     | fm: 86.489 | p: 85.752 | r: 87.474
rouge2     | fm: 53.764 | p: 53.521 | r: 54.126
rougeL     | fm: 75.389 | p: 74.777 | r: 76.193
rougeLsum  | fm: 75.546 | p: 74.889 | r: 76.286
r1fm+r2fm = 140.253

input #75 time: 0:08:54 | total time: 11:27:42


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.8455807796429504
highest_index [0]
highest [0.8455807796429504]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.887316882610321 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8808434009552002 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8732225894927979 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8509443402290344 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best perm rec loss: 0.8498644232749939 for ['[CLS] regards fallrd tuesdaymill described en rest inception drag press twelvehedron vantage [SEP]']
[Init] best perm rec loss: 0.8488771915435791 for ['[CLS] fall resthedron tuesdayrd inception twelve regardsmill drag vantage en described press [SEP]']
[Init] best perm rec loss: 0.8478929996490479 for ['[CLS] described fallrd drag tuesday press vantage rest twelve enhedron regardsmill inception [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.968 (perp=11.927, rec=0.326, cos=0.256), tot_loss_proj:4.149 [t=0.22s]
prediction: ['[CLS] had turned suit gray no pressure controlled british unneck stoppedroving its challenging [SEP]']
[ 100/2000] tot_loss=2.537 (perp=10.445, rec=0.167, cos=0.281), tot_loss_proj:3.312 [t=0.22s]
prediction: ['[CLS] has turned though ways like silence when had ) tract stopped challenging himself challenging [SEP]']
[ 150/2000] tot_loss=2.420 (perp=10.114, rec=0.148, cos=0.249), tot_loss_proj:3.754 [t=0.22s]
prediction: ['[CLS] has turned 66 ways as 6 allen when ) 66 stopped challenging himself challenging [SEP]']
[ 200/2000] tot_loss=2.384 (perp=10.027, rec=0.105, cos=0.273), tot_loss_proj:3.197 [t=0.22s]
prediction: ['[CLS] has s 66. as 6 allen at, 66 stopped challenging himself challenging [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.449 (perp=10.334, rec=0.109, cos=0.274), tot_loss_proj:3.628 [t=0.22s]
prediction: ['[CLS] has s 66 challenging as 6 allen at, 66 stopped challenging himself regarded [SEP]']
[ 300/2000] tot_loss=2.448 (perp=10.352, rec=0.102, cos=0.276), tot_loss_proj:3.527 [t=0.22s]
prediction: ['[CLS] has s 66 challenging as 6 allen at, 66 stopped challenging himself jeans [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.018 (perp=8.306, rec=0.084, cos=0.273), tot_loss_proj:2.898 [t=0.22s]
prediction: ['[CLS] has s 66 challenging as 66, at allen 66 stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.964 (perp=7.990, rec=0.089, cos=0.277), tot_loss_proj:2.963 [t=0.22s]
prediction: ["[CLS] has s 66 as challenging ', at allen 66 stopped challenging himself. [SEP]"]
[ 450/2000] tot_loss=1.957 (perp=7.990, rec=0.080, cos=0.278), tot_loss_proj:2.955 [t=0.22s]
prediction: ["[CLS] has s 66 as challenging ', at allen 66 stopped challenging himself. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.876 (perp=7.579, rec=0.083, cos=0.277), tot_loss_proj:2.618 [t=0.22s]
prediction: ["[CLS] 66 s 66 as challenging ', at allen has stopped challenging himself. [SEP]"]
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.848 (perp=7.439, rec=0.083, cos=0.277), tot_loss_proj:2.433 [t=0.22s]
prediction: ["[CLS] 66 s 66 as challenging'at, allen has stopped challenging himself. [SEP]"]
[ 600/2000] tot_loss=1.946 (perp=7.919, rec=0.084, cos=0.278), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging cause at, allen has stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.026 (perp=8.326, rec=0.084, cos=0.278), tot_loss_proj:2.772 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging, at 80 allen has stopped challenging himself. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.778 (perp=7.122, rec=0.075, cos=0.278), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
[ 750/2000] tot_loss=1.783 (perp=7.122, rec=0.080, cos=0.279), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.787 (perp=7.122, rec=0.084, cos=0.279), tot_loss_proj:2.494 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.787 (perp=7.122, rec=0.084, cos=0.279), tot_loss_proj:2.490 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
[ 900/2000] tot_loss=1.789 (perp=7.122, rec=0.086, cos=0.279), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.792 (perp=7.122, rec=0.088, cos=0.279), tot_loss_proj:2.493 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.784 (perp=7.122, rec=0.080, cos=0.279), tot_loss_proj:2.480 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
[1050/2000] tot_loss=1.779 (perp=7.122, rec=0.076, cos=0.279), tot_loss_proj:2.486 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.781 (perp=7.122, rec=0.077, cos=0.280), tot_loss_proj:2.489 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.779 (perp=7.122, rec=0.075, cos=0.280), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
[1200/2000] tot_loss=1.784 (perp=7.122, rec=0.080, cos=0.280), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.699 (perp=6.757, rec=0.069, cos=0.279), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] 66 s as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.713 (perp=6.757, rec=0.083, cos=0.278), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] 66 s as challenging. at 66, allen has stopped challenging himself. [SEP]']
[1350/2000] tot_loss=1.709 (perp=6.757, rec=0.079, cos=0.279), tot_loss_proj:2.381 [t=0.22s]
prediction: ['[CLS] 66 s as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.641 (perp=6.429, rec=0.076, cos=0.279), tot_loss_proj:2.354 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.646 (perp=6.429, rec=0.082, cos=0.279), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
[1500/2000] tot_loss=1.637 (perp=6.429, rec=0.072, cos=0.279), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.650 (perp=6.429, rec=0.084, cos=0.279), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=6.429, rec=0.079, cos=0.279), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
[1650/2000] tot_loss=1.646 (perp=6.429, rec=0.080, cos=0.279), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.653 (perp=6.429, rec=0.088, cos=0.279), tot_loss_proj:2.355 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.644 (perp=6.429, rec=0.079, cos=0.279), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
[1800/2000] tot_loss=1.641 (perp=6.429, rec=0.076, cos=0.280), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.653 (perp=6.429, rec=0.088, cos=0.280), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.638 (perp=6.429, rec=0.072, cos=0.280), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
[1950/2000] tot_loss=1.644 (perp=6.429, rec=0.078, cos=0.280), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.638 (perp=6.429, rec=0.072, cos=0.280), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] s 66 as challenging. at 66, allen has stopped challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] 66 s 66 as challenging. at, allen has stopped challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 122.783

[Aggregate metrics]:
rouge1     | fm: 86.465 | p: 85.680 | r: 87.482
rouge2     | fm: 53.476 | p: 53.147 | r: 53.784
rougeL     | fm: 75.437 | p: 74.812 | r: 76.243
rougeLsum  | fm: 75.532 | p: 74.845 | r: 76.331
r1fm+r2fm = 139.941

input #76 time: 0:08:47 | total time: 11:36:30


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.8243102830628102
highest_index [0]
highest [0.8243102830628102]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.8059394359588623 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8058650493621826 for ["[CLS] it got tracking holmes internal aboriginal communist seek manifested surface basket nicky cut 'ane [SEP]"]
[Init] best rec loss: 0.8008553385734558 for ['[CLS] low each mob descending person architecture channels partnership platinum friendtry aw idea anderson america [SEP]']
[Init] best rec loss: 0.7721497416496277 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.7393258213996887 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.7355148792266846 for ['[CLS] too type bred cold crowd more elements lips critique leather under battlefield simple lot pony [SEP]']
[Init] best perm rec loss: 0.7327942252159119 for ['[CLS] lips elements crowd lot bred critique under pony more too simple cold type leather battlefield [SEP]']
[Init] best perm rec loss: 0.7306500673294067 for ['[CLS] critique simple elements under type lips cold more bred battlefield leather pony lot crowd too [SEP]']
[Init] best perm rec loss: 0.7306311130523682 for ['[CLS] bred lot battlefield simple elements more pony lips cold crowd critique type leather under too [SEP]']
[Init] best perm rec loss: 0.7289929986000061 for ['[CLS] cold type elements pony crowd under bred too critique simple battlefield leather more lot lips [SEP]']
[Init] best perm rec loss: 0.7275546789169312 for ['[CLS] lot under bred lips pony cold simple leather crowd type critique more battlefield too elements [SEP]']
[Init] best perm rec loss: 0.7265589833259583 for ['[CLS] under cold crowd leather type bred pony critique battlefield lot elements too more lips simple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.965 (perp=11.471, rec=0.356, cos=0.315), tot_loss_proj:3.500 [t=0.22s]
prediction: ['[CLS]port clear audience lifting the triumph beneath low edge golden spirit x its und promises [SEP]']
[ 100/2000] tot_loss=2.831 (perp=11.500, rec=0.226, cos=0.305), tot_loss_proj:3.293 [t=0.22s]
prediction: ['[CLS]has big that lifting its made above gospel edge passesars is its material realm [SEP]']
[ 150/2000] tot_loss=2.468 (perp=10.071, rec=0.148, cos=0.306), tot_loss_proj:2.968 [t=0.22s]
prediction: ['[CLS]has big that life its made above promise soarars is the material realm [SEP]']
[ 200/2000] tot_loss=2.289 (perp=9.280, rec=0.120, cos=0.313), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS]has make that life its that above promise soarars is the material realm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.155 (perp=8.604, rec=0.118, cos=0.316), tot_loss_proj:2.665 [t=0.22s]
prediction: ['[CLS] world promised make life promise that above its soarsars is the material realm [SEP]']
[ 300/2000] tot_loss=2.219 (perp=9.037, rec=0.095, cos=0.317), tot_loss_proj:2.795 [t=0.22s]
prediction: ['[CLS] world promised make life promise that above its so promisears is the material realm [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.086 (perp=8.391, rec=0.090, cos=0.317), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] of promised make believe life that is its so promisears above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.778 (perp=6.927, rec=0.076, cos=0.317), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] of promise make believe life that is its promise soars above the material realm [SEP]']
[ 450/2000] tot_loss=1.775 (perp=6.927, rec=0.071, cos=0.318), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] of promise make believe life that is its promise soars above the material realm [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.669 (perp=6.392, rec=0.073, cos=0.318), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] of promise make believe life is that its promise soars above the material realm [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.579 (perp=5.938, rec=0.073, cos=0.318), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] of make believe life promise is that its promise soars above the material realm [SEP]']
[ 600/2000] tot_loss=1.584 (perp=5.938, rec=0.077, cos=0.319), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] of make believe life promise is that its promise soars above the material realm [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.589 (perp=5.938, rec=0.083, cos=0.318), tot_loss_proj:1.782 [t=0.22s]
prediction: ['[CLS] of make believe life promise is that its promise soars above the material realm [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.767 (perp=6.862, rec=0.076, cos=0.318), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] of make believe life promise is that its of soars above the material realm [SEP]']
[ 750/2000] tot_loss=1.746 (perp=6.862, rec=0.055, cos=0.318), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] of make believe life promise is that its of soars above the material realm [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.532 (perp=5.723, rec=0.069, cos=0.319), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] of make believe life is that its promise of soars above the material realm [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.535 (perp=5.723, rec=0.072, cos=0.318), tot_loss_proj:1.724 [t=0.22s]
prediction: ['[CLS] of make believe life is that its promise of soars above the material realm [SEP]']
[ 900/2000] tot_loss=1.537 (perp=5.723, rec=0.074, cos=0.318), tot_loss_proj:1.718 [t=0.22s]
prediction: ['[CLS] of make believe life is that its promise of soars above the material realm [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.493 (perp=5.501, rec=0.074, cos=0.319), tot_loss_proj:1.650 [t=0.22s]
prediction: ['[CLS] life of make believe is that its promise of soars above the material realm [SEP]']
Attempt swap
[1000/2000] tot_loss=1.496 (perp=5.501, rec=0.077, cos=0.319), tot_loss_proj:1.666 [t=0.22s]
prediction: ['[CLS] life of make believe is that its promise of soars above the material realm [SEP]']
[1050/2000] tot_loss=1.486 (perp=5.501, rec=0.067, cos=0.319), tot_loss_proj:1.648 [t=0.22s]
prediction: ['[CLS] life of make believe is that its promise of soars above the material realm [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.410 (perp=5.104, rec=0.070, cos=0.319), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.414 (perp=5.104, rec=0.074, cos=0.319), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
[1200/2000] tot_loss=1.403 (perp=5.104, rec=0.063, cos=0.319), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.401 (perp=5.104, rec=0.061, cos=0.319), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1300/2000] tot_loss=1.394 (perp=5.104, rec=0.054, cos=0.319), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
[1350/2000] tot_loss=1.414 (perp=5.104, rec=0.074, cos=0.319), tot_loss_proj:1.583 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.404 (perp=5.104, rec=0.064, cos=0.319), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.409 (perp=5.104, rec=0.069, cos=0.319), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
[1500/2000] tot_loss=1.408 (perp=5.104, rec=0.067, cos=0.319), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.410 (perp=5.104, rec=0.070, cos=0.319), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1600/2000] tot_loss=1.402 (perp=5.104, rec=0.062, cos=0.319), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
[1650/2000] tot_loss=1.404 (perp=5.104, rec=0.064, cos=0.319), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.401 (perp=5.104, rec=0.060, cos=0.319), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1750/2000] tot_loss=1.410 (perp=5.104, rec=0.070, cos=0.319), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
[1800/2000] tot_loss=1.409 (perp=5.104, rec=0.069, cos=0.319), tot_loss_proj:1.584 [t=0.23s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
[1850/2000] tot_loss=1.399 (perp=5.104, rec=0.059, cos=0.319), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] of make believe is that its promise of life soars above the material realm [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.409 (perp=5.111, rec=0.068, cos=0.319), tot_loss_proj:1.523 [t=0.22s]
prediction: ['[CLS] of make believe is its promise of life that soars above the material realm [SEP]']
[1950/2000] tot_loss=1.404 (perp=5.111, rec=0.063, cos=0.319), tot_loss_proj:1.517 [t=0.22s]
prediction: ['[CLS] of make believe is its promise of life that soars above the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.404 (perp=5.111, rec=0.062, cos=0.319), tot_loss_proj:1.504 [t=0.22s]
prediction: ['[CLS] of make believe is its promise of life that soars above the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] of make believe is that its promise of life soars above the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 55.172 | p: 53.333 | r: 57.143
rougeL     | fm: 77.419 | p: 75.000 | r: 80.000
rougeLsum  | fm: 77.419 | p: 75.000 | r: 80.000
r1fm+r2fm = 151.947

[Aggregate metrics]:
rouge1     | fm: 86.591 | p: 85.830 | r: 87.608
rouge2     | fm: 53.639 | p: 53.374 | r: 53.937
rougeL     | fm: 75.527 | p: 74.860 | r: 76.351
rougeLsum  | fm: 75.498 | p: 74.807 | r: 76.304
r1fm+r2fm = 140.229

input #77 time: 0:08:54 | total time: 11:45:24


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.899893431614784
highest_index [0]
highest [0.899893431614784]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9513670802116394 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9172993302345276 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.7990917563438416 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.7984216809272766 for ['[CLS] frontuting grace [SEP]']
[Init] best rec loss: 0.7589104771614075 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.7524875998497009 for ['[CLS] le grant screens [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.303 (perp=9.081, rec=0.297, cos=0.189), tot_loss_proj:2.940 [t=0.22s]
prediction: ['[CLS] leave exit exit [SEP]']
[ 100/2000] tot_loss=2.196 (perp=9.346, rec=0.145, cos=0.182), tot_loss_proj:2.700 [t=0.22s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 150/2000] tot_loss=2.156 (perp=9.346, rec=0.103, cos=0.184), tot_loss_proj:2.704 [t=0.22s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 200/2000] tot_loss=2.132 (perp=9.346, rec=0.075, cos=0.188), tot_loss_proj:2.709 [t=0.22s]
prediction: ['[CLS] exit exit theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.847 (perp=7.958, rec=0.066, cos=0.190), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.843 (perp=7.958, rec=0.063, cos=0.188), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.853 (perp=7.958, rec=0.072, cos=0.189), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.838 (perp=7.958, rec=0.059, cos=0.187), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.845 (perp=7.958, rec=0.065, cos=0.189), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.842 (perp=7.958, rec=0.062, cos=0.188), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.839 (perp=7.958, rec=0.057, cos=0.190), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.840 (perp=7.958, rec=0.059, cos=0.190), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.840 (perp=7.958, rec=0.059, cos=0.189), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.847 (perp=7.958, rec=0.067, cos=0.188), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.837 (perp=7.958, rec=0.055, cos=0.190), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.831 (perp=7.958, rec=0.050, cos=0.190), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.830 (perp=7.958, rec=0.049, cos=0.190), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.837 (perp=7.958, rec=0.057, cos=0.189), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.842 (perp=7.958, rec=0.060, cos=0.190), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.835 (perp=7.958, rec=0.053, cos=0.190), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.834 (perp=7.958, rec=0.054, cos=0.188), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.844 (perp=7.958, rec=0.062, cos=0.190), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.844 (perp=7.958, rec=0.063, cos=0.190), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.847 (perp=7.958, rec=0.067, cos=0.188), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.848 (perp=7.958, rec=0.066, cos=0.190), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.850 (perp=7.958, rec=0.068, cos=0.190), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.843 (perp=7.958, rec=0.062, cos=0.189), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.835 (perp=7.958, rec=0.054, cos=0.190), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.834 (perp=7.958, rec=0.052, cos=0.190), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.850 (perp=7.958, rec=0.068, cos=0.190), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.846 (perp=7.958, rec=0.065, cos=0.190), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.843 (perp=7.958, rec=0.062, cos=0.190), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.843 (perp=7.958, rec=0.062, cos=0.190), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.840 (perp=7.958, rec=0.058, cos=0.190), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.841 (perp=7.958, rec=0.059, cos=0.190), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.835 (perp=7.958, rec=0.054, cos=0.190), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.846 (perp=7.958, rec=0.065, cos=0.190), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.850 (perp=7.958, rec=0.068, cos=0.190), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.850 (perp=7.958, rec=0.069, cos=0.190), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.837 (perp=7.958, rec=0.055, cos=0.190), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.724 | p: 85.967 | r: 87.752
rouge2     | fm: 54.060 | p: 53.777 | r: 54.403
rougeL     | fm: 75.781 | p: 75.143 | r: 76.647
rougeLsum  | fm: 75.848 | p: 75.108 | r: 76.618
r1fm+r2fm = 140.784

input #78 time: 0:08:42 | total time: 11:54:07


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.8153504304730479
highest_index [0]
highest [0.8153504304730479]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9653611779212952 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9510411620140076 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 0.946803629398346 for ['[CLS] neither tokyo [SEP]']
[Init] best rec loss: 0.8843750357627869 for ['[CLS] clay starts [SEP]']
[Init] best rec loss: 0.8450197577476501 for ['[CLS] armada containing [SEP]']
[Init] best rec loss: 0.8398720622062683 for ['[CLS] amount volumes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.815 (perp=11.428, rec=0.194, cos=0.335), tot_loss_proj:3.003 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.772 (perp=11.428, rec=0.152, cos=0.334), tot_loss_proj:2.993 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.749 (perp=11.428, rec=0.131, cos=0.333), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.281 (perp=9.382, rec=0.070, cos=0.334), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.156 (perp=8.695, rec=0.085, cos=0.331), tot_loss_proj:2.376 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=2.145 (perp=8.695, rec=0.072, cos=0.335), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.135 (perp=8.695, rec=0.061, cos=0.335), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.147 (perp=8.695, rec=0.073, cos=0.335), tot_loss_proj:2.357 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=2.142 (perp=8.695, rec=0.068, cos=0.335), tot_loss_proj:2.355 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.144 (perp=8.695, rec=0.070, cos=0.335), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.140 (perp=8.695, rec=0.066, cos=0.335), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=2.133 (perp=8.695, rec=0.059, cos=0.335), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.140 (perp=8.695, rec=0.066, cos=0.335), tot_loss_proj:2.359 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.144 (perp=8.695, rec=0.070, cos=0.335), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=2.135 (perp=8.695, rec=0.061, cos=0.335), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.142 (perp=8.695, rec=0.068, cos=0.335), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.128 (perp=8.695, rec=0.054, cos=0.335), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=2.134 (perp=8.695, rec=0.060, cos=0.335), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.147 (perp=8.695, rec=0.073, cos=0.335), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=2.142 (perp=8.695, rec=0.068, cos=0.335), tot_loss_proj:2.341 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=2.143 (perp=8.695, rec=0.069, cos=0.335), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=2.129 (perp=8.695, rec=0.055, cos=0.335), tot_loss_proj:2.362 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=2.146 (perp=8.695, rec=0.072, cos=0.335), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=2.133 (perp=8.695, rec=0.059, cos=0.335), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=2.138 (perp=8.695, rec=0.064, cos=0.335), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.135 (perp=8.695, rec=0.061, cos=0.335), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=2.131 (perp=8.695, rec=0.057, cos=0.335), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.134 (perp=8.695, rec=0.060, cos=0.335), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.135 (perp=8.695, rec=0.061, cos=0.335), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=2.133 (perp=8.695, rec=0.059, cos=0.335), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.139 (perp=8.695, rec=0.065, cos=0.335), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.130 (perp=8.695, rec=0.056, cos=0.335), tot_loss_proj:2.344 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=2.148 (perp=8.695, rec=0.074, cos=0.335), tot_loss_proj:2.334 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.143 (perp=8.695, rec=0.069, cos=0.335), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.147 (perp=8.695, rec=0.073, cos=0.335), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=2.142 (perp=8.695, rec=0.068, cos=0.335), tot_loss_proj:2.346 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.133 (perp=8.695, rec=0.059, cos=0.335), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.138 (perp=8.695, rec=0.064, cos=0.335), tot_loss_proj:2.349 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=2.128 (perp=8.695, rec=0.054, cos=0.335), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.135 (perp=8.695, rec=0.061, cos=0.335), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.002 | p: 86.218 | r: 87.960
rouge2     | fm: 53.614 | p: 53.335 | r: 53.907
rougeL     | fm: 75.783 | p: 75.115 | r: 76.614
rougeLsum  | fm: 75.830 | p: 75.129 | r: 76.646
r1fm+r2fm = 140.616

input #79 time: 0:08:44 | total time: 12:02:51


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.8006379119204454
highest_index [0]
highest [0.8006379119204454]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9560205340385437 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9490706920623779 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9330174326896667 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9055994749069214 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.8901746273040771 for ['[CLS] xavier regular plain standings masters [SEP]']
[Init] best rec loss: 0.8736257553100586 for ['[CLS] heard pavilionplane ian tu [SEP]']
[Init] best perm rec loss: 0.8718249201774597 for ['[CLS] heardplane ian tu pavilion [SEP]']
[Init] best perm rec loss: 0.8715472221374512 for ['[CLS] tu heard ian pavilionplane [SEP]']
[Init] best perm rec loss: 0.8699312210083008 for ['[CLS]plane pavilion heard tu ian [SEP]']
[Init] best perm rec loss: 0.8695284724235535 for ['[CLS] heard tuplane pavilion ian [SEP]']
[Init] best perm rec loss: 0.8684927821159363 for ['[CLS] pavilionplane heard tu ian [SEP]']
[Init] best perm rec loss: 0.8684551119804382 for ['[CLS]plane ian tu heard pavilion [SEP]']
[Init] best perm rec loss: 0.8676961064338684 for ['[CLS] tuplane heard pavilion ian [SEP]']
[Init] best perm rec loss: 0.8671950101852417 for ['[CLS] ianplane tu pavilion heard [SEP]']
[Init] best perm rec loss: 0.8658819198608398 for ['[CLS] ianplane pavilion heard tu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.315 (perp=11.403, rec=0.691, cos=0.343), tot_loss_proj:4.197 [t=0.22s]
prediction: ['[CLS] shortly peter remained dutch included [SEP]']
[ 100/2000] tot_loss=3.737 (perp=14.073, rec=0.592, cos=0.330), tot_loss_proj:4.537 [t=0.22s]
prediction: ['[CLS] sk records emigrated dutchrks [SEP]']
[ 150/2000] tot_loss=3.485 (perp=13.023, rec=0.532, cos=0.349), tot_loss_proj:4.294 [t=0.22s]
prediction: ['[CLS] youngest harry perishedzen wise [SEP]']
[ 200/2000] tot_loss=3.665 (perp=14.448, rec=0.511, cos=0.264), tot_loss_proj:4.647 [t=0.22s]
prediction: ['[CLS] youngestzen latticezen wise [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.244 (perp=12.259, rec=0.509, cos=0.283), tot_loss_proj:3.768 [t=0.22s]
prediction: ['[CLS] wizenrablezen wise [SEP]']
[ 300/2000] tot_loss=3.347 (perp=12.897, rec=0.475, cos=0.292), tot_loss_proj:4.014 [t=0.22s]
prediction: ['[CLS] wizencapezen wise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.082 (perp=11.819, rec=0.475, cos=0.243), tot_loss_proj:3.809 [t=0.22s]
prediction: ['[CLS] wizenzenrmed wise [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.127 (perp=11.819, rec=0.465, cos=0.299), tot_loss_proj:3.814 [t=0.22s]
prediction: ['[CLS] wizenzenrmed wise [SEP]']
[ 450/2000] tot_loss=3.135 (perp=11.819, rec=0.434, cos=0.338), tot_loss_proj:3.813 [t=0.22s]
prediction: ['[CLS] wizenzenrmed wise [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.121 (perp=11.819, rec=0.424, cos=0.334), tot_loss_proj:3.818 [t=0.22s]
prediction: ['[CLS] wizenzenrmed wise [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.386 (perp=13.365, rec=0.422, cos=0.292), tot_loss_proj:4.334 [t=0.22s]
prediction: ['[CLS] wizenzen reserved wise [SEP]']
[ 600/2000] tot_loss=3.347 (perp=13.365, rec=0.416, cos=0.258), tot_loss_proj:4.330 [t=0.22s]
prediction: ['[CLS] wizenzen reserved wise [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.733 (perp=10.350, rec=0.418, cos=0.245), tot_loss_proj:3.472 [t=0.22s]
prediction: ['[CLS] wizenzen wa wise [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.718 (perp=10.350, rec=0.412, cos=0.235), tot_loss_proj:3.471 [t=0.22s]
prediction: ['[CLS] wizenzen wa wise [SEP]']
[ 750/2000] tot_loss=2.734 (perp=10.350, rec=0.413, cos=0.250), tot_loss_proj:3.471 [t=0.22s]
prediction: ['[CLS] wizenzen wa wise [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.765 (perp=10.350, rec=0.404, cos=0.291), tot_loss_proj:3.472 [t=0.22s]
prediction: ['[CLS] wizenzen wa wise [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.809 (perp=10.350, rec=0.398, cos=0.341), tot_loss_proj:3.472 [t=0.22s]
prediction: ['[CLS] wizenzen wa wise [SEP]']
[ 900/2000] tot_loss=2.764 (perp=10.350, rec=0.386, cos=0.308), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS] wizenzen wa wise [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.900 (perp=11.183, rec=0.386, cos=0.277), tot_loss_proj:3.535 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1000/2000] tot_loss=2.893 (perp=11.183, rec=0.389, cos=0.267), tot_loss_proj:3.542 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1050/2000] tot_loss=2.960 (perp=11.183, rec=0.385, cos=0.339), tot_loss_proj:3.538 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1100/2000] tot_loss=2.926 (perp=11.183, rec=0.394, cos=0.296), tot_loss_proj:3.542 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1150/2000] tot_loss=2.897 (perp=11.183, rec=0.386, cos=0.275), tot_loss_proj:3.541 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1200/2000] tot_loss=2.964 (perp=11.183, rec=0.391, cos=0.337), tot_loss_proj:3.547 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1250/2000] tot_loss=2.914 (perp=11.183, rec=0.380, cos=0.297), tot_loss_proj:3.542 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1300/2000] tot_loss=2.943 (perp=11.183, rec=0.379, cos=0.328), tot_loss_proj:3.538 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1350/2000] tot_loss=2.928 (perp=11.183, rec=0.372, cos=0.319), tot_loss_proj:3.541 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1400/2000] tot_loss=2.917 (perp=11.183, rec=0.382, cos=0.298), tot_loss_proj:3.546 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1450/2000] tot_loss=2.943 (perp=11.183, rec=0.371, cos=0.335), tot_loss_proj:3.547 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1500/2000] tot_loss=2.932 (perp=11.183, rec=0.387, cos=0.308), tot_loss_proj:3.542 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1550/2000] tot_loss=2.947 (perp=11.183, rec=0.373, cos=0.338), tot_loss_proj:3.548 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1600/2000] tot_loss=2.930 (perp=11.183, rec=0.382, cos=0.311), tot_loss_proj:3.553 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1650/2000] tot_loss=2.948 (perp=11.183, rec=0.375, cos=0.336), tot_loss_proj:3.544 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1700/2000] tot_loss=2.948 (perp=11.183, rec=0.377, cos=0.334), tot_loss_proj:3.541 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1750/2000] tot_loss=2.950 (perp=11.183, rec=0.380, cos=0.334), tot_loss_proj:3.548 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1800/2000] tot_loss=2.970 (perp=11.183, rec=0.379, cos=0.355), tot_loss_proj:3.543 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1850/2000] tot_loss=2.939 (perp=11.183, rec=0.373, cos=0.329), tot_loss_proj:3.544 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[1900/2000] tot_loss=2.959 (perp=11.183, rec=0.374, cos=0.348), tot_loss_proj:3.541 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
[1950/2000] tot_loss=2.953 (perp=11.183, rec=0.383, cos=0.334), tot_loss_proj:3.535 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Attempt swap
[2000/2000] tot_loss=2.949 (perp=11.183, rec=0.372, cos=0.341), tot_loss_proj:3.545 [t=0.22s]
prediction: ['[CLS] wizenzen rate wise [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizenzen rate wise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 60.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 60.000 | r: 75.000
rougeLsum  | fm: 66.667 | p: 60.000 | r: 75.000
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 86.676 | p: 85.826 | r: 87.764
rouge2     | fm: 52.878 | p: 52.645 | r: 53.185
rougeL     | fm: 75.728 | p: 75.047 | r: 76.600
rougeLsum  | fm: 75.725 | p: 74.991 | r: 76.646
r1fm+r2fm = 139.554

input #80 time: 0:08:45 | total time: 12:11:37


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.8876020148840326
highest_index [0]
highest [0.8876020148840326]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9537463188171387 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.926715075969696 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.874933660030365 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8436337113380432 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8421163558959961 for ['[CLS]eering dominance sectional cummings lil yankee [SEP]']
[Init] best rec loss: 0.805587112903595 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.7969527244567871 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7745770215988159 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best perm rec loss: 0.7737991809844971 for ['[CLS] missingitating modelled bands approval threads [SEP]']
[Init] best perm rec loss: 0.7720701694488525 for ['[CLS] missing bands approval modelleditating threads [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.699 (perp=10.869, rec=0.318, cos=0.207), tot_loss_proj:3.479 [t=0.22s]
prediction: ['[CLS] not bacterium hits hardly important player [SEP]']
[ 100/2000] tot_loss=2.162 (perp=9.071, rec=0.145, cos=0.203), tot_loss_proj:3.093 [t=0.22s]
prediction: ['[CLS] not most player the impressive player [SEP]']
[ 150/2000] tot_loss=1.942 (perp=8.252, rec=0.083, cos=0.208), tot_loss_proj:3.415 [t=0.22s]
prediction: ['[CLS] not most is the impressive player [SEP]']
[ 200/2000] tot_loss=1.930 (perp=8.252, rec=0.067, cos=0.212), tot_loss_proj:3.415 [t=0.22s]
prediction: ['[CLS] not most is the impressive player [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.680 (perp=7.044, rec=0.063, cos=0.208), tot_loss_proj:3.159 [t=0.22s]
prediction: ['[CLS] not is the most impressive player [SEP]']
[ 300/2000] tot_loss=1.685 (perp=7.044, rec=0.065, cos=0.211), tot_loss_proj:3.161 [t=0.22s]
prediction: ['[CLS] not is the most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.685 (perp=7.044, rec=0.065, cos=0.211), tot_loss_proj:3.171 [t=0.22s]
prediction: ['[CLS] not is the most impressive player [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.470 (perp=5.977, rec=0.066, cos=0.208), tot_loss_proj:1.545 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.458 (perp=5.977, rec=0.052, cos=0.211), tot_loss_proj:1.552 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.469 (perp=5.977, rec=0.062, cos=0.211), tot_loss_proj:1.550 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.462 (perp=5.977, rec=0.056, cos=0.211), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.471 (perp=5.977, rec=0.064, cos=0.212), tot_loss_proj:1.551 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.458 (perp=5.977, rec=0.051, cos=0.212), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.464 (perp=5.977, rec=0.062, cos=0.207), tot_loss_proj:1.554 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.462 (perp=5.977, rec=0.056, cos=0.211), tot_loss_proj:1.538 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.468 (perp=5.977, rec=0.062, cos=0.211), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.468 (perp=5.977, rec=0.061, cos=0.212), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.466 (perp=5.977, rec=0.058, cos=0.212), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=5.977, rec=0.062, cos=0.212), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.471 (perp=5.977, rec=0.064, cos=0.212), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.471 (perp=5.977, rec=0.063, cos=0.212), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.467 (perp=5.977, rec=0.059, cos=0.212), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.467 (perp=5.977, rec=0.060, cos=0.212), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.472 (perp=5.977, rec=0.065, cos=0.212), tot_loss_proj:1.539 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.469 (perp=5.977, rec=0.061, cos=0.212), tot_loss_proj:1.543 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.459 (perp=5.977, rec=0.055, cos=0.208), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.464 (perp=5.977, rec=0.058, cos=0.211), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.470 (perp=5.977, rec=0.064, cos=0.211), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.470 (perp=5.977, rec=0.063, cos=0.212), tot_loss_proj:1.547 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.467 (perp=5.977, rec=0.060, cos=0.212), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.474 (perp=5.977, rec=0.067, cos=0.212), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.466 (perp=5.977, rec=0.058, cos=0.212), tot_loss_proj:1.537 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.464 (perp=5.977, rec=0.057, cos=0.212), tot_loss_proj:1.544 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.460 (perp=5.977, rec=0.053, cos=0.212), tot_loss_proj:1.546 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.460 (perp=5.977, rec=0.053, cos=0.212), tot_loss_proj:1.542 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.478 (perp=5.977, rec=0.070, cos=0.212), tot_loss_proj:1.554 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.463 (perp=5.977, rec=0.056, cos=0.212), tot_loss_proj:1.541 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.476 (perp=5.977, rec=0.068, cos=0.212), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.462 (perp=5.977, rec=0.054, cos=0.212), tot_loss_proj:1.545 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.466 (perp=5.977, rec=0.059, cos=0.212), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.818 | p: 86.030 | r: 87.895
rouge2     | fm: 53.357 | p: 53.082 | r: 53.723
rougeL     | fm: 75.923 | p: 75.217 | r: 76.781
rougeLsum  | fm: 76.019 | p: 75.287 | r: 76.843
r1fm+r2fm = 140.175

input #81 time: 0:08:46 | total time: 12:20:23


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.8939516074397175
highest_index [0]
highest [0.8939516074397175]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9480867385864258 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9428175687789917 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9351033568382263 for ['[CLS] firmly wilder after weighted ninection latter i [SEP]']
[Init] best rec loss: 0.9078506827354431 for ['[CLS] seaside ray moved throat traitor mistake ports homage [SEP]']
[Init] best rec loss: 0.8961086273193359 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best perm rec loss: 0.8950014114379883 for ['[CLS] babyturn aesian soft letter eric distribution [SEP]']
[Init] best perm rec loss: 0.8948898911476135 for ['[CLS] a distribution ericturn letter babyesian soft [SEP]']
[Init] best perm rec loss: 0.8929476141929626 for ['[CLS] a soft letter eric babyturn distributionesian [SEP]']
[Init] best perm rec loss: 0.8911707997322083 for ['[CLS] letteresian soft distribution a eric babyturn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.097 (perp=13.197, rec=0.265, cos=0.193), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] hurry sense undone limp mud stopped undone script [SEP]']
[ 100/2000] tot_loss=2.016 (perp=8.389, rec=0.139, cos=0.199), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] it is undone a sloppy by undone script [SEP]']
[ 150/2000] tot_loss=2.241 (perp=9.819, rec=0.081, cos=0.196), tot_loss_proj:2.746 [t=0.22s]
prediction: ['[CLS] it s sloppy a sloppy by undone script [SEP]']
[ 200/2000] tot_loss=2.230 (perp=9.819, rec=0.069, cos=0.198), tot_loss_proj:2.756 [t=0.22s]
prediction: ['[CLS] it s sloppy a sloppy by undone script [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.945 (perp=8.373, rec=0.074, cos=0.197), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS] it s sloppy a sloppy script undone by [SEP]']
[ 300/2000] tot_loss=1.938 (perp=8.373, rec=0.064, cos=0.200), tot_loss_proj:2.324 [t=0.22s]
prediction: ['[CLS] it s sloppy a sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.826 (perp=7.778, rec=0.070, cos=0.200), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.821 (perp=7.778, rec=0.065, cos=0.200), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 450/2000] tot_loss=1.806 (perp=7.778, rec=0.050, cos=0.200), tot_loss_proj:2.188 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.822 (perp=7.778, rec=0.066, cos=0.200), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.827 (perp=7.778, rec=0.071, cos=0.200), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 600/2000] tot_loss=1.818 (perp=7.778, rec=0.062, cos=0.201), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.812 (perp=7.778, rec=0.056, cos=0.200), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.822 (perp=7.778, rec=0.066, cos=0.201), tot_loss_proj:2.195 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 750/2000] tot_loss=1.829 (perp=7.778, rec=0.073, cos=0.201), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.829 (perp=7.778, rec=0.073, cos=0.201), tot_loss_proj:2.194 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.819 (perp=7.778, rec=0.064, cos=0.199), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 900/2000] tot_loss=1.824 (perp=7.778, rec=0.068, cos=0.201), tot_loss_proj:2.200 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.825 (perp=7.778, rec=0.070, cos=0.200), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1000/2000] tot_loss=1.833 (perp=7.778, rec=0.078, cos=0.200), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1050/2000] tot_loss=1.814 (perp=7.778, rec=0.058, cos=0.200), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1100/2000] tot_loss=1.820 (perp=7.778, rec=0.064, cos=0.201), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.826 (perp=7.778, rec=0.072, cos=0.198), tot_loss_proj:2.195 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1200/2000] tot_loss=1.818 (perp=7.778, rec=0.062, cos=0.200), tot_loss_proj:2.201 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1250/2000] tot_loss=1.828 (perp=7.778, rec=0.072, cos=0.201), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1300/2000] tot_loss=1.807 (perp=7.778, rec=0.050, cos=0.201), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1350/2000] tot_loss=1.819 (perp=7.778, rec=0.062, cos=0.201), tot_loss_proj:2.203 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1400/2000] tot_loss=1.835 (perp=7.778, rec=0.078, cos=0.201), tot_loss_proj:2.200 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1450/2000] tot_loss=1.826 (perp=7.778, rec=0.071, cos=0.199), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1500/2000] tot_loss=1.810 (perp=7.778, rec=0.054, cos=0.200), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.814 (perp=7.778, rec=0.059, cos=0.200), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1600/2000] tot_loss=1.828 (perp=7.778, rec=0.072, cos=0.200), tot_loss_proj:2.213 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1650/2000] tot_loss=1.825 (perp=7.778, rec=0.069, cos=0.200), tot_loss_proj:2.216 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1700/2000] tot_loss=1.836 (perp=7.778, rec=0.080, cos=0.200), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1750/2000] tot_loss=1.812 (perp=7.778, rec=0.056, cos=0.200), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1800/2000] tot_loss=1.810 (perp=7.778, rec=0.054, cos=0.201), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.812 (perp=7.778, rec=0.055, cos=0.201), tot_loss_proj:2.196 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.823 (perp=7.778, rec=0.068, cos=0.199), tot_loss_proj:2.214 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1950/2000] tot_loss=1.827 (perp=7.778, rec=0.072, cos=0.200), tot_loss_proj:2.220 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[2000/2000] tot_loss=1.823 (perp=7.778, rec=0.067, cos=0.200), tot_loss_proj:2.207 [t=0.22s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s a sloppy sloppy script undone by [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 86.980 | p: 86.082 | r: 88.088
rouge2     | fm: 53.417 | p: 53.062 | r: 53.822
rougeL     | fm: 75.883 | p: 75.078 | r: 76.838
rougeLsum  | fm: 75.971 | p: 75.212 | r: 76.877
r1fm+r2fm = 140.396

input #82 time: 0:08:46 | total time: 12:29:09


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.8300240806418056
highest_index [0]
highest [0.8300240806418056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8587944507598877 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.837592363357544 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.8298784494400024 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 0.7985304594039917 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.7919870018959045 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.7858113050460815 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.7832745909690857 for ['[CLS] envelope comprehensive nearly vice neck follows boys pitch stew residence [SEP]']
[Init] best perm rec loss: 0.7821168899536133 for ['[CLS] nearly vice pitch neck stew envelope follows boys comprehensive residence [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=10.446, rec=0.351, cos=0.312), tot_loss_proj:3.839 [t=0.22s]
prediction: ['[CLS] argentina cannot which develop culture grew australia when young avenue [SEP]']
[ 100/2000] tot_loss=2.304 (perp=8.984, rec=0.202, cos=0.305), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] childhood know what is what grows when when wants up [SEP]']
[ 150/2000] tot_loss=2.155 (perp=8.693, rec=0.115, cos=0.302), tot_loss_proj:2.903 [t=0.22s]
prediction: ['[CLS] it know what wants what grows when when wants be [SEP]']
[ 200/2000] tot_loss=2.125 (perp=8.628, rec=0.089, cos=0.310), tot_loss_proj:2.676 [t=0.22s]
prediction: ['[CLS] it know what wants what grows to when wants be [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.979 (perp=7.933, rec=0.083, cos=0.309), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] know what it wants on grows to when wants be [SEP]']
[ 300/2000] tot_loss=1.978 (perp=7.933, rec=0.081, cos=0.310), tot_loss_proj:2.429 [t=0.22s]
prediction: ['[CLS] know what it wants on grows to when wants be [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.095 (perp=8.549, rec=0.076, cos=0.310), tot_loss_proj:2.766 [t=0.22s]
prediction: ['[CLS] know what it wants grows circumstances to when wants be [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.006 (perp=8.091, rec=0.082, cos=0.306), tot_loss_proj:2.781 [t=0.22s]
prediction: ['[CLS] know what it wants grows to circumstances when wants be [SEP]']
[ 450/2000] tot_loss=2.013 (perp=8.091, rec=0.084, cos=0.310), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS] know what it wants grows to circumstances when wants be [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.921 (perp=7.697, rec=0.072, cos=0.310), tot_loss_proj:2.544 [t=0.22s]
prediction: ['[CLS] know what it wants grows to be when wants circumstances [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.898 (perp=7.525, rec=0.086, cos=0.307), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] know what it wants grows to be when circumstances wants [SEP]']
[ 600/2000] tot_loss=1.889 (perp=7.525, rec=0.074, cos=0.310), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] know what it wants grows to be when circumstances wants [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.801 (perp=7.068, rec=0.078, cos=0.309), tot_loss_proj:2.185 [t=0.22s]
prediction: ['[CLS] know what it wants to be grows when circumstances wants [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.647 (perp=6.289, rec=0.081, cos=0.308), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] know what it wants to be wants when life grows [SEP]']
[ 750/2000] tot_loss=1.648 (perp=6.289, rec=0.080, cos=0.310), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] know what it wants to be wants when life grows [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.663 (perp=6.415, rec=0.070, cos=0.311), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS] know what it wants to be wants when there grows [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.662 (perp=6.347, rec=0.083, cos=0.310), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] know what it wants to be there when wants grows [SEP]']
[ 900/2000] tot_loss=1.801 (perp=7.080, rec=0.075, cos=0.310), tot_loss_proj:2.246 [t=0.22s]
prediction: ['[CLS] know what it wants to be up when wants grows [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.763 (perp=6.903, rec=0.074, cos=0.308), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] know what it wants up to be when wants grows [SEP]']
Attempt swap
[1000/2000] tot_loss=1.762 (perp=6.903, rec=0.071, cos=0.310), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] know what it wants up to be when wants grows [SEP]']
[1050/2000] tot_loss=1.770 (perp=6.903, rec=0.079, cos=0.310), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] know what it wants up to be when wants grows [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.603 (perp=6.100, rec=0.075, cos=0.308), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.600 (perp=6.100, rec=0.070, cos=0.310), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
[1200/2000] tot_loss=1.606 (perp=6.100, rec=0.076, cos=0.310), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.610 (perp=6.100, rec=0.079, cos=0.311), tot_loss_proj:1.871 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=6.100, rec=0.071, cos=0.311), tot_loss_proj:1.871 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
[1350/2000] tot_loss=1.605 (perp=6.100, rec=0.075, cos=0.310), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.603 (perp=6.100, rec=0.073, cos=0.310), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.603 (perp=6.100, rec=0.073, cos=0.310), tot_loss_proj:1.875 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
[1500/2000] tot_loss=1.602 (perp=6.100, rec=0.073, cos=0.309), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.601 (perp=6.100, rec=0.072, cos=0.309), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.599 (perp=6.100, rec=0.070, cos=0.309), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
[1650/2000] tot_loss=1.599 (perp=6.100, rec=0.071, cos=0.309), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.600 (perp=6.100, rec=0.072, cos=0.308), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.606 (perp=6.100, rec=0.078, cos=0.308), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
[1800/2000] tot_loss=1.602 (perp=6.100, rec=0.074, cos=0.308), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.602 (perp=6.100, rec=0.073, cos=0.308), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.602 (perp=6.100, rec=0.074, cos=0.308), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
[1950/2000] tot_loss=1.591 (perp=6.100, rec=0.063, cos=0.308), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.602 (perp=6.100, rec=0.074, cos=0.308), tot_loss_proj:1.866 [t=0.22s]
prediction: ['[CLS] know what it wants to be when wants grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when wants grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 81.818 | p: 81.818 | r: 81.818
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 173.485

[Aggregate metrics]:
rouge1     | fm: 86.972 | p: 86.087 | r: 88.082
rouge2     | fm: 53.628 | p: 53.283 | r: 54.005
rougeL     | fm: 76.199 | p: 75.459 | r: 77.094
rougeLsum  | fm: 76.230 | p: 75.508 | r: 77.138
r1fm+r2fm = 140.600

input #83 time: 0:08:49 | total time: 12:37:58


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.8267792289324909
highest_index [0]
highest [0.8267792289324909]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9014952778816223 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8774308562278748 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8594344854354858 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8566556572914124 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.8480242490768433 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8341774344444275 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8337205052375793 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8233206868171692 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8229894638061523 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8174721598625183 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8005920052528381 for ['[CLS] hometails para hundreds sexy couple chinese [SEP]']
[Init] best perm rec loss: 0.8005673885345459 for ['[CLS] hundreds chinese hometails sexy couple para [SEP]']
[Init] best perm rec loss: 0.7935788035392761 for ['[CLS] home hundreds para sexytails chinese couple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.915 (perp=11.530, rec=0.305, cos=0.304), tot_loss_proj:3.270 [t=0.22s]
prediction: ['[CLS] lost losing by lost backwards peasant ability [SEP]']
[ 100/2000] tot_loss=2.644 (perp=10.858, rec=0.161, cos=0.311), tot_loss_proj:3.186 [t=0.22s]
prediction: ['[CLS] lost lost for lost think people ability [SEP]']
[ 150/2000] tot_loss=2.732 (perp=11.479, rec=0.127, cos=0.309), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] lost lost have lost think people ability [SEP]']
[ 200/2000] tot_loss=2.380 (perp=9.918, rec=0.090, cos=0.307), tot_loss_proj:2.899 [t=0.22s]
prediction: ['[CLS] have lost to lost think people ability [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.866 (perp=7.411, rec=0.072, cos=0.311), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 300/2000] tot_loss=1.870 (perp=7.411, rec=0.076, cos=0.312), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.864 (perp=7.411, rec=0.070, cos=0.312), tot_loss_proj:2.293 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.863 (perp=7.411, rec=0.068, cos=0.313), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 450/2000] tot_loss=1.868 (perp=7.411, rec=0.073, cos=0.313), tot_loss_proj:2.295 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.858 (perp=7.411, rec=0.062, cos=0.314), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.862 (perp=7.411, rec=0.067, cos=0.314), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 600/2000] tot_loss=1.871 (perp=7.411, rec=0.075, cos=0.314), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.868 (perp=7.411, rec=0.072, cos=0.314), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.866 (perp=7.411, rec=0.070, cos=0.314), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 750/2000] tot_loss=1.863 (perp=7.411, rec=0.067, cos=0.314), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.861 (perp=7.411, rec=0.065, cos=0.314), tot_loss_proj:2.300 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.873 (perp=7.411, rec=0.077, cos=0.314), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[ 900/2000] tot_loss=1.854 (perp=7.411, rec=0.058, cos=0.314), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.855 (perp=7.411, rec=0.059, cos=0.314), tot_loss_proj:2.307 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.864 (perp=7.411, rec=0.068, cos=0.314), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[1050/2000] tot_loss=1.868 (perp=7.411, rec=0.072, cos=0.314), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.859 (perp=7.411, rec=0.063, cos=0.314), tot_loss_proj:2.311 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.855 (perp=7.411, rec=0.059, cos=0.314), tot_loss_proj:2.312 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[1200/2000] tot_loss=1.880 (perp=7.411, rec=0.085, cos=0.314), tot_loss_proj:2.305 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.855 (perp=7.411, rec=0.060, cos=0.314), tot_loss_proj:2.310 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.874 (perp=7.411, rec=0.076, cos=0.316), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] have lost the lost ability people think [SEP]']
[1350/2000] tot_loss=2.041 (perp=8.302, rec=0.064, cos=0.316), tot_loss_proj:2.737 [t=0.22s]
prediction: ['[CLS] have to the lost ability people think [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.749 (perp=6.915, rec=0.052, cos=0.314), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] have people the lost ability to think [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.488 (perp=5.545, rec=0.063, cos=0.315), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] have people lost the ability to think [SEP]']
[1500/2000] tot_loss=1.487 (perp=5.545, rec=0.063, cos=0.315), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] have people lost the ability to think [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.324 (perp=4.681, rec=0.073, cos=0.315), tot_loss_proj:1.374 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.312 (perp=4.681, rec=0.061, cos=0.315), tot_loss_proj:1.368 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.312 (perp=4.681, rec=0.061, cos=0.315), tot_loss_proj:1.364 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.307 (perp=4.681, rec=0.055, cos=0.316), tot_loss_proj:1.370 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.312 (perp=4.681, rec=0.060, cos=0.316), tot_loss_proj:1.365 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.320 (perp=4.681, rec=0.068, cos=0.316), tot_loss_proj:1.374 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.316 (perp=4.681, rec=0.064, cos=0.316), tot_loss_proj:1.379 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.301 (perp=4.681, rec=0.050, cos=0.316), tot_loss_proj:1.371 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.302 (perp=4.681, rec=0.050, cos=0.316), tot_loss_proj:1.363 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.319 (perp=4.681, rec=0.067, cos=0.316), tot_loss_proj:1.379 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.221 | p: 86.295 | r: 88.246
rouge2     | fm: 54.386 | p: 54.097 | r: 54.702
rougeL     | fm: 76.386 | p: 75.635 | r: 77.343
rougeLsum  | fm: 76.455 | p: 75.697 | r: 77.405
r1fm+r2fm = 141.606

input #84 time: 0:08:46 | total time: 12:46:45


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9060306436999546
highest_index [0]
highest [0.9060306436999546]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.8835742473602295 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8819425106048584 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.8785814642906189 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.852861225605011 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8480734825134277 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best rec loss: 0.8457182049751282 for ['[CLS] inside feminist brought vision swing artificial agent fai manipulatedsome [SEP]']
[Init] best rec loss: 0.8435969948768616 for ['[CLS] go historyacious such what crazymas albeit includetime [SEP]']
[Init] best perm rec loss: 0.8422051668167114 for ['[CLS] crazy include whattime such albeitmasacious history go [SEP]']
[Init] best perm rec loss: 0.8418944478034973 for ['[CLS] what albeit suchaciousmas include crazytime go history [SEP]']
[Init] best perm rec loss: 0.8416463136672974 for ['[CLS]acious albeit suchmas include go historytime crazy what [SEP]']
[Init] best perm rec loss: 0.8406314849853516 for ['[CLS] go include suchmasacious albeittime history what crazy [SEP]']
[Init] best perm rec loss: 0.8400303721427917 for ['[CLS] gomas albeit history whattime include such crazyacious [SEP]']
[Init] best perm rec loss: 0.8399977087974548 for ['[CLS] goacious include whattime such albeit crazymas history [SEP]']
[Init] best perm rec loss: 0.839905321598053 for ['[CLS] crazy whatacious suchmastime history go albeit include [SEP]']
[Init] best perm rec loss: 0.838695228099823 for ['[CLS]timeaciousmas albeit history such crazy what go include [SEP]']
[Init] best perm rec loss: 0.838619589805603 for ['[CLS]mas albeitacious include crazy suchtime history go what [SEP]']
[Init] best perm rec loss: 0.8384509682655334 for ['[CLS] suchmastime albeit crazy whatacious include go history [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.502 (perp=10.103, rec=0.308, cos=0.174), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] also badly. unfortunately most less good unfortunately cent good [SEP]']
[ 100/2000] tot_loss=2.125 (perp=9.004, rec=0.150, cos=0.174), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] also unfortunately, unfortunately very not good unfortunately s good [SEP]']
[ 150/2000] tot_loss=1.975 (perp=8.495, rec=0.114, cos=0.162), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] also unfortunately, unfortunately very not very unfortunately s good [SEP]']
[ 200/2000] tot_loss=1.887 (perp=8.036, rec=0.104, cos=0.176), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] also unfortunately, unfortunately very not very unfortunately it good [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.772 (perp=7.455, rec=0.108, cos=0.173), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] also unfortunately, unfortunately not very very unfortunately it good [SEP]']
[ 300/2000] tot_loss=1.754 (perp=7.455, rec=0.085, cos=0.179), tot_loss_proj:2.378 [t=0.22s]
prediction: ['[CLS] also unfortunately, unfortunately not very very unfortunately it good [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.484 (perp=6.139, rec=0.077, cos=0.179), tot_loss_proj:1.814 [t=0.22s]
prediction: ["[CLS] also unfortunately, unfortunately'it not very very good [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.423 (perp=5.829, rec=0.082, cos=0.175), tot_loss_proj:1.751 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately'it not very very good [SEP]"]
[ 450/2000] tot_loss=1.428 (perp=5.829, rec=0.085, cos=0.177), tot_loss_proj:1.742 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately'it not very very good [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.588 (perp=6.600, rec=0.090, cos=0.177), tot_loss_proj:1.906 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately'it not very s good [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.302 (perp=5.235, rec=0.087, cos=0.168), tot_loss_proj:1.673 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately's it not very good [SEP]"]
[ 600/2000] tot_loss=1.304 (perp=5.235, rec=0.083, cos=0.175), tot_loss_proj:1.681 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately's it not very good [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.168 (perp=4.549, rec=0.082, cos=0.177), tot_loss_proj:1.444 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately it's not very good [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.165 (perp=4.549, rec=0.078, cos=0.177), tot_loss_proj:1.448 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately it's not very good [SEP]"]
[ 750/2000] tot_loss=1.153 (perp=4.549, rec=0.066, cos=0.178), tot_loss_proj:1.438 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately it's not very good [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.156 (perp=4.549, rec=0.069, cos=0.178), tot_loss_proj:1.450 [t=0.22s]
prediction: ["[CLS] unfortunately also, unfortunately it's not very good [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.119 (perp=4.363, rec=0.072, cos=0.175), tot_loss_proj:1.272 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[ 900/2000] tot_loss=1.119 (perp=4.363, rec=0.070, cos=0.176), tot_loss_proj:1.265 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.133 (perp=4.363, rec=0.082, cos=0.178), tot_loss_proj:1.266 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.122 (perp=4.363, rec=0.071, cos=0.178), tot_loss_proj:1.275 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[1050/2000] tot_loss=1.121 (perp=4.363, rec=0.070, cos=0.179), tot_loss_proj:1.276 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.135 (perp=4.363, rec=0.084, cos=0.179), tot_loss_proj:1.265 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.119 (perp=4.363, rec=0.068, cos=0.179), tot_loss_proj:1.274 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[1200/2000] tot_loss=1.140 (perp=4.363, rec=0.089, cos=0.179), tot_loss_proj:1.266 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.123 (perp=4.363, rec=0.072, cos=0.179), tot_loss_proj:1.268 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.131 (perp=4.363, rec=0.079, cos=0.179), tot_loss_proj:1.268 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[1350/2000] tot_loss=1.125 (perp=4.363, rec=0.074, cos=0.179), tot_loss_proj:1.277 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.120 (perp=4.363, rec=0.069, cos=0.179), tot_loss_proj:1.265 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.116 (perp=4.363, rec=0.065, cos=0.179), tot_loss_proj:1.265 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[1500/2000] tot_loss=1.127 (perp=4.363, rec=0.075, cos=0.179), tot_loss_proj:1.277 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.116 (perp=4.363, rec=0.066, cos=0.177), tot_loss_proj:1.265 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.116 (perp=4.363, rec=0.065, cos=0.178), tot_loss_proj:1.274 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[1650/2000] tot_loss=1.122 (perp=4.363, rec=0.070, cos=0.179), tot_loss_proj:1.280 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.119 (perp=4.363, rec=0.068, cos=0.179), tot_loss_proj:1.285 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.119 (perp=4.363, rec=0.068, cos=0.179), tot_loss_proj:1.270 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
[1800/2000] tot_loss=1.112 (perp=4.363, rec=0.060, cos=0.179), tot_loss_proj:1.281 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.123 (perp=4.363, rec=0.072, cos=0.179), tot_loss_proj:1.265 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately it's also not very good [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.426 (perp=5.873, rec=0.072, cos=0.179), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] unfortunately, unfortunately it. s also not very good [SEP]']
[1950/2000] tot_loss=1.430 (perp=5.873, rec=0.076, cos=0.179), tot_loss_proj:1.568 [t=0.22s]
prediction: ['[CLS] unfortunately, unfortunately it. s also not very good [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.437 (perp=5.890, rec=0.082, cos=0.177), tot_loss_proj:1.621 [t=0.22s]
prediction: ["[CLS] unfortunately, unfortunately'it s also not very good [SEP]"]
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, unfortunately it's also not very good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 87.252 | p: 86.346 | r: 88.405
rouge2     | fm: 54.737 | p: 54.362 | r: 55.161
rougeL     | fm: 76.633 | p: 75.813 | r: 77.621
rougeLsum  | fm: 76.703 | p: 75.932 | r: 77.672
r1fm+r2fm = 141.989

input #85 time: 0:08:48 | total time: 12:55:34


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.8182903464131113
highest_index [0]
highest [0.8182903464131113]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9247846007347107 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.8880853652954102 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.78695148229599 for ['[CLS]q suicide drew [SEP]']
[Init] best rec loss: 0.7854275107383728 for ['[CLS] dial commanded tres [SEP]']
[Init] best perm rec loss: 0.7844029664993286 for ['[CLS] tres dial commanded [SEP]']
[Init] best perm rec loss: 0.7839035391807556 for ['[CLS] commanded dial tres [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.840 (perp=11.493, rec=0.214, cos=0.328), tot_loss_proj:2.917 [t=0.23s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
[ 100/2000] tot_loss=2.756 (perp=11.493, rec=0.128, cos=0.330), tot_loss_proj:2.909 [t=0.23s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
[ 150/2000] tot_loss=2.742 (perp=11.493, rec=0.116, cos=0.327), tot_loss_proj:2.910 [t=0.23s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
[ 200/2000] tot_loss=2.729 (perp=11.493, rec=0.101, cos=0.330), tot_loss_proj:2.916 [t=0.23s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.096 (perp=8.419, rec=0.087, cos=0.325), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 300/2000] tot_loss=2.079 (perp=8.419, rec=0.065, cos=0.330), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.080 (perp=8.419, rec=0.067, cos=0.330), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.081 (perp=8.419, rec=0.067, cos=0.330), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 450/2000] tot_loss=2.078 (perp=8.419, rec=0.064, cos=0.330), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.082 (perp=8.419, rec=0.068, cos=0.330), tot_loss_proj:2.139 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.079 (perp=8.419, rec=0.065, cos=0.330), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 600/2000] tot_loss=2.078 (perp=8.419, rec=0.064, cos=0.330), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.070 (perp=8.419, rec=0.056, cos=0.330), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.071 (perp=8.419, rec=0.057, cos=0.330), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 750/2000] tot_loss=2.064 (perp=8.419, rec=0.050, cos=0.330), tot_loss_proj:2.151 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.088 (perp=8.419, rec=0.074, cos=0.330), tot_loss_proj:2.152 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.073 (perp=8.419, rec=0.059, cos=0.330), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 900/2000] tot_loss=2.073 (perp=8.419, rec=0.059, cos=0.330), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.075 (perp=8.419, rec=0.061, cos=0.330), tot_loss_proj:2.158 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.072 (perp=8.419, rec=0.059, cos=0.330), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1050/2000] tot_loss=2.080 (perp=8.419, rec=0.066, cos=0.330), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.069 (perp=8.419, rec=0.055, cos=0.330), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.080 (perp=8.419, rec=0.066, cos=0.330), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1200/2000] tot_loss=2.078 (perp=8.419, rec=0.064, cos=0.330), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.079 (perp=8.419, rec=0.065, cos=0.330), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.068 (perp=8.419, rec=0.054, cos=0.330), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1350/2000] tot_loss=2.082 (perp=8.419, rec=0.068, cos=0.330), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.079 (perp=8.419, rec=0.065, cos=0.330), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.085 (perp=8.419, rec=0.071, cos=0.330), tot_loss_proj:2.135 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1500/2000] tot_loss=2.077 (perp=8.419, rec=0.063, cos=0.330), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.070 (perp=8.419, rec=0.056, cos=0.330), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.073 (perp=8.419, rec=0.059, cos=0.330), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1650/2000] tot_loss=2.077 (perp=8.419, rec=0.063, cos=0.330), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.078 (perp=8.419, rec=0.064, cos=0.330), tot_loss_proj:2.143 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.072 (perp=8.419, rec=0.058, cos=0.330), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1800/2000] tot_loss=2.072 (perp=8.419, rec=0.058, cos=0.330), tot_loss_proj:2.133 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.070 (perp=8.419, rec=0.056, cos=0.330), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.076 (perp=8.419, rec=0.062, cos=0.330), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
[1950/2000] tot_loss=2.080 (perp=8.419, rec=0.065, cos=0.330), tot_loss_proj:2.151 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.075 (perp=8.419, rec=0.061, cos=0.330), tot_loss_proj:2.151 [t=0.23s]
prediction: ['[CLS] emotional and clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] emotional and clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.392 | p: 86.508 | r: 88.518
rouge2     | fm: 54.138 | p: 53.777 | r: 54.596
rougeL     | fm: 76.553 | p: 75.740 | r: 77.470
rougeLsum  | fm: 76.419 | p: 75.693 | r: 77.325
r1fm+r2fm = 141.530

input #86 time: 0:09:07 | total time: 13:04:42


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.8322776620589338
highest_index [0]
highest [0.8322776620589338]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7397480607032776 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7263126969337463 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6799606084823608 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6641985774040222 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6455215215682983 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6400265097618103 for ['[CLS] bran eureka [SEP]']
[Init] best rec loss: 0.6354008913040161 for ['[CLS] under fan [SEP]']
[Init] best rec loss: 0.6101650595664978 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6063004732131958 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.043 (perp=12.536, rec=0.238, cos=0.297), tot_loss_proj:3.595 [t=0.23s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.992 (perp=12.536, rec=0.194, cos=0.290), tot_loss_proj:3.587 [t=0.23s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=2.977 (perp=12.536, rec=0.172, cos=0.298), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 200/2000] tot_loss=2.976 (perp=12.536, rec=0.175, cos=0.293), tot_loss_proj:3.592 [t=0.23s]
prediction: ['[CLS]ulsiveulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.945 (perp=12.536, rec=0.136, cos=0.302), tot_loss_proj:3.584 [t=0.23s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 300/2000] tot_loss=2.964 (perp=12.894, rec=0.082, cos=0.303), tot_loss_proj:3.554 [t=0.23s]
prediction: ['[CLS]ulsive prop [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.825 (perp=7.258, rec=0.080, cos=0.293), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.822 (perp=7.258, rec=0.068, cos=0.302), tot_loss_proj:1.825 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.821 (perp=7.258, rec=0.065, cos=0.305), tot_loss_proj:1.817 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.808 (perp=7.258, rec=0.051, cos=0.306), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.841 (perp=7.258, rec=0.083, cos=0.306), tot_loss_proj:1.826 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.830 (perp=7.258, rec=0.072, cos=0.307), tot_loss_proj:1.833 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.820 (perp=7.258, rec=0.072, cos=0.297), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.831 (perp=7.258, rec=0.073, cos=0.306), tot_loss_proj:1.818 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.808 (perp=7.258, rec=0.050, cos=0.307), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.818 (perp=7.258, rec=0.060, cos=0.307), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.810 (perp=7.258, rec=0.051, cos=0.307), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.811 (perp=7.258, rec=0.054, cos=0.305), tot_loss_proj:1.817 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.818 (perp=7.258, rec=0.060, cos=0.306), tot_loss_proj:1.831 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.808 (perp=7.258, rec=0.050, cos=0.307), tot_loss_proj:1.818 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.822 (perp=7.258, rec=0.064, cos=0.307), tot_loss_proj:1.822 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.826 (perp=7.258, rec=0.068, cos=0.307), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.820 (perp=7.258, rec=0.061, cos=0.307), tot_loss_proj:1.831 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.807 (perp=7.258, rec=0.048, cos=0.307), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.812 (perp=7.258, rec=0.055, cos=0.305), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.818 (perp=7.258, rec=0.060, cos=0.307), tot_loss_proj:1.819 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.812 (perp=7.258, rec=0.054, cos=0.307), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.826 (perp=7.258, rec=0.068, cos=0.307), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.829 (perp=7.258, rec=0.071, cos=0.307), tot_loss_proj:1.833 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.823 (perp=7.258, rec=0.065, cos=0.307), tot_loss_proj:1.822 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.823 (perp=7.258, rec=0.064, cos=0.307), tot_loss_proj:1.824 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.817 (perp=7.258, rec=0.058, cos=0.307), tot_loss_proj:1.809 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.820 (perp=7.258, rec=0.062, cos=0.307), tot_loss_proj:1.798 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.823 (perp=7.258, rec=0.065, cos=0.307), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.832 (perp=7.258, rec=0.073, cos=0.307), tot_loss_proj:1.823 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.819 (perp=7.258, rec=0.060, cos=0.307), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.812 (perp=7.258, rec=0.053, cos=0.307), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.824 (perp=7.258, rec=0.065, cos=0.307), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.824 (perp=7.258, rec=0.066, cos=0.307), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.827 (perp=7.258, rec=0.069, cos=0.307), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.541 | p: 86.588 | r: 88.691
rouge2     | fm: 54.635 | p: 54.294 | r: 55.048
rougeL     | fm: 76.734 | p: 75.927 | r: 77.613
rougeLsum  | fm: 76.696 | p: 75.946 | r: 77.676
r1fm+r2fm = 142.176

input #87 time: 0:09:06 | total time: 13:13:48


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.8055418642380863
highest_index [0]
highest [0.8055418642380863]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9141274094581604 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9140498042106628 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.913747251033783 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 0.9127427935600281 for ['[CLS] isabella wilde desire after cause sign leg bled [SEP] horse jerry from frost abnormal hedge whole glance simulation imam leon buzz orthodox event issues some running drive readers sw revolution rounded cuttingchemist k any france my framework redundant ding registered [SEP] located [SEP]']
[Init] best rec loss: 0.9117532968521118 for ['[CLS] of peninsulamygy behind lobby marie constructiontion obeyed santocide prominentlyaclefus now leon ruled reviewш cole menlle ⟨ [ containing &foot men oldest captured crensiere points carrier ahead a laundry investigator wrinkledhil 2015 [SEP]']
[Init] best rec loss: 0.9099510908126831 for ['[CLS] wink overall ranked solitary digital based multi loadratwhile howarddeck supreme future hen [MASK] valuable brandy present by wise late 2018 ancientuto am rubble⁄ studios when warned patentssr mayor office personaeving making flamelyn shannon competition back [SEP]']
[Init] best rec loss: 0.9074996113777161 for ['[CLS] central nose paint even³ healthy bronx semifinal usa value getting erebidae isabella yacht storage blinds non system order panther hardened decades some₃ tango sc formula closernesianties law loss softened instruments catalina place stems behind union cover d battleship issue [SEP]']
[Init] best rec loss: 0.9046677350997925 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.8963474035263062 for ['[CLS] earliest established exclusive separated graduated paper come rattled personnel road clear reapers weaving owned corruption everythingoris usedl spend fate pine top mile publishing referring au languagetium large osborn turnszi respectively jaw sessions house december hamlet father hurry canada africa [SEP]']
[Init] best perm rec loss: 0.8958557844161987 for ['[CLS] separated top sessionstiuml exclusive earliest au hurry weaving paper mile spend corruption africa clear established everything fate come pine used respectively referring house graduated father owned jaw turns personnel december language reapers hamlet large road rattledzi osbornoris publishing canada [SEP]']
[Init] best perm rec loss: 0.8957989811897278 for ['[CLS]zi clear reapers osborn earliest language used paper respectivelyorisl spend rattled separated publishing fate sessions hamlet personnel au house large graduated december africa exclusive turns jawtium mile referring top canada pine weaving everything father road owned established come hurry corruption [SEP]']
[Init] best perm rec loss: 0.8949765563011169 for ['[CLS] au everything language spend fate top hurry earliest december exclusivel graduated used osborn paper reapers come clear canada rattled respectively road hamlet referring weaving pine large separated house owned corruptionzi established sessions publishingtium jaw personneloris africa turns mile father [SEP]']
[Init] best perm rec loss: 0.8931931257247925 for ['[CLS] reapers personnel hurry father come earliest graduated exclusive hamlet au house separated fate respectively pineoris referring established turns weavingtium everything osborn sessions clear road spend owned canada africa milezi used top decemberl corruption publishing large jaw rattled paper language [SEP]']
[Init] best perm rec loss: 0.892576277256012 for ['[CLS] house fate canadatium december separated weaving paper father mile respectively reapers publishing earliest road osborn large clear hurry referringzi language exclusive spend corruption hamlet come sessionsoris rattled au everything used owned graduated pine established top personnel turns jaw africal [SEP]']
[Init] best perm rec loss: 0.8922362327575684 for ['[CLS]zi paper clear language fatetium separated large personnel africa spend come pinel reapers sessions osborn hamlet au weaving referring owned established respectively december publishing road corruption graduated earliest everything jaw mileoris exclusive turns rattled father hurry top house canada used [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.523 (perp=12.737, rec=0.652, cos=0.323), tot_loss_proj:4.090 [t=0.23s]
prediction: ["[CLS] laws japaneseestinal thatomi arrested swapped nap racismction sexual american cone yard thighs'ireland | con evab bad law scandal its kevin adults fivb heavily demontar ticked rape her began even [ an know how majority families question [SEP]"]
[ 100/2000] tot_loss=3.079 (perp=10.992, rec=0.561, cos=0.319), tot_loss_proj:3.824 [t=0.23s]
prediction: ["[CLS] officer canaryurance'remember. generated some lifeless s private election mommy each injustice ever their dismissed torture libby proven bad law experts atrocities sees adults fivb killing and its ( fire her was beautiful [ the knows how oldies drama included [SEP]"]
[ 150/2000] tot_loss=3.089 (perp=11.296, rec=0.472, cos=0.357), tot_loss_proj:3.923 [t=0.24s]
prediction: ['[CLS] acts killing t the inmates fine generated some lifeless chain domestic national opponents when unfair after the? rescue security - bad accept perfectly poetic sees adults fivb provisions the of ( detention we began sweet [ the know by unanimous drama included [SEP]']
[ 200/2000] tot_loss=3.247 (perp=12.262, rec=0.513, cos=0.282), tot_loss_proj:4.087 [t=0.24s]
prediction: ['[CLS] police elevator carmine that accused understand starters healthy collins without communist ofpods argentine interests a be ruined torture crossed a understand law wondering atrocities techniques adults discrimination yarmouth home its god precedent we was thession groom know by unanimous really asked [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.132 (perp=12.125, rec=0.494, cos=0.213), tot_loss_proj:4.277 [t=0.23s]
prediction: ['[CLS] we processes carmine our prison is behind tatum collins without criminal of abuse argentine rules understand peace ruined relay crossed safely understand ultimate understands atrocities techniquesturing discrimination could the of compiled morning we understand beautifulssion hydro know love fireworks really asked [SEP]']
[ 300/2000] tot_loss=3.137 (perp=12.066, rec=0.512, cos=0.212), tot_loss_proj:4.220 [t=0.23s]
prediction: ['[CLS] we recruitment frederick our understands is behind tatum collins. criminal her repeatedly argentine rules ultimate our ruined relay crossed safely understands greatest understands joy techniques⁺ discrimination could these of proved morning we understand sweetssion hydro know joy fireworks romance love [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.977 (perp=11.361, rec=0.418, cos=0.286), tot_loss_proj:4.157 [t=0.24s]
prediction: ['[CLS] we understands frederick said recruitment is emotional couch mutants. the of repeatedly argentine interests stefan our ruined sensation crossed public understands how understands joy enjoyed thanking snail could confidence of । crazy we understand sweetssion william know romance fireworks really facing [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.877 (perp=13.836, rec=0.750, cos=0.360), tot_loss_proj:4.538 [t=0.23s]
prediction: ['[CLS] people reacher eliminated lange tributary [SEP]hui tatum lifeless steward criminal the [SEP] yacht into latino our wasoman catherine percent understands one understood [SEP] millennium revenue blogs harassment supports was damon baseball we understand conner curran automaticchment the percent newsletter hour [SEP]']
[ 450/2000] tot_loss=3.454 (perp=12.549, rec=0.628, cos=0.316), tot_loss_proj:4.373 [t=0.23s]
prediction: ['[CLS] people alleged john. tributary [SEP] nests verity hungarian steward criminal the [SEP] criticized. latino our was civic catherine thirteen understands [SEP] understood [SEP] millennium revenue blogs harassment supports wasney baseball we understand flowering curran automaticchment the adult newsletter hour [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.400 (perp=12.560, rec=0.583, cos=0.305), tot_loss_proj:4.331 [t=0.24s]
prediction: ['[CLS]ologist alleged kelsey. tributary verity hungarian steward criminal the [SEP] ellis. [SEP] sports whitman our was civicriety twelve understands [SEP] understood [SEP] millennium revenue blogs harassment supports was emeritus baseball we understand stimulus housemates automaticchment the adult newsletter hour [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.324 (perp=12.681, rec=0.542, cos=0.246), tot_loss_proj:4.313 [t=0.23s]
prediction: ['[CLS] indians alleged dwyer. hungary [SEP] recipes speaks criminal the verity ellis into [SEP] sports whitman our was civic baggage twelve understands [SEP] understood [SEP] millennium♣ blogs harassment of wasnos baseball we understand stimulus housemates automaticchment the racecourse newsletter hour [SEP]']
[ 600/2000] tot_loss=3.297 (perp=12.340, rec=0.566, cos=0.262), tot_loss_proj:4.169 [t=0.24s]
prediction: ['[CLS] birds alleged morris. hungary [SEP] wasted speaks criminal the verity ellis into [SEP] sports abby our wasathic baggage twelve understands one understood [SEP] millennium enforcement blogs harassment of ofnos baseball we understand stimulus refrigerator cactuschment the racecourse newsletter hour [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.234 (perp=12.017, rec=0.523, cos=0.309), tot_loss_proj:4.182 [t=0.24s]
prediction: ['[CLS] hungaryologist alleged morris. [SEP]ˈ speaks the the verity website into [SEP] sports abby. wasathic baggage twelve understands one understood [SEP] millennium soils blogs harassment of ofnos dominican we understand stimulus refrigerator cactuschment the racecourse newsletter hour [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.265 (perp=11.811, rec=0.545, cos=0.358), tot_loss_proj:4.080 [t=0.23s]
prediction: ['[CLS] hungaryologist alleged challenged. [SEP] nothing speaks the the verity website into was sports abby. [SEP]athic baggage twelve understands one understood [SEP] millennium♣ blogs attacks of of romance dominican we understand stimulus refrigerator cactuschment the racecourse newsletter hour [SEP]']
[ 750/2000] tot_loss=3.273 (perp=12.844, rec=0.508, cos=0.196), tot_loss_proj:4.416 [t=0.24s]
prediction: ['[CLS] hungary indians bureau challenged compound [SEP] nothing speaks criminal the verity waitress. was sports whitman rules [SEP] civicriety equal understands one understood [SEP] tiny soils blogs attacks of of romance dominican rescue understand stimulus refrigerator inches district the elderly miles hour [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.277 (perp=12.470, rec=0.488, cos=0.295), tot_loss_proj:4.288 [t=0.23s]
prediction: ['[CLS] hungary indians verity john compound [SEP] nothing speaks the the bureau website into was sports whitman rules [SEP] civicriety equal understands one understood [SEP] tiny soils blogs attacks of of romance dominican understands understand stimulus refrigerator inches district his elderly miles hour [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.216 (perp=12.462, rec=0.498, cos=0.225), tot_loss_proj:4.272 [t=0.24s]
prediction: ['[CLS] hungary indians verity challenged miles [SEP] nothing speaks the the bureau website into was adult whitman rules [SEP] nadiariety equal understands one understood [SEP] tiny soils blogs attacks of of romance dominican lives understand stimulus refrigerator inches district his municipality compound hour [SEP]']
[ 900/2000] tot_loss=3.214 (perp=12.497, rec=0.482, cos=0.232), tot_loss_proj:4.305 [t=0.24s]
prediction: ['[CLS] hungary experts verity challenged miles [SEP] nothing speaks the the bureau website into had sports whitman rules [SEP] nadiariety equal understands one understood [SEP] tiny soils blogs attacks of of romance gastropod lives understand stimulus refrigerator inches district his municipality compound hour [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.213 (perp=12.238, rec=0.469, cos=0.297), tot_loss_proj:4.283 [t=0.23s]
prediction: ['[CLS] hungary experts verity challenged miles [SEP] nothing speaks the stimulus bureau website into had sports whitman rules [SEP] nadia slopes equal understands one understood [SEP] tiny soils blogs attacks of of romance gastropod lives understand the refrigerator inches district his municipality salt hour [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.133 (perp=12.000, rec=0.463, cos=0.269), tot_loss_proj:4.185 [t=0.23s]
prediction: ['[CLS] hungary experts verity challenged miles [SEP] nothing speaks the stimulus bureau website into had inhabited whitman rules [SEP] nadia slopes equal understands one understood [SEP] tiny soils blogs attacks of his romance gastropod lives understand the refrigerator inches district of municipality salt hour [SEP]']
[1050/2000] tot_loss=3.187 (perp=12.196, rec=0.458, cos=0.290), tot_loss_proj:4.231 [t=0.23s]
prediction: ['[CLS] of experts verity challengedwei [SEP] nothing speaks the stimulus bureau website into had inhabited whitman rules [SEP] nadia slopes equal understands one understood [SEP] tiny soils blogs attacks of his romance gastropod lives understand the refrigerator inches district of municipality salt hour [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.272 (perp=12.386, rec=0.453, cos=0.342), tot_loss_proj:4.245 [t=0.24s]
prediction: ['[CLS] [MASK] experts verity challenged one [SEP] nothing speaks the stimulus bureau website into had inhabited whitman rules [SEP] nadia slopes equal understandswei understood [SEP] tiny soils blogs attacks of his romance gastropod lives understand the refrigerator inches lands of municipality salt hour [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=3.191 (perp=12.265, rec=0.468, cos=0.271), tot_loss_proj:4.251 [t=0.24s]
prediction: ['[CLS] [MASK] experts verity one [SEP] nothing speaks the stimulus bureau website into john had inhabited whitman rules [SEP]zziness slopes equal understandswei understood [SEP] tiny soils blogs attacks of his romance gastropod lives understand the housemates inches lands of weekend salt hour [SEP]']
[1200/2000] tot_loss=3.243 (perp=12.451, rec=0.449, cos=0.304), tot_loss_proj:4.334 [t=0.23s]
prediction: ['[CLS] [MASK] experts verity one [SEP] nothing speaks the lady bureau website into john had inhabited whitman rules [SEP]zziness slopes equal understandswei understood [SEP] tiny soils blogs attacks of the romance gastropod lives understand the housemates inches lands of weekend salt hour [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.151 (perp=11.937, rec=0.449, cos=0.315), tot_loss_proj:4.275 [t=0.23s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing speaks the lady bureau website into john had softball whitman rules [SEP]zziness animals equal understandswei understood [MASK] tiny soils blogs attacks of the wonderful gastropod lives understand the housemates inches lands of weekend salt hour [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.085 (perp=11.642, rec=0.447, cos=0.310), tot_loss_proj:4.220 [t=0.23s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing speaks the lady inches website into john had softball whitman rules [SEP]zziness animals equal understandswei understood [MASK] tiny soils blogs attacks of the wonderful gastropod lives understand the housemates bureau lands of weekend salt hour [SEP]']
[1350/2000] tot_loss=3.144 (perp=11.859, rec=0.441, cos=0.331), tot_loss_proj:4.249 [t=0.24s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing okay the lady inches website into john had softball whitman rules [SEP]zziness animals equal understandswei understood [MASK] tiny soils blogs attacks of the wonderful gastropod lives understand the housemates bureau lands of weekend salt hour [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=3.093 (perp=11.615, rec=0.441, cos=0.329), tot_loss_proj:4.197 [t=0.24s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing okay the lady inches website into john understands softball whitman rules [SEP]zziness animals equal hadwei understood [MASK] tiny soils blogs attacks of the wonderful gastropod lives understand the housemates bureau lands of weekend salt hour [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.958 (perp=11.253, rec=0.443, cos=0.264), tot_loss_proj:4.107 [t=0.23s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing okay the lady inches website into john understands softball whitman rules [SEP]zziness animals equal hadwei understood [MASK] tiny soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands hour [SEP]']
[1500/2000] tot_loss=3.008 (perp=11.104, rec=0.440, cos=0.347), tot_loss_proj:4.116 [t=0.24s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing okay the lady inches website into john understands softball whitman rules [SEP]zziness animals equal hadwei understood [MASK] tiny soils blogs and of the wonderful gastropod lives understand the housemates bureau salt of summer lands hour [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.952 (perp=11.098, rec=0.438, cos=0.294), tot_loss_proj:4.057 [t=0.24s]
prediction: ['[CLS] [SEP] models verity one [SEP] nothing okay the lady inches hour into john understands softball whitman rules [SEP]zziness animals equal hadwei understood [MASK] tiny soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.909 (perp=11.057, rec=0.441, cos=0.257), tot_loss_proj:4.026 [t=0.24s]
prediction: ['[CLS] [SEP] models understood one [SEP] nothing okay the lady inches hour into john understands softball whitman rules [SEP]zziness animals equal hadwei verity [MASK] tiny soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
[1650/2000] tot_loss=2.880 (perp=11.057, rec=0.435, cos=0.233), tot_loss_proj:4.022 [t=0.24s]
prediction: ['[CLS] [SEP] models understood one [SEP] nothing okay the lady inches hour into john understands softball whitman rules [SEP]zziness animals equal hadwei verity [MASK] tiny soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.843 (perp=10.817, rec=0.434, cos=0.245), tot_loss_proj:3.959 [t=0.24s]
prediction: ['[CLS] [SEP] models understood one [SEP] nothing okay the lady inches hour into john understands softball whitman rules [SEP]zziness animals had equalwei verity [MASK] tiny soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.806 (perp=10.566, rec=0.436, cos=0.257), tot_loss_proj:3.916 [t=0.23s]
prediction: ['[CLS] [SEP] models one [SEP] nothing understood okay the lady inches hour into john understands softball whitman rules [SEP]zziness animals had equalwei verity [MASK] morning soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
[1800/2000] tot_loss=2.789 (perp=10.573, rec=0.437, cos=0.238), tot_loss_proj:3.931 [t=0.24s]
prediction: ['[CLS] [SEP] understand one [SEP] nothing understood okay the lady inches hour into john understands softball whitman rules [SEP]zziness animals had equal lodging verity [MASK] morning soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.791 (perp=10.520, rec=0.431, cos=0.256), tot_loss_proj:3.973 [t=0.23s]
prediction: ['[CLS] [SEP] models one [SEP] hour understood okay the lady inches nothing into john understands softball whitman rules [SEP]zziness animals had equal lodging verity [MASK] morning soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.795 (perp=10.525, rec=0.430, cos=0.259), tot_loss_proj:3.981 [t=0.23s]
prediction: ['[CLS] [SEP] models [SEP] one hour understood okay the lady inches nothing into john understands gamer whitman rules [SEP]zziness animals had equal lodging verity [MASK] morning soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
[1950/2000] tot_loss=2.793 (perp=10.525, rec=0.429, cos=0.259), tot_loss_proj:3.982 [t=0.24s]
prediction: ['[CLS] [SEP] models [SEP] one hour understood okay the lady inches nothing into john understands gamer whitman rules [SEP]zziness animals had equal lodging verity [MASK] morning soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.771 (perp=10.365, rec=0.431, cos=0.267), tot_loss_proj:3.956 [t=0.24s]
prediction: ['[CLS] [SEP] models [SEP] one hour understood okay the lady whitman inches nothing into john understands softball rules [SEP]zziness animals had equal lodging verity [MASK] tiny soils blogs and of the understands gastropod lives understand the housemates bureau salt of summer lands website [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] we understands frederick our recruitment is emotional couch collins. the the repeatedly argentine rules stefan our ruined sensation crossed public understands how understands joy sees thanking discrimination. old of ow crazy we understand sweetssion william know joy fireworks connection facing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 27.500 | p: 26.190 | r: 28.947
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 17.500 | p: 16.667 | r: 18.421
rougeLsum  | fm: 17.500 | p: 16.667 | r: 18.421
r1fm+r2fm = 27.500

[Aggregate metrics]:
rouge1     | fm: 86.815 | p: 85.900 | r: 87.964
rouge2     | fm: 54.022 | p: 53.641 | r: 54.486
rougeL     | fm: 76.171 | p: 75.414 | r: 77.084
rougeLsum  | fm: 76.099 | p: 75.330 | r: 76.988
r1fm+r2fm = 140.838

input #88 time: 0:09:14 | total time: 13:23:03


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.8769727666634118
highest_index [0]
highest [0.8769727666634118]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9166818857192993 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.907081127166748 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.9054931402206421 for ['[CLS] intended contract are fate ny journalism gravel chin tyler ceremony mode bog window mm playingfighter colt cloth statistics tracked gravity tripleng china metacritic like skye neighborhood fountain elevenft healthy [SEP]']
[Init] best rec loss: 0.8888074159622192 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8785948753356934 for ['[CLS] back highsred reich deputy short engaged clappeddrop entire welcome rang hey israelilockqua tissue faith played suspected reduce exception macdonald links other need6 learningbody vicar over catholic [SEP]']
[Init] best rec loss: 0.8458151817321777 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8440582752227783 for ['[CLS]kell belaρ brodie alderman j breath v firedried pop series littleizing guggenheim ran my relationvating dreams joggediving [SEP] dr... russell around state can roth braden four [SEP]']
[Init] best rec loss: 0.8373841643333435 for ['[CLS] regime * des islander out settle press dai banana condemned artillery wrong pounded in holmes lower inspiration won permanent mounted starting twitter question turned football faithful super mass where lookingdom fellow [SEP]']
[Init] best rec loss: 0.8297647833824158 for ['[CLS] isabella organ mama lyndon conspiracy leader aquatic oliviagul exhibit energy making wake mineə sub duct tournament ( parent sell carpet gradient goose covenant retrievedover even each uncle republic range [SEP]']
[Init] best perm rec loss: 0.8296209573745728 for ['[CLS] carpet duct retrieved gradient energy organ mama eachover aquatic leader exhibitgul ( isabellaə olivia mine even goose conspiracy sub range uncle making covenant republic wake tournament sell parent lyndon [SEP]']
[Init] best perm rec loss: 0.8288018107414246 for ['[CLS] olivia aquatic parent carpet covenant exhibit mama mine leader conspiracy making gradient wake lyndon duct gooseover uncle range retrievedgul republic energy ( isabella evenə each tournament sub organ sell [SEP]']
[Init] best perm rec loss: 0.8288010954856873 for ['[CLS] sub wake olivia lyndonə isabella gradient goose organ conspiracy even (gul mama tournament parent duct eachover aquatic making republic leader retrieved exhibit covenant range mine sell carpet uncle energy [SEP]']
[Init] best perm rec loss: 0.8284770846366882 for ['[CLS] each tournament carpet ( retrieved lyndon exhibit energy uncle making sub aquatic isabella organ leader gradient goose olivia range even sell duct parent wakegul mamaə conspiracy covenant mineover republic [SEP]']
[Init] best perm rec loss: 0.8277155756950378 for ['[CLS] parentover conspiracy mine uncle making mama goose tournamentə republic aquatic lyndon covenant isabella gradient duct energy retrieved olivia range ( organ sub leader carpet each wake even sellgul exhibit [SEP]']
[Init] best perm rec loss: 0.8274106979370117 for ['[CLS] sub goose each gradient making organ uncle isabella parent aquatic tournamentover lyndon republic conspiracyə retrieved (gul energy mine leader olivia covenant even exhibit wake duct carpet range sell mama [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.880 (perp=11.618, rec=0.334, cos=0.223), tot_loss_proj:3.597 [t=0.23s]
prediction: ['[CLS] tactic mindsched setting gray tactic ball off immediately data valkyrie on disk or news ] had ( draft currently, information exploit political damagedgyhaus fun der to thoughts not [SEP]']
[ 100/2000] tot_loss=2.805 (perp=11.454, rec=0.305, cos=0.209), tot_loss_proj:3.535 [t=0.23s]
prediction: ["[CLS] tactic headsched covering domenico tactic see the extremely enoughd to something kanye news'had, worse sooner - products in development likelyllice... crazy cold title engineering [SEP]"]
[ 150/2000] tot_loss=2.661 (perp=10.930, rec=0.248, cos=0.227), tot_loss_proj:3.230 [t=0.23s]
prediction: ['[CLS] tactic heads as cover dim tactic see the extremely generatedd cover - brandon news - has, worse worse - exclusive ; founded existing worse worse... picture cold title ideas [SEP]']
[ 200/2000] tot_loss=2.681 (perp=11.100, rec=0.255, cos=0.206), tot_loss_proj:3.264 [t=0.23s]
prediction: ['[CLS] tactic minds to cover‖ tactic paper fact very generatedd cover ‖tangle ideas ] has, worse worsedo origin - research " worse worse... scrambled cold title ideas [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.472 (perp=10.069, rec=0.238, cos=0.220), tot_loss_proj:2.988 [t=0.24s]
prediction: ['[CLS] tactic minds to coverted tactic a fact very - has generatedd cover - fact ideas - worse worsedo or - developed "zzled worse... artificial cold title ideas [SEP]']
[ 300/2000] tot_loss=2.585 (perp=10.678, rec=0.232, cos=0.218), tot_loss_proj:3.131 [t=0.23s]
prediction: ['[CLS] tactic minds to coverted tactic a fact very. has generatedd cover -sy picture - worse worsedo about - started...ive worse... artificial cold title ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.369 (perp=9.670, rec=0.206, cos=0.229), tot_loss_proj:2.916 [t=0.23s]
prediction: ['[CLS] tactic importance to cover cold tactic a fact very. is generatedd cover -sy picture - worse worsedo about - made other yet worse - autoted art ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.603 (perp=10.033, rec=0.373, cos=0.224), tot_loss_proj:2.997 [t=0.24s]
prediction: ['[CLS] tactic scans to cover half tactic the fact appearance. is composedn up the ර picture - worse lot about fl maintained recently -ish seven worse - picture ideas [SEP]']
[ 450/2000] tot_loss=2.564 (perp=10.137, rec=0.320, cos=0.216), tot_loss_proj:3.122 [t=0.23s]
prediction: ['[CLS] tactic resolution to cover half tactic the fact fares his is composedn up the – image - worse lo re about fl tested hotels -ish seven worse - the ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.479 (perp=9.895, rec=0.273, cos=0.227), tot_loss_proj:2.936 [t=0.23s]
prediction: ['[CLS]tya resolution to cover half tactic the fact allegedly politics is composedn up the tactic image - worse too re about fl tested hotels - yet seven worse - picture ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.438 (perp=9.792, rec=0.255, cos=0.225), tot_loss_proj:2.937 [t=0.24s]
prediction: ['[CLS]tya resolution to cover half tactic the fact allegedly tested is composedn up the tactic image - worse too st about fl und stale - yet seven worse - picture ideas [SEP]']
[ 600/2000] tot_loss=2.529 (perp=10.359, rec=0.234, cos=0.223), tot_loss_proj:3.075 [t=0.23s]
prediction: ['[CLS]tya resolution to cover half tactic the fact created tested is composedn up the tactic image - worse too re about fl und recently -ish seven worse - picture ideas [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.462 (perp=10.038, rec=0.233, cos=0.222), tot_loss_proj:3.054 [t=0.23s]
prediction: ['[CLS]tya resolution to cover half tactic the fact created tested is composedn up the tactic image - - too re been fl picture recently worse yet seven worse - picture ideas [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.409 (perp=9.767, rec=0.226, cos=0.229), tot_loss_proj:3.001 [t=0.24s]
prediction: ['[CLS]tya resolution to cover half tactic the fact created tested is composed - up the tactic image - - too re been fl picture recently worse yet seven worsen picture ideas [SEP]']
[ 750/2000] tot_loss=2.521 (perp=10.422, rec=0.216, cos=0.220), tot_loss_proj:3.099 [t=0.23s]
prediction: ['[CLS]ples resolution to cover supposed tactic the fact created tested is composed -cap the tactic image - - too st been fl picture recently worseish seven worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.478 (perp=10.224, rec=0.209, cos=0.224), tot_loss_proj:3.061 [t=0.23s]
prediction: ['[CLS]ples tactic to cover supposed tactic the fact created tested is composed -cap the resolution image - - too re been fl und recently worseish seven worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.408 (perp=9.829, rec=0.216, cos=0.226), tot_loss_proj:2.975 [t=0.23s]
prediction: ['[CLS]ples tactic to cover supposed tactic the fact created tested is composed -foot the resolution - - - too re been flish recently worse und seven worsen picture ideas [SEP]']
[ 900/2000] tot_loss=2.428 (perp=9.964, rec=0.210, cos=0.225), tot_loss_proj:3.043 [t=0.23s]
prediction: ['[CLS]ples tactic to cover muttered tactic the fact created tested is composed -foot the resolution sort - - too st been flish recently worse und seven worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.450 (perp=10.027, rec=0.216, cos=0.229), tot_loss_proj:3.067 [t=0.24s]
prediction: ['[CLS] tested tactic to cover muttered tactic the fact createdples is composed -foot the resolution sort - - too re been flish recently worse und seven worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.411 (perp=9.899, rec=0.203, cos=0.229), tot_loss_proj:3.033 [t=0.23s]
prediction: ['[CLS] tested tactic to cover muttered tactic the fact createdples is composed worsefoot the resolution sort - - too re been orish damaged - und seven worsen picture ideas [SEP]']
[1050/2000] tot_loss=2.391 (perp=9.789, rec=0.204, cos=0.229), tot_loss_proj:2.993 [t=0.23s]
prediction: ['[CLS] tested tactic to cover muttered tactic the fact createdples is composed worseim the resolution sort - - too re been orish damaged - und seven worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.368 (perp=9.699, rec=0.202, cos=0.227), tot_loss_proj:2.949 [t=0.23s]
prediction: ['[CLS] tested tactic to cover muttered tactic the fact createdples is composed worseim the resolution sort - - too re been sevenish damaged - und or worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.458 (perp=10.140, rec=0.209, cos=0.222), tot_loss_proj:3.011 [t=0.23s]
prediction: ['[CLS] playoffs tactic to cover muttered tactic the fact sortples constructed composed worseim the resolution created -, too re been sevenish damaged - und or worsen picture ideas [SEP]']
[1200/2000] tot_loss=2.505 (perp=10.359, rec=0.206, cos=0.227), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] playoffs tactic to cover muttered tactic the fact sortples constructed composed worseim the resolution worse -, too re been sevenish damaged - und or worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.432 (perp=10.043, rec=0.194, cos=0.229), tot_loss_proj:3.039 [t=0.24s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed composed worseim the resolution worse - playoffs too re been sevenish damaged - perhaps or worsen picture ideas [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.405 (perp=9.873, rec=0.202, cos=0.228), tot_loss_proj:3.004 [t=0.23s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed composed worseim the resolution - playoffs too re been sevenish damaged - worse perhaps or worsen picture ideas [SEP]']
[1350/2000] tot_loss=2.417 (perp=9.929, rec=0.201, cos=0.230), tot_loss_proj:3.025 [t=0.23s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worseim the resolution - playoffs too re been sevenish damaged - worse perhaps or worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.398 (perp=9.847, rec=0.201, cos=0.228), tot_loss_proj:3.016 [t=0.24s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worseim the resolution - seven too re been playoffsish damaged - worse perhaps or worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.367 (perp=9.696, rec=0.198, cos=0.229), tot_loss_proj:2.976 [t=0.23s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worseim the resolution - seven too re been playoffsish damaged - or perhaps worse worsen picture ideas [SEP]']
[1500/2000] tot_loss=2.359 (perp=9.696, rec=0.191, cos=0.229), tot_loss_proj:2.977 [t=0.23s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worseim the resolution - seven too re been playoffsish damaged - or perhaps worse worsen picture ideas [SEP]']
Attempt swap
[1550/2000] tot_loss=2.359 (perp=9.696, rec=0.191, cos=0.228), tot_loss_proj:2.977 [t=0.23s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worseim the resolution - seven too re been playoffsish damaged - or perhaps worse worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.287 (perp=9.312, rec=0.197, cos=0.228), tot_loss_proj:2.839 [t=0.24s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worse been the resolution - seven too reim playoffsish damaged - or perhaps worse worsen picture ideas [SEP]']
[1650/2000] tot_loss=2.368 (perp=9.720, rec=0.196, cos=0.228), tot_loss_proj:2.966 [t=0.24s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worse been the resolution - seven too reim playoffsish damaged - or 978 worse worsen picture ideas [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.348 (perp=9.608, rec=0.198, cos=0.228), tot_loss_proj:2.938 [t=0.23s]
prediction: ['[CLS], tactic to cover muttered tactic the fact sortples constructed constructed worse been the resolution - seven too reim playoffs damaged - or 978 worseish worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.318 (perp=9.478, rec=0.194, cos=0.229), tot_loss_proj:2.956 [t=0.23s]
prediction: ['[CLS] worse tactic to cover muttered tactic the fact sortples constructed constructed, been the resolution - seven too reim playoffs damaged - or 978 worseish worsen picture ideas [SEP]']
[1800/2000] tot_loss=2.313 (perp=9.478, rec=0.189, cos=0.229), tot_loss_proj:2.958 [t=0.23s]
prediction: ['[CLS] worse tactic to cover muttered tactic the fact sortples constructed constructed, been the resolution - seven too reim playoffs damaged - or 978 worseish worsen picture ideas [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.296 (perp=9.371, rec=0.194, cos=0.228), tot_loss_proj:2.946 [t=0.23s]
prediction: ['[CLS] worse tactic to cover muttered tactic the fact sortples constructed constructed, been the resolution - seven too reim playoffs damaged - or 978 worsen worseish picture ideas [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.270 (perp=9.214, rec=0.198, cos=0.229), tot_loss_proj:2.900 [t=0.23s]
prediction: ['[CLS] the tactic to covermost tactic the fact sortples constructed constructed, " worse resolution - seven too reim playoffs damaged - or 978 worsen worseish picture ideas [SEP]']
[1950/2000] tot_loss=2.268 (perp=9.214, rec=0.196, cos=0.229), tot_loss_proj:2.898 [t=0.23s]
prediction: ['[CLS] the tactic to covermost tactic the fact sortples constructed constructed, " worse resolution - seven too reim playoffs damaged - or 978 worsen worseish picture ideas [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.281 (perp=9.299, rec=0.192, cos=0.229), tot_loss_proj:2.929 [t=0.23s]
prediction: ['[CLS] the tactic to cover too tactic the fact sortples constructed constructed, " worse resolution - sevenmost stim playoffs damaged - or 978 worsen worseish picture ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] the tactic to cover too tactic the fact sortples constructed constructed, " worse resolution - sevenmost stim playoffs damaged - or 978 worsen worseish picture ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.167 | p: 52.000 | r: 56.522
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 41.667 | p: 40.000 | r: 43.478
rougeLsum  | fm: 41.667 | p: 40.000 | r: 43.478
r1fm+r2fm = 71.558

[Aggregate metrics]:
rouge1     | fm: 86.552 | p: 85.570 | r: 87.679
rouge2     | fm: 53.746 | p: 53.364 | r: 54.206
rougeL     | fm: 75.641 | p: 74.875 | r: 76.619
rougeLsum  | fm: 75.687 | p: 74.913 | r: 76.590
r1fm+r2fm = 140.298

input #89 time: 0:09:13 | total time: 13:32:16


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.8859323676094488
highest_index [0]
highest [0.8859323676094488]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8989258408546448 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8960291743278503 for ['[CLS] region prefecture about hundred miller bravery [SEP]']
[Init] best rec loss: 0.8459963202476501 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8111385703086853 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8090829849243164 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8055201768875122 for ['[CLS] released male cannot spirited entourage when [SEP]']
[Init] best perm rec loss: 0.8041074275970459 for ['[CLS] when male released entourage spirited cannot [SEP]']
[Init] best perm rec loss: 0.8015682101249695 for ['[CLS] when released male spirited cannot entourage [SEP]']
[Init] best perm rec loss: 0.8012628555297852 for ['[CLS] male spirited cannot entourage released when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.571 (perp=10.540, rec=0.261, cos=0.202), tot_loss_proj:3.096 [t=0.23s]
prediction: ['[CLS] how how and fraud ridiculous $ [SEP]']
[ 100/2000] tot_loss=2.373 (perp=9.949, rec=0.174, cos=0.209), tot_loss_proj:2.983 [t=0.23s]
prediction: ['[CLS] how how and money ridiculous $ [SEP]']
[ 150/2000] tot_loss=2.343 (perp=9.949, rec=0.142, cos=0.211), tot_loss_proj:2.973 [t=0.23s]
prediction: ['[CLS] how how and money ridiculous $ [SEP]']
[ 200/2000] tot_loss=2.262 (perp=9.641, rec=0.123, cos=0.211), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] how how and money ridiculous oriented [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.729 (perp=6.936, rec=0.133, cos=0.208), tot_loss_proj:1.813 [t=0.23s]
prediction: ['[CLS] how how ridiculous and money oriented [SEP]']
[ 300/2000] tot_loss=2.011 (perp=8.522, rec=0.094, cos=0.212), tot_loss_proj:2.547 [t=0.23s]
prediction: ['[CLS] how derived ridiculous and money oriented [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.963 (perp=8.200, rec=0.107, cos=0.216), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] how ridiculous derived and money oriented [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.813 (perp=7.594, rec=0.083, cos=0.211), tot_loss_proj:1.993 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented nuts [SEP]']
[ 450/2000] tot_loss=1.820 (perp=7.594, rec=0.091, cos=0.210), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented nuts [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.817 (perp=7.594, rec=0.084, cos=0.214), tot_loss_proj:1.990 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented nuts [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.663 (perp=6.870, rec=0.077, cos=0.212), tot_loss_proj:1.837 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.674 (perp=6.870, rec=0.087, cos=0.213), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.654 (perp=6.870, rec=0.067, cos=0.213), tot_loss_proj:1.838 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=6.870, rec=0.089, cos=0.216), tot_loss_proj:1.836 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.672 (perp=6.870, rec=0.085, cos=0.213), tot_loss_proj:1.839 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.658 (perp=6.870, rec=0.070, cos=0.213), tot_loss_proj:1.838 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.653 (perp=6.870, rec=0.065, cos=0.214), tot_loss_proj:1.842 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.665 (perp=6.870, rec=0.078, cos=0.213), tot_loss_proj:1.841 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.662 (perp=6.870, rec=0.074, cos=0.214), tot_loss_proj:1.837 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.660 (perp=6.870, rec=0.072, cos=0.214), tot_loss_proj:1.848 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.669 (perp=6.870, rec=0.081, cos=0.215), tot_loss_proj:1.849 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.654 (perp=6.870, rec=0.066, cos=0.214), tot_loss_proj:1.846 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.648 (perp=6.870, rec=0.060, cos=0.214), tot_loss_proj:1.844 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.647 (perp=6.870, rec=0.058, cos=0.214), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.660 (perp=6.870, rec=0.072, cos=0.214), tot_loss_proj:1.850 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.660 (perp=6.870, rec=0.072, cos=0.214), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.652 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.652 (perp=6.870, rec=0.064, cos=0.214), tot_loss_proj:1.847 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.656 (perp=6.870, rec=0.068, cos=0.214), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.649 (perp=6.870, rec=0.060, cos=0.214), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.667 (perp=6.870, rec=0.079, cos=0.214), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.664 (perp=6.870, rec=0.075, cos=0.214), tot_loss_proj:1.839 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.652 (perp=6.870, rec=0.064, cos=0.214), tot_loss_proj:1.838 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.656 (perp=6.870, rec=0.068, cos=0.214), tot_loss_proj:1.849 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.651 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.650 (perp=6.870, rec=0.062, cos=0.214), tot_loss_proj:1.843 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.651 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.653 (perp=6.870, rec=0.065, cos=0.214), tot_loss_proj:1.846 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.664 (perp=6.870, rec=0.076, cos=0.214), tot_loss_proj:1.845 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.678 | p: 85.745 | r: 87.820
rouge2     | fm: 54.165 | p: 53.785 | r: 54.629
rougeL     | fm: 75.879 | p: 75.135 | r: 76.844
rougeLsum  | fm: 76.025 | p: 75.259 | r: 76.920
r1fm+r2fm = 140.843

input #90 time: 0:09:02 | total time: 13:41:19


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9027383705024011
highest_index [0]
highest [0.9027383705024011]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.7961481213569641 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7949368953704834 for ['[CLS]underscribe canton below messenger speaking been does [SEP]']
[Init] best rec loss: 0.7532783150672913 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7486745119094849 for ['[CLS] lynn through father viva black forgiveness stab around [SEP]']
[Init] best rec loss: 0.7314306497573853 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.6874892115592957 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6864751577377319 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6760411858558655 for ['[CLS] neal african milne architecture joint rolls conductline [SEP]']
[Init] best rec loss: 0.6605625748634338 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6584671139717102 for ['[CLS] one addict remindericide anywayheredislauslish [SEP]']
[Init] best perm rec loss: 0.6567610502243042 for ['[CLS]lish anyway addict one remindericideislaushered [SEP]']
[Init] best perm rec loss: 0.6564019918441772 for ['[CLS] onelishicide addictheredislaus reminder anyway [SEP]']
[Init] best perm rec loss: 0.6527097225189209 for ['[CLS] onehered reminder addictislauslishicide anyway [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.077 (perp=12.805, rec=0.353, cos=0.163), tot_loss_proj:3.758 [t=0.22s]
prediction: ['[CLS] loco y ridiculous ridiculous ears sick slot... [SEP]']
[ 100/2000] tot_loss=2.913 (perp=12.683, rec=0.208, cos=0.168), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] loco loco ridiculous ridiculous more more slot but [SEP]']
[ 150/2000] tot_loss=2.443 (perp=10.645, rec=0.133, cos=0.181), tot_loss_proj:3.047 [t=0.22s]
prediction: ['[CLS] loco mu ridiculous no more morey but [SEP]']
[ 200/2000] tot_loss=2.407 (perp=10.645, rec=0.097, cos=0.180), tot_loss_proj:3.044 [t=0.22s]
prediction: ['[CLS] loco mu ridiculous no more morey but [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.050 (perp=8.694, rec=0.133, cos=0.178), tot_loss_proj:2.482 [t=0.22s]
prediction: ['[CLS] morey loco mu ridiculous no more but [SEP]']
[ 300/2000] tot_loss=2.001 (perp=8.694, rec=0.078, cos=0.184), tot_loss_proj:2.477 [t=0.22s]
prediction: ['[CLS] morey loco mu ridiculous no more but [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.002 (perp=8.694, rec=0.082, cos=0.181), tot_loss_proj:2.463 [t=0.22s]
prediction: ['[CLS] morey loco mu ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.939 (perp=8.414, rec=0.081, cos=0.176), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] muy loco more ridiculous no more but [SEP]']
[ 450/2000] tot_loss=1.940 (perp=8.414, rec=0.072, cos=0.185), tot_loss_proj:2.247 [t=0.22s]
prediction: ['[CLS] muy loco more ridiculous no more but [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.940 (perp=8.414, rec=0.074, cos=0.183), tot_loss_proj:2.242 [t=0.22s]
prediction: ['[CLS] muy loco more ridiculous no more but [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.065 (perp=9.138, rec=0.065, cos=0.173), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] muy loco no ridiculous no more but [SEP]']
[ 600/2000] tot_loss=1.876 (perp=8.108, rec=0.070, cos=0.184), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] muy loco, ridiculous no more but [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.747 (perp=7.488, rec=0.072, cos=0.177), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.739 (perp=7.488, rec=0.061, cos=0.181), tot_loss_proj:1.782 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.728 (perp=7.488, rec=0.049, cos=0.182), tot_loss_proj:1.776 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.744 (perp=7.488, rec=0.064, cos=0.183), tot_loss_proj:1.779 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.735 (perp=7.488, rec=0.054, cos=0.183), tot_loss_proj:1.776 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.739 (perp=7.488, rec=0.058, cos=0.183), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.745 (perp=7.488, rec=0.064, cos=0.183), tot_loss_proj:1.772 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.751 (perp=7.488, rec=0.070, cos=0.183), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.727 (perp=7.488, rec=0.046, cos=0.184), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.745 (perp=7.488, rec=0.063, cos=0.184), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=7.488, rec=0.063, cos=0.184), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.745 (perp=7.488, rec=0.063, cos=0.184), tot_loss_proj:1.778 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.746 (perp=7.488, rec=0.064, cos=0.184), tot_loss_proj:1.777 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.734 (perp=7.488, rec=0.052, cos=0.184), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.741 (perp=7.488, rec=0.059, cos=0.184), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.727 (perp=7.488, rec=0.045, cos=0.184), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.746 (perp=7.488, rec=0.064, cos=0.184), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.742 (perp=7.488, rec=0.060, cos=0.184), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=7.488, rec=0.066, cos=0.184), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.745 (perp=7.488, rec=0.063, cos=0.184), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.746 (perp=7.488, rec=0.064, cos=0.184), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.743 (perp=7.488, rec=0.061, cos=0.184), tot_loss_proj:1.772 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.752 (perp=7.488, rec=0.070, cos=0.184), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.748 (perp=7.488, rec=0.066, cos=0.184), tot_loss_proj:1.776 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.743 (perp=7.488, rec=0.061, cos=0.184), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.729 (perp=7.488, rec=0.047, cos=0.184), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.742 (perp=7.488, rec=0.060, cos=0.184), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.741 (perp=7.488, rec=0.059, cos=0.185), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.796 | p: 85.893 | r: 87.915
rouge2     | fm: 54.736 | p: 54.380 | r: 55.217
rougeL     | fm: 76.216 | p: 75.499 | r: 77.136
rougeLsum  | fm: 76.185 | p: 75.367 | r: 77.114
r1fm+r2fm = 141.532

input #91 time: 0:08:44 | total time: 13:50:03


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.8514846544809684
highest_index [0]
highest [0.8514846544809684]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8217656016349792 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8217141032218933 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.7769816517829895 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7696342468261719 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7689929604530334 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7379249334335327 for ['[CLS] tank lonely [SEP]']
[Init] best rec loss: 0.6997861266136169 for ['[CLS] paths locked [SEP]']
[Init] best perm rec loss: 0.6967146396636963 for ['[CLS] locked paths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.975 (perp=7.647, rec=0.181, cos=0.265), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=1.877 (perp=7.647, rec=0.079, cos=0.268), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.875 (perp=7.647, rec=0.073, cos=0.273), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.865 (perp=7.647, rec=0.061, cos=0.274), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.879 (perp=7.647, rec=0.076, cos=0.274), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.860 (perp=7.647, rec=0.057, cos=0.274), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.838 (perp=7.647, rec=0.040, cos=0.269), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.872 (perp=7.647, rec=0.068, cos=0.275), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.871 (perp=7.647, rec=0.068, cos=0.274), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.854 (perp=7.647, rec=0.058, cos=0.266), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.879 (perp=7.647, rec=0.075, cos=0.275), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.873 (perp=7.647, rec=0.069, cos=0.274), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.860 (perp=7.647, rec=0.057, cos=0.275), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.872 (perp=7.647, rec=0.069, cos=0.274), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.858 (perp=7.647, rec=0.053, cos=0.275), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.864 (perp=7.647, rec=0.062, cos=0.273), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.869 (perp=7.647, rec=0.065, cos=0.274), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.859 (perp=7.647, rec=0.054, cos=0.275), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.858 (perp=7.647, rec=0.059, cos=0.270), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.851 (perp=7.647, rec=0.048, cos=0.274), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.865 (perp=7.647, rec=0.061, cos=0.275), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.876 (perp=7.647, rec=0.071, cos=0.275), tot_loss_proj:1.882 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.870 (perp=7.647, rec=0.067, cos=0.274), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.856 (perp=7.647, rec=0.052, cos=0.274), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.861 (perp=7.647, rec=0.057, cos=0.275), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.868 (perp=7.647, rec=0.064, cos=0.275), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.859 (perp=7.647, rec=0.055, cos=0.275), tot_loss_proj:1.868 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.871 (perp=7.647, rec=0.066, cos=0.275), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.844 (perp=7.647, rec=0.040, cos=0.275), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.840 (perp=7.647, rec=0.035, cos=0.275), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.863 (perp=7.647, rec=0.061, cos=0.272), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.872 (perp=7.647, rec=0.068, cos=0.274), tot_loss_proj:1.871 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.867 (perp=7.647, rec=0.063, cos=0.275), tot_loss_proj:1.857 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.864 (perp=7.647, rec=0.060, cos=0.275), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.856 (perp=7.647, rec=0.052, cos=0.275), tot_loss_proj:1.867 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.865 (perp=7.647, rec=0.061, cos=0.275), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.859 (perp=7.647, rec=0.055, cos=0.275), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.863 (perp=7.647, rec=0.059, cos=0.275), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.852 (perp=7.647, rec=0.048, cos=0.275), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.863 (perp=7.647, rec=0.058, cos=0.275), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.930 | p: 86.062 | r: 88.039
rouge2     | fm: 55.049 | p: 54.711 | r: 55.480
rougeL     | fm: 76.421 | p: 75.718 | r: 77.327
rougeLsum  | fm: 76.433 | p: 75.691 | r: 77.329
r1fm+r2fm = 141.979

input #92 time: 0:08:44 | total time: 13:58:48


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.8170377150593839
highest_index [0]
highest [0.8170377150593839]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9388556480407715 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8846307396888733 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.8673256635665894 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 0.8636058568954468 for ['[CLS] thousands fuel conditional scales progressed empowered mar [SEP]']
[Init] best rec loss: 0.8526772260665894 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 0.8473193645477295 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 0.8460219502449036 for ['[CLS] madonna premiership jeremy further colby [CLS]rac [SEP]']
[Init] best perm rec loss: 0.8455647826194763 for ['[CLS] further madonna colby premiership jeremyrac [CLS] [SEP]']
[Init] best perm rec loss: 0.8441386818885803 for ['[CLS] jeremyrac colby premiership further [CLS] madonna [SEP]']
[Init] best perm rec loss: 0.844131588935852 for ['[CLS] colbyrac madonna [CLS] premiership jeremy further [SEP]']
[Init] best perm rec loss: 0.8435031175613403 for ['[CLS] colby jeremy furtherrac premiership [CLS] madonna [SEP]']
[Init] best perm rec loss: 0.842919647693634 for ['[CLS]rac jeremy colby madonna further premiership [CLS] [SEP]']
[Init] best perm rec loss: 0.8423647284507751 for ['[CLS]rac madonna further [CLS] jeremy premiership colby [SEP]']
[Init] best perm rec loss: 0.8391352891921997 for ['[CLS] madonna jeremyrac premiership colby further [CLS] [SEP]']
[Init] best perm rec loss: 0.8388211727142334 for ['[CLS] madonna jeremyrac further premiership colby [CLS] [SEP]']
[Init] best perm rec loss: 0.8384848833084106 for ['[CLS] further madonnarac colby premiership jeremy [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=11.211, rec=0.247, cos=0.327), tot_loss_proj:3.211 [t=0.22s]
prediction: ['[CLS] understanding [SEP] funnyles, recorded way [SEP]']
[ 100/2000] tot_loss=2.417 (perp=9.626, rec=0.168, cos=0.324), tot_loss_proj:2.639 [t=0.22s]
prediction: ['[CLS] understanding in funnyis in funny way [SEP]']
[ 150/2000] tot_loss=2.450 (perp=9.967, rec=0.130, cos=0.327), tot_loss_proj:2.632 [t=0.22s]
prediction: ['[CLS] understanding in funny often its funny way [SEP]']
[ 200/2000] tot_loss=2.442 (perp=10.096, rec=0.093, cos=0.330), tot_loss_proj:2.694 [t=0.22s]
prediction: ['[CLS] understanding in understanding often its funny way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.184 (perp=8.827, rec=0.090, cos=0.328), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] understanding in understanding its often funny way [SEP]']
[ 300/2000] tot_loss=2.171 (perp=8.827, rec=0.075, cos=0.331), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] understanding in understanding its often funny way [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.036 (perp=8.087, rec=0.088, cos=0.331), tot_loss_proj:2.206 [t=0.22s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.033 (perp=8.087, rec=0.085, cos=0.330), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
[ 450/2000] tot_loss=2.022 (perp=8.087, rec=0.072, cos=0.332), tot_loss_proj:2.205 [t=0.22s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.017 (perp=8.087, rec=0.070, cos=0.330), tot_loss_proj:2.211 [t=0.22s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.791 (perp=6.938, rec=0.072, cos=0.331), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 600/2000] tot_loss=1.792 (perp=6.938, rec=0.073, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.740 (perp=6.704, rec=0.069, cos=0.331), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.732 (perp=6.704, rec=0.060, cos=0.332), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 750/2000] tot_loss=1.737 (perp=6.704, rec=0.064, cos=0.332), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.738 (perp=6.704, rec=0.065, cos=0.332), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.747 (perp=6.704, rec=0.074, cos=0.332), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.745 (perp=6.704, rec=0.071, cos=0.332), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=6.704, rec=0.059, cos=0.332), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.741 (perp=6.704, rec=0.068, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.733 (perp=6.704, rec=0.060, cos=0.332), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.738 (perp=6.704, rec=0.065, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.736 (perp=6.704, rec=0.063, cos=0.332), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.733 (perp=6.704, rec=0.060, cos=0.332), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.735 (perp=6.704, rec=0.062, cos=0.332), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.738 (perp=6.704, rec=0.065, cos=0.332), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.728 (perp=6.704, rec=0.055, cos=0.332), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.735 (perp=6.704, rec=0.062, cos=0.332), tot_loss_proj:1.980 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.735 (perp=6.704, rec=0.062, cos=0.332), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.744 (perp=6.704, rec=0.071, cos=0.332), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.731 (perp=6.704, rec=0.058, cos=0.332), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.740 (perp=6.704, rec=0.067, cos=0.332), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.740 (perp=6.704, rec=0.067, cos=0.332), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.745 (perp=6.704, rec=0.072, cos=0.332), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.739 (perp=6.704, rec=0.066, cos=0.332), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.738 (perp=6.704, rec=0.065, cos=0.332), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=6.704, rec=0.063, cos=0.332), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.737 (perp=6.704, rec=0.063, cos=0.332), tot_loss_proj:1.974 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.737 (perp=6.704, rec=0.064, cos=0.332), tot_loss_proj:1.978 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.739 (perp=6.704, rec=0.065, cos=0.332), tot_loss_proj:1.967 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 87.147 | p: 86.263 | r: 88.208
rouge2     | fm: 55.187 | p: 54.879 | r: 55.612
rougeL     | fm: 76.698 | p: 75.937 | r: 77.563
rougeLsum  | fm: 76.561 | p: 75.864 | r: 77.493
r1fm+r2fm = 142.334

input #93 time: 0:08:48 | total time: 14:07:36


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.8576534777353578
highest_index [0]
highest [0.8576534777353578]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9550880789756775 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9542281627655029 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9513195753097534 for ['[CLS] past vices siblings theatrical view slate will shelter ancient border [SEP]']
[Init] best rec loss: 0.9233896136283875 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 0.9182111024856567 for ['[CLS] convicted hunter entire fan wine9 league threat privatek rough [SEP]']
[Init] best rec loss: 0.9091429710388184 for ['[CLS] enough usingac sur mile ready down maymise majesty assumption [SEP]']
[Init] best rec loss: 0.8997244238853455 for ['[CLS] barber eithertype roador motivefirm trusted ednaack wanted [SEP]']
[Init] best perm rec loss: 0.8996092081069946 for ['[CLS] ednaackfirmortype barber road wanted motive trusted either [SEP]']
[Init] best perm rec loss: 0.8976786732673645 for ['[CLS]or road either edna barberfirm trusted motivetype wantedack [SEP]']
[Init] best perm rec loss: 0.8973366618156433 for ['[CLS] motive wantedfirm either barber trusted road ednaackortype [SEP]']
[Init] best perm rec loss: 0.8971049785614014 for ['[CLS] either ednaackfirm wanted motiveortype road barber trusted [SEP]']
[Init] best perm rec loss: 0.8968819379806519 for ['[CLS]or wanted edna roadack barber motivetype trustedfirm either [SEP]']
[Init] best perm rec loss: 0.8968653082847595 for ['[CLS] wanted trustedtype barber motive eitherackfirm roador edna [SEP]']
[Init] best perm rec loss: 0.8959499001502991 for ['[CLS] road trustedtype motiveack barber ednaor wanted eitherfirm [SEP]']
[Init] best perm rec loss: 0.895821750164032 for ['[CLS]typefirm edna roadorack trusted motive barber wanted either [SEP]']
[Init] best perm rec loss: 0.8955407738685608 for ['[CLS] road edna barberack trustedor motive wantedfirm eithertype [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.511 (perp=13.491, rec=0.600, cos=0.213), tot_loss_proj:4.563 [t=0.22s]
prediction: ['[CLS] tomorrow hashher emma father actress never brown open anniversary money [SEP]']
[ 100/2000] tot_loss=3.340 (perp=12.946, rec=0.534, cos=0.217), tot_loss_proj:4.148 [t=0.22s]
prediction: ['[CLS] no original their originally the neither « neither [SEP] inflicted funny [SEP]']
[ 150/2000] tot_loss=3.161 (perp=12.015, rec=0.555, cos=0.203), tot_loss_proj:4.085 [t=0.22s]
prediction: ['[CLS] surprised original every original the version or jeff [SEP]inge sympathy [SEP]']
[ 200/2000] tot_loss=2.934 (perp=11.305, rec=0.501, cos=0.171), tot_loss_proj:4.224 [t=0.22s]
prediction: ['[CLS] surprised original nor original the original or neither [SEP] cape funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.634 (perp=9.838, rec=0.483, cos=0.183), tot_loss_proj:3.488 [t=0.22s]
prediction: ['[CLS] surprised nor original the cape original nor neither nor cape funny [SEP]']
[ 300/2000] tot_loss=3.094 (perp=11.846, rec=0.527, cos=0.198), tot_loss_proj:3.897 [t=0.22s]
prediction: ['[CLS] poems myra awoke its least original nor funny anclusive laugh [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.825 (perp=10.836, rec=0.491, cos=0.168), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] poems nor neither nor awoke cape cape original nor cape funny [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.820 (perp=10.623, rec=0.469, cos=0.227), tot_loss_proj:4.039 [t=0.22s]
prediction: ['[CLS] poems nor neither than cape cape original nor cape funny awoke [SEP]']
[ 450/2000] tot_loss=2.985 (perp=11.114, rec=0.521, cos=0.242), tot_loss_proj:3.972 [t=0.22s]
prediction: ['[CLS] poems nor neither nor cape cape neither nor cape zombiesᴬ [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.861 (perp=11.321, rec=0.459, cos=0.138), tot_loss_proj:3.805 [t=0.22s]
prediction: ['[CLS] nor funny nor cape cape neither nor cape funny poems goodnight [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.449 (perp=8.988, rec=0.455, cos=0.197), tot_loss_proj:3.266 [t=0.22s]
prediction: ['[CLS] nor neither nor cape cape funny nor cape funny poems goodnight [SEP]']
[ 600/2000] tot_loss=2.456 (perp=8.988, rec=0.470, cos=0.189), tot_loss_proj:3.281 [t=0.22s]
prediction: ['[CLS] nor neither nor cape cape funny nor cape funny poems goodnight [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.282 (perp=8.377, rec=0.441, cos=0.165), tot_loss_proj:3.189 [t=0.22s]
prediction: ['[CLS] nor neither cape nor cape funny nor cape funny poems goodnight [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.327 (perp=8.205, rec=0.481, cos=0.204), tot_loss_proj:2.829 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape comics cannot goodnight [SEP]']
[ 750/2000] tot_loss=2.382 (perp=8.959, rec=0.430, cos=0.160), tot_loss_proj:3.101 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape jedi cannot goodnight [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.495 (perp=8.959, rec=0.430, cos=0.273), tot_loss_proj:3.109 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape jedi cannot goodnight [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.223 (perp=8.272, rec=0.426, cos=0.143), tot_loss_proj:2.650 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape goodnight cannot animated [SEP]']
[ 900/2000] tot_loss=2.202 (perp=8.272, rec=0.409, cos=0.139), tot_loss_proj:2.650 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape goodnight cannot animated [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.687 (perp=10.721, rec=0.415, cos=0.128), tot_loss_proj:3.457 [t=0.22s]
prediction: ['[CLS] neither cape nor creatures nor funny nor cape goodnight cannot jedi [SEP]']
Attempt swap
[1000/2000] tot_loss=2.324 (perp=8.272, rec=0.408, cos=0.262), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape goodnight cannot animated [SEP]']
[1050/2000] tot_loss=2.203 (perp=8.272, rec=0.393, cos=0.155), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape goodnight cannot animated [SEP]']
Attempt swap
[1100/2000] tot_loss=2.820 (perp=10.786, rec=0.420, cos=0.243), tot_loss_proj:3.507 [t=0.22s]
prediction: ['[CLS] original cape nor cape nor funny nor cape goodnight cannot animated [SEP]']
Attempt swap
[1150/2000] tot_loss=2.170 (perp=8.272, rec=0.390, cos=0.125), tot_loss_proj:2.652 [t=0.22s]
prediction: ['[CLS] neither cape nor cape nor funny nor cape goodnight cannot animated [SEP]']
[1200/2000] tot_loss=3.131 (perp=12.485, rec=0.381, cos=0.253), tot_loss_proj:3.775 [t=0.22s]
prediction: ['[CLS] original cape nor creatures nor funny nor cape goodnight cannot animated [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.675 (perp=10.761, rec=0.391, cos=0.132), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] original nor cape creatures neither funny nor cape goodnight cannot animated [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.579 (perp=9.866, rec=0.393, cos=0.213), tot_loss_proj:3.201 [t=0.22s]
prediction: ['[CLS] original neither funny nor cape creatures nor cape goodnight cannot animated [SEP]']
[1350/2000] tot_loss=2.573 (perp=9.866, rec=0.389, cos=0.211), tot_loss_proj:3.194 [t=0.22s]
prediction: ['[CLS] original neither funny nor cape creatures nor cape goodnight cannot animated [SEP]']
Attempt swap
[1400/2000] tot_loss=2.508 (perp=9.866, rec=0.392, cos=0.143), tot_loss_proj:3.200 [t=0.22s]
prediction: ['[CLS] original neither funny nor cape creatures nor cape goodnight cannot animated [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.472 (perp=9.401, rec=0.397, cos=0.195), tot_loss_proj:3.037 [t=0.22s]
prediction: ['[CLS] original neither animated nor cape creatures nor cape goodnight cannot funny [SEP]']
[1500/2000] tot_loss=2.604 (perp=10.497, rec=0.383, cos=0.122), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] original neither animated than cape creatures nor cape goodnight cannot funny [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.649 (perp=10.216, rec=0.386, cos=0.221), tot_loss_proj:3.228 [t=0.22s]
prediction: ['[CLS] than neither animated original cape creatures nor cape goodnight cannot funny [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.673 (perp=10.533, rec=0.391, cos=0.176), tot_loss_proj:3.592 [t=0.22s]
prediction: ['[CLS] than neither animated original cape creatures nor funny bourne goodnight cannot [SEP]']
[1650/2000] tot_loss=2.719 (perp=10.533, rec=0.383, cos=0.230), tot_loss_proj:3.590 [t=0.22s]
prediction: ['[CLS] than neither animated original cape creatures nor funny bourne goodnight cannot [SEP]']
Attempt swap
[1700/2000] tot_loss=2.643 (perp=10.533, rec=0.386, cos=0.151), tot_loss_proj:3.594 [t=0.22s]
prediction: ['[CLS] than neither animated original cape creatures nor funny bourne goodnight cannot [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.647 (perp=10.208, rec=0.391, cos=0.215), tot_loss_proj:3.551 [t=0.22s]
prediction: ['[CLS] than neither animated original bourne creatures nor funny cape goodnight cannot [SEP]']
[1800/2000] tot_loss=2.736 (perp=10.881, rec=0.392, cos=0.169), tot_loss_proj:3.617 [t=0.22s]
prediction: ['[CLS] than neither animated original bourne sessions nor funny cape goodnight cannot [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.719 (perp=10.470, rec=0.386, cos=0.239), tot_loss_proj:3.573 [t=0.22s]
prediction: ['[CLS] than neither bourne original animated sessions nor funny cape goodnight cannot [SEP]']
Attempt swap
[1900/2000] tot_loss=2.652 (perp=10.470, rec=0.385, cos=0.172), tot_loss_proj:3.574 [t=0.22s]
prediction: ['[CLS] than neither bourne original animated sessions nor funny cape goodnight cannot [SEP]']
[1950/2000] tot_loss=2.701 (perp=10.470, rec=0.379, cos=0.228), tot_loss_proj:3.577 [t=0.22s]
prediction: ['[CLS] than neither bourne original animated sessions nor funny cape goodnight cannot [SEP]']
Attempt swap
[2000/2000] tot_loss=2.706 (perp=10.470, rec=0.370, cos=0.242), tot_loss_proj:3.572 [t=0.22s]
prediction: ['[CLS] than neither bourne original animated sessions nor funny cape goodnight cannot [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] than neither bourne original animated sessions nor funny cape goodnight cannot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 46.154 | r: 54.545
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 46.154 | r: 54.545
rougeLsum  | fm: 50.000 | p: 46.154 | r: 54.545
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 86.761 | p: 85.862 | r: 87.880
rouge2     | fm: 54.428 | p: 54.133 | r: 54.871
rougeL     | fm: 76.346 | p: 75.562 | r: 77.267
rougeLsum  | fm: 76.277 | p: 75.484 | r: 77.272
r1fm+r2fm = 141.190

input #94 time: 0:08:48 | total time: 14:16:24


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.8433581136753758
highest_index [0]
highest [0.8433581136753758]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.0311760902404785 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.0184509754180908 for ['[CLS] reprinted geographic fairchild clary remains hitler tristanved thumb big hot dates muscle commander funding [SEP]']
[Init] best rec loss: 0.9943406581878662 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9901204705238342 for ['[CLS] head felt infrastructure frequencyori 2018 news window saint kw ministry tragic hour electric grant [SEP]']
[Init] best rec loss: 0.9836694002151489 for ['[CLS] sooner rue " pace leagues della smell sul epithet greenon power local concacaf relay [SEP]']
[Init] best rec loss: 0.9804097414016724 for ['[CLS] footprint brain arrival rec [MASK] 45 reverse if pal struggled spanning caleb born day classic [SEP]']
[Init] best rec loss: 0.9768874645233154 for ['[CLS] elephant insuranceheater you session naturehoot eye attic stake bus cheating about injection temple [SEP]']
[Init] best rec loss: 0.9692021012306213 for ['[CLS] gas somewhereator bulk aka unlessssee actual como deliver? jockuble occasion [SEP]']
[Init] best perm rec loss: 0.9649105072021484 for ['[CLS] deliver unlessssee actual aka como occasion jocku somewhereble gas bulk?ator [SEP]']
[Init] best perm rec loss: 0.9645350575447083 for ['[CLS]sseeator jock como gas unless actualble bulk occasion somewhere? deliveru aka [SEP]']
[Init] best perm rec loss: 0.964383602142334 for ['[CLS] unlessssee bulku como gasator deliver occasion? actualble somewhere jock aka [SEP]']
[Init] best perm rec loss: 0.9639659523963928 for ['[CLS] bulk actualatoruble? como occasion deliver somewhere gasssee aka jock unless [SEP]']
[Init] best perm rec loss: 0.9625771045684814 for ['[CLS] unlessator actualu?ssee deliver aka gas somewhere bulkble occasion jock como [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.441 (perp=12.492, rec=0.642, cos=0.301), tot_loss_proj:4.356 [t=0.22s]
prediction: ['[CLS] appearance prepared betty avoiding as ) series & alive place simone anang springs you [SEP]']
[ 100/2000] tot_loss=3.168 (perp=12.184, rec=0.538, cos=0.193), tot_loss_proj:4.171 [t=0.22s]
prediction: ['[CLS] appearance dadmissive avoiding characters regret, " hopeless dynasty moses an outstanding perfectionquitable [SEP]']
[ 150/2000] tot_loss=3.323 (perp=12.866, rec=0.544, cos=0.206), tot_loss_proj:4.058 [t=0.22s]
prediction: ['[CLS] appearancessat reacher tavi aftermath ) a " hopeless dynasty willard an becomes primitivequitable [SEP]']
[ 200/2000] tot_loss=3.183 (perp=12.416, rec=0.512, cos=0.188), tot_loss_proj:3.313 [t=0.22s]
prediction: ['[CLS] becomessat hopeless slate aftermath ; a became hopeless dynasty hopeless an becomes hopelessquitable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.669 (perp=14.015, rec=0.585, cos=0.281), tot_loss_proj:4.341 [t=0.22s]
prediction: ['[CLS] becomessatquitable slate aftermathrut becomes became hopelessdle willard ) becomesitude louisiana [SEP]']
[ 300/2000] tot_loss=3.248 (perp=12.249, rec=0.495, cos=0.303), tot_loss_proj:3.368 [t=0.22s]
prediction: ['[CLS] becomes hopelessˈ slate aftermath ; becomes became hopelessdle willard an becomes hopeless hopeless [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.131 (perp=11.787, rec=0.505, cos=0.269), tot_loss_proj:3.525 [t=0.22s]
prediction: ['[CLS] becomes hopelessˈ slate settled ( willard becomes hopelessdle becomes [SEP] becomes hopeless hopeless [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.027 (perp=11.195, rec=0.511, cos=0.277), tot_loss_proj:3.201 [t=0.22s]
prediction: ['[CLS] becomes hopeless cannabis slatedle ( willard becomes hopeless summarized becomes [SEP] becomes hopeless hopeless [SEP]']
[ 450/2000] tot_loss=2.999 (perp=11.716, rec=0.430, cos=0.226), tot_loss_proj:3.373 [t=0.22s]
prediction: ['[CLS] becomes hopeless ª wellesdle ( willard becomes hopeless summarized becomesᅭ becomes hopeless hopeless [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.058 (perp=12.121, rec=0.441, cos=0.193), tot_loss_proj:3.513 [t=0.22s]
prediction: ['[CLS] becomes hopeless morale ªdle ^ willard becomes hopeless settled becomesᅭ becomes hopeless hopeless [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.198 (perp=12.424, rec=0.485, cos=0.228), tot_loss_proj:3.554 [t=0.22s]
prediction: ['[CLS] becomes hopeless orleans blowdle welles hopeless becomes hopeless where becomesᅭ becomes hopeless hopeless [SEP]']
[ 600/2000] tot_loss=2.697 (perp=10.712, rec=0.408, cos=0.146), tot_loss_proj:3.139 [t=0.22s]
prediction: ['[CLS] becomes hopeless / blowdle wi hopeless becomes hopeless where becomesᅭ becomes hopeless hopeless [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.981 (perp=11.555, rec=0.407, cos=0.262), tot_loss_proj:3.697 [t=0.22s]
prediction: ['[CLS] becomes hopeless / somedaydle welles hopeless becomes hopeless where hopeless becomeshead becomes gandhi [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.689 (perp=10.431, rec=0.414, cos=0.189), tot_loss_proj:3.393 [t=0.22s]
prediction: ['[CLS] becomes hopeless / hopelessdle welles someday becomes hopeless where hopeless becomes unnoticed becomes gandhi [SEP]']
[ 750/2000] tot_loss=3.408 (perp=13.037, rec=0.556, cos=0.244), tot_loss_proj:4.157 [t=0.22s]
prediction: ['[CLS] becomes hopeless orleans chavezdlejia someday becomes hopeless © hopeless becomes an becomes gandhi [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.076 (perp=12.008, rec=0.444, cos=0.230), tot_loss_proj:3.556 [t=0.22s]
prediction: ['[CLS] becomes hopeless polymer chavez wellesquitable becomes hopeless where hopeless becomes an becomedle gandhi [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.985 (perp=11.352, rec=0.417, cos=0.298), tot_loss_proj:3.623 [t=0.22s]
prediction: ['[CLS]quitable hopeless polymer willard welles becomes story hopeless where hopeless becomes an becomedle gandhi [SEP]']
[ 900/2000] tot_loss=3.060 (perp=11.824, rec=0.405, cos=0.290), tot_loss_proj:3.705 [t=0.22s]
prediction: ['[CLS]quitable hopeless polymer chavez welles becomes story hopeless where hopeless becomes an becomedle gandhi [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.938 (perp=11.226, rec=0.412, cos=0.281), tot_loss_proj:3.608 [t=0.22s]
prediction: ['[CLS]quitable hopeless polymer chavez becomes story hopeless where hopeless welles becomes an becomedle gandhi [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.731 (perp=10.866, rec=0.397, cos=0.160), tot_loss_proj:3.453 [t=0.22s]
prediction: ['[CLS] polymer hopelessquitable chavez becomes story hopeless where hopeless welles becomes an becomedle gandhi [SEP]']
[1050/2000] tot_loss=2.696 (perp=10.804, rec=0.384, cos=0.151), tot_loss_proj:3.613 [t=0.22s]
prediction: ['[CLS] polymer hopeless someday chavez becomes story hopeless where hopeless welles becomes an becomedle gandhi [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.721 (perp=10.671, rec=0.381, cos=0.206), tot_loss_proj:3.658 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopeless welles becomes an becomedle gandhi [SEP]']
Attempt swap
[1150/2000] tot_loss=2.739 (perp=10.671, rec=0.379, cos=0.226), tot_loss_proj:3.660 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopeless welles becomes an becomedle gandhi [SEP]']
[1200/2000] tot_loss=3.028 (perp=11.933, rec=0.378, cos=0.263), tot_loss_proj:3.693 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopeless welles becomes un becomedle shack [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.896 (perp=11.795, rec=0.383, cos=0.154), tot_loss_proj:3.564 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopeless welles becomes undle become shack [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.979 (perp=12.002, rec=0.382, cos=0.197), tot_loss_proj:3.653 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjia becomesizeddle shack become [SEP]']
[1350/2000] tot_loss=3.004 (perp=12.002, rec=0.374, cos=0.229), tot_loss_proj:3.656 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjia becomesizeddle shack become [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.847 (perp=11.652, rec=0.368, cos=0.148), tot_loss_proj:3.582 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1450/2000] tot_loss=2.872 (perp=11.652, rec=0.364, cos=0.177), tot_loss_proj:3.590 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
[1500/2000] tot_loss=2.923 (perp=11.652, rec=0.367, cos=0.225), tot_loss_proj:3.580 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1550/2000] tot_loss=2.991 (perp=11.652, rec=0.367, cos=0.293), tot_loss_proj:3.583 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1600/2000] tot_loss=2.857 (perp=11.652, rec=0.362, cos=0.164), tot_loss_proj:3.585 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
[1650/2000] tot_loss=2.896 (perp=11.652, rec=0.364, cos=0.201), tot_loss_proj:3.583 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1700/2000] tot_loss=2.950 (perp=11.652, rec=0.360, cos=0.259), tot_loss_proj:3.586 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1750/2000] tot_loss=2.872 (perp=11.652, rec=0.356, cos=0.186), tot_loss_proj:3.584 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
[1800/2000] tot_loss=2.897 (perp=11.652, rec=0.362, cos=0.205), tot_loss_proj:3.593 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1850/2000] tot_loss=2.928 (perp=11.652, rec=0.357, cos=0.240), tot_loss_proj:3.587 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[1900/2000] tot_loss=2.925 (perp=11.652, rec=0.353, cos=0.242), tot_loss_proj:3.588 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
[1950/2000] tot_loss=2.896 (perp=11.652, rec=0.359, cos=0.207), tot_loss_proj:3.582 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Attempt swap
[2000/2000] tot_loss=2.933 (perp=11.652, rec=0.357, cos=0.246), tot_loss_proj:3.588 [t=0.22s]
prediction: ['[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] someday hopeless polymer chavez becomes story hopeless where hopelessjiadleized becomes shack become [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 43.478 | p: 35.714 | r: 55.556
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 34.783 | p: 28.571 | r: 44.444
rougeLsum  | fm: 34.783 | p: 28.571 | r: 44.444
r1fm+r2fm = 43.478

[Aggregate metrics]:
rouge1     | fm: 86.291 | p: 85.319 | r: 87.554
rouge2     | fm: 53.895 | p: 53.570 | r: 54.303
rougeL     | fm: 75.710 | p: 74.898 | r: 76.793
rougeLsum  | fm: 75.874 | p: 75.025 | r: 76.866
r1fm+r2fm = 140.186

input #95 time: 0:08:54 | total time: 14:25:18


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.8647858652884262
highest_index [0]
highest [0.8647858652884262]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8353004455566406 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8133513927459717 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 0.8048515319824219 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7859963178634644 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7738314867019653 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7713531851768494 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 0.7563806176185608 for ['[CLS] foreign x universalhausen ant southeast leave brands ascent perpendicular are article holding wrestling capability [SEP]']
[Init] best perm rec loss: 0.7535303235054016 for ['[CLS] wrestling x article southeast holding perpendicular foreign leavehausen ascent universal capability are ant brands [SEP]']
[Init] best perm rec loss: 0.7533855438232422 for ['[CLS] foreign universal ascent southeast article leave ant brands xhausen perpendicular capability are wrestling holding [SEP]']
[Init] best perm rec loss: 0.7529667019844055 for ['[CLS] article wrestling holding are universalhausen southeast perpendicular capability brands ant ascent x leave foreign [SEP]']
[Init] best perm rec loss: 0.7523720860481262 for ['[CLS] brandshausen southeast wrestling article leave foreign are universal ant capability perpendicular ascent holding x [SEP]']
[Init] best perm rec loss: 0.7523212432861328 for ['[CLS] brands perpendicular ant are leave x article wrestling foreign universal holding southeasthausen ascent capability [SEP]']
[Init] best perm rec loss: 0.7513741254806519 for ['[CLS] anthausen ascent leave universal foreign brands southeast perpendicular x are wrestling capability article holding [SEP]']
[Init] best perm rec loss: 0.7489926218986511 for ['[CLS] leave article x brands foreign wrestling are southeast perpendicular ant universalhausen ascent holding capability [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.870 (perp=11.297, rec=0.357, cos=0.253), tot_loss_proj:3.820 [t=0.22s]
prediction: ['[CLS] gonzalez force solo on on damage need allow in chance donovanman raise into interaction [SEP]']
[ 100/2000] tot_loss=2.707 (perp=10.988, rec=0.260, cos=0.250), tot_loss_proj:3.592 [t=0.22s]
prediction: ['[CLS] himself people on into into force involved become lesser situations lesser men leave lesser cover [SEP]']
[ 150/2000] tot_loss=2.436 (perp=10.107, rec=0.186, cos=0.229), tot_loss_proj:3.255 [t=0.22s]
prediction: ['[CLS] force people on and into force needs make lesser situations lesser men run lesser cover [SEP]']
[ 200/2000] tot_loss=2.407 (perp=10.230, rec=0.116, cos=0.246), tot_loss_proj:3.348 [t=0.22s]
prediction: ['[CLS] force people on and into himself would make lesser situations lesser men run lesser cover [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.234 (perp=9.497, rec=0.100, cos=0.235), tot_loss_proj:2.799 [t=0.22s]
prediction: ['[CLS] force people on and into himself would lesser situations make lesser men run lesser cover [SEP]']
[ 300/2000] tot_loss=2.239 (perp=9.497, rec=0.089, cos=0.250), tot_loss_proj:2.799 [t=0.22s]
prediction: ['[CLS] force people on and into himself would lesser situations make lesser men run lesser cover [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.208 (perp=9.371, rec=0.083, cos=0.251), tot_loss_proj:3.032 [t=0.22s]
prediction: ['[CLS] force on people and into himself would lesser situations make lesser men run lesser cover [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.134 (perp=9.002, rec=0.084, cos=0.250), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS] force on people and himself would into lesser situations make lesser men run lesser cover [SEP]']
[ 450/2000] tot_loss=2.134 (perp=9.002, rec=0.082, cos=0.251), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS] force on people and himself would into lesser situations make lesser men run lesser cover [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.087 (perp=8.807, rec=0.083, cos=0.243), tot_loss_proj:2.991 [t=0.22s]
prediction: ['[CLS] force on people himself and would into lesser situations make lesser men run lesser cover [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.805 (perp=7.419, rec=0.076, cos=0.245), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[ 600/2000] tot_loss=1.804 (perp=7.419, rec=0.072, cos=0.248), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.802 (perp=7.419, rec=0.069, cos=0.249), tot_loss_proj:3.004 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=7.419, rec=0.069, cos=0.249), tot_loss_proj:3.002 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[ 750/2000] tot_loss=1.796 (perp=7.419, rec=0.063, cos=0.249), tot_loss_proj:3.002 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=7.419, rec=0.071, cos=0.249), tot_loss_proj:3.001 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.802 (perp=7.419, rec=0.068, cos=0.250), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[ 900/2000] tot_loss=1.810 (perp=7.419, rec=0.077, cos=0.249), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.806 (perp=7.419, rec=0.073, cos=0.250), tot_loss_proj:2.995 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1000/2000] tot_loss=1.795 (perp=7.419, rec=0.062, cos=0.250), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[1050/2000] tot_loss=1.797 (perp=7.419, rec=0.063, cos=0.250), tot_loss_proj:2.993 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1100/2000] tot_loss=1.798 (perp=7.419, rec=0.064, cos=0.250), tot_loss_proj:2.993 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1150/2000] tot_loss=1.804 (perp=7.419, rec=0.071, cos=0.249), tot_loss_proj:2.989 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[1200/2000] tot_loss=1.803 (perp=7.419, rec=0.070, cos=0.250), tot_loss_proj:2.991 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1250/2000] tot_loss=1.800 (perp=7.419, rec=0.066, cos=0.250), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1300/2000] tot_loss=1.798 (perp=7.419, rec=0.064, cos=0.250), tot_loss_proj:2.988 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[1350/2000] tot_loss=1.794 (perp=7.419, rec=0.061, cos=0.250), tot_loss_proj:2.986 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1400/2000] tot_loss=1.805 (perp=7.419, rec=0.071, cos=0.250), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1450/2000] tot_loss=1.792 (perp=7.419, rec=0.058, cos=0.250), tot_loss_proj:2.992 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[1500/2000] tot_loss=1.808 (perp=7.419, rec=0.074, cos=0.250), tot_loss_proj:2.993 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1550/2000] tot_loss=1.804 (perp=7.419, rec=0.070, cos=0.250), tot_loss_proj:2.986 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1600/2000] tot_loss=1.804 (perp=7.419, rec=0.070, cos=0.250), tot_loss_proj:2.987 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
[1650/2000] tot_loss=1.803 (perp=7.419, rec=0.069, cos=0.250), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]']
Attempt swap
[1700/2000] tot_loss=1.834 (perp=7.587, rec=0.066, cos=0.250), tot_loss_proj:2.991 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make would men run for cover [SEP]']
Attempt swap
[1750/2000] tot_loss=1.836 (perp=7.587, rec=0.069, cos=0.250), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make would men run for cover [SEP]']
[1800/2000] tot_loss=1.829 (perp=7.587, rec=0.062, cos=0.250), tot_loss_proj:2.992 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would make would men run for cover [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.790 (perp=7.368, rec=0.067, cos=0.249), tot_loss_proj:3.042 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would would make men run for cover [SEP]']
Attempt swap
[1900/2000] tot_loss=1.789 (perp=7.368, rec=0.066, cos=0.249), tot_loss_proj:3.042 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would would make men run for cover [SEP]']
[1950/2000] tot_loss=1.800 (perp=7.368, rec=0.077, cos=0.249), tot_loss_proj:3.041 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would would make men run for cover [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=7.368, rec=0.069, cos=0.249), tot_loss_proj:3.042 [t=0.22s]
prediction: ['[CLS] force on people himself and into lesser situations would would make men run for cover [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] force on people himself and into lesser situations would make lesser men run for cover [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.235 | p: 88.235 | r: 88.235
rougeLsum  | fm: 88.235 | p: 88.235 | r: 88.235
r1fm+r2fm = 156.618

[Aggregate metrics]:
rouge1     | fm: 86.398 | p: 85.413 | r: 87.588
rouge2     | fm: 54.090 | p: 53.731 | r: 54.499
rougeL     | fm: 76.016 | p: 75.178 | r: 77.034
rougeLsum  | fm: 75.962 | p: 75.122 | r: 76.966
r1fm+r2fm = 140.488

input #96 time: 0:08:54 | total time: 14:34:13


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.8269460837492295
highest_index [0]
highest [0.8269460837492295]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7543307542800903 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.7293781042098999 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.7272301912307739 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.7262187004089355 for ['[CLS]ten pass test which 2016 victoria [SEP]']
[Init] best perm rec loss: 0.7246458530426025 for ['[CLS] test which victoria passten 2016 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.554 (perp=14.350, rec=0.365, cos=0.319), tot_loss_proj:4.088 [t=0.22s]
prediction: ['[CLS] theme everyfor commission immortal characters [SEP]']
[ 100/2000] tot_loss=2.263 (perp=8.856, rec=0.185, cos=0.307), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] theme unfor themegettable [SEP]']
[ 150/2000] tot_loss=2.395 (perp=9.790, rec=0.125, cos=0.311), tot_loss_proj:2.937 [t=0.22s]
prediction: ['[CLS] ride unfor charactersgettable [SEP]']
[ 200/2000] tot_loss=2.288 (perp=9.422, rec=0.099, cos=0.304), tot_loss_proj:3.281 [t=0.22s]
prediction: ['[CLS] theme unfor charactersgettable [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.730 (perp=6.663, rec=0.092, cos=0.305), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] online unforgettable characters [SEP]']
[ 300/2000] tot_loss=1.437 (perp=5.309, rec=0.073, cos=0.303), tot_loss_proj:1.439 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.430 (perp=5.309, rec=0.056, cos=0.312), tot_loss_proj:1.443 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.434 (perp=5.309, rec=0.058, cos=0.314), tot_loss_proj:1.432 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.442 (perp=5.309, rec=0.066, cos=0.315), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.441 (perp=5.309, rec=0.064, cos=0.315), tot_loss_proj:1.438 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.451 (perp=5.309, rec=0.073, cos=0.315), tot_loss_proj:1.432 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.445 (perp=5.309, rec=0.068, cos=0.315), tot_loss_proj:1.435 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.431 (perp=5.309, rec=0.054, cos=0.315), tot_loss_proj:1.430 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.445 (perp=5.309, rec=0.067, cos=0.315), tot_loss_proj:1.439 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.438 (perp=5.309, rec=0.061, cos=0.316), tot_loss_proj:1.447 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.434 (perp=5.309, rec=0.056, cos=0.316), tot_loss_proj:1.437 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.423 (perp=5.309, rec=0.045, cos=0.316), tot_loss_proj:1.438 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.436 (perp=5.309, rec=0.059, cos=0.316), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.443 (perp=5.309, rec=0.065, cos=0.316), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.437 (perp=5.309, rec=0.059, cos=0.316), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.429 (perp=5.309, rec=0.052, cos=0.316), tot_loss_proj:1.426 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.447 (perp=5.309, rec=0.069, cos=0.316), tot_loss_proj:1.431 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.442 (perp=5.309, rec=0.064, cos=0.316), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.432 (perp=5.309, rec=0.054, cos=0.316), tot_loss_proj:1.440 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.439 (perp=5.309, rec=0.062, cos=0.316), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.447 (perp=5.309, rec=0.069, cos=0.316), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.440 (perp=5.309, rec=0.063, cos=0.316), tot_loss_proj:1.442 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.429 (perp=5.309, rec=0.052, cos=0.316), tot_loss_proj:1.427 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.432 (perp=5.309, rec=0.055, cos=0.316), tot_loss_proj:1.447 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.445 (perp=5.309, rec=0.068, cos=0.316), tot_loss_proj:1.440 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.445 (perp=5.309, rec=0.067, cos=0.316), tot_loss_proj:1.449 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.441 (perp=5.309, rec=0.064, cos=0.316), tot_loss_proj:1.433 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.435 (perp=5.309, rec=0.058, cos=0.316), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.426 (perp=5.309, rec=0.048, cos=0.316), tot_loss_proj:1.452 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.443 (perp=5.309, rec=0.065, cos=0.316), tot_loss_proj:1.434 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.425 (perp=5.309, rec=0.047, cos=0.316), tot_loss_proj:1.448 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.437 (perp=5.309, rec=0.059, cos=0.316), tot_loss_proj:1.439 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.437 (perp=5.309, rec=0.060, cos=0.316), tot_loss_proj:1.435 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.436 (perp=5.309, rec=0.059, cos=0.316), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.430 (perp=5.309, rec=0.052, cos=0.316), tot_loss_proj:1.449 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.503 | p: 85.549 | r: 87.721
rouge2     | fm: 54.445 | p: 54.116 | r: 54.840
rougeL     | fm: 76.282 | p: 75.524 | r: 77.312
rougeLsum  | fm: 76.339 | p: 75.488 | r: 77.343
r1fm+r2fm = 140.948

input #97 time: 0:08:48 | total time: 14:43:01


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.8785005644791556
highest_index [0]
highest [0.8785005644791556]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6505756378173828 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6490594148635864 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.962 (perp=12.257, rec=0.295, cos=0.215), tot_loss_proj:3.536 [t=0.22s]
prediction: ['[CLS] emptyfulful losses [SEP]']
[ 100/2000] tot_loss=2.804 (perp=12.067, rec=0.166, cos=0.225), tot_loss_proj:3.287 [t=0.22s]
prediction: ['[CLS] unfulful losses [SEP]']
[ 150/2000] tot_loss=2.520 (perp=10.905, rec=0.115, cos=0.225), tot_loss_proj:3.135 [t=0.22s]
prediction: ['[CLS] unllingful losses [SEP]']
[ 200/2000] tot_loss=2.654 (perp=11.610, rec=0.120, cos=0.212), tot_loss_proj:3.246 [t=0.22s]
prediction: ['[CLS] unllingful additional [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.308 (perp=4.947, rec=0.099, cos=0.220), tot_loss_proj:1.297 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.280 (perp=4.947, rec=0.066, cos=0.225), tot_loss_proj:1.280 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.265 (perp=4.947, rec=0.049, cos=0.226), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.282 (perp=4.947, rec=0.065, cos=0.227), tot_loss_proj:1.284 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.278 (perp=4.947, rec=0.061, cos=0.228), tot_loss_proj:1.281 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.268 (perp=4.947, rec=0.051, cos=0.228), tot_loss_proj:1.277 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.277 (perp=4.947, rec=0.059, cos=0.228), tot_loss_proj:1.275 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.267 (perp=4.947, rec=0.065, cos=0.213), tot_loss_proj:1.287 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.282 (perp=4.947, rec=0.066, cos=0.227), tot_loss_proj:1.273 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.265 (perp=4.947, rec=0.048, cos=0.228), tot_loss_proj:1.282 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.280 (perp=4.947, rec=0.063, cos=0.228), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.274 (perp=4.947, rec=0.057, cos=0.228), tot_loss_proj:1.290 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.274 (perp=4.947, rec=0.057, cos=0.228), tot_loss_proj:1.284 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.276 (perp=4.947, rec=0.059, cos=0.228), tot_loss_proj:1.285 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.286 (perp=4.947, rec=0.072, cos=0.224), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.272 (perp=4.947, rec=0.055, cos=0.227), tot_loss_proj:1.286 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.268 (perp=4.947, rec=0.051, cos=0.228), tot_loss_proj:1.277 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.271 (perp=4.947, rec=0.053, cos=0.228), tot_loss_proj:1.289 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.285 (perp=4.947, rec=0.068, cos=0.228), tot_loss_proj:1.286 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.273 (perp=4.947, rec=0.056, cos=0.228), tot_loss_proj:1.280 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.293 (perp=4.947, rec=0.075, cos=0.228), tot_loss_proj:1.270 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.260 (perp=4.947, rec=0.042, cos=0.228), tot_loss_proj:1.275 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.283 (perp=4.947, rec=0.066, cos=0.228), tot_loss_proj:1.295 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.285 (perp=4.947, rec=0.067, cos=0.228), tot_loss_proj:1.287 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.273 (perp=4.947, rec=0.057, cos=0.226), tot_loss_proj:1.303 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.283 (perp=4.947, rec=0.066, cos=0.227), tot_loss_proj:1.289 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.271 (perp=4.947, rec=0.054, cos=0.228), tot_loss_proj:1.285 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.281 (perp=4.947, rec=0.064, cos=0.228), tot_loss_proj:1.280 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.275 (perp=4.947, rec=0.057, cos=0.228), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.284 (perp=4.947, rec=0.066, cos=0.228), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.280 (perp=4.947, rec=0.062, cos=0.228), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.275 (perp=4.947, rec=0.058, cos=0.228), tot_loss_proj:1.292 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.284 (perp=4.947, rec=0.066, cos=0.228), tot_loss_proj:1.277 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.272 (perp=4.947, rec=0.055, cos=0.228), tot_loss_proj:1.280 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.281 (perp=4.947, rec=0.063, cos=0.228), tot_loss_proj:1.289 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.272 (perp=4.947, rec=0.055, cos=0.228), tot_loss_proj:1.276 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.690 | p: 85.748 | r: 87.900
rouge2     | fm: 54.848 | p: 54.505 | r: 55.216
rougeL     | fm: 76.573 | p: 75.737 | r: 77.569
rougeLsum  | fm: 76.440 | p: 75.660 | r: 77.430
r1fm+r2fm = 141.538

input #98 time: 0:08:47 | total time: 14:51:48


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.8812660403805372
highest_index [0]
highest [0.8812660403805372]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8054328560829163 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.792051374912262 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7634684443473816 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7557575702667236 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.744829535484314 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7380564212799072 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7363418340682983 for ['[CLS] dental services synonym when slight cushion orient garcia barbie earliest distance bearing re still himself claire [MASK] forced opposedˈ ratings harper temps currently actually rightte ferns bet screensaging taste thunder knowledgets te [SEP]']
[Init] best perm rec loss: 0.7341373562812805 for ['[CLS]ˈ tasteaging forced right dental orient [MASK] cushionte opposed ferns screens barbie bearing services temps thunder te knowledge earliest himself actually when distance bet clairets ratings slight re synonym currently garcia still harper [SEP]']
[Init] best perm rec loss: 0.7340615391731262 for ['[CLS] bet re slight services ratings dental actually harper screens when currently garcia claireˈ right earliest taste himself opposed cushion forced knowledge bearing distance barbie thunderteaging synonym orientts te still ferns temps [MASK] [SEP]']
[Init] best perm rec loss: 0.7335733771324158 for ['[CLS] screenste currently knowledge slightts re bet himselfˈaging orient services taste harper te distance synonym earliest still ratings barbie dental [MASK] claire garcia right when cushion opposed actually thunder ferns bearing temps forced [SEP]']
[Init] best perm rec loss: 0.7332755327224731 for ['[CLS] forced right earliest actually dental opposedˈ screens re currently barbie bet bearing services when ratings orient te claire synonym garcia taste himself still temps harper ferns distanceaging cushiontets [MASK] thunder slight knowledge [SEP]']
[Init] best perm rec loss: 0.7327141165733337 for ['[CLS] cushionte orient actually distance synonym still garcia barbie claire taste currently earliest servicests [MASK] screens te knowledge slight opposed bearing bet forced tempsaging ratings when himself rightˈ harper re dental ferns thunder [SEP]']
[Init] best perm rec loss: 0.7314876317977905 for ['[CLS] currentlyts cushion still earliestaging garcia dental harper re synonym claire taste ferns barbie services te right himself screens temps ratings when knowledge bearing actuallyˈ distance opposed slight forcedte orient thunder [MASK] bet [SEP]']
[Init] best perm rec loss: 0.7308281660079956 for ['[CLS] te thunder re ratings taste still ferns knowledge himselfˈ garcia currently [MASK] claire cushion slightaging opposed barbiets right dental harper forced earliest synonym actually services screens when bearing distance orient bette temps [SEP]']
[Init] best perm rec loss: 0.7305322885513306 for ['[CLS] claire himself orient te thunder bearing forced knowledge harper earliestaging slight when ferns right taste opposedˈ still barbie currently screenste synonym cushion actually ratings servicests garcia dental bet distance [MASK] re temps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.063 (perp=12.307, rec=0.401, cos=0.200), tot_loss_proj:3.538 [t=0.22s]
prediction: ['[CLS] nevergizing congressional lawsuit around0 ticket by ignoring germans late divi junk processing they anyus control ruined during governmentst defensivenellable package threats " detect dental evidence cases teamers fia [SEP]']
[ 100/2000] tot_loss=3.008 (perp=12.209, rec=0.322, cos=0.243), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] tried hurting presidential government articles5 funssing federal players officially disussing hours an -age under ruined during thest skin implementations disease package newscast but an bail prohibition getting films chase [SEP]']
[ 150/2000] tot_loss=2.722 (perp=11.465, rec=0.246, cos=0.183), tot_loss_proj:3.627 [t=0.22s]
prediction: ["[CLS] freakingssing presidential soviet articles & funssing federal korea thanks di'ssing work ` - crime mis stolen during notssing obviously ridiculous disease matter newscast but got bail postage di films chase [SEP]"]
[ 200/2000] tot_loss=2.679 (perp=11.119, rec=0.256, cos=0.199), tot_loss_proj:3.413 [t=0.22s]
prediction: ['[CLS]ssingssing liberals yankees matches much funssing his riders yelled dimassing it ` - crime mis rotten this yourssing\'" during matter ticket but had terrible it di filming chase [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.528 (perp=10.663, rec=0.195, cos=0.200), tot_loss_proj:3.218 [t=0.22s]
prediction: ['[CLS]ssing spoiled ` classic words much funssing his rider walked di\'ssing it ` - crimecing horrible but\'finallyssing " ` matter ticket but had terrible it di film that besides [SEP]']
[ 300/2000] tot_loss=2.586 (perp=11.012, rec=0.178, cos=0.205), tot_loss_proj:3.121 [t=0.22s]
prediction: ['[CLS]ssing walked ` classic ` much funssing the captain walked di\'ssing ticket ` - mindcing horrible this\'ssingssing " ` problem ticket but had terrible it di film that besides [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.575 (perp=11.103, rec=0.162, cos=0.192), tot_loss_proj:3.570 [t=0.22s]
prediction: ['[CLS]ssing backed ` classic things much funssing the ` walked di\'ssing ticket ` - mindcing horrible the\'dissing " ` stress ticket but had terrible\'ssing film much besides [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.453 (perp=10.449, rec=0.156, cos=0.207), tot_loss_proj:3.193 [t=0.22s]
prediction: ["[CLS]ssing backed ` donald muttering much funssing the ` walked dissing ticket ` - mind 'cing horrible the'dissing'`'ticket but had terrible'ssing film much besides [SEP]"]
[ 450/2000] tot_loss=2.378 (perp=10.058, rec=0.148, cos=0.218), tot_loss_proj:3.028 [t=0.22s]
prediction: ["[CLS]ssing walked ` ` muttering much funssing the ` walked dissing ticket ` - mind 'cing horrible the'dissing'` stress ticket but had terrible'' film much besides [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.261 (perp=9.571, rec=0.139, cos=0.207), tot_loss_proj:2.892 [t=0.22s]
prediction: ["[CLS]ssing walked ` ` muttering much funssing'` walked dissing ticket ` - mind thecing horrible the'dissing'` mind ticket but had terrible'' film much besides [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.147 (perp=8.961, rec=0.144, cos=0.210), tot_loss_proj:2.798 [t=0.22s]
prediction: ["[CLS]ssing walked ` ` muttering much funssing'` walked dissing ticket ` - mind the'horrible the'dissing ticket ` mind'but had terrible'' film much besides [SEP]"]
[ 600/2000] tot_loss=2.134 (perp=8.933, rec=0.136, cos=0.212), tot_loss_proj:2.879 [t=0.22s]
prediction: ["[CLS]ssing walked ` ` muttering much funssing'` walked dissing ticket ` - mind the'horrible the'dissing ticket ` mind'but had terrible'mind film much besides [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.197 (perp=9.250, rec=0.138, cos=0.210), tot_loss_proj:2.902 [t=0.22s]
prediction: ["[CLS]ssing walked ` announced muttering much funssing'` walked dissing mind ` - mind the'mind the'dissing ticket ` mind'but had terrible'horrible film much besides [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.128 (perp=8.950, rec=0.135, cos=0.203), tot_loss_proj:2.964 [t=0.22s]
prediction: ["[CLS]ssing walked ` muttering announced much funssing'` walked dissing mind ` and mind the'mind the'dissing ticket ` mind'but had terrible'horrible film much besides [SEP]"]
[ 750/2000] tot_loss=2.178 (perp=9.171, rec=0.130, cos=0.213), tot_loss_proj:2.906 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering announced much funssing'` walked dissing mind ` and mind the'' the'dissing ticket ` mind'but had terrible'horrible film much besides [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.149 (perp=9.046, rec=0.127, cos=0.212), tot_loss_proj:2.845 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering announced much funssing'` walked dissing mind ` and mind the ticket'the'dissing'` mind'but had terrible out horrible film much besides [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.096 (perp=8.777, rec=0.122, cos=0.219), tot_loss_proj:2.851 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering announced much funssing'n walked dissing mind ` and mind the ticket'the'dissing'` that'but had terrible out terrible film mind besides [SEP]"]
[ 900/2000] tot_loss=2.091 (perp=8.777, rec=0.119, cos=0.217), tot_loss_proj:2.854 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering announced much funssing'n walked dissing mind ` and mind the ticket'the'dissing'` that'but had terrible out terrible film mind besides [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.064 (perp=8.630, rec=0.122, cos=0.216), tot_loss_proj:2.780 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering aloud much funssing'n walked dissing'cost ` and mind the ticket'the dissing'` that'but had terrible out terrible film mind desperately [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.988 (perp=8.281, rec=0.121, cos=0.210), tot_loss_proj:2.684 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering aloud much funssing'n walked dissing'cost `'mind the ticket'the dissing'` that'but had terrible and terrible film mind so [SEP]"]
[1050/2000] tot_loss=1.974 (perp=8.281, rec=0.103, cos=0.214), tot_loss_proj:2.682 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering aloud much funssing'n walked dissing'cost `'mind the ticket'the dissing'` that'but had terrible and terrible film mind so [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.951 (perp=8.145, rec=0.105, cos=0.217), tot_loss_proj:2.750 [t=0.22s]
prediction: ["[CLS]uising walked ` muttering aloud much funssing'` walked dissing'cost n'mind the ticket'the dissing'` that'but had terrible and terrible film mind so [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.917 (perp=7.973, rec=0.107, cos=0.216), tot_loss_proj:2.808 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering aloud much funssing'` walked dissing'cost n'mind the ticket'the dissing'` that'but had terrible and terrible mind film so [SEP]"]
[1200/2000] tot_loss=1.915 (perp=7.935, rec=0.111, cos=0.217), tot_loss_proj:2.693 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'cost n'mind the ticket'the dissing'` that'but had terrible and terrible mind film so [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.900 (perp=7.935, rec=0.097, cos=0.216), tot_loss_proj:2.692 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'cost n'mind the ticket'the dissing'` that'but had terrible and terrible mind film so [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.881 (perp=7.791, rec=0.103, cos=0.220), tot_loss_proj:2.619 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'cost n'mind the ticket'the dissing'but that'` had terrible and terrible mind film so [SEP]"]
[1350/2000] tot_loss=1.917 (perp=8.002, rec=0.098, cos=0.219), tot_loss_proj:2.617 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'cost n'mind the ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.926 (perp=8.010, rec=0.105, cos=0.219), tot_loss_proj:2.611 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.921 (perp=8.010, rec=0.101, cos=0.218), tot_loss_proj:2.614 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
[1500/2000] tot_loss=1.921 (perp=8.010, rec=0.099, cos=0.220), tot_loss_proj:2.612 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.926 (perp=8.010, rec=0.104, cos=0.220), tot_loss_proj:2.613 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.927 (perp=8.010, rec=0.104, cos=0.221), tot_loss_proj:2.610 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
[1650/2000] tot_loss=1.925 (perp=8.010, rec=0.102, cos=0.221), tot_loss_proj:2.610 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.912 (perp=8.010, rec=0.090, cos=0.220), tot_loss_proj:2.608 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.924 (perp=8.010, rec=0.100, cos=0.222), tot_loss_proj:2.611 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
[1800/2000] tot_loss=1.923 (perp=8.010, rec=0.098, cos=0.223), tot_loss_proj:2.612 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.915 (perp=8.010, rec=0.094, cos=0.219), tot_loss_proj:2.626 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind ticket'the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.900 (perp=7.928, rec=0.096, cos=0.219), tot_loss_proj:2.617 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind'ticket the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
[1950/2000] tot_loss=1.902 (perp=7.928, rec=0.097, cos=0.219), tot_loss_proj:2.620 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind'ticket the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.901 (perp=7.928, rec=0.094, cos=0.221), tot_loss_proj:2.619 [t=0.22s]
prediction: ["[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind'ticket the dissing ` but that'` had terrible and terrible mind film so [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] answering walked ` muttering they much funssing'` walked dissing'costn'the mind'ticket the dissing ` but that'` had terrible and terrible mind film so [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 72.000 | r: 69.231
rouge2     | fm: 4.082 | p: 4.167 | r: 4.000
rougeL     | fm: 35.294 | p: 36.000 | r: 34.615
rougeLsum  | fm: 35.294 | p: 36.000 | r: 34.615
r1fm+r2fm = 74.670

[Aggregate metrics]:
rouge1     | fm: 86.521 | p: 85.546 | r: 87.709
rouge2     | fm: 54.420 | p: 54.078 | r: 54.823
rougeL     | fm: 76.061 | p: 75.305 | r: 77.109
rougeLsum  | fm: 76.190 | p: 75.344 | r: 77.183
r1fm+r2fm = 140.940

input #99 time: 0:08:52 | total time: 15:00:41


Average Cosine Similarity: 0.8612605572637498
Done with all.
